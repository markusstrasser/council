{"video_id": "x0_404KeDIc", "title": "Depth From Vision: Self-Supervision (Andrej Karpathy)", "description": "From Tesla Autonomy Day on April 22, 2019: https://youtu.be/Ucp0TTmvqOE", "author": "Yarrow Bouchard", "keywords": [], "channel_url": "https://www.youtube.com/channel/UChK-jDhbVRL10xQSVUthPBg", "length": 53, "views": 1216, "publish_date": "11/02/2022", "timestamp": 1577836800, "entity": "Andrew Kaparthy", "transcript": {"text": " The last mechanism I will talk about very briefly is slightly more fancy and gets a bit more technical, but it is a mechanism that has recently... There's a few papers basically over the last year or two on this approach. It's called self-supervision. So what you do in a lot of these papers is you only feed raw videos into neural networks with no labels whatsoever, and you can still get neural networks to learn depth. And it's a little bit technical, so I can't go into the full details, but the idea is that the neural network predicts depth at every single frame of that video, and then there are no explicit targets that the neural network is supposed to regress to with the labels, but instead the objective for the network is to be consistent over time. So whatever depth you predict should be consistent over the duration of that video, and the only way to be consistent is to be right, as the neural network automatically predicts the correct depths for all the pixels, and we've reproduced some of these results internally, so this also works quite well.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 8.0, "text": " The last mechanism I will talk about very briefly is slightly more fancy and gets a bit more technical, but it is a mechanism that has recently...", "tokens": [50364, 440, 1036, 7513, 286, 486, 751, 466, 588, 10515, 307, 4748, 544, 10247, 293, 2170, 257, 857, 544, 6191, 11, 457, 309, 307, 257, 7513, 300, 575, 3938, 485, 50764, 50764, 821, 311, 257, 1326, 10577, 1936, 670, 264, 1036, 1064, 420, 732, 322, 341, 3109, 13, 467, 311, 1219, 2698, 12, 48172, 6763, 13, 51064, 51064, 407, 437, 291, 360, 294, 257, 688, 295, 613, 10577, 307, 291, 787, 3154, 8936, 2145, 666, 18161, 9590, 365, 572, 16949, 17076, 11, 293, 291, 393, 920, 483, 18161, 9590, 281, 1466, 7161, 13, 51564, 51564], "temperature": 0.0, "avg_logprob": -0.15735236803690592, "compression_ratio": 1.64453125, "no_speech_prob": 0.027126329019665718}, {"id": 1, "seek": 0, "start": 8.0, "end": 14.0, "text": " There's a few papers basically over the last year or two on this approach. It's called self-supervision.", "tokens": [50364, 440, 1036, 7513, 286, 486, 751, 466, 588, 10515, 307, 4748, 544, 10247, 293, 2170, 257, 857, 544, 6191, 11, 457, 309, 307, 257, 7513, 300, 575, 3938, 485, 50764, 50764, 821, 311, 257, 1326, 10577, 1936, 670, 264, 1036, 1064, 420, 732, 322, 341, 3109, 13, 467, 311, 1219, 2698, 12, 48172, 6763, 13, 51064, 51064, 407, 437, 291, 360, 294, 257, 688, 295, 613, 10577, 307, 291, 787, 3154, 8936, 2145, 666, 18161, 9590, 365, 572, 16949, 17076, 11, 293, 291, 393, 920, 483, 18161, 9590, 281, 1466, 7161, 13, 51564, 51564], "temperature": 0.0, "avg_logprob": -0.15735236803690592, "compression_ratio": 1.64453125, "no_speech_prob": 0.027126329019665718}, {"id": 2, "seek": 0, "start": 14.0, "end": 24.0, "text": " So what you do in a lot of these papers is you only feed raw videos into neural networks with no labels whatsoever, and you can still get neural networks to learn depth.", "tokens": [50364, 440, 1036, 7513, 286, 486, 751, 466, 588, 10515, 307, 4748, 544, 10247, 293, 2170, 257, 857, 544, 6191, 11, 457, 309, 307, 257, 7513, 300, 575, 3938, 485, 50764, 50764, 821, 311, 257, 1326, 10577, 1936, 670, 264, 1036, 1064, 420, 732, 322, 341, 3109, 13, 467, 311, 1219, 2698, 12, 48172, 6763, 13, 51064, 51064, 407, 437, 291, 360, 294, 257, 688, 295, 613, 10577, 307, 291, 787, 3154, 8936, 2145, 666, 18161, 9590, 365, 572, 16949, 17076, 11, 293, 291, 393, 920, 483, 18161, 9590, 281, 1466, 7161, 13, 51564, 51564], "temperature": 0.0, "avg_logprob": -0.15735236803690592, "compression_ratio": 1.64453125, "no_speech_prob": 0.027126329019665718}, {"id": 3, "seek": 2400, "start": 24.0, "end": 31.0, "text": " And it's a little bit technical, so I can't go into the full details, but the idea is that the neural network predicts depth at every single frame of that video,", "tokens": [50364, 400, 309, 311, 257, 707, 857, 6191, 11, 370, 286, 393, 380, 352, 666, 264, 1577, 4365, 11, 457, 264, 1558, 307, 300, 264, 18161, 3209, 6069, 82, 7161, 412, 633, 2167, 3920, 295, 300, 960, 11, 50714, 50714, 293, 550, 456, 366, 572, 13691, 12911, 300, 264, 18161, 3209, 307, 3442, 281, 1121, 735, 281, 365, 264, 16949, 11, 457, 2602, 264, 10024, 337, 264, 3209, 307, 281, 312, 8398, 670, 565, 13, 51114, 51114, 407, 2035, 7161, 291, 6069, 820, 312, 8398, 670, 264, 16365, 295, 300, 960, 11, 293, 264, 787, 636, 281, 312, 8398, 307, 281, 312, 558, 11, 51464, 51464, 382, 264, 18161, 3209, 6772, 6069, 82, 264, 3006, 28439, 337, 439, 264, 18668, 13, 400, 321, 600, 11408, 1232, 512, 295, 613, 3542, 19501, 11, 370, 341, 611, 1985, 1596, 731, 13, 51814], "temperature": 0.0, "avg_logprob": -0.0530155804140348, "compression_ratio": 1.9515151515151514, "no_speech_prob": 0.00026494319899939}, {"id": 4, "seek": 2400, "start": 31.0, "end": 39.0, "text": " and then there are no explicit targets that the neural network is supposed to regress to with the labels, but instead the objective for the network is to be consistent over time.", "tokens": [50364, 400, 309, 311, 257, 707, 857, 6191, 11, 370, 286, 393, 380, 352, 666, 264, 1577, 4365, 11, 457, 264, 1558, 307, 300, 264, 18161, 3209, 6069, 82, 7161, 412, 633, 2167, 3920, 295, 300, 960, 11, 50714, 50714, 293, 550, 456, 366, 572, 13691, 12911, 300, 264, 18161, 3209, 307, 3442, 281, 1121, 735, 281, 365, 264, 16949, 11, 457, 2602, 264, 10024, 337, 264, 3209, 307, 281, 312, 8398, 670, 565, 13, 51114, 51114, 407, 2035, 7161, 291, 6069, 820, 312, 8398, 670, 264, 16365, 295, 300, 960, 11, 293, 264, 787, 636, 281, 312, 8398, 307, 281, 312, 558, 11, 51464, 51464, 382, 264, 18161, 3209, 6772, 6069, 82, 264, 3006, 28439, 337, 439, 264, 18668, 13, 400, 321, 600, 11408, 1232, 512, 295, 613, 3542, 19501, 11, 370, 341, 611, 1985, 1596, 731, 13, 51814], "temperature": 0.0, "avg_logprob": -0.0530155804140348, "compression_ratio": 1.9515151515151514, "no_speech_prob": 0.00026494319899939}, {"id": 5, "seek": 2400, "start": 39.0, "end": 46.0, "text": " So whatever depth you predict should be consistent over the duration of that video, and the only way to be consistent is to be right,", "tokens": [50364, 400, 309, 311, 257, 707, 857, 6191, 11, 370, 286, 393, 380, 352, 666, 264, 1577, 4365, 11, 457, 264, 1558, 307, 300, 264, 18161, 3209, 6069, 82, 7161, 412, 633, 2167, 3920, 295, 300, 960, 11, 50714, 50714, 293, 550, 456, 366, 572, 13691, 12911, 300, 264, 18161, 3209, 307, 3442, 281, 1121, 735, 281, 365, 264, 16949, 11, 457, 2602, 264, 10024, 337, 264, 3209, 307, 281, 312, 8398, 670, 565, 13, 51114, 51114, 407, 2035, 7161, 291, 6069, 820, 312, 8398, 670, 264, 16365, 295, 300, 960, 11, 293, 264, 787, 636, 281, 312, 8398, 307, 281, 312, 558, 11, 51464, 51464, 382, 264, 18161, 3209, 6772, 6069, 82, 264, 3006, 28439, 337, 439, 264, 18668, 13, 400, 321, 600, 11408, 1232, 512, 295, 613, 3542, 19501, 11, 370, 341, 611, 1985, 1596, 731, 13, 51814], "temperature": 0.0, "avg_logprob": -0.0530155804140348, "compression_ratio": 1.9515151515151514, "no_speech_prob": 0.00026494319899939}, {"id": 6, "seek": 4600, "start": 46.0, "end": 54.0, "text": " as the neural network automatically predicts the correct depths for all the pixels, and we've reproduced some of these results internally, so this also works quite well.", "tokens": [50364, 382, 264, 18161, 3209, 6772, 6069, 82, 264, 3006, 28439, 337, 439, 264, 18668, 11, 293, 321, 600, 11408, 1232, 512, 295, 613, 3542, 19501, 11, 370, 341, 611, 1985, 1596, 731, 13, 50764], "temperature": 0.0, "avg_logprob": -0.054176777601242065, "compression_ratio": 1.3629032258064515, "no_speech_prob": 7.103411917341873e-05}], "language": "en", "video_id": "x0_404KeDIc", "entity": "Andrew Kaparthy"}}