{"video_id": "54TxZZpK5Ok", "title": "5.12 Additional Neural Network Concepts | Additional Layer Types --[Machine Learning | Andrew Ng]", "description": "Second Course:\nAdvanced Learning Algorithms.\n\n\nIf you liked the content please subscribe and put a little blue thumb.\nTake heart!", "author": "Machine Learning", "keywords": [], "channel_url": "https://www.youtube.com/channel/UClG5HEAJJFOavT_UolqYROQ", "length": 536, "views": 86, "publish_date": "11/04/2022", "timestamp": 1661472000, "entity": "ML Specialization, Andrew Ng (2022)", "transcript": {"text": " All the neural network layers we've used so far have been the dense layer type in which every neuron in a layer gets as its inputs all the activations from the previous layer. And it turns out that just using the dense layer type, you can actually build some pretty powerful learning algorithms. And to help you build further intuition about what neural networks can do, it turns out that there are some other types of layers as well with other properties. In this video, I'd like to briefly touch on this and give you an example of a different type of neural network layer. Let's take a look. To recap, in the dense layer that we've been using, the activation of a neuron in, say, the second hidden layer is a function of every single activation value from the previous layer of A1. But it turns out that for some applications, someone designing a neural network may choose to use a different type of layer. One other layer type that you may see in some work is called a convolutional layer. Let me illustrate this with an example. So what I'm showing on the left is the input X, which is a handwritten digit 9. And what I'm going to do is construct a hidden layer, which will compute different activations as functions of this input image X. But here's something I can do. For the first hidden unit, which I've drawn in blue, rather than saying this neuron can look at all the pixels in this image, I might say this neuron can only look at the pixels in this little rectangular region. The second neuron, which I'm going to illustrate in magenta, is also not going to look at the entire input image X. Instead, it's only going to look at the pixels in a limited region of the image. And so on for the third neuron and the fourth neuron, and so on and so forth, down to the last neuron, which maybe looks only at that region of the image. So why might you want to do this? Why won't you let every neuron look at all the pixels, but instead look at only some of the pixels? Well, some of the benefits are, first, it speeds up computation. And second advantage is that a neural network that uses this type of layer called a convolutional layer can need less training data. Or alternatively, it can also be less prone to overfitting. You'd heard me talk a bit about overfitting in the previous course, but this is something that we'll dive into greater detail on next week as well, when we talk about practical tips for using learning algorithms. And this type of layer, where each neuron only looks at a region of the input image, is called a convolutional layer. It was a researcher, Yang Le Kun, who had figured out a lot of the details of how to get convolutional layers to work and popularize their use. Let me illustrate in more detail a convolutional layer. And if you have multiple convolutional layers in a neural network, sometimes that's called a convolutional neural network. To illustrate the convolutional layer, or convolutional neural network, on this slide, I'm going to use, instead of a 2D image input, I'm going to use a one-dimensional input. And the motivating example I'm going to use is classification of EKG signals, or electrocardiograms. So if you put two electrodes on your chest, you will record voltages that look like this that correspond to your heartbeat. This is actually something that my Stanford research group did research on. We're actually reading EKG signals that actually look like this to try to diagnose if a patient may have a heart issue. So an EKG signal, an electrocardiogram, ECG in some places, EKG in some places, is just a list of numbers corresponding to the height of this surface at different points in time. So you may have, say, 100 numbers corresponding to the height of this curve at 100 different points of time. And the learning task is, given this time series, given this EKG signal, to classify, say whether this patient has a heart disease or some diagnosable heart condition, here's what a convolutional neural network might do. So I'm going to take the EKG signal and rotate it 90 degrees to lay it on the side. And so we have here 100 inputs, X1, X2, all the way through X100, like so. And when I construct the first hidden layer, instead of having the first hidden unit take as input all 100 numbers, let me have the first hidden unit look at only X1 through X20. So that corresponds to looking at just a small window of this EKG signal. The second hidden layer, shown in a different color here, will look at X11 through X30, so it looks at a different window in this EKG signal. And the third hidden layer looks at another window, X21 through X40, and so on. And the final hidden unit in this example will look at X81 through X100, so it looks at a small window toward the end of this EKG time series. So this is a convolutional layer, because each unit in this layer looks at only a limited window of the input. Now this layer of the neural network has nine units. The next layer can also be a convolutional layer. So in the second hidden layer, let me architect my first unit, not to look at all nine activations from the previous layer, but to look at, say, just the first five activations from the previous layer. And then my second unit in this second hidden layer may look at just another five numbers, say A3 to A7. And the third and final hidden unit in this layer will only look at A5 through A9. And then maybe finally, these activations, A2, gets inputs to a sigmoid unit that does look at all three of these values of A2 in order to make a binary classification regarding presence or absence of heart disease. So this is an example of a neural network with the first hidden layer being a convolutional layer, the second hidden layer also being a convolutional layer, and then the output layer being a sigmoid layer. And it turns out that with convolutional layers, you have many architectural choices, such as how big is the window of inputs that a single neuron should look at, and how many neurons should each layer have. And by choosing those architectural parameters effectively, you can build new versions of neural networks that can be even more effective than the dense layer for some applications. To recap, that's it for the convolutional layer and convolutional neural networks. I'm not going to go deeper into convolutional networks in this class, and you don't need to know anything about them to do the homeworks and finish this class successfully. But I hope that you find this additional intuition that neural networks can have other types of layers as well to be useful. And in fact, if you sometimes hear about the latest cutting edge architectures, like a transformer model or an LSTM or an attention model, a lot of this research in neural networks even today pertains to researchers trying to invent new types of layers for neural networks and plugging these different types of layers together as building blocks to form even more complex and hopefully more powerful neural networks. So that's it for the required videos for this week. Thank you and congrats on sticking with me all the way through this. And I look forward to seeing you next week also, where we'll start to talk about practical advice for how you can build machine learning systems. I hope that the tips you learn next week will help you become much more effective at building useful machine learning systems. And I look forward also to seeing you next week.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 8.6, "text": " All the neural network layers we've used so far have been the dense layer type in which", "tokens": [50364, 1057, 264, 18161, 3209, 7914, 321, 600, 1143, 370, 1400, 362, 668, 264, 18011, 4583, 2010, 294, 597, 50794, 50794, 633, 34090, 294, 257, 4583, 2170, 382, 1080, 15743, 439, 264, 2430, 763, 490, 264, 3894, 4583, 13, 51143, 51143, 400, 309, 4523, 484, 300, 445, 1228, 264, 18011, 4583, 2010, 11, 291, 393, 767, 1322, 512, 1238, 51372, 51372, 4005, 2539, 14642, 13, 51494, 51494, 400, 281, 854, 291, 1322, 3052, 24002, 466, 437, 18161, 9590, 393, 360, 11, 309, 4523, 484, 51772, 51772], "temperature": 0.0, "avg_logprob": -0.10743848208723397, "compression_ratio": 1.7568807339449541, "no_speech_prob": 0.022613704204559326}, {"id": 1, "seek": 0, "start": 8.6, "end": 15.58, "text": " every neuron in a layer gets as its inputs all the activations from the previous layer.", "tokens": [50364, 1057, 264, 18161, 3209, 7914, 321, 600, 1143, 370, 1400, 362, 668, 264, 18011, 4583, 2010, 294, 597, 50794, 50794, 633, 34090, 294, 257, 4583, 2170, 382, 1080, 15743, 439, 264, 2430, 763, 490, 264, 3894, 4583, 13, 51143, 51143, 400, 309, 4523, 484, 300, 445, 1228, 264, 18011, 4583, 2010, 11, 291, 393, 767, 1322, 512, 1238, 51372, 51372, 4005, 2539, 14642, 13, 51494, 51494, 400, 281, 854, 291, 1322, 3052, 24002, 466, 437, 18161, 9590, 393, 360, 11, 309, 4523, 484, 51772, 51772], "temperature": 0.0, "avg_logprob": -0.10743848208723397, "compression_ratio": 1.7568807339449541, "no_speech_prob": 0.022613704204559326}, {"id": 2, "seek": 0, "start": 15.58, "end": 20.16, "text": " And it turns out that just using the dense layer type, you can actually build some pretty", "tokens": [50364, 1057, 264, 18161, 3209, 7914, 321, 600, 1143, 370, 1400, 362, 668, 264, 18011, 4583, 2010, 294, 597, 50794, 50794, 633, 34090, 294, 257, 4583, 2170, 382, 1080, 15743, 439, 264, 2430, 763, 490, 264, 3894, 4583, 13, 51143, 51143, 400, 309, 4523, 484, 300, 445, 1228, 264, 18011, 4583, 2010, 11, 291, 393, 767, 1322, 512, 1238, 51372, 51372, 4005, 2539, 14642, 13, 51494, 51494, 400, 281, 854, 291, 1322, 3052, 24002, 466, 437, 18161, 9590, 393, 360, 11, 309, 4523, 484, 51772, 51772], "temperature": 0.0, "avg_logprob": -0.10743848208723397, "compression_ratio": 1.7568807339449541, "no_speech_prob": 0.022613704204559326}, {"id": 3, "seek": 0, "start": 20.16, "end": 22.6, "text": " powerful learning algorithms.", "tokens": [50364, 1057, 264, 18161, 3209, 7914, 321, 600, 1143, 370, 1400, 362, 668, 264, 18011, 4583, 2010, 294, 597, 50794, 50794, 633, 34090, 294, 257, 4583, 2170, 382, 1080, 15743, 439, 264, 2430, 763, 490, 264, 3894, 4583, 13, 51143, 51143, 400, 309, 4523, 484, 300, 445, 1228, 264, 18011, 4583, 2010, 11, 291, 393, 767, 1322, 512, 1238, 51372, 51372, 4005, 2539, 14642, 13, 51494, 51494, 400, 281, 854, 291, 1322, 3052, 24002, 466, 437, 18161, 9590, 393, 360, 11, 309, 4523, 484, 51772, 51772], "temperature": 0.0, "avg_logprob": -0.10743848208723397, "compression_ratio": 1.7568807339449541, "no_speech_prob": 0.022613704204559326}, {"id": 4, "seek": 0, "start": 22.6, "end": 28.16, "text": " And to help you build further intuition about what neural networks can do, it turns out", "tokens": [50364, 1057, 264, 18161, 3209, 7914, 321, 600, 1143, 370, 1400, 362, 668, 264, 18011, 4583, 2010, 294, 597, 50794, 50794, 633, 34090, 294, 257, 4583, 2170, 382, 1080, 15743, 439, 264, 2430, 763, 490, 264, 3894, 4583, 13, 51143, 51143, 400, 309, 4523, 484, 300, 445, 1228, 264, 18011, 4583, 2010, 11, 291, 393, 767, 1322, 512, 1238, 51372, 51372, 4005, 2539, 14642, 13, 51494, 51494, 400, 281, 854, 291, 1322, 3052, 24002, 466, 437, 18161, 9590, 393, 360, 11, 309, 4523, 484, 51772, 51772], "temperature": 0.0, "avg_logprob": -0.10743848208723397, "compression_ratio": 1.7568807339449541, "no_speech_prob": 0.022613704204559326}, {"id": 5, "seek": 2816, "start": 28.16, "end": 32.480000000000004, "text": " that there are some other types of layers as well with other properties.", "tokens": [50364, 300, 456, 366, 512, 661, 3467, 295, 7914, 382, 731, 365, 661, 7221, 13, 50580, 50580, 682, 341, 960, 11, 286, 1116, 411, 281, 10515, 2557, 322, 341, 293, 976, 291, 364, 1365, 295, 257, 819, 50854, 50854, 2010, 295, 18161, 3209, 4583, 13, 50934, 50934, 961, 311, 747, 257, 574, 13, 51014, 51014, 1407, 20928, 11, 294, 264, 18011, 4583, 300, 321, 600, 668, 1228, 11, 264, 24433, 295, 257, 34090, 294, 11, 584, 11, 51428, 51428, 264, 1150, 7633, 4583, 307, 257, 2445, 295, 633, 2167, 24433, 2158, 490, 264, 3894, 51743, 51743], "temperature": 0.0, "avg_logprob": -0.13441673750729904, "compression_ratio": 1.6425531914893616, "no_speech_prob": 1.7501717593404464e-05}, {"id": 6, "seek": 2816, "start": 32.480000000000004, "end": 37.96, "text": " In this video, I'd like to briefly touch on this and give you an example of a different", "tokens": [50364, 300, 456, 366, 512, 661, 3467, 295, 7914, 382, 731, 365, 661, 7221, 13, 50580, 50580, 682, 341, 960, 11, 286, 1116, 411, 281, 10515, 2557, 322, 341, 293, 976, 291, 364, 1365, 295, 257, 819, 50854, 50854, 2010, 295, 18161, 3209, 4583, 13, 50934, 50934, 961, 311, 747, 257, 574, 13, 51014, 51014, 1407, 20928, 11, 294, 264, 18011, 4583, 300, 321, 600, 668, 1228, 11, 264, 24433, 295, 257, 34090, 294, 11, 584, 11, 51428, 51428, 264, 1150, 7633, 4583, 307, 257, 2445, 295, 633, 2167, 24433, 2158, 490, 264, 3894, 51743, 51743], "temperature": 0.0, "avg_logprob": -0.13441673750729904, "compression_ratio": 1.6425531914893616, "no_speech_prob": 1.7501717593404464e-05}, {"id": 7, "seek": 2816, "start": 37.96, "end": 39.56, "text": " type of neural network layer.", "tokens": [50364, 300, 456, 366, 512, 661, 3467, 295, 7914, 382, 731, 365, 661, 7221, 13, 50580, 50580, 682, 341, 960, 11, 286, 1116, 411, 281, 10515, 2557, 322, 341, 293, 976, 291, 364, 1365, 295, 257, 819, 50854, 50854, 2010, 295, 18161, 3209, 4583, 13, 50934, 50934, 961, 311, 747, 257, 574, 13, 51014, 51014, 1407, 20928, 11, 294, 264, 18011, 4583, 300, 321, 600, 668, 1228, 11, 264, 24433, 295, 257, 34090, 294, 11, 584, 11, 51428, 51428, 264, 1150, 7633, 4583, 307, 257, 2445, 295, 633, 2167, 24433, 2158, 490, 264, 3894, 51743, 51743], "temperature": 0.0, "avg_logprob": -0.13441673750729904, "compression_ratio": 1.6425531914893616, "no_speech_prob": 1.7501717593404464e-05}, {"id": 8, "seek": 2816, "start": 39.56, "end": 41.16, "text": " Let's take a look.", "tokens": [50364, 300, 456, 366, 512, 661, 3467, 295, 7914, 382, 731, 365, 661, 7221, 13, 50580, 50580, 682, 341, 960, 11, 286, 1116, 411, 281, 10515, 2557, 322, 341, 293, 976, 291, 364, 1365, 295, 257, 819, 50854, 50854, 2010, 295, 18161, 3209, 4583, 13, 50934, 50934, 961, 311, 747, 257, 574, 13, 51014, 51014, 1407, 20928, 11, 294, 264, 18011, 4583, 300, 321, 600, 668, 1228, 11, 264, 24433, 295, 257, 34090, 294, 11, 584, 11, 51428, 51428, 264, 1150, 7633, 4583, 307, 257, 2445, 295, 633, 2167, 24433, 2158, 490, 264, 3894, 51743, 51743], "temperature": 0.0, "avg_logprob": -0.13441673750729904, "compression_ratio": 1.6425531914893616, "no_speech_prob": 1.7501717593404464e-05}, {"id": 9, "seek": 2816, "start": 41.16, "end": 49.44, "text": " To recap, in the dense layer that we've been using, the activation of a neuron in, say,", "tokens": [50364, 300, 456, 366, 512, 661, 3467, 295, 7914, 382, 731, 365, 661, 7221, 13, 50580, 50580, 682, 341, 960, 11, 286, 1116, 411, 281, 10515, 2557, 322, 341, 293, 976, 291, 364, 1365, 295, 257, 819, 50854, 50854, 2010, 295, 18161, 3209, 4583, 13, 50934, 50934, 961, 311, 747, 257, 574, 13, 51014, 51014, 1407, 20928, 11, 294, 264, 18011, 4583, 300, 321, 600, 668, 1228, 11, 264, 24433, 295, 257, 34090, 294, 11, 584, 11, 51428, 51428, 264, 1150, 7633, 4583, 307, 257, 2445, 295, 633, 2167, 24433, 2158, 490, 264, 3894, 51743, 51743], "temperature": 0.0, "avg_logprob": -0.13441673750729904, "compression_ratio": 1.6425531914893616, "no_speech_prob": 1.7501717593404464e-05}, {"id": 10, "seek": 2816, "start": 49.44, "end": 55.74, "text": " the second hidden layer is a function of every single activation value from the previous", "tokens": [50364, 300, 456, 366, 512, 661, 3467, 295, 7914, 382, 731, 365, 661, 7221, 13, 50580, 50580, 682, 341, 960, 11, 286, 1116, 411, 281, 10515, 2557, 322, 341, 293, 976, 291, 364, 1365, 295, 257, 819, 50854, 50854, 2010, 295, 18161, 3209, 4583, 13, 50934, 50934, 961, 311, 747, 257, 574, 13, 51014, 51014, 1407, 20928, 11, 294, 264, 18011, 4583, 300, 321, 600, 668, 1228, 11, 264, 24433, 295, 257, 34090, 294, 11, 584, 11, 51428, 51428, 264, 1150, 7633, 4583, 307, 257, 2445, 295, 633, 2167, 24433, 2158, 490, 264, 3894, 51743, 51743], "temperature": 0.0, "avg_logprob": -0.13441673750729904, "compression_ratio": 1.6425531914893616, "no_speech_prob": 1.7501717593404464e-05}, {"id": 11, "seek": 5574, "start": 55.74, "end": 63.32, "text": " layer of A1. But it turns out that for some applications, someone designing a neural network", "tokens": [50364, 4583, 295, 316, 16, 13, 583, 309, 4523, 484, 300, 337, 512, 5821, 11, 1580, 14685, 257, 18161, 3209, 50743, 50743, 815, 2826, 281, 764, 257, 819, 2010, 295, 4583, 13, 50943, 50943, 1485, 661, 4583, 2010, 300, 291, 815, 536, 294, 512, 589, 307, 1219, 257, 45216, 304, 4583, 13, 51267, 51267, 961, 385, 23221, 341, 365, 364, 1365, 13, 51390, 51390, 407, 437, 286, 478, 4099, 322, 264, 1411, 307, 264, 4846, 1783, 11, 597, 307, 257, 1011, 26859, 14293, 1722, 13, 51709, 51709], "temperature": 0.0, "avg_logprob": -0.12073056264357133, "compression_ratio": 1.508849557522124, "no_speech_prob": 2.4060552732407814e-06}, {"id": 12, "seek": 5574, "start": 63.32, "end": 67.32000000000001, "text": " may choose to use a different type of layer.", "tokens": [50364, 4583, 295, 316, 16, 13, 583, 309, 4523, 484, 300, 337, 512, 5821, 11, 1580, 14685, 257, 18161, 3209, 50743, 50743, 815, 2826, 281, 764, 257, 819, 2010, 295, 4583, 13, 50943, 50943, 1485, 661, 4583, 2010, 300, 291, 815, 536, 294, 512, 589, 307, 1219, 257, 45216, 304, 4583, 13, 51267, 51267, 961, 385, 23221, 341, 365, 364, 1365, 13, 51390, 51390, 407, 437, 286, 478, 4099, 322, 264, 1411, 307, 264, 4846, 1783, 11, 597, 307, 257, 1011, 26859, 14293, 1722, 13, 51709, 51709], "temperature": 0.0, "avg_logprob": -0.12073056264357133, "compression_ratio": 1.508849557522124, "no_speech_prob": 2.4060552732407814e-06}, {"id": 13, "seek": 5574, "start": 67.32000000000001, "end": 73.8, "text": " One other layer type that you may see in some work is called a convolutional layer.", "tokens": [50364, 4583, 295, 316, 16, 13, 583, 309, 4523, 484, 300, 337, 512, 5821, 11, 1580, 14685, 257, 18161, 3209, 50743, 50743, 815, 2826, 281, 764, 257, 819, 2010, 295, 4583, 13, 50943, 50943, 1485, 661, 4583, 2010, 300, 291, 815, 536, 294, 512, 589, 307, 1219, 257, 45216, 304, 4583, 13, 51267, 51267, 961, 385, 23221, 341, 365, 364, 1365, 13, 51390, 51390, 407, 437, 286, 478, 4099, 322, 264, 1411, 307, 264, 4846, 1783, 11, 597, 307, 257, 1011, 26859, 14293, 1722, 13, 51709, 51709], "temperature": 0.0, "avg_logprob": -0.12073056264357133, "compression_ratio": 1.508849557522124, "no_speech_prob": 2.4060552732407814e-06}, {"id": 14, "seek": 5574, "start": 73.8, "end": 76.26, "text": " Let me illustrate this with an example.", "tokens": [50364, 4583, 295, 316, 16, 13, 583, 309, 4523, 484, 300, 337, 512, 5821, 11, 1580, 14685, 257, 18161, 3209, 50743, 50743, 815, 2826, 281, 764, 257, 819, 2010, 295, 4583, 13, 50943, 50943, 1485, 661, 4583, 2010, 300, 291, 815, 536, 294, 512, 589, 307, 1219, 257, 45216, 304, 4583, 13, 51267, 51267, 961, 385, 23221, 341, 365, 364, 1365, 13, 51390, 51390, 407, 437, 286, 478, 4099, 322, 264, 1411, 307, 264, 4846, 1783, 11, 597, 307, 257, 1011, 26859, 14293, 1722, 13, 51709, 51709], "temperature": 0.0, "avg_logprob": -0.12073056264357133, "compression_ratio": 1.508849557522124, "no_speech_prob": 2.4060552732407814e-06}, {"id": 15, "seek": 5574, "start": 76.26, "end": 82.64, "text": " So what I'm showing on the left is the input X, which is a handwritten digit 9.", "tokens": [50364, 4583, 295, 316, 16, 13, 583, 309, 4523, 484, 300, 337, 512, 5821, 11, 1580, 14685, 257, 18161, 3209, 50743, 50743, 815, 2826, 281, 764, 257, 819, 2010, 295, 4583, 13, 50943, 50943, 1485, 661, 4583, 2010, 300, 291, 815, 536, 294, 512, 589, 307, 1219, 257, 45216, 304, 4583, 13, 51267, 51267, 961, 385, 23221, 341, 365, 364, 1365, 13, 51390, 51390, 407, 437, 286, 478, 4099, 322, 264, 1411, 307, 264, 4846, 1783, 11, 597, 307, 257, 1011, 26859, 14293, 1722, 13, 51709, 51709], "temperature": 0.0, "avg_logprob": -0.12073056264357133, "compression_ratio": 1.508849557522124, "no_speech_prob": 2.4060552732407814e-06}, {"id": 16, "seek": 8264, "start": 82.64, "end": 88.28, "text": " And what I'm going to do is construct a hidden layer, which will compute different activations", "tokens": [50364, 400, 437, 286, 478, 516, 281, 360, 307, 7690, 257, 7633, 4583, 11, 597, 486, 14722, 819, 2430, 763, 50646, 50646, 382, 6828, 295, 341, 4846, 3256, 1783, 13, 50808, 50808, 583, 510, 311, 746, 286, 393, 360, 13, 50914, 50914, 1171, 264, 700, 7633, 4985, 11, 597, 286, 600, 10117, 294, 3344, 11, 2831, 813, 1566, 341, 34090, 393, 51207, 51207, 574, 412, 439, 264, 18668, 294, 341, 3256, 11, 286, 1062, 584, 341, 34090, 393, 787, 574, 412, 264, 18668, 51525, 51525, 294, 341, 707, 31167, 4458, 13, 51676, 51676], "temperature": 0.0, "avg_logprob": -0.07442893880478879, "compression_ratio": 1.654867256637168, "no_speech_prob": 9.665853212936781e-06}, {"id": 17, "seek": 8264, "start": 88.28, "end": 91.52, "text": " as functions of this input image X.", "tokens": [50364, 400, 437, 286, 478, 516, 281, 360, 307, 7690, 257, 7633, 4583, 11, 597, 486, 14722, 819, 2430, 763, 50646, 50646, 382, 6828, 295, 341, 4846, 3256, 1783, 13, 50808, 50808, 583, 510, 311, 746, 286, 393, 360, 13, 50914, 50914, 1171, 264, 700, 7633, 4985, 11, 597, 286, 600, 10117, 294, 3344, 11, 2831, 813, 1566, 341, 34090, 393, 51207, 51207, 574, 412, 439, 264, 18668, 294, 341, 3256, 11, 286, 1062, 584, 341, 34090, 393, 787, 574, 412, 264, 18668, 51525, 51525, 294, 341, 707, 31167, 4458, 13, 51676, 51676], "temperature": 0.0, "avg_logprob": -0.07442893880478879, "compression_ratio": 1.654867256637168, "no_speech_prob": 9.665853212936781e-06}, {"id": 18, "seek": 8264, "start": 91.52, "end": 93.64, "text": " But here's something I can do.", "tokens": [50364, 400, 437, 286, 478, 516, 281, 360, 307, 7690, 257, 7633, 4583, 11, 597, 486, 14722, 819, 2430, 763, 50646, 50646, 382, 6828, 295, 341, 4846, 3256, 1783, 13, 50808, 50808, 583, 510, 311, 746, 286, 393, 360, 13, 50914, 50914, 1171, 264, 700, 7633, 4985, 11, 597, 286, 600, 10117, 294, 3344, 11, 2831, 813, 1566, 341, 34090, 393, 51207, 51207, 574, 412, 439, 264, 18668, 294, 341, 3256, 11, 286, 1062, 584, 341, 34090, 393, 787, 574, 412, 264, 18668, 51525, 51525, 294, 341, 707, 31167, 4458, 13, 51676, 51676], "temperature": 0.0, "avg_logprob": -0.07442893880478879, "compression_ratio": 1.654867256637168, "no_speech_prob": 9.665853212936781e-06}, {"id": 19, "seek": 8264, "start": 93.64, "end": 99.5, "text": " For the first hidden unit, which I've drawn in blue, rather than saying this neuron can", "tokens": [50364, 400, 437, 286, 478, 516, 281, 360, 307, 7690, 257, 7633, 4583, 11, 597, 486, 14722, 819, 2430, 763, 50646, 50646, 382, 6828, 295, 341, 4846, 3256, 1783, 13, 50808, 50808, 583, 510, 311, 746, 286, 393, 360, 13, 50914, 50914, 1171, 264, 700, 7633, 4985, 11, 597, 286, 600, 10117, 294, 3344, 11, 2831, 813, 1566, 341, 34090, 393, 51207, 51207, 574, 412, 439, 264, 18668, 294, 341, 3256, 11, 286, 1062, 584, 341, 34090, 393, 787, 574, 412, 264, 18668, 51525, 51525, 294, 341, 707, 31167, 4458, 13, 51676, 51676], "temperature": 0.0, "avg_logprob": -0.07442893880478879, "compression_ratio": 1.654867256637168, "no_speech_prob": 9.665853212936781e-06}, {"id": 20, "seek": 8264, "start": 99.5, "end": 105.86, "text": " look at all the pixels in this image, I might say this neuron can only look at the pixels", "tokens": [50364, 400, 437, 286, 478, 516, 281, 360, 307, 7690, 257, 7633, 4583, 11, 597, 486, 14722, 819, 2430, 763, 50646, 50646, 382, 6828, 295, 341, 4846, 3256, 1783, 13, 50808, 50808, 583, 510, 311, 746, 286, 393, 360, 13, 50914, 50914, 1171, 264, 700, 7633, 4985, 11, 597, 286, 600, 10117, 294, 3344, 11, 2831, 813, 1566, 341, 34090, 393, 51207, 51207, 574, 412, 439, 264, 18668, 294, 341, 3256, 11, 286, 1062, 584, 341, 34090, 393, 787, 574, 412, 264, 18668, 51525, 51525, 294, 341, 707, 31167, 4458, 13, 51676, 51676], "temperature": 0.0, "avg_logprob": -0.07442893880478879, "compression_ratio": 1.654867256637168, "no_speech_prob": 9.665853212936781e-06}, {"id": 21, "seek": 8264, "start": 105.86, "end": 108.88, "text": " in this little rectangular region.", "tokens": [50364, 400, 437, 286, 478, 516, 281, 360, 307, 7690, 257, 7633, 4583, 11, 597, 486, 14722, 819, 2430, 763, 50646, 50646, 382, 6828, 295, 341, 4846, 3256, 1783, 13, 50808, 50808, 583, 510, 311, 746, 286, 393, 360, 13, 50914, 50914, 1171, 264, 700, 7633, 4985, 11, 597, 286, 600, 10117, 294, 3344, 11, 2831, 813, 1566, 341, 34090, 393, 51207, 51207, 574, 412, 439, 264, 18668, 294, 341, 3256, 11, 286, 1062, 584, 341, 34090, 393, 787, 574, 412, 264, 18668, 51525, 51525, 294, 341, 707, 31167, 4458, 13, 51676, 51676], "temperature": 0.0, "avg_logprob": -0.07442893880478879, "compression_ratio": 1.654867256637168, "no_speech_prob": 9.665853212936781e-06}, {"id": 22, "seek": 10888, "start": 108.88, "end": 113.19999999999999, "text": " The second neuron, which I'm going to illustrate in magenta, is also not going to look at the", "tokens": [50364, 440, 1150, 34090, 11, 597, 286, 478, 516, 281, 23221, 294, 2258, 8938, 11, 307, 611, 406, 516, 281, 574, 412, 264, 50580, 50580, 2302, 4846, 3256, 1783, 13, 7156, 11, 309, 311, 787, 516, 281, 574, 412, 264, 18668, 294, 257, 5567, 4458, 50890, 50890, 295, 264, 3256, 13, 50972, 50972, 400, 370, 322, 337, 264, 2636, 34090, 293, 264, 6409, 34090, 11, 293, 370, 322, 293, 370, 5220, 11, 760, 281, 264, 51332, 51332, 1036, 34090, 11, 597, 1310, 1542, 787, 412, 300, 4458, 295, 264, 3256, 13, 51674, 51674, 407, 983, 1062, 291, 528, 281, 360, 341, 30, 51762, 51762], "temperature": 0.0, "avg_logprob": -0.11096512930733816, "compression_ratio": 1.807511737089202, "no_speech_prob": 3.966920303355437e-06}, {"id": 23, "seek": 10888, "start": 113.19999999999999, "end": 119.39999999999999, "text": " entire input image X. Instead, it's only going to look at the pixels in a limited region", "tokens": [50364, 440, 1150, 34090, 11, 597, 286, 478, 516, 281, 23221, 294, 2258, 8938, 11, 307, 611, 406, 516, 281, 574, 412, 264, 50580, 50580, 2302, 4846, 3256, 1783, 13, 7156, 11, 309, 311, 787, 516, 281, 574, 412, 264, 18668, 294, 257, 5567, 4458, 50890, 50890, 295, 264, 3256, 13, 50972, 50972, 400, 370, 322, 337, 264, 2636, 34090, 293, 264, 6409, 34090, 11, 293, 370, 322, 293, 370, 5220, 11, 760, 281, 264, 51332, 51332, 1036, 34090, 11, 597, 1310, 1542, 787, 412, 300, 4458, 295, 264, 3256, 13, 51674, 51674, 407, 983, 1062, 291, 528, 281, 360, 341, 30, 51762, 51762], "temperature": 0.0, "avg_logprob": -0.11096512930733816, "compression_ratio": 1.807511737089202, "no_speech_prob": 3.966920303355437e-06}, {"id": 24, "seek": 10888, "start": 119.39999999999999, "end": 121.03999999999999, "text": " of the image.", "tokens": [50364, 440, 1150, 34090, 11, 597, 286, 478, 516, 281, 23221, 294, 2258, 8938, 11, 307, 611, 406, 516, 281, 574, 412, 264, 50580, 50580, 2302, 4846, 3256, 1783, 13, 7156, 11, 309, 311, 787, 516, 281, 574, 412, 264, 18668, 294, 257, 5567, 4458, 50890, 50890, 295, 264, 3256, 13, 50972, 50972, 400, 370, 322, 337, 264, 2636, 34090, 293, 264, 6409, 34090, 11, 293, 370, 322, 293, 370, 5220, 11, 760, 281, 264, 51332, 51332, 1036, 34090, 11, 597, 1310, 1542, 787, 412, 300, 4458, 295, 264, 3256, 13, 51674, 51674, 407, 983, 1062, 291, 528, 281, 360, 341, 30, 51762, 51762], "temperature": 0.0, "avg_logprob": -0.11096512930733816, "compression_ratio": 1.807511737089202, "no_speech_prob": 3.966920303355437e-06}, {"id": 25, "seek": 10888, "start": 121.03999999999999, "end": 128.24, "text": " And so on for the third neuron and the fourth neuron, and so on and so forth, down to the", "tokens": [50364, 440, 1150, 34090, 11, 597, 286, 478, 516, 281, 23221, 294, 2258, 8938, 11, 307, 611, 406, 516, 281, 574, 412, 264, 50580, 50580, 2302, 4846, 3256, 1783, 13, 7156, 11, 309, 311, 787, 516, 281, 574, 412, 264, 18668, 294, 257, 5567, 4458, 50890, 50890, 295, 264, 3256, 13, 50972, 50972, 400, 370, 322, 337, 264, 2636, 34090, 293, 264, 6409, 34090, 11, 293, 370, 322, 293, 370, 5220, 11, 760, 281, 264, 51332, 51332, 1036, 34090, 11, 597, 1310, 1542, 787, 412, 300, 4458, 295, 264, 3256, 13, 51674, 51674, 407, 983, 1062, 291, 528, 281, 360, 341, 30, 51762, 51762], "temperature": 0.0, "avg_logprob": -0.11096512930733816, "compression_ratio": 1.807511737089202, "no_speech_prob": 3.966920303355437e-06}, {"id": 26, "seek": 10888, "start": 128.24, "end": 135.07999999999998, "text": " last neuron, which maybe looks only at that region of the image.", "tokens": [50364, 440, 1150, 34090, 11, 597, 286, 478, 516, 281, 23221, 294, 2258, 8938, 11, 307, 611, 406, 516, 281, 574, 412, 264, 50580, 50580, 2302, 4846, 3256, 1783, 13, 7156, 11, 309, 311, 787, 516, 281, 574, 412, 264, 18668, 294, 257, 5567, 4458, 50890, 50890, 295, 264, 3256, 13, 50972, 50972, 400, 370, 322, 337, 264, 2636, 34090, 293, 264, 6409, 34090, 11, 293, 370, 322, 293, 370, 5220, 11, 760, 281, 264, 51332, 51332, 1036, 34090, 11, 597, 1310, 1542, 787, 412, 300, 4458, 295, 264, 3256, 13, 51674, 51674, 407, 983, 1062, 291, 528, 281, 360, 341, 30, 51762, 51762], "temperature": 0.0, "avg_logprob": -0.11096512930733816, "compression_ratio": 1.807511737089202, "no_speech_prob": 3.966920303355437e-06}, {"id": 27, "seek": 10888, "start": 135.07999999999998, "end": 136.84, "text": " So why might you want to do this?", "tokens": [50364, 440, 1150, 34090, 11, 597, 286, 478, 516, 281, 23221, 294, 2258, 8938, 11, 307, 611, 406, 516, 281, 574, 412, 264, 50580, 50580, 2302, 4846, 3256, 1783, 13, 7156, 11, 309, 311, 787, 516, 281, 574, 412, 264, 18668, 294, 257, 5567, 4458, 50890, 50890, 295, 264, 3256, 13, 50972, 50972, 400, 370, 322, 337, 264, 2636, 34090, 293, 264, 6409, 34090, 11, 293, 370, 322, 293, 370, 5220, 11, 760, 281, 264, 51332, 51332, 1036, 34090, 11, 597, 1310, 1542, 787, 412, 300, 4458, 295, 264, 3256, 13, 51674, 51674, 407, 983, 1062, 291, 528, 281, 360, 341, 30, 51762, 51762], "temperature": 0.0, "avg_logprob": -0.11096512930733816, "compression_ratio": 1.807511737089202, "no_speech_prob": 3.966920303355437e-06}, {"id": 28, "seek": 13684, "start": 136.84, "end": 141.6, "text": " Why won't you let every neuron look at all the pixels, but instead look at only some", "tokens": [50364, 1545, 1582, 380, 291, 718, 633, 34090, 574, 412, 439, 264, 18668, 11, 457, 2602, 574, 412, 787, 512, 50602, 50602, 295, 264, 18668, 30, 50652, 50652, 1042, 11, 512, 295, 264, 5311, 366, 11, 700, 11, 309, 16411, 493, 24903, 13, 50984, 50984, 400, 1150, 5002, 307, 300, 257, 18161, 3209, 300, 4960, 341, 2010, 295, 4583, 1219, 257, 45216, 304, 51236, 51236, 4583, 393, 643, 1570, 3097, 1412, 13, 51408, 51408, 1610, 8535, 356, 11, 309, 393, 611, 312, 1570, 25806, 281, 670, 69, 2414, 13, 51632, 51632, 509, 1116, 2198, 385, 751, 257, 857, 466, 670, 69, 2414, 294, 264, 3894, 1164, 11, 457, 341, 307, 746, 51854, 51854], "temperature": 0.0, "avg_logprob": -0.15456182914867736, "compression_ratio": 1.6679104477611941, "no_speech_prob": 1.1015731615771074e-06}, {"id": 29, "seek": 13684, "start": 141.6, "end": 142.6, "text": " of the pixels?", "tokens": [50364, 1545, 1582, 380, 291, 718, 633, 34090, 574, 412, 439, 264, 18668, 11, 457, 2602, 574, 412, 787, 512, 50602, 50602, 295, 264, 18668, 30, 50652, 50652, 1042, 11, 512, 295, 264, 5311, 366, 11, 700, 11, 309, 16411, 493, 24903, 13, 50984, 50984, 400, 1150, 5002, 307, 300, 257, 18161, 3209, 300, 4960, 341, 2010, 295, 4583, 1219, 257, 45216, 304, 51236, 51236, 4583, 393, 643, 1570, 3097, 1412, 13, 51408, 51408, 1610, 8535, 356, 11, 309, 393, 611, 312, 1570, 25806, 281, 670, 69, 2414, 13, 51632, 51632, 509, 1116, 2198, 385, 751, 257, 857, 466, 670, 69, 2414, 294, 264, 3894, 1164, 11, 457, 341, 307, 746, 51854, 51854], "temperature": 0.0, "avg_logprob": -0.15456182914867736, "compression_ratio": 1.6679104477611941, "no_speech_prob": 1.1015731615771074e-06}, {"id": 30, "seek": 13684, "start": 142.6, "end": 149.24, "text": " Well, some of the benefits are, first, it speeds up computation.", "tokens": [50364, 1545, 1582, 380, 291, 718, 633, 34090, 574, 412, 439, 264, 18668, 11, 457, 2602, 574, 412, 787, 512, 50602, 50602, 295, 264, 18668, 30, 50652, 50652, 1042, 11, 512, 295, 264, 5311, 366, 11, 700, 11, 309, 16411, 493, 24903, 13, 50984, 50984, 400, 1150, 5002, 307, 300, 257, 18161, 3209, 300, 4960, 341, 2010, 295, 4583, 1219, 257, 45216, 304, 51236, 51236, 4583, 393, 643, 1570, 3097, 1412, 13, 51408, 51408, 1610, 8535, 356, 11, 309, 393, 611, 312, 1570, 25806, 281, 670, 69, 2414, 13, 51632, 51632, 509, 1116, 2198, 385, 751, 257, 857, 466, 670, 69, 2414, 294, 264, 3894, 1164, 11, 457, 341, 307, 746, 51854, 51854], "temperature": 0.0, "avg_logprob": -0.15456182914867736, "compression_ratio": 1.6679104477611941, "no_speech_prob": 1.1015731615771074e-06}, {"id": 31, "seek": 13684, "start": 149.24, "end": 154.28, "text": " And second advantage is that a neural network that uses this type of layer called a convolutional", "tokens": [50364, 1545, 1582, 380, 291, 718, 633, 34090, 574, 412, 439, 264, 18668, 11, 457, 2602, 574, 412, 787, 512, 50602, 50602, 295, 264, 18668, 30, 50652, 50652, 1042, 11, 512, 295, 264, 5311, 366, 11, 700, 11, 309, 16411, 493, 24903, 13, 50984, 50984, 400, 1150, 5002, 307, 300, 257, 18161, 3209, 300, 4960, 341, 2010, 295, 4583, 1219, 257, 45216, 304, 51236, 51236, 4583, 393, 643, 1570, 3097, 1412, 13, 51408, 51408, 1610, 8535, 356, 11, 309, 393, 611, 312, 1570, 25806, 281, 670, 69, 2414, 13, 51632, 51632, 509, 1116, 2198, 385, 751, 257, 857, 466, 670, 69, 2414, 294, 264, 3894, 1164, 11, 457, 341, 307, 746, 51854, 51854], "temperature": 0.0, "avg_logprob": -0.15456182914867736, "compression_ratio": 1.6679104477611941, "no_speech_prob": 1.1015731615771074e-06}, {"id": 32, "seek": 13684, "start": 154.28, "end": 157.72, "text": " layer can need less training data.", "tokens": [50364, 1545, 1582, 380, 291, 718, 633, 34090, 574, 412, 439, 264, 18668, 11, 457, 2602, 574, 412, 787, 512, 50602, 50602, 295, 264, 18668, 30, 50652, 50652, 1042, 11, 512, 295, 264, 5311, 366, 11, 700, 11, 309, 16411, 493, 24903, 13, 50984, 50984, 400, 1150, 5002, 307, 300, 257, 18161, 3209, 300, 4960, 341, 2010, 295, 4583, 1219, 257, 45216, 304, 51236, 51236, 4583, 393, 643, 1570, 3097, 1412, 13, 51408, 51408, 1610, 8535, 356, 11, 309, 393, 611, 312, 1570, 25806, 281, 670, 69, 2414, 13, 51632, 51632, 509, 1116, 2198, 385, 751, 257, 857, 466, 670, 69, 2414, 294, 264, 3894, 1164, 11, 457, 341, 307, 746, 51854, 51854], "temperature": 0.0, "avg_logprob": -0.15456182914867736, "compression_ratio": 1.6679104477611941, "no_speech_prob": 1.1015731615771074e-06}, {"id": 33, "seek": 13684, "start": 157.72, "end": 162.2, "text": " Or alternatively, it can also be less prone to overfitting.", "tokens": [50364, 1545, 1582, 380, 291, 718, 633, 34090, 574, 412, 439, 264, 18668, 11, 457, 2602, 574, 412, 787, 512, 50602, 50602, 295, 264, 18668, 30, 50652, 50652, 1042, 11, 512, 295, 264, 5311, 366, 11, 700, 11, 309, 16411, 493, 24903, 13, 50984, 50984, 400, 1150, 5002, 307, 300, 257, 18161, 3209, 300, 4960, 341, 2010, 295, 4583, 1219, 257, 45216, 304, 51236, 51236, 4583, 393, 643, 1570, 3097, 1412, 13, 51408, 51408, 1610, 8535, 356, 11, 309, 393, 611, 312, 1570, 25806, 281, 670, 69, 2414, 13, 51632, 51632, 509, 1116, 2198, 385, 751, 257, 857, 466, 670, 69, 2414, 294, 264, 3894, 1164, 11, 457, 341, 307, 746, 51854, 51854], "temperature": 0.0, "avg_logprob": -0.15456182914867736, "compression_ratio": 1.6679104477611941, "no_speech_prob": 1.1015731615771074e-06}, {"id": 34, "seek": 13684, "start": 162.2, "end": 166.64000000000001, "text": " You'd heard me talk a bit about overfitting in the previous course, but this is something", "tokens": [50364, 1545, 1582, 380, 291, 718, 633, 34090, 574, 412, 439, 264, 18668, 11, 457, 2602, 574, 412, 787, 512, 50602, 50602, 295, 264, 18668, 30, 50652, 50652, 1042, 11, 512, 295, 264, 5311, 366, 11, 700, 11, 309, 16411, 493, 24903, 13, 50984, 50984, 400, 1150, 5002, 307, 300, 257, 18161, 3209, 300, 4960, 341, 2010, 295, 4583, 1219, 257, 45216, 304, 51236, 51236, 4583, 393, 643, 1570, 3097, 1412, 13, 51408, 51408, 1610, 8535, 356, 11, 309, 393, 611, 312, 1570, 25806, 281, 670, 69, 2414, 13, 51632, 51632, 509, 1116, 2198, 385, 751, 257, 857, 466, 670, 69, 2414, 294, 264, 3894, 1164, 11, 457, 341, 307, 746, 51854, 51854], "temperature": 0.0, "avg_logprob": -0.15456182914867736, "compression_ratio": 1.6679104477611941, "no_speech_prob": 1.1015731615771074e-06}, {"id": 35, "seek": 16664, "start": 166.64, "end": 171.48, "text": " that we'll dive into greater detail on next week as well, when we talk about practical", "tokens": [50364, 300, 321, 603, 9192, 666, 5044, 2607, 322, 958, 1243, 382, 731, 11, 562, 321, 751, 466, 8496, 50606, 50606, 6082, 337, 1228, 2539, 14642, 13, 50810, 50810, 400, 341, 2010, 295, 4583, 11, 689, 1184, 34090, 787, 1542, 412, 257, 4458, 295, 264, 4846, 3256, 11, 51194, 51194, 307, 1219, 257, 45216, 304, 4583, 13, 51348, 51348, 467, 390, 257, 21751, 11, 11978, 1456, 19089, 11, 567, 632, 8932, 484, 257, 688, 295, 264, 4365, 295, 577, 281, 51568, 51568, 483, 45216, 304, 7914, 281, 589, 293, 3743, 1125, 641, 764, 13, 51794, 51794], "temperature": 0.0, "avg_logprob": -0.12152570547516812, "compression_ratio": 1.5933609958506223, "no_speech_prob": 4.710770554083865e-06}, {"id": 36, "seek": 16664, "start": 171.48, "end": 175.55999999999997, "text": " tips for using learning algorithms.", "tokens": [50364, 300, 321, 603, 9192, 666, 5044, 2607, 322, 958, 1243, 382, 731, 11, 562, 321, 751, 466, 8496, 50606, 50606, 6082, 337, 1228, 2539, 14642, 13, 50810, 50810, 400, 341, 2010, 295, 4583, 11, 689, 1184, 34090, 787, 1542, 412, 257, 4458, 295, 264, 4846, 3256, 11, 51194, 51194, 307, 1219, 257, 45216, 304, 4583, 13, 51348, 51348, 467, 390, 257, 21751, 11, 11978, 1456, 19089, 11, 567, 632, 8932, 484, 257, 688, 295, 264, 4365, 295, 577, 281, 51568, 51568, 483, 45216, 304, 7914, 281, 589, 293, 3743, 1125, 641, 764, 13, 51794, 51794], "temperature": 0.0, "avg_logprob": -0.12152570547516812, "compression_ratio": 1.5933609958506223, "no_speech_prob": 4.710770554083865e-06}, {"id": 37, "seek": 16664, "start": 175.55999999999997, "end": 183.23999999999998, "text": " And this type of layer, where each neuron only looks at a region of the input image,", "tokens": [50364, 300, 321, 603, 9192, 666, 5044, 2607, 322, 958, 1243, 382, 731, 11, 562, 321, 751, 466, 8496, 50606, 50606, 6082, 337, 1228, 2539, 14642, 13, 50810, 50810, 400, 341, 2010, 295, 4583, 11, 689, 1184, 34090, 787, 1542, 412, 257, 4458, 295, 264, 4846, 3256, 11, 51194, 51194, 307, 1219, 257, 45216, 304, 4583, 13, 51348, 51348, 467, 390, 257, 21751, 11, 11978, 1456, 19089, 11, 567, 632, 8932, 484, 257, 688, 295, 264, 4365, 295, 577, 281, 51568, 51568, 483, 45216, 304, 7914, 281, 589, 293, 3743, 1125, 641, 764, 13, 51794, 51794], "temperature": 0.0, "avg_logprob": -0.12152570547516812, "compression_ratio": 1.5933609958506223, "no_speech_prob": 4.710770554083865e-06}, {"id": 38, "seek": 16664, "start": 183.23999999999998, "end": 186.32, "text": " is called a convolutional layer.", "tokens": [50364, 300, 321, 603, 9192, 666, 5044, 2607, 322, 958, 1243, 382, 731, 11, 562, 321, 751, 466, 8496, 50606, 50606, 6082, 337, 1228, 2539, 14642, 13, 50810, 50810, 400, 341, 2010, 295, 4583, 11, 689, 1184, 34090, 787, 1542, 412, 257, 4458, 295, 264, 4846, 3256, 11, 51194, 51194, 307, 1219, 257, 45216, 304, 4583, 13, 51348, 51348, 467, 390, 257, 21751, 11, 11978, 1456, 19089, 11, 567, 632, 8932, 484, 257, 688, 295, 264, 4365, 295, 577, 281, 51568, 51568, 483, 45216, 304, 7914, 281, 589, 293, 3743, 1125, 641, 764, 13, 51794, 51794], "temperature": 0.0, "avg_logprob": -0.12152570547516812, "compression_ratio": 1.5933609958506223, "no_speech_prob": 4.710770554083865e-06}, {"id": 39, "seek": 16664, "start": 186.32, "end": 190.72, "text": " It was a researcher, Yang Le Kun, who had figured out a lot of the details of how to", "tokens": [50364, 300, 321, 603, 9192, 666, 5044, 2607, 322, 958, 1243, 382, 731, 11, 562, 321, 751, 466, 8496, 50606, 50606, 6082, 337, 1228, 2539, 14642, 13, 50810, 50810, 400, 341, 2010, 295, 4583, 11, 689, 1184, 34090, 787, 1542, 412, 257, 4458, 295, 264, 4846, 3256, 11, 51194, 51194, 307, 1219, 257, 45216, 304, 4583, 13, 51348, 51348, 467, 390, 257, 21751, 11, 11978, 1456, 19089, 11, 567, 632, 8932, 484, 257, 688, 295, 264, 4365, 295, 577, 281, 51568, 51568, 483, 45216, 304, 7914, 281, 589, 293, 3743, 1125, 641, 764, 13, 51794, 51794], "temperature": 0.0, "avg_logprob": -0.12152570547516812, "compression_ratio": 1.5933609958506223, "no_speech_prob": 4.710770554083865e-06}, {"id": 40, "seek": 16664, "start": 190.72, "end": 195.23999999999998, "text": " get convolutional layers to work and popularize their use.", "tokens": [50364, 300, 321, 603, 9192, 666, 5044, 2607, 322, 958, 1243, 382, 731, 11, 562, 321, 751, 466, 8496, 50606, 50606, 6082, 337, 1228, 2539, 14642, 13, 50810, 50810, 400, 341, 2010, 295, 4583, 11, 689, 1184, 34090, 787, 1542, 412, 257, 4458, 295, 264, 4846, 3256, 11, 51194, 51194, 307, 1219, 257, 45216, 304, 4583, 13, 51348, 51348, 467, 390, 257, 21751, 11, 11978, 1456, 19089, 11, 567, 632, 8932, 484, 257, 688, 295, 264, 4365, 295, 577, 281, 51568, 51568, 483, 45216, 304, 7914, 281, 589, 293, 3743, 1125, 641, 764, 13, 51794, 51794], "temperature": 0.0, "avg_logprob": -0.12152570547516812, "compression_ratio": 1.5933609958506223, "no_speech_prob": 4.710770554083865e-06}, {"id": 41, "seek": 19524, "start": 195.24, "end": 201.32000000000002, "text": " Let me illustrate in more detail a convolutional layer.", "tokens": [50364, 961, 385, 23221, 294, 544, 2607, 257, 45216, 304, 4583, 13, 50668, 50668, 400, 498, 291, 362, 3866, 45216, 304, 7914, 294, 257, 18161, 3209, 11, 2171, 300, 311, 1219, 50907, 50907, 257, 45216, 304, 18161, 3209, 13, 51064, 51064, 1407, 23221, 264, 45216, 304, 4583, 11, 420, 45216, 304, 18161, 3209, 11, 322, 341, 4137, 11, 51288, 51288, 286, 478, 516, 281, 764, 11, 2602, 295, 257, 568, 35, 3256, 4846, 11, 286, 478, 516, 281, 764, 257, 472, 12, 18759, 4846, 13, 51662, 51662], "temperature": 0.0, "avg_logprob": -0.12067029692909935, "compression_ratio": 1.9135135135135135, "no_speech_prob": 1.706161583570065e-06}, {"id": 42, "seek": 19524, "start": 201.32000000000002, "end": 206.10000000000002, "text": " And if you have multiple convolutional layers in a neural network, sometimes that's called", "tokens": [50364, 961, 385, 23221, 294, 544, 2607, 257, 45216, 304, 4583, 13, 50668, 50668, 400, 498, 291, 362, 3866, 45216, 304, 7914, 294, 257, 18161, 3209, 11, 2171, 300, 311, 1219, 50907, 50907, 257, 45216, 304, 18161, 3209, 13, 51064, 51064, 1407, 23221, 264, 45216, 304, 4583, 11, 420, 45216, 304, 18161, 3209, 11, 322, 341, 4137, 11, 51288, 51288, 286, 478, 516, 281, 764, 11, 2602, 295, 257, 568, 35, 3256, 4846, 11, 286, 478, 516, 281, 764, 257, 472, 12, 18759, 4846, 13, 51662, 51662], "temperature": 0.0, "avg_logprob": -0.12067029692909935, "compression_ratio": 1.9135135135135135, "no_speech_prob": 1.706161583570065e-06}, {"id": 43, "seek": 19524, "start": 206.10000000000002, "end": 209.24, "text": " a convolutional neural network.", "tokens": [50364, 961, 385, 23221, 294, 544, 2607, 257, 45216, 304, 4583, 13, 50668, 50668, 400, 498, 291, 362, 3866, 45216, 304, 7914, 294, 257, 18161, 3209, 11, 2171, 300, 311, 1219, 50907, 50907, 257, 45216, 304, 18161, 3209, 13, 51064, 51064, 1407, 23221, 264, 45216, 304, 4583, 11, 420, 45216, 304, 18161, 3209, 11, 322, 341, 4137, 11, 51288, 51288, 286, 478, 516, 281, 764, 11, 2602, 295, 257, 568, 35, 3256, 4846, 11, 286, 478, 516, 281, 764, 257, 472, 12, 18759, 4846, 13, 51662, 51662], "temperature": 0.0, "avg_logprob": -0.12067029692909935, "compression_ratio": 1.9135135135135135, "no_speech_prob": 1.706161583570065e-06}, {"id": 44, "seek": 19524, "start": 209.24, "end": 213.72, "text": " To illustrate the convolutional layer, or convolutional neural network, on this slide,", "tokens": [50364, 961, 385, 23221, 294, 544, 2607, 257, 45216, 304, 4583, 13, 50668, 50668, 400, 498, 291, 362, 3866, 45216, 304, 7914, 294, 257, 18161, 3209, 11, 2171, 300, 311, 1219, 50907, 50907, 257, 45216, 304, 18161, 3209, 13, 51064, 51064, 1407, 23221, 264, 45216, 304, 4583, 11, 420, 45216, 304, 18161, 3209, 11, 322, 341, 4137, 11, 51288, 51288, 286, 478, 516, 281, 764, 11, 2602, 295, 257, 568, 35, 3256, 4846, 11, 286, 478, 516, 281, 764, 257, 472, 12, 18759, 4846, 13, 51662, 51662], "temperature": 0.0, "avg_logprob": -0.12067029692909935, "compression_ratio": 1.9135135135135135, "no_speech_prob": 1.706161583570065e-06}, {"id": 45, "seek": 19524, "start": 213.72, "end": 221.20000000000002, "text": " I'm going to use, instead of a 2D image input, I'm going to use a one-dimensional input.", "tokens": [50364, 961, 385, 23221, 294, 544, 2607, 257, 45216, 304, 4583, 13, 50668, 50668, 400, 498, 291, 362, 3866, 45216, 304, 7914, 294, 257, 18161, 3209, 11, 2171, 300, 311, 1219, 50907, 50907, 257, 45216, 304, 18161, 3209, 13, 51064, 51064, 1407, 23221, 264, 45216, 304, 4583, 11, 420, 45216, 304, 18161, 3209, 11, 322, 341, 4137, 11, 51288, 51288, 286, 478, 516, 281, 764, 11, 2602, 295, 257, 568, 35, 3256, 4846, 11, 286, 478, 516, 281, 764, 257, 472, 12, 18759, 4846, 13, 51662, 51662], "temperature": 0.0, "avg_logprob": -0.12067029692909935, "compression_ratio": 1.9135135135135135, "no_speech_prob": 1.706161583570065e-06}, {"id": 46, "seek": 22120, "start": 221.2, "end": 229.28, "text": " And the motivating example I'm going to use is classification of EKG signals, or electrocardiograms.", "tokens": [50364, 400, 264, 41066, 1365, 286, 478, 516, 281, 764, 307, 21538, 295, 46078, 38, 12354, 11, 420, 16717, 22259, 72, 12820, 82, 13, 50768, 50768, 407, 498, 291, 829, 732, 47824, 322, 428, 7443, 11, 291, 486, 2136, 49614, 300, 574, 411, 341, 51036, 51036, 300, 6805, 281, 428, 34851, 13, 51180, 51180, 639, 307, 767, 746, 300, 452, 20374, 2132, 1594, 630, 2132, 322, 13, 51396, 51396, 492, 434, 767, 3760, 46078, 38, 12354, 300, 767, 574, 411, 341, 281, 853, 281, 36238, 498, 257, 4537, 51694, 51694, 815, 362, 257, 1917, 2734, 13, 51829, 51829], "temperature": 0.0, "avg_logprob": -0.10240992151125512, "compression_ratio": 1.6600790513833992, "no_speech_prob": 4.092750259587774e-06}, {"id": 47, "seek": 22120, "start": 229.28, "end": 234.64, "text": " So if you put two electrodes on your chest, you will record voltages that look like this", "tokens": [50364, 400, 264, 41066, 1365, 286, 478, 516, 281, 764, 307, 21538, 295, 46078, 38, 12354, 11, 420, 16717, 22259, 72, 12820, 82, 13, 50768, 50768, 407, 498, 291, 829, 732, 47824, 322, 428, 7443, 11, 291, 486, 2136, 49614, 300, 574, 411, 341, 51036, 51036, 300, 6805, 281, 428, 34851, 13, 51180, 51180, 639, 307, 767, 746, 300, 452, 20374, 2132, 1594, 630, 2132, 322, 13, 51396, 51396, 492, 434, 767, 3760, 46078, 38, 12354, 300, 767, 574, 411, 341, 281, 853, 281, 36238, 498, 257, 4537, 51694, 51694, 815, 362, 257, 1917, 2734, 13, 51829, 51829], "temperature": 0.0, "avg_logprob": -0.10240992151125512, "compression_ratio": 1.6600790513833992, "no_speech_prob": 4.092750259587774e-06}, {"id": 48, "seek": 22120, "start": 234.64, "end": 237.51999999999998, "text": " that correspond to your heartbeat.", "tokens": [50364, 400, 264, 41066, 1365, 286, 478, 516, 281, 764, 307, 21538, 295, 46078, 38, 12354, 11, 420, 16717, 22259, 72, 12820, 82, 13, 50768, 50768, 407, 498, 291, 829, 732, 47824, 322, 428, 7443, 11, 291, 486, 2136, 49614, 300, 574, 411, 341, 51036, 51036, 300, 6805, 281, 428, 34851, 13, 51180, 51180, 639, 307, 767, 746, 300, 452, 20374, 2132, 1594, 630, 2132, 322, 13, 51396, 51396, 492, 434, 767, 3760, 46078, 38, 12354, 300, 767, 574, 411, 341, 281, 853, 281, 36238, 498, 257, 4537, 51694, 51694, 815, 362, 257, 1917, 2734, 13, 51829, 51829], "temperature": 0.0, "avg_logprob": -0.10240992151125512, "compression_ratio": 1.6600790513833992, "no_speech_prob": 4.092750259587774e-06}, {"id": 49, "seek": 22120, "start": 237.51999999999998, "end": 241.83999999999997, "text": " This is actually something that my Stanford research group did research on.", "tokens": [50364, 400, 264, 41066, 1365, 286, 478, 516, 281, 764, 307, 21538, 295, 46078, 38, 12354, 11, 420, 16717, 22259, 72, 12820, 82, 13, 50768, 50768, 407, 498, 291, 829, 732, 47824, 322, 428, 7443, 11, 291, 486, 2136, 49614, 300, 574, 411, 341, 51036, 51036, 300, 6805, 281, 428, 34851, 13, 51180, 51180, 639, 307, 767, 746, 300, 452, 20374, 2132, 1594, 630, 2132, 322, 13, 51396, 51396, 492, 434, 767, 3760, 46078, 38, 12354, 300, 767, 574, 411, 341, 281, 853, 281, 36238, 498, 257, 4537, 51694, 51694, 815, 362, 257, 1917, 2734, 13, 51829, 51829], "temperature": 0.0, "avg_logprob": -0.10240992151125512, "compression_ratio": 1.6600790513833992, "no_speech_prob": 4.092750259587774e-06}, {"id": 50, "seek": 22120, "start": 241.83999999999997, "end": 247.79999999999998, "text": " We're actually reading EKG signals that actually look like this to try to diagnose if a patient", "tokens": [50364, 400, 264, 41066, 1365, 286, 478, 516, 281, 764, 307, 21538, 295, 46078, 38, 12354, 11, 420, 16717, 22259, 72, 12820, 82, 13, 50768, 50768, 407, 498, 291, 829, 732, 47824, 322, 428, 7443, 11, 291, 486, 2136, 49614, 300, 574, 411, 341, 51036, 51036, 300, 6805, 281, 428, 34851, 13, 51180, 51180, 639, 307, 767, 746, 300, 452, 20374, 2132, 1594, 630, 2132, 322, 13, 51396, 51396, 492, 434, 767, 3760, 46078, 38, 12354, 300, 767, 574, 411, 341, 281, 853, 281, 36238, 498, 257, 4537, 51694, 51694, 815, 362, 257, 1917, 2734, 13, 51829, 51829], "temperature": 0.0, "avg_logprob": -0.10240992151125512, "compression_ratio": 1.6600790513833992, "no_speech_prob": 4.092750259587774e-06}, {"id": 51, "seek": 22120, "start": 247.79999999999998, "end": 250.5, "text": " may have a heart issue.", "tokens": [50364, 400, 264, 41066, 1365, 286, 478, 516, 281, 764, 307, 21538, 295, 46078, 38, 12354, 11, 420, 16717, 22259, 72, 12820, 82, 13, 50768, 50768, 407, 498, 291, 829, 732, 47824, 322, 428, 7443, 11, 291, 486, 2136, 49614, 300, 574, 411, 341, 51036, 51036, 300, 6805, 281, 428, 34851, 13, 51180, 51180, 639, 307, 767, 746, 300, 452, 20374, 2132, 1594, 630, 2132, 322, 13, 51396, 51396, 492, 434, 767, 3760, 46078, 38, 12354, 300, 767, 574, 411, 341, 281, 853, 281, 36238, 498, 257, 4537, 51694, 51694, 815, 362, 257, 1917, 2734, 13, 51829, 51829], "temperature": 0.0, "avg_logprob": -0.10240992151125512, "compression_ratio": 1.6600790513833992, "no_speech_prob": 4.092750259587774e-06}, {"id": 52, "seek": 25050, "start": 250.5, "end": 257.8, "text": " So an EKG signal, an electrocardiogram, ECG in some places, EKG in some places, is just", "tokens": [50364, 407, 364, 46078, 38, 6358, 11, 364, 16717, 22259, 72, 12820, 11, 19081, 38, 294, 512, 3190, 11, 46078, 38, 294, 512, 3190, 11, 307, 445, 50729, 50729, 257, 1329, 295, 3547, 11760, 281, 264, 6681, 295, 341, 3753, 412, 819, 2793, 294, 565, 13, 51036, 51036, 407, 291, 815, 362, 11, 584, 11, 2319, 3547, 11760, 281, 264, 6681, 295, 341, 7605, 412, 2319, 819, 51323, 51323, 2793, 295, 565, 13, 51465, 51465, 400, 264, 2539, 5633, 307, 11, 2212, 341, 565, 2638, 11, 2212, 341, 46078, 38, 6358, 11, 281, 33872, 11, 51823, 51823], "temperature": 0.0, "avg_logprob": -0.1077368891969019, "compression_ratio": 1.8195121951219513, "no_speech_prob": 4.356814315542579e-06}, {"id": 53, "seek": 25050, "start": 257.8, "end": 263.94, "text": " a list of numbers corresponding to the height of this surface at different points in time.", "tokens": [50364, 407, 364, 46078, 38, 6358, 11, 364, 16717, 22259, 72, 12820, 11, 19081, 38, 294, 512, 3190, 11, 46078, 38, 294, 512, 3190, 11, 307, 445, 50729, 50729, 257, 1329, 295, 3547, 11760, 281, 264, 6681, 295, 341, 3753, 412, 819, 2793, 294, 565, 13, 51036, 51036, 407, 291, 815, 362, 11, 584, 11, 2319, 3547, 11760, 281, 264, 6681, 295, 341, 7605, 412, 2319, 819, 51323, 51323, 2793, 295, 565, 13, 51465, 51465, 400, 264, 2539, 5633, 307, 11, 2212, 341, 565, 2638, 11, 2212, 341, 46078, 38, 6358, 11, 281, 33872, 11, 51823, 51823], "temperature": 0.0, "avg_logprob": -0.1077368891969019, "compression_ratio": 1.8195121951219513, "no_speech_prob": 4.356814315542579e-06}, {"id": 54, "seek": 25050, "start": 263.94, "end": 269.68, "text": " So you may have, say, 100 numbers corresponding to the height of this curve at 100 different", "tokens": [50364, 407, 364, 46078, 38, 6358, 11, 364, 16717, 22259, 72, 12820, 11, 19081, 38, 294, 512, 3190, 11, 46078, 38, 294, 512, 3190, 11, 307, 445, 50729, 50729, 257, 1329, 295, 3547, 11760, 281, 264, 6681, 295, 341, 3753, 412, 819, 2793, 294, 565, 13, 51036, 51036, 407, 291, 815, 362, 11, 584, 11, 2319, 3547, 11760, 281, 264, 6681, 295, 341, 7605, 412, 2319, 819, 51323, 51323, 2793, 295, 565, 13, 51465, 51465, 400, 264, 2539, 5633, 307, 11, 2212, 341, 565, 2638, 11, 2212, 341, 46078, 38, 6358, 11, 281, 33872, 11, 51823, 51823], "temperature": 0.0, "avg_logprob": -0.1077368891969019, "compression_ratio": 1.8195121951219513, "no_speech_prob": 4.356814315542579e-06}, {"id": 55, "seek": 25050, "start": 269.68, "end": 272.52, "text": " points of time.", "tokens": [50364, 407, 364, 46078, 38, 6358, 11, 364, 16717, 22259, 72, 12820, 11, 19081, 38, 294, 512, 3190, 11, 46078, 38, 294, 512, 3190, 11, 307, 445, 50729, 50729, 257, 1329, 295, 3547, 11760, 281, 264, 6681, 295, 341, 3753, 412, 819, 2793, 294, 565, 13, 51036, 51036, 407, 291, 815, 362, 11, 584, 11, 2319, 3547, 11760, 281, 264, 6681, 295, 341, 7605, 412, 2319, 819, 51323, 51323, 2793, 295, 565, 13, 51465, 51465, 400, 264, 2539, 5633, 307, 11, 2212, 341, 565, 2638, 11, 2212, 341, 46078, 38, 6358, 11, 281, 33872, 11, 51823, 51823], "temperature": 0.0, "avg_logprob": -0.1077368891969019, "compression_ratio": 1.8195121951219513, "no_speech_prob": 4.356814315542579e-06}, {"id": 56, "seek": 25050, "start": 272.52, "end": 279.68, "text": " And the learning task is, given this time series, given this EKG signal, to classify,", "tokens": [50364, 407, 364, 46078, 38, 6358, 11, 364, 16717, 22259, 72, 12820, 11, 19081, 38, 294, 512, 3190, 11, 46078, 38, 294, 512, 3190, 11, 307, 445, 50729, 50729, 257, 1329, 295, 3547, 11760, 281, 264, 6681, 295, 341, 3753, 412, 819, 2793, 294, 565, 13, 51036, 51036, 407, 291, 815, 362, 11, 584, 11, 2319, 3547, 11760, 281, 264, 6681, 295, 341, 7605, 412, 2319, 819, 51323, 51323, 2793, 295, 565, 13, 51465, 51465, 400, 264, 2539, 5633, 307, 11, 2212, 341, 565, 2638, 11, 2212, 341, 46078, 38, 6358, 11, 281, 33872, 11, 51823, 51823], "temperature": 0.0, "avg_logprob": -0.1077368891969019, "compression_ratio": 1.8195121951219513, "no_speech_prob": 4.356814315542579e-06}, {"id": 57, "seek": 27968, "start": 279.68, "end": 286.56, "text": " say whether this patient has a heart disease or some diagnosable heart condition, here's", "tokens": [50364, 584, 1968, 341, 4537, 575, 257, 1917, 4752, 420, 512, 7234, 329, 712, 1917, 4188, 11, 510, 311, 50708, 50708, 437, 257, 45216, 304, 18161, 3209, 1062, 360, 13, 50872, 50872, 407, 286, 478, 516, 281, 747, 264, 46078, 38, 6358, 293, 13121, 309, 4289, 5310, 281, 2360, 309, 322, 264, 1252, 13, 51104, 51104, 400, 370, 321, 362, 510, 2319, 15743, 11, 1783, 16, 11, 1783, 17, 11, 439, 264, 636, 807, 1783, 6879, 11, 411, 370, 13, 51438, 51438, 400, 562, 286, 7690, 264, 700, 7633, 4583, 11, 2602, 295, 1419, 264, 700, 7633, 4985, 747, 51806, 51806], "temperature": 0.0, "avg_logprob": -0.09469960717593923, "compression_ratio": 1.556910569105691, "no_speech_prob": 6.144050530565437e-06}, {"id": 58, "seek": 27968, "start": 286.56, "end": 289.84000000000003, "text": " what a convolutional neural network might do.", "tokens": [50364, 584, 1968, 341, 4537, 575, 257, 1917, 4752, 420, 512, 7234, 329, 712, 1917, 4188, 11, 510, 311, 50708, 50708, 437, 257, 45216, 304, 18161, 3209, 1062, 360, 13, 50872, 50872, 407, 286, 478, 516, 281, 747, 264, 46078, 38, 6358, 293, 13121, 309, 4289, 5310, 281, 2360, 309, 322, 264, 1252, 13, 51104, 51104, 400, 370, 321, 362, 510, 2319, 15743, 11, 1783, 16, 11, 1783, 17, 11, 439, 264, 636, 807, 1783, 6879, 11, 411, 370, 13, 51438, 51438, 400, 562, 286, 7690, 264, 700, 7633, 4583, 11, 2602, 295, 1419, 264, 700, 7633, 4985, 747, 51806, 51806], "temperature": 0.0, "avg_logprob": -0.09469960717593923, "compression_ratio": 1.556910569105691, "no_speech_prob": 6.144050530565437e-06}, {"id": 59, "seek": 27968, "start": 289.84000000000003, "end": 294.48, "text": " So I'm going to take the EKG signal and rotate it 90 degrees to lay it on the side.", "tokens": [50364, 584, 1968, 341, 4537, 575, 257, 1917, 4752, 420, 512, 7234, 329, 712, 1917, 4188, 11, 510, 311, 50708, 50708, 437, 257, 45216, 304, 18161, 3209, 1062, 360, 13, 50872, 50872, 407, 286, 478, 516, 281, 747, 264, 46078, 38, 6358, 293, 13121, 309, 4289, 5310, 281, 2360, 309, 322, 264, 1252, 13, 51104, 51104, 400, 370, 321, 362, 510, 2319, 15743, 11, 1783, 16, 11, 1783, 17, 11, 439, 264, 636, 807, 1783, 6879, 11, 411, 370, 13, 51438, 51438, 400, 562, 286, 7690, 264, 700, 7633, 4583, 11, 2602, 295, 1419, 264, 700, 7633, 4985, 747, 51806, 51806], "temperature": 0.0, "avg_logprob": -0.09469960717593923, "compression_ratio": 1.556910569105691, "no_speech_prob": 6.144050530565437e-06}, {"id": 60, "seek": 27968, "start": 294.48, "end": 301.16, "text": " And so we have here 100 inputs, X1, X2, all the way through X100, like so.", "tokens": [50364, 584, 1968, 341, 4537, 575, 257, 1917, 4752, 420, 512, 7234, 329, 712, 1917, 4188, 11, 510, 311, 50708, 50708, 437, 257, 45216, 304, 18161, 3209, 1062, 360, 13, 50872, 50872, 407, 286, 478, 516, 281, 747, 264, 46078, 38, 6358, 293, 13121, 309, 4289, 5310, 281, 2360, 309, 322, 264, 1252, 13, 51104, 51104, 400, 370, 321, 362, 510, 2319, 15743, 11, 1783, 16, 11, 1783, 17, 11, 439, 264, 636, 807, 1783, 6879, 11, 411, 370, 13, 51438, 51438, 400, 562, 286, 7690, 264, 700, 7633, 4583, 11, 2602, 295, 1419, 264, 700, 7633, 4985, 747, 51806, 51806], "temperature": 0.0, "avg_logprob": -0.09469960717593923, "compression_ratio": 1.556910569105691, "no_speech_prob": 6.144050530565437e-06}, {"id": 61, "seek": 27968, "start": 301.16, "end": 308.52, "text": " And when I construct the first hidden layer, instead of having the first hidden unit take", "tokens": [50364, 584, 1968, 341, 4537, 575, 257, 1917, 4752, 420, 512, 7234, 329, 712, 1917, 4188, 11, 510, 311, 50708, 50708, 437, 257, 45216, 304, 18161, 3209, 1062, 360, 13, 50872, 50872, 407, 286, 478, 516, 281, 747, 264, 46078, 38, 6358, 293, 13121, 309, 4289, 5310, 281, 2360, 309, 322, 264, 1252, 13, 51104, 51104, 400, 370, 321, 362, 510, 2319, 15743, 11, 1783, 16, 11, 1783, 17, 11, 439, 264, 636, 807, 1783, 6879, 11, 411, 370, 13, 51438, 51438, 400, 562, 286, 7690, 264, 700, 7633, 4583, 11, 2602, 295, 1419, 264, 700, 7633, 4985, 747, 51806, 51806], "temperature": 0.0, "avg_logprob": -0.09469960717593923, "compression_ratio": 1.556910569105691, "no_speech_prob": 6.144050530565437e-06}, {"id": 62, "seek": 30852, "start": 308.52, "end": 315.0, "text": " as input all 100 numbers, let me have the first hidden unit look at only X1 through", "tokens": [50364, 382, 4846, 439, 2319, 3547, 11, 718, 385, 362, 264, 700, 7633, 4985, 574, 412, 787, 1783, 16, 807, 50688, 50688, 1783, 2009, 13, 50754, 50754, 407, 300, 23249, 281, 1237, 412, 445, 257, 1359, 4910, 295, 341, 46078, 38, 6358, 13, 51040, 51040, 440, 1150, 7633, 4583, 11, 4898, 294, 257, 819, 2017, 510, 11, 486, 574, 412, 1783, 5348, 807, 1783, 3446, 11, 51344, 51344, 370, 309, 1542, 412, 257, 819, 4910, 294, 341, 46078, 38, 6358, 13, 51556, 51556, 400, 264, 2636, 7633, 4583, 1542, 412, 1071, 4910, 11, 1783, 4436, 807, 1783, 5254, 11, 293, 370, 322, 13, 51804, 51804], "temperature": 0.0, "avg_logprob": -0.09895394883065853, "compression_ratio": 1.7142857142857142, "no_speech_prob": 1.2098552133466e-06}, {"id": 63, "seek": 30852, "start": 315.0, "end": 316.32, "text": " X20.", "tokens": [50364, 382, 4846, 439, 2319, 3547, 11, 718, 385, 362, 264, 700, 7633, 4985, 574, 412, 787, 1783, 16, 807, 50688, 50688, 1783, 2009, 13, 50754, 50754, 407, 300, 23249, 281, 1237, 412, 445, 257, 1359, 4910, 295, 341, 46078, 38, 6358, 13, 51040, 51040, 440, 1150, 7633, 4583, 11, 4898, 294, 257, 819, 2017, 510, 11, 486, 574, 412, 1783, 5348, 807, 1783, 3446, 11, 51344, 51344, 370, 309, 1542, 412, 257, 819, 4910, 294, 341, 46078, 38, 6358, 13, 51556, 51556, 400, 264, 2636, 7633, 4583, 1542, 412, 1071, 4910, 11, 1783, 4436, 807, 1783, 5254, 11, 293, 370, 322, 13, 51804, 51804], "temperature": 0.0, "avg_logprob": -0.09895394883065853, "compression_ratio": 1.7142857142857142, "no_speech_prob": 1.2098552133466e-06}, {"id": 64, "seek": 30852, "start": 316.32, "end": 322.03999999999996, "text": " So that corresponds to looking at just a small window of this EKG signal.", "tokens": [50364, 382, 4846, 439, 2319, 3547, 11, 718, 385, 362, 264, 700, 7633, 4985, 574, 412, 787, 1783, 16, 807, 50688, 50688, 1783, 2009, 13, 50754, 50754, 407, 300, 23249, 281, 1237, 412, 445, 257, 1359, 4910, 295, 341, 46078, 38, 6358, 13, 51040, 51040, 440, 1150, 7633, 4583, 11, 4898, 294, 257, 819, 2017, 510, 11, 486, 574, 412, 1783, 5348, 807, 1783, 3446, 11, 51344, 51344, 370, 309, 1542, 412, 257, 819, 4910, 294, 341, 46078, 38, 6358, 13, 51556, 51556, 400, 264, 2636, 7633, 4583, 1542, 412, 1071, 4910, 11, 1783, 4436, 807, 1783, 5254, 11, 293, 370, 322, 13, 51804, 51804], "temperature": 0.0, "avg_logprob": -0.09895394883065853, "compression_ratio": 1.7142857142857142, "no_speech_prob": 1.2098552133466e-06}, {"id": 65, "seek": 30852, "start": 322.03999999999996, "end": 328.12, "text": " The second hidden layer, shown in a different color here, will look at X11 through X30,", "tokens": [50364, 382, 4846, 439, 2319, 3547, 11, 718, 385, 362, 264, 700, 7633, 4985, 574, 412, 787, 1783, 16, 807, 50688, 50688, 1783, 2009, 13, 50754, 50754, 407, 300, 23249, 281, 1237, 412, 445, 257, 1359, 4910, 295, 341, 46078, 38, 6358, 13, 51040, 51040, 440, 1150, 7633, 4583, 11, 4898, 294, 257, 819, 2017, 510, 11, 486, 574, 412, 1783, 5348, 807, 1783, 3446, 11, 51344, 51344, 370, 309, 1542, 412, 257, 819, 4910, 294, 341, 46078, 38, 6358, 13, 51556, 51556, 400, 264, 2636, 7633, 4583, 1542, 412, 1071, 4910, 11, 1783, 4436, 807, 1783, 5254, 11, 293, 370, 322, 13, 51804, 51804], "temperature": 0.0, "avg_logprob": -0.09895394883065853, "compression_ratio": 1.7142857142857142, "no_speech_prob": 1.2098552133466e-06}, {"id": 66, "seek": 30852, "start": 328.12, "end": 332.35999999999996, "text": " so it looks at a different window in this EKG signal.", "tokens": [50364, 382, 4846, 439, 2319, 3547, 11, 718, 385, 362, 264, 700, 7633, 4985, 574, 412, 787, 1783, 16, 807, 50688, 50688, 1783, 2009, 13, 50754, 50754, 407, 300, 23249, 281, 1237, 412, 445, 257, 1359, 4910, 295, 341, 46078, 38, 6358, 13, 51040, 51040, 440, 1150, 7633, 4583, 11, 4898, 294, 257, 819, 2017, 510, 11, 486, 574, 412, 1783, 5348, 807, 1783, 3446, 11, 51344, 51344, 370, 309, 1542, 412, 257, 819, 4910, 294, 341, 46078, 38, 6358, 13, 51556, 51556, 400, 264, 2636, 7633, 4583, 1542, 412, 1071, 4910, 11, 1783, 4436, 807, 1783, 5254, 11, 293, 370, 322, 13, 51804, 51804], "temperature": 0.0, "avg_logprob": -0.09895394883065853, "compression_ratio": 1.7142857142857142, "no_speech_prob": 1.2098552133466e-06}, {"id": 67, "seek": 30852, "start": 332.35999999999996, "end": 337.32, "text": " And the third hidden layer looks at another window, X21 through X40, and so on.", "tokens": [50364, 382, 4846, 439, 2319, 3547, 11, 718, 385, 362, 264, 700, 7633, 4985, 574, 412, 787, 1783, 16, 807, 50688, 50688, 1783, 2009, 13, 50754, 50754, 407, 300, 23249, 281, 1237, 412, 445, 257, 1359, 4910, 295, 341, 46078, 38, 6358, 13, 51040, 51040, 440, 1150, 7633, 4583, 11, 4898, 294, 257, 819, 2017, 510, 11, 486, 574, 412, 1783, 5348, 807, 1783, 3446, 11, 51344, 51344, 370, 309, 1542, 412, 257, 819, 4910, 294, 341, 46078, 38, 6358, 13, 51556, 51556, 400, 264, 2636, 7633, 4583, 1542, 412, 1071, 4910, 11, 1783, 4436, 807, 1783, 5254, 11, 293, 370, 322, 13, 51804, 51804], "temperature": 0.0, "avg_logprob": -0.09895394883065853, "compression_ratio": 1.7142857142857142, "no_speech_prob": 1.2098552133466e-06}, {"id": 68, "seek": 33732, "start": 337.32, "end": 344.24, "text": " And the final hidden unit in this example will look at X81 through X100, so it looks", "tokens": [50364, 400, 264, 2572, 7633, 4985, 294, 341, 1365, 486, 574, 412, 1783, 32875, 807, 1783, 6879, 11, 370, 309, 1542, 50710, 50710, 412, 257, 1359, 4910, 7361, 264, 917, 295, 341, 46078, 38, 565, 2638, 13, 50986, 50986, 407, 341, 307, 257, 45216, 304, 4583, 11, 570, 1184, 4985, 294, 341, 4583, 1542, 412, 787, 257, 5567, 51240, 51240, 4910, 295, 264, 4846, 13, 51390, 51390, 823, 341, 4583, 295, 264, 18161, 3209, 575, 4949, 6815, 13, 51677, 51677], "temperature": 0.0, "avg_logprob": -0.10402442790843823, "compression_ratio": 1.5612244897959184, "no_speech_prob": 1.0676951660570921e-06}, {"id": 69, "seek": 33732, "start": 344.24, "end": 349.76, "text": " at a small window toward the end of this EKG time series.", "tokens": [50364, 400, 264, 2572, 7633, 4985, 294, 341, 1365, 486, 574, 412, 1783, 32875, 807, 1783, 6879, 11, 370, 309, 1542, 50710, 50710, 412, 257, 1359, 4910, 7361, 264, 917, 295, 341, 46078, 38, 565, 2638, 13, 50986, 50986, 407, 341, 307, 257, 45216, 304, 4583, 11, 570, 1184, 4985, 294, 341, 4583, 1542, 412, 787, 257, 5567, 51240, 51240, 4910, 295, 264, 4846, 13, 51390, 51390, 823, 341, 4583, 295, 264, 18161, 3209, 575, 4949, 6815, 13, 51677, 51677], "temperature": 0.0, "avg_logprob": -0.10402442790843823, "compression_ratio": 1.5612244897959184, "no_speech_prob": 1.0676951660570921e-06}, {"id": 70, "seek": 33732, "start": 349.76, "end": 354.84, "text": " So this is a convolutional layer, because each unit in this layer looks at only a limited", "tokens": [50364, 400, 264, 2572, 7633, 4985, 294, 341, 1365, 486, 574, 412, 1783, 32875, 807, 1783, 6879, 11, 370, 309, 1542, 50710, 50710, 412, 257, 1359, 4910, 7361, 264, 917, 295, 341, 46078, 38, 565, 2638, 13, 50986, 50986, 407, 341, 307, 257, 45216, 304, 4583, 11, 570, 1184, 4985, 294, 341, 4583, 1542, 412, 787, 257, 5567, 51240, 51240, 4910, 295, 264, 4846, 13, 51390, 51390, 823, 341, 4583, 295, 264, 18161, 3209, 575, 4949, 6815, 13, 51677, 51677], "temperature": 0.0, "avg_logprob": -0.10402442790843823, "compression_ratio": 1.5612244897959184, "no_speech_prob": 1.0676951660570921e-06}, {"id": 71, "seek": 33732, "start": 354.84, "end": 357.84, "text": " window of the input.", "tokens": [50364, 400, 264, 2572, 7633, 4985, 294, 341, 1365, 486, 574, 412, 1783, 32875, 807, 1783, 6879, 11, 370, 309, 1542, 50710, 50710, 412, 257, 1359, 4910, 7361, 264, 917, 295, 341, 46078, 38, 565, 2638, 13, 50986, 50986, 407, 341, 307, 257, 45216, 304, 4583, 11, 570, 1184, 4985, 294, 341, 4583, 1542, 412, 787, 257, 5567, 51240, 51240, 4910, 295, 264, 4846, 13, 51390, 51390, 823, 341, 4583, 295, 264, 18161, 3209, 575, 4949, 6815, 13, 51677, 51677], "temperature": 0.0, "avg_logprob": -0.10402442790843823, "compression_ratio": 1.5612244897959184, "no_speech_prob": 1.0676951660570921e-06}, {"id": 72, "seek": 33732, "start": 357.84, "end": 363.58, "text": " Now this layer of the neural network has nine units.", "tokens": [50364, 400, 264, 2572, 7633, 4985, 294, 341, 1365, 486, 574, 412, 1783, 32875, 807, 1783, 6879, 11, 370, 309, 1542, 50710, 50710, 412, 257, 1359, 4910, 7361, 264, 917, 295, 341, 46078, 38, 565, 2638, 13, 50986, 50986, 407, 341, 307, 257, 45216, 304, 4583, 11, 570, 1184, 4985, 294, 341, 4583, 1542, 412, 787, 257, 5567, 51240, 51240, 4910, 295, 264, 4846, 13, 51390, 51390, 823, 341, 4583, 295, 264, 18161, 3209, 575, 4949, 6815, 13, 51677, 51677], "temperature": 0.0, "avg_logprob": -0.10402442790843823, "compression_ratio": 1.5612244897959184, "no_speech_prob": 1.0676951660570921e-06}, {"id": 73, "seek": 36358, "start": 363.58, "end": 368.52, "text": " The next layer can also be a convolutional layer.", "tokens": [50364, 440, 958, 4583, 393, 611, 312, 257, 45216, 304, 4583, 13, 50611, 50611, 407, 294, 264, 1150, 7633, 4583, 11, 718, 385, 6331, 452, 700, 4985, 11, 406, 281, 574, 412, 439, 4949, 2430, 763, 51083, 51083, 490, 264, 3894, 4583, 11, 457, 281, 574, 412, 11, 584, 11, 445, 264, 700, 1732, 2430, 763, 490, 264, 3894, 51390, 51390, 4583, 13, 51455, 51455, 400, 550, 452, 1150, 4985, 294, 341, 1150, 7633, 4583, 815, 574, 412, 445, 1071, 1732, 3547, 11, 51827, 51827], "temperature": 0.0, "avg_logprob": -0.09514721049818882, "compression_ratio": 1.8387096774193548, "no_speech_prob": 8.013375008886214e-06}, {"id": 74, "seek": 36358, "start": 368.52, "end": 377.96, "text": " So in the second hidden layer, let me architect my first unit, not to look at all nine activations", "tokens": [50364, 440, 958, 4583, 393, 611, 312, 257, 45216, 304, 4583, 13, 50611, 50611, 407, 294, 264, 1150, 7633, 4583, 11, 718, 385, 6331, 452, 700, 4985, 11, 406, 281, 574, 412, 439, 4949, 2430, 763, 51083, 51083, 490, 264, 3894, 4583, 11, 457, 281, 574, 412, 11, 584, 11, 445, 264, 700, 1732, 2430, 763, 490, 264, 3894, 51390, 51390, 4583, 13, 51455, 51455, 400, 550, 452, 1150, 4985, 294, 341, 1150, 7633, 4583, 815, 574, 412, 445, 1071, 1732, 3547, 11, 51827, 51827], "temperature": 0.0, "avg_logprob": -0.09514721049818882, "compression_ratio": 1.8387096774193548, "no_speech_prob": 8.013375008886214e-06}, {"id": 75, "seek": 36358, "start": 377.96, "end": 384.09999999999997, "text": " from the previous layer, but to look at, say, just the first five activations from the previous", "tokens": [50364, 440, 958, 4583, 393, 611, 312, 257, 45216, 304, 4583, 13, 50611, 50611, 407, 294, 264, 1150, 7633, 4583, 11, 718, 385, 6331, 452, 700, 4985, 11, 406, 281, 574, 412, 439, 4949, 2430, 763, 51083, 51083, 490, 264, 3894, 4583, 11, 457, 281, 574, 412, 11, 584, 11, 445, 264, 700, 1732, 2430, 763, 490, 264, 3894, 51390, 51390, 4583, 13, 51455, 51455, 400, 550, 452, 1150, 4985, 294, 341, 1150, 7633, 4583, 815, 574, 412, 445, 1071, 1732, 3547, 11, 51827, 51827], "temperature": 0.0, "avg_logprob": -0.09514721049818882, "compression_ratio": 1.8387096774193548, "no_speech_prob": 8.013375008886214e-06}, {"id": 76, "seek": 36358, "start": 384.09999999999997, "end": 385.4, "text": " layer.", "tokens": [50364, 440, 958, 4583, 393, 611, 312, 257, 45216, 304, 4583, 13, 50611, 50611, 407, 294, 264, 1150, 7633, 4583, 11, 718, 385, 6331, 452, 700, 4985, 11, 406, 281, 574, 412, 439, 4949, 2430, 763, 51083, 51083, 490, 264, 3894, 4583, 11, 457, 281, 574, 412, 11, 584, 11, 445, 264, 700, 1732, 2430, 763, 490, 264, 3894, 51390, 51390, 4583, 13, 51455, 51455, 400, 550, 452, 1150, 4985, 294, 341, 1150, 7633, 4583, 815, 574, 412, 445, 1071, 1732, 3547, 11, 51827, 51827], "temperature": 0.0, "avg_logprob": -0.09514721049818882, "compression_ratio": 1.8387096774193548, "no_speech_prob": 8.013375008886214e-06}, {"id": 77, "seek": 36358, "start": 385.4, "end": 392.84, "text": " And then my second unit in this second hidden layer may look at just another five numbers,", "tokens": [50364, 440, 958, 4583, 393, 611, 312, 257, 45216, 304, 4583, 13, 50611, 50611, 407, 294, 264, 1150, 7633, 4583, 11, 718, 385, 6331, 452, 700, 4985, 11, 406, 281, 574, 412, 439, 4949, 2430, 763, 51083, 51083, 490, 264, 3894, 4583, 11, 457, 281, 574, 412, 11, 584, 11, 445, 264, 700, 1732, 2430, 763, 490, 264, 3894, 51390, 51390, 4583, 13, 51455, 51455, 400, 550, 452, 1150, 4985, 294, 341, 1150, 7633, 4583, 815, 574, 412, 445, 1071, 1732, 3547, 11, 51827, 51827], "temperature": 0.0, "avg_logprob": -0.09514721049818882, "compression_ratio": 1.8387096774193548, "no_speech_prob": 8.013375008886214e-06}, {"id": 78, "seek": 39284, "start": 392.84, "end": 395.08, "text": " say A3 to A7.", "tokens": [50364, 584, 316, 18, 281, 316, 22, 13, 50476, 50476, 400, 264, 2636, 293, 2572, 7633, 4985, 294, 341, 4583, 486, 787, 574, 412, 316, 20, 807, 316, 24, 13, 50798, 50798, 400, 550, 1310, 2721, 11, 613, 2430, 763, 11, 316, 17, 11, 2170, 15743, 281, 257, 4556, 3280, 327, 4985, 300, 775, 51206, 51206, 574, 412, 439, 1045, 295, 613, 4190, 295, 316, 17, 294, 1668, 281, 652, 257, 17434, 21538, 8595, 51578, 51578, 6814, 420, 17145, 295, 1917, 4752, 13, 51724, 51724], "temperature": 0.0, "avg_logprob": -0.10021219697109489, "compression_ratio": 1.5445544554455446, "no_speech_prob": 1.248256126018532e-06}, {"id": 79, "seek": 39284, "start": 395.08, "end": 401.52, "text": " And the third and final hidden unit in this layer will only look at A5 through A9.", "tokens": [50364, 584, 316, 18, 281, 316, 22, 13, 50476, 50476, 400, 264, 2636, 293, 2572, 7633, 4985, 294, 341, 4583, 486, 787, 574, 412, 316, 20, 807, 316, 24, 13, 50798, 50798, 400, 550, 1310, 2721, 11, 613, 2430, 763, 11, 316, 17, 11, 2170, 15743, 281, 257, 4556, 3280, 327, 4985, 300, 775, 51206, 51206, 574, 412, 439, 1045, 295, 613, 4190, 295, 316, 17, 294, 1668, 281, 652, 257, 17434, 21538, 8595, 51578, 51578, 6814, 420, 17145, 295, 1917, 4752, 13, 51724, 51724], "temperature": 0.0, "avg_logprob": -0.10021219697109489, "compression_ratio": 1.5445544554455446, "no_speech_prob": 1.248256126018532e-06}, {"id": 80, "seek": 39284, "start": 401.52, "end": 409.67999999999995, "text": " And then maybe finally, these activations, A2, gets inputs to a sigmoid unit that does", "tokens": [50364, 584, 316, 18, 281, 316, 22, 13, 50476, 50476, 400, 264, 2636, 293, 2572, 7633, 4985, 294, 341, 4583, 486, 787, 574, 412, 316, 20, 807, 316, 24, 13, 50798, 50798, 400, 550, 1310, 2721, 11, 613, 2430, 763, 11, 316, 17, 11, 2170, 15743, 281, 257, 4556, 3280, 327, 4985, 300, 775, 51206, 51206, 574, 412, 439, 1045, 295, 613, 4190, 295, 316, 17, 294, 1668, 281, 652, 257, 17434, 21538, 8595, 51578, 51578, 6814, 420, 17145, 295, 1917, 4752, 13, 51724, 51724], "temperature": 0.0, "avg_logprob": -0.10021219697109489, "compression_ratio": 1.5445544554455446, "no_speech_prob": 1.248256126018532e-06}, {"id": 81, "seek": 39284, "start": 409.67999999999995, "end": 417.12, "text": " look at all three of these values of A2 in order to make a binary classification regarding", "tokens": [50364, 584, 316, 18, 281, 316, 22, 13, 50476, 50476, 400, 264, 2636, 293, 2572, 7633, 4985, 294, 341, 4583, 486, 787, 574, 412, 316, 20, 807, 316, 24, 13, 50798, 50798, 400, 550, 1310, 2721, 11, 613, 2430, 763, 11, 316, 17, 11, 2170, 15743, 281, 257, 4556, 3280, 327, 4985, 300, 775, 51206, 51206, 574, 412, 439, 1045, 295, 613, 4190, 295, 316, 17, 294, 1668, 281, 652, 257, 17434, 21538, 8595, 51578, 51578, 6814, 420, 17145, 295, 1917, 4752, 13, 51724, 51724], "temperature": 0.0, "avg_logprob": -0.10021219697109489, "compression_ratio": 1.5445544554455446, "no_speech_prob": 1.248256126018532e-06}, {"id": 82, "seek": 39284, "start": 417.12, "end": 420.03999999999996, "text": " presence or absence of heart disease.", "tokens": [50364, 584, 316, 18, 281, 316, 22, 13, 50476, 50476, 400, 264, 2636, 293, 2572, 7633, 4985, 294, 341, 4583, 486, 787, 574, 412, 316, 20, 807, 316, 24, 13, 50798, 50798, 400, 550, 1310, 2721, 11, 613, 2430, 763, 11, 316, 17, 11, 2170, 15743, 281, 257, 4556, 3280, 327, 4985, 300, 775, 51206, 51206, 574, 412, 439, 1045, 295, 613, 4190, 295, 316, 17, 294, 1668, 281, 652, 257, 17434, 21538, 8595, 51578, 51578, 6814, 420, 17145, 295, 1917, 4752, 13, 51724, 51724], "temperature": 0.0, "avg_logprob": -0.10021219697109489, "compression_ratio": 1.5445544554455446, "no_speech_prob": 1.248256126018532e-06}, {"id": 83, "seek": 42004, "start": 420.04, "end": 425.04, "text": " So this is an example of a neural network with the first hidden layer being a convolutional", "tokens": [50364, 407, 341, 307, 364, 1365, 295, 257, 18161, 3209, 365, 264, 700, 7633, 4583, 885, 257, 45216, 304, 50614, 50614, 4583, 11, 264, 1150, 7633, 4583, 611, 885, 257, 45216, 304, 4583, 11, 293, 550, 264, 5598, 50840, 50840, 4583, 885, 257, 4556, 3280, 327, 4583, 13, 50996, 50996, 400, 309, 4523, 484, 300, 365, 45216, 304, 7914, 11, 291, 362, 867, 26621, 7994, 11, 1270, 51267, 51267, 382, 577, 955, 307, 264, 4910, 295, 15743, 300, 257, 2167, 34090, 820, 574, 412, 11, 293, 577, 867, 51514, 51514, 22027, 820, 1184, 4583, 362, 13, 51659, 51659], "temperature": 0.0, "avg_logprob": -0.1158338219228417, "compression_ratio": 1.8772727272727272, "no_speech_prob": 7.690250072300842e-07}, {"id": 84, "seek": 42004, "start": 425.04, "end": 429.56, "text": " layer, the second hidden layer also being a convolutional layer, and then the output", "tokens": [50364, 407, 341, 307, 364, 1365, 295, 257, 18161, 3209, 365, 264, 700, 7633, 4583, 885, 257, 45216, 304, 50614, 50614, 4583, 11, 264, 1150, 7633, 4583, 611, 885, 257, 45216, 304, 4583, 11, 293, 550, 264, 5598, 50840, 50840, 4583, 885, 257, 4556, 3280, 327, 4583, 13, 50996, 50996, 400, 309, 4523, 484, 300, 365, 45216, 304, 7914, 11, 291, 362, 867, 26621, 7994, 11, 1270, 51267, 51267, 382, 577, 955, 307, 264, 4910, 295, 15743, 300, 257, 2167, 34090, 820, 574, 412, 11, 293, 577, 867, 51514, 51514, 22027, 820, 1184, 4583, 362, 13, 51659, 51659], "temperature": 0.0, "avg_logprob": -0.1158338219228417, "compression_ratio": 1.8772727272727272, "no_speech_prob": 7.690250072300842e-07}, {"id": 85, "seek": 42004, "start": 429.56, "end": 432.68, "text": " layer being a sigmoid layer.", "tokens": [50364, 407, 341, 307, 364, 1365, 295, 257, 18161, 3209, 365, 264, 700, 7633, 4583, 885, 257, 45216, 304, 50614, 50614, 4583, 11, 264, 1150, 7633, 4583, 611, 885, 257, 45216, 304, 4583, 11, 293, 550, 264, 5598, 50840, 50840, 4583, 885, 257, 4556, 3280, 327, 4583, 13, 50996, 50996, 400, 309, 4523, 484, 300, 365, 45216, 304, 7914, 11, 291, 362, 867, 26621, 7994, 11, 1270, 51267, 51267, 382, 577, 955, 307, 264, 4910, 295, 15743, 300, 257, 2167, 34090, 820, 574, 412, 11, 293, 577, 867, 51514, 51514, 22027, 820, 1184, 4583, 362, 13, 51659, 51659], "temperature": 0.0, "avg_logprob": -0.1158338219228417, "compression_ratio": 1.8772727272727272, "no_speech_prob": 7.690250072300842e-07}, {"id": 86, "seek": 42004, "start": 432.68, "end": 438.1, "text": " And it turns out that with convolutional layers, you have many architectural choices, such", "tokens": [50364, 407, 341, 307, 364, 1365, 295, 257, 18161, 3209, 365, 264, 700, 7633, 4583, 885, 257, 45216, 304, 50614, 50614, 4583, 11, 264, 1150, 7633, 4583, 611, 885, 257, 45216, 304, 4583, 11, 293, 550, 264, 5598, 50840, 50840, 4583, 885, 257, 4556, 3280, 327, 4583, 13, 50996, 50996, 400, 309, 4523, 484, 300, 365, 45216, 304, 7914, 11, 291, 362, 867, 26621, 7994, 11, 1270, 51267, 51267, 382, 577, 955, 307, 264, 4910, 295, 15743, 300, 257, 2167, 34090, 820, 574, 412, 11, 293, 577, 867, 51514, 51514, 22027, 820, 1184, 4583, 362, 13, 51659, 51659], "temperature": 0.0, "avg_logprob": -0.1158338219228417, "compression_ratio": 1.8772727272727272, "no_speech_prob": 7.690250072300842e-07}, {"id": 87, "seek": 42004, "start": 438.1, "end": 443.04, "text": " as how big is the window of inputs that a single neuron should look at, and how many", "tokens": [50364, 407, 341, 307, 364, 1365, 295, 257, 18161, 3209, 365, 264, 700, 7633, 4583, 885, 257, 45216, 304, 50614, 50614, 4583, 11, 264, 1150, 7633, 4583, 611, 885, 257, 45216, 304, 4583, 11, 293, 550, 264, 5598, 50840, 50840, 4583, 885, 257, 4556, 3280, 327, 4583, 13, 50996, 50996, 400, 309, 4523, 484, 300, 365, 45216, 304, 7914, 11, 291, 362, 867, 26621, 7994, 11, 1270, 51267, 51267, 382, 577, 955, 307, 264, 4910, 295, 15743, 300, 257, 2167, 34090, 820, 574, 412, 11, 293, 577, 867, 51514, 51514, 22027, 820, 1184, 4583, 362, 13, 51659, 51659], "temperature": 0.0, "avg_logprob": -0.1158338219228417, "compression_ratio": 1.8772727272727272, "no_speech_prob": 7.690250072300842e-07}, {"id": 88, "seek": 42004, "start": 443.04, "end": 445.94, "text": " neurons should each layer have.", "tokens": [50364, 407, 341, 307, 364, 1365, 295, 257, 18161, 3209, 365, 264, 700, 7633, 4583, 885, 257, 45216, 304, 50614, 50614, 4583, 11, 264, 1150, 7633, 4583, 611, 885, 257, 45216, 304, 4583, 11, 293, 550, 264, 5598, 50840, 50840, 4583, 885, 257, 4556, 3280, 327, 4583, 13, 50996, 50996, 400, 309, 4523, 484, 300, 365, 45216, 304, 7914, 11, 291, 362, 867, 26621, 7994, 11, 1270, 51267, 51267, 382, 577, 955, 307, 264, 4910, 295, 15743, 300, 257, 2167, 34090, 820, 574, 412, 11, 293, 577, 867, 51514, 51514, 22027, 820, 1184, 4583, 362, 13, 51659, 51659], "temperature": 0.0, "avg_logprob": -0.1158338219228417, "compression_ratio": 1.8772727272727272, "no_speech_prob": 7.690250072300842e-07}, {"id": 89, "seek": 44594, "start": 445.94, "end": 451.71999999999997, "text": " And by choosing those architectural parameters effectively, you can build new versions of", "tokens": [50364, 400, 538, 10875, 729, 26621, 9834, 8659, 11, 291, 393, 1322, 777, 9606, 295, 50653, 50653, 18161, 9590, 300, 393, 312, 754, 544, 4942, 813, 264, 18011, 4583, 337, 512, 5821, 13, 50929, 50929, 1407, 20928, 11, 300, 311, 309, 337, 264, 45216, 304, 4583, 293, 45216, 304, 18161, 9590, 13, 51191, 51191, 286, 478, 406, 516, 281, 352, 7731, 666, 45216, 304, 9590, 294, 341, 1508, 11, 293, 291, 500, 380, 643, 51427, 51427, 281, 458, 1340, 466, 552, 281, 360, 264, 14578, 82, 293, 2413, 341, 1508, 10727, 13, 51681, 51681], "temperature": 0.0, "avg_logprob": -0.07762978704352128, "compression_ratio": 1.7620967741935485, "no_speech_prob": 2.123322019542684e-06}, {"id": 90, "seek": 44594, "start": 451.71999999999997, "end": 457.24, "text": " neural networks that can be even more effective than the dense layer for some applications.", "tokens": [50364, 400, 538, 10875, 729, 26621, 9834, 8659, 11, 291, 393, 1322, 777, 9606, 295, 50653, 50653, 18161, 9590, 300, 393, 312, 754, 544, 4942, 813, 264, 18011, 4583, 337, 512, 5821, 13, 50929, 50929, 1407, 20928, 11, 300, 311, 309, 337, 264, 45216, 304, 4583, 293, 45216, 304, 18161, 9590, 13, 51191, 51191, 286, 478, 406, 516, 281, 352, 7731, 666, 45216, 304, 9590, 294, 341, 1508, 11, 293, 291, 500, 380, 643, 51427, 51427, 281, 458, 1340, 466, 552, 281, 360, 264, 14578, 82, 293, 2413, 341, 1508, 10727, 13, 51681, 51681], "temperature": 0.0, "avg_logprob": -0.07762978704352128, "compression_ratio": 1.7620967741935485, "no_speech_prob": 2.123322019542684e-06}, {"id": 91, "seek": 44594, "start": 457.24, "end": 462.48, "text": " To recap, that's it for the convolutional layer and convolutional neural networks.", "tokens": [50364, 400, 538, 10875, 729, 26621, 9834, 8659, 11, 291, 393, 1322, 777, 9606, 295, 50653, 50653, 18161, 9590, 300, 393, 312, 754, 544, 4942, 813, 264, 18011, 4583, 337, 512, 5821, 13, 50929, 50929, 1407, 20928, 11, 300, 311, 309, 337, 264, 45216, 304, 4583, 293, 45216, 304, 18161, 9590, 13, 51191, 51191, 286, 478, 406, 516, 281, 352, 7731, 666, 45216, 304, 9590, 294, 341, 1508, 11, 293, 291, 500, 380, 643, 51427, 51427, 281, 458, 1340, 466, 552, 281, 360, 264, 14578, 82, 293, 2413, 341, 1508, 10727, 13, 51681, 51681], "temperature": 0.0, "avg_logprob": -0.07762978704352128, "compression_ratio": 1.7620967741935485, "no_speech_prob": 2.123322019542684e-06}, {"id": 92, "seek": 44594, "start": 462.48, "end": 467.2, "text": " I'm not going to go deeper into convolutional networks in this class, and you don't need", "tokens": [50364, 400, 538, 10875, 729, 26621, 9834, 8659, 11, 291, 393, 1322, 777, 9606, 295, 50653, 50653, 18161, 9590, 300, 393, 312, 754, 544, 4942, 813, 264, 18011, 4583, 337, 512, 5821, 13, 50929, 50929, 1407, 20928, 11, 300, 311, 309, 337, 264, 45216, 304, 4583, 293, 45216, 304, 18161, 9590, 13, 51191, 51191, 286, 478, 406, 516, 281, 352, 7731, 666, 45216, 304, 9590, 294, 341, 1508, 11, 293, 291, 500, 380, 643, 51427, 51427, 281, 458, 1340, 466, 552, 281, 360, 264, 14578, 82, 293, 2413, 341, 1508, 10727, 13, 51681, 51681], "temperature": 0.0, "avg_logprob": -0.07762978704352128, "compression_ratio": 1.7620967741935485, "no_speech_prob": 2.123322019542684e-06}, {"id": 93, "seek": 44594, "start": 467.2, "end": 472.28, "text": " to know anything about them to do the homeworks and finish this class successfully.", "tokens": [50364, 400, 538, 10875, 729, 26621, 9834, 8659, 11, 291, 393, 1322, 777, 9606, 295, 50653, 50653, 18161, 9590, 300, 393, 312, 754, 544, 4942, 813, 264, 18011, 4583, 337, 512, 5821, 13, 50929, 50929, 1407, 20928, 11, 300, 311, 309, 337, 264, 45216, 304, 4583, 293, 45216, 304, 18161, 9590, 13, 51191, 51191, 286, 478, 406, 516, 281, 352, 7731, 666, 45216, 304, 9590, 294, 341, 1508, 11, 293, 291, 500, 380, 643, 51427, 51427, 281, 458, 1340, 466, 552, 281, 360, 264, 14578, 82, 293, 2413, 341, 1508, 10727, 13, 51681, 51681], "temperature": 0.0, "avg_logprob": -0.07762978704352128, "compression_ratio": 1.7620967741935485, "no_speech_prob": 2.123322019542684e-06}, {"id": 94, "seek": 47228, "start": 472.28, "end": 477.76, "text": " But I hope that you find this additional intuition that neural networks can have other types", "tokens": [50364, 583, 286, 1454, 300, 291, 915, 341, 4497, 24002, 300, 18161, 9590, 393, 362, 661, 3467, 50638, 50638, 295, 7914, 382, 731, 281, 312, 4420, 13, 50776, 50776, 400, 294, 1186, 11, 498, 291, 2171, 1568, 466, 264, 6792, 6492, 4691, 6331, 1303, 11, 411, 257, 51032, 51032, 31782, 2316, 420, 364, 441, 6840, 44, 420, 364, 3202, 2316, 11, 257, 688, 295, 341, 2132, 294, 18161, 9590, 51352, 51352, 754, 965, 13269, 2315, 281, 10309, 1382, 281, 7962, 777, 3467, 295, 7914, 337, 18161, 9590, 51674, 51674], "temperature": 0.0, "avg_logprob": -0.09665761523776584, "compression_ratio": 1.6965811965811965, "no_speech_prob": 4.289144271751866e-06}, {"id": 95, "seek": 47228, "start": 477.76, "end": 480.52, "text": " of layers as well to be useful.", "tokens": [50364, 583, 286, 1454, 300, 291, 915, 341, 4497, 24002, 300, 18161, 9590, 393, 362, 661, 3467, 50638, 50638, 295, 7914, 382, 731, 281, 312, 4420, 13, 50776, 50776, 400, 294, 1186, 11, 498, 291, 2171, 1568, 466, 264, 6792, 6492, 4691, 6331, 1303, 11, 411, 257, 51032, 51032, 31782, 2316, 420, 364, 441, 6840, 44, 420, 364, 3202, 2316, 11, 257, 688, 295, 341, 2132, 294, 18161, 9590, 51352, 51352, 754, 965, 13269, 2315, 281, 10309, 1382, 281, 7962, 777, 3467, 295, 7914, 337, 18161, 9590, 51674, 51674], "temperature": 0.0, "avg_logprob": -0.09665761523776584, "compression_ratio": 1.6965811965811965, "no_speech_prob": 4.289144271751866e-06}, {"id": 96, "seek": 47228, "start": 480.52, "end": 485.64, "text": " And in fact, if you sometimes hear about the latest cutting edge architectures, like a", "tokens": [50364, 583, 286, 1454, 300, 291, 915, 341, 4497, 24002, 300, 18161, 9590, 393, 362, 661, 3467, 50638, 50638, 295, 7914, 382, 731, 281, 312, 4420, 13, 50776, 50776, 400, 294, 1186, 11, 498, 291, 2171, 1568, 466, 264, 6792, 6492, 4691, 6331, 1303, 11, 411, 257, 51032, 51032, 31782, 2316, 420, 364, 441, 6840, 44, 420, 364, 3202, 2316, 11, 257, 688, 295, 341, 2132, 294, 18161, 9590, 51352, 51352, 754, 965, 13269, 2315, 281, 10309, 1382, 281, 7962, 777, 3467, 295, 7914, 337, 18161, 9590, 51674, 51674], "temperature": 0.0, "avg_logprob": -0.09665761523776584, "compression_ratio": 1.6965811965811965, "no_speech_prob": 4.289144271751866e-06}, {"id": 97, "seek": 47228, "start": 485.64, "end": 492.03999999999996, "text": " transformer model or an LSTM or an attention model, a lot of this research in neural networks", "tokens": [50364, 583, 286, 1454, 300, 291, 915, 341, 4497, 24002, 300, 18161, 9590, 393, 362, 661, 3467, 50638, 50638, 295, 7914, 382, 731, 281, 312, 4420, 13, 50776, 50776, 400, 294, 1186, 11, 498, 291, 2171, 1568, 466, 264, 6792, 6492, 4691, 6331, 1303, 11, 411, 257, 51032, 51032, 31782, 2316, 420, 364, 441, 6840, 44, 420, 364, 3202, 2316, 11, 257, 688, 295, 341, 2132, 294, 18161, 9590, 51352, 51352, 754, 965, 13269, 2315, 281, 10309, 1382, 281, 7962, 777, 3467, 295, 7914, 337, 18161, 9590, 51674, 51674], "temperature": 0.0, "avg_logprob": -0.09665761523776584, "compression_ratio": 1.6965811965811965, "no_speech_prob": 4.289144271751866e-06}, {"id": 98, "seek": 47228, "start": 492.03999999999996, "end": 498.47999999999996, "text": " even today pertains to researchers trying to invent new types of layers for neural networks", "tokens": [50364, 583, 286, 1454, 300, 291, 915, 341, 4497, 24002, 300, 18161, 9590, 393, 362, 661, 3467, 50638, 50638, 295, 7914, 382, 731, 281, 312, 4420, 13, 50776, 50776, 400, 294, 1186, 11, 498, 291, 2171, 1568, 466, 264, 6792, 6492, 4691, 6331, 1303, 11, 411, 257, 51032, 51032, 31782, 2316, 420, 364, 441, 6840, 44, 420, 364, 3202, 2316, 11, 257, 688, 295, 341, 2132, 294, 18161, 9590, 51352, 51352, 754, 965, 13269, 2315, 281, 10309, 1382, 281, 7962, 777, 3467, 295, 7914, 337, 18161, 9590, 51674, 51674], "temperature": 0.0, "avg_logprob": -0.09665761523776584, "compression_ratio": 1.6965811965811965, "no_speech_prob": 4.289144271751866e-06}, {"id": 99, "seek": 49848, "start": 498.48, "end": 503.40000000000003, "text": " and plugging these different types of layers together as building blocks to form even more", "tokens": [50364, 293, 42975, 613, 819, 3467, 295, 7914, 1214, 382, 2390, 8474, 281, 1254, 754, 544, 50610, 50610, 3997, 293, 4696, 544, 4005, 18161, 9590, 13, 50832, 50832, 407, 300, 311, 309, 337, 264, 4739, 2145, 337, 341, 1243, 13, 50990, 50990, 1044, 291, 293, 8882, 1720, 322, 13465, 365, 385, 439, 264, 636, 807, 341, 13, 51198, 51198, 400, 286, 574, 2128, 281, 2577, 291, 958, 1243, 611, 11, 689, 321, 603, 722, 281, 751, 466, 8496, 51483, 51483, 5192, 337, 577, 291, 393, 1322, 3479, 2539, 3652, 13, 51690, 51690], "temperature": 0.0, "avg_logprob": -0.08316779905749906, "compression_ratio": 1.5769230769230769, "no_speech_prob": 8.012764737941325e-06}, {"id": 100, "seek": 49848, "start": 503.40000000000003, "end": 507.84000000000003, "text": " complex and hopefully more powerful neural networks.", "tokens": [50364, 293, 42975, 613, 819, 3467, 295, 7914, 1214, 382, 2390, 8474, 281, 1254, 754, 544, 50610, 50610, 3997, 293, 4696, 544, 4005, 18161, 9590, 13, 50832, 50832, 407, 300, 311, 309, 337, 264, 4739, 2145, 337, 341, 1243, 13, 50990, 50990, 1044, 291, 293, 8882, 1720, 322, 13465, 365, 385, 439, 264, 636, 807, 341, 13, 51198, 51198, 400, 286, 574, 2128, 281, 2577, 291, 958, 1243, 611, 11, 689, 321, 603, 722, 281, 751, 466, 8496, 51483, 51483, 5192, 337, 577, 291, 393, 1322, 3479, 2539, 3652, 13, 51690, 51690], "temperature": 0.0, "avg_logprob": -0.08316779905749906, "compression_ratio": 1.5769230769230769, "no_speech_prob": 8.012764737941325e-06}, {"id": 101, "seek": 49848, "start": 507.84000000000003, "end": 511.0, "text": " So that's it for the required videos for this week.", "tokens": [50364, 293, 42975, 613, 819, 3467, 295, 7914, 1214, 382, 2390, 8474, 281, 1254, 754, 544, 50610, 50610, 3997, 293, 4696, 544, 4005, 18161, 9590, 13, 50832, 50832, 407, 300, 311, 309, 337, 264, 4739, 2145, 337, 341, 1243, 13, 50990, 50990, 1044, 291, 293, 8882, 1720, 322, 13465, 365, 385, 439, 264, 636, 807, 341, 13, 51198, 51198, 400, 286, 574, 2128, 281, 2577, 291, 958, 1243, 611, 11, 689, 321, 603, 722, 281, 751, 466, 8496, 51483, 51483, 5192, 337, 577, 291, 393, 1322, 3479, 2539, 3652, 13, 51690, 51690], "temperature": 0.0, "avg_logprob": -0.08316779905749906, "compression_ratio": 1.5769230769230769, "no_speech_prob": 8.012764737941325e-06}, {"id": 102, "seek": 49848, "start": 511.0, "end": 515.16, "text": " Thank you and congrats on sticking with me all the way through this.", "tokens": [50364, 293, 42975, 613, 819, 3467, 295, 7914, 1214, 382, 2390, 8474, 281, 1254, 754, 544, 50610, 50610, 3997, 293, 4696, 544, 4005, 18161, 9590, 13, 50832, 50832, 407, 300, 311, 309, 337, 264, 4739, 2145, 337, 341, 1243, 13, 50990, 50990, 1044, 291, 293, 8882, 1720, 322, 13465, 365, 385, 439, 264, 636, 807, 341, 13, 51198, 51198, 400, 286, 574, 2128, 281, 2577, 291, 958, 1243, 611, 11, 689, 321, 603, 722, 281, 751, 466, 8496, 51483, 51483, 5192, 337, 577, 291, 393, 1322, 3479, 2539, 3652, 13, 51690, 51690], "temperature": 0.0, "avg_logprob": -0.08316779905749906, "compression_ratio": 1.5769230769230769, "no_speech_prob": 8.012764737941325e-06}, {"id": 103, "seek": 49848, "start": 515.16, "end": 520.86, "text": " And I look forward to seeing you next week also, where we'll start to talk about practical", "tokens": [50364, 293, 42975, 613, 819, 3467, 295, 7914, 1214, 382, 2390, 8474, 281, 1254, 754, 544, 50610, 50610, 3997, 293, 4696, 544, 4005, 18161, 9590, 13, 50832, 50832, 407, 300, 311, 309, 337, 264, 4739, 2145, 337, 341, 1243, 13, 50990, 50990, 1044, 291, 293, 8882, 1720, 322, 13465, 365, 385, 439, 264, 636, 807, 341, 13, 51198, 51198, 400, 286, 574, 2128, 281, 2577, 291, 958, 1243, 611, 11, 689, 321, 603, 722, 281, 751, 466, 8496, 51483, 51483, 5192, 337, 577, 291, 393, 1322, 3479, 2539, 3652, 13, 51690, 51690], "temperature": 0.0, "avg_logprob": -0.08316779905749906, "compression_ratio": 1.5769230769230769, "no_speech_prob": 8.012764737941325e-06}, {"id": 104, "seek": 49848, "start": 520.86, "end": 525.0, "text": " advice for how you can build machine learning systems.", "tokens": [50364, 293, 42975, 613, 819, 3467, 295, 7914, 1214, 382, 2390, 8474, 281, 1254, 754, 544, 50610, 50610, 3997, 293, 4696, 544, 4005, 18161, 9590, 13, 50832, 50832, 407, 300, 311, 309, 337, 264, 4739, 2145, 337, 341, 1243, 13, 50990, 50990, 1044, 291, 293, 8882, 1720, 322, 13465, 365, 385, 439, 264, 636, 807, 341, 13, 51198, 51198, 400, 286, 574, 2128, 281, 2577, 291, 958, 1243, 611, 11, 689, 321, 603, 722, 281, 751, 466, 8496, 51483, 51483, 5192, 337, 577, 291, 393, 1322, 3479, 2539, 3652, 13, 51690, 51690], "temperature": 0.0, "avg_logprob": -0.08316779905749906, "compression_ratio": 1.5769230769230769, "no_speech_prob": 8.012764737941325e-06}, {"id": 105, "seek": 52500, "start": 525.0, "end": 530.48, "text": " I hope that the tips you learn next week will help you become much more effective at building", "tokens": [50364, 286, 1454, 300, 264, 6082, 291, 1466, 958, 1243, 486, 854, 291, 1813, 709, 544, 4942, 412, 2390, 50638, 50638, 4420, 3479, 2539, 3652, 13, 50750, 50750, 407, 286, 574, 2128, 611, 281, 2577, 291, 958, 1243, 13, 50866], "temperature": 0.0, "avg_logprob": -0.1608803795605171, "compression_ratio": 1.3700787401574803, "no_speech_prob": 4.5247241359902546e-05}, {"id": 106, "seek": 52500, "start": 530.48, "end": 532.72, "text": " useful machine learning systems.", "tokens": [50364, 286, 1454, 300, 264, 6082, 291, 1466, 958, 1243, 486, 854, 291, 1813, 709, 544, 4942, 412, 2390, 50638, 50638, 4420, 3479, 2539, 3652, 13, 50750, 50750, 407, 286, 574, 2128, 611, 281, 2577, 291, 958, 1243, 13, 50866], "temperature": 0.0, "avg_logprob": -0.1608803795605171, "compression_ratio": 1.3700787401574803, "no_speech_prob": 4.5247241359902546e-05}, {"id": 107, "seek": 53272, "start": 532.72, "end": 555.72, "text": " And I look forward also to seeing you next week.", "tokens": [50364, 400, 286, 574, 2128, 611, 281, 2577, 291, 958, 1243, 13, 51514], "temperature": 0.0, "avg_logprob": -0.3972266401563372, "compression_ratio": 0.8571428571428571, "no_speech_prob": 0.00032681640004739165}], "language": "en", "video_id": "54TxZZpK5Ok", "entity": "ML Specialization, Andrew Ng (2022)"}}