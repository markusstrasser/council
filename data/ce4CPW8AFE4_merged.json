{"video_id": "ce4CPW8AFE4", "title": "3.8 Regularization to Reduce Overfitting | Addressing Overfitting-[Machine Learning|Andrew Ng]", "description": "First Course:\nSupervised Machine Learning : Regression and Classification.\n\nIf you liked the content please subscribe and put a little blue thumb.\nTake heart!", "author": "Machine Learning", "keywords": [], "channel_url": "https://www.youtube.com/channel/UClG5HEAJJFOavT_UolqYROQ", "length": 495, "views": 179, "publish_date": "11/04/2022", "timestamp": 1661299200, "entity": "ML Specialization, Andrew Ng (2022)", "transcript": {"text": " Later in this specialization, we'll talk about debugging and diagnosing things that can go wrong with learning algorithms. You also learn about specific tools to recognize when overfitting and underfitting may be occurring. But for now, when you think overfitting has occurred, let's talk about what you can do to address it. Let's say you fit a model and it has high variance as overfit. Here's our overfit house price prediction model. One way to address this problem is to collect more training data. So that's one option. If you're able to get more data, that is more training examples on sizes and prices of houses, then with the larger training set, the learning algorithm will learn to fit a function that is less wiggly. So you can continue to fit a high order polynomial or some other function with a lot of features. And if you have enough training examples, it will still do okay. So to summarize, the number one tool you can use against overfitting is to get more training data. Now, getting more data isn't always an option. Maybe only so many houses have been sold in this location. So maybe there just isn't more data to be had. So when the data is available, this can work really well. A second option for addressing overfitting is to see if you can use fewer features. In the previous video, our model's features included the size x as well as the size squared, that is x squared, and x cubed and x to the 4 and so on. These were a lot of polynomial features. So in that case, one way to reduce overfitting is to just not use so many of these polynomial features. But now let's look at a different example. Maybe you have a lot of different features of a house with which to try to predict its price, ranging from the size, number of bedrooms, number of floors, the age, average income of the neighborhood, and so on and so forth to the distance to the nearest coffee shop. It turns out that if you have a lot of features like these, but don't have enough training data, then your learning algorithm may also overfit to your training set. Now instead of using all 100 features, if we were to pick just a subset of the most useful ones, maybe size, bedrooms, and the age of the house, if you think those are the most relevant features, then using just that smaller subset of features, you may find that your model no longer overfits as badly. Choosing the most appropriate set of features to use is sometimes also called feature selection. One way you could do so is to use your intuition to choose what you think is the best set of features. What's most relevant for predicting the price. Now one disadvantage of feature selection is that by using only a subset of the features, the algorithm is throwing away some of the information that you have about the houses. For example, maybe all of these features, or 100 of them, are actually useful for predicting the price of a house. So maybe you don't want to throw away some of the information by throwing away some of the features. Later in course two, you also see some algorithms for automatically choosing the most appropriate set of features to use for prediction tasks. Now this takes us to the third option for reducing overfitting. This technique, which we'll look at in even greater depth in the next video, is called regularization. If you look at an overfit model, here's a model using polynomial features x, x squared, x cubed, and so on. You find that the parameters are often relatively large. Now if you were to eliminate some of these features, say if you were to eliminate the feature x4, that corresponds to setting this parameter to zero. So setting a parameter to zero is equivalent to eliminating a feature, which is what we saw on the previous slide. It turns out that regularization is a way to more gently reduce the impacts of some of the features without doing something as harsh as eliminating it outright. What regularization does is encourage the learning algorithm to shrink the values of the parameters without necessarily demanding that the parameter is set to exactly zero. And it turns out that even if you fit a higher order polynomial like this, so long as you can get the algorithm to use smaller parameter values, w1, w2, w3, w4, you end up with a curve that ends up fitting the training data much better. So what regularization does is it lets you keep all of your features, but it just prevents the features from having an overly large effect, which is what sometimes can cause overfitting. By the way, by convention, we normally just reduce the size of the wj parameters, that is w1 through wn. It kind of doesn't make a huge difference whether you regularize the parameter b as well. You could do so if you want or not if you don't. I usually don't and it's just fine to regularize w1, w2 all the way to wn, but not really encourage b to become smaller. In practice, it should make very little difference whether you also regularize b or not. So to recap, these are the three ways you saw in this video for addressing overfitting. One, collect more data. If you can get more data, this can really help reduce overfitting. Sometimes that's not possible, in which case some of the options are, two, try selecting and using only a subset of the features. You learn more about feature selection in course two. Three would be to reduce the size of the parameters using regularization. This will be the subject of the next video as well. As for myself, I use regularization all the time. So this is a very useful technique for training learning algorithms, including neural networks specifically, which you see later in the specialization as well. I hope you also check out the optional lab on overfitting. In the lab, you will see different examples of overfitting and adjust those examples by clicking on options in the plots. You also be able to add your own data points by clicking on the plot and see how that changes the curve that is fit. You can also try examples for both regression and classification, and you really change the degree of the polynomial to be x, x squared, x cubed, and so on. The lab also lets you play with two different options for addressing overfitting. You can add additional training data to reduce overfitting, and you can also select which features to include or to exclude as another way to try to reduce overfitting. So please take a look at the lab, which I hope will help you build your intuition about overfitting as well as some methods for addressing it. In this video, you also saw the idea of regularization at a relatively high level. I realize that all of these details on regularization may not fully make sense to you yet, but in the next video, we'll start to formulate exactly how to apply regularization and exactly what regularization means. And then we'll start to figure out how to make this work with our learning algorithms to make linear regression and literacy regression and in the future, other algorithms as well, avoid overfitting. Let's take a look at that in the next video.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 7.04, "text": " Later in this specialization, we'll talk about debugging and diagnosing things that", "tokens": [50364, 11965, 294, 341, 2121, 2144, 11, 321, 603, 751, 466, 45592, 293, 7234, 6110, 721, 300, 50716, 50716, 393, 352, 2085, 365, 2539, 14642, 13, 50840, 50840, 509, 611, 1466, 466, 2685, 3873, 281, 5521, 562, 670, 69, 2414, 293, 833, 69, 2414, 815, 312, 18386, 13, 51154, 51154, 583, 337, 586, 11, 562, 291, 519, 670, 69, 2414, 575, 11068, 11, 718, 311, 751, 466, 437, 291, 393, 360, 51406, 51406, 281, 2985, 309, 13, 51492, 51492, 961, 311, 584, 291, 3318, 257, 2316, 293, 309, 575, 1090, 21977, 382, 670, 6845, 13, 51756, 51756], "temperature": 0.0, "avg_logprob": -0.14527492133938535, "compression_ratio": 1.6869565217391305, "no_speech_prob": 0.01223446149379015}, {"id": 1, "seek": 0, "start": 7.04, "end": 9.52, "text": " can go wrong with learning algorithms.", "tokens": [50364, 11965, 294, 341, 2121, 2144, 11, 321, 603, 751, 466, 45592, 293, 7234, 6110, 721, 300, 50716, 50716, 393, 352, 2085, 365, 2539, 14642, 13, 50840, 50840, 509, 611, 1466, 466, 2685, 3873, 281, 5521, 562, 670, 69, 2414, 293, 833, 69, 2414, 815, 312, 18386, 13, 51154, 51154, 583, 337, 586, 11, 562, 291, 519, 670, 69, 2414, 575, 11068, 11, 718, 311, 751, 466, 437, 291, 393, 360, 51406, 51406, 281, 2985, 309, 13, 51492, 51492, 961, 311, 584, 291, 3318, 257, 2316, 293, 309, 575, 1090, 21977, 382, 670, 6845, 13, 51756, 51756], "temperature": 0.0, "avg_logprob": -0.14527492133938535, "compression_ratio": 1.6869565217391305, "no_speech_prob": 0.01223446149379015}, {"id": 2, "seek": 0, "start": 9.52, "end": 15.8, "text": " You also learn about specific tools to recognize when overfitting and underfitting may be occurring.", "tokens": [50364, 11965, 294, 341, 2121, 2144, 11, 321, 603, 751, 466, 45592, 293, 7234, 6110, 721, 300, 50716, 50716, 393, 352, 2085, 365, 2539, 14642, 13, 50840, 50840, 509, 611, 1466, 466, 2685, 3873, 281, 5521, 562, 670, 69, 2414, 293, 833, 69, 2414, 815, 312, 18386, 13, 51154, 51154, 583, 337, 586, 11, 562, 291, 519, 670, 69, 2414, 575, 11068, 11, 718, 311, 751, 466, 437, 291, 393, 360, 51406, 51406, 281, 2985, 309, 13, 51492, 51492, 961, 311, 584, 291, 3318, 257, 2316, 293, 309, 575, 1090, 21977, 382, 670, 6845, 13, 51756, 51756], "temperature": 0.0, "avg_logprob": -0.14527492133938535, "compression_ratio": 1.6869565217391305, "no_speech_prob": 0.01223446149379015}, {"id": 3, "seek": 0, "start": 15.8, "end": 20.84, "text": " But for now, when you think overfitting has occurred, let's talk about what you can do", "tokens": [50364, 11965, 294, 341, 2121, 2144, 11, 321, 603, 751, 466, 45592, 293, 7234, 6110, 721, 300, 50716, 50716, 393, 352, 2085, 365, 2539, 14642, 13, 50840, 50840, 509, 611, 1466, 466, 2685, 3873, 281, 5521, 562, 670, 69, 2414, 293, 833, 69, 2414, 815, 312, 18386, 13, 51154, 51154, 583, 337, 586, 11, 562, 291, 519, 670, 69, 2414, 575, 11068, 11, 718, 311, 751, 466, 437, 291, 393, 360, 51406, 51406, 281, 2985, 309, 13, 51492, 51492, 961, 311, 584, 291, 3318, 257, 2316, 293, 309, 575, 1090, 21977, 382, 670, 6845, 13, 51756, 51756], "temperature": 0.0, "avg_logprob": -0.14527492133938535, "compression_ratio": 1.6869565217391305, "no_speech_prob": 0.01223446149379015}, {"id": 4, "seek": 0, "start": 20.84, "end": 22.56, "text": " to address it.", "tokens": [50364, 11965, 294, 341, 2121, 2144, 11, 321, 603, 751, 466, 45592, 293, 7234, 6110, 721, 300, 50716, 50716, 393, 352, 2085, 365, 2539, 14642, 13, 50840, 50840, 509, 611, 1466, 466, 2685, 3873, 281, 5521, 562, 670, 69, 2414, 293, 833, 69, 2414, 815, 312, 18386, 13, 51154, 51154, 583, 337, 586, 11, 562, 291, 519, 670, 69, 2414, 575, 11068, 11, 718, 311, 751, 466, 437, 291, 393, 360, 51406, 51406, 281, 2985, 309, 13, 51492, 51492, 961, 311, 584, 291, 3318, 257, 2316, 293, 309, 575, 1090, 21977, 382, 670, 6845, 13, 51756, 51756], "temperature": 0.0, "avg_logprob": -0.14527492133938535, "compression_ratio": 1.6869565217391305, "no_speech_prob": 0.01223446149379015}, {"id": 5, "seek": 0, "start": 22.56, "end": 27.84, "text": " Let's say you fit a model and it has high variance as overfit.", "tokens": [50364, 11965, 294, 341, 2121, 2144, 11, 321, 603, 751, 466, 45592, 293, 7234, 6110, 721, 300, 50716, 50716, 393, 352, 2085, 365, 2539, 14642, 13, 50840, 50840, 509, 611, 1466, 466, 2685, 3873, 281, 5521, 562, 670, 69, 2414, 293, 833, 69, 2414, 815, 312, 18386, 13, 51154, 51154, 583, 337, 586, 11, 562, 291, 519, 670, 69, 2414, 575, 11068, 11, 718, 311, 751, 466, 437, 291, 393, 360, 51406, 51406, 281, 2985, 309, 13, 51492, 51492, 961, 311, 584, 291, 3318, 257, 2316, 293, 309, 575, 1090, 21977, 382, 670, 6845, 13, 51756, 51756], "temperature": 0.0, "avg_logprob": -0.14527492133938535, "compression_ratio": 1.6869565217391305, "no_speech_prob": 0.01223446149379015}, {"id": 6, "seek": 2784, "start": 27.84, "end": 32.28, "text": " Here's our overfit house price prediction model.", "tokens": [50364, 1692, 311, 527, 670, 6845, 1782, 3218, 17630, 2316, 13, 50586, 50586, 1485, 636, 281, 2985, 341, 1154, 307, 281, 2500, 544, 3097, 1412, 13, 50828, 50828, 407, 300, 311, 472, 3614, 13, 50932, 50932, 759, 291, 434, 1075, 281, 483, 544, 1412, 11, 300, 307, 544, 3097, 5110, 322, 11602, 293, 7901, 295, 8078, 11, 51276, 51276, 550, 365, 264, 4833, 3097, 992, 11, 264, 2539, 9284, 486, 1466, 281, 3318, 257, 2445, 300, 51576, 51576, 307, 1570, 261, 46737, 13, 51680, 51680], "temperature": 0.0, "avg_logprob": -0.12461651203244231, "compression_ratio": 1.6536585365853658, "no_speech_prob": 8.013127626327332e-06}, {"id": 7, "seek": 2784, "start": 32.28, "end": 37.12, "text": " One way to address this problem is to collect more training data.", "tokens": [50364, 1692, 311, 527, 670, 6845, 1782, 3218, 17630, 2316, 13, 50586, 50586, 1485, 636, 281, 2985, 341, 1154, 307, 281, 2500, 544, 3097, 1412, 13, 50828, 50828, 407, 300, 311, 472, 3614, 13, 50932, 50932, 759, 291, 434, 1075, 281, 483, 544, 1412, 11, 300, 307, 544, 3097, 5110, 322, 11602, 293, 7901, 295, 8078, 11, 51276, 51276, 550, 365, 264, 4833, 3097, 992, 11, 264, 2539, 9284, 486, 1466, 281, 3318, 257, 2445, 300, 51576, 51576, 307, 1570, 261, 46737, 13, 51680, 51680], "temperature": 0.0, "avg_logprob": -0.12461651203244231, "compression_ratio": 1.6536585365853658, "no_speech_prob": 8.013127626327332e-06}, {"id": 8, "seek": 2784, "start": 37.12, "end": 39.2, "text": " So that's one option.", "tokens": [50364, 1692, 311, 527, 670, 6845, 1782, 3218, 17630, 2316, 13, 50586, 50586, 1485, 636, 281, 2985, 341, 1154, 307, 281, 2500, 544, 3097, 1412, 13, 50828, 50828, 407, 300, 311, 472, 3614, 13, 50932, 50932, 759, 291, 434, 1075, 281, 483, 544, 1412, 11, 300, 307, 544, 3097, 5110, 322, 11602, 293, 7901, 295, 8078, 11, 51276, 51276, 550, 365, 264, 4833, 3097, 992, 11, 264, 2539, 9284, 486, 1466, 281, 3318, 257, 2445, 300, 51576, 51576, 307, 1570, 261, 46737, 13, 51680, 51680], "temperature": 0.0, "avg_logprob": -0.12461651203244231, "compression_ratio": 1.6536585365853658, "no_speech_prob": 8.013127626327332e-06}, {"id": 9, "seek": 2784, "start": 39.2, "end": 46.08, "text": " If you're able to get more data, that is more training examples on sizes and prices of houses,", "tokens": [50364, 1692, 311, 527, 670, 6845, 1782, 3218, 17630, 2316, 13, 50586, 50586, 1485, 636, 281, 2985, 341, 1154, 307, 281, 2500, 544, 3097, 1412, 13, 50828, 50828, 407, 300, 311, 472, 3614, 13, 50932, 50932, 759, 291, 434, 1075, 281, 483, 544, 1412, 11, 300, 307, 544, 3097, 5110, 322, 11602, 293, 7901, 295, 8078, 11, 51276, 51276, 550, 365, 264, 4833, 3097, 992, 11, 264, 2539, 9284, 486, 1466, 281, 3318, 257, 2445, 300, 51576, 51576, 307, 1570, 261, 46737, 13, 51680, 51680], "temperature": 0.0, "avg_logprob": -0.12461651203244231, "compression_ratio": 1.6536585365853658, "no_speech_prob": 8.013127626327332e-06}, {"id": 10, "seek": 2784, "start": 46.08, "end": 52.08, "text": " then with the larger training set, the learning algorithm will learn to fit a function that", "tokens": [50364, 1692, 311, 527, 670, 6845, 1782, 3218, 17630, 2316, 13, 50586, 50586, 1485, 636, 281, 2985, 341, 1154, 307, 281, 2500, 544, 3097, 1412, 13, 50828, 50828, 407, 300, 311, 472, 3614, 13, 50932, 50932, 759, 291, 434, 1075, 281, 483, 544, 1412, 11, 300, 307, 544, 3097, 5110, 322, 11602, 293, 7901, 295, 8078, 11, 51276, 51276, 550, 365, 264, 4833, 3097, 992, 11, 264, 2539, 9284, 486, 1466, 281, 3318, 257, 2445, 300, 51576, 51576, 307, 1570, 261, 46737, 13, 51680, 51680], "temperature": 0.0, "avg_logprob": -0.12461651203244231, "compression_ratio": 1.6536585365853658, "no_speech_prob": 8.013127626327332e-06}, {"id": 11, "seek": 2784, "start": 52.08, "end": 54.16, "text": " is less wiggly.", "tokens": [50364, 1692, 311, 527, 670, 6845, 1782, 3218, 17630, 2316, 13, 50586, 50586, 1485, 636, 281, 2985, 341, 1154, 307, 281, 2500, 544, 3097, 1412, 13, 50828, 50828, 407, 300, 311, 472, 3614, 13, 50932, 50932, 759, 291, 434, 1075, 281, 483, 544, 1412, 11, 300, 307, 544, 3097, 5110, 322, 11602, 293, 7901, 295, 8078, 11, 51276, 51276, 550, 365, 264, 4833, 3097, 992, 11, 264, 2539, 9284, 486, 1466, 281, 3318, 257, 2445, 300, 51576, 51576, 307, 1570, 261, 46737, 13, 51680, 51680], "temperature": 0.0, "avg_logprob": -0.12461651203244231, "compression_ratio": 1.6536585365853658, "no_speech_prob": 8.013127626327332e-06}, {"id": 12, "seek": 5416, "start": 54.16, "end": 60.239999999999995, "text": " So you can continue to fit a high order polynomial or some other function with a lot of features.", "tokens": [50364, 407, 291, 393, 2354, 281, 3318, 257, 1090, 1668, 26110, 420, 512, 661, 2445, 365, 257, 688, 295, 4122, 13, 50668, 50668, 400, 498, 291, 362, 1547, 3097, 5110, 11, 309, 486, 920, 360, 1392, 13, 50900, 50900, 407, 281, 20858, 11, 264, 1230, 472, 2290, 291, 393, 764, 1970, 670, 69, 2414, 307, 281, 483, 544, 3097, 51196, 51196, 1412, 13, 51246, 51246, 823, 11, 1242, 544, 1412, 1943, 380, 1009, 364, 3614, 13, 51416, 51416, 2704, 787, 370, 867, 8078, 362, 668, 3718, 294, 341, 4914, 13, 51588, 51588, 407, 1310, 456, 445, 1943, 380, 544, 1412, 281, 312, 632, 13, 51744, 51744], "temperature": 0.0, "avg_logprob": -0.08846993312657436, "compression_ratio": 1.6171875, "no_speech_prob": 8.939511644712184e-06}, {"id": 13, "seek": 5416, "start": 60.239999999999995, "end": 64.88, "text": " And if you have enough training examples, it will still do okay.", "tokens": [50364, 407, 291, 393, 2354, 281, 3318, 257, 1090, 1668, 26110, 420, 512, 661, 2445, 365, 257, 688, 295, 4122, 13, 50668, 50668, 400, 498, 291, 362, 1547, 3097, 5110, 11, 309, 486, 920, 360, 1392, 13, 50900, 50900, 407, 281, 20858, 11, 264, 1230, 472, 2290, 291, 393, 764, 1970, 670, 69, 2414, 307, 281, 483, 544, 3097, 51196, 51196, 1412, 13, 51246, 51246, 823, 11, 1242, 544, 1412, 1943, 380, 1009, 364, 3614, 13, 51416, 51416, 2704, 787, 370, 867, 8078, 362, 668, 3718, 294, 341, 4914, 13, 51588, 51588, 407, 1310, 456, 445, 1943, 380, 544, 1412, 281, 312, 632, 13, 51744, 51744], "temperature": 0.0, "avg_logprob": -0.08846993312657436, "compression_ratio": 1.6171875, "no_speech_prob": 8.939511644712184e-06}, {"id": 14, "seek": 5416, "start": 64.88, "end": 70.8, "text": " So to summarize, the number one tool you can use against overfitting is to get more training", "tokens": [50364, 407, 291, 393, 2354, 281, 3318, 257, 1090, 1668, 26110, 420, 512, 661, 2445, 365, 257, 688, 295, 4122, 13, 50668, 50668, 400, 498, 291, 362, 1547, 3097, 5110, 11, 309, 486, 920, 360, 1392, 13, 50900, 50900, 407, 281, 20858, 11, 264, 1230, 472, 2290, 291, 393, 764, 1970, 670, 69, 2414, 307, 281, 483, 544, 3097, 51196, 51196, 1412, 13, 51246, 51246, 823, 11, 1242, 544, 1412, 1943, 380, 1009, 364, 3614, 13, 51416, 51416, 2704, 787, 370, 867, 8078, 362, 668, 3718, 294, 341, 4914, 13, 51588, 51588, 407, 1310, 456, 445, 1943, 380, 544, 1412, 281, 312, 632, 13, 51744, 51744], "temperature": 0.0, "avg_logprob": -0.08846993312657436, "compression_ratio": 1.6171875, "no_speech_prob": 8.939511644712184e-06}, {"id": 15, "seek": 5416, "start": 70.8, "end": 71.8, "text": " data.", "tokens": [50364, 407, 291, 393, 2354, 281, 3318, 257, 1090, 1668, 26110, 420, 512, 661, 2445, 365, 257, 688, 295, 4122, 13, 50668, 50668, 400, 498, 291, 362, 1547, 3097, 5110, 11, 309, 486, 920, 360, 1392, 13, 50900, 50900, 407, 281, 20858, 11, 264, 1230, 472, 2290, 291, 393, 764, 1970, 670, 69, 2414, 307, 281, 483, 544, 3097, 51196, 51196, 1412, 13, 51246, 51246, 823, 11, 1242, 544, 1412, 1943, 380, 1009, 364, 3614, 13, 51416, 51416, 2704, 787, 370, 867, 8078, 362, 668, 3718, 294, 341, 4914, 13, 51588, 51588, 407, 1310, 456, 445, 1943, 380, 544, 1412, 281, 312, 632, 13, 51744, 51744], "temperature": 0.0, "avg_logprob": -0.08846993312657436, "compression_ratio": 1.6171875, "no_speech_prob": 8.939511644712184e-06}, {"id": 16, "seek": 5416, "start": 71.8, "end": 75.19999999999999, "text": " Now, getting more data isn't always an option.", "tokens": [50364, 407, 291, 393, 2354, 281, 3318, 257, 1090, 1668, 26110, 420, 512, 661, 2445, 365, 257, 688, 295, 4122, 13, 50668, 50668, 400, 498, 291, 362, 1547, 3097, 5110, 11, 309, 486, 920, 360, 1392, 13, 50900, 50900, 407, 281, 20858, 11, 264, 1230, 472, 2290, 291, 393, 764, 1970, 670, 69, 2414, 307, 281, 483, 544, 3097, 51196, 51196, 1412, 13, 51246, 51246, 823, 11, 1242, 544, 1412, 1943, 380, 1009, 364, 3614, 13, 51416, 51416, 2704, 787, 370, 867, 8078, 362, 668, 3718, 294, 341, 4914, 13, 51588, 51588, 407, 1310, 456, 445, 1943, 380, 544, 1412, 281, 312, 632, 13, 51744, 51744], "temperature": 0.0, "avg_logprob": -0.08846993312657436, "compression_ratio": 1.6171875, "no_speech_prob": 8.939511644712184e-06}, {"id": 17, "seek": 5416, "start": 75.19999999999999, "end": 78.64, "text": " Maybe only so many houses have been sold in this location.", "tokens": [50364, 407, 291, 393, 2354, 281, 3318, 257, 1090, 1668, 26110, 420, 512, 661, 2445, 365, 257, 688, 295, 4122, 13, 50668, 50668, 400, 498, 291, 362, 1547, 3097, 5110, 11, 309, 486, 920, 360, 1392, 13, 50900, 50900, 407, 281, 20858, 11, 264, 1230, 472, 2290, 291, 393, 764, 1970, 670, 69, 2414, 307, 281, 483, 544, 3097, 51196, 51196, 1412, 13, 51246, 51246, 823, 11, 1242, 544, 1412, 1943, 380, 1009, 364, 3614, 13, 51416, 51416, 2704, 787, 370, 867, 8078, 362, 668, 3718, 294, 341, 4914, 13, 51588, 51588, 407, 1310, 456, 445, 1943, 380, 544, 1412, 281, 312, 632, 13, 51744, 51744], "temperature": 0.0, "avg_logprob": -0.08846993312657436, "compression_ratio": 1.6171875, "no_speech_prob": 8.939511644712184e-06}, {"id": 18, "seek": 5416, "start": 78.64, "end": 81.75999999999999, "text": " So maybe there just isn't more data to be had.", "tokens": [50364, 407, 291, 393, 2354, 281, 3318, 257, 1090, 1668, 26110, 420, 512, 661, 2445, 365, 257, 688, 295, 4122, 13, 50668, 50668, 400, 498, 291, 362, 1547, 3097, 5110, 11, 309, 486, 920, 360, 1392, 13, 50900, 50900, 407, 281, 20858, 11, 264, 1230, 472, 2290, 291, 393, 764, 1970, 670, 69, 2414, 307, 281, 483, 544, 3097, 51196, 51196, 1412, 13, 51246, 51246, 823, 11, 1242, 544, 1412, 1943, 380, 1009, 364, 3614, 13, 51416, 51416, 2704, 787, 370, 867, 8078, 362, 668, 3718, 294, 341, 4914, 13, 51588, 51588, 407, 1310, 456, 445, 1943, 380, 544, 1412, 281, 312, 632, 13, 51744, 51744], "temperature": 0.0, "avg_logprob": -0.08846993312657436, "compression_ratio": 1.6171875, "no_speech_prob": 8.939511644712184e-06}, {"id": 19, "seek": 8176, "start": 81.76, "end": 84.88000000000001, "text": " So when the data is available, this can work really well.", "tokens": [50364, 407, 562, 264, 1412, 307, 2435, 11, 341, 393, 589, 534, 731, 13, 50520, 50520, 316, 1150, 3614, 337, 14329, 670, 69, 2414, 307, 281, 536, 498, 291, 393, 764, 13366, 4122, 13, 50858, 50858, 682, 264, 3894, 960, 11, 527, 2316, 311, 4122, 5556, 264, 2744, 2031, 382, 731, 382, 264, 2744, 8889, 11, 51208, 51208, 300, 307, 2031, 8889, 11, 293, 2031, 36510, 293, 2031, 281, 264, 1017, 293, 370, 322, 13, 51500, 51500, 1981, 645, 257, 688, 295, 26110, 4122, 13, 51678, 51678], "temperature": 0.0, "avg_logprob": -0.14453107660466974, "compression_ratio": 1.5885167464114833, "no_speech_prob": 1.7330238506474416e-06}, {"id": 20, "seek": 8176, "start": 84.88000000000001, "end": 91.64, "text": " A second option for addressing overfitting is to see if you can use fewer features.", "tokens": [50364, 407, 562, 264, 1412, 307, 2435, 11, 341, 393, 589, 534, 731, 13, 50520, 50520, 316, 1150, 3614, 337, 14329, 670, 69, 2414, 307, 281, 536, 498, 291, 393, 764, 13366, 4122, 13, 50858, 50858, 682, 264, 3894, 960, 11, 527, 2316, 311, 4122, 5556, 264, 2744, 2031, 382, 731, 382, 264, 2744, 8889, 11, 51208, 51208, 300, 307, 2031, 8889, 11, 293, 2031, 36510, 293, 2031, 281, 264, 1017, 293, 370, 322, 13, 51500, 51500, 1981, 645, 257, 688, 295, 26110, 4122, 13, 51678, 51678], "temperature": 0.0, "avg_logprob": -0.14453107660466974, "compression_ratio": 1.5885167464114833, "no_speech_prob": 1.7330238506474416e-06}, {"id": 21, "seek": 8176, "start": 91.64, "end": 98.64, "text": " In the previous video, our model's features included the size x as well as the size squared,", "tokens": [50364, 407, 562, 264, 1412, 307, 2435, 11, 341, 393, 589, 534, 731, 13, 50520, 50520, 316, 1150, 3614, 337, 14329, 670, 69, 2414, 307, 281, 536, 498, 291, 393, 764, 13366, 4122, 13, 50858, 50858, 682, 264, 3894, 960, 11, 527, 2316, 311, 4122, 5556, 264, 2744, 2031, 382, 731, 382, 264, 2744, 8889, 11, 51208, 51208, 300, 307, 2031, 8889, 11, 293, 2031, 36510, 293, 2031, 281, 264, 1017, 293, 370, 322, 13, 51500, 51500, 1981, 645, 257, 688, 295, 26110, 4122, 13, 51678, 51678], "temperature": 0.0, "avg_logprob": -0.14453107660466974, "compression_ratio": 1.5885167464114833, "no_speech_prob": 1.7330238506474416e-06}, {"id": 22, "seek": 8176, "start": 98.64, "end": 104.48, "text": " that is x squared, and x cubed and x to the 4 and so on.", "tokens": [50364, 407, 562, 264, 1412, 307, 2435, 11, 341, 393, 589, 534, 731, 13, 50520, 50520, 316, 1150, 3614, 337, 14329, 670, 69, 2414, 307, 281, 536, 498, 291, 393, 764, 13366, 4122, 13, 50858, 50858, 682, 264, 3894, 960, 11, 527, 2316, 311, 4122, 5556, 264, 2744, 2031, 382, 731, 382, 264, 2744, 8889, 11, 51208, 51208, 300, 307, 2031, 8889, 11, 293, 2031, 36510, 293, 2031, 281, 264, 1017, 293, 370, 322, 13, 51500, 51500, 1981, 645, 257, 688, 295, 26110, 4122, 13, 51678, 51678], "temperature": 0.0, "avg_logprob": -0.14453107660466974, "compression_ratio": 1.5885167464114833, "no_speech_prob": 1.7330238506474416e-06}, {"id": 23, "seek": 8176, "start": 104.48, "end": 108.04, "text": " These were a lot of polynomial features.", "tokens": [50364, 407, 562, 264, 1412, 307, 2435, 11, 341, 393, 589, 534, 731, 13, 50520, 50520, 316, 1150, 3614, 337, 14329, 670, 69, 2414, 307, 281, 536, 498, 291, 393, 764, 13366, 4122, 13, 50858, 50858, 682, 264, 3894, 960, 11, 527, 2316, 311, 4122, 5556, 264, 2744, 2031, 382, 731, 382, 264, 2744, 8889, 11, 51208, 51208, 300, 307, 2031, 8889, 11, 293, 2031, 36510, 293, 2031, 281, 264, 1017, 293, 370, 322, 13, 51500, 51500, 1981, 645, 257, 688, 295, 26110, 4122, 13, 51678, 51678], "temperature": 0.0, "avg_logprob": -0.14453107660466974, "compression_ratio": 1.5885167464114833, "no_speech_prob": 1.7330238506474416e-06}, {"id": 24, "seek": 10804, "start": 108.04, "end": 114.16000000000001, "text": " So in that case, one way to reduce overfitting is to just not use so many of these polynomial", "tokens": [50364, 407, 294, 300, 1389, 11, 472, 636, 281, 5407, 670, 69, 2414, 307, 281, 445, 406, 764, 370, 867, 295, 613, 26110, 50670, 50670, 4122, 13, 50742, 50742, 583, 586, 718, 311, 574, 412, 257, 819, 1365, 13, 50885, 50885, 2704, 291, 362, 257, 688, 295, 819, 4122, 295, 257, 1782, 365, 597, 281, 853, 281, 6069, 1080, 51080, 51080, 3218, 11, 25532, 490, 264, 2744, 11, 1230, 295, 39955, 11, 1230, 295, 21008, 11, 264, 3205, 11, 4274, 5742, 51352, 51352, 295, 264, 7630, 11, 293, 370, 322, 293, 370, 5220, 281, 264, 4560, 281, 264, 23831, 4982, 3945, 13, 51628, 51628], "temperature": 0.0, "avg_logprob": -0.10243925367082868, "compression_ratio": 1.6454183266932272, "no_speech_prob": 1.6280326917694765e-06}, {"id": 25, "seek": 10804, "start": 114.16000000000001, "end": 115.60000000000001, "text": " features.", "tokens": [50364, 407, 294, 300, 1389, 11, 472, 636, 281, 5407, 670, 69, 2414, 307, 281, 445, 406, 764, 370, 867, 295, 613, 26110, 50670, 50670, 4122, 13, 50742, 50742, 583, 586, 718, 311, 574, 412, 257, 819, 1365, 13, 50885, 50885, 2704, 291, 362, 257, 688, 295, 819, 4122, 295, 257, 1782, 365, 597, 281, 853, 281, 6069, 1080, 51080, 51080, 3218, 11, 25532, 490, 264, 2744, 11, 1230, 295, 39955, 11, 1230, 295, 21008, 11, 264, 3205, 11, 4274, 5742, 51352, 51352, 295, 264, 7630, 11, 293, 370, 322, 293, 370, 5220, 281, 264, 4560, 281, 264, 23831, 4982, 3945, 13, 51628, 51628], "temperature": 0.0, "avg_logprob": -0.10243925367082868, "compression_ratio": 1.6454183266932272, "no_speech_prob": 1.6280326917694765e-06}, {"id": 26, "seek": 10804, "start": 115.60000000000001, "end": 118.46000000000001, "text": " But now let's look at a different example.", "tokens": [50364, 407, 294, 300, 1389, 11, 472, 636, 281, 5407, 670, 69, 2414, 307, 281, 445, 406, 764, 370, 867, 295, 613, 26110, 50670, 50670, 4122, 13, 50742, 50742, 583, 586, 718, 311, 574, 412, 257, 819, 1365, 13, 50885, 50885, 2704, 291, 362, 257, 688, 295, 819, 4122, 295, 257, 1782, 365, 597, 281, 853, 281, 6069, 1080, 51080, 51080, 3218, 11, 25532, 490, 264, 2744, 11, 1230, 295, 39955, 11, 1230, 295, 21008, 11, 264, 3205, 11, 4274, 5742, 51352, 51352, 295, 264, 7630, 11, 293, 370, 322, 293, 370, 5220, 281, 264, 4560, 281, 264, 23831, 4982, 3945, 13, 51628, 51628], "temperature": 0.0, "avg_logprob": -0.10243925367082868, "compression_ratio": 1.6454183266932272, "no_speech_prob": 1.6280326917694765e-06}, {"id": 27, "seek": 10804, "start": 118.46000000000001, "end": 122.36000000000001, "text": " Maybe you have a lot of different features of a house with which to try to predict its", "tokens": [50364, 407, 294, 300, 1389, 11, 472, 636, 281, 5407, 670, 69, 2414, 307, 281, 445, 406, 764, 370, 867, 295, 613, 26110, 50670, 50670, 4122, 13, 50742, 50742, 583, 586, 718, 311, 574, 412, 257, 819, 1365, 13, 50885, 50885, 2704, 291, 362, 257, 688, 295, 819, 4122, 295, 257, 1782, 365, 597, 281, 853, 281, 6069, 1080, 51080, 51080, 3218, 11, 25532, 490, 264, 2744, 11, 1230, 295, 39955, 11, 1230, 295, 21008, 11, 264, 3205, 11, 4274, 5742, 51352, 51352, 295, 264, 7630, 11, 293, 370, 322, 293, 370, 5220, 281, 264, 4560, 281, 264, 23831, 4982, 3945, 13, 51628, 51628], "temperature": 0.0, "avg_logprob": -0.10243925367082868, "compression_ratio": 1.6454183266932272, "no_speech_prob": 1.6280326917694765e-06}, {"id": 28, "seek": 10804, "start": 122.36000000000001, "end": 127.80000000000001, "text": " price, ranging from the size, number of bedrooms, number of floors, the age, average income", "tokens": [50364, 407, 294, 300, 1389, 11, 472, 636, 281, 5407, 670, 69, 2414, 307, 281, 445, 406, 764, 370, 867, 295, 613, 26110, 50670, 50670, 4122, 13, 50742, 50742, 583, 586, 718, 311, 574, 412, 257, 819, 1365, 13, 50885, 50885, 2704, 291, 362, 257, 688, 295, 819, 4122, 295, 257, 1782, 365, 597, 281, 853, 281, 6069, 1080, 51080, 51080, 3218, 11, 25532, 490, 264, 2744, 11, 1230, 295, 39955, 11, 1230, 295, 21008, 11, 264, 3205, 11, 4274, 5742, 51352, 51352, 295, 264, 7630, 11, 293, 370, 322, 293, 370, 5220, 281, 264, 4560, 281, 264, 23831, 4982, 3945, 13, 51628, 51628], "temperature": 0.0, "avg_logprob": -0.10243925367082868, "compression_ratio": 1.6454183266932272, "no_speech_prob": 1.6280326917694765e-06}, {"id": 29, "seek": 10804, "start": 127.80000000000001, "end": 133.32, "text": " of the neighborhood, and so on and so forth to the distance to the nearest coffee shop.", "tokens": [50364, 407, 294, 300, 1389, 11, 472, 636, 281, 5407, 670, 69, 2414, 307, 281, 445, 406, 764, 370, 867, 295, 613, 26110, 50670, 50670, 4122, 13, 50742, 50742, 583, 586, 718, 311, 574, 412, 257, 819, 1365, 13, 50885, 50885, 2704, 291, 362, 257, 688, 295, 819, 4122, 295, 257, 1782, 365, 597, 281, 853, 281, 6069, 1080, 51080, 51080, 3218, 11, 25532, 490, 264, 2744, 11, 1230, 295, 39955, 11, 1230, 295, 21008, 11, 264, 3205, 11, 4274, 5742, 51352, 51352, 295, 264, 7630, 11, 293, 370, 322, 293, 370, 5220, 281, 264, 4560, 281, 264, 23831, 4982, 3945, 13, 51628, 51628], "temperature": 0.0, "avg_logprob": -0.10243925367082868, "compression_ratio": 1.6454183266932272, "no_speech_prob": 1.6280326917694765e-06}, {"id": 30, "seek": 13332, "start": 133.32, "end": 138.76, "text": " It turns out that if you have a lot of features like these, but don't have enough training", "tokens": [50364, 467, 4523, 484, 300, 498, 291, 362, 257, 688, 295, 4122, 411, 613, 11, 457, 500, 380, 362, 1547, 3097, 50636, 50636, 1412, 11, 550, 428, 2539, 9284, 815, 611, 670, 6845, 281, 428, 3097, 992, 13, 50912, 50912, 823, 2602, 295, 1228, 439, 2319, 4122, 11, 498, 321, 645, 281, 1888, 445, 257, 25993, 295, 264, 881, 51161, 51161, 4420, 2306, 11, 1310, 2744, 11, 39955, 11, 293, 264, 3205, 295, 264, 1782, 11, 498, 291, 519, 729, 366, 264, 51558, 51558, 881, 7340, 4122, 11, 550, 1228, 445, 300, 4356, 25993, 295, 4122, 11, 291, 815, 915, 300, 51824, 51824], "temperature": 0.0, "avg_logprob": -0.09304828827197735, "compression_ratio": 1.757201646090535, "no_speech_prob": 1.3210974429966882e-05}, {"id": 31, "seek": 13332, "start": 138.76, "end": 144.28, "text": " data, then your learning algorithm may also overfit to your training set.", "tokens": [50364, 467, 4523, 484, 300, 498, 291, 362, 257, 688, 295, 4122, 411, 613, 11, 457, 500, 380, 362, 1547, 3097, 50636, 50636, 1412, 11, 550, 428, 2539, 9284, 815, 611, 670, 6845, 281, 428, 3097, 992, 13, 50912, 50912, 823, 2602, 295, 1228, 439, 2319, 4122, 11, 498, 321, 645, 281, 1888, 445, 257, 25993, 295, 264, 881, 51161, 51161, 4420, 2306, 11, 1310, 2744, 11, 39955, 11, 293, 264, 3205, 295, 264, 1782, 11, 498, 291, 519, 729, 366, 264, 51558, 51558, 881, 7340, 4122, 11, 550, 1228, 445, 300, 4356, 25993, 295, 4122, 11, 291, 815, 915, 300, 51824, 51824], "temperature": 0.0, "avg_logprob": -0.09304828827197735, "compression_ratio": 1.757201646090535, "no_speech_prob": 1.3210974429966882e-05}, {"id": 32, "seek": 13332, "start": 144.28, "end": 149.26, "text": " Now instead of using all 100 features, if we were to pick just a subset of the most", "tokens": [50364, 467, 4523, 484, 300, 498, 291, 362, 257, 688, 295, 4122, 411, 613, 11, 457, 500, 380, 362, 1547, 3097, 50636, 50636, 1412, 11, 550, 428, 2539, 9284, 815, 611, 670, 6845, 281, 428, 3097, 992, 13, 50912, 50912, 823, 2602, 295, 1228, 439, 2319, 4122, 11, 498, 321, 645, 281, 1888, 445, 257, 25993, 295, 264, 881, 51161, 51161, 4420, 2306, 11, 1310, 2744, 11, 39955, 11, 293, 264, 3205, 295, 264, 1782, 11, 498, 291, 519, 729, 366, 264, 51558, 51558, 881, 7340, 4122, 11, 550, 1228, 445, 300, 4356, 25993, 295, 4122, 11, 291, 815, 915, 300, 51824, 51824], "temperature": 0.0, "avg_logprob": -0.09304828827197735, "compression_ratio": 1.757201646090535, "no_speech_prob": 1.3210974429966882e-05}, {"id": 33, "seek": 13332, "start": 149.26, "end": 157.2, "text": " useful ones, maybe size, bedrooms, and the age of the house, if you think those are the", "tokens": [50364, 467, 4523, 484, 300, 498, 291, 362, 257, 688, 295, 4122, 411, 613, 11, 457, 500, 380, 362, 1547, 3097, 50636, 50636, 1412, 11, 550, 428, 2539, 9284, 815, 611, 670, 6845, 281, 428, 3097, 992, 13, 50912, 50912, 823, 2602, 295, 1228, 439, 2319, 4122, 11, 498, 321, 645, 281, 1888, 445, 257, 25993, 295, 264, 881, 51161, 51161, 4420, 2306, 11, 1310, 2744, 11, 39955, 11, 293, 264, 3205, 295, 264, 1782, 11, 498, 291, 519, 729, 366, 264, 51558, 51558, 881, 7340, 4122, 11, 550, 1228, 445, 300, 4356, 25993, 295, 4122, 11, 291, 815, 915, 300, 51824, 51824], "temperature": 0.0, "avg_logprob": -0.09304828827197735, "compression_ratio": 1.757201646090535, "no_speech_prob": 1.3210974429966882e-05}, {"id": 34, "seek": 13332, "start": 157.2, "end": 162.51999999999998, "text": " most relevant features, then using just that smaller subset of features, you may find that", "tokens": [50364, 467, 4523, 484, 300, 498, 291, 362, 257, 688, 295, 4122, 411, 613, 11, 457, 500, 380, 362, 1547, 3097, 50636, 50636, 1412, 11, 550, 428, 2539, 9284, 815, 611, 670, 6845, 281, 428, 3097, 992, 13, 50912, 50912, 823, 2602, 295, 1228, 439, 2319, 4122, 11, 498, 321, 645, 281, 1888, 445, 257, 25993, 295, 264, 881, 51161, 51161, 4420, 2306, 11, 1310, 2744, 11, 39955, 11, 293, 264, 3205, 295, 264, 1782, 11, 498, 291, 519, 729, 366, 264, 51558, 51558, 881, 7340, 4122, 11, 550, 1228, 445, 300, 4356, 25993, 295, 4122, 11, 291, 815, 915, 300, 51824, 51824], "temperature": 0.0, "avg_logprob": -0.09304828827197735, "compression_ratio": 1.757201646090535, "no_speech_prob": 1.3210974429966882e-05}, {"id": 35, "seek": 16252, "start": 162.52, "end": 166.72, "text": " your model no longer overfits as badly.", "tokens": [50364, 428, 2316, 572, 2854, 670, 13979, 382, 13425, 13, 50574, 50574, 12366, 6110, 264, 881, 6854, 992, 295, 4122, 281, 764, 307, 2171, 611, 1219, 4111, 9450, 13, 50882, 50882, 1485, 636, 291, 727, 360, 370, 307, 281, 764, 428, 24002, 281, 2826, 437, 291, 519, 307, 264, 1151, 992, 295, 51130, 51130, 4122, 13, 51180, 51180, 708, 311, 881, 7340, 337, 32884, 264, 3218, 13, 51326, 51326, 823, 472, 24292, 295, 4111, 9450, 307, 300, 538, 1228, 787, 257, 25993, 295, 264, 4122, 11, 51660, 51660], "temperature": 0.0, "avg_logprob": -0.08966879898242736, "compression_ratio": 1.709090909090909, "no_speech_prob": 2.7693386073224247e-06}, {"id": 36, "seek": 16252, "start": 166.72, "end": 172.88, "text": " Choosing the most appropriate set of features to use is sometimes also called feature selection.", "tokens": [50364, 428, 2316, 572, 2854, 670, 13979, 382, 13425, 13, 50574, 50574, 12366, 6110, 264, 881, 6854, 992, 295, 4122, 281, 764, 307, 2171, 611, 1219, 4111, 9450, 13, 50882, 50882, 1485, 636, 291, 727, 360, 370, 307, 281, 764, 428, 24002, 281, 2826, 437, 291, 519, 307, 264, 1151, 992, 295, 51130, 51130, 4122, 13, 51180, 51180, 708, 311, 881, 7340, 337, 32884, 264, 3218, 13, 51326, 51326, 823, 472, 24292, 295, 4111, 9450, 307, 300, 538, 1228, 787, 257, 25993, 295, 264, 4122, 11, 51660, 51660], "temperature": 0.0, "avg_logprob": -0.08966879898242736, "compression_ratio": 1.709090909090909, "no_speech_prob": 2.7693386073224247e-06}, {"id": 37, "seek": 16252, "start": 172.88, "end": 177.84, "text": " One way you could do so is to use your intuition to choose what you think is the best set of", "tokens": [50364, 428, 2316, 572, 2854, 670, 13979, 382, 13425, 13, 50574, 50574, 12366, 6110, 264, 881, 6854, 992, 295, 4122, 281, 764, 307, 2171, 611, 1219, 4111, 9450, 13, 50882, 50882, 1485, 636, 291, 727, 360, 370, 307, 281, 764, 428, 24002, 281, 2826, 437, 291, 519, 307, 264, 1151, 992, 295, 51130, 51130, 4122, 13, 51180, 51180, 708, 311, 881, 7340, 337, 32884, 264, 3218, 13, 51326, 51326, 823, 472, 24292, 295, 4111, 9450, 307, 300, 538, 1228, 787, 257, 25993, 295, 264, 4122, 11, 51660, 51660], "temperature": 0.0, "avg_logprob": -0.08966879898242736, "compression_ratio": 1.709090909090909, "no_speech_prob": 2.7693386073224247e-06}, {"id": 38, "seek": 16252, "start": 177.84, "end": 178.84, "text": " features.", "tokens": [50364, 428, 2316, 572, 2854, 670, 13979, 382, 13425, 13, 50574, 50574, 12366, 6110, 264, 881, 6854, 992, 295, 4122, 281, 764, 307, 2171, 611, 1219, 4111, 9450, 13, 50882, 50882, 1485, 636, 291, 727, 360, 370, 307, 281, 764, 428, 24002, 281, 2826, 437, 291, 519, 307, 264, 1151, 992, 295, 51130, 51130, 4122, 13, 51180, 51180, 708, 311, 881, 7340, 337, 32884, 264, 3218, 13, 51326, 51326, 823, 472, 24292, 295, 4111, 9450, 307, 300, 538, 1228, 787, 257, 25993, 295, 264, 4122, 11, 51660, 51660], "temperature": 0.0, "avg_logprob": -0.08966879898242736, "compression_ratio": 1.709090909090909, "no_speech_prob": 2.7693386073224247e-06}, {"id": 39, "seek": 16252, "start": 178.84, "end": 181.76000000000002, "text": " What's most relevant for predicting the price.", "tokens": [50364, 428, 2316, 572, 2854, 670, 13979, 382, 13425, 13, 50574, 50574, 12366, 6110, 264, 881, 6854, 992, 295, 4122, 281, 764, 307, 2171, 611, 1219, 4111, 9450, 13, 50882, 50882, 1485, 636, 291, 727, 360, 370, 307, 281, 764, 428, 24002, 281, 2826, 437, 291, 519, 307, 264, 1151, 992, 295, 51130, 51130, 4122, 13, 51180, 51180, 708, 311, 881, 7340, 337, 32884, 264, 3218, 13, 51326, 51326, 823, 472, 24292, 295, 4111, 9450, 307, 300, 538, 1228, 787, 257, 25993, 295, 264, 4122, 11, 51660, 51660], "temperature": 0.0, "avg_logprob": -0.08966879898242736, "compression_ratio": 1.709090909090909, "no_speech_prob": 2.7693386073224247e-06}, {"id": 40, "seek": 16252, "start": 181.76000000000002, "end": 188.44, "text": " Now one disadvantage of feature selection is that by using only a subset of the features,", "tokens": [50364, 428, 2316, 572, 2854, 670, 13979, 382, 13425, 13, 50574, 50574, 12366, 6110, 264, 881, 6854, 992, 295, 4122, 281, 764, 307, 2171, 611, 1219, 4111, 9450, 13, 50882, 50882, 1485, 636, 291, 727, 360, 370, 307, 281, 764, 428, 24002, 281, 2826, 437, 291, 519, 307, 264, 1151, 992, 295, 51130, 51130, 4122, 13, 51180, 51180, 708, 311, 881, 7340, 337, 32884, 264, 3218, 13, 51326, 51326, 823, 472, 24292, 295, 4111, 9450, 307, 300, 538, 1228, 787, 257, 25993, 295, 264, 4122, 11, 51660, 51660], "temperature": 0.0, "avg_logprob": -0.08966879898242736, "compression_ratio": 1.709090909090909, "no_speech_prob": 2.7693386073224247e-06}, {"id": 41, "seek": 18844, "start": 188.44, "end": 193.32, "text": " the algorithm is throwing away some of the information that you have about the houses.", "tokens": [50364, 264, 9284, 307, 10238, 1314, 512, 295, 264, 1589, 300, 291, 362, 466, 264, 8078, 13, 50608, 50608, 1171, 1365, 11, 1310, 439, 295, 613, 4122, 11, 420, 2319, 295, 552, 11, 366, 767, 4420, 337, 32884, 50882, 50882, 264, 3218, 295, 257, 1782, 13, 50962, 50962, 407, 1310, 291, 500, 380, 528, 281, 3507, 1314, 512, 295, 264, 1589, 538, 10238, 1314, 512, 295, 51178, 51178, 264, 4122, 13, 51228, 51228, 11965, 294, 1164, 732, 11, 291, 611, 536, 512, 14642, 337, 6772, 10875, 264, 881, 6854, 51564, 51564, 992, 295, 4122, 281, 764, 337, 17630, 9608, 13, 51728, 51728], "temperature": 0.0, "avg_logprob": -0.11503611259090091, "compression_ratio": 1.8697478991596639, "no_speech_prob": 2.482452146068681e-06}, {"id": 42, "seek": 18844, "start": 193.32, "end": 198.8, "text": " For example, maybe all of these features, or 100 of them, are actually useful for predicting", "tokens": [50364, 264, 9284, 307, 10238, 1314, 512, 295, 264, 1589, 300, 291, 362, 466, 264, 8078, 13, 50608, 50608, 1171, 1365, 11, 1310, 439, 295, 613, 4122, 11, 420, 2319, 295, 552, 11, 366, 767, 4420, 337, 32884, 50882, 50882, 264, 3218, 295, 257, 1782, 13, 50962, 50962, 407, 1310, 291, 500, 380, 528, 281, 3507, 1314, 512, 295, 264, 1589, 538, 10238, 1314, 512, 295, 51178, 51178, 264, 4122, 13, 51228, 51228, 11965, 294, 1164, 732, 11, 291, 611, 536, 512, 14642, 337, 6772, 10875, 264, 881, 6854, 51564, 51564, 992, 295, 4122, 281, 764, 337, 17630, 9608, 13, 51728, 51728], "temperature": 0.0, "avg_logprob": -0.11503611259090091, "compression_ratio": 1.8697478991596639, "no_speech_prob": 2.482452146068681e-06}, {"id": 43, "seek": 18844, "start": 198.8, "end": 200.4, "text": " the price of a house.", "tokens": [50364, 264, 9284, 307, 10238, 1314, 512, 295, 264, 1589, 300, 291, 362, 466, 264, 8078, 13, 50608, 50608, 1171, 1365, 11, 1310, 439, 295, 613, 4122, 11, 420, 2319, 295, 552, 11, 366, 767, 4420, 337, 32884, 50882, 50882, 264, 3218, 295, 257, 1782, 13, 50962, 50962, 407, 1310, 291, 500, 380, 528, 281, 3507, 1314, 512, 295, 264, 1589, 538, 10238, 1314, 512, 295, 51178, 51178, 264, 4122, 13, 51228, 51228, 11965, 294, 1164, 732, 11, 291, 611, 536, 512, 14642, 337, 6772, 10875, 264, 881, 6854, 51564, 51564, 992, 295, 4122, 281, 764, 337, 17630, 9608, 13, 51728, 51728], "temperature": 0.0, "avg_logprob": -0.11503611259090091, "compression_ratio": 1.8697478991596639, "no_speech_prob": 2.482452146068681e-06}, {"id": 44, "seek": 18844, "start": 200.4, "end": 204.72, "text": " So maybe you don't want to throw away some of the information by throwing away some of", "tokens": [50364, 264, 9284, 307, 10238, 1314, 512, 295, 264, 1589, 300, 291, 362, 466, 264, 8078, 13, 50608, 50608, 1171, 1365, 11, 1310, 439, 295, 613, 4122, 11, 420, 2319, 295, 552, 11, 366, 767, 4420, 337, 32884, 50882, 50882, 264, 3218, 295, 257, 1782, 13, 50962, 50962, 407, 1310, 291, 500, 380, 528, 281, 3507, 1314, 512, 295, 264, 1589, 538, 10238, 1314, 512, 295, 51178, 51178, 264, 4122, 13, 51228, 51228, 11965, 294, 1164, 732, 11, 291, 611, 536, 512, 14642, 337, 6772, 10875, 264, 881, 6854, 51564, 51564, 992, 295, 4122, 281, 764, 337, 17630, 9608, 13, 51728, 51728], "temperature": 0.0, "avg_logprob": -0.11503611259090091, "compression_ratio": 1.8697478991596639, "no_speech_prob": 2.482452146068681e-06}, {"id": 45, "seek": 18844, "start": 204.72, "end": 205.72, "text": " the features.", "tokens": [50364, 264, 9284, 307, 10238, 1314, 512, 295, 264, 1589, 300, 291, 362, 466, 264, 8078, 13, 50608, 50608, 1171, 1365, 11, 1310, 439, 295, 613, 4122, 11, 420, 2319, 295, 552, 11, 366, 767, 4420, 337, 32884, 50882, 50882, 264, 3218, 295, 257, 1782, 13, 50962, 50962, 407, 1310, 291, 500, 380, 528, 281, 3507, 1314, 512, 295, 264, 1589, 538, 10238, 1314, 512, 295, 51178, 51178, 264, 4122, 13, 51228, 51228, 11965, 294, 1164, 732, 11, 291, 611, 536, 512, 14642, 337, 6772, 10875, 264, 881, 6854, 51564, 51564, 992, 295, 4122, 281, 764, 337, 17630, 9608, 13, 51728, 51728], "temperature": 0.0, "avg_logprob": -0.11503611259090091, "compression_ratio": 1.8697478991596639, "no_speech_prob": 2.482452146068681e-06}, {"id": 46, "seek": 18844, "start": 205.72, "end": 212.44, "text": " Later in course two, you also see some algorithms for automatically choosing the most appropriate", "tokens": [50364, 264, 9284, 307, 10238, 1314, 512, 295, 264, 1589, 300, 291, 362, 466, 264, 8078, 13, 50608, 50608, 1171, 1365, 11, 1310, 439, 295, 613, 4122, 11, 420, 2319, 295, 552, 11, 366, 767, 4420, 337, 32884, 50882, 50882, 264, 3218, 295, 257, 1782, 13, 50962, 50962, 407, 1310, 291, 500, 380, 528, 281, 3507, 1314, 512, 295, 264, 1589, 538, 10238, 1314, 512, 295, 51178, 51178, 264, 4122, 13, 51228, 51228, 11965, 294, 1164, 732, 11, 291, 611, 536, 512, 14642, 337, 6772, 10875, 264, 881, 6854, 51564, 51564, 992, 295, 4122, 281, 764, 337, 17630, 9608, 13, 51728, 51728], "temperature": 0.0, "avg_logprob": -0.11503611259090091, "compression_ratio": 1.8697478991596639, "no_speech_prob": 2.482452146068681e-06}, {"id": 47, "seek": 18844, "start": 212.44, "end": 215.72, "text": " set of features to use for prediction tasks.", "tokens": [50364, 264, 9284, 307, 10238, 1314, 512, 295, 264, 1589, 300, 291, 362, 466, 264, 8078, 13, 50608, 50608, 1171, 1365, 11, 1310, 439, 295, 613, 4122, 11, 420, 2319, 295, 552, 11, 366, 767, 4420, 337, 32884, 50882, 50882, 264, 3218, 295, 257, 1782, 13, 50962, 50962, 407, 1310, 291, 500, 380, 528, 281, 3507, 1314, 512, 295, 264, 1589, 538, 10238, 1314, 512, 295, 51178, 51178, 264, 4122, 13, 51228, 51228, 11965, 294, 1164, 732, 11, 291, 611, 536, 512, 14642, 337, 6772, 10875, 264, 881, 6854, 51564, 51564, 992, 295, 4122, 281, 764, 337, 17630, 9608, 13, 51728, 51728], "temperature": 0.0, "avg_logprob": -0.11503611259090091, "compression_ratio": 1.8697478991596639, "no_speech_prob": 2.482452146068681e-06}, {"id": 48, "seek": 21572, "start": 215.72, "end": 219.76, "text": " Now this takes us to the third option for reducing overfitting.", "tokens": [50364, 823, 341, 2516, 505, 281, 264, 2636, 3614, 337, 12245, 670, 69, 2414, 13, 50566, 50566, 639, 6532, 11, 597, 321, 603, 574, 412, 294, 754, 5044, 7161, 294, 264, 958, 960, 11, 307, 1219, 50806, 50806, 3890, 2144, 13, 50938, 50938, 759, 291, 574, 412, 364, 670, 6845, 2316, 11, 510, 311, 257, 2316, 1228, 26110, 4122, 2031, 11, 2031, 8889, 11, 51302, 51302, 2031, 36510, 11, 293, 370, 322, 13, 51382, 51382, 509, 915, 300, 264, 9834, 366, 2049, 7226, 2416, 13, 51595, 51595, 823, 498, 291, 645, 281, 13819, 512, 295, 613, 4122, 11, 584, 498, 291, 645, 281, 13819, 264, 51858, 51858], "temperature": 0.0, "avg_logprob": -0.10609807791533293, "compression_ratio": 1.6613545816733069, "no_speech_prob": 3.726582008312107e-06}, {"id": 49, "seek": 21572, "start": 219.76, "end": 224.56, "text": " This technique, which we'll look at in even greater depth in the next video, is called", "tokens": [50364, 823, 341, 2516, 505, 281, 264, 2636, 3614, 337, 12245, 670, 69, 2414, 13, 50566, 50566, 639, 6532, 11, 597, 321, 603, 574, 412, 294, 754, 5044, 7161, 294, 264, 958, 960, 11, 307, 1219, 50806, 50806, 3890, 2144, 13, 50938, 50938, 759, 291, 574, 412, 364, 670, 6845, 2316, 11, 510, 311, 257, 2316, 1228, 26110, 4122, 2031, 11, 2031, 8889, 11, 51302, 51302, 2031, 36510, 11, 293, 370, 322, 13, 51382, 51382, 509, 915, 300, 264, 9834, 366, 2049, 7226, 2416, 13, 51595, 51595, 823, 498, 291, 645, 281, 13819, 512, 295, 613, 4122, 11, 584, 498, 291, 645, 281, 13819, 264, 51858, 51858], "temperature": 0.0, "avg_logprob": -0.10609807791533293, "compression_ratio": 1.6613545816733069, "no_speech_prob": 3.726582008312107e-06}, {"id": 50, "seek": 21572, "start": 224.56, "end": 227.2, "text": " regularization.", "tokens": [50364, 823, 341, 2516, 505, 281, 264, 2636, 3614, 337, 12245, 670, 69, 2414, 13, 50566, 50566, 639, 6532, 11, 597, 321, 603, 574, 412, 294, 754, 5044, 7161, 294, 264, 958, 960, 11, 307, 1219, 50806, 50806, 3890, 2144, 13, 50938, 50938, 759, 291, 574, 412, 364, 670, 6845, 2316, 11, 510, 311, 257, 2316, 1228, 26110, 4122, 2031, 11, 2031, 8889, 11, 51302, 51302, 2031, 36510, 11, 293, 370, 322, 13, 51382, 51382, 509, 915, 300, 264, 9834, 366, 2049, 7226, 2416, 13, 51595, 51595, 823, 498, 291, 645, 281, 13819, 512, 295, 613, 4122, 11, 584, 498, 291, 645, 281, 13819, 264, 51858, 51858], "temperature": 0.0, "avg_logprob": -0.10609807791533293, "compression_ratio": 1.6613545816733069, "no_speech_prob": 3.726582008312107e-06}, {"id": 51, "seek": 21572, "start": 227.2, "end": 234.48, "text": " If you look at an overfit model, here's a model using polynomial features x, x squared,", "tokens": [50364, 823, 341, 2516, 505, 281, 264, 2636, 3614, 337, 12245, 670, 69, 2414, 13, 50566, 50566, 639, 6532, 11, 597, 321, 603, 574, 412, 294, 754, 5044, 7161, 294, 264, 958, 960, 11, 307, 1219, 50806, 50806, 3890, 2144, 13, 50938, 50938, 759, 291, 574, 412, 364, 670, 6845, 2316, 11, 510, 311, 257, 2316, 1228, 26110, 4122, 2031, 11, 2031, 8889, 11, 51302, 51302, 2031, 36510, 11, 293, 370, 322, 13, 51382, 51382, 509, 915, 300, 264, 9834, 366, 2049, 7226, 2416, 13, 51595, 51595, 823, 498, 291, 645, 281, 13819, 512, 295, 613, 4122, 11, 584, 498, 291, 645, 281, 13819, 264, 51858, 51858], "temperature": 0.0, "avg_logprob": -0.10609807791533293, "compression_ratio": 1.6613545816733069, "no_speech_prob": 3.726582008312107e-06}, {"id": 52, "seek": 21572, "start": 234.48, "end": 236.07999999999998, "text": " x cubed, and so on.", "tokens": [50364, 823, 341, 2516, 505, 281, 264, 2636, 3614, 337, 12245, 670, 69, 2414, 13, 50566, 50566, 639, 6532, 11, 597, 321, 603, 574, 412, 294, 754, 5044, 7161, 294, 264, 958, 960, 11, 307, 1219, 50806, 50806, 3890, 2144, 13, 50938, 50938, 759, 291, 574, 412, 364, 670, 6845, 2316, 11, 510, 311, 257, 2316, 1228, 26110, 4122, 2031, 11, 2031, 8889, 11, 51302, 51302, 2031, 36510, 11, 293, 370, 322, 13, 51382, 51382, 509, 915, 300, 264, 9834, 366, 2049, 7226, 2416, 13, 51595, 51595, 823, 498, 291, 645, 281, 13819, 512, 295, 613, 4122, 11, 584, 498, 291, 645, 281, 13819, 264, 51858, 51858], "temperature": 0.0, "avg_logprob": -0.10609807791533293, "compression_ratio": 1.6613545816733069, "no_speech_prob": 3.726582008312107e-06}, {"id": 53, "seek": 21572, "start": 236.07999999999998, "end": 240.34, "text": " You find that the parameters are often relatively large.", "tokens": [50364, 823, 341, 2516, 505, 281, 264, 2636, 3614, 337, 12245, 670, 69, 2414, 13, 50566, 50566, 639, 6532, 11, 597, 321, 603, 574, 412, 294, 754, 5044, 7161, 294, 264, 958, 960, 11, 307, 1219, 50806, 50806, 3890, 2144, 13, 50938, 50938, 759, 291, 574, 412, 364, 670, 6845, 2316, 11, 510, 311, 257, 2316, 1228, 26110, 4122, 2031, 11, 2031, 8889, 11, 51302, 51302, 2031, 36510, 11, 293, 370, 322, 13, 51382, 51382, 509, 915, 300, 264, 9834, 366, 2049, 7226, 2416, 13, 51595, 51595, 823, 498, 291, 645, 281, 13819, 512, 295, 613, 4122, 11, 584, 498, 291, 645, 281, 13819, 264, 51858, 51858], "temperature": 0.0, "avg_logprob": -0.10609807791533293, "compression_ratio": 1.6613545816733069, "no_speech_prob": 3.726582008312107e-06}, {"id": 54, "seek": 21572, "start": 240.34, "end": 245.6, "text": " Now if you were to eliminate some of these features, say if you were to eliminate the", "tokens": [50364, 823, 341, 2516, 505, 281, 264, 2636, 3614, 337, 12245, 670, 69, 2414, 13, 50566, 50566, 639, 6532, 11, 597, 321, 603, 574, 412, 294, 754, 5044, 7161, 294, 264, 958, 960, 11, 307, 1219, 50806, 50806, 3890, 2144, 13, 50938, 50938, 759, 291, 574, 412, 364, 670, 6845, 2316, 11, 510, 311, 257, 2316, 1228, 26110, 4122, 2031, 11, 2031, 8889, 11, 51302, 51302, 2031, 36510, 11, 293, 370, 322, 13, 51382, 51382, 509, 915, 300, 264, 9834, 366, 2049, 7226, 2416, 13, 51595, 51595, 823, 498, 291, 645, 281, 13819, 512, 295, 613, 4122, 11, 584, 498, 291, 645, 281, 13819, 264, 51858, 51858], "temperature": 0.0, "avg_logprob": -0.10609807791533293, "compression_ratio": 1.6613545816733069, "no_speech_prob": 3.726582008312107e-06}, {"id": 55, "seek": 24560, "start": 245.6, "end": 253.12, "text": " feature x4, that corresponds to setting this parameter to zero.", "tokens": [50364, 4111, 2031, 19, 11, 300, 23249, 281, 3287, 341, 13075, 281, 4018, 13, 50740, 50740, 407, 3287, 257, 13075, 281, 4018, 307, 10344, 281, 31203, 257, 4111, 11, 597, 307, 437, 321, 51006, 51006, 1866, 322, 264, 3894, 4137, 13, 51137, 51137, 467, 4523, 484, 300, 3890, 2144, 307, 257, 636, 281, 544, 13073, 5407, 264, 11606, 295, 512, 51414, 51414, 295, 264, 4122, 1553, 884, 746, 382, 14897, 382, 31203, 309, 35189, 13, 51705, 51705], "temperature": 0.0, "avg_logprob": -0.10261711707481971, "compression_ratio": 1.661764705882353, "no_speech_prob": 2.1567955172940856e-06}, {"id": 56, "seek": 24560, "start": 253.12, "end": 258.44, "text": " So setting a parameter to zero is equivalent to eliminating a feature, which is what we", "tokens": [50364, 4111, 2031, 19, 11, 300, 23249, 281, 3287, 341, 13075, 281, 4018, 13, 50740, 50740, 407, 3287, 257, 13075, 281, 4018, 307, 10344, 281, 31203, 257, 4111, 11, 597, 307, 437, 321, 51006, 51006, 1866, 322, 264, 3894, 4137, 13, 51137, 51137, 467, 4523, 484, 300, 3890, 2144, 307, 257, 636, 281, 544, 13073, 5407, 264, 11606, 295, 512, 51414, 51414, 295, 264, 4122, 1553, 884, 746, 382, 14897, 382, 31203, 309, 35189, 13, 51705, 51705], "temperature": 0.0, "avg_logprob": -0.10261711707481971, "compression_ratio": 1.661764705882353, "no_speech_prob": 2.1567955172940856e-06}, {"id": 57, "seek": 24560, "start": 258.44, "end": 261.06, "text": " saw on the previous slide.", "tokens": [50364, 4111, 2031, 19, 11, 300, 23249, 281, 3287, 341, 13075, 281, 4018, 13, 50740, 50740, 407, 3287, 257, 13075, 281, 4018, 307, 10344, 281, 31203, 257, 4111, 11, 597, 307, 437, 321, 51006, 51006, 1866, 322, 264, 3894, 4137, 13, 51137, 51137, 467, 4523, 484, 300, 3890, 2144, 307, 257, 636, 281, 544, 13073, 5407, 264, 11606, 295, 512, 51414, 51414, 295, 264, 4122, 1553, 884, 746, 382, 14897, 382, 31203, 309, 35189, 13, 51705, 51705], "temperature": 0.0, "avg_logprob": -0.10261711707481971, "compression_ratio": 1.661764705882353, "no_speech_prob": 2.1567955172940856e-06}, {"id": 58, "seek": 24560, "start": 261.06, "end": 266.6, "text": " It turns out that regularization is a way to more gently reduce the impacts of some", "tokens": [50364, 4111, 2031, 19, 11, 300, 23249, 281, 3287, 341, 13075, 281, 4018, 13, 50740, 50740, 407, 3287, 257, 13075, 281, 4018, 307, 10344, 281, 31203, 257, 4111, 11, 597, 307, 437, 321, 51006, 51006, 1866, 322, 264, 3894, 4137, 13, 51137, 51137, 467, 4523, 484, 300, 3890, 2144, 307, 257, 636, 281, 544, 13073, 5407, 264, 11606, 295, 512, 51414, 51414, 295, 264, 4122, 1553, 884, 746, 382, 14897, 382, 31203, 309, 35189, 13, 51705, 51705], "temperature": 0.0, "avg_logprob": -0.10261711707481971, "compression_ratio": 1.661764705882353, "no_speech_prob": 2.1567955172940856e-06}, {"id": 59, "seek": 24560, "start": 266.6, "end": 272.42, "text": " of the features without doing something as harsh as eliminating it outright.", "tokens": [50364, 4111, 2031, 19, 11, 300, 23249, 281, 3287, 341, 13075, 281, 4018, 13, 50740, 50740, 407, 3287, 257, 13075, 281, 4018, 307, 10344, 281, 31203, 257, 4111, 11, 597, 307, 437, 321, 51006, 51006, 1866, 322, 264, 3894, 4137, 13, 51137, 51137, 467, 4523, 484, 300, 3890, 2144, 307, 257, 636, 281, 544, 13073, 5407, 264, 11606, 295, 512, 51414, 51414, 295, 264, 4122, 1553, 884, 746, 382, 14897, 382, 31203, 309, 35189, 13, 51705, 51705], "temperature": 0.0, "avg_logprob": -0.10261711707481971, "compression_ratio": 1.661764705882353, "no_speech_prob": 2.1567955172940856e-06}, {"id": 60, "seek": 27242, "start": 272.42, "end": 277.40000000000003, "text": " What regularization does is encourage the learning algorithm to shrink the values of", "tokens": [50364, 708, 3890, 2144, 775, 307, 5373, 264, 2539, 9284, 281, 23060, 264, 4190, 295, 50613, 50613, 264, 9834, 1553, 4725, 19960, 300, 264, 13075, 307, 992, 281, 2293, 4018, 13, 50947, 50947, 400, 309, 4523, 484, 300, 754, 498, 291, 3318, 257, 2946, 1668, 26110, 411, 341, 11, 370, 938, 382, 291, 51219, 51219, 393, 483, 264, 9284, 281, 764, 4356, 13075, 4190, 11, 261, 16, 11, 261, 17, 11, 261, 18, 11, 261, 19, 11, 291, 917, 493, 365, 257, 51553, 51553, 7605, 300, 5314, 493, 15669, 264, 3097, 1412, 709, 1101, 13, 51789, 51789], "temperature": 0.0, "avg_logprob": -0.07957104760773327, "compression_ratio": 1.6693877551020408, "no_speech_prob": 2.8129561542300507e-06}, {"id": 61, "seek": 27242, "start": 277.40000000000003, "end": 284.08000000000004, "text": " the parameters without necessarily demanding that the parameter is set to exactly zero.", "tokens": [50364, 708, 3890, 2144, 775, 307, 5373, 264, 2539, 9284, 281, 23060, 264, 4190, 295, 50613, 50613, 264, 9834, 1553, 4725, 19960, 300, 264, 13075, 307, 992, 281, 2293, 4018, 13, 50947, 50947, 400, 309, 4523, 484, 300, 754, 498, 291, 3318, 257, 2946, 1668, 26110, 411, 341, 11, 370, 938, 382, 291, 51219, 51219, 393, 483, 264, 9284, 281, 764, 4356, 13075, 4190, 11, 261, 16, 11, 261, 17, 11, 261, 18, 11, 261, 19, 11, 291, 917, 493, 365, 257, 51553, 51553, 7605, 300, 5314, 493, 15669, 264, 3097, 1412, 709, 1101, 13, 51789, 51789], "temperature": 0.0, "avg_logprob": -0.07957104760773327, "compression_ratio": 1.6693877551020408, "no_speech_prob": 2.8129561542300507e-06}, {"id": 62, "seek": 27242, "start": 284.08000000000004, "end": 289.52000000000004, "text": " And it turns out that even if you fit a higher order polynomial like this, so long as you", "tokens": [50364, 708, 3890, 2144, 775, 307, 5373, 264, 2539, 9284, 281, 23060, 264, 4190, 295, 50613, 50613, 264, 9834, 1553, 4725, 19960, 300, 264, 13075, 307, 992, 281, 2293, 4018, 13, 50947, 50947, 400, 309, 4523, 484, 300, 754, 498, 291, 3318, 257, 2946, 1668, 26110, 411, 341, 11, 370, 938, 382, 291, 51219, 51219, 393, 483, 264, 9284, 281, 764, 4356, 13075, 4190, 11, 261, 16, 11, 261, 17, 11, 261, 18, 11, 261, 19, 11, 291, 917, 493, 365, 257, 51553, 51553, 7605, 300, 5314, 493, 15669, 264, 3097, 1412, 709, 1101, 13, 51789, 51789], "temperature": 0.0, "avg_logprob": -0.07957104760773327, "compression_ratio": 1.6693877551020408, "no_speech_prob": 2.8129561542300507e-06}, {"id": 63, "seek": 27242, "start": 289.52000000000004, "end": 296.20000000000005, "text": " can get the algorithm to use smaller parameter values, w1, w2, w3, w4, you end up with a", "tokens": [50364, 708, 3890, 2144, 775, 307, 5373, 264, 2539, 9284, 281, 23060, 264, 4190, 295, 50613, 50613, 264, 9834, 1553, 4725, 19960, 300, 264, 13075, 307, 992, 281, 2293, 4018, 13, 50947, 50947, 400, 309, 4523, 484, 300, 754, 498, 291, 3318, 257, 2946, 1668, 26110, 411, 341, 11, 370, 938, 382, 291, 51219, 51219, 393, 483, 264, 9284, 281, 764, 4356, 13075, 4190, 11, 261, 16, 11, 261, 17, 11, 261, 18, 11, 261, 19, 11, 291, 917, 493, 365, 257, 51553, 51553, 7605, 300, 5314, 493, 15669, 264, 3097, 1412, 709, 1101, 13, 51789, 51789], "temperature": 0.0, "avg_logprob": -0.07957104760773327, "compression_ratio": 1.6693877551020408, "no_speech_prob": 2.8129561542300507e-06}, {"id": 64, "seek": 27242, "start": 296.20000000000005, "end": 300.92, "text": " curve that ends up fitting the training data much better.", "tokens": [50364, 708, 3890, 2144, 775, 307, 5373, 264, 2539, 9284, 281, 23060, 264, 4190, 295, 50613, 50613, 264, 9834, 1553, 4725, 19960, 300, 264, 13075, 307, 992, 281, 2293, 4018, 13, 50947, 50947, 400, 309, 4523, 484, 300, 754, 498, 291, 3318, 257, 2946, 1668, 26110, 411, 341, 11, 370, 938, 382, 291, 51219, 51219, 393, 483, 264, 9284, 281, 764, 4356, 13075, 4190, 11, 261, 16, 11, 261, 17, 11, 261, 18, 11, 261, 19, 11, 291, 917, 493, 365, 257, 51553, 51553, 7605, 300, 5314, 493, 15669, 264, 3097, 1412, 709, 1101, 13, 51789, 51789], "temperature": 0.0, "avg_logprob": -0.07957104760773327, "compression_ratio": 1.6693877551020408, "no_speech_prob": 2.8129561542300507e-06}, {"id": 65, "seek": 30092, "start": 300.92, "end": 306.40000000000003, "text": " So what regularization does is it lets you keep all of your features, but it just prevents", "tokens": [50364, 407, 437, 3890, 2144, 775, 307, 309, 6653, 291, 1066, 439, 295, 428, 4122, 11, 457, 309, 445, 22367, 50638, 50638, 264, 4122, 490, 1419, 364, 24324, 2416, 1802, 11, 597, 307, 437, 2171, 393, 3082, 670, 69, 2414, 13, 51046, 51046, 3146, 264, 636, 11, 538, 10286, 11, 321, 5646, 445, 5407, 264, 2744, 295, 264, 261, 73, 9834, 11, 300, 51378, 51378, 307, 261, 16, 807, 45368, 13, 51492, 51492, 467, 733, 295, 1177, 380, 652, 257, 2603, 2649, 1968, 291, 3890, 1125, 264, 13075, 272, 382, 51728, 51728, 731, 13, 51778, 51778], "temperature": 0.0, "avg_logprob": -0.10297039857844717, "compression_ratio": 1.6008403361344539, "no_speech_prob": 2.443964604026405e-06}, {"id": 66, "seek": 30092, "start": 306.40000000000003, "end": 314.56, "text": " the features from having an overly large effect, which is what sometimes can cause overfitting.", "tokens": [50364, 407, 437, 3890, 2144, 775, 307, 309, 6653, 291, 1066, 439, 295, 428, 4122, 11, 457, 309, 445, 22367, 50638, 50638, 264, 4122, 490, 1419, 364, 24324, 2416, 1802, 11, 597, 307, 437, 2171, 393, 3082, 670, 69, 2414, 13, 51046, 51046, 3146, 264, 636, 11, 538, 10286, 11, 321, 5646, 445, 5407, 264, 2744, 295, 264, 261, 73, 9834, 11, 300, 51378, 51378, 307, 261, 16, 807, 45368, 13, 51492, 51492, 467, 733, 295, 1177, 380, 652, 257, 2603, 2649, 1968, 291, 3890, 1125, 264, 13075, 272, 382, 51728, 51728, 731, 13, 51778, 51778], "temperature": 0.0, "avg_logprob": -0.10297039857844717, "compression_ratio": 1.6008403361344539, "no_speech_prob": 2.443964604026405e-06}, {"id": 67, "seek": 30092, "start": 314.56, "end": 321.20000000000005, "text": " By the way, by convention, we normally just reduce the size of the wj parameters, that", "tokens": [50364, 407, 437, 3890, 2144, 775, 307, 309, 6653, 291, 1066, 439, 295, 428, 4122, 11, 457, 309, 445, 22367, 50638, 50638, 264, 4122, 490, 1419, 364, 24324, 2416, 1802, 11, 597, 307, 437, 2171, 393, 3082, 670, 69, 2414, 13, 51046, 51046, 3146, 264, 636, 11, 538, 10286, 11, 321, 5646, 445, 5407, 264, 2744, 295, 264, 261, 73, 9834, 11, 300, 51378, 51378, 307, 261, 16, 807, 45368, 13, 51492, 51492, 467, 733, 295, 1177, 380, 652, 257, 2603, 2649, 1968, 291, 3890, 1125, 264, 13075, 272, 382, 51728, 51728, 731, 13, 51778, 51778], "temperature": 0.0, "avg_logprob": -0.10297039857844717, "compression_ratio": 1.6008403361344539, "no_speech_prob": 2.443964604026405e-06}, {"id": 68, "seek": 30092, "start": 321.20000000000005, "end": 323.48, "text": " is w1 through wn.", "tokens": [50364, 407, 437, 3890, 2144, 775, 307, 309, 6653, 291, 1066, 439, 295, 428, 4122, 11, 457, 309, 445, 22367, 50638, 50638, 264, 4122, 490, 1419, 364, 24324, 2416, 1802, 11, 597, 307, 437, 2171, 393, 3082, 670, 69, 2414, 13, 51046, 51046, 3146, 264, 636, 11, 538, 10286, 11, 321, 5646, 445, 5407, 264, 2744, 295, 264, 261, 73, 9834, 11, 300, 51378, 51378, 307, 261, 16, 807, 45368, 13, 51492, 51492, 467, 733, 295, 1177, 380, 652, 257, 2603, 2649, 1968, 291, 3890, 1125, 264, 13075, 272, 382, 51728, 51728, 731, 13, 51778, 51778], "temperature": 0.0, "avg_logprob": -0.10297039857844717, "compression_ratio": 1.6008403361344539, "no_speech_prob": 2.443964604026405e-06}, {"id": 69, "seek": 30092, "start": 323.48, "end": 328.20000000000005, "text": " It kind of doesn't make a huge difference whether you regularize the parameter b as", "tokens": [50364, 407, 437, 3890, 2144, 775, 307, 309, 6653, 291, 1066, 439, 295, 428, 4122, 11, 457, 309, 445, 22367, 50638, 50638, 264, 4122, 490, 1419, 364, 24324, 2416, 1802, 11, 597, 307, 437, 2171, 393, 3082, 670, 69, 2414, 13, 51046, 51046, 3146, 264, 636, 11, 538, 10286, 11, 321, 5646, 445, 5407, 264, 2744, 295, 264, 261, 73, 9834, 11, 300, 51378, 51378, 307, 261, 16, 807, 45368, 13, 51492, 51492, 467, 733, 295, 1177, 380, 652, 257, 2603, 2649, 1968, 291, 3890, 1125, 264, 13075, 272, 382, 51728, 51728, 731, 13, 51778, 51778], "temperature": 0.0, "avg_logprob": -0.10297039857844717, "compression_ratio": 1.6008403361344539, "no_speech_prob": 2.443964604026405e-06}, {"id": 70, "seek": 30092, "start": 328.20000000000005, "end": 329.20000000000005, "text": " well.", "tokens": [50364, 407, 437, 3890, 2144, 775, 307, 309, 6653, 291, 1066, 439, 295, 428, 4122, 11, 457, 309, 445, 22367, 50638, 50638, 264, 4122, 490, 1419, 364, 24324, 2416, 1802, 11, 597, 307, 437, 2171, 393, 3082, 670, 69, 2414, 13, 51046, 51046, 3146, 264, 636, 11, 538, 10286, 11, 321, 5646, 445, 5407, 264, 2744, 295, 264, 261, 73, 9834, 11, 300, 51378, 51378, 307, 261, 16, 807, 45368, 13, 51492, 51492, 467, 733, 295, 1177, 380, 652, 257, 2603, 2649, 1968, 291, 3890, 1125, 264, 13075, 272, 382, 51728, 51728, 731, 13, 51778, 51778], "temperature": 0.0, "avg_logprob": -0.10297039857844717, "compression_ratio": 1.6008403361344539, "no_speech_prob": 2.443964604026405e-06}, {"id": 71, "seek": 32920, "start": 329.2, "end": 331.59999999999997, "text": " You could do so if you want or not if you don't.", "tokens": [50364, 509, 727, 360, 370, 498, 291, 528, 420, 406, 498, 291, 500, 380, 13, 50484, 50484, 286, 2673, 500, 380, 293, 309, 311, 445, 2489, 281, 3890, 1125, 261, 16, 11, 261, 17, 439, 264, 636, 281, 45368, 11, 457, 406, 534, 5373, 50888, 50888, 272, 281, 1813, 4356, 13, 50994, 50994, 682, 3124, 11, 309, 820, 652, 588, 707, 2649, 1968, 291, 611, 3890, 1125, 272, 420, 406, 13, 51300, 51300, 407, 281, 20928, 11, 613, 366, 264, 1045, 2098, 291, 1866, 294, 341, 960, 337, 14329, 670, 69, 2414, 13, 51636, 51636, 1485, 11, 2500, 544, 1412, 13, 51770, 51770], "temperature": 0.0, "avg_logprob": -0.1511691717001108, "compression_ratio": 1.5811965811965811, "no_speech_prob": 9.66579591477057e-06}, {"id": 72, "seek": 32920, "start": 331.59999999999997, "end": 339.68, "text": " I usually don't and it's just fine to regularize w1, w2 all the way to wn, but not really encourage", "tokens": [50364, 509, 727, 360, 370, 498, 291, 528, 420, 406, 498, 291, 500, 380, 13, 50484, 50484, 286, 2673, 500, 380, 293, 309, 311, 445, 2489, 281, 3890, 1125, 261, 16, 11, 261, 17, 439, 264, 636, 281, 45368, 11, 457, 406, 534, 5373, 50888, 50888, 272, 281, 1813, 4356, 13, 50994, 50994, 682, 3124, 11, 309, 820, 652, 588, 707, 2649, 1968, 291, 611, 3890, 1125, 272, 420, 406, 13, 51300, 51300, 407, 281, 20928, 11, 613, 366, 264, 1045, 2098, 291, 1866, 294, 341, 960, 337, 14329, 670, 69, 2414, 13, 51636, 51636, 1485, 11, 2500, 544, 1412, 13, 51770, 51770], "temperature": 0.0, "avg_logprob": -0.1511691717001108, "compression_ratio": 1.5811965811965811, "no_speech_prob": 9.66579591477057e-06}, {"id": 73, "seek": 32920, "start": 339.68, "end": 341.8, "text": " b to become smaller.", "tokens": [50364, 509, 727, 360, 370, 498, 291, 528, 420, 406, 498, 291, 500, 380, 13, 50484, 50484, 286, 2673, 500, 380, 293, 309, 311, 445, 2489, 281, 3890, 1125, 261, 16, 11, 261, 17, 439, 264, 636, 281, 45368, 11, 457, 406, 534, 5373, 50888, 50888, 272, 281, 1813, 4356, 13, 50994, 50994, 682, 3124, 11, 309, 820, 652, 588, 707, 2649, 1968, 291, 611, 3890, 1125, 272, 420, 406, 13, 51300, 51300, 407, 281, 20928, 11, 613, 366, 264, 1045, 2098, 291, 1866, 294, 341, 960, 337, 14329, 670, 69, 2414, 13, 51636, 51636, 1485, 11, 2500, 544, 1412, 13, 51770, 51770], "temperature": 0.0, "avg_logprob": -0.1511691717001108, "compression_ratio": 1.5811965811965811, "no_speech_prob": 9.66579591477057e-06}, {"id": 74, "seek": 32920, "start": 341.8, "end": 347.91999999999996, "text": " In practice, it should make very little difference whether you also regularize b or not.", "tokens": [50364, 509, 727, 360, 370, 498, 291, 528, 420, 406, 498, 291, 500, 380, 13, 50484, 50484, 286, 2673, 500, 380, 293, 309, 311, 445, 2489, 281, 3890, 1125, 261, 16, 11, 261, 17, 439, 264, 636, 281, 45368, 11, 457, 406, 534, 5373, 50888, 50888, 272, 281, 1813, 4356, 13, 50994, 50994, 682, 3124, 11, 309, 820, 652, 588, 707, 2649, 1968, 291, 611, 3890, 1125, 272, 420, 406, 13, 51300, 51300, 407, 281, 20928, 11, 613, 366, 264, 1045, 2098, 291, 1866, 294, 341, 960, 337, 14329, 670, 69, 2414, 13, 51636, 51636, 1485, 11, 2500, 544, 1412, 13, 51770, 51770], "temperature": 0.0, "avg_logprob": -0.1511691717001108, "compression_ratio": 1.5811965811965811, "no_speech_prob": 9.66579591477057e-06}, {"id": 75, "seek": 32920, "start": 347.91999999999996, "end": 354.64, "text": " So to recap, these are the three ways you saw in this video for addressing overfitting.", "tokens": [50364, 509, 727, 360, 370, 498, 291, 528, 420, 406, 498, 291, 500, 380, 13, 50484, 50484, 286, 2673, 500, 380, 293, 309, 311, 445, 2489, 281, 3890, 1125, 261, 16, 11, 261, 17, 439, 264, 636, 281, 45368, 11, 457, 406, 534, 5373, 50888, 50888, 272, 281, 1813, 4356, 13, 50994, 50994, 682, 3124, 11, 309, 820, 652, 588, 707, 2649, 1968, 291, 611, 3890, 1125, 272, 420, 406, 13, 51300, 51300, 407, 281, 20928, 11, 613, 366, 264, 1045, 2098, 291, 1866, 294, 341, 960, 337, 14329, 670, 69, 2414, 13, 51636, 51636, 1485, 11, 2500, 544, 1412, 13, 51770, 51770], "temperature": 0.0, "avg_logprob": -0.1511691717001108, "compression_ratio": 1.5811965811965811, "no_speech_prob": 9.66579591477057e-06}, {"id": 76, "seek": 32920, "start": 354.64, "end": 357.32, "text": " One, collect more data.", "tokens": [50364, 509, 727, 360, 370, 498, 291, 528, 420, 406, 498, 291, 500, 380, 13, 50484, 50484, 286, 2673, 500, 380, 293, 309, 311, 445, 2489, 281, 3890, 1125, 261, 16, 11, 261, 17, 439, 264, 636, 281, 45368, 11, 457, 406, 534, 5373, 50888, 50888, 272, 281, 1813, 4356, 13, 50994, 50994, 682, 3124, 11, 309, 820, 652, 588, 707, 2649, 1968, 291, 611, 3890, 1125, 272, 420, 406, 13, 51300, 51300, 407, 281, 20928, 11, 613, 366, 264, 1045, 2098, 291, 1866, 294, 341, 960, 337, 14329, 670, 69, 2414, 13, 51636, 51636, 1485, 11, 2500, 544, 1412, 13, 51770, 51770], "temperature": 0.0, "avg_logprob": -0.1511691717001108, "compression_ratio": 1.5811965811965811, "no_speech_prob": 9.66579591477057e-06}, {"id": 77, "seek": 35732, "start": 357.32, "end": 362.62, "text": " If you can get more data, this can really help reduce overfitting.", "tokens": [50364, 759, 291, 393, 483, 544, 1412, 11, 341, 393, 534, 854, 5407, 670, 69, 2414, 13, 50629, 50629, 4803, 300, 311, 406, 1944, 11, 294, 597, 1389, 512, 295, 264, 3956, 366, 11, 732, 11, 853, 18182, 50934, 50934, 293, 1228, 787, 257, 25993, 295, 264, 4122, 13, 51110, 51110, 509, 1466, 544, 466, 4111, 9450, 294, 1164, 732, 13, 51364, 51364, 6244, 576, 312, 281, 5407, 264, 2744, 295, 264, 9834, 1228, 3890, 2144, 13, 51688, 51688, 639, 486, 312, 264, 3983, 295, 264, 958, 960, 382, 731, 13, 51858, 51858], "temperature": 0.0, "avg_logprob": -0.1362890994295161, "compression_ratio": 1.6206896551724137, "no_speech_prob": 6.4389600993308704e-06}, {"id": 78, "seek": 35732, "start": 362.62, "end": 368.71999999999997, "text": " Sometimes that's not possible, in which case some of the options are, two, try selecting", "tokens": [50364, 759, 291, 393, 483, 544, 1412, 11, 341, 393, 534, 854, 5407, 670, 69, 2414, 13, 50629, 50629, 4803, 300, 311, 406, 1944, 11, 294, 597, 1389, 512, 295, 264, 3956, 366, 11, 732, 11, 853, 18182, 50934, 50934, 293, 1228, 787, 257, 25993, 295, 264, 4122, 13, 51110, 51110, 509, 1466, 544, 466, 4111, 9450, 294, 1164, 732, 13, 51364, 51364, 6244, 576, 312, 281, 5407, 264, 2744, 295, 264, 9834, 1228, 3890, 2144, 13, 51688, 51688, 639, 486, 312, 264, 3983, 295, 264, 958, 960, 382, 731, 13, 51858, 51858], "temperature": 0.0, "avg_logprob": -0.1362890994295161, "compression_ratio": 1.6206896551724137, "no_speech_prob": 6.4389600993308704e-06}, {"id": 79, "seek": 35732, "start": 368.71999999999997, "end": 372.24, "text": " and using only a subset of the features.", "tokens": [50364, 759, 291, 393, 483, 544, 1412, 11, 341, 393, 534, 854, 5407, 670, 69, 2414, 13, 50629, 50629, 4803, 300, 311, 406, 1944, 11, 294, 597, 1389, 512, 295, 264, 3956, 366, 11, 732, 11, 853, 18182, 50934, 50934, 293, 1228, 787, 257, 25993, 295, 264, 4122, 13, 51110, 51110, 509, 1466, 544, 466, 4111, 9450, 294, 1164, 732, 13, 51364, 51364, 6244, 576, 312, 281, 5407, 264, 2744, 295, 264, 9834, 1228, 3890, 2144, 13, 51688, 51688, 639, 486, 312, 264, 3983, 295, 264, 958, 960, 382, 731, 13, 51858, 51858], "temperature": 0.0, "avg_logprob": -0.1362890994295161, "compression_ratio": 1.6206896551724137, "no_speech_prob": 6.4389600993308704e-06}, {"id": 80, "seek": 35732, "start": 372.24, "end": 377.32, "text": " You learn more about feature selection in course two.", "tokens": [50364, 759, 291, 393, 483, 544, 1412, 11, 341, 393, 534, 854, 5407, 670, 69, 2414, 13, 50629, 50629, 4803, 300, 311, 406, 1944, 11, 294, 597, 1389, 512, 295, 264, 3956, 366, 11, 732, 11, 853, 18182, 50934, 50934, 293, 1228, 787, 257, 25993, 295, 264, 4122, 13, 51110, 51110, 509, 1466, 544, 466, 4111, 9450, 294, 1164, 732, 13, 51364, 51364, 6244, 576, 312, 281, 5407, 264, 2744, 295, 264, 9834, 1228, 3890, 2144, 13, 51688, 51688, 639, 486, 312, 264, 3983, 295, 264, 958, 960, 382, 731, 13, 51858, 51858], "temperature": 0.0, "avg_logprob": -0.1362890994295161, "compression_ratio": 1.6206896551724137, "no_speech_prob": 6.4389600993308704e-06}, {"id": 81, "seek": 35732, "start": 377.32, "end": 383.8, "text": " Three would be to reduce the size of the parameters using regularization.", "tokens": [50364, 759, 291, 393, 483, 544, 1412, 11, 341, 393, 534, 854, 5407, 670, 69, 2414, 13, 50629, 50629, 4803, 300, 311, 406, 1944, 11, 294, 597, 1389, 512, 295, 264, 3956, 366, 11, 732, 11, 853, 18182, 50934, 50934, 293, 1228, 787, 257, 25993, 295, 264, 4122, 13, 51110, 51110, 509, 1466, 544, 466, 4111, 9450, 294, 1164, 732, 13, 51364, 51364, 6244, 576, 312, 281, 5407, 264, 2744, 295, 264, 9834, 1228, 3890, 2144, 13, 51688, 51688, 639, 486, 312, 264, 3983, 295, 264, 958, 960, 382, 731, 13, 51858, 51858], "temperature": 0.0, "avg_logprob": -0.1362890994295161, "compression_ratio": 1.6206896551724137, "no_speech_prob": 6.4389600993308704e-06}, {"id": 82, "seek": 35732, "start": 383.8, "end": 387.2, "text": " This will be the subject of the next video as well.", "tokens": [50364, 759, 291, 393, 483, 544, 1412, 11, 341, 393, 534, 854, 5407, 670, 69, 2414, 13, 50629, 50629, 4803, 300, 311, 406, 1944, 11, 294, 597, 1389, 512, 295, 264, 3956, 366, 11, 732, 11, 853, 18182, 50934, 50934, 293, 1228, 787, 257, 25993, 295, 264, 4122, 13, 51110, 51110, 509, 1466, 544, 466, 4111, 9450, 294, 1164, 732, 13, 51364, 51364, 6244, 576, 312, 281, 5407, 264, 2744, 295, 264, 9834, 1228, 3890, 2144, 13, 51688, 51688, 639, 486, 312, 264, 3983, 295, 264, 958, 960, 382, 731, 13, 51858, 51858], "temperature": 0.0, "avg_logprob": -0.1362890994295161, "compression_ratio": 1.6206896551724137, "no_speech_prob": 6.4389600993308704e-06}, {"id": 83, "seek": 38720, "start": 387.2, "end": 390.0, "text": " As for myself, I use regularization all the time.", "tokens": [50364, 1018, 337, 2059, 11, 286, 764, 3890, 2144, 439, 264, 565, 13, 50504, 50504, 407, 341, 307, 257, 588, 4420, 6532, 337, 3097, 2539, 14642, 11, 3009, 18161, 9590, 50756, 50756, 4682, 11, 597, 291, 536, 1780, 294, 264, 2121, 2144, 382, 731, 13, 50952, 50952, 286, 1454, 291, 611, 1520, 484, 264, 17312, 2715, 322, 670, 69, 2414, 13, 51224, 51224, 682, 264, 2715, 11, 291, 486, 536, 819, 5110, 295, 670, 69, 2414, 293, 4369, 729, 5110, 538, 51515, 51515, 9697, 322, 3956, 294, 264, 28609, 13, 51668, 51668], "temperature": 0.0, "avg_logprob": -0.12392427588021883, "compression_ratio": 1.6317991631799162, "no_speech_prob": 6.338996172416955e-06}, {"id": 84, "seek": 38720, "start": 390.0, "end": 395.03999999999996, "text": " So this is a very useful technique for training learning algorithms, including neural networks", "tokens": [50364, 1018, 337, 2059, 11, 286, 764, 3890, 2144, 439, 264, 565, 13, 50504, 50504, 407, 341, 307, 257, 588, 4420, 6532, 337, 3097, 2539, 14642, 11, 3009, 18161, 9590, 50756, 50756, 4682, 11, 597, 291, 536, 1780, 294, 264, 2121, 2144, 382, 731, 13, 50952, 50952, 286, 1454, 291, 611, 1520, 484, 264, 17312, 2715, 322, 670, 69, 2414, 13, 51224, 51224, 682, 264, 2715, 11, 291, 486, 536, 819, 5110, 295, 670, 69, 2414, 293, 4369, 729, 5110, 538, 51515, 51515, 9697, 322, 3956, 294, 264, 28609, 13, 51668, 51668], "temperature": 0.0, "avg_logprob": -0.12392427588021883, "compression_ratio": 1.6317991631799162, "no_speech_prob": 6.338996172416955e-06}, {"id": 85, "seek": 38720, "start": 395.03999999999996, "end": 398.96, "text": " specifically, which you see later in the specialization as well.", "tokens": [50364, 1018, 337, 2059, 11, 286, 764, 3890, 2144, 439, 264, 565, 13, 50504, 50504, 407, 341, 307, 257, 588, 4420, 6532, 337, 3097, 2539, 14642, 11, 3009, 18161, 9590, 50756, 50756, 4682, 11, 597, 291, 536, 1780, 294, 264, 2121, 2144, 382, 731, 13, 50952, 50952, 286, 1454, 291, 611, 1520, 484, 264, 17312, 2715, 322, 670, 69, 2414, 13, 51224, 51224, 682, 264, 2715, 11, 291, 486, 536, 819, 5110, 295, 670, 69, 2414, 293, 4369, 729, 5110, 538, 51515, 51515, 9697, 322, 3956, 294, 264, 28609, 13, 51668, 51668], "temperature": 0.0, "avg_logprob": -0.12392427588021883, "compression_ratio": 1.6317991631799162, "no_speech_prob": 6.338996172416955e-06}, {"id": 86, "seek": 38720, "start": 398.96, "end": 404.4, "text": " I hope you also check out the optional lab on overfitting.", "tokens": [50364, 1018, 337, 2059, 11, 286, 764, 3890, 2144, 439, 264, 565, 13, 50504, 50504, 407, 341, 307, 257, 588, 4420, 6532, 337, 3097, 2539, 14642, 11, 3009, 18161, 9590, 50756, 50756, 4682, 11, 597, 291, 536, 1780, 294, 264, 2121, 2144, 382, 731, 13, 50952, 50952, 286, 1454, 291, 611, 1520, 484, 264, 17312, 2715, 322, 670, 69, 2414, 13, 51224, 51224, 682, 264, 2715, 11, 291, 486, 536, 819, 5110, 295, 670, 69, 2414, 293, 4369, 729, 5110, 538, 51515, 51515, 9697, 322, 3956, 294, 264, 28609, 13, 51668, 51668], "temperature": 0.0, "avg_logprob": -0.12392427588021883, "compression_ratio": 1.6317991631799162, "no_speech_prob": 6.338996172416955e-06}, {"id": 87, "seek": 38720, "start": 404.4, "end": 410.21999999999997, "text": " In the lab, you will see different examples of overfitting and adjust those examples by", "tokens": [50364, 1018, 337, 2059, 11, 286, 764, 3890, 2144, 439, 264, 565, 13, 50504, 50504, 407, 341, 307, 257, 588, 4420, 6532, 337, 3097, 2539, 14642, 11, 3009, 18161, 9590, 50756, 50756, 4682, 11, 597, 291, 536, 1780, 294, 264, 2121, 2144, 382, 731, 13, 50952, 50952, 286, 1454, 291, 611, 1520, 484, 264, 17312, 2715, 322, 670, 69, 2414, 13, 51224, 51224, 682, 264, 2715, 11, 291, 486, 536, 819, 5110, 295, 670, 69, 2414, 293, 4369, 729, 5110, 538, 51515, 51515, 9697, 322, 3956, 294, 264, 28609, 13, 51668, 51668], "temperature": 0.0, "avg_logprob": -0.12392427588021883, "compression_ratio": 1.6317991631799162, "no_speech_prob": 6.338996172416955e-06}, {"id": 88, "seek": 38720, "start": 410.21999999999997, "end": 413.28, "text": " clicking on options in the plots.", "tokens": [50364, 1018, 337, 2059, 11, 286, 764, 3890, 2144, 439, 264, 565, 13, 50504, 50504, 407, 341, 307, 257, 588, 4420, 6532, 337, 3097, 2539, 14642, 11, 3009, 18161, 9590, 50756, 50756, 4682, 11, 597, 291, 536, 1780, 294, 264, 2121, 2144, 382, 731, 13, 50952, 50952, 286, 1454, 291, 611, 1520, 484, 264, 17312, 2715, 322, 670, 69, 2414, 13, 51224, 51224, 682, 264, 2715, 11, 291, 486, 536, 819, 5110, 295, 670, 69, 2414, 293, 4369, 729, 5110, 538, 51515, 51515, 9697, 322, 3956, 294, 264, 28609, 13, 51668, 51668], "temperature": 0.0, "avg_logprob": -0.12392427588021883, "compression_ratio": 1.6317991631799162, "no_speech_prob": 6.338996172416955e-06}, {"id": 89, "seek": 41328, "start": 413.28, "end": 419.03999999999996, "text": " You also be able to add your own data points by clicking on the plot and see how that changes", "tokens": [50364, 509, 611, 312, 1075, 281, 909, 428, 1065, 1412, 2793, 538, 9697, 322, 264, 7542, 293, 536, 577, 300, 2962, 50652, 50652, 264, 7605, 300, 307, 3318, 13, 50776, 50776, 509, 393, 611, 853, 5110, 337, 1293, 24590, 293, 21538, 11, 293, 291, 534, 1319, 51074, 51074, 264, 4314, 295, 264, 26110, 281, 312, 2031, 11, 2031, 8889, 11, 2031, 36510, 11, 293, 370, 322, 13, 51398, 51398, 440, 2715, 611, 6653, 291, 862, 365, 732, 819, 3956, 337, 14329, 670, 69, 2414, 13, 51668, 51668], "temperature": 0.0, "avg_logprob": -0.10026907920837402, "compression_ratio": 1.6063348416289593, "no_speech_prob": 3.5007235510420287e-06}, {"id": 90, "seek": 41328, "start": 419.03999999999996, "end": 421.52, "text": " the curve that is fit.", "tokens": [50364, 509, 611, 312, 1075, 281, 909, 428, 1065, 1412, 2793, 538, 9697, 322, 264, 7542, 293, 536, 577, 300, 2962, 50652, 50652, 264, 7605, 300, 307, 3318, 13, 50776, 50776, 509, 393, 611, 853, 5110, 337, 1293, 24590, 293, 21538, 11, 293, 291, 534, 1319, 51074, 51074, 264, 4314, 295, 264, 26110, 281, 312, 2031, 11, 2031, 8889, 11, 2031, 36510, 11, 293, 370, 322, 13, 51398, 51398, 440, 2715, 611, 6653, 291, 862, 365, 732, 819, 3956, 337, 14329, 670, 69, 2414, 13, 51668, 51668], "temperature": 0.0, "avg_logprob": -0.10026907920837402, "compression_ratio": 1.6063348416289593, "no_speech_prob": 3.5007235510420287e-06}, {"id": 91, "seek": 41328, "start": 421.52, "end": 427.47999999999996, "text": " You can also try examples for both regression and classification, and you really change", "tokens": [50364, 509, 611, 312, 1075, 281, 909, 428, 1065, 1412, 2793, 538, 9697, 322, 264, 7542, 293, 536, 577, 300, 2962, 50652, 50652, 264, 7605, 300, 307, 3318, 13, 50776, 50776, 509, 393, 611, 853, 5110, 337, 1293, 24590, 293, 21538, 11, 293, 291, 534, 1319, 51074, 51074, 264, 4314, 295, 264, 26110, 281, 312, 2031, 11, 2031, 8889, 11, 2031, 36510, 11, 293, 370, 322, 13, 51398, 51398, 440, 2715, 611, 6653, 291, 862, 365, 732, 819, 3956, 337, 14329, 670, 69, 2414, 13, 51668, 51668], "temperature": 0.0, "avg_logprob": -0.10026907920837402, "compression_ratio": 1.6063348416289593, "no_speech_prob": 3.5007235510420287e-06}, {"id": 92, "seek": 41328, "start": 427.47999999999996, "end": 433.96, "text": " the degree of the polynomial to be x, x squared, x cubed, and so on.", "tokens": [50364, 509, 611, 312, 1075, 281, 909, 428, 1065, 1412, 2793, 538, 9697, 322, 264, 7542, 293, 536, 577, 300, 2962, 50652, 50652, 264, 7605, 300, 307, 3318, 13, 50776, 50776, 509, 393, 611, 853, 5110, 337, 1293, 24590, 293, 21538, 11, 293, 291, 534, 1319, 51074, 51074, 264, 4314, 295, 264, 26110, 281, 312, 2031, 11, 2031, 8889, 11, 2031, 36510, 11, 293, 370, 322, 13, 51398, 51398, 440, 2715, 611, 6653, 291, 862, 365, 732, 819, 3956, 337, 14329, 670, 69, 2414, 13, 51668, 51668], "temperature": 0.0, "avg_logprob": -0.10026907920837402, "compression_ratio": 1.6063348416289593, "no_speech_prob": 3.5007235510420287e-06}, {"id": 93, "seek": 41328, "start": 433.96, "end": 439.35999999999996, "text": " The lab also lets you play with two different options for addressing overfitting.", "tokens": [50364, 509, 611, 312, 1075, 281, 909, 428, 1065, 1412, 2793, 538, 9697, 322, 264, 7542, 293, 536, 577, 300, 2962, 50652, 50652, 264, 7605, 300, 307, 3318, 13, 50776, 50776, 509, 393, 611, 853, 5110, 337, 1293, 24590, 293, 21538, 11, 293, 291, 534, 1319, 51074, 51074, 264, 4314, 295, 264, 26110, 281, 312, 2031, 11, 2031, 8889, 11, 2031, 36510, 11, 293, 370, 322, 13, 51398, 51398, 440, 2715, 611, 6653, 291, 862, 365, 732, 819, 3956, 337, 14329, 670, 69, 2414, 13, 51668, 51668], "temperature": 0.0, "avg_logprob": -0.10026907920837402, "compression_ratio": 1.6063348416289593, "no_speech_prob": 3.5007235510420287e-06}, {"id": 94, "seek": 43936, "start": 439.36, "end": 444.58000000000004, "text": " You can add additional training data to reduce overfitting, and you can also select which", "tokens": [50364, 509, 393, 909, 4497, 3097, 1412, 281, 5407, 670, 69, 2414, 11, 293, 291, 393, 611, 3048, 597, 50625, 50625, 4122, 281, 4090, 420, 281, 33536, 382, 1071, 636, 281, 853, 281, 5407, 670, 69, 2414, 13, 50956, 50956, 407, 1767, 747, 257, 574, 412, 264, 2715, 11, 597, 286, 1454, 486, 854, 291, 1322, 428, 24002, 466, 51194, 51194, 670, 69, 2414, 382, 731, 382, 512, 7150, 337, 14329, 309, 13, 51408, 51408, 682, 341, 960, 11, 291, 611, 1866, 264, 1558, 295, 3890, 2144, 412, 257, 7226, 1090, 1496, 13, 51700, 51700], "temperature": 0.0, "avg_logprob": -0.06669369339942932, "compression_ratio": 1.676595744680851, "no_speech_prob": 2.0260533801774727e-06}, {"id": 95, "seek": 43936, "start": 444.58000000000004, "end": 451.2, "text": " features to include or to exclude as another way to try to reduce overfitting.", "tokens": [50364, 509, 393, 909, 4497, 3097, 1412, 281, 5407, 670, 69, 2414, 11, 293, 291, 393, 611, 3048, 597, 50625, 50625, 4122, 281, 4090, 420, 281, 33536, 382, 1071, 636, 281, 853, 281, 5407, 670, 69, 2414, 13, 50956, 50956, 407, 1767, 747, 257, 574, 412, 264, 2715, 11, 597, 286, 1454, 486, 854, 291, 1322, 428, 24002, 466, 51194, 51194, 670, 69, 2414, 382, 731, 382, 512, 7150, 337, 14329, 309, 13, 51408, 51408, 682, 341, 960, 11, 291, 611, 1866, 264, 1558, 295, 3890, 2144, 412, 257, 7226, 1090, 1496, 13, 51700, 51700], "temperature": 0.0, "avg_logprob": -0.06669369339942932, "compression_ratio": 1.676595744680851, "no_speech_prob": 2.0260533801774727e-06}, {"id": 96, "seek": 43936, "start": 451.2, "end": 455.96000000000004, "text": " So please take a look at the lab, which I hope will help you build your intuition about", "tokens": [50364, 509, 393, 909, 4497, 3097, 1412, 281, 5407, 670, 69, 2414, 11, 293, 291, 393, 611, 3048, 597, 50625, 50625, 4122, 281, 4090, 420, 281, 33536, 382, 1071, 636, 281, 853, 281, 5407, 670, 69, 2414, 13, 50956, 50956, 407, 1767, 747, 257, 574, 412, 264, 2715, 11, 597, 286, 1454, 486, 854, 291, 1322, 428, 24002, 466, 51194, 51194, 670, 69, 2414, 382, 731, 382, 512, 7150, 337, 14329, 309, 13, 51408, 51408, 682, 341, 960, 11, 291, 611, 1866, 264, 1558, 295, 3890, 2144, 412, 257, 7226, 1090, 1496, 13, 51700, 51700], "temperature": 0.0, "avg_logprob": -0.06669369339942932, "compression_ratio": 1.676595744680851, "no_speech_prob": 2.0260533801774727e-06}, {"id": 97, "seek": 43936, "start": 455.96000000000004, "end": 460.24, "text": " overfitting as well as some methods for addressing it.", "tokens": [50364, 509, 393, 909, 4497, 3097, 1412, 281, 5407, 670, 69, 2414, 11, 293, 291, 393, 611, 3048, 597, 50625, 50625, 4122, 281, 4090, 420, 281, 33536, 382, 1071, 636, 281, 853, 281, 5407, 670, 69, 2414, 13, 50956, 50956, 407, 1767, 747, 257, 574, 412, 264, 2715, 11, 597, 286, 1454, 486, 854, 291, 1322, 428, 24002, 466, 51194, 51194, 670, 69, 2414, 382, 731, 382, 512, 7150, 337, 14329, 309, 13, 51408, 51408, 682, 341, 960, 11, 291, 611, 1866, 264, 1558, 295, 3890, 2144, 412, 257, 7226, 1090, 1496, 13, 51700, 51700], "temperature": 0.0, "avg_logprob": -0.06669369339942932, "compression_ratio": 1.676595744680851, "no_speech_prob": 2.0260533801774727e-06}, {"id": 98, "seek": 43936, "start": 460.24, "end": 466.08000000000004, "text": " In this video, you also saw the idea of regularization at a relatively high level.", "tokens": [50364, 509, 393, 909, 4497, 3097, 1412, 281, 5407, 670, 69, 2414, 11, 293, 291, 393, 611, 3048, 597, 50625, 50625, 4122, 281, 4090, 420, 281, 33536, 382, 1071, 636, 281, 853, 281, 5407, 670, 69, 2414, 13, 50956, 50956, 407, 1767, 747, 257, 574, 412, 264, 2715, 11, 597, 286, 1454, 486, 854, 291, 1322, 428, 24002, 466, 51194, 51194, 670, 69, 2414, 382, 731, 382, 512, 7150, 337, 14329, 309, 13, 51408, 51408, 682, 341, 960, 11, 291, 611, 1866, 264, 1558, 295, 3890, 2144, 412, 257, 7226, 1090, 1496, 13, 51700, 51700], "temperature": 0.0, "avg_logprob": -0.06669369339942932, "compression_ratio": 1.676595744680851, "no_speech_prob": 2.0260533801774727e-06}, {"id": 99, "seek": 46608, "start": 466.08, "end": 472.47999999999996, "text": " I realize that all of these details on regularization may not fully make sense to you yet, but in", "tokens": [50364, 286, 4325, 300, 439, 295, 613, 4365, 322, 3890, 2144, 815, 406, 4498, 652, 2020, 281, 291, 1939, 11, 457, 294, 50684, 50684, 264, 958, 960, 11, 321, 603, 722, 281, 47881, 2293, 577, 281, 3079, 3890, 2144, 293, 2293, 437, 50982, 50982, 3890, 2144, 1355, 13, 51072, 51072, 400, 550, 321, 603, 722, 281, 2573, 484, 577, 281, 652, 341, 589, 365, 527, 2539, 14642, 51312, 51312, 281, 652, 8213, 24590, 293, 23166, 24590, 293, 294, 264, 2027, 11, 661, 14642, 382, 731, 11, 51584, 51584, 5042, 670, 69, 2414, 13, 51634, 51634, 961, 311, 747, 257, 574, 412, 300, 294, 264, 958, 960, 13, 51766], "temperature": 0.0, "avg_logprob": -0.152502882371255, "compression_ratio": 1.8693877551020408, "no_speech_prob": 7.527357411163393e-06}, {"id": 100, "seek": 46608, "start": 472.47999999999996, "end": 478.44, "text": " the next video, we'll start to formulate exactly how to apply regularization and exactly what", "tokens": [50364, 286, 4325, 300, 439, 295, 613, 4365, 322, 3890, 2144, 815, 406, 4498, 652, 2020, 281, 291, 1939, 11, 457, 294, 50684, 50684, 264, 958, 960, 11, 321, 603, 722, 281, 47881, 2293, 577, 281, 3079, 3890, 2144, 293, 2293, 437, 50982, 50982, 3890, 2144, 1355, 13, 51072, 51072, 400, 550, 321, 603, 722, 281, 2573, 484, 577, 281, 652, 341, 589, 365, 527, 2539, 14642, 51312, 51312, 281, 652, 8213, 24590, 293, 23166, 24590, 293, 294, 264, 2027, 11, 661, 14642, 382, 731, 11, 51584, 51584, 5042, 670, 69, 2414, 13, 51634, 51634, 961, 311, 747, 257, 574, 412, 300, 294, 264, 958, 960, 13, 51766], "temperature": 0.0, "avg_logprob": -0.152502882371255, "compression_ratio": 1.8693877551020408, "no_speech_prob": 7.527357411163393e-06}, {"id": 101, "seek": 46608, "start": 478.44, "end": 480.24, "text": " regularization means.", "tokens": [50364, 286, 4325, 300, 439, 295, 613, 4365, 322, 3890, 2144, 815, 406, 4498, 652, 2020, 281, 291, 1939, 11, 457, 294, 50684, 50684, 264, 958, 960, 11, 321, 603, 722, 281, 47881, 2293, 577, 281, 3079, 3890, 2144, 293, 2293, 437, 50982, 50982, 3890, 2144, 1355, 13, 51072, 51072, 400, 550, 321, 603, 722, 281, 2573, 484, 577, 281, 652, 341, 589, 365, 527, 2539, 14642, 51312, 51312, 281, 652, 8213, 24590, 293, 23166, 24590, 293, 294, 264, 2027, 11, 661, 14642, 382, 731, 11, 51584, 51584, 5042, 670, 69, 2414, 13, 51634, 51634, 961, 311, 747, 257, 574, 412, 300, 294, 264, 958, 960, 13, 51766], "temperature": 0.0, "avg_logprob": -0.152502882371255, "compression_ratio": 1.8693877551020408, "no_speech_prob": 7.527357411163393e-06}, {"id": 102, "seek": 46608, "start": 480.24, "end": 485.03999999999996, "text": " And then we'll start to figure out how to make this work with our learning algorithms", "tokens": [50364, 286, 4325, 300, 439, 295, 613, 4365, 322, 3890, 2144, 815, 406, 4498, 652, 2020, 281, 291, 1939, 11, 457, 294, 50684, 50684, 264, 958, 960, 11, 321, 603, 722, 281, 47881, 2293, 577, 281, 3079, 3890, 2144, 293, 2293, 437, 50982, 50982, 3890, 2144, 1355, 13, 51072, 51072, 400, 550, 321, 603, 722, 281, 2573, 484, 577, 281, 652, 341, 589, 365, 527, 2539, 14642, 51312, 51312, 281, 652, 8213, 24590, 293, 23166, 24590, 293, 294, 264, 2027, 11, 661, 14642, 382, 731, 11, 51584, 51584, 5042, 670, 69, 2414, 13, 51634, 51634, 961, 311, 747, 257, 574, 412, 300, 294, 264, 958, 960, 13, 51766], "temperature": 0.0, "avg_logprob": -0.152502882371255, "compression_ratio": 1.8693877551020408, "no_speech_prob": 7.527357411163393e-06}, {"id": 103, "seek": 46608, "start": 485.03999999999996, "end": 490.47999999999996, "text": " to make linear regression and literacy regression and in the future, other algorithms as well,", "tokens": [50364, 286, 4325, 300, 439, 295, 613, 4365, 322, 3890, 2144, 815, 406, 4498, 652, 2020, 281, 291, 1939, 11, 457, 294, 50684, 50684, 264, 958, 960, 11, 321, 603, 722, 281, 47881, 2293, 577, 281, 3079, 3890, 2144, 293, 2293, 437, 50982, 50982, 3890, 2144, 1355, 13, 51072, 51072, 400, 550, 321, 603, 722, 281, 2573, 484, 577, 281, 652, 341, 589, 365, 527, 2539, 14642, 51312, 51312, 281, 652, 8213, 24590, 293, 23166, 24590, 293, 294, 264, 2027, 11, 661, 14642, 382, 731, 11, 51584, 51584, 5042, 670, 69, 2414, 13, 51634, 51634, 961, 311, 747, 257, 574, 412, 300, 294, 264, 958, 960, 13, 51766], "temperature": 0.0, "avg_logprob": -0.152502882371255, "compression_ratio": 1.8693877551020408, "no_speech_prob": 7.527357411163393e-06}, {"id": 104, "seek": 46608, "start": 490.47999999999996, "end": 491.47999999999996, "text": " avoid overfitting.", "tokens": [50364, 286, 4325, 300, 439, 295, 613, 4365, 322, 3890, 2144, 815, 406, 4498, 652, 2020, 281, 291, 1939, 11, 457, 294, 50684, 50684, 264, 958, 960, 11, 321, 603, 722, 281, 47881, 2293, 577, 281, 3079, 3890, 2144, 293, 2293, 437, 50982, 50982, 3890, 2144, 1355, 13, 51072, 51072, 400, 550, 321, 603, 722, 281, 2573, 484, 577, 281, 652, 341, 589, 365, 527, 2539, 14642, 51312, 51312, 281, 652, 8213, 24590, 293, 23166, 24590, 293, 294, 264, 2027, 11, 661, 14642, 382, 731, 11, 51584, 51584, 5042, 670, 69, 2414, 13, 51634, 51634, 961, 311, 747, 257, 574, 412, 300, 294, 264, 958, 960, 13, 51766], "temperature": 0.0, "avg_logprob": -0.152502882371255, "compression_ratio": 1.8693877551020408, "no_speech_prob": 7.527357411163393e-06}, {"id": 105, "seek": 49148, "start": 491.48, "end": 496.24, "text": " Let's take a look at that in the next video.", "tokens": [50364, 961, 311, 747, 257, 574, 412, 300, 294, 264, 958, 960, 13, 50602], "temperature": 0.0, "avg_logprob": -0.3290201822916667, "compression_ratio": 0.8979591836734694, "no_speech_prob": 8.046095172176138e-05}], "language": "en", "video_id": "ce4CPW8AFE4", "entity": "ML Specialization, Andrew Ng (2022)"}}