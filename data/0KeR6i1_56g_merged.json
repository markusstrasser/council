{"video_id": "0KeR6i1_56g", "title": "Week 10 \u2013 Lecture: Self-supervised learning (SSL) in computer vision (CV)", "description": "Course website: http://bit.ly/pDL-home\nPlaylist: http://bit.ly/pDL-YouTube\nSpeaker: Ishan Misra\nWeek 10: http://bit.ly/pDL-en-10\n\n0:00:00 \u2013 Week 10 \u2013 Lecture\n\nLECTURE Part A: http://bit.ly/pDL-en-10-1\nIn this section, we understand the motivation behind Self-Supervised Learning (SSL), define what it is and see some of its applications in NLP and Computer Vision. We understand how pretext tasks aid with SSL and see some example pretext tasks in images, videos and videos with sound. Finally, we try to get an intuition behind the representation learned by pretext tasks.\n0:01:15 \u2013 Challenges of supervised learning and how self supervised learning differs from supervised and unsupervised, with examples in NLP and Relative positions for vision\n0:12:39 \u2013 Examples of pretext tasks in images, videos and videos with sound\n0:40:26 \u2013 Understanding what the \"pretext\" task learns\n\nLECTURE Part B: http://bit.ly/pDL-en-10-2\nIn this section, we discuss the shortcomings of pretext tasks, define characteristics that make a good pretrained feature, and how we can achieve this using Clustering and Contrastive Learning. We then learn about ClusterFit, its steps and performance. We further dive into a specific simple framework for Contrastive Learning known as PIRL. We discuss its working as well as its evaluation in different contexts.\n1:01:50 \u2013 Generalization of pretext task and ClusterFit\n1:19:08 \u2013 Basic idea of PIRL\n1:38:09 \u2013 Evaluating PIRL on different tasks and questions", "author": "Alfredo Canziani", "keywords": ["Yann LeCun", "Deep Learning", "PyTorch", "NYU", "contrastive methods", "SSL", "unsupervised learning", "representation learning", "CV", "triplet loss", "pretext task"], "channel_url": "https://www.youtube.com/channel/UCupQLyNchb9-2Z5lmUOIijw", "length": 7242, "views": 15335, "publish_date": "11/02/2022", "timestamp": 1592784000, "entity": "Yann LeCun", "transcript": {"text": " The recording is running. And so as you can see today, we have a guest lecturer. We have Ishan Misra. Ishan Misra is a research scientist at Facebook AI Research Fair, where he works on computer vision and machine learning. His research interest is in reducing the need for supervision in visual learning. He finished his PhD at the Robotics Institute at Carnegie Mellon University, where he worked with Martin Herbert and Abhinav Gupta. His PhD thesis was about, it was titled, Visual Learning with Minimal Human Supervision, for which he received the SCS Distinguished Dissertation Award in 2018. So with less, how do you say, with further ado, I don't know how to speak English, let's get, we cannot even have the round of applause. Can we have like in the chat round of applause for our speaker? So everyone, my name is Ishan. I'll be talking about self supervised learning and computer vision today. And a lot of the focus is actually going to be sort of more on the discriminative style of approaches. And it's not really going to be on generative style of approaches. And I sort of go about it more and more as I go into my talk. So this sort of success story for representation learning or like computer vision so far has been really this sort of pre-training step or the ImageNet moment of like computer vision. So what has worked really well is that when we have a large label data set like ImageNet, we can learn a representation by performing our image classification task on this large data set. And what is very useful is not just performing this particular task at hand, but to take these representations that you learn and then to use them for downstream tasks where you may not have enough label data. And this has worked really, really well and is sort of the more standard recipe of success. Now this really involves collecting a large data set of supervised images. And you need to get a bunch of these large diverse images and label them with a bunch of large diverse concepts. So let's try to first see whether we can sort of collect these labels and what are sort of the difficulties in doing so. So the ImageNet data set is a very sort of small data set in the grander scheme of things. For example, ImageNet just has 14 million images and it has roughly 22,000 concepts. And just labeling this entire thing, if you look at the amount of effort that was spent, it's about 22 human years to label this entire data set. For contrast, a lot of people are looking at these alternative supervision approaches where you are predicting something like not really a very sort of pristine nice label, but something which is more easy to get. For example, predict like hashtags or predict GPS locations of images. Or what we're going to really focus on in this lecture is going to be about self-supervised learning, which is going to be using the data itself. So the first question that I always like to sort of start out with is why don't you just like get labels for all your data? Why do you even want to invent this entire line of research? Why not just get all the labels? So I did this small exercise where I plotted the amount of supervision that we have for vision data sets. So what I did is basically I looked at all the images which have bounding boxes. And so these are images where you know what kind of concepts are in the image and you also have a box drawn around them. And this is sort of the standard thing to do for something like an object detection model. So if you look at all the data sets in vision that have bounding boxes, you'll get roughly about a million or so images. Now if you relax this constraint and you say that, okay, I don't really care about where the object is located. All I care about is what objects are present in the image. And so if you relax that constraint, you immediately get an order of magnitude more data. So you basically get about 14 million images or so. Now if you further sort of relax this constraint and you say that I don't really care about this image level supervision either, all I care about is internet pictures that are present. You'll get basically about five orders of magnitude more amount of data. And so if you look at this plot now, you can see immediately that the amount of data that we have, which is labeled even at a bounding box or an image level is basically nothing compared to what images exist in the internet scale. And I haven't really forgotten these images, like forgotten the bars on the left hand side. It's just that they completely disappear. And you really need to make this plot something like a log plot to actually even get these bars to appear. So now of course, internet photos do not represent everything about the world. There are things that really require motion or things that really require other physical senses to learn. So in the real world, there are going to be far more things that you actually experience, far more sensory inputs that you can get. And it's really hard to obtain labels for all this data. And again, to put things in perspective, ImageNet, which is just 14 images and with a very small number of concepts that you have required a lot of time to label. So clearly labeling is not really going to scale to either all of internet photos or even the real world. So the other problem with labeling is that for complex concepts like video, it's just really hard to scale labeling. The second problem is that rare concepts are really hard to label. So for example, this is one of the popular image data sets called LabelMe. And over here, we can see that if you look at the kinds of concepts you observe, there are a lot of concepts that are so rare that you're going to have to label a lot of data to even get a few instances of these concepts. So in this data set, 10% of the classes account for more than 93% of the data, which already tells you that in order to sort of scale labeling to more and more concepts, you'll need a lot and lot more data with very diminishing returns. So this is sort of the standard long tail problem. And of course, pre-training is not always the right thing to do. For example, if you just completely change your domain to now move into say medical imaging, it's not clear whether image net pre-training is the right sort of thing for this task. If you do not know sort of the downstream task a priori, how do you collect a big data set and how do you do this entire pre-training downstream task fine tuning recipe? So self-supervised learning sort of comes in between and it tries to give you an alternate way to pre-train your models or to learn from data or learn from experiences without requiring pristine supervision. So in this case, there are sort of two simple definitions that you can come up with for self-supervised learning. The first is more from like a discriminative or like a supervised training perspective. So in image net, for example, you have an image and it can be classified into one of 1,000 labels. So self-supervised learning can be thought of as a way to obtain labels from the data using an automatic process. So that automatic process does not really require a lot of human intervention. And so once you get these automatic labels, now you can sort of go ahead and train your model with these labels. The other way of thinking about self-supervised learning is that it's really a prediction problem where you're trying to predict a part of the data from the other parts of the data. So you have some observed data and you have some hidden data. And you can now formulate a task where given the observed data, you try to predict either the hidden data or some property of the hidden data. And so pretty much a lot of sort of the self-supervised techniques can be viewed in this particular framework. So the term sort of self-supervised learning, I really like to give this analogy, which is from Virginia Dessa. So where she sort of tries to distinguish between the three terms, supervised, unsupervised, and self-supervised. And so in supervised learning, you have, say, an input cow and you're given the exact target for it, which is, say, going to be the label cow. In unsupervised learning, you're given this input and it's not clear what really the entire target is, what exactly is the objective function or so on. Self-supervised learning is sort of the term which is preferred now more and more. And the idea is that the label really comes from either a co-occurring modality or co-occurring part of the data itself. So really all of the power is in the data and you're really trying to predict sort of predict either parts of it or properties of the data. So some very sort of standard and successful examples of this are, say, either the Word to Vec model, where given this, say, a sentence, for example, the cat sits on the mat, you're given a part of the sentence that you observe, so which is in this case labeled as the context or the history. And then you have a part of the sentence, a word in this case, which is not observed, which you sort of hide from this entire model. And given this context, you ask the model to predict this target. And so you have your self-supervised objective, you can minimize it in a particular fashion, and now you will learn a representation for your input data. And Word to Vec has been, I mean, it has actually shown a lot of promise in variety of applications. And this entire sort of predictive model has inspired a lot of work in computer vision as well. The success of self-supervised learning is sort of undebatable in natural language processing. So in 2018, there was this really successful model called BERT, which basically is a form of a masked autoencoder. And this model has sort of revolutionized the amount of things that you can do in NLP with limited amount of data. And a lot of people call this the ImageNet moment of NLP. So in this talk, we'll sort of, again, to motivate why we want to use self-supervised learning. We are really going to focus on sort of how you can look at data and you can use observations and interactions of the data to formulate self-supervised tasks, how you can leverage multiple modalities. And I'll talk a little bit more about what this term modalities means, or structure in the data to sort of learn the representations. So let's move on to the context of computer vision. And I'll sort of now try to define things that I've been talking about in a slightly high level in more concrete fashion. First question. So self-supervised learning is basically just unsupervised learning, right? Yes. I mean, yes, yes. I mean, basically the sort of main differences like unsupervised is a sort of very poorly defined term. So what is supervised, but what is unsupervised? So for example, the analogy given by Jitendra Malik is there is a cat, but there is no category called un-cat. So that's the reason to sort of come like prefer this term more and more that it's really about using the data or the properties of the data itself to come up with supervision. So that's why self-supervision. So someone is suggesting it's a subset. Yes, I guess. Yes. I mean, I guess my reason for calling it this is that the algorithms are essentially the same as supervised learning algorithms with some modifications. Because you're kind of training the system to learn part of its input from another part of the input. So it's very similar to supervised learning in many ways, except that you need to handle uncertainty better. And the negative category, if you want, may be much larger, which is kind of an issue. But unsupervised learning is really not very well defined. Self-supervised learning is kind of a better defined concept. It's not entirely clear. It's a subset of unsupervised. So moving ahead, I'll now sort of try to talk about self-supervised learning more in the context of vision. In vision, a lot of these sort of prediction problems have been framed as pretext tasks. So a lot of the vision algorithms sort of, and this term comes more from 2015, from this particular paper by Carl Torsch. And the idea here was that you have a text task or the sort of task that you really care about at the end, like image classification. But of course, you don't have a lot of data for that, or you want to solve a task before going to the real task, so a pretext task. So this pretext task is a prediction task that you are solving, but it's not often the real task that you really care about. So you'll solve this particular task to learn a representation, and then you'll finally get your downstream task where you want to use this representation to perform something meaningful. So these pretext tasks are sort of funny. They're often fairly like people got very creative with sort of coming up with these pretext tasks. So let's look at how you can define a bunch of pretext tasks and what each of these pretext tasks is trying to do. And so you can use either images, video, video and sound when you're trying to do these things. And in each case, you'll have a bunch of observed data, and you'll try to either predict hidden data or you'll try to predict the property of the hidden data. And this sort of distinguishes a bunch of approaches. So let's look at how you can use images to define something like a pretext task. So the paper that introduced this term pretext task came up with this fairly sort of funny method, but what you do is you take say two image patches. Basically take the network and you ask the network to predict what is the relative position of each patch with respect to the other. So in this case, say I first sample a blue patch and now I sample another red patch. So what I do is I basically feed forward both of these patches through a comnet and I have a classifier that is going to solve an eight way classification problem. And how do I get the label for this classification problem? Well, I just look at where the red patch is located with respect to the blue patch. And that's it. So at the end of it, you're just predicting, you're just solving an eight way classification task. You've got your labels by basically doing this sort of exploiting this property of the input data. And that's it. Now you can use this to basically train this entire comnet. So to look at it in a different way, it's only solving a very small classification problem. It's just solving basically eight possible locations of a problem. Surprisingly enough, doing this sort of pretext task actually learns something fairly reasonable. So the one way to look at what this network has learned is to look at what it considers our nearest neighbors and its visual representation. So to explain this plot a little bit more, on the left hand side, you have the input patch. So you feed forward this input patch through that CNN. And you basically extract a bunch of patches on the data, on your data set. So in this case, ImageNet. And you compute feature representations for each of these patches. Now for the particular input patch that you send through the comnet, you compute the nearest neighbors of all the patches from the data set. And you can use three different networks to compute the feature representations. So the first column is the relative positioning pretext task. And the second column is basically a randomly initialized AlexNet. And then the third column is basically ImageNet pre-trained AlexNet. So if you sort of look at what this relative positioning task is capturing, it's really able to find very good patches, patches that are identical or very close to the input patch. And you also see that it's, for example, like in the row of the cat. So that's the fourth row. You can see that it's actually able to figure out it's slightly invariant to say the color. So the input cat was black and white, but it's actually able to pick out cats which are not just black and white. So it's really doing something. It's at least able to reason about patches as a whole. So why should this representation do anything which is semantic? So the nearest neighbor visualization technique is good at telling you what this representation space has captured. So in this case, what we can confidently say is that this relative patch representation has learned to sort of associate a bunch of these local patches together, local patches that have roughly the same appearance. And so because it is able to reason about these local patches, maybe it's actually able to reason about the image because image can sort of be viewed as a bunch of local patches together. So it's able to sort of put these patches in one part of the representation space. Now people have, like I said, people have gotten fairly creative with the kinds of pretext tasks they do. So another sort of popular pretext task is predicting rotations of an image. And this, so this task is very straightforward. You have an image. You can either apply a rotation of 0 degrees, 90 degrees, 180 degrees, or 270 degrees to it. And basically you send in that particular image after applying a rotation and you ask the network to predict what was the exact rotation applied to the image. And it just solves a four way classification problem. So it predicts basically either if the rotation is 0, 90, 180, or 270. And this pretext task is actually one of the most popular pretext tasks now because it's so easy to implement. You basically just take an image. It's very, very simple. You don't really need to sample too many patches or solve any sort of complicated thing. It's a very standard architecture and you can solve this. And it's become fairly popular now. So the network is going to be basically trained. So the feature are trained in order to solve this problem, right? So the output will be somehow dependent on the specific task someone is going to be picking somehow, right? Yes. So this is, again, this is a pretext task. So we are not really interested in predicting the rotations of an image. We are just using this task as a proxy to learn some features so that on the downstream task, say when someone gives us a thousand labeled images of a cat, we can then use this pre-trained feature representation to do that particular task. So these pretext tasks are often really not going to make a lot of semantic sense. And that's sort of the reason for calling them pretext because you have a downstream task where you actually have some semantic or some label that you actually know is good. Yeah, thanks. Why would the predicting rotations give us any sort of useful representations? Yes. So in fact, when this paper came out, this was the question of many, many people. And it was my question as well. Imperatively, this actually works really well. And sort of my intuition for this has basically been that in order to predict what sort of the rotation of an object is, it needs to roughly understand what the boundaries are, what sort of some concepts in this image are. For example, to predict that this particular image is rotated by 180 degrees, it needs to at least recognize or sort of segregate the sky from the sand or the sky from the water or at least understand that for a tree, the leaves are generally not below the bar. Trees don't grow downwards, they grow upwards. So it sort of needs to reason about some things implicitly. It's not super clear what it really needs to do, but this task empirically works very well. Has this only been tried or works as a task with like a discrete classification or has been tried on like a continuous scale of angles at which the image is rotated? Yes. So you can do both versions. So you can sort of increase the number of bins you want and as you basically make it very, very large, you're approaching more of a regression problem where you have a continuous variable. In practice, these four sort of angles work pretty well. I mean, increasing gives marginal benefits. There's a question about the previous slide. How does the nearest neighborhood work in this context? Do you run every patch, each patch through the CNN? Yes. So this is just for visualization. This is just for sort of understanding. So although it is like sort of expensive to compute this, it gives you a very good idea of what the representation has learned. So what the authors did was basically extract a bunch of patches from each image, roughly 10 to nine patches. And so on a small set of images. So I think in this case, it was like 50 to 100,000 images. And then you basically just compute nearest neighbors on those patches of those images. Is that clear? Yeah, that's it. So another task, which is also fairly popular is called colorization. So in this case, given a grayscale image, you basically try to predict the colors of that image. So you can really formulate this task for any image. You can take an image, you can remove its color, and you can ask a network to basically predict the color from this black and white or sort of grayscale image. And this task by itself is not as, it's actually useful in some respect. So a lot of like old movies, when you sort of see them colorized, so like movies shot in say the 40s or 30s, when there was not a lot of color technology, you can actually have this task really sort of be applied there. So in some way, it actually is more useful than other pretext tasks. And why does this task learn something meaningful? Well, it needs to sort of recognize that trees are green. It needs to understand what the sort of object categories is in order to color it fairly well. And so in practice, this has now sort of been extended to the video domain. And there are a lot of follow up works on sort of colorization itself. It's interesting because I think the color mapping is not deterministic, right? I mean, it's not deterministic, yes. So there are several possible true solutions, right? Yes. So the initial paper was basically sort of proposing a deterministic mapping. So you were solving either a classification or a regression problem. So you only could have say a blue colored umbrella. And if you could never sort of predict a gray colored umbrella. And so what ended up happening was for a lot of categories, which have different kinds of colors. So for example, let's assume say you have a ball and that ball can appear either in the red, blue or green colors. The network would sort of predict that to be gray because well, I mean, that's sort of the mean of all of these things. So that's the best it can do. There was follow up work from David Forsythe's group in UIUC, which tried to sort of come up with variational auto encoders. So you actually had a latent variable and then you would have diverse colorization. So in practice, you can basically do approaches like that. So you can actually have now a green colored ball. And because you're doing that for the entire scene, you can actually have consistent colorings of the entire scene. Yeah. That's what I think we've been talking with Jan. Whenever we have like some mapping that goes from one to many, then we should choose like a latent variable model, which allow us to choose a multiple solution given that we have the same input. Right. Yeah. So I think the reason why people did not really focus a lot on that particular aspect in this case was at least back in the day, one, it was not clear what was working and what was not. And second, this was still a pretext task and people were not really concerned about the colorization quality. People were more concerned about the representation quality. But I think now a lot of us understand that both of them are fairly sort of tied to one another, that you really need to have this sort of non-deterministic mapping to get something more out of the data. I see. Thanks. And finally, so this is, and I apologize for this picture. It's from the paper. I think it was low resolution. But so this is another task, which is like context auto encoders. So the idea is basically borrowed pretty much from say Word2vec. So you hide a particular part of the image. And now given the surrounding part of the image, you need to predict what was hidden. So it's really sort of the fill in the blanks task. And why should this work? Well, it's at least trying to reason about what objects are present. So cars can run on the roads or like buildings are basically consist of like windows and closer to the ground. They're supposed to have doors and so on. So it needs to learn something more about like the implicit structure of the data by performing this task. So this was just about images. And now I'll sort of talk about what are the other tasks that you can do in video. So in video, the sort of main source of supervision is this notion of sequentiality of frames. So frames basically have an inherent order in them. And you want to sort of use that order to get something. For example, say predict the order of frames or fill in the blanks and a bunch of sort of other pretext tasks that are all dependent on sequential nature. So here I'll sort of talk about one of the works that I did in 2016, which was about predicting the temporally correct or incorrect order of frames. This is very much inspired from earlier work that Yan and basically others did on sort of sequential ordering of frames through contrastive learning. And I'll talk about those towards the end when I actually talk about contrastive learning. So in this particular work, we were very much inspired by like the pretext tasks again. And we solve a binary classification problem. So given a bunch of frames, we extract three frames. And if we extract them in the right order, we label them plus one. And if we shuffle them, basically we label them as zero. And so now we need to solve a binary classification problem to predict whether something is shuffled or not. And the reason this sort of works is because, so given three frames, let's think of them as basically start, middle and end. This network really tries to learn, given a start and end point, is this point a valid sort of interpolation of these start and end points? So it really tries to sort of interpolate smoothly these features given this visual input. So the network is fairly straightforward. It's a sort of triplet Siamese network. You have three frames. You feed forward each one of them independently. You concatenate the features that you obtain from these three frames. And then you perform a binary classification problem. So you predict whether this thing is correct or incorrect, whether it's basically shuffled or not shuffled. You can basically minimize this with cross entropy loss. And you can train this entire network end to end. So again, like I had mentioned earlier, nearest neighbor is sort of a good way to visualize what these networks are learning. So we followed prior work and we basically looked at the nearest neighbors of frames. So on the left-hand side, you have a query frame. You feed forward that frame. You get a feature. And then you basically look at the nearest neighbors in that feature representation. And we'll do that for ImageNet, Shuffle and Learn, and then random features. So what you observe is there's a very stark difference between what ImageNet, Shuffle, and Random give you. So the first row, if you look at the sort of gym scene, ImageNet is really good at figuring out that it's a gym scene. The nearest neighbor it retrieves looks very different from the initial image that we've given. The floor is much better lit. In the query, the floor was actually black. And the exact exercise being performed is not really the same, but ImageNet is sort of really good at collapsing this entire semantic category and really sort of bringing in various different gym scenes together close by in the representation space. The same thing sort of goes for the row below. So you have an outdoor scene and ImageNet is immediately able to sort of pick up on that outdoor part of it. It's able to figure out that there is grass and so on. And it sort of brings these two points together in the feature space. If you look at, say, the sort of rightmost, the nearest neighbors retrieved by the random network, you see that it really focuses on the color. So in the top row, it's really sort of focusing on the black floor. It's really looking at maybe sort of the black color in this image. And that's how it's retrieving its nearest neighbor. If you look at the shuffle and learn, the nearest neighbors, they're fairly odd. It's not immediately clear whether it's focusing on the color or whether it's focusing on that entire semantic concept. And so on, sort of further inspection. And after looking at a lot of these examples, we figured out that it was really looking at the pose of the person. So if you look at in the top row, the person is doing sort of an upside, is upside down. And that's sort of the nearest neighbor retrieved as well. And in the second row, also the person is sort of has their foot in a, like has their feet in a particular way. And it's really trying to sort of get there with its nearest neighbor. And it's sort of ignoring the entire scene. So it's not really focused on the background. And when we were thinking about this, why would a network even try to do something of this sort? Well, we looked, we thought back to our pretext task. So the pretext task was predicting the order or basically predicting whether things are in the right order or not. And to do this, you really need to focus on what is moving in the scene or sort of the, in this case, the people. So if you focus on the background, you'll never be able to answer this question fairly well because well, the background doesn't change a lot between three frames that are taken sort of close by in a video. The only thing that sort of changes is the person or the sort of things that are moving in that video. So sort of accidentally, we basically trained a network that was really trying to sort of look at things that are moving and then ended up focusing on the pose of this, pose of people. Now, of course, this is my interpretation. We wanted to verify this quantitatively. So what we did is we took our representation and we fine tuned it on this task of human key point estimation. So this task is basically given up human. You need to sort of predict where certain key points are. So the key points are going to be, they're defined as basically say the nose, the neck, the left shoulder, right shoulder, right elbow, left elbow, wrist, and so on. So you basically have these bunch of predefined key points and you train a network to sort of predict this. So this is really useful for something like tracking or pose estimation of a person. So we took our shuffle and learn self-supervised method and we fine tuned it on these two datasets called Flick and MPII. And we did the same thing for ImageNet supervised network. And this is back in the days of AlexNet. So AlexNet was the architecture that we used. And in sort of fairly surprisingly, what we found is that the self-supervised representation was very competitive or even slightly better than ImageNet supervised representation at this task of key point estimation. So in this case, what I'm measuring is AUC, which is area under the curve. So higher is better. And you can see that it's performing fairly well, which was very surprising to us because we hadn't really thought about this task when we were designing our pretext task. We really thought that doing this pretext task will help us understand actions better. But it turns out that if like you can have sort of surprising outcomes depending on what you ended up creating as a pretext task, so in this case, that was both estimation. So for this example, you said you fine tuned it on human key point estimation. So is that kind of like a supervised step at like once you have your pretext representations? Yes. So the pipeline basically generally goes like you do a pre-planning step. So that can basically be say ImageNet supervision, which is predicting one of 1000 classes. And then you have a downstream task where you have a few amount of labels. So you basically just, so in this case, that's predicting the human key points. So this way of evaluation, what it does is it basically has, it takes a bunch of pre-trained networks and then it fine-tunes them using the same supervised data at the end. And so what you're evaluating is how good was it if I started from say ImageNet supervised network or a shuffle and learn network to perform this task of key point estimation. Okay. Thank you. Isn't it strange that it did this well since shuffle and learn focuses on the background? So it actually focuses a lot on the foreground. So that's what I was trying to sort of come up with this talk about in this example. So if you look at like what the nearest neighbors are, it's really looking at the person to come up with this, right? It's looking at the upside down person to sort of come up with its nearest neighbor. And the reason is if you want to talk about ordering of frames, I really need to focus on things that move. And in these videos, people are the things that move. So if it focuses on the background, it actually will not be able to solve the shuffle and learn task. So this was sort of surprising and it sort of goes to show that if you design your pretext task well, it will work well for a certain sort of set of downstream tasks. And there have been sort of fairly nice methods since then, which I've been basically about predicting this sort of using sequentiality and sort of predicting whether things are in the correct order or not. So this is odd when out networks, which basically rather than solving a binary classification problem, it actually tries to predict which of the frames is the one that is odd when out, the one that is sort of shuffled. And this because you're sort of increasing the amount of information that you're predicting at the output, this sort of network ends up doing better and better. And it also sort of reasons about more frames at a time. So now you've seen sort of images and video. There has been a lot of creative work at the sort of multimodal. So where you have two modalities, video and sound or two sensory inputs. And these two have been sort of very popular and fairly nice sort of work coming out of this regime. So the key sort of signal in these works is predicting whether an image or say a video clip corresponds to an audio clip. So the way you can sort of construct these tasks is to take a video and you can basically just sample any frame from it and similarly take an audio track and sample any part of that. And now the problem is basically to predict whether these things are corresponding or not. So essentially given this entire sort of video, say of a drum, you can sample the frame and the corresponding audio and call that the positive. And in this case, you basically take a different video and you take the audio from the drum video and that becomes your negative. And so again, you can solve a binary classification problem by taking these bunch of positives and negatives. So the architecture for this is fairly straightforward. You take in an image, you pass it through a vision sub network. You have your audio, you pass it through an audio sub network. You get 128 dimensional features for them. So also embeddings. Then you sort of fuse them together and have a binary classification problem saying whether these things correspond or not. So at the end of it, it's just solving a single binary problem. What it sort of shows is that you can actually do a bunch of sort of nice things when you train networks this way. So you can answer the question, what is making a sound because the network really needs to focus on say, to predict whether the sound is coming from this video. It also needs to identify what in the video might be making the sound. So if it's the sound of a guitar, it needs to sort of understand what a guitar roughly looks like. Or if it's a drum, it sort of needs to roughly identify what a drum is. So in this particular case, the author sort of looked at visualizations for, in this case, two instruments. So you have a piano and a flute. And you look at just the video information and nothing else. The network already sort of puts a very high sort of visual importance on the piano and on the flute. And this is because when you sort of feed forward this image, it knows that there are going to be these two kinds of things that can produce sounds. So it really sort of learns to identify these kinds of objects automatically. Do you know about the slide before, whenever you had the convolutional net over the spectrogram, do you know what is the kernel size for that audio component? Just I'm interested to know whether it makes sense to have a rectangular or a square kernel size? These are square kernels. I mean, now there are sort of more improved models. So this is basically operating on the log spectrogram. So it's still handcrafted. You need to decide how you're computing that spectrogram exactly. People have now figured out that you can actually use the raw audio and you can actually apply convolutional filters directly on the raw audio signal. And for that, it's generally a small window. It really depends on what the corresponding video that you're using. So roughly about a second's worth of audio and a second's worth of video. So now that I've sort of shown you how there are like multiple different creative ways of defining what a pretext task is, let's try to see what a pretext task learns. And how can you sort of, if I give you 25 different pretext tasks, how can you a priori decide which one is the one that you want to use and what are they going to sort of learn? So the first thing is pretext tasks are actually complementary. So there was this really nice paper in 2017 that looked at two of these sort of tasks. So relative position was the first pretext task I talked about, where you take two patches and you try to predict what their relative position with respect to one another is. And colorization is basically taking a grayscale image and trying to predict its colors. And so what these authors showed is basically that if you train a single network to do both of these tasks, to predict both the colorized output as well as relative position, you can actually get gains in performance. So again, this is evaluated the same way I was talking about earlier. You have a pre-trained network, and then you're basically evaluating it on an end task. In this case, image net classification and detection benchmark. And in both cases, you sort of can get gains by performing both of these tasks. So you get best of both worlds. So in some way, what this also shows you is that a single pretext task may not be the right answer. So predicting just color or predicting just relative position may not be the right answer to learn self-supervised representations. In fact, if you sort of reason about what information is being predicted, it really varies a lot across tasks. So starting with the relative position task, you're predicting a fairly low level information. You're predicting just sort of eight possible locations. So just an eight-way classification problem. Or for that shuffle and learn problem, you're predicting whether things are shuffled or not. So it's just a simple binary problem. So it's very sort of less amount of information that's being predicted. Whereas if you look at on the extreme right, if you are trying to predict what is missing in an image and you're trying to reconstruct the pixels, you're predicting a lot of information because that entire box contains, I mean, it can have a very, you can have very different appearance space. So if you have n pixels, then you can basically have a lot of different values for that entire predictive region. So you're predicting a lot of information there. So essentially, this is one simple way of thinking about pretext tasks. How much information are you predicting? And that can give you already a good idea of whether you're actually predicting a lot of information. So probably that representation is actually going to be better. So in general, this is sort of going to guide the next part of my talk. You can think of this sort of predicting more information part on an axis. And I'll talk about three different sort of categories in this. Actually, two different categories. So pretext tasks is what I've been talking about till now, which is just predicting simple classification problems, like different degrees of rotation or so on. And sort of move to contrastive methods, which actually predicts way more information than these pretext tasks. And in this particular talk, I'm actually not going to talk about generative models, but generative models predict more information than say a typical contrastive method. And so this is basically one way of thinking about these classes of methods. Question. How do we train multiple pair training pre-training tasks? Do we shuffle data for both tasks? If training individually, won't it lead to catastrophic forgetting? Right. So the simple way of doing that is basically that you have, so you can basically alternate batches. So you can have the same network. And in one batch, you basically feed it black and white images, and you ask it to predict the colored part of it. And in the second batch, you basically feed it patches, and you ask it to do the relative position tasks. You basically have two different head or fully connected layers at the top. So you can basically alternate between these tasks. What the authors of the paper did was actually slightly more sophisticated. They basically had a sort of multitask network, which was three or four, depending on the number of pretext tasks you have. And you actually solve all of them at once. But there was sort of more involved weight sharing across these four or three, four different tasks networks. Hi, I have a question. So about the pretext tasks, what performance should we aim for in a pretext task? When do we know that this is enough? Or when can we stop? And because ultimately, we care about the performance on the downstream. That's question one. And question two is you were speaking about low information and more information. For example, in the case where you mentioned where you were predicting whether it's in the correct sequence or not, you could have also predicted the actual permutation of the images. So how do you decide between which task to follow and based on what? So both parts. The second part of the question, actually, that's going to be in a couple of slides. So I'll sort of defer to that question, that one later. But the first part, how much do you train this model on a pretext task? So a sort of good sign of a pretext task is that as your accuracy on the pretext task improves, so as you get better at predicting whether things are shuffled or not, or as you get better at predicting rotations, the accuracy on the downstream semantic task will also improve. So a good rule of thumb for basically using these pretext tasks is to have a very difficult pretext task or try to make it as difficult as possible. And then optimize or reduce the loss on that pretext task so that your final downstream accuracy improves. So it's very correlated. Right, so in practice, you'll actually train the entire pipeline each time, like the pretext and the downstream and measure the performance. So it's not like you stop the pretext at a certain point and then switch over to only like downstream or something. So that's generally how these methods are evaluated. But I guess when you're developing, you'll probably do this pipeline multiple times. So these methods are sort of trained, like you do your pretext task, then you stop, and then you perform your downstream evaluation task. And that gives you the final sort of measurement of how good your pretext task was. And that's it. You do this entire thing once. Right, thank you. And about the second part of your question, the more information part, I'll sort of come to it later, the permutation and so on. Good. So these are sort of the three main buckets. And the first two are what are going to be covered basically now. So this was another work we did, which was basically about scaling self-supervised learning. So in this particular work, we focused on two problems. One was the colorization problem that I talked about earlier. And the second is this more sort of like more information variant of the relative position task. So this task is called jigsaw puzzles. The idea is that you take an image and you split it into multiple different patches, and you try to predict exactly, and then you shuffle these patches basically by a permutation. And then you predict which permutation was applied to the input. So that's very similar to what Shreyas was suggesting earlier. All right. So the way you solve this problem is you take, say in this case, three patches. You feed forward each one of these patches independently. You concatenate their feature, and then you classify which permutation was basically used to permute these input patches. Now the authors used nine patches to solve this problem. And that's basically going to be nine factorial, which is 360,000 number of permutations. Of course, when you're trying to perform this classification at the end, this means that your fully connected layer should have 360,000 output neurons, which is a very large number. So in practice, what the authors did was basically have a subset of permutations that they use. So say they sample 100 permutations from the nine factorial permutations, and then just have this perform this 100 way classification. So in some way, you can look at the size of this subset as the problem complexity or the amount of information that you're predicting. If you predict the full nine factorial thing, you're actually solving, you're basically predicting a lot of information at the output. If you only sub sample, say two or three permutations, then you're basically not predicting a lot of information. So the problem basically gets harder and harder as the size of the subset increases. So in this paper, we basically wanted to study the entire role of how much information that you predict and how good is the final representation that you learn. So in terms of evaluation, there are two ways to sort of evaluate once you have a self supervised written network. And there's still a lot of debate on which one is exactly the right method to evaluate networks. So the first way is to basically fine tune all the layers of a network. So you have a downstream task, say pose estimation, or say image classification. You train this network and you update all the parameters of this network for the downstream task. The second way is to just use your network as a feature extractor. So you basically run your images through it, you get your feature representation, and now you only train a linear classifier on top of that fixed feature representation. So in this particular work, we said that a good representation should transfer a little amount of training. So we opted basically for the second part, which is just to train a linear classifier on top of a network treated as a feature extractor. So there are of course, different pros and cons of using both methods. So the first method that is fine tuning all the layers is treating the self supervised network as an initialization, because you're basically updating the entire network. So if your downstream task basically has say 1 million images, you're updating your entire network for that 1 million images. Whereas in the second case, you're just training very limited number of parameters on the fixed feature extractor. So in some way, basically the second one is measuring how good of a feature is that you've learned. All right, so the other thing that is sort of critical in evaluating self supervised methods is to evaluate them on a bunch of different tasks. So earlier, when I talked about that shuffle and learn work, I just showed you results on pose estimation. So on pose estimation, it was doing really well, but I actually did not do really well on other tasks like say action recognition. So in this particular evaluation, we sort of wanted to correct that mistake and we wanted to focus on multiple different tasks. So a variety of different tasks like say image classification, few short learning, object detection, 3D understanding, navigation, and so on. So we define basically like a set of nine different tasks. So the way to evaluate the representations is basically to extract fixed features. And you can extract these fixed features from different parts of the network. So they can come basically from a layer which is very close to the input or from a very high level layer, which is very close to the output. And then this way you're sort of measuring the semanticness of each of these different layers. And the sort of standard thing we did for a lot of these experiments was to use an image classification task to sort of understand what is going on. So the image classification task is on this data set called BoC, which is fairly standard for detection and classification. And the idea is to predict whether an image has one of 20 classes. So an image can actually have more than one class. For example, like that picture of a person with a dog that has both person and dog. So this network now needs to recognize both the objects in it. So it's slightly harder than ImageNet where you basically need to only sort of identify one of the key objects in the image. So the first thing we did was basically to verify the hypothesis, whether increasing the amount of information predicted actually results in better representations. So on the x-axis, we're increasing the number of permutations that we're using to basically train our network. So that's going from 100 to 10,000. And on the y-axis, we're basically measuring the downstream transfer performance of these pre-trained representations. And it's measured using a metric called map, which is mean average precision. So essentially, because this is a sort of multi-level classification problem, you're going to measure average precision for each of the different 20 classes. And then you're going to compute the mean of that average precision. So higher is better in this case. So we do that for two different architectures, AlexNet, which was originally used in the jigsaw paper, and then ResNet-50. And what you observe is for AlexNet, increasing the amount of permutations is useful up to a certain point, but the gain is overall limited. Whereas for ResNet, if you increase the amount of permutations, the representation quality gets better and better. And our hypothesis was basically that the ResNet model has enough capacity that it can actually solve a very difficult permutation problem. And when it solves a difficult permutation problem, it's able to learn much better representations that generalize to different downstream tasks. So the next thing we did was to evaluate our method on the object detection task. So object detection is basically where you try to identify what objects are present in an image. You try to draw a box around them. And you're measured basically based on how good the box is around the object and whether you were able to identify all the objects in an image. And again, for this one, we use the same BOC data set. So this was the setting where we basically fine-tuned all the layers of a network because that's what's standard in detection. And what we observed was basically on two different splits of this BOC data set, the jigsaw method was actually fairly comparable within the margin of error to basically training a image net supervised method. So you have an image net supervised network. You fine-tune that on the task of detection and you get a mean average precision of 70.5 or 76.2. And the jigsaw method is basically within the margin of error of these methods, which in itself sort of shows that it actually had some sort of nice semantic property and it was able to localize objects really well. And to put this sort of in context, for semantic feature learning in computer vision, especially, object detection is sort of considered the benchmark data set to do something really well on. And this result, basically when we've sort of published it, was the closest anyone had ever come to supervised pre-training in terms of detection. Some question? So is pre-text tasks similar to what we could try achieving with transfer learning? Is it like a subset of that or? Yes. So, I mean, the way you evaluate these pre-text tasks is by transfer learning. So you perform your original pre-text task and then you fine-tune it on a data set for a particular task like detection. So the evaluation is always transfer learning. So the next task we looked at was surface normal evaluation. So this is basically given input. You try to estimate what are the 3D properties of the, like basically at each pixel location in the input. So you try to predict what is the surface orientation. So in 3D, basically the X, Y, and Z vectors at each particular surface. So it's a sort of dense prediction problem where you need to assign that X, Y, Z vector to each location in the input. And for that, we use this nice data set created by NYU. And we basically measured the prediction properties of our method and compared it to an image net supervised method. And so in this case, we measured the median error and the percentage correct predictions. So the median error basically means that lower is better and percentage correct means higher is better. So it turned out that the Jigsaw pre-training task was actually really good in this case. And it provided like significant improvements over image net pre-training. So it was basically across some multiple different sets, multiple different splits. It was able to really easily outperform the image net supervised pre-trained method. So again, it sort of goes on to show that evaluating a pretext task on multiple different tasks and multiple different data sets is really important to understand what is really going on in your pretext task. So somehow Jigsaw is really incorporating something about like geometry and something about like pixel level information much better than image net supervised methods. So finally, we found sort of the Achilles heel of this method, like the Jigsaw pre-training task. So to do this, we evaluated on like the setting called few-shot learning. So in few-shot learning, you have very sort of limited number of training examples, and you're training your classifier just on these very limited number of training examples. So on the x-axis, I have the number of training examples that were used to train a method. So that goes from say 1 to 96. And I'm sort of showing you curves for like two different self-supervised methods. So Jigsaw methods trained on two different data sets, image net, which is on the top, and a random ResNet-50. What you can observe is that there is a significant gap in performance between a self-supervised method and a supervised method. And that gap basically just does not seem to reduce as you increase the number of labeled examples, which point sort of shows that self-supervised representations, although they may be good at tasks like say pose estimation or particular tasks like surface normal estimation, there is still a lot of difference between what sort of semantic aspect of the data they capture, because this in the sort of few short learning task, if I give you one image, and if you're able to say something about it, your feature representation needs to be fairly good to solve that task. The other way we evaluated this method was to basically look at what it learns at each different layer. So we basically trained linear classifiers on different layer representations in a ResNet-50. So from the CON1, which is going to be the layer closest to the input to the output, say of the Res2 block, the Res3 block, and the Res5 block. So Res5 is basically the sort of highest level representation that you'll get out from a ResNet-50. And after that representation is where you perform this entire jigsaw, like predicting the permutation task. And so you look at, in this case, the x-axis represents the sort of where the feature is coming from, CON1 or Res5. And on the y-axis, we are looking at the, again, mean average precision of image classification on the OC. And funnily enough, what you see is basically that the representation quality improves when you go from CON1 to Res4. So it steadily sort of increases in the mean average precision. But towards the end, there's a sharp drop. So Res4 to Res5 is a sharp drop in performance. Is that due to the fact that it specializes to the specific task? Yes, exactly. So this was very worrying, because if you were to sort of plot this thing for a supervised network, you observe that from CON1 to Res5, the representation quality always improves. And this is true for pretty much any good supervised network. Whereas for a lot of the self-supervised networks, we sort of repeated this experiment for the rotation network, for colorization, for relative position. We would always observe this very sharp gap from Res4 to Res5. And so this says that the end task that we are solving, the pretext task, is probably not very nice, because it's not very well aligned to the downstream semantic tasks that we really want to solve. Which basically brings me to the next part, which is to understand what is missing from these pretext or these sort of proxy tasks. So recap, pretext tasks are basically something like predicting rotation or to predict, say, jigsaw puzzles. And it's very sort of, if you look at it in the bigger picture of things, they're very surprising. And the fact that they even work is super surprising. So for pretext tasks, we have this pre-training step, which is self-supervised. And then we have our transfer tasks, which are image classification or detection. And it's really a lot of wishful thinking and a lot of hope that the pre-training task and the transfer task are super aligned. And there is no evidence, really. It's a lot of just wishing really, really hard that whatever pretext task we've come up with is really well aligned with our transfer task. And solving that pretext task will do really well in transfer tasks. So a lot of research basically goes into designing these pretext tasks and implementing them really well. But it's not clear why solving something like jigsaw puzzles should teach us anything about semantics or, for example, even the case of, say, weak supervised learning, where you're trying to predict hashtags from an image, it's not clear why predicting hashtags of an image is actually going to do something well for learning a good classifier on transfer tasks. So this question remains that, how do you design good pre-training tasks which are well aligned with your transfer tasks? So this hope of generalization is basically you can, and the way we can sort of evaluate this is basically by looking at the representation that each layer. And if the last year we do not see representations that are well aligned with the transfer task, then that is a red flag and that's sort of telling us that maybe this pre-training task is not really the right task to solve. So like I mentioned earlier, this basically is the sort of pattern that we get for jigsaw. And this shows us that probably the last years are very much specialized towards the jigsaw problem. So in general, what we really want from pre-trained features is that they should represent how images are related to one another. So feature representation should, and this basically goes back to say the nearest neighbor visualizations that I had. They should really be able to group together images that are semantically related in some way. And the second property is basically a property that has been the backbone of designing vision features. So even before say the deep learning features are popular, the handcrafted features were always all about invariance, about sort of being invariant to things like lighting or things like exact color or exact location. So these are the two properties that we really want in our pre-trained features. And there are sort of two ways of achieving these things. One is clustering and the other is contrastive learning. And both these methods have promised because they are really solving, they're basically trying to get these properties when they're sort of trying to learn representations. And I believe that's why they've actually now started performing so much better than whatever pretext tasks that were hand designed for so far. So now I sort of focus on two recent works that we have, which are, which fall into this bucket of clustering and invariances. So one is called cluster fit, the other is called Perl, and both of them will be presented at CVPR this year. So the first work is cluster fit. It's a method which we think is very good to improve generalization of visual representations. So clustering is basically a good way to understand what images are grouped together, what images go together and what images do not go together. And it's sort of, by basically performing clustering on the feature space, you can get these nice buckets of images that are related and images that are not related. So the main idea of this paper is extremely simple. There are just two steps. One is the cluster step, the other is the predict step. So what we do is we take a pre-trained network and this can be any pre-trained network. It does not really have to be just a self supervised network. It can either be image pre-trained network or a network pre-trained, say using hashtags or a self supervised network like one trained to predict jigsaw permutations. And you take this pre-trained network and you extract a bunch of features from it on a set of images. And of course, these images have no labels. You extract these features and you perform k-means clustering. And what you now get is basically for each label, for each image, you know which cluster it belongs to and that becomes its label. So in the second fit step, what you do is you train a network from scratch. So like from random bits and you train this network to predict just these pseudo labels. So they're pseudo because they were basically obtained using clustering. So they're not really hard labels which were given by say a human annotator. And so now this second network is just trained to predict these cluster assignments. So it takes our image and it tries to predict which one of the k clusters that you got from your k-means does this image belong to. So a standard pre-train and transfer task is to basically perform your pre-training. So that's the top row is to perform your pre-training on an objective like predicting hashtags or predicting GPS locations. And then to evaluate this feature based by learning C-Linear Probe. In the cluster fit world, we basically do not touch the pre-training. So you perform your pre-training as you were. You just insert a step in between which is the cluster fit step where you take a data set D and you take your pre-trained network and you learn a new network from scratch on this data. And finally, you basically use this green network for all your downstream tasks. So the reason we believe that this method works is because the clustering step, when you're sort of clustering just these images, you're only capturing the essential information which is basically what images go together and what images do not go together. So you're throwing away all the other information that is present in the original network. You're just capturing the sort of inter-image relationships that were captured, that were modeled by the initial network. And to sort of understand this, we performed a fairly simple experiment. We added label noise, so synthetic label noise to ImageNet. And we trained the network basically on this noisy ImageNet. So just flip a bunch of image labels and train a network. And now you evaluate the feature representation from this network on a downstream task, which is again ImageNet, but it's a much larger version of ImageNet. So it's 9,000-way classification. So we basically on the x-axis have the amount of label noise added to the images. So that's going from 0% to 75%. And on the y-axis, we are looking at the transfer performance on the larger ImageNet, the ImageNet 9,000 dataset. So the pink line is showing you the pre-trained network, which is basically as the amount of label noise increases, the pre-trained network's performance on the downstream task decreases. And this is not surprising, because as your labels become less and less reliable, of course, your representation quality is going to suffer. So that sort of goes down very quickly. In the sort of blue line, we experimented with this technique called model distillation, where you take your initial network and you use that to generate labels. So you look at the output of that network and you look at the sort of confidence in the outputs to generate labels for a second network. And that's called model distillation. So model distillation generally performs better than the pre-trained network. And you can see that all across. So as the amount of label noise increases, the distillation model actually is much better than the original model. And finally, towards the end, we have cluster fit. So that's the green line. And you can see that the cluster fit model is consistently better than basically any of these methods, either distillation or pre-training, and consistently gives better results in including when you have zero label noise, which is basically when you have a pre-trained image net network. So we applied. Question, can you elaborate on the difference between distillation and cluster fit once more? Yes. So in distillation, I'll go back to this picture. Yes. So in distillation, what you would do is you would basically, so in this first step, you would take the pre-trained network and you would use the labels this network is predicting. So say the network basically predicts 1000 classes. So you basically use those labels in a softer fashion to generate labels for your images. So say the network was trained to predict 100 different types of dogs. So you take your images and you get a distribution over the 100 different types of dogs and use that distribution to train your second network. Whereas in cluster fit, you don't really care about the label space or the sort of output space of the pre-trained network. You only look at the features. You don't even look at the last fully connected layer. You just look at the previous features. Got it. Also, why would the softer distribution help with training? Like why would training on this be helped? What's the intuition behind distillation? So distillation's main intuition is basically that if your network was trained really well, so suppose you had no label noise, because a lot of things are not really, a lot of images really don't belong in the same classes. So suppose your data set actually had 200 different types of dogs, but you had only 100 of them labeled. And so for a lot of these images, say you actually had to assign, you had to pick basically which one of the dogs it was, a softer distribution is basically going to help you discover hidden categories. So it's basically 0.5 kind of this type of dog and 0.5 this kind of dog. So basically having these sort of softer labels helps you enhance sort of the initial class distribution that you have. Okay, thank you. So we applied this method to the self-supervised learning. So the jigsaw task that I talked about earlier, and we were able to see surprising amounts of gains across a bunch of data sets. So the jigsaw method is in the top row, which, and in each of the sort of columns, you're looking at the transfer performance of basically this jigsaw method on a bunch of different data sets. If you apply cluster fit to this jigsaw method, you actually can see gains across all of these data sets and they're fairly consistent. And we performed this test on a bunch of different pre-training methods like rotnet, so predicting rotations. And again, we could see fairly nice gains across these four different data sets. And surprisingly enough, cluster fit really works on any pre-trained network. So it can be either a fully supervised network or a weekly supervised network. So say a network that was trained to predict hashtags or a weekly supervised video network or basically any self-supervised network. And in each of these cases, we can observe fairly consistent and large gains when you apply cluster fit. So it's actually able to improve the generalization of most of these methods. I think you're dragging your microphone around. It's very noisy. Me? Yeah. It's stuck on my laptop. So the second thing is basically these gains were possible without extra data, labels or changes in the architecture. So in some way, you can think of this as being self-supervised fine tuning step. So you have your pre-trained network and then you basically perform this cluster step, which is cluster fit step, which is completely self-supervised or unsupervised. And then you can observe that the representation quality improves. I had a question. In the slide that you showed the improvement with Jigsaw and by using cluster fit. So in this cluster fit, is it separate thing? It is not using Jigsaw at all. So it is applied on top of the Jigsaw method. So there was a pre-trained network from which you extract features. So in this case, that pre-trained network is the Jigsaw pre-trained network. Oh, okay. But you take the Jigsaw pre-trained network and then you basically perform cluster fit on top of it. Okay. Thank you. Then Lordway, why cluster fit is a good idea? I think the main sort of intuition is that when you say perform the Jigsaw task, the last layer becomes very much fine tuned for that particular Jigsaw task. So we saw that accuracy go down. Now, when you take those features and you perform clustering on it, you can think of this as basically you're reducing the amount of information. If I train the second network to directly regress the features of the first network, I would basically get the same exact network. But if I train the second network only to predict what images are grouped together in the first one, I'm actually predicting lesser information. And our thinking is basically that clustering is some kind of a noise removal technique. So it's really removing all the artifacts that are specific to Jigsaw from that feature space. And so the second network is actually learning something slightly more generic. That's sort of the reason for this experiment as well. So in this case, we sort of empirically validate that hypothesis by actually injecting amount of label noise. So the last layer basically is going to get more and more noisy. And when you do cluster fit on top of this, you actually again see improvement. So that's sort of our validation of this hypothesis. I had another question. So did you measure the performance of cluster fit on object detection? Did it perform as well or was it just great in classification? So it performed well in detection as well. So it actually performs well. So there were initial experiments on detection where it actually does perform well. We did not really push a lot on the detection aspect of it in this particular paper. We were sort of more interested in retrieval or like linear classification kind of experiments. Okay, because I was thinking if we are making these pseudo labels, we are basically making it unable to classification task instead of a detection task. Maybe we could lose some of those features that Jigsaw got. Right, that is possible. At least the initial experiments that I had run did not seem to suggest this. There was improvement in detection. It was minor. But detection improvements overall like the gap in performance is already so small that the improvements are actually generally very small in general. Okay, thank you. I had a doubt in the same cluster fit algorithm. So will the final layer of cluster fit algorithm not get again covariant to the labels that were used for training it on that task? It becomes less covariant. So what we found was if you were to sort of the paper has this plot, I don't have it in the slides, unfortunately, the paper has the plot where okay, this particular plot where we were looking at con one to res five, cluster fit is much better. So the res five to res four gap for cluster fit is much smaller than it is for Jigsaw or Rocknet. But was it better than res four or was it slightly worse? So it was on on VOC classification, it was better. But for say other tasks like image net, it was slightly worse. So it did not completely fix the problem. Okay, thank you. Which was sort of the motivation for Perl. So basically, I'll not talk about Perl. So Perl was sort of born from the hypothesis again, that you need to be invariant to these pretext tasks. So before I get into the details of Perl, I will talk really a little bit about in general contrastive learning. How many minutes do I have, by the way? 15 minutes more or less. Okay, so great. So contrastive learning is basically a sort of general framework that tries to learn a feature space that can combine together or sort of put together points that are related and push apart points that are not related. So in this case, imagine like the blue boxes are the related points, the greens are related and the purple are the related points. You'll extract features for each of these data points through a shared network, which is called a Sianese network. You'll get a bunch of image features for each of these data points. And then you'll apply a loss function, which is a contrastive loss function, which is going to try to sort of minimize the distance between the blue points as opposed to say the distance between the blue point and the green point. Or the distance basically between the blue point should be less than the distance between the blue point and the green point or the blue point and the purple point. So embeddings from the related samples should be much closer than embeddings from the unrelated samples. So that's sort of the general idea of contrastive learning. And of course, Jan was one of the first people to sort of propose this method in his earlier paper with Raya Hatsal, which is called Dr. Lim. And so contrastive learning has now made a resurgence in self-supervised learning. Pretty much a lot of the self-supervised state of the art methods are really based on contrastive learning. And the main question is, how do you define what is related and unrelated? So in the case of supervised learning, that's fairly clear. All of the dog images are related images. And any image that is not a dog image is basically an unrelated image. But it's not so clear how to define the related and unrelatedness in this case of self-supervised learning. The other sort of main difference from something like a pretext task is that contrastive learning really reasons about the entire or a lot of data at once. So to go back to my previous slide, if you look at the loss function, it always involves multiple images. It involves, in the first row, it involves basically the blue images and the green images. In the second row, it involves the blue images and the purple images. Whereas if you look at a task like, say, jigsaw or a task like rotation, you're always reasoning about a single image independently. So that's sort of another difference with contrastive learning. Contrastive learning always reasons about multiple data points at once. So now coming to the question, how do you define related or unrelated images? You can actually use similar techniques to what I was talking about earlier. You can use frames of a video. So you can use the sort of sequential nature of data. So to sort of understand that frames that are nearby in a video are related and frames, say, from a different video, which are further away in time, are unrelated. And that sort of has formed the basis of a lot of self-supervised learning methods in this area. So if you know of this popular method called CPC, which is contrastive predictive coding, that really relies on the sequential nature of a signal. And it basically says that samples that are close by in the time space are related and samples that are further apart in the time space are unrelated. And there's a fairly large amount of work basically exploiting this. It can either be in the speech domain. It can either be in video. It can be in text, or it can be in regular images. And recently, we've also been working on video and audio. So basically saying that a video and its corresponding audio are related samples, and a video and audio from a different image video are basically unrelated samples. And some of the early work in sort of self-supervised learning also use this contrastive learning method. And the way they defined related samples was fairly interesting. So you run an object tracker over a video, and that sort of gives you a moving patch. And what you say is that any patch that was tracked by my tracker is related to my original patch, whereas any patch from a different video is a not related patch. And so that basically gives you these bunch of related and unrelated samples. So if you look at, in this case, figure C, where you have this distance notation, what this network tries to learn is basically that patches that are coming from the same video are related, and patches that are coming from different videos are not related. And so in some way, it automatically learns about different poses of an object. So a cycle viewed from different viewing angles or different poses of a dog, and it tries to sort of group them together. In general, if you just talk about images, a lot of work is done on looking at nearby image patches versus distant patches. So most of the sort of CPC version one and CPC version two methods are really sort of exploiting this property of images. So what you do is you have image patches that are close by, you call them as positives, and image patches that are further apart, like far, farther away in the image are considered as negatives. And then you basically just minimize a contrastive loss using this sort of definition of positives and negatives. The more sort of popular or like performant way of doing this is to look at patches coming from an image and contrast them with patches coming from a different image. So this sort of forms the basis of a lot of popular methods, like instance discrimination, MoCo, Perl, SEMClear. The idea is basically what's shown in the image. To sort of get into more detail, what these methods do is they extract two completely random patches from an image. So these patches can be overlapping, they can actually be contained within one another, or they can be completely far apart, and then apply some sort of data augmentation. So in this case, say a color jittering or removing the color or so on. And then you define these two patches to be your sort of positive examples. You extract another patch from a different image, and this is again a random patch, and that basically becomes your negative. And a lot of these methods will extract a lot of negative patches, and then they will basically perform contrastive learning. So you are relating to positive samples, but you have a lot of negative samples that you're contrasting this against. So now moving to Perl a little bit, let's sort of try to understand what the main difference of pretext tasks is and how contrastive learning is sort of very different from pretext tasks. So the one thing I already mentioned was pretext tasks always reason about a single image at once. So the idea is that given an image, you apply a transform to that image. So in this case, say a jigsaw transform, and then you basically input this transformed image into a con net, and you try to predict the property of the transform that you applied. So the permutation that you applied or the rotation that you applied or the kind of color that you removed and so on. So the pretext tasks always reason about a single image. And the second thing is that the task that you're performing in this case really has to capture some property of the transform. So it really needs to capture the exact permutation that you applied or the kind of rotation that you applied, which means that the last year representations are actually going to vary or sort of vary a lot as the transform changes. And that is by design because you're really trying to solve that pretext task. But unfortunately, what this means is that the last year representations capture a very low level property of the signal. So they capture things like rotation or so on. Whereas what is sort of designed or what is expected of these representations is that they are sort of invariant to these things. You should be able to recognize a cat no matter whether the cat is upright or whether the cat is bent towards by 90 degrees. Whereas when you're solving that particular pretext task, you're imposing the exact opposite thing. You're saying that I should be able to recognize whether this picture is upright or whether this picture is basically tilted sideways. So there are many exceptions in which you really want these low level representations to be covariant. And a lot of it really has to do on the task that you're performing. And quite a few tasks in 3D really want to be predictive. So you want to sort of predict what camera transforms you have when you're looking at two views of the same object or so on. But unless you have that kind of a specific application for a lot of semantic tasks, you really want to be invariant to the transform that are used as input. So invariants have sort of been the workhorse for feature learning. So something like SIF, which is a fairly popular handcrafted feature, the I in SIF really stands for invariant. And supervised networks, for example, supervised Alex nets or supervised Res Nets, they're trained to be invariant data augmentation. You want this network to classify different crops or different rotations of this image as a tree, rather than ask it to predict what exactly was the transformation applied to the input. So this is what inspired Perl. So Perl stands for pretext invariant representation learning, where the idea is that you want the representation to be invariant or capture as little information as possible of the input transform. So you have the image, you have the transform version of the image, you feed forward both of these images through a content, you get a representation, and then you basically encourage these representations to be similar. So in terms of the notation I was talking about earlier, you basically say that the image I and any pretext transformed version of this image I are related samples, and any other image is an unrelated sample. So in this way, when you train this network, this representation hopefully contains very little information about this transform T. And yes, you train it using contrastive learning. So contrastive learning part is to basically, you have say feature vi coming from the original image I, and you have the feature vit coming from the transform version. And you want both of these representations to be the same. And in the paper, we looked at two different state of the art pretext transforms. So that is the jigsaw and the rotation method that I talked about earlier. And we also explored combinations of these transforms. So apply both jigsaw and rotation at the same time. So in some way, this is like multi-task learning, but you're not really trying to predict both jigsaw and rotation, you're trying to be invariant to both jigsaw and rotation. So the key thing that has sort of made contrastive learning work well in the past, like sort of successful attempts, is really using a large number of negatives. And one of the good sort of papers that introduced this was this instance discrimination paper from 2018, which introduced this concept of a memory bank. And this has powered, I would say, most of the sort of recent methods, which are state of the art, including MoCo, Perl. And they're all sort of built and sort of hinge on this idea of a memory bank. Can I ask you to unplug your headphones from the computer? Because it's very noisy. Because the microphone is picked from the headphones. And that's been very... Is it better now? Maybe. I don't know. Let's try. Okay, let's try. So the memory bank is a sort of nice way to get a large number of negatives without really increasing the sort of compute requirement. So what you do is you store a feature vector per image in sort of memory. And then you use that feature vector in your contrastive learning. So okay, let's sort of first talk about how you would do this entire Perl setup without using a memory bank. So you have an image i, you have an image it, you feed forward both of these images, you get a feature vector f of vi from the original image i, you get a feature g of vit from the transformed versions, the patches in this case. And what you want is the features f and g to be similar. And you want features from any other image, so an unrelated image, to basically be dissimilar. So in this case, what we now can do is rather than if we want a lot of negatives, we would really want a lot of these negative images to be feed forward at the same time, which really means that you need a very large batch size to be able to do this. And of course, a large batch size means is not really sort of good, is not possible on say a limited amount of GPU memory. So the way to sort of do that is to use something called a memory bank. So what this memory bank does is that it stores a feature vector for each of the images in your data set. And when you're doing contrastive learning, rather than using feature vectors, say from a different negative image, sort of a different image in your batch, you can just retrieve these features from a memory. You can just retrieve features of any other unglittered image from the memory, and you can just substitute that to perform contrastive learning. So in Perl, we divided the objective into two parts. There was a contrastive term to bring the feature vector from the transformed image, so g of vi, similar to the representation that we have in the memory, so m of i. And similarly, we have a second contrastive term that tries to bring the feature f of vi close to the feature representation that we have in memory. So essentially, g is being pulled close to mi, and f is being pulled close to mi. So by transitivity, f and g are being pulled close to one another. And the reason for separating this out was it sort of stabilized training, and we were able to train without doing this, basically the training would not really converge. And so by separating this out into two forms, rather than doing direct contrastive learning between f and g, we were able to stabilize training and actually get it working. So the way to evaluate this is basically by standard sort of pre-training evaluation setup, so transfer learning, where we can pre-train on images without labels. So the standard we are doing this is to take ImageNet, throw away the labels, and pretend it is unsupervised, and then evaluate using, say, full fine tuning or training a linear classifier. The second thing we did was also test Perl and its robustness to image distributions by training it on in-the-wild images. So we just took one linear image randomly from Flickr. So this is the YFCC dataset. And then we basically pre-trained on these images and then performed transfer learning on different datasets. I had a question about the Perl method, about the memory bank. Wouldn't those feature representations stored in the memory bank be out of date? Yeah, so they do go a little bit out of date, but in practice, it really does not make that much of a difference. So there's a particular way of updating them using... So m of i is a moving average of the representation f, and that moving average, although it's stale, it actually does not matter a lot in practice, you can still continue to use them. So assuming like I recently read the paper SimClear, which used a huge batch size, like 8,000 or something. So using the memory bank approach and getting these 8,000 examples in one loss function, is that possible? Yes, so the sort of SimClear way of doing it really requires a large batch size because you're getting negatives from different images in the same batch. Whereas if you use something like the memory bank, you really do not need a large batch size. So you can train this with like 32 images in a batch because all the negatives are really coming from the memory bank, which does not really require you to do multiple feed forwards. Okay, thank you. If you're using memory bank, then you can't back propagate through the negative example. So is that not a problem? I mean, it does not create that much of a problem really. So that was one thing I was worried about as well. So in the initial versions, we did try something which was like using a larger batch size. But when we switched to something like the memory bank, it did not really reduce performance, very, very little, very much in the reduction in performance. Okay, any intuition why that's the case? I think overall contrastive learning is fairly slow to converge. So all like all methods and clear and like the latest version of moco and so on. All of them train for very large number of epochs anyway. So the number of backpacks that you're getting or the number of memory or parameter updates that you're doing are very large in general. So the fact that you miss out on one of them in this particular case probably does not have that middle of an effect. Okay, thanks. Last five minutes. Cool. Almost there. So yeah, we basically evaluate Perl on a bunch of different tasks. So the first thing was object detection. Again, sort of standard task in vision. And in this case, Perl was able to outperform image net supervised training on detection for both the VOC 07 and 7 plus 12 data sets. And it outperforms on the sort of most stricter evaluation criterion, which is AP all, which is now introduced by Coco, which was already sort of a positive sign that it was able to do this. The second thing we looked at was basically evaluating Perl on semi supervised learning. And once again, Perl was performing fairly well. It was actually better than say the pretext task of jigsaw. So the only difference between the top row and the bottom row is the fact that Perl is an invariant version, whereas jigsaw is a covariant version. And in terms of linear classification, when Perl came out, it was basically at par with CPC's latest version and was performing fairly well on a bunch of different parameter settings and a bunch of different architectures. And of course, now you can have fairly good performance by methods like SimClear. So that number for SimClear corresponding would basically be about 69 or 70 compared to Perl's 63-ish number. The other thing we looked at was basically how Perl sort of generalizes across data distributions. So for this, we looked at just flicker images from the YFCC dataset. And Perl was able to sort of outperform methods that were trained using 100 times more data. So the jigsaw row in the second, like the jigsaw row, which is the second row, was trained on 100 million images, whereas Perl was just trained on 1 million images. And despite that, it's actually able to sort of outperform the jigsaw method fairly easily. This again shows you the power of baking invariants into your representation rather than predicting pretext tasks. And finally, the sort of thing I started out with, which is that whether this thing is actually semantic. So if you look at different layers of representations, so Con1 to Res5, jigsaw basically shows a drop in performance from Res4 to Res5, whereas for Perl, you see a sort of nicely increasing graph, whereas Res4 and Res5 get increasingly more and more semantic. In terms of problem complexity, Perl was very good at handling that because you're never predicting the number of permutations. You're just using them at input as sort of data augmentation. So Perl can sort of scale very well to all the 360,000 possible permutations in the nine patches, whereas for jigsaw, because you're predicting that, you're very limited by the size of your output space. And the paper also shows that we can extend Perl to not just like, it's not limited to jigsaw, you can do that on rotation. You can in fact do it on a combination of jigsaw and rotation, and you can get more and more gains when you basically start doing this. So basically, if you look at these methods, starting from pretext tasks to clustering to Perl, as you go from the left to the right, you basically get more and more invariance. And in some way, you also see an increase in performance, which sort of suggests that baking in more and more invariance to your methods is actually going to be more helpful in the long term. There are some shortcomings, which is basically that we really do not understand what are the set of data transforms that matter. So jigsaw works really well, but it's not very clear why this is happening. So some sort of future work, or if you want to spend your spare cycles thinking about something is really understanding what invariances really matter when you're trying to solve a supervised task. What invariance really matter for something like a mission. And that's it. So basically predict more and more information and try to be as invariant as possible. Thank you. Hey, so I had a question. Yes, these contrastive networks, they can't use the batch norm layer, right? Because then information would pass from one sample to the other. And then the network might learn a very trivial way of separating the negatives from the positive. So it like for example, we really did not observe that phenomenon at all. So we did not really have to do any special tricks with batch. No, we were able to use batch norm as is. Okay. And it's not necessary for all the contrastive networks to not be using batch norm. It's okay to have the batch norm layer. It's yeah, it's I mean, for example, for simpler and so on, they try to move to sync batch norm because they want to emulate a large batch size. So you might have to do some tweaks in batch norm. But basically, you cannot avoid it really, because if you completely remove batch norm, then training these like very deep networks is generally very hard anyway. Okay, do you think that Perl paper works with the batch norm layers because it uses a memory bank and all the representations are not taken at the same time? Whereas I think MoCo, they specifically mentioned not to use the batch norm layer or use it spread across multiple GPUs. So that that I think is one difference for sure. Because basically the negatives that you're contrasting against and the positive word are from different time steps, which makes it harder for batch norm to sort of cheat. Whereas for the other methods, like MoCo and SMP, they're very correlated to the particular batch that you're evaluating right now. Okay, so is there any suggestion if we are using a N pair loss rather than a memory bank? Is there any suggestion how to go about this? Whether we should just stick to Alex net and VGG, which don't use a batch norm layer or is there any way to turn it off? So what's a can you describe the setting a little bit more? So basically, what I'm trying to do is train on a frames of videos. And I'm using a N pair setting, where I'm trying to contrast between N samples rather than two or three samples. And what I'm worried about is whether I should be using batch norm or not. And if I'm not using batch norm at all, then which pre trained sorry, pre architecture models can I use? That's tricky. So the one problem with video frames is basically that fairly correlated. So in general batch norm, basically, the performance of batch norm degrades when you have fairly correlated samples. So video that becomes more and more a problem. The unfortunate sort of like the sad news is basically that even like if you look at a typical implementation of Alex net these days, it will include batch norm. It's just because it's much more stable to train with that you can train with a higher learning rate and a lot you can basically use it for a bunch of different downstream tasks. So I think you may still have to use batch norm. If not, you can give other variants like group norm, which basically do not really depend on the batch size. Okay, makes sense. Thank you. Okay. Thank you so much. Ishan. There's a lot of no interest in details. I think we still have like eight minutes if people are I think there are like still many left in class. Any questions? Yep, I had one question which I had also put forward in a lecture when we were discussing Perl. So this question is about the loss function. Can I answer it right now? Okay, so when I read the paper, so there was a probability term that we were computing after computing the VI and the VIT representation for image and the transformed version. And after getting those probabilities, then we were using a noise contrastive estimation loss. So I was kind of confused that won't it had been better if just a negative log of that probability had been minimized. So you can use both really. So the reason to use NC was basically more to do with how the memory bank paper was set up. So NC you would if you have k negatives, you are basically solving k plus one problems. So the one problem is basically you basically have k plus one different binary problems that you're solving. So that's one way of doing it. The other way of doing it is basically what is now called info NC, which is really just softmax. So you just apply a softmax and you minimize the negative log likelihood for that. It's because that edge, the probability function looked like a softmax. So at the time when I had tried it out, it actually gave me slightly worse results. And so that's basically why I used NC. And this was just initial experiments. Now when I'm trying it out, it actually gives me similar results. So I guess in the end it does not make that much of a difference. This is more related to the course, but we're going to have a project on self supervised learning. So I was wondering, can you give us information on how to get it, get a self supervised learning model working as in the implementation details? Like this has been a lecture on the high level ideas. So how to get it working quickly. So I think, I mean, there are certain class of techniques that are going to be much easier to get working from the get go. So for example, if you were looking at just pretext tasks, then you would basically look at something like rotation because it's a very easy task to implement. You really cannot go wrong with it. I mean, there are just very few things to implement. So just the number of moving pieces are good indicator. The other thing to remember is basically if you're sort of implementing up existing method, then there are going to be lots of tiny details. The author's talk about, so for example, the exact learning rate that they used or the way they use batch norm or so on. If there are lots of these things, then basically it's going to be harder and harder for you to sort of reproduce or more and more things for you to get wrong. Second thing to remember is data augmentation. Data augmentation that are really critical. So if you get anything working, you would try to sort of add more data augmentations to it. And would you recommend us trying poll or do you think that would be too difficult to do in one month? I'm not sure what the setting is really. So I'm not sure if I can comment on that. Okay. Thanks. And just one more thing, did you try using momentum contrast on polls instead of memory bank? I haven't. So we basically moved to the end to end version, which is like similar to what Cynthia is. So the thing is, I mean, you can basically gather a bunch of negatives from different GPUs and increase your batch size. That actually generally helps a lot. I would suspect MoCo would help a lot as well. I think MoCo got improved performance over Cynthia by replacing end to end training with MoCo. Right. I think the numbers are still fairly similar. And there are small differences in evaluation protocols that you sort of see across these papers. So yeah, I think so we're planning to sort of release a more standardized evaluation benchmark. So we did that last year. Unfortunately, that was in cafe too. So we're trying to sort of release something in PyTorch now, which will provide a lot of standardized implementation. So like Perl and a bunch of these and a standardized evaluation protocol for everything. Thanks a lot. Ishan, I had a question about this sensor-wise learning. So what do you think is the state of like generative methods? And did you think about combining like contrastive methods with generative methods like Cynthia actually has a different space? So they have like a linear layer on top of the feature representation where they compute the actual feature representation where they did the contrastive loss, the NCE stuff. So like, do you think like having another head like that basically given like a crop of image, you just try to scale out that crop of image and you have that information because you crop that image, right? And use the GAN or something. So I mean, it is definitely a good idea. I think it's just the tricky part is getting these things to train as just non-trivial. So initially, like I haven't really tried any generative approaches. In my experience, that's slightly more finicky and harder to get to work. But I do agree. I think sort of in the longer term, they are like, they are sort of the things to focus on. Thank you. Last question. No, that's it. I guess. Oh, I can actually ask a question. So this is regarding distillation actually. So you were telling me how predicting softer distributions gives a richer target, right? So can you elaborate on that? Because it sort of increases the uncertainty of our model, right? We are predicting from a one-hot distribution and then making it softer and then we're predicting on that. So more uncertainty. And moreover, like, why do they call it distillation? Because I sort of feel like you need more parameters to account for this richer target. Right. So the one thing is basically if you train on one-hot labels, your models tend to be very overconfident in general. So if you have heard of these tricks called label smoothing, which is sort of now being used by a bunch of methods, label smoothing is like, you can think of it like the sort of simplest version of distillation. So you have a one-hot vector that you were trying to predict, but rather than trying to predict an entire one-hot vector, what you do is you take some probability mass out of that. So you will predict one and a bunch of zeros. So other than doing that, you predict say 0.97 and you add 0.1, 0.1, 0.1, 0.2. I like the remainder three labels to just add a uniform distribution to the remainder. So distillation is a sort of more informed way of doing this. So rather than like randomly sort of increasing the probability of a random unrelated class, you actually have a network which was pre-trained, which is pretty good to this. In general, software distributions are very useful for pre-training methods because models tend to be overconfident. Pre-training on like software distribution is actually slightly easier than optimization problems. So you can work slightly faster as well. So both of these benefits are present in distillation and also something like label smoothing. Also because smooth labels allow you to have a dog-looking cat or a cat-looking dog. So if you have a very big network that has been trained on very many samples, it will actually have a proper idea of what is an ambiguous perhaps image. And therefore, if you can actually learn that soft idea, you're going to be learning more than if you just give that one hot label. I think we are running out of time. I think we are out of time like half an hour ago, but this was the question and answer session. If there are no really, really urgent questions still pending, I will be calling it, call the end of the lesson. So thank you for tuning in. I'll see you tomorrow at the practical session. Don't forget to come. And that was it. So thank you so much, Ishan. And I'll see you around. Thank you, Ishan. Thank you, everyone. Take care, everyone. Bye-bye.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 3.12, "text": " The recording is running.", "tokens": [50364, 440, 6613, 307, 2614, 13, 50520, 50520, 400, 370, 382, 291, 393, 536, 965, 11, 321, 362, 257, 8341, 49881, 13, 50697, 50697, 492, 362, 1119, 3451, 23240, 424, 13, 50775, 50775, 1119, 3451, 23240, 424, 307, 257, 2132, 12662, 412, 4384, 7318, 10303, 12157, 11, 689, 415, 1985, 322, 3820, 51081, 51081, 5201, 293, 3479, 2539, 13, 51166, 51166, 2812, 2132, 1179, 307, 294, 12245, 264, 643, 337, 32675, 294, 5056, 2539, 13, 51434, 51434, 634, 4335, 702, 14476, 412, 264, 29601, 1167, 9446, 412, 47301, 376, 898, 266, 3535, 11, 689, 415, 2732, 51731, 51731], "temperature": 0.0, "avg_logprob": -0.20600692671958845, "compression_ratio": 1.6311475409836065, "no_speech_prob": 0.06376038491725922}, {"id": 1, "seek": 0, "start": 3.12, "end": 6.66, "text": " And so as you can see today, we have a guest lecturer.", "tokens": [50364, 440, 6613, 307, 2614, 13, 50520, 50520, 400, 370, 382, 291, 393, 536, 965, 11, 321, 362, 257, 8341, 49881, 13, 50697, 50697, 492, 362, 1119, 3451, 23240, 424, 13, 50775, 50775, 1119, 3451, 23240, 424, 307, 257, 2132, 12662, 412, 4384, 7318, 10303, 12157, 11, 689, 415, 1985, 322, 3820, 51081, 51081, 5201, 293, 3479, 2539, 13, 51166, 51166, 2812, 2132, 1179, 307, 294, 12245, 264, 643, 337, 32675, 294, 5056, 2539, 13, 51434, 51434, 634, 4335, 702, 14476, 412, 264, 29601, 1167, 9446, 412, 47301, 376, 898, 266, 3535, 11, 689, 415, 2732, 51731, 51731], "temperature": 0.0, "avg_logprob": -0.20600692671958845, "compression_ratio": 1.6311475409836065, "no_speech_prob": 0.06376038491725922}, {"id": 2, "seek": 0, "start": 6.66, "end": 8.22, "text": " We have Ishan Misra.", "tokens": [50364, 440, 6613, 307, 2614, 13, 50520, 50520, 400, 370, 382, 291, 393, 536, 965, 11, 321, 362, 257, 8341, 49881, 13, 50697, 50697, 492, 362, 1119, 3451, 23240, 424, 13, 50775, 50775, 1119, 3451, 23240, 424, 307, 257, 2132, 12662, 412, 4384, 7318, 10303, 12157, 11, 689, 415, 1985, 322, 3820, 51081, 51081, 5201, 293, 3479, 2539, 13, 51166, 51166, 2812, 2132, 1179, 307, 294, 12245, 264, 643, 337, 32675, 294, 5056, 2539, 13, 51434, 51434, 634, 4335, 702, 14476, 412, 264, 29601, 1167, 9446, 412, 47301, 376, 898, 266, 3535, 11, 689, 415, 2732, 51731, 51731], "temperature": 0.0, "avg_logprob": -0.20600692671958845, "compression_ratio": 1.6311475409836065, "no_speech_prob": 0.06376038491725922}, {"id": 3, "seek": 0, "start": 8.22, "end": 14.34, "text": " Ishan Misra is a research scientist at Facebook AI Research Fair, where he works on computer", "tokens": [50364, 440, 6613, 307, 2614, 13, 50520, 50520, 400, 370, 382, 291, 393, 536, 965, 11, 321, 362, 257, 8341, 49881, 13, 50697, 50697, 492, 362, 1119, 3451, 23240, 424, 13, 50775, 50775, 1119, 3451, 23240, 424, 307, 257, 2132, 12662, 412, 4384, 7318, 10303, 12157, 11, 689, 415, 1985, 322, 3820, 51081, 51081, 5201, 293, 3479, 2539, 13, 51166, 51166, 2812, 2132, 1179, 307, 294, 12245, 264, 643, 337, 32675, 294, 5056, 2539, 13, 51434, 51434, 634, 4335, 702, 14476, 412, 264, 29601, 1167, 9446, 412, 47301, 376, 898, 266, 3535, 11, 689, 415, 2732, 51731, 51731], "temperature": 0.0, "avg_logprob": -0.20600692671958845, "compression_ratio": 1.6311475409836065, "no_speech_prob": 0.06376038491725922}, {"id": 4, "seek": 0, "start": 14.34, "end": 16.04, "text": " vision and machine learning.", "tokens": [50364, 440, 6613, 307, 2614, 13, 50520, 50520, 400, 370, 382, 291, 393, 536, 965, 11, 321, 362, 257, 8341, 49881, 13, 50697, 50697, 492, 362, 1119, 3451, 23240, 424, 13, 50775, 50775, 1119, 3451, 23240, 424, 307, 257, 2132, 12662, 412, 4384, 7318, 10303, 12157, 11, 689, 415, 1985, 322, 3820, 51081, 51081, 5201, 293, 3479, 2539, 13, 51166, 51166, 2812, 2132, 1179, 307, 294, 12245, 264, 643, 337, 32675, 294, 5056, 2539, 13, 51434, 51434, 634, 4335, 702, 14476, 412, 264, 29601, 1167, 9446, 412, 47301, 376, 898, 266, 3535, 11, 689, 415, 2732, 51731, 51731], "temperature": 0.0, "avg_logprob": -0.20600692671958845, "compression_ratio": 1.6311475409836065, "no_speech_prob": 0.06376038491725922}, {"id": 5, "seek": 0, "start": 16.04, "end": 21.400000000000002, "text": " His research interest is in reducing the need for supervision in visual learning.", "tokens": [50364, 440, 6613, 307, 2614, 13, 50520, 50520, 400, 370, 382, 291, 393, 536, 965, 11, 321, 362, 257, 8341, 49881, 13, 50697, 50697, 492, 362, 1119, 3451, 23240, 424, 13, 50775, 50775, 1119, 3451, 23240, 424, 307, 257, 2132, 12662, 412, 4384, 7318, 10303, 12157, 11, 689, 415, 1985, 322, 3820, 51081, 51081, 5201, 293, 3479, 2539, 13, 51166, 51166, 2812, 2132, 1179, 307, 294, 12245, 264, 643, 337, 32675, 294, 5056, 2539, 13, 51434, 51434, 634, 4335, 702, 14476, 412, 264, 29601, 1167, 9446, 412, 47301, 376, 898, 266, 3535, 11, 689, 415, 2732, 51731, 51731], "temperature": 0.0, "avg_logprob": -0.20600692671958845, "compression_ratio": 1.6311475409836065, "no_speech_prob": 0.06376038491725922}, {"id": 6, "seek": 0, "start": 21.400000000000002, "end": 27.34, "text": " He finished his PhD at the Robotics Institute at Carnegie Mellon University, where he worked", "tokens": [50364, 440, 6613, 307, 2614, 13, 50520, 50520, 400, 370, 382, 291, 393, 536, 965, 11, 321, 362, 257, 8341, 49881, 13, 50697, 50697, 492, 362, 1119, 3451, 23240, 424, 13, 50775, 50775, 1119, 3451, 23240, 424, 307, 257, 2132, 12662, 412, 4384, 7318, 10303, 12157, 11, 689, 415, 1985, 322, 3820, 51081, 51081, 5201, 293, 3479, 2539, 13, 51166, 51166, 2812, 2132, 1179, 307, 294, 12245, 264, 643, 337, 32675, 294, 5056, 2539, 13, 51434, 51434, 634, 4335, 702, 14476, 412, 264, 29601, 1167, 9446, 412, 47301, 376, 898, 266, 3535, 11, 689, 415, 2732, 51731, 51731], "temperature": 0.0, "avg_logprob": -0.20600692671958845, "compression_ratio": 1.6311475409836065, "no_speech_prob": 0.06376038491725922}, {"id": 7, "seek": 2734, "start": 27.34, "end": 32.16, "text": " with Martin Herbert and Abhinav Gupta.", "tokens": [50364, 365, 9184, 41942, 293, 2847, 10876, 706, 2694, 47366, 13, 50605, 50605, 2812, 14476, 22288, 390, 466, 11, 309, 390, 19841, 11, 23187, 15205, 365, 2829, 10650, 10294, 4548, 6763, 11, 50925, 50925, 337, 597, 415, 4613, 264, 9028, 50, 9840, 7050, 4729, 413, 891, 911, 399, 13894, 294, 6096, 13, 51233, 51233, 407, 365, 1570, 11, 577, 360, 291, 584, 11, 365, 3052, 22450, 11, 286, 500, 380, 458, 577, 281, 1710, 3669, 11, 718, 311, 51559, 51559, 483, 11, 321, 2644, 754, 362, 264, 3098, 295, 9969, 13, 51733, 51733], "temperature": 0.0, "avg_logprob": -0.18092685050152718, "compression_ratio": 1.405857740585774, "no_speech_prob": 0.0001360825845040381}, {"id": 8, "seek": 2734, "start": 32.16, "end": 38.56, "text": " His PhD thesis was about, it was titled, Visual Learning with Minimal Human Supervision,", "tokens": [50364, 365, 9184, 41942, 293, 2847, 10876, 706, 2694, 47366, 13, 50605, 50605, 2812, 14476, 22288, 390, 466, 11, 309, 390, 19841, 11, 23187, 15205, 365, 2829, 10650, 10294, 4548, 6763, 11, 50925, 50925, 337, 597, 415, 4613, 264, 9028, 50, 9840, 7050, 4729, 413, 891, 911, 399, 13894, 294, 6096, 13, 51233, 51233, 407, 365, 1570, 11, 577, 360, 291, 584, 11, 365, 3052, 22450, 11, 286, 500, 380, 458, 577, 281, 1710, 3669, 11, 718, 311, 51559, 51559, 483, 11, 321, 2644, 754, 362, 264, 3098, 295, 9969, 13, 51733, 51733], "temperature": 0.0, "avg_logprob": -0.18092685050152718, "compression_ratio": 1.405857740585774, "no_speech_prob": 0.0001360825845040381}, {"id": 9, "seek": 2734, "start": 38.56, "end": 44.72, "text": " for which he received the SCS Distinguished Dissertation Award in 2018.", "tokens": [50364, 365, 9184, 41942, 293, 2847, 10876, 706, 2694, 47366, 13, 50605, 50605, 2812, 14476, 22288, 390, 466, 11, 309, 390, 19841, 11, 23187, 15205, 365, 2829, 10650, 10294, 4548, 6763, 11, 50925, 50925, 337, 597, 415, 4613, 264, 9028, 50, 9840, 7050, 4729, 413, 891, 911, 399, 13894, 294, 6096, 13, 51233, 51233, 407, 365, 1570, 11, 577, 360, 291, 584, 11, 365, 3052, 22450, 11, 286, 500, 380, 458, 577, 281, 1710, 3669, 11, 718, 311, 51559, 51559, 483, 11, 321, 2644, 754, 362, 264, 3098, 295, 9969, 13, 51733, 51733], "temperature": 0.0, "avg_logprob": -0.18092685050152718, "compression_ratio": 1.405857740585774, "no_speech_prob": 0.0001360825845040381}, {"id": 10, "seek": 2734, "start": 44.72, "end": 51.24, "text": " So with less, how do you say, with further ado, I don't know how to speak English, let's", "tokens": [50364, 365, 9184, 41942, 293, 2847, 10876, 706, 2694, 47366, 13, 50605, 50605, 2812, 14476, 22288, 390, 466, 11, 309, 390, 19841, 11, 23187, 15205, 365, 2829, 10650, 10294, 4548, 6763, 11, 50925, 50925, 337, 597, 415, 4613, 264, 9028, 50, 9840, 7050, 4729, 413, 891, 911, 399, 13894, 294, 6096, 13, 51233, 51233, 407, 365, 1570, 11, 577, 360, 291, 584, 11, 365, 3052, 22450, 11, 286, 500, 380, 458, 577, 281, 1710, 3669, 11, 718, 311, 51559, 51559, 483, 11, 321, 2644, 754, 362, 264, 3098, 295, 9969, 13, 51733, 51733], "temperature": 0.0, "avg_logprob": -0.18092685050152718, "compression_ratio": 1.405857740585774, "no_speech_prob": 0.0001360825845040381}, {"id": 11, "seek": 2734, "start": 51.24, "end": 54.72, "text": " get, we cannot even have the round of applause.", "tokens": [50364, 365, 9184, 41942, 293, 2847, 10876, 706, 2694, 47366, 13, 50605, 50605, 2812, 14476, 22288, 390, 466, 11, 309, 390, 19841, 11, 23187, 15205, 365, 2829, 10650, 10294, 4548, 6763, 11, 50925, 50925, 337, 597, 415, 4613, 264, 9028, 50, 9840, 7050, 4729, 413, 891, 911, 399, 13894, 294, 6096, 13, 51233, 51233, 407, 365, 1570, 11, 577, 360, 291, 584, 11, 365, 3052, 22450, 11, 286, 500, 380, 458, 577, 281, 1710, 3669, 11, 718, 311, 51559, 51559, 483, 11, 321, 2644, 754, 362, 264, 3098, 295, 9969, 13, 51733, 51733], "temperature": 0.0, "avg_logprob": -0.18092685050152718, "compression_ratio": 1.405857740585774, "no_speech_prob": 0.0001360825845040381}, {"id": 12, "seek": 5472, "start": 54.72, "end": 58.64, "text": " Can we have like in the chat round of applause for our speaker?", "tokens": [50364, 1664, 321, 362, 411, 294, 264, 5081, 3098, 295, 9969, 337, 527, 8145, 30, 50560, 50560, 407, 1518, 11, 452, 1315, 307, 1119, 3451, 13, 50666, 50666, 286, 603, 312, 1417, 466, 2698, 46533, 2539, 293, 3820, 5201, 965, 13, 50836, 50836, 400, 257, 688, 295, 264, 1879, 307, 767, 516, 281, 312, 1333, 295, 544, 322, 264, 20828, 1166, 3758, 51070, 51070, 295, 11587, 13, 51166, 51166, 400, 309, 311, 406, 534, 516, 281, 312, 322, 1337, 1166, 3758, 295, 11587, 13, 51276, 51276, 400, 286, 1333, 295, 352, 466, 309, 544, 293, 544, 382, 286, 352, 666, 452, 751, 13, 51492, 51492, 407, 341, 1333, 295, 2245, 1657, 337, 10290, 2539, 420, 411, 3820, 5201, 370, 1400, 575, 51782, 51782], "temperature": 0.0, "avg_logprob": -0.1999597087983162, "compression_ratio": 1.8058608058608059, "no_speech_prob": 4.9065118219004944e-05}, {"id": 13, "seek": 5472, "start": 58.64, "end": 60.76, "text": " So everyone, my name is Ishan.", "tokens": [50364, 1664, 321, 362, 411, 294, 264, 5081, 3098, 295, 9969, 337, 527, 8145, 30, 50560, 50560, 407, 1518, 11, 452, 1315, 307, 1119, 3451, 13, 50666, 50666, 286, 603, 312, 1417, 466, 2698, 46533, 2539, 293, 3820, 5201, 965, 13, 50836, 50836, 400, 257, 688, 295, 264, 1879, 307, 767, 516, 281, 312, 1333, 295, 544, 322, 264, 20828, 1166, 3758, 51070, 51070, 295, 11587, 13, 51166, 51166, 400, 309, 311, 406, 534, 516, 281, 312, 322, 1337, 1166, 3758, 295, 11587, 13, 51276, 51276, 400, 286, 1333, 295, 352, 466, 309, 544, 293, 544, 382, 286, 352, 666, 452, 751, 13, 51492, 51492, 407, 341, 1333, 295, 2245, 1657, 337, 10290, 2539, 420, 411, 3820, 5201, 370, 1400, 575, 51782, 51782], "temperature": 0.0, "avg_logprob": -0.1999597087983162, "compression_ratio": 1.8058608058608059, "no_speech_prob": 4.9065118219004944e-05}, {"id": 14, "seek": 5472, "start": 60.76, "end": 64.16, "text": " I'll be talking about self supervised learning and computer vision today.", "tokens": [50364, 1664, 321, 362, 411, 294, 264, 5081, 3098, 295, 9969, 337, 527, 8145, 30, 50560, 50560, 407, 1518, 11, 452, 1315, 307, 1119, 3451, 13, 50666, 50666, 286, 603, 312, 1417, 466, 2698, 46533, 2539, 293, 3820, 5201, 965, 13, 50836, 50836, 400, 257, 688, 295, 264, 1879, 307, 767, 516, 281, 312, 1333, 295, 544, 322, 264, 20828, 1166, 3758, 51070, 51070, 295, 11587, 13, 51166, 51166, 400, 309, 311, 406, 534, 516, 281, 312, 322, 1337, 1166, 3758, 295, 11587, 13, 51276, 51276, 400, 286, 1333, 295, 352, 466, 309, 544, 293, 544, 382, 286, 352, 666, 452, 751, 13, 51492, 51492, 407, 341, 1333, 295, 2245, 1657, 337, 10290, 2539, 420, 411, 3820, 5201, 370, 1400, 575, 51782, 51782], "temperature": 0.0, "avg_logprob": -0.1999597087983162, "compression_ratio": 1.8058608058608059, "no_speech_prob": 4.9065118219004944e-05}, {"id": 15, "seek": 5472, "start": 64.16, "end": 68.84, "text": " And a lot of the focus is actually going to be sort of more on the discriminative style", "tokens": [50364, 1664, 321, 362, 411, 294, 264, 5081, 3098, 295, 9969, 337, 527, 8145, 30, 50560, 50560, 407, 1518, 11, 452, 1315, 307, 1119, 3451, 13, 50666, 50666, 286, 603, 312, 1417, 466, 2698, 46533, 2539, 293, 3820, 5201, 965, 13, 50836, 50836, 400, 257, 688, 295, 264, 1879, 307, 767, 516, 281, 312, 1333, 295, 544, 322, 264, 20828, 1166, 3758, 51070, 51070, 295, 11587, 13, 51166, 51166, 400, 309, 311, 406, 534, 516, 281, 312, 322, 1337, 1166, 3758, 295, 11587, 13, 51276, 51276, 400, 286, 1333, 295, 352, 466, 309, 544, 293, 544, 382, 286, 352, 666, 452, 751, 13, 51492, 51492, 407, 341, 1333, 295, 2245, 1657, 337, 10290, 2539, 420, 411, 3820, 5201, 370, 1400, 575, 51782, 51782], "temperature": 0.0, "avg_logprob": -0.1999597087983162, "compression_ratio": 1.8058608058608059, "no_speech_prob": 4.9065118219004944e-05}, {"id": 16, "seek": 5472, "start": 68.84, "end": 70.75999999999999, "text": " of approaches.", "tokens": [50364, 1664, 321, 362, 411, 294, 264, 5081, 3098, 295, 9969, 337, 527, 8145, 30, 50560, 50560, 407, 1518, 11, 452, 1315, 307, 1119, 3451, 13, 50666, 50666, 286, 603, 312, 1417, 466, 2698, 46533, 2539, 293, 3820, 5201, 965, 13, 50836, 50836, 400, 257, 688, 295, 264, 1879, 307, 767, 516, 281, 312, 1333, 295, 544, 322, 264, 20828, 1166, 3758, 51070, 51070, 295, 11587, 13, 51166, 51166, 400, 309, 311, 406, 534, 516, 281, 312, 322, 1337, 1166, 3758, 295, 11587, 13, 51276, 51276, 400, 286, 1333, 295, 352, 466, 309, 544, 293, 544, 382, 286, 352, 666, 452, 751, 13, 51492, 51492, 407, 341, 1333, 295, 2245, 1657, 337, 10290, 2539, 420, 411, 3820, 5201, 370, 1400, 575, 51782, 51782], "temperature": 0.0, "avg_logprob": -0.1999597087983162, "compression_ratio": 1.8058608058608059, "no_speech_prob": 4.9065118219004944e-05}, {"id": 17, "seek": 5472, "start": 70.75999999999999, "end": 72.96000000000001, "text": " And it's not really going to be on generative style of approaches.", "tokens": [50364, 1664, 321, 362, 411, 294, 264, 5081, 3098, 295, 9969, 337, 527, 8145, 30, 50560, 50560, 407, 1518, 11, 452, 1315, 307, 1119, 3451, 13, 50666, 50666, 286, 603, 312, 1417, 466, 2698, 46533, 2539, 293, 3820, 5201, 965, 13, 50836, 50836, 400, 257, 688, 295, 264, 1879, 307, 767, 516, 281, 312, 1333, 295, 544, 322, 264, 20828, 1166, 3758, 51070, 51070, 295, 11587, 13, 51166, 51166, 400, 309, 311, 406, 534, 516, 281, 312, 322, 1337, 1166, 3758, 295, 11587, 13, 51276, 51276, 400, 286, 1333, 295, 352, 466, 309, 544, 293, 544, 382, 286, 352, 666, 452, 751, 13, 51492, 51492, 407, 341, 1333, 295, 2245, 1657, 337, 10290, 2539, 420, 411, 3820, 5201, 370, 1400, 575, 51782, 51782], "temperature": 0.0, "avg_logprob": -0.1999597087983162, "compression_ratio": 1.8058608058608059, "no_speech_prob": 4.9065118219004944e-05}, {"id": 18, "seek": 5472, "start": 72.96000000000001, "end": 77.28, "text": " And I sort of go about it more and more as I go into my talk.", "tokens": [50364, 1664, 321, 362, 411, 294, 264, 5081, 3098, 295, 9969, 337, 527, 8145, 30, 50560, 50560, 407, 1518, 11, 452, 1315, 307, 1119, 3451, 13, 50666, 50666, 286, 603, 312, 1417, 466, 2698, 46533, 2539, 293, 3820, 5201, 965, 13, 50836, 50836, 400, 257, 688, 295, 264, 1879, 307, 767, 516, 281, 312, 1333, 295, 544, 322, 264, 20828, 1166, 3758, 51070, 51070, 295, 11587, 13, 51166, 51166, 400, 309, 311, 406, 534, 516, 281, 312, 322, 1337, 1166, 3758, 295, 11587, 13, 51276, 51276, 400, 286, 1333, 295, 352, 466, 309, 544, 293, 544, 382, 286, 352, 666, 452, 751, 13, 51492, 51492, 407, 341, 1333, 295, 2245, 1657, 337, 10290, 2539, 420, 411, 3820, 5201, 370, 1400, 575, 51782, 51782], "temperature": 0.0, "avg_logprob": -0.1999597087983162, "compression_ratio": 1.8058608058608059, "no_speech_prob": 4.9065118219004944e-05}, {"id": 19, "seek": 5472, "start": 77.28, "end": 83.08, "text": " So this sort of success story for representation learning or like computer vision so far has", "tokens": [50364, 1664, 321, 362, 411, 294, 264, 5081, 3098, 295, 9969, 337, 527, 8145, 30, 50560, 50560, 407, 1518, 11, 452, 1315, 307, 1119, 3451, 13, 50666, 50666, 286, 603, 312, 1417, 466, 2698, 46533, 2539, 293, 3820, 5201, 965, 13, 50836, 50836, 400, 257, 688, 295, 264, 1879, 307, 767, 516, 281, 312, 1333, 295, 544, 322, 264, 20828, 1166, 3758, 51070, 51070, 295, 11587, 13, 51166, 51166, 400, 309, 311, 406, 534, 516, 281, 312, 322, 1337, 1166, 3758, 295, 11587, 13, 51276, 51276, 400, 286, 1333, 295, 352, 466, 309, 544, 293, 544, 382, 286, 352, 666, 452, 751, 13, 51492, 51492, 407, 341, 1333, 295, 2245, 1657, 337, 10290, 2539, 420, 411, 3820, 5201, 370, 1400, 575, 51782, 51782], "temperature": 0.0, "avg_logprob": -0.1999597087983162, "compression_ratio": 1.8058608058608059, "no_speech_prob": 4.9065118219004944e-05}, {"id": 20, "seek": 8308, "start": 83.08, "end": 89.6, "text": " been really this sort of pre-training step or the ImageNet moment of like computer vision.", "tokens": [50364, 668, 534, 341, 1333, 295, 659, 12, 17227, 1760, 1823, 420, 264, 29903, 31890, 1623, 295, 411, 3820, 5201, 13, 50690, 50690, 407, 437, 575, 2732, 534, 731, 307, 300, 562, 321, 362, 257, 2416, 7645, 1412, 992, 411, 29903, 31890, 11, 50954, 50954, 321, 393, 1466, 257, 10290, 538, 10205, 527, 3256, 21538, 5633, 322, 341, 2416, 51182, 51182, 1412, 992, 13, 51246, 51246, 400, 437, 307, 588, 4420, 307, 406, 445, 10205, 341, 1729, 5633, 412, 1011, 11, 457, 281, 747, 51486, 51486, 613, 33358, 300, 291, 1466, 293, 550, 281, 764, 552, 337, 30621, 9608, 689, 291, 51670, 51670, 815, 406, 362, 1547, 7645, 1412, 13, 51788, 51788], "temperature": 0.0, "avg_logprob": -0.13177593197442788, "compression_ratio": 1.7745454545454546, "no_speech_prob": 2.667864646355156e-05}, {"id": 21, "seek": 8308, "start": 89.6, "end": 94.88, "text": " So what has worked really well is that when we have a large label data set like ImageNet,", "tokens": [50364, 668, 534, 341, 1333, 295, 659, 12, 17227, 1760, 1823, 420, 264, 29903, 31890, 1623, 295, 411, 3820, 5201, 13, 50690, 50690, 407, 437, 575, 2732, 534, 731, 307, 300, 562, 321, 362, 257, 2416, 7645, 1412, 992, 411, 29903, 31890, 11, 50954, 50954, 321, 393, 1466, 257, 10290, 538, 10205, 527, 3256, 21538, 5633, 322, 341, 2416, 51182, 51182, 1412, 992, 13, 51246, 51246, 400, 437, 307, 588, 4420, 307, 406, 445, 10205, 341, 1729, 5633, 412, 1011, 11, 457, 281, 747, 51486, 51486, 613, 33358, 300, 291, 1466, 293, 550, 281, 764, 552, 337, 30621, 9608, 689, 291, 51670, 51670, 815, 406, 362, 1547, 7645, 1412, 13, 51788, 51788], "temperature": 0.0, "avg_logprob": -0.13177593197442788, "compression_ratio": 1.7745454545454546, "no_speech_prob": 2.667864646355156e-05}, {"id": 22, "seek": 8308, "start": 94.88, "end": 99.44, "text": " we can learn a representation by performing our image classification task on this large", "tokens": [50364, 668, 534, 341, 1333, 295, 659, 12, 17227, 1760, 1823, 420, 264, 29903, 31890, 1623, 295, 411, 3820, 5201, 13, 50690, 50690, 407, 437, 575, 2732, 534, 731, 307, 300, 562, 321, 362, 257, 2416, 7645, 1412, 992, 411, 29903, 31890, 11, 50954, 50954, 321, 393, 1466, 257, 10290, 538, 10205, 527, 3256, 21538, 5633, 322, 341, 2416, 51182, 51182, 1412, 992, 13, 51246, 51246, 400, 437, 307, 588, 4420, 307, 406, 445, 10205, 341, 1729, 5633, 412, 1011, 11, 457, 281, 747, 51486, 51486, 613, 33358, 300, 291, 1466, 293, 550, 281, 764, 552, 337, 30621, 9608, 689, 291, 51670, 51670, 815, 406, 362, 1547, 7645, 1412, 13, 51788, 51788], "temperature": 0.0, "avg_logprob": -0.13177593197442788, "compression_ratio": 1.7745454545454546, "no_speech_prob": 2.667864646355156e-05}, {"id": 23, "seek": 8308, "start": 99.44, "end": 100.72, "text": " data set.", "tokens": [50364, 668, 534, 341, 1333, 295, 659, 12, 17227, 1760, 1823, 420, 264, 29903, 31890, 1623, 295, 411, 3820, 5201, 13, 50690, 50690, 407, 437, 575, 2732, 534, 731, 307, 300, 562, 321, 362, 257, 2416, 7645, 1412, 992, 411, 29903, 31890, 11, 50954, 50954, 321, 393, 1466, 257, 10290, 538, 10205, 527, 3256, 21538, 5633, 322, 341, 2416, 51182, 51182, 1412, 992, 13, 51246, 51246, 400, 437, 307, 588, 4420, 307, 406, 445, 10205, 341, 1729, 5633, 412, 1011, 11, 457, 281, 747, 51486, 51486, 613, 33358, 300, 291, 1466, 293, 550, 281, 764, 552, 337, 30621, 9608, 689, 291, 51670, 51670, 815, 406, 362, 1547, 7645, 1412, 13, 51788, 51788], "temperature": 0.0, "avg_logprob": -0.13177593197442788, "compression_ratio": 1.7745454545454546, "no_speech_prob": 2.667864646355156e-05}, {"id": 24, "seek": 8308, "start": 100.72, "end": 105.52, "text": " And what is very useful is not just performing this particular task at hand, but to take", "tokens": [50364, 668, 534, 341, 1333, 295, 659, 12, 17227, 1760, 1823, 420, 264, 29903, 31890, 1623, 295, 411, 3820, 5201, 13, 50690, 50690, 407, 437, 575, 2732, 534, 731, 307, 300, 562, 321, 362, 257, 2416, 7645, 1412, 992, 411, 29903, 31890, 11, 50954, 50954, 321, 393, 1466, 257, 10290, 538, 10205, 527, 3256, 21538, 5633, 322, 341, 2416, 51182, 51182, 1412, 992, 13, 51246, 51246, 400, 437, 307, 588, 4420, 307, 406, 445, 10205, 341, 1729, 5633, 412, 1011, 11, 457, 281, 747, 51486, 51486, 613, 33358, 300, 291, 1466, 293, 550, 281, 764, 552, 337, 30621, 9608, 689, 291, 51670, 51670, 815, 406, 362, 1547, 7645, 1412, 13, 51788, 51788], "temperature": 0.0, "avg_logprob": -0.13177593197442788, "compression_ratio": 1.7745454545454546, "no_speech_prob": 2.667864646355156e-05}, {"id": 25, "seek": 8308, "start": 105.52, "end": 109.2, "text": " these representations that you learn and then to use them for downstream tasks where you", "tokens": [50364, 668, 534, 341, 1333, 295, 659, 12, 17227, 1760, 1823, 420, 264, 29903, 31890, 1623, 295, 411, 3820, 5201, 13, 50690, 50690, 407, 437, 575, 2732, 534, 731, 307, 300, 562, 321, 362, 257, 2416, 7645, 1412, 992, 411, 29903, 31890, 11, 50954, 50954, 321, 393, 1466, 257, 10290, 538, 10205, 527, 3256, 21538, 5633, 322, 341, 2416, 51182, 51182, 1412, 992, 13, 51246, 51246, 400, 437, 307, 588, 4420, 307, 406, 445, 10205, 341, 1729, 5633, 412, 1011, 11, 457, 281, 747, 51486, 51486, 613, 33358, 300, 291, 1466, 293, 550, 281, 764, 552, 337, 30621, 9608, 689, 291, 51670, 51670, 815, 406, 362, 1547, 7645, 1412, 13, 51788, 51788], "temperature": 0.0, "avg_logprob": -0.13177593197442788, "compression_ratio": 1.7745454545454546, "no_speech_prob": 2.667864646355156e-05}, {"id": 26, "seek": 8308, "start": 109.2, "end": 111.56, "text": " may not have enough label data.", "tokens": [50364, 668, 534, 341, 1333, 295, 659, 12, 17227, 1760, 1823, 420, 264, 29903, 31890, 1623, 295, 411, 3820, 5201, 13, 50690, 50690, 407, 437, 575, 2732, 534, 731, 307, 300, 562, 321, 362, 257, 2416, 7645, 1412, 992, 411, 29903, 31890, 11, 50954, 50954, 321, 393, 1466, 257, 10290, 538, 10205, 527, 3256, 21538, 5633, 322, 341, 2416, 51182, 51182, 1412, 992, 13, 51246, 51246, 400, 437, 307, 588, 4420, 307, 406, 445, 10205, 341, 1729, 5633, 412, 1011, 11, 457, 281, 747, 51486, 51486, 613, 33358, 300, 291, 1466, 293, 550, 281, 764, 552, 337, 30621, 9608, 689, 291, 51670, 51670, 815, 406, 362, 1547, 7645, 1412, 13, 51788, 51788], "temperature": 0.0, "avg_logprob": -0.13177593197442788, "compression_ratio": 1.7745454545454546, "no_speech_prob": 2.667864646355156e-05}, {"id": 27, "seek": 11156, "start": 111.56, "end": 117.84, "text": " And this has worked really, really well and is sort of the more standard recipe of success.", "tokens": [50364, 400, 341, 575, 2732, 534, 11, 534, 731, 293, 307, 1333, 295, 264, 544, 3832, 6782, 295, 2245, 13, 50678, 50678, 823, 341, 534, 11626, 12510, 257, 2416, 1412, 992, 295, 46533, 5267, 13, 51040, 51040, 400, 291, 643, 281, 483, 257, 3840, 295, 613, 2416, 9521, 5267, 293, 7645, 552, 365, 257, 3840, 51252, 51252, 295, 2416, 9521, 10392, 13, 51396, 51396, 407, 718, 311, 853, 281, 700, 536, 1968, 321, 393, 1333, 295, 2500, 613, 16949, 293, 437, 366, 1333, 51740, 51740, 295, 264, 14399, 294, 884, 370, 13, 51848, 51848], "temperature": 0.0, "avg_logprob": -0.12184236426102488, "compression_ratio": 1.7391304347826086, "no_speech_prob": 4.35653782915324e-06}, {"id": 28, "seek": 11156, "start": 117.84, "end": 125.08, "text": " Now this really involves collecting a large data set of supervised images.", "tokens": [50364, 400, 341, 575, 2732, 534, 11, 534, 731, 293, 307, 1333, 295, 264, 544, 3832, 6782, 295, 2245, 13, 50678, 50678, 823, 341, 534, 11626, 12510, 257, 2416, 1412, 992, 295, 46533, 5267, 13, 51040, 51040, 400, 291, 643, 281, 483, 257, 3840, 295, 613, 2416, 9521, 5267, 293, 7645, 552, 365, 257, 3840, 51252, 51252, 295, 2416, 9521, 10392, 13, 51396, 51396, 407, 718, 311, 853, 281, 700, 536, 1968, 321, 393, 1333, 295, 2500, 613, 16949, 293, 437, 366, 1333, 51740, 51740, 295, 264, 14399, 294, 884, 370, 13, 51848, 51848], "temperature": 0.0, "avg_logprob": -0.12184236426102488, "compression_ratio": 1.7391304347826086, "no_speech_prob": 4.35653782915324e-06}, {"id": 29, "seek": 11156, "start": 125.08, "end": 129.32, "text": " And you need to get a bunch of these large diverse images and label them with a bunch", "tokens": [50364, 400, 341, 575, 2732, 534, 11, 534, 731, 293, 307, 1333, 295, 264, 544, 3832, 6782, 295, 2245, 13, 50678, 50678, 823, 341, 534, 11626, 12510, 257, 2416, 1412, 992, 295, 46533, 5267, 13, 51040, 51040, 400, 291, 643, 281, 483, 257, 3840, 295, 613, 2416, 9521, 5267, 293, 7645, 552, 365, 257, 3840, 51252, 51252, 295, 2416, 9521, 10392, 13, 51396, 51396, 407, 718, 311, 853, 281, 700, 536, 1968, 321, 393, 1333, 295, 2500, 613, 16949, 293, 437, 366, 1333, 51740, 51740, 295, 264, 14399, 294, 884, 370, 13, 51848, 51848], "temperature": 0.0, "avg_logprob": -0.12184236426102488, "compression_ratio": 1.7391304347826086, "no_speech_prob": 4.35653782915324e-06}, {"id": 30, "seek": 11156, "start": 129.32, "end": 132.2, "text": " of large diverse concepts.", "tokens": [50364, 400, 341, 575, 2732, 534, 11, 534, 731, 293, 307, 1333, 295, 264, 544, 3832, 6782, 295, 2245, 13, 50678, 50678, 823, 341, 534, 11626, 12510, 257, 2416, 1412, 992, 295, 46533, 5267, 13, 51040, 51040, 400, 291, 643, 281, 483, 257, 3840, 295, 613, 2416, 9521, 5267, 293, 7645, 552, 365, 257, 3840, 51252, 51252, 295, 2416, 9521, 10392, 13, 51396, 51396, 407, 718, 311, 853, 281, 700, 536, 1968, 321, 393, 1333, 295, 2500, 613, 16949, 293, 437, 366, 1333, 51740, 51740, 295, 264, 14399, 294, 884, 370, 13, 51848, 51848], "temperature": 0.0, "avg_logprob": -0.12184236426102488, "compression_ratio": 1.7391304347826086, "no_speech_prob": 4.35653782915324e-06}, {"id": 31, "seek": 11156, "start": 132.2, "end": 139.08, "text": " So let's try to first see whether we can sort of collect these labels and what are sort", "tokens": [50364, 400, 341, 575, 2732, 534, 11, 534, 731, 293, 307, 1333, 295, 264, 544, 3832, 6782, 295, 2245, 13, 50678, 50678, 823, 341, 534, 11626, 12510, 257, 2416, 1412, 992, 295, 46533, 5267, 13, 51040, 51040, 400, 291, 643, 281, 483, 257, 3840, 295, 613, 2416, 9521, 5267, 293, 7645, 552, 365, 257, 3840, 51252, 51252, 295, 2416, 9521, 10392, 13, 51396, 51396, 407, 718, 311, 853, 281, 700, 536, 1968, 321, 393, 1333, 295, 2500, 613, 16949, 293, 437, 366, 1333, 51740, 51740, 295, 264, 14399, 294, 884, 370, 13, 51848, 51848], "temperature": 0.0, "avg_logprob": -0.12184236426102488, "compression_ratio": 1.7391304347826086, "no_speech_prob": 4.35653782915324e-06}, {"id": 32, "seek": 11156, "start": 139.08, "end": 141.24, "text": " of the difficulties in doing so.", "tokens": [50364, 400, 341, 575, 2732, 534, 11, 534, 731, 293, 307, 1333, 295, 264, 544, 3832, 6782, 295, 2245, 13, 50678, 50678, 823, 341, 534, 11626, 12510, 257, 2416, 1412, 992, 295, 46533, 5267, 13, 51040, 51040, 400, 291, 643, 281, 483, 257, 3840, 295, 613, 2416, 9521, 5267, 293, 7645, 552, 365, 257, 3840, 51252, 51252, 295, 2416, 9521, 10392, 13, 51396, 51396, 407, 718, 311, 853, 281, 700, 536, 1968, 321, 393, 1333, 295, 2500, 613, 16949, 293, 437, 366, 1333, 51740, 51740, 295, 264, 14399, 294, 884, 370, 13, 51848, 51848], "temperature": 0.0, "avg_logprob": -0.12184236426102488, "compression_ratio": 1.7391304347826086, "no_speech_prob": 4.35653782915324e-06}, {"id": 33, "seek": 14124, "start": 141.24, "end": 148.76000000000002, "text": " So the ImageNet data set is a very sort of small data set in the grander scheme of things.", "tokens": [50364, 407, 264, 29903, 31890, 1412, 992, 307, 257, 588, 1333, 295, 1359, 1412, 992, 294, 264, 2697, 260, 12232, 295, 721, 13, 50740, 50740, 1171, 1365, 11, 29903, 31890, 445, 575, 3499, 2459, 5267, 293, 309, 575, 9810, 5853, 11, 1360, 10392, 13, 51066, 51066, 400, 445, 40244, 341, 2302, 551, 11, 498, 291, 574, 412, 264, 2372, 295, 4630, 300, 390, 4418, 11, 51274, 51274, 309, 311, 466, 5853, 1952, 924, 281, 7645, 341, 2302, 1412, 992, 13, 51508, 51508, 1171, 8712, 11, 257, 688, 295, 561, 366, 1237, 412, 613, 8535, 32675, 11587, 51704, 51704], "temperature": 0.0, "avg_logprob": -0.11883237626817492, "compression_ratio": 1.628, "no_speech_prob": 1.0289159035892226e-05}, {"id": 34, "seek": 14124, "start": 148.76000000000002, "end": 155.28, "text": " For example, ImageNet just has 14 million images and it has roughly 22,000 concepts.", "tokens": [50364, 407, 264, 29903, 31890, 1412, 992, 307, 257, 588, 1333, 295, 1359, 1412, 992, 294, 264, 2697, 260, 12232, 295, 721, 13, 50740, 50740, 1171, 1365, 11, 29903, 31890, 445, 575, 3499, 2459, 5267, 293, 309, 575, 9810, 5853, 11, 1360, 10392, 13, 51066, 51066, 400, 445, 40244, 341, 2302, 551, 11, 498, 291, 574, 412, 264, 2372, 295, 4630, 300, 390, 4418, 11, 51274, 51274, 309, 311, 466, 5853, 1952, 924, 281, 7645, 341, 2302, 1412, 992, 13, 51508, 51508, 1171, 8712, 11, 257, 688, 295, 561, 366, 1237, 412, 613, 8535, 32675, 11587, 51704, 51704], "temperature": 0.0, "avg_logprob": -0.11883237626817492, "compression_ratio": 1.628, "no_speech_prob": 1.0289159035892226e-05}, {"id": 35, "seek": 14124, "start": 155.28, "end": 159.44, "text": " And just labeling this entire thing, if you look at the amount of effort that was spent,", "tokens": [50364, 407, 264, 29903, 31890, 1412, 992, 307, 257, 588, 1333, 295, 1359, 1412, 992, 294, 264, 2697, 260, 12232, 295, 721, 13, 50740, 50740, 1171, 1365, 11, 29903, 31890, 445, 575, 3499, 2459, 5267, 293, 309, 575, 9810, 5853, 11, 1360, 10392, 13, 51066, 51066, 400, 445, 40244, 341, 2302, 551, 11, 498, 291, 574, 412, 264, 2372, 295, 4630, 300, 390, 4418, 11, 51274, 51274, 309, 311, 466, 5853, 1952, 924, 281, 7645, 341, 2302, 1412, 992, 13, 51508, 51508, 1171, 8712, 11, 257, 688, 295, 561, 366, 1237, 412, 613, 8535, 32675, 11587, 51704, 51704], "temperature": 0.0, "avg_logprob": -0.11883237626817492, "compression_ratio": 1.628, "no_speech_prob": 1.0289159035892226e-05}, {"id": 36, "seek": 14124, "start": 159.44, "end": 164.12, "text": " it's about 22 human years to label this entire data set.", "tokens": [50364, 407, 264, 29903, 31890, 1412, 992, 307, 257, 588, 1333, 295, 1359, 1412, 992, 294, 264, 2697, 260, 12232, 295, 721, 13, 50740, 50740, 1171, 1365, 11, 29903, 31890, 445, 575, 3499, 2459, 5267, 293, 309, 575, 9810, 5853, 11, 1360, 10392, 13, 51066, 51066, 400, 445, 40244, 341, 2302, 551, 11, 498, 291, 574, 412, 264, 2372, 295, 4630, 300, 390, 4418, 11, 51274, 51274, 309, 311, 466, 5853, 1952, 924, 281, 7645, 341, 2302, 1412, 992, 13, 51508, 51508, 1171, 8712, 11, 257, 688, 295, 561, 366, 1237, 412, 613, 8535, 32675, 11587, 51704, 51704], "temperature": 0.0, "avg_logprob": -0.11883237626817492, "compression_ratio": 1.628, "no_speech_prob": 1.0289159035892226e-05}, {"id": 37, "seek": 14124, "start": 164.12, "end": 168.04000000000002, "text": " For contrast, a lot of people are looking at these alternative supervision approaches", "tokens": [50364, 407, 264, 29903, 31890, 1412, 992, 307, 257, 588, 1333, 295, 1359, 1412, 992, 294, 264, 2697, 260, 12232, 295, 721, 13, 50740, 50740, 1171, 1365, 11, 29903, 31890, 445, 575, 3499, 2459, 5267, 293, 309, 575, 9810, 5853, 11, 1360, 10392, 13, 51066, 51066, 400, 445, 40244, 341, 2302, 551, 11, 498, 291, 574, 412, 264, 2372, 295, 4630, 300, 390, 4418, 11, 51274, 51274, 309, 311, 466, 5853, 1952, 924, 281, 7645, 341, 2302, 1412, 992, 13, 51508, 51508, 1171, 8712, 11, 257, 688, 295, 561, 366, 1237, 412, 613, 8535, 32675, 11587, 51704, 51704], "temperature": 0.0, "avg_logprob": -0.11883237626817492, "compression_ratio": 1.628, "no_speech_prob": 1.0289159035892226e-05}, {"id": 38, "seek": 16804, "start": 168.04, "end": 174.4, "text": " where you are predicting something like not really a very sort of pristine nice label,", "tokens": [50364, 689, 291, 366, 32884, 746, 411, 406, 534, 257, 588, 1333, 295, 582, 42745, 1481, 7645, 11, 50682, 50682, 457, 746, 597, 307, 544, 1858, 281, 483, 13, 50802, 50802, 1171, 1365, 11, 6069, 411, 50016, 420, 6069, 19462, 9253, 295, 5267, 13, 51062, 51062, 1610, 437, 321, 434, 516, 281, 534, 1879, 322, 294, 341, 7991, 307, 516, 281, 312, 466, 2698, 12, 48172, 24420, 51268, 51268, 2539, 11, 597, 307, 516, 281, 312, 1228, 264, 1412, 2564, 13, 51500, 51500, 407, 264, 700, 1168, 300, 286, 1009, 411, 281, 1333, 295, 722, 484, 365, 307, 983, 500, 380, 291, 445, 51766, 51766], "temperature": 0.0, "avg_logprob": -0.14995520969606796, "compression_ratio": 1.6848249027237354, "no_speech_prob": 1.952463026100304e-05}, {"id": 39, "seek": 16804, "start": 174.4, "end": 176.79999999999998, "text": " but something which is more easy to get.", "tokens": [50364, 689, 291, 366, 32884, 746, 411, 406, 534, 257, 588, 1333, 295, 582, 42745, 1481, 7645, 11, 50682, 50682, 457, 746, 597, 307, 544, 1858, 281, 483, 13, 50802, 50802, 1171, 1365, 11, 6069, 411, 50016, 420, 6069, 19462, 9253, 295, 5267, 13, 51062, 51062, 1610, 437, 321, 434, 516, 281, 534, 1879, 322, 294, 341, 7991, 307, 516, 281, 312, 466, 2698, 12, 48172, 24420, 51268, 51268, 2539, 11, 597, 307, 516, 281, 312, 1228, 264, 1412, 2564, 13, 51500, 51500, 407, 264, 700, 1168, 300, 286, 1009, 411, 281, 1333, 295, 722, 484, 365, 307, 983, 500, 380, 291, 445, 51766, 51766], "temperature": 0.0, "avg_logprob": -0.14995520969606796, "compression_ratio": 1.6848249027237354, "no_speech_prob": 1.952463026100304e-05}, {"id": 40, "seek": 16804, "start": 176.79999999999998, "end": 182.0, "text": " For example, predict like hashtags or predict GPS locations of images.", "tokens": [50364, 689, 291, 366, 32884, 746, 411, 406, 534, 257, 588, 1333, 295, 582, 42745, 1481, 7645, 11, 50682, 50682, 457, 746, 597, 307, 544, 1858, 281, 483, 13, 50802, 50802, 1171, 1365, 11, 6069, 411, 50016, 420, 6069, 19462, 9253, 295, 5267, 13, 51062, 51062, 1610, 437, 321, 434, 516, 281, 534, 1879, 322, 294, 341, 7991, 307, 516, 281, 312, 466, 2698, 12, 48172, 24420, 51268, 51268, 2539, 11, 597, 307, 516, 281, 312, 1228, 264, 1412, 2564, 13, 51500, 51500, 407, 264, 700, 1168, 300, 286, 1009, 411, 281, 1333, 295, 722, 484, 365, 307, 983, 500, 380, 291, 445, 51766, 51766], "temperature": 0.0, "avg_logprob": -0.14995520969606796, "compression_ratio": 1.6848249027237354, "no_speech_prob": 1.952463026100304e-05}, {"id": 41, "seek": 16804, "start": 182.0, "end": 186.12, "text": " Or what we're going to really focus on in this lecture is going to be about self-supervised", "tokens": [50364, 689, 291, 366, 32884, 746, 411, 406, 534, 257, 588, 1333, 295, 582, 42745, 1481, 7645, 11, 50682, 50682, 457, 746, 597, 307, 544, 1858, 281, 483, 13, 50802, 50802, 1171, 1365, 11, 6069, 411, 50016, 420, 6069, 19462, 9253, 295, 5267, 13, 51062, 51062, 1610, 437, 321, 434, 516, 281, 534, 1879, 322, 294, 341, 7991, 307, 516, 281, 312, 466, 2698, 12, 48172, 24420, 51268, 51268, 2539, 11, 597, 307, 516, 281, 312, 1228, 264, 1412, 2564, 13, 51500, 51500, 407, 264, 700, 1168, 300, 286, 1009, 411, 281, 1333, 295, 722, 484, 365, 307, 983, 500, 380, 291, 445, 51766, 51766], "temperature": 0.0, "avg_logprob": -0.14995520969606796, "compression_ratio": 1.6848249027237354, "no_speech_prob": 1.952463026100304e-05}, {"id": 42, "seek": 16804, "start": 186.12, "end": 190.76, "text": " learning, which is going to be using the data itself.", "tokens": [50364, 689, 291, 366, 32884, 746, 411, 406, 534, 257, 588, 1333, 295, 582, 42745, 1481, 7645, 11, 50682, 50682, 457, 746, 597, 307, 544, 1858, 281, 483, 13, 50802, 50802, 1171, 1365, 11, 6069, 411, 50016, 420, 6069, 19462, 9253, 295, 5267, 13, 51062, 51062, 1610, 437, 321, 434, 516, 281, 534, 1879, 322, 294, 341, 7991, 307, 516, 281, 312, 466, 2698, 12, 48172, 24420, 51268, 51268, 2539, 11, 597, 307, 516, 281, 312, 1228, 264, 1412, 2564, 13, 51500, 51500, 407, 264, 700, 1168, 300, 286, 1009, 411, 281, 1333, 295, 722, 484, 365, 307, 983, 500, 380, 291, 445, 51766, 51766], "temperature": 0.0, "avg_logprob": -0.14995520969606796, "compression_ratio": 1.6848249027237354, "no_speech_prob": 1.952463026100304e-05}, {"id": 43, "seek": 16804, "start": 190.76, "end": 196.07999999999998, "text": " So the first question that I always like to sort of start out with is why don't you just", "tokens": [50364, 689, 291, 366, 32884, 746, 411, 406, 534, 257, 588, 1333, 295, 582, 42745, 1481, 7645, 11, 50682, 50682, 457, 746, 597, 307, 544, 1858, 281, 483, 13, 50802, 50802, 1171, 1365, 11, 6069, 411, 50016, 420, 6069, 19462, 9253, 295, 5267, 13, 51062, 51062, 1610, 437, 321, 434, 516, 281, 534, 1879, 322, 294, 341, 7991, 307, 516, 281, 312, 466, 2698, 12, 48172, 24420, 51268, 51268, 2539, 11, 597, 307, 516, 281, 312, 1228, 264, 1412, 2564, 13, 51500, 51500, 407, 264, 700, 1168, 300, 286, 1009, 411, 281, 1333, 295, 722, 484, 365, 307, 983, 500, 380, 291, 445, 51766, 51766], "temperature": 0.0, "avg_logprob": -0.14995520969606796, "compression_ratio": 1.6848249027237354, "no_speech_prob": 1.952463026100304e-05}, {"id": 44, "seek": 19608, "start": 196.08, "end": 197.96, "text": " like get labels for all your data?", "tokens": [50364, 411, 483, 16949, 337, 439, 428, 1412, 30, 50458, 50458, 1545, 360, 291, 754, 528, 281, 7962, 341, 2302, 1622, 295, 2132, 30, 50616, 50616, 1545, 406, 445, 483, 439, 264, 16949, 30, 50730, 50730, 407, 286, 630, 341, 1359, 5380, 689, 286, 43288, 264, 2372, 295, 32675, 300, 321, 362, 337, 50966, 50966, 5201, 1412, 6352, 13, 51096, 51096, 407, 437, 286, 630, 307, 1936, 286, 2956, 412, 439, 264, 5267, 597, 362, 5472, 278, 9002, 13, 51345, 51345, 400, 370, 613, 366, 5267, 689, 291, 458, 437, 733, 295, 10392, 366, 294, 264, 3256, 293, 291, 51554, 51554, 611, 362, 257, 2424, 10117, 926, 552, 13, 51652, 51652, 400, 341, 307, 1333, 295, 264, 3832, 551, 281, 360, 337, 746, 411, 364, 2657, 17784, 2316, 13, 51860, 51860], "temperature": 0.0, "avg_logprob": -0.12011041063250917, "compression_ratio": 1.7864406779661017, "no_speech_prob": 9.817916179599706e-06}, {"id": 45, "seek": 19608, "start": 197.96, "end": 201.12, "text": " Why do you even want to invent this entire line of research?", "tokens": [50364, 411, 483, 16949, 337, 439, 428, 1412, 30, 50458, 50458, 1545, 360, 291, 754, 528, 281, 7962, 341, 2302, 1622, 295, 2132, 30, 50616, 50616, 1545, 406, 445, 483, 439, 264, 16949, 30, 50730, 50730, 407, 286, 630, 341, 1359, 5380, 689, 286, 43288, 264, 2372, 295, 32675, 300, 321, 362, 337, 50966, 50966, 5201, 1412, 6352, 13, 51096, 51096, 407, 437, 286, 630, 307, 1936, 286, 2956, 412, 439, 264, 5267, 597, 362, 5472, 278, 9002, 13, 51345, 51345, 400, 370, 613, 366, 5267, 689, 291, 458, 437, 733, 295, 10392, 366, 294, 264, 3256, 293, 291, 51554, 51554, 611, 362, 257, 2424, 10117, 926, 552, 13, 51652, 51652, 400, 341, 307, 1333, 295, 264, 3832, 551, 281, 360, 337, 746, 411, 364, 2657, 17784, 2316, 13, 51860, 51860], "temperature": 0.0, "avg_logprob": -0.12011041063250917, "compression_ratio": 1.7864406779661017, "no_speech_prob": 9.817916179599706e-06}, {"id": 46, "seek": 19608, "start": 201.12, "end": 203.4, "text": " Why not just get all the labels?", "tokens": [50364, 411, 483, 16949, 337, 439, 428, 1412, 30, 50458, 50458, 1545, 360, 291, 754, 528, 281, 7962, 341, 2302, 1622, 295, 2132, 30, 50616, 50616, 1545, 406, 445, 483, 439, 264, 16949, 30, 50730, 50730, 407, 286, 630, 341, 1359, 5380, 689, 286, 43288, 264, 2372, 295, 32675, 300, 321, 362, 337, 50966, 50966, 5201, 1412, 6352, 13, 51096, 51096, 407, 437, 286, 630, 307, 1936, 286, 2956, 412, 439, 264, 5267, 597, 362, 5472, 278, 9002, 13, 51345, 51345, 400, 370, 613, 366, 5267, 689, 291, 458, 437, 733, 295, 10392, 366, 294, 264, 3256, 293, 291, 51554, 51554, 611, 362, 257, 2424, 10117, 926, 552, 13, 51652, 51652, 400, 341, 307, 1333, 295, 264, 3832, 551, 281, 360, 337, 746, 411, 364, 2657, 17784, 2316, 13, 51860, 51860], "temperature": 0.0, "avg_logprob": -0.12011041063250917, "compression_ratio": 1.7864406779661017, "no_speech_prob": 9.817916179599706e-06}, {"id": 47, "seek": 19608, "start": 203.4, "end": 208.12, "text": " So I did this small exercise where I plotted the amount of supervision that we have for", "tokens": [50364, 411, 483, 16949, 337, 439, 428, 1412, 30, 50458, 50458, 1545, 360, 291, 754, 528, 281, 7962, 341, 2302, 1622, 295, 2132, 30, 50616, 50616, 1545, 406, 445, 483, 439, 264, 16949, 30, 50730, 50730, 407, 286, 630, 341, 1359, 5380, 689, 286, 43288, 264, 2372, 295, 32675, 300, 321, 362, 337, 50966, 50966, 5201, 1412, 6352, 13, 51096, 51096, 407, 437, 286, 630, 307, 1936, 286, 2956, 412, 439, 264, 5267, 597, 362, 5472, 278, 9002, 13, 51345, 51345, 400, 370, 613, 366, 5267, 689, 291, 458, 437, 733, 295, 10392, 366, 294, 264, 3256, 293, 291, 51554, 51554, 611, 362, 257, 2424, 10117, 926, 552, 13, 51652, 51652, 400, 341, 307, 1333, 295, 264, 3832, 551, 281, 360, 337, 746, 411, 364, 2657, 17784, 2316, 13, 51860, 51860], "temperature": 0.0, "avg_logprob": -0.12011041063250917, "compression_ratio": 1.7864406779661017, "no_speech_prob": 9.817916179599706e-06}, {"id": 48, "seek": 19608, "start": 208.12, "end": 210.72000000000003, "text": " vision data sets.", "tokens": [50364, 411, 483, 16949, 337, 439, 428, 1412, 30, 50458, 50458, 1545, 360, 291, 754, 528, 281, 7962, 341, 2302, 1622, 295, 2132, 30, 50616, 50616, 1545, 406, 445, 483, 439, 264, 16949, 30, 50730, 50730, 407, 286, 630, 341, 1359, 5380, 689, 286, 43288, 264, 2372, 295, 32675, 300, 321, 362, 337, 50966, 50966, 5201, 1412, 6352, 13, 51096, 51096, 407, 437, 286, 630, 307, 1936, 286, 2956, 412, 439, 264, 5267, 597, 362, 5472, 278, 9002, 13, 51345, 51345, 400, 370, 613, 366, 5267, 689, 291, 458, 437, 733, 295, 10392, 366, 294, 264, 3256, 293, 291, 51554, 51554, 611, 362, 257, 2424, 10117, 926, 552, 13, 51652, 51652, 400, 341, 307, 1333, 295, 264, 3832, 551, 281, 360, 337, 746, 411, 364, 2657, 17784, 2316, 13, 51860, 51860], "temperature": 0.0, "avg_logprob": -0.12011041063250917, "compression_ratio": 1.7864406779661017, "no_speech_prob": 9.817916179599706e-06}, {"id": 49, "seek": 19608, "start": 210.72000000000003, "end": 215.70000000000002, "text": " So what I did is basically I looked at all the images which have bounding boxes.", "tokens": [50364, 411, 483, 16949, 337, 439, 428, 1412, 30, 50458, 50458, 1545, 360, 291, 754, 528, 281, 7962, 341, 2302, 1622, 295, 2132, 30, 50616, 50616, 1545, 406, 445, 483, 439, 264, 16949, 30, 50730, 50730, 407, 286, 630, 341, 1359, 5380, 689, 286, 43288, 264, 2372, 295, 32675, 300, 321, 362, 337, 50966, 50966, 5201, 1412, 6352, 13, 51096, 51096, 407, 437, 286, 630, 307, 1936, 286, 2956, 412, 439, 264, 5267, 597, 362, 5472, 278, 9002, 13, 51345, 51345, 400, 370, 613, 366, 5267, 689, 291, 458, 437, 733, 295, 10392, 366, 294, 264, 3256, 293, 291, 51554, 51554, 611, 362, 257, 2424, 10117, 926, 552, 13, 51652, 51652, 400, 341, 307, 1333, 295, 264, 3832, 551, 281, 360, 337, 746, 411, 364, 2657, 17784, 2316, 13, 51860, 51860], "temperature": 0.0, "avg_logprob": -0.12011041063250917, "compression_ratio": 1.7864406779661017, "no_speech_prob": 9.817916179599706e-06}, {"id": 50, "seek": 19608, "start": 215.70000000000002, "end": 219.88000000000002, "text": " And so these are images where you know what kind of concepts are in the image and you", "tokens": [50364, 411, 483, 16949, 337, 439, 428, 1412, 30, 50458, 50458, 1545, 360, 291, 754, 528, 281, 7962, 341, 2302, 1622, 295, 2132, 30, 50616, 50616, 1545, 406, 445, 483, 439, 264, 16949, 30, 50730, 50730, 407, 286, 630, 341, 1359, 5380, 689, 286, 43288, 264, 2372, 295, 32675, 300, 321, 362, 337, 50966, 50966, 5201, 1412, 6352, 13, 51096, 51096, 407, 437, 286, 630, 307, 1936, 286, 2956, 412, 439, 264, 5267, 597, 362, 5472, 278, 9002, 13, 51345, 51345, 400, 370, 613, 366, 5267, 689, 291, 458, 437, 733, 295, 10392, 366, 294, 264, 3256, 293, 291, 51554, 51554, 611, 362, 257, 2424, 10117, 926, 552, 13, 51652, 51652, 400, 341, 307, 1333, 295, 264, 3832, 551, 281, 360, 337, 746, 411, 364, 2657, 17784, 2316, 13, 51860, 51860], "temperature": 0.0, "avg_logprob": -0.12011041063250917, "compression_ratio": 1.7864406779661017, "no_speech_prob": 9.817916179599706e-06}, {"id": 51, "seek": 19608, "start": 219.88000000000002, "end": 221.84, "text": " also have a box drawn around them.", "tokens": [50364, 411, 483, 16949, 337, 439, 428, 1412, 30, 50458, 50458, 1545, 360, 291, 754, 528, 281, 7962, 341, 2302, 1622, 295, 2132, 30, 50616, 50616, 1545, 406, 445, 483, 439, 264, 16949, 30, 50730, 50730, 407, 286, 630, 341, 1359, 5380, 689, 286, 43288, 264, 2372, 295, 32675, 300, 321, 362, 337, 50966, 50966, 5201, 1412, 6352, 13, 51096, 51096, 407, 437, 286, 630, 307, 1936, 286, 2956, 412, 439, 264, 5267, 597, 362, 5472, 278, 9002, 13, 51345, 51345, 400, 370, 613, 366, 5267, 689, 291, 458, 437, 733, 295, 10392, 366, 294, 264, 3256, 293, 291, 51554, 51554, 611, 362, 257, 2424, 10117, 926, 552, 13, 51652, 51652, 400, 341, 307, 1333, 295, 264, 3832, 551, 281, 360, 337, 746, 411, 364, 2657, 17784, 2316, 13, 51860, 51860], "temperature": 0.0, "avg_logprob": -0.12011041063250917, "compression_ratio": 1.7864406779661017, "no_speech_prob": 9.817916179599706e-06}, {"id": 52, "seek": 19608, "start": 221.84, "end": 226.0, "text": " And this is sort of the standard thing to do for something like an object detection model.", "tokens": [50364, 411, 483, 16949, 337, 439, 428, 1412, 30, 50458, 50458, 1545, 360, 291, 754, 528, 281, 7962, 341, 2302, 1622, 295, 2132, 30, 50616, 50616, 1545, 406, 445, 483, 439, 264, 16949, 30, 50730, 50730, 407, 286, 630, 341, 1359, 5380, 689, 286, 43288, 264, 2372, 295, 32675, 300, 321, 362, 337, 50966, 50966, 5201, 1412, 6352, 13, 51096, 51096, 407, 437, 286, 630, 307, 1936, 286, 2956, 412, 439, 264, 5267, 597, 362, 5472, 278, 9002, 13, 51345, 51345, 400, 370, 613, 366, 5267, 689, 291, 458, 437, 733, 295, 10392, 366, 294, 264, 3256, 293, 291, 51554, 51554, 611, 362, 257, 2424, 10117, 926, 552, 13, 51652, 51652, 400, 341, 307, 1333, 295, 264, 3832, 551, 281, 360, 337, 746, 411, 364, 2657, 17784, 2316, 13, 51860, 51860], "temperature": 0.0, "avg_logprob": -0.12011041063250917, "compression_ratio": 1.7864406779661017, "no_speech_prob": 9.817916179599706e-06}, {"id": 53, "seek": 22600, "start": 226.0, "end": 229.24, "text": " So if you look at all the data sets in vision that have bounding boxes, you'll get roughly", "tokens": [50364, 407, 498, 291, 574, 412, 439, 264, 1412, 6352, 294, 5201, 300, 362, 5472, 278, 9002, 11, 291, 603, 483, 9810, 50526, 50526, 466, 257, 2459, 420, 370, 5267, 13, 50628, 50628, 823, 498, 291, 5789, 341, 25534, 293, 291, 584, 300, 11, 1392, 11, 286, 500, 380, 534, 1127, 466, 689, 50852, 50852, 264, 2657, 307, 6870, 13, 50902, 50902, 1057, 286, 1127, 466, 307, 437, 6565, 366, 1974, 294, 264, 3256, 13, 51142, 51142, 400, 370, 498, 291, 5789, 300, 25534, 11, 291, 4258, 483, 364, 1668, 295, 15668, 544, 1412, 13, 51358, 51358, 407, 291, 1936, 483, 466, 3499, 2459, 5267, 420, 370, 13, 51608, 51608, 823, 498, 291, 3052, 1333, 295, 5789, 341, 25534, 293, 291, 584, 300, 286, 500, 380, 534, 1127, 466, 51848, 51848], "temperature": 0.0, "avg_logprob": -0.1642216769131747, "compression_ratio": 1.9444444444444444, "no_speech_prob": 2.014497840718832e-05}, {"id": 54, "seek": 22600, "start": 229.24, "end": 231.28, "text": " about a million or so images.", "tokens": [50364, 407, 498, 291, 574, 412, 439, 264, 1412, 6352, 294, 5201, 300, 362, 5472, 278, 9002, 11, 291, 603, 483, 9810, 50526, 50526, 466, 257, 2459, 420, 370, 5267, 13, 50628, 50628, 823, 498, 291, 5789, 341, 25534, 293, 291, 584, 300, 11, 1392, 11, 286, 500, 380, 534, 1127, 466, 689, 50852, 50852, 264, 2657, 307, 6870, 13, 50902, 50902, 1057, 286, 1127, 466, 307, 437, 6565, 366, 1974, 294, 264, 3256, 13, 51142, 51142, 400, 370, 498, 291, 5789, 300, 25534, 11, 291, 4258, 483, 364, 1668, 295, 15668, 544, 1412, 13, 51358, 51358, 407, 291, 1936, 483, 466, 3499, 2459, 5267, 420, 370, 13, 51608, 51608, 823, 498, 291, 3052, 1333, 295, 5789, 341, 25534, 293, 291, 584, 300, 286, 500, 380, 534, 1127, 466, 51848, 51848], "temperature": 0.0, "avg_logprob": -0.1642216769131747, "compression_ratio": 1.9444444444444444, "no_speech_prob": 2.014497840718832e-05}, {"id": 55, "seek": 22600, "start": 231.28, "end": 235.76, "text": " Now if you relax this constraint and you say that, okay, I don't really care about where", "tokens": [50364, 407, 498, 291, 574, 412, 439, 264, 1412, 6352, 294, 5201, 300, 362, 5472, 278, 9002, 11, 291, 603, 483, 9810, 50526, 50526, 466, 257, 2459, 420, 370, 5267, 13, 50628, 50628, 823, 498, 291, 5789, 341, 25534, 293, 291, 584, 300, 11, 1392, 11, 286, 500, 380, 534, 1127, 466, 689, 50852, 50852, 264, 2657, 307, 6870, 13, 50902, 50902, 1057, 286, 1127, 466, 307, 437, 6565, 366, 1974, 294, 264, 3256, 13, 51142, 51142, 400, 370, 498, 291, 5789, 300, 25534, 11, 291, 4258, 483, 364, 1668, 295, 15668, 544, 1412, 13, 51358, 51358, 407, 291, 1936, 483, 466, 3499, 2459, 5267, 420, 370, 13, 51608, 51608, 823, 498, 291, 3052, 1333, 295, 5789, 341, 25534, 293, 291, 584, 300, 286, 500, 380, 534, 1127, 466, 51848, 51848], "temperature": 0.0, "avg_logprob": -0.1642216769131747, "compression_ratio": 1.9444444444444444, "no_speech_prob": 2.014497840718832e-05}, {"id": 56, "seek": 22600, "start": 235.76, "end": 236.76, "text": " the object is located.", "tokens": [50364, 407, 498, 291, 574, 412, 439, 264, 1412, 6352, 294, 5201, 300, 362, 5472, 278, 9002, 11, 291, 603, 483, 9810, 50526, 50526, 466, 257, 2459, 420, 370, 5267, 13, 50628, 50628, 823, 498, 291, 5789, 341, 25534, 293, 291, 584, 300, 11, 1392, 11, 286, 500, 380, 534, 1127, 466, 689, 50852, 50852, 264, 2657, 307, 6870, 13, 50902, 50902, 1057, 286, 1127, 466, 307, 437, 6565, 366, 1974, 294, 264, 3256, 13, 51142, 51142, 400, 370, 498, 291, 5789, 300, 25534, 11, 291, 4258, 483, 364, 1668, 295, 15668, 544, 1412, 13, 51358, 51358, 407, 291, 1936, 483, 466, 3499, 2459, 5267, 420, 370, 13, 51608, 51608, 823, 498, 291, 3052, 1333, 295, 5789, 341, 25534, 293, 291, 584, 300, 286, 500, 380, 534, 1127, 466, 51848, 51848], "temperature": 0.0, "avg_logprob": -0.1642216769131747, "compression_ratio": 1.9444444444444444, "no_speech_prob": 2.014497840718832e-05}, {"id": 57, "seek": 22600, "start": 236.76, "end": 241.56, "text": " All I care about is what objects are present in the image.", "tokens": [50364, 407, 498, 291, 574, 412, 439, 264, 1412, 6352, 294, 5201, 300, 362, 5472, 278, 9002, 11, 291, 603, 483, 9810, 50526, 50526, 466, 257, 2459, 420, 370, 5267, 13, 50628, 50628, 823, 498, 291, 5789, 341, 25534, 293, 291, 584, 300, 11, 1392, 11, 286, 500, 380, 534, 1127, 466, 689, 50852, 50852, 264, 2657, 307, 6870, 13, 50902, 50902, 1057, 286, 1127, 466, 307, 437, 6565, 366, 1974, 294, 264, 3256, 13, 51142, 51142, 400, 370, 498, 291, 5789, 300, 25534, 11, 291, 4258, 483, 364, 1668, 295, 15668, 544, 1412, 13, 51358, 51358, 407, 291, 1936, 483, 466, 3499, 2459, 5267, 420, 370, 13, 51608, 51608, 823, 498, 291, 3052, 1333, 295, 5789, 341, 25534, 293, 291, 584, 300, 286, 500, 380, 534, 1127, 466, 51848, 51848], "temperature": 0.0, "avg_logprob": -0.1642216769131747, "compression_ratio": 1.9444444444444444, "no_speech_prob": 2.014497840718832e-05}, {"id": 58, "seek": 22600, "start": 241.56, "end": 245.88, "text": " And so if you relax that constraint, you immediately get an order of magnitude more data.", "tokens": [50364, 407, 498, 291, 574, 412, 439, 264, 1412, 6352, 294, 5201, 300, 362, 5472, 278, 9002, 11, 291, 603, 483, 9810, 50526, 50526, 466, 257, 2459, 420, 370, 5267, 13, 50628, 50628, 823, 498, 291, 5789, 341, 25534, 293, 291, 584, 300, 11, 1392, 11, 286, 500, 380, 534, 1127, 466, 689, 50852, 50852, 264, 2657, 307, 6870, 13, 50902, 50902, 1057, 286, 1127, 466, 307, 437, 6565, 366, 1974, 294, 264, 3256, 13, 51142, 51142, 400, 370, 498, 291, 5789, 300, 25534, 11, 291, 4258, 483, 364, 1668, 295, 15668, 544, 1412, 13, 51358, 51358, 407, 291, 1936, 483, 466, 3499, 2459, 5267, 420, 370, 13, 51608, 51608, 823, 498, 291, 3052, 1333, 295, 5789, 341, 25534, 293, 291, 584, 300, 286, 500, 380, 534, 1127, 466, 51848, 51848], "temperature": 0.0, "avg_logprob": -0.1642216769131747, "compression_ratio": 1.9444444444444444, "no_speech_prob": 2.014497840718832e-05}, {"id": 59, "seek": 22600, "start": 245.88, "end": 250.88, "text": " So you basically get about 14 million images or so.", "tokens": [50364, 407, 498, 291, 574, 412, 439, 264, 1412, 6352, 294, 5201, 300, 362, 5472, 278, 9002, 11, 291, 603, 483, 9810, 50526, 50526, 466, 257, 2459, 420, 370, 5267, 13, 50628, 50628, 823, 498, 291, 5789, 341, 25534, 293, 291, 584, 300, 11, 1392, 11, 286, 500, 380, 534, 1127, 466, 689, 50852, 50852, 264, 2657, 307, 6870, 13, 50902, 50902, 1057, 286, 1127, 466, 307, 437, 6565, 366, 1974, 294, 264, 3256, 13, 51142, 51142, 400, 370, 498, 291, 5789, 300, 25534, 11, 291, 4258, 483, 364, 1668, 295, 15668, 544, 1412, 13, 51358, 51358, 407, 291, 1936, 483, 466, 3499, 2459, 5267, 420, 370, 13, 51608, 51608, 823, 498, 291, 3052, 1333, 295, 5789, 341, 25534, 293, 291, 584, 300, 286, 500, 380, 534, 1127, 466, 51848, 51848], "temperature": 0.0, "avg_logprob": -0.1642216769131747, "compression_ratio": 1.9444444444444444, "no_speech_prob": 2.014497840718832e-05}, {"id": 60, "seek": 22600, "start": 250.88, "end": 255.68, "text": " Now if you further sort of relax this constraint and you say that I don't really care about", "tokens": [50364, 407, 498, 291, 574, 412, 439, 264, 1412, 6352, 294, 5201, 300, 362, 5472, 278, 9002, 11, 291, 603, 483, 9810, 50526, 50526, 466, 257, 2459, 420, 370, 5267, 13, 50628, 50628, 823, 498, 291, 5789, 341, 25534, 293, 291, 584, 300, 11, 1392, 11, 286, 500, 380, 534, 1127, 466, 689, 50852, 50852, 264, 2657, 307, 6870, 13, 50902, 50902, 1057, 286, 1127, 466, 307, 437, 6565, 366, 1974, 294, 264, 3256, 13, 51142, 51142, 400, 370, 498, 291, 5789, 300, 25534, 11, 291, 4258, 483, 364, 1668, 295, 15668, 544, 1412, 13, 51358, 51358, 407, 291, 1936, 483, 466, 3499, 2459, 5267, 420, 370, 13, 51608, 51608, 823, 498, 291, 3052, 1333, 295, 5789, 341, 25534, 293, 291, 584, 300, 286, 500, 380, 534, 1127, 466, 51848, 51848], "temperature": 0.0, "avg_logprob": -0.1642216769131747, "compression_ratio": 1.9444444444444444, "no_speech_prob": 2.014497840718832e-05}, {"id": 61, "seek": 25568, "start": 255.68, "end": 262.44, "text": " this image level supervision either, all I care about is internet pictures that are present.", "tokens": [50364, 341, 3256, 1496, 32675, 2139, 11, 439, 286, 1127, 466, 307, 4705, 5242, 300, 366, 1974, 13, 50702, 50702, 509, 603, 483, 1936, 466, 1732, 9470, 295, 15668, 544, 2372, 295, 1412, 13, 50985, 50985, 400, 370, 498, 291, 574, 412, 341, 7542, 586, 11, 291, 393, 536, 4258, 300, 264, 2372, 295, 1412, 300, 51220, 51220, 321, 362, 11, 597, 307, 21335, 754, 412, 257, 5472, 278, 2424, 420, 364, 3256, 1496, 307, 1936, 1825, 51454, 51454, 5347, 281, 437, 5267, 2514, 294, 264, 4705, 4373, 13, 51702, 51702], "temperature": 0.0, "avg_logprob": -0.13004629508308743, "compression_ratio": 1.6779661016949152, "no_speech_prob": 7.296230705833295e-06}, {"id": 62, "seek": 25568, "start": 262.44, "end": 268.1, "text": " You'll get basically about five orders of magnitude more amount of data.", "tokens": [50364, 341, 3256, 1496, 32675, 2139, 11, 439, 286, 1127, 466, 307, 4705, 5242, 300, 366, 1974, 13, 50702, 50702, 509, 603, 483, 1936, 466, 1732, 9470, 295, 15668, 544, 2372, 295, 1412, 13, 50985, 50985, 400, 370, 498, 291, 574, 412, 341, 7542, 586, 11, 291, 393, 536, 4258, 300, 264, 2372, 295, 1412, 300, 51220, 51220, 321, 362, 11, 597, 307, 21335, 754, 412, 257, 5472, 278, 2424, 420, 364, 3256, 1496, 307, 1936, 1825, 51454, 51454, 5347, 281, 437, 5267, 2514, 294, 264, 4705, 4373, 13, 51702, 51702], "temperature": 0.0, "avg_logprob": -0.13004629508308743, "compression_ratio": 1.6779661016949152, "no_speech_prob": 7.296230705833295e-06}, {"id": 63, "seek": 25568, "start": 268.1, "end": 272.8, "text": " And so if you look at this plot now, you can see immediately that the amount of data that", "tokens": [50364, 341, 3256, 1496, 32675, 2139, 11, 439, 286, 1127, 466, 307, 4705, 5242, 300, 366, 1974, 13, 50702, 50702, 509, 603, 483, 1936, 466, 1732, 9470, 295, 15668, 544, 2372, 295, 1412, 13, 50985, 50985, 400, 370, 498, 291, 574, 412, 341, 7542, 586, 11, 291, 393, 536, 4258, 300, 264, 2372, 295, 1412, 300, 51220, 51220, 321, 362, 11, 597, 307, 21335, 754, 412, 257, 5472, 278, 2424, 420, 364, 3256, 1496, 307, 1936, 1825, 51454, 51454, 5347, 281, 437, 5267, 2514, 294, 264, 4705, 4373, 13, 51702, 51702], "temperature": 0.0, "avg_logprob": -0.13004629508308743, "compression_ratio": 1.6779661016949152, "no_speech_prob": 7.296230705833295e-06}, {"id": 64, "seek": 25568, "start": 272.8, "end": 277.48, "text": " we have, which is labeled even at a bounding box or an image level is basically nothing", "tokens": [50364, 341, 3256, 1496, 32675, 2139, 11, 439, 286, 1127, 466, 307, 4705, 5242, 300, 366, 1974, 13, 50702, 50702, 509, 603, 483, 1936, 466, 1732, 9470, 295, 15668, 544, 2372, 295, 1412, 13, 50985, 50985, 400, 370, 498, 291, 574, 412, 341, 7542, 586, 11, 291, 393, 536, 4258, 300, 264, 2372, 295, 1412, 300, 51220, 51220, 321, 362, 11, 597, 307, 21335, 754, 412, 257, 5472, 278, 2424, 420, 364, 3256, 1496, 307, 1936, 1825, 51454, 51454, 5347, 281, 437, 5267, 2514, 294, 264, 4705, 4373, 13, 51702, 51702], "temperature": 0.0, "avg_logprob": -0.13004629508308743, "compression_ratio": 1.6779661016949152, "no_speech_prob": 7.296230705833295e-06}, {"id": 65, "seek": 25568, "start": 277.48, "end": 282.44, "text": " compared to what images exist in the internet scale.", "tokens": [50364, 341, 3256, 1496, 32675, 2139, 11, 439, 286, 1127, 466, 307, 4705, 5242, 300, 366, 1974, 13, 50702, 50702, 509, 603, 483, 1936, 466, 1732, 9470, 295, 15668, 544, 2372, 295, 1412, 13, 50985, 50985, 400, 370, 498, 291, 574, 412, 341, 7542, 586, 11, 291, 393, 536, 4258, 300, 264, 2372, 295, 1412, 300, 51220, 51220, 321, 362, 11, 597, 307, 21335, 754, 412, 257, 5472, 278, 2424, 420, 364, 3256, 1496, 307, 1936, 1825, 51454, 51454, 5347, 281, 437, 5267, 2514, 294, 264, 4705, 4373, 13, 51702, 51702], "temperature": 0.0, "avg_logprob": -0.13004629508308743, "compression_ratio": 1.6779661016949152, "no_speech_prob": 7.296230705833295e-06}, {"id": 66, "seek": 28244, "start": 282.44, "end": 287.08, "text": " And I haven't really forgotten these images, like forgotten the bars on the left hand side.", "tokens": [50364, 400, 286, 2378, 380, 534, 11832, 613, 5267, 11, 411, 11832, 264, 10228, 322, 264, 1411, 1011, 1252, 13, 50596, 50596, 467, 311, 445, 300, 436, 2584, 11596, 13, 50690, 50690, 400, 291, 534, 643, 281, 652, 341, 7542, 746, 411, 257, 3565, 7542, 281, 767, 754, 483, 613, 50862, 50862, 10228, 281, 4204, 13, 51026, 51026, 407, 586, 295, 1164, 11, 4705, 5787, 360, 406, 2906, 1203, 466, 264, 1002, 13, 51262, 51262, 821, 366, 721, 300, 534, 3651, 5394, 420, 721, 300, 534, 3651, 661, 4001, 51442, 51442, 17057, 281, 1466, 13, 51509, 51509, 407, 294, 264, 957, 1002, 11, 456, 366, 516, 281, 312, 1400, 544, 721, 300, 291, 767, 1752, 11, 51732, 51732], "temperature": 0.0, "avg_logprob": -0.12204067646956243, "compression_ratio": 1.8392857142857142, "no_speech_prob": 8.013327715161722e-06}, {"id": 67, "seek": 28244, "start": 287.08, "end": 288.96, "text": " It's just that they completely disappear.", "tokens": [50364, 400, 286, 2378, 380, 534, 11832, 613, 5267, 11, 411, 11832, 264, 10228, 322, 264, 1411, 1011, 1252, 13, 50596, 50596, 467, 311, 445, 300, 436, 2584, 11596, 13, 50690, 50690, 400, 291, 534, 643, 281, 652, 341, 7542, 746, 411, 257, 3565, 7542, 281, 767, 754, 483, 613, 50862, 50862, 10228, 281, 4204, 13, 51026, 51026, 407, 586, 295, 1164, 11, 4705, 5787, 360, 406, 2906, 1203, 466, 264, 1002, 13, 51262, 51262, 821, 366, 721, 300, 534, 3651, 5394, 420, 721, 300, 534, 3651, 661, 4001, 51442, 51442, 17057, 281, 1466, 13, 51509, 51509, 407, 294, 264, 957, 1002, 11, 456, 366, 516, 281, 312, 1400, 544, 721, 300, 291, 767, 1752, 11, 51732, 51732], "temperature": 0.0, "avg_logprob": -0.12204067646956243, "compression_ratio": 1.8392857142857142, "no_speech_prob": 8.013327715161722e-06}, {"id": 68, "seek": 28244, "start": 288.96, "end": 292.4, "text": " And you really need to make this plot something like a log plot to actually even get these", "tokens": [50364, 400, 286, 2378, 380, 534, 11832, 613, 5267, 11, 411, 11832, 264, 10228, 322, 264, 1411, 1011, 1252, 13, 50596, 50596, 467, 311, 445, 300, 436, 2584, 11596, 13, 50690, 50690, 400, 291, 534, 643, 281, 652, 341, 7542, 746, 411, 257, 3565, 7542, 281, 767, 754, 483, 613, 50862, 50862, 10228, 281, 4204, 13, 51026, 51026, 407, 586, 295, 1164, 11, 4705, 5787, 360, 406, 2906, 1203, 466, 264, 1002, 13, 51262, 51262, 821, 366, 721, 300, 534, 3651, 5394, 420, 721, 300, 534, 3651, 661, 4001, 51442, 51442, 17057, 281, 1466, 13, 51509, 51509, 407, 294, 264, 957, 1002, 11, 456, 366, 516, 281, 312, 1400, 544, 721, 300, 291, 767, 1752, 11, 51732, 51732], "temperature": 0.0, "avg_logprob": -0.12204067646956243, "compression_ratio": 1.8392857142857142, "no_speech_prob": 8.013327715161722e-06}, {"id": 69, "seek": 28244, "start": 292.4, "end": 295.68, "text": " bars to appear.", "tokens": [50364, 400, 286, 2378, 380, 534, 11832, 613, 5267, 11, 411, 11832, 264, 10228, 322, 264, 1411, 1011, 1252, 13, 50596, 50596, 467, 311, 445, 300, 436, 2584, 11596, 13, 50690, 50690, 400, 291, 534, 643, 281, 652, 341, 7542, 746, 411, 257, 3565, 7542, 281, 767, 754, 483, 613, 50862, 50862, 10228, 281, 4204, 13, 51026, 51026, 407, 586, 295, 1164, 11, 4705, 5787, 360, 406, 2906, 1203, 466, 264, 1002, 13, 51262, 51262, 821, 366, 721, 300, 534, 3651, 5394, 420, 721, 300, 534, 3651, 661, 4001, 51442, 51442, 17057, 281, 1466, 13, 51509, 51509, 407, 294, 264, 957, 1002, 11, 456, 366, 516, 281, 312, 1400, 544, 721, 300, 291, 767, 1752, 11, 51732, 51732], "temperature": 0.0, "avg_logprob": -0.12204067646956243, "compression_ratio": 1.8392857142857142, "no_speech_prob": 8.013327715161722e-06}, {"id": 70, "seek": 28244, "start": 295.68, "end": 300.4, "text": " So now of course, internet photos do not represent everything about the world.", "tokens": [50364, 400, 286, 2378, 380, 534, 11832, 613, 5267, 11, 411, 11832, 264, 10228, 322, 264, 1411, 1011, 1252, 13, 50596, 50596, 467, 311, 445, 300, 436, 2584, 11596, 13, 50690, 50690, 400, 291, 534, 643, 281, 652, 341, 7542, 746, 411, 257, 3565, 7542, 281, 767, 754, 483, 613, 50862, 50862, 10228, 281, 4204, 13, 51026, 51026, 407, 586, 295, 1164, 11, 4705, 5787, 360, 406, 2906, 1203, 466, 264, 1002, 13, 51262, 51262, 821, 366, 721, 300, 534, 3651, 5394, 420, 721, 300, 534, 3651, 661, 4001, 51442, 51442, 17057, 281, 1466, 13, 51509, 51509, 407, 294, 264, 957, 1002, 11, 456, 366, 516, 281, 312, 1400, 544, 721, 300, 291, 767, 1752, 11, 51732, 51732], "temperature": 0.0, "avg_logprob": -0.12204067646956243, "compression_ratio": 1.8392857142857142, "no_speech_prob": 8.013327715161722e-06}, {"id": 71, "seek": 28244, "start": 300.4, "end": 304.0, "text": " There are things that really require motion or things that really require other physical", "tokens": [50364, 400, 286, 2378, 380, 534, 11832, 613, 5267, 11, 411, 11832, 264, 10228, 322, 264, 1411, 1011, 1252, 13, 50596, 50596, 467, 311, 445, 300, 436, 2584, 11596, 13, 50690, 50690, 400, 291, 534, 643, 281, 652, 341, 7542, 746, 411, 257, 3565, 7542, 281, 767, 754, 483, 613, 50862, 50862, 10228, 281, 4204, 13, 51026, 51026, 407, 586, 295, 1164, 11, 4705, 5787, 360, 406, 2906, 1203, 466, 264, 1002, 13, 51262, 51262, 821, 366, 721, 300, 534, 3651, 5394, 420, 721, 300, 534, 3651, 661, 4001, 51442, 51442, 17057, 281, 1466, 13, 51509, 51509, 407, 294, 264, 957, 1002, 11, 456, 366, 516, 281, 312, 1400, 544, 721, 300, 291, 767, 1752, 11, 51732, 51732], "temperature": 0.0, "avg_logprob": -0.12204067646956243, "compression_ratio": 1.8392857142857142, "no_speech_prob": 8.013327715161722e-06}, {"id": 72, "seek": 28244, "start": 304.0, "end": 305.34, "text": " senses to learn.", "tokens": [50364, 400, 286, 2378, 380, 534, 11832, 613, 5267, 11, 411, 11832, 264, 10228, 322, 264, 1411, 1011, 1252, 13, 50596, 50596, 467, 311, 445, 300, 436, 2584, 11596, 13, 50690, 50690, 400, 291, 534, 643, 281, 652, 341, 7542, 746, 411, 257, 3565, 7542, 281, 767, 754, 483, 613, 50862, 50862, 10228, 281, 4204, 13, 51026, 51026, 407, 586, 295, 1164, 11, 4705, 5787, 360, 406, 2906, 1203, 466, 264, 1002, 13, 51262, 51262, 821, 366, 721, 300, 534, 3651, 5394, 420, 721, 300, 534, 3651, 661, 4001, 51442, 51442, 17057, 281, 1466, 13, 51509, 51509, 407, 294, 264, 957, 1002, 11, 456, 366, 516, 281, 312, 1400, 544, 721, 300, 291, 767, 1752, 11, 51732, 51732], "temperature": 0.0, "avg_logprob": -0.12204067646956243, "compression_ratio": 1.8392857142857142, "no_speech_prob": 8.013327715161722e-06}, {"id": 73, "seek": 28244, "start": 305.34, "end": 309.8, "text": " So in the real world, there are going to be far more things that you actually experience,", "tokens": [50364, 400, 286, 2378, 380, 534, 11832, 613, 5267, 11, 411, 11832, 264, 10228, 322, 264, 1411, 1011, 1252, 13, 50596, 50596, 467, 311, 445, 300, 436, 2584, 11596, 13, 50690, 50690, 400, 291, 534, 643, 281, 652, 341, 7542, 746, 411, 257, 3565, 7542, 281, 767, 754, 483, 613, 50862, 50862, 10228, 281, 4204, 13, 51026, 51026, 407, 586, 295, 1164, 11, 4705, 5787, 360, 406, 2906, 1203, 466, 264, 1002, 13, 51262, 51262, 821, 366, 721, 300, 534, 3651, 5394, 420, 721, 300, 534, 3651, 661, 4001, 51442, 51442, 17057, 281, 1466, 13, 51509, 51509, 407, 294, 264, 957, 1002, 11, 456, 366, 516, 281, 312, 1400, 544, 721, 300, 291, 767, 1752, 11, 51732, 51732], "temperature": 0.0, "avg_logprob": -0.12204067646956243, "compression_ratio": 1.8392857142857142, "no_speech_prob": 8.013327715161722e-06}, {"id": 74, "seek": 30980, "start": 309.8, "end": 312.6, "text": " far more sensory inputs that you can get.", "tokens": [50364, 1400, 544, 27233, 15743, 300, 291, 393, 483, 13, 50504, 50504, 400, 309, 311, 534, 1152, 281, 12701, 16949, 337, 439, 341, 1412, 13, 50658, 50658, 400, 797, 11, 281, 829, 721, 294, 4585, 11, 29903, 31890, 11, 597, 307, 445, 3499, 5267, 293, 365, 257, 588, 1359, 50974, 50974, 1230, 295, 10392, 300, 291, 362, 4739, 257, 688, 295, 565, 281, 7645, 13, 51170, 51170, 407, 4448, 40244, 307, 406, 534, 516, 281, 4373, 281, 2139, 439, 295, 4705, 5787, 420, 51392, 51392, 754, 264, 957, 1002, 13, 51548, 51548], "temperature": 0.0, "avg_logprob": -0.12429875199512769, "compression_ratio": 1.5617021276595744, "no_speech_prob": 5.422092272056034e-06}, {"id": 75, "seek": 30980, "start": 312.6, "end": 315.68, "text": " And it's really hard to obtain labels for all this data.", "tokens": [50364, 1400, 544, 27233, 15743, 300, 291, 393, 483, 13, 50504, 50504, 400, 309, 311, 534, 1152, 281, 12701, 16949, 337, 439, 341, 1412, 13, 50658, 50658, 400, 797, 11, 281, 829, 721, 294, 4585, 11, 29903, 31890, 11, 597, 307, 445, 3499, 5267, 293, 365, 257, 588, 1359, 50974, 50974, 1230, 295, 10392, 300, 291, 362, 4739, 257, 688, 295, 565, 281, 7645, 13, 51170, 51170, 407, 4448, 40244, 307, 406, 534, 516, 281, 4373, 281, 2139, 439, 295, 4705, 5787, 420, 51392, 51392, 754, 264, 957, 1002, 13, 51548, 51548], "temperature": 0.0, "avg_logprob": -0.12429875199512769, "compression_ratio": 1.5617021276595744, "no_speech_prob": 5.422092272056034e-06}, {"id": 76, "seek": 30980, "start": 315.68, "end": 322.0, "text": " And again, to put things in perspective, ImageNet, which is just 14 images and with a very small", "tokens": [50364, 1400, 544, 27233, 15743, 300, 291, 393, 483, 13, 50504, 50504, 400, 309, 311, 534, 1152, 281, 12701, 16949, 337, 439, 341, 1412, 13, 50658, 50658, 400, 797, 11, 281, 829, 721, 294, 4585, 11, 29903, 31890, 11, 597, 307, 445, 3499, 5267, 293, 365, 257, 588, 1359, 50974, 50974, 1230, 295, 10392, 300, 291, 362, 4739, 257, 688, 295, 565, 281, 7645, 13, 51170, 51170, 407, 4448, 40244, 307, 406, 534, 516, 281, 4373, 281, 2139, 439, 295, 4705, 5787, 420, 51392, 51392, 754, 264, 957, 1002, 13, 51548, 51548], "temperature": 0.0, "avg_logprob": -0.12429875199512769, "compression_ratio": 1.5617021276595744, "no_speech_prob": 5.422092272056034e-06}, {"id": 77, "seek": 30980, "start": 322.0, "end": 325.92, "text": " number of concepts that you have required a lot of time to label.", "tokens": [50364, 1400, 544, 27233, 15743, 300, 291, 393, 483, 13, 50504, 50504, 400, 309, 311, 534, 1152, 281, 12701, 16949, 337, 439, 341, 1412, 13, 50658, 50658, 400, 797, 11, 281, 829, 721, 294, 4585, 11, 29903, 31890, 11, 597, 307, 445, 3499, 5267, 293, 365, 257, 588, 1359, 50974, 50974, 1230, 295, 10392, 300, 291, 362, 4739, 257, 688, 295, 565, 281, 7645, 13, 51170, 51170, 407, 4448, 40244, 307, 406, 534, 516, 281, 4373, 281, 2139, 439, 295, 4705, 5787, 420, 51392, 51392, 754, 264, 957, 1002, 13, 51548, 51548], "temperature": 0.0, "avg_logprob": -0.12429875199512769, "compression_ratio": 1.5617021276595744, "no_speech_prob": 5.422092272056034e-06}, {"id": 78, "seek": 30980, "start": 325.92, "end": 330.36, "text": " So clearly labeling is not really going to scale to either all of internet photos or", "tokens": [50364, 1400, 544, 27233, 15743, 300, 291, 393, 483, 13, 50504, 50504, 400, 309, 311, 534, 1152, 281, 12701, 16949, 337, 439, 341, 1412, 13, 50658, 50658, 400, 797, 11, 281, 829, 721, 294, 4585, 11, 29903, 31890, 11, 597, 307, 445, 3499, 5267, 293, 365, 257, 588, 1359, 50974, 50974, 1230, 295, 10392, 300, 291, 362, 4739, 257, 688, 295, 565, 281, 7645, 13, 51170, 51170, 407, 4448, 40244, 307, 406, 534, 516, 281, 4373, 281, 2139, 439, 295, 4705, 5787, 420, 51392, 51392, 754, 264, 957, 1002, 13, 51548, 51548], "temperature": 0.0, "avg_logprob": -0.12429875199512769, "compression_ratio": 1.5617021276595744, "no_speech_prob": 5.422092272056034e-06}, {"id": 79, "seek": 30980, "start": 330.36, "end": 333.48, "text": " even the real world.", "tokens": [50364, 1400, 544, 27233, 15743, 300, 291, 393, 483, 13, 50504, 50504, 400, 309, 311, 534, 1152, 281, 12701, 16949, 337, 439, 341, 1412, 13, 50658, 50658, 400, 797, 11, 281, 829, 721, 294, 4585, 11, 29903, 31890, 11, 597, 307, 445, 3499, 5267, 293, 365, 257, 588, 1359, 50974, 50974, 1230, 295, 10392, 300, 291, 362, 4739, 257, 688, 295, 565, 281, 7645, 13, 51170, 51170, 407, 4448, 40244, 307, 406, 534, 516, 281, 4373, 281, 2139, 439, 295, 4705, 5787, 420, 51392, 51392, 754, 264, 957, 1002, 13, 51548, 51548], "temperature": 0.0, "avg_logprob": -0.12429875199512769, "compression_ratio": 1.5617021276595744, "no_speech_prob": 5.422092272056034e-06}, {"id": 80, "seek": 33348, "start": 333.48, "end": 340.36, "text": " So the other problem with labeling is that for complex concepts like video, it's just", "tokens": [50364, 407, 264, 661, 1154, 365, 40244, 307, 300, 337, 3997, 10392, 411, 960, 11, 309, 311, 445, 50708, 50708, 534, 1152, 281, 4373, 40244, 13, 50862, 50862, 440, 1150, 1154, 307, 300, 5892, 10392, 366, 534, 1152, 281, 7645, 13, 51128, 51128, 407, 337, 1365, 11, 341, 307, 472, 295, 264, 3743, 3256, 1412, 6352, 1219, 10137, 338, 12671, 13, 51406, 51406, 400, 670, 510, 11, 321, 393, 536, 300, 498, 291, 574, 412, 264, 3685, 295, 10392, 291, 11441, 11, 456, 51612, 51612, 366, 257, 688, 295, 10392, 300, 366, 370, 5892, 300, 291, 434, 516, 281, 362, 281, 7645, 257, 688, 295, 1412, 51848, 51848], "temperature": 0.0, "avg_logprob": -0.10379968870670424, "compression_ratio": 1.7892561983471074, "no_speech_prob": 2.9479201657522935e-06}, {"id": 81, "seek": 33348, "start": 340.36, "end": 343.44, "text": " really hard to scale labeling.", "tokens": [50364, 407, 264, 661, 1154, 365, 40244, 307, 300, 337, 3997, 10392, 411, 960, 11, 309, 311, 445, 50708, 50708, 534, 1152, 281, 4373, 40244, 13, 50862, 50862, 440, 1150, 1154, 307, 300, 5892, 10392, 366, 534, 1152, 281, 7645, 13, 51128, 51128, 407, 337, 1365, 11, 341, 307, 472, 295, 264, 3743, 3256, 1412, 6352, 1219, 10137, 338, 12671, 13, 51406, 51406, 400, 670, 510, 11, 321, 393, 536, 300, 498, 291, 574, 412, 264, 3685, 295, 10392, 291, 11441, 11, 456, 51612, 51612, 366, 257, 688, 295, 10392, 300, 366, 370, 5892, 300, 291, 434, 516, 281, 362, 281, 7645, 257, 688, 295, 1412, 51848, 51848], "temperature": 0.0, "avg_logprob": -0.10379968870670424, "compression_ratio": 1.7892561983471074, "no_speech_prob": 2.9479201657522935e-06}, {"id": 82, "seek": 33348, "start": 343.44, "end": 348.76, "text": " The second problem is that rare concepts are really hard to label.", "tokens": [50364, 407, 264, 661, 1154, 365, 40244, 307, 300, 337, 3997, 10392, 411, 960, 11, 309, 311, 445, 50708, 50708, 534, 1152, 281, 4373, 40244, 13, 50862, 50862, 440, 1150, 1154, 307, 300, 5892, 10392, 366, 534, 1152, 281, 7645, 13, 51128, 51128, 407, 337, 1365, 11, 341, 307, 472, 295, 264, 3743, 3256, 1412, 6352, 1219, 10137, 338, 12671, 13, 51406, 51406, 400, 670, 510, 11, 321, 393, 536, 300, 498, 291, 574, 412, 264, 3685, 295, 10392, 291, 11441, 11, 456, 51612, 51612, 366, 257, 688, 295, 10392, 300, 366, 370, 5892, 300, 291, 434, 516, 281, 362, 281, 7645, 257, 688, 295, 1412, 51848, 51848], "temperature": 0.0, "avg_logprob": -0.10379968870670424, "compression_ratio": 1.7892561983471074, "no_speech_prob": 2.9479201657522935e-06}, {"id": 83, "seek": 33348, "start": 348.76, "end": 354.32, "text": " So for example, this is one of the popular image data sets called LabelMe.", "tokens": [50364, 407, 264, 661, 1154, 365, 40244, 307, 300, 337, 3997, 10392, 411, 960, 11, 309, 311, 445, 50708, 50708, 534, 1152, 281, 4373, 40244, 13, 50862, 50862, 440, 1150, 1154, 307, 300, 5892, 10392, 366, 534, 1152, 281, 7645, 13, 51128, 51128, 407, 337, 1365, 11, 341, 307, 472, 295, 264, 3743, 3256, 1412, 6352, 1219, 10137, 338, 12671, 13, 51406, 51406, 400, 670, 510, 11, 321, 393, 536, 300, 498, 291, 574, 412, 264, 3685, 295, 10392, 291, 11441, 11, 456, 51612, 51612, 366, 257, 688, 295, 10392, 300, 366, 370, 5892, 300, 291, 434, 516, 281, 362, 281, 7645, 257, 688, 295, 1412, 51848, 51848], "temperature": 0.0, "avg_logprob": -0.10379968870670424, "compression_ratio": 1.7892561983471074, "no_speech_prob": 2.9479201657522935e-06}, {"id": 84, "seek": 33348, "start": 354.32, "end": 358.44, "text": " And over here, we can see that if you look at the kinds of concepts you observe, there", "tokens": [50364, 407, 264, 661, 1154, 365, 40244, 307, 300, 337, 3997, 10392, 411, 960, 11, 309, 311, 445, 50708, 50708, 534, 1152, 281, 4373, 40244, 13, 50862, 50862, 440, 1150, 1154, 307, 300, 5892, 10392, 366, 534, 1152, 281, 7645, 13, 51128, 51128, 407, 337, 1365, 11, 341, 307, 472, 295, 264, 3743, 3256, 1412, 6352, 1219, 10137, 338, 12671, 13, 51406, 51406, 400, 670, 510, 11, 321, 393, 536, 300, 498, 291, 574, 412, 264, 3685, 295, 10392, 291, 11441, 11, 456, 51612, 51612, 366, 257, 688, 295, 10392, 300, 366, 370, 5892, 300, 291, 434, 516, 281, 362, 281, 7645, 257, 688, 295, 1412, 51848, 51848], "temperature": 0.0, "avg_logprob": -0.10379968870670424, "compression_ratio": 1.7892561983471074, "no_speech_prob": 2.9479201657522935e-06}, {"id": 85, "seek": 33348, "start": 358.44, "end": 363.16, "text": " are a lot of concepts that are so rare that you're going to have to label a lot of data", "tokens": [50364, 407, 264, 661, 1154, 365, 40244, 307, 300, 337, 3997, 10392, 411, 960, 11, 309, 311, 445, 50708, 50708, 534, 1152, 281, 4373, 40244, 13, 50862, 50862, 440, 1150, 1154, 307, 300, 5892, 10392, 366, 534, 1152, 281, 7645, 13, 51128, 51128, 407, 337, 1365, 11, 341, 307, 472, 295, 264, 3743, 3256, 1412, 6352, 1219, 10137, 338, 12671, 13, 51406, 51406, 400, 670, 510, 11, 321, 393, 536, 300, 498, 291, 574, 412, 264, 3685, 295, 10392, 291, 11441, 11, 456, 51612, 51612, 366, 257, 688, 295, 10392, 300, 366, 370, 5892, 300, 291, 434, 516, 281, 362, 281, 7645, 257, 688, 295, 1412, 51848, 51848], "temperature": 0.0, "avg_logprob": -0.10379968870670424, "compression_ratio": 1.7892561983471074, "no_speech_prob": 2.9479201657522935e-06}, {"id": 86, "seek": 36316, "start": 363.16, "end": 366.6, "text": " to even get a few instances of these concepts.", "tokens": [50364, 281, 754, 483, 257, 1326, 14519, 295, 613, 10392, 13, 50536, 50536, 407, 294, 341, 1412, 992, 11, 1266, 4, 295, 264, 5359, 2696, 337, 544, 813, 28876, 4, 295, 264, 1412, 11, 597, 1217, 50860, 50860, 5112, 291, 300, 294, 1668, 281, 1333, 295, 4373, 40244, 281, 544, 293, 544, 10392, 11, 291, 603, 643, 257, 688, 51150, 51150, 293, 688, 544, 1412, 365, 588, 15739, 3807, 11247, 13, 51272, 51272, 407, 341, 307, 1333, 295, 264, 3832, 938, 6838, 1154, 13, 51526, 51526, 400, 295, 1164, 11, 659, 12, 17227, 1760, 307, 406, 1009, 264, 558, 551, 281, 360, 13, 51746, 51746], "temperature": 0.0, "avg_logprob": -0.10116085916195276, "compression_ratio": 1.6487603305785123, "no_speech_prob": 1.5206115676846821e-05}, {"id": 87, "seek": 36316, "start": 366.6, "end": 373.08000000000004, "text": " So in this data set, 10% of the classes account for more than 93% of the data, which already", "tokens": [50364, 281, 754, 483, 257, 1326, 14519, 295, 613, 10392, 13, 50536, 50536, 407, 294, 341, 1412, 992, 11, 1266, 4, 295, 264, 5359, 2696, 337, 544, 813, 28876, 4, 295, 264, 1412, 11, 597, 1217, 50860, 50860, 5112, 291, 300, 294, 1668, 281, 1333, 295, 4373, 40244, 281, 544, 293, 544, 10392, 11, 291, 603, 643, 257, 688, 51150, 51150, 293, 688, 544, 1412, 365, 588, 15739, 3807, 11247, 13, 51272, 51272, 407, 341, 307, 1333, 295, 264, 3832, 938, 6838, 1154, 13, 51526, 51526, 400, 295, 1164, 11, 659, 12, 17227, 1760, 307, 406, 1009, 264, 558, 551, 281, 360, 13, 51746, 51746], "temperature": 0.0, "avg_logprob": -0.10116085916195276, "compression_ratio": 1.6487603305785123, "no_speech_prob": 1.5206115676846821e-05}, {"id": 88, "seek": 36316, "start": 373.08000000000004, "end": 378.88000000000005, "text": " tells you that in order to sort of scale labeling to more and more concepts, you'll need a lot", "tokens": [50364, 281, 754, 483, 257, 1326, 14519, 295, 613, 10392, 13, 50536, 50536, 407, 294, 341, 1412, 992, 11, 1266, 4, 295, 264, 5359, 2696, 337, 544, 813, 28876, 4, 295, 264, 1412, 11, 597, 1217, 50860, 50860, 5112, 291, 300, 294, 1668, 281, 1333, 295, 4373, 40244, 281, 544, 293, 544, 10392, 11, 291, 603, 643, 257, 688, 51150, 51150, 293, 688, 544, 1412, 365, 588, 15739, 3807, 11247, 13, 51272, 51272, 407, 341, 307, 1333, 295, 264, 3832, 938, 6838, 1154, 13, 51526, 51526, 400, 295, 1164, 11, 659, 12, 17227, 1760, 307, 406, 1009, 264, 558, 551, 281, 360, 13, 51746, 51746], "temperature": 0.0, "avg_logprob": -0.10116085916195276, "compression_ratio": 1.6487603305785123, "no_speech_prob": 1.5206115676846821e-05}, {"id": 89, "seek": 36316, "start": 378.88000000000005, "end": 381.32000000000005, "text": " and lot more data with very diminishing returns.", "tokens": [50364, 281, 754, 483, 257, 1326, 14519, 295, 613, 10392, 13, 50536, 50536, 407, 294, 341, 1412, 992, 11, 1266, 4, 295, 264, 5359, 2696, 337, 544, 813, 28876, 4, 295, 264, 1412, 11, 597, 1217, 50860, 50860, 5112, 291, 300, 294, 1668, 281, 1333, 295, 4373, 40244, 281, 544, 293, 544, 10392, 11, 291, 603, 643, 257, 688, 51150, 51150, 293, 688, 544, 1412, 365, 588, 15739, 3807, 11247, 13, 51272, 51272, 407, 341, 307, 1333, 295, 264, 3832, 938, 6838, 1154, 13, 51526, 51526, 400, 295, 1164, 11, 659, 12, 17227, 1760, 307, 406, 1009, 264, 558, 551, 281, 360, 13, 51746, 51746], "temperature": 0.0, "avg_logprob": -0.10116085916195276, "compression_ratio": 1.6487603305785123, "no_speech_prob": 1.5206115676846821e-05}, {"id": 90, "seek": 36316, "start": 381.32000000000005, "end": 386.40000000000003, "text": " So this is sort of the standard long tail problem.", "tokens": [50364, 281, 754, 483, 257, 1326, 14519, 295, 613, 10392, 13, 50536, 50536, 407, 294, 341, 1412, 992, 11, 1266, 4, 295, 264, 5359, 2696, 337, 544, 813, 28876, 4, 295, 264, 1412, 11, 597, 1217, 50860, 50860, 5112, 291, 300, 294, 1668, 281, 1333, 295, 4373, 40244, 281, 544, 293, 544, 10392, 11, 291, 603, 643, 257, 688, 51150, 51150, 293, 688, 544, 1412, 365, 588, 15739, 3807, 11247, 13, 51272, 51272, 407, 341, 307, 1333, 295, 264, 3832, 938, 6838, 1154, 13, 51526, 51526, 400, 295, 1164, 11, 659, 12, 17227, 1760, 307, 406, 1009, 264, 558, 551, 281, 360, 13, 51746, 51746], "temperature": 0.0, "avg_logprob": -0.10116085916195276, "compression_ratio": 1.6487603305785123, "no_speech_prob": 1.5206115676846821e-05}, {"id": 91, "seek": 36316, "start": 386.40000000000003, "end": 390.8, "text": " And of course, pre-training is not always the right thing to do.", "tokens": [50364, 281, 754, 483, 257, 1326, 14519, 295, 613, 10392, 13, 50536, 50536, 407, 294, 341, 1412, 992, 11, 1266, 4, 295, 264, 5359, 2696, 337, 544, 813, 28876, 4, 295, 264, 1412, 11, 597, 1217, 50860, 50860, 5112, 291, 300, 294, 1668, 281, 1333, 295, 4373, 40244, 281, 544, 293, 544, 10392, 11, 291, 603, 643, 257, 688, 51150, 51150, 293, 688, 544, 1412, 365, 588, 15739, 3807, 11247, 13, 51272, 51272, 407, 341, 307, 1333, 295, 264, 3832, 938, 6838, 1154, 13, 51526, 51526, 400, 295, 1164, 11, 659, 12, 17227, 1760, 307, 406, 1009, 264, 558, 551, 281, 360, 13, 51746, 51746], "temperature": 0.0, "avg_logprob": -0.10116085916195276, "compression_ratio": 1.6487603305785123, "no_speech_prob": 1.5206115676846821e-05}, {"id": 92, "seek": 39080, "start": 390.8, "end": 395.64, "text": " For example, if you just completely change your domain to now move into say medical imaging,", "tokens": [50364, 1171, 1365, 11, 498, 291, 445, 2584, 1319, 428, 9274, 281, 586, 1286, 666, 584, 4625, 25036, 11, 50606, 50606, 309, 311, 406, 1850, 1968, 3256, 2533, 659, 12, 17227, 1760, 307, 264, 558, 1333, 295, 551, 337, 341, 5633, 13, 50850, 50850, 759, 291, 360, 406, 458, 1333, 295, 264, 30621, 5633, 257, 4059, 72, 11, 577, 360, 291, 2500, 257, 955, 1412, 51054, 51054, 992, 293, 577, 360, 291, 360, 341, 2302, 659, 12, 17227, 1760, 30621, 5633, 2489, 15164, 6782, 30, 51362, 51362, 407, 2698, 12, 48172, 24420, 2539, 1333, 295, 1487, 294, 1296, 293, 309, 9898, 281, 976, 291, 364, 18873, 51596, 51596], "temperature": 0.0, "avg_logprob": -0.1378577608580983, "compression_ratio": 1.72265625, "no_speech_prob": 1.7777700122678652e-05}, {"id": 93, "seek": 39080, "start": 395.64, "end": 400.52000000000004, "text": " it's not clear whether image net pre-training is the right sort of thing for this task.", "tokens": [50364, 1171, 1365, 11, 498, 291, 445, 2584, 1319, 428, 9274, 281, 586, 1286, 666, 584, 4625, 25036, 11, 50606, 50606, 309, 311, 406, 1850, 1968, 3256, 2533, 659, 12, 17227, 1760, 307, 264, 558, 1333, 295, 551, 337, 341, 5633, 13, 50850, 50850, 759, 291, 360, 406, 458, 1333, 295, 264, 30621, 5633, 257, 4059, 72, 11, 577, 360, 291, 2500, 257, 955, 1412, 51054, 51054, 992, 293, 577, 360, 291, 360, 341, 2302, 659, 12, 17227, 1760, 30621, 5633, 2489, 15164, 6782, 30, 51362, 51362, 407, 2698, 12, 48172, 24420, 2539, 1333, 295, 1487, 294, 1296, 293, 309, 9898, 281, 976, 291, 364, 18873, 51596, 51596], "temperature": 0.0, "avg_logprob": -0.1378577608580983, "compression_ratio": 1.72265625, "no_speech_prob": 1.7777700122678652e-05}, {"id": 94, "seek": 39080, "start": 400.52000000000004, "end": 404.6, "text": " If you do not know sort of the downstream task a priori, how do you collect a big data", "tokens": [50364, 1171, 1365, 11, 498, 291, 445, 2584, 1319, 428, 9274, 281, 586, 1286, 666, 584, 4625, 25036, 11, 50606, 50606, 309, 311, 406, 1850, 1968, 3256, 2533, 659, 12, 17227, 1760, 307, 264, 558, 1333, 295, 551, 337, 341, 5633, 13, 50850, 50850, 759, 291, 360, 406, 458, 1333, 295, 264, 30621, 5633, 257, 4059, 72, 11, 577, 360, 291, 2500, 257, 955, 1412, 51054, 51054, 992, 293, 577, 360, 291, 360, 341, 2302, 659, 12, 17227, 1760, 30621, 5633, 2489, 15164, 6782, 30, 51362, 51362, 407, 2698, 12, 48172, 24420, 2539, 1333, 295, 1487, 294, 1296, 293, 309, 9898, 281, 976, 291, 364, 18873, 51596, 51596], "temperature": 0.0, "avg_logprob": -0.1378577608580983, "compression_ratio": 1.72265625, "no_speech_prob": 1.7777700122678652e-05}, {"id": 95, "seek": 39080, "start": 404.6, "end": 410.76, "text": " set and how do you do this entire pre-training downstream task fine tuning recipe?", "tokens": [50364, 1171, 1365, 11, 498, 291, 445, 2584, 1319, 428, 9274, 281, 586, 1286, 666, 584, 4625, 25036, 11, 50606, 50606, 309, 311, 406, 1850, 1968, 3256, 2533, 659, 12, 17227, 1760, 307, 264, 558, 1333, 295, 551, 337, 341, 5633, 13, 50850, 50850, 759, 291, 360, 406, 458, 1333, 295, 264, 30621, 5633, 257, 4059, 72, 11, 577, 360, 291, 2500, 257, 955, 1412, 51054, 51054, 992, 293, 577, 360, 291, 360, 341, 2302, 659, 12, 17227, 1760, 30621, 5633, 2489, 15164, 6782, 30, 51362, 51362, 407, 2698, 12, 48172, 24420, 2539, 1333, 295, 1487, 294, 1296, 293, 309, 9898, 281, 976, 291, 364, 18873, 51596, 51596], "temperature": 0.0, "avg_logprob": -0.1378577608580983, "compression_ratio": 1.72265625, "no_speech_prob": 1.7777700122678652e-05}, {"id": 96, "seek": 39080, "start": 410.76, "end": 415.44, "text": " So self-supervised learning sort of comes in between and it tries to give you an alternate", "tokens": [50364, 1171, 1365, 11, 498, 291, 445, 2584, 1319, 428, 9274, 281, 586, 1286, 666, 584, 4625, 25036, 11, 50606, 50606, 309, 311, 406, 1850, 1968, 3256, 2533, 659, 12, 17227, 1760, 307, 264, 558, 1333, 295, 551, 337, 341, 5633, 13, 50850, 50850, 759, 291, 360, 406, 458, 1333, 295, 264, 30621, 5633, 257, 4059, 72, 11, 577, 360, 291, 2500, 257, 955, 1412, 51054, 51054, 992, 293, 577, 360, 291, 360, 341, 2302, 659, 12, 17227, 1760, 30621, 5633, 2489, 15164, 6782, 30, 51362, 51362, 407, 2698, 12, 48172, 24420, 2539, 1333, 295, 1487, 294, 1296, 293, 309, 9898, 281, 976, 291, 364, 18873, 51596, 51596], "temperature": 0.0, "avg_logprob": -0.1378577608580983, "compression_ratio": 1.72265625, "no_speech_prob": 1.7777700122678652e-05}, {"id": 97, "seek": 41544, "start": 415.44, "end": 422.36, "text": " way to pre-train your models or to learn from data or learn from experiences without requiring", "tokens": [50364, 636, 281, 659, 12, 83, 7146, 428, 5245, 420, 281, 1466, 490, 1412, 420, 1466, 490, 5235, 1553, 24165, 50710, 50710, 582, 42745, 32675, 13, 50806, 50806, 407, 294, 341, 1389, 11, 456, 366, 1333, 295, 732, 2199, 21988, 300, 291, 393, 808, 493, 365, 337, 51076, 51076, 2698, 12, 48172, 24420, 2539, 13, 51160, 51160, 440, 700, 307, 544, 490, 411, 257, 20828, 1166, 420, 411, 257, 46533, 3097, 4585, 13, 51396, 51396, 407, 294, 3256, 2533, 11, 337, 1365, 11, 291, 362, 364, 3256, 293, 309, 393, 312, 20627, 666, 472, 295, 51612, 51612, 502, 11, 1360, 16949, 13, 51682, 51682], "temperature": 0.0, "avg_logprob": -0.09976603190104166, "compression_ratio": 1.668, "no_speech_prob": 3.8447328734037e-06}, {"id": 98, "seek": 41544, "start": 422.36, "end": 424.28, "text": " pristine supervision.", "tokens": [50364, 636, 281, 659, 12, 83, 7146, 428, 5245, 420, 281, 1466, 490, 1412, 420, 1466, 490, 5235, 1553, 24165, 50710, 50710, 582, 42745, 32675, 13, 50806, 50806, 407, 294, 341, 1389, 11, 456, 366, 1333, 295, 732, 2199, 21988, 300, 291, 393, 808, 493, 365, 337, 51076, 51076, 2698, 12, 48172, 24420, 2539, 13, 51160, 51160, 440, 700, 307, 544, 490, 411, 257, 20828, 1166, 420, 411, 257, 46533, 3097, 4585, 13, 51396, 51396, 407, 294, 3256, 2533, 11, 337, 1365, 11, 291, 362, 364, 3256, 293, 309, 393, 312, 20627, 666, 472, 295, 51612, 51612, 502, 11, 1360, 16949, 13, 51682, 51682], "temperature": 0.0, "avg_logprob": -0.09976603190104166, "compression_ratio": 1.668, "no_speech_prob": 3.8447328734037e-06}, {"id": 99, "seek": 41544, "start": 424.28, "end": 429.68, "text": " So in this case, there are sort of two simple definitions that you can come up with for", "tokens": [50364, 636, 281, 659, 12, 83, 7146, 428, 5245, 420, 281, 1466, 490, 1412, 420, 1466, 490, 5235, 1553, 24165, 50710, 50710, 582, 42745, 32675, 13, 50806, 50806, 407, 294, 341, 1389, 11, 456, 366, 1333, 295, 732, 2199, 21988, 300, 291, 393, 808, 493, 365, 337, 51076, 51076, 2698, 12, 48172, 24420, 2539, 13, 51160, 51160, 440, 700, 307, 544, 490, 411, 257, 20828, 1166, 420, 411, 257, 46533, 3097, 4585, 13, 51396, 51396, 407, 294, 3256, 2533, 11, 337, 1365, 11, 291, 362, 364, 3256, 293, 309, 393, 312, 20627, 666, 472, 295, 51612, 51612, 502, 11, 1360, 16949, 13, 51682, 51682], "temperature": 0.0, "avg_logprob": -0.09976603190104166, "compression_ratio": 1.668, "no_speech_prob": 3.8447328734037e-06}, {"id": 100, "seek": 41544, "start": 429.68, "end": 431.36, "text": " self-supervised learning.", "tokens": [50364, 636, 281, 659, 12, 83, 7146, 428, 5245, 420, 281, 1466, 490, 1412, 420, 1466, 490, 5235, 1553, 24165, 50710, 50710, 582, 42745, 32675, 13, 50806, 50806, 407, 294, 341, 1389, 11, 456, 366, 1333, 295, 732, 2199, 21988, 300, 291, 393, 808, 493, 365, 337, 51076, 51076, 2698, 12, 48172, 24420, 2539, 13, 51160, 51160, 440, 700, 307, 544, 490, 411, 257, 20828, 1166, 420, 411, 257, 46533, 3097, 4585, 13, 51396, 51396, 407, 294, 3256, 2533, 11, 337, 1365, 11, 291, 362, 364, 3256, 293, 309, 393, 312, 20627, 666, 472, 295, 51612, 51612, 502, 11, 1360, 16949, 13, 51682, 51682], "temperature": 0.0, "avg_logprob": -0.09976603190104166, "compression_ratio": 1.668, "no_speech_prob": 3.8447328734037e-06}, {"id": 101, "seek": 41544, "start": 431.36, "end": 436.08, "text": " The first is more from like a discriminative or like a supervised training perspective.", "tokens": [50364, 636, 281, 659, 12, 83, 7146, 428, 5245, 420, 281, 1466, 490, 1412, 420, 1466, 490, 5235, 1553, 24165, 50710, 50710, 582, 42745, 32675, 13, 50806, 50806, 407, 294, 341, 1389, 11, 456, 366, 1333, 295, 732, 2199, 21988, 300, 291, 393, 808, 493, 365, 337, 51076, 51076, 2698, 12, 48172, 24420, 2539, 13, 51160, 51160, 440, 700, 307, 544, 490, 411, 257, 20828, 1166, 420, 411, 257, 46533, 3097, 4585, 13, 51396, 51396, 407, 294, 3256, 2533, 11, 337, 1365, 11, 291, 362, 364, 3256, 293, 309, 393, 312, 20627, 666, 472, 295, 51612, 51612, 502, 11, 1360, 16949, 13, 51682, 51682], "temperature": 0.0, "avg_logprob": -0.09976603190104166, "compression_ratio": 1.668, "no_speech_prob": 3.8447328734037e-06}, {"id": 102, "seek": 41544, "start": 436.08, "end": 440.4, "text": " So in image net, for example, you have an image and it can be classified into one of", "tokens": [50364, 636, 281, 659, 12, 83, 7146, 428, 5245, 420, 281, 1466, 490, 1412, 420, 1466, 490, 5235, 1553, 24165, 50710, 50710, 582, 42745, 32675, 13, 50806, 50806, 407, 294, 341, 1389, 11, 456, 366, 1333, 295, 732, 2199, 21988, 300, 291, 393, 808, 493, 365, 337, 51076, 51076, 2698, 12, 48172, 24420, 2539, 13, 51160, 51160, 440, 700, 307, 544, 490, 411, 257, 20828, 1166, 420, 411, 257, 46533, 3097, 4585, 13, 51396, 51396, 407, 294, 3256, 2533, 11, 337, 1365, 11, 291, 362, 364, 3256, 293, 309, 393, 312, 20627, 666, 472, 295, 51612, 51612, 502, 11, 1360, 16949, 13, 51682, 51682], "temperature": 0.0, "avg_logprob": -0.09976603190104166, "compression_ratio": 1.668, "no_speech_prob": 3.8447328734037e-06}, {"id": 103, "seek": 41544, "start": 440.4, "end": 441.8, "text": " 1,000 labels.", "tokens": [50364, 636, 281, 659, 12, 83, 7146, 428, 5245, 420, 281, 1466, 490, 1412, 420, 1466, 490, 5235, 1553, 24165, 50710, 50710, 582, 42745, 32675, 13, 50806, 50806, 407, 294, 341, 1389, 11, 456, 366, 1333, 295, 732, 2199, 21988, 300, 291, 393, 808, 493, 365, 337, 51076, 51076, 2698, 12, 48172, 24420, 2539, 13, 51160, 51160, 440, 700, 307, 544, 490, 411, 257, 20828, 1166, 420, 411, 257, 46533, 3097, 4585, 13, 51396, 51396, 407, 294, 3256, 2533, 11, 337, 1365, 11, 291, 362, 364, 3256, 293, 309, 393, 312, 20627, 666, 472, 295, 51612, 51612, 502, 11, 1360, 16949, 13, 51682, 51682], "temperature": 0.0, "avg_logprob": -0.09976603190104166, "compression_ratio": 1.668, "no_speech_prob": 3.8447328734037e-06}, {"id": 104, "seek": 44180, "start": 441.8, "end": 448.12, "text": " So self-supervised learning can be thought of as a way to obtain labels from the data", "tokens": [50364, 407, 2698, 12, 48172, 24420, 2539, 393, 312, 1194, 295, 382, 257, 636, 281, 12701, 16949, 490, 264, 1412, 50680, 50680, 1228, 364, 12509, 1399, 13, 50778, 50778, 407, 300, 12509, 1399, 775, 406, 534, 3651, 257, 688, 295, 1952, 13176, 13, 50998, 50998, 400, 370, 1564, 291, 483, 613, 12509, 16949, 11, 586, 291, 393, 1333, 295, 352, 2286, 293, 3847, 428, 51214, 51214, 2316, 365, 613, 16949, 13, 51380, 51380, 440, 661, 636, 295, 1953, 466, 2698, 12, 48172, 24420, 2539, 307, 300, 309, 311, 534, 257, 17630, 51580, 51580], "temperature": 0.0, "avg_logprob": -0.08221865207590956, "compression_ratio": 1.7324561403508771, "no_speech_prob": 7.646196536370553e-06}, {"id": 105, "seek": 44180, "start": 448.12, "end": 450.08, "text": " using an automatic process.", "tokens": [50364, 407, 2698, 12, 48172, 24420, 2539, 393, 312, 1194, 295, 382, 257, 636, 281, 12701, 16949, 490, 264, 1412, 50680, 50680, 1228, 364, 12509, 1399, 13, 50778, 50778, 407, 300, 12509, 1399, 775, 406, 534, 3651, 257, 688, 295, 1952, 13176, 13, 50998, 50998, 400, 370, 1564, 291, 483, 613, 12509, 16949, 11, 586, 291, 393, 1333, 295, 352, 2286, 293, 3847, 428, 51214, 51214, 2316, 365, 613, 16949, 13, 51380, 51380, 440, 661, 636, 295, 1953, 466, 2698, 12, 48172, 24420, 2539, 307, 300, 309, 311, 534, 257, 17630, 51580, 51580], "temperature": 0.0, "avg_logprob": -0.08221865207590956, "compression_ratio": 1.7324561403508771, "no_speech_prob": 7.646196536370553e-06}, {"id": 106, "seek": 44180, "start": 450.08, "end": 454.48, "text": " So that automatic process does not really require a lot of human intervention.", "tokens": [50364, 407, 2698, 12, 48172, 24420, 2539, 393, 312, 1194, 295, 382, 257, 636, 281, 12701, 16949, 490, 264, 1412, 50680, 50680, 1228, 364, 12509, 1399, 13, 50778, 50778, 407, 300, 12509, 1399, 775, 406, 534, 3651, 257, 688, 295, 1952, 13176, 13, 50998, 50998, 400, 370, 1564, 291, 483, 613, 12509, 16949, 11, 586, 291, 393, 1333, 295, 352, 2286, 293, 3847, 428, 51214, 51214, 2316, 365, 613, 16949, 13, 51380, 51380, 440, 661, 636, 295, 1953, 466, 2698, 12, 48172, 24420, 2539, 307, 300, 309, 311, 534, 257, 17630, 51580, 51580], "temperature": 0.0, "avg_logprob": -0.08221865207590956, "compression_ratio": 1.7324561403508771, "no_speech_prob": 7.646196536370553e-06}, {"id": 107, "seek": 44180, "start": 454.48, "end": 458.8, "text": " And so once you get these automatic labels, now you can sort of go ahead and train your", "tokens": [50364, 407, 2698, 12, 48172, 24420, 2539, 393, 312, 1194, 295, 382, 257, 636, 281, 12701, 16949, 490, 264, 1412, 50680, 50680, 1228, 364, 12509, 1399, 13, 50778, 50778, 407, 300, 12509, 1399, 775, 406, 534, 3651, 257, 688, 295, 1952, 13176, 13, 50998, 50998, 400, 370, 1564, 291, 483, 613, 12509, 16949, 11, 586, 291, 393, 1333, 295, 352, 2286, 293, 3847, 428, 51214, 51214, 2316, 365, 613, 16949, 13, 51380, 51380, 440, 661, 636, 295, 1953, 466, 2698, 12, 48172, 24420, 2539, 307, 300, 309, 311, 534, 257, 17630, 51580, 51580], "temperature": 0.0, "avg_logprob": -0.08221865207590956, "compression_ratio": 1.7324561403508771, "no_speech_prob": 7.646196536370553e-06}, {"id": 108, "seek": 44180, "start": 458.8, "end": 462.12, "text": " model with these labels.", "tokens": [50364, 407, 2698, 12, 48172, 24420, 2539, 393, 312, 1194, 295, 382, 257, 636, 281, 12701, 16949, 490, 264, 1412, 50680, 50680, 1228, 364, 12509, 1399, 13, 50778, 50778, 407, 300, 12509, 1399, 775, 406, 534, 3651, 257, 688, 295, 1952, 13176, 13, 50998, 50998, 400, 370, 1564, 291, 483, 613, 12509, 16949, 11, 586, 291, 393, 1333, 295, 352, 2286, 293, 3847, 428, 51214, 51214, 2316, 365, 613, 16949, 13, 51380, 51380, 440, 661, 636, 295, 1953, 466, 2698, 12, 48172, 24420, 2539, 307, 300, 309, 311, 534, 257, 17630, 51580, 51580], "temperature": 0.0, "avg_logprob": -0.08221865207590956, "compression_ratio": 1.7324561403508771, "no_speech_prob": 7.646196536370553e-06}, {"id": 109, "seek": 44180, "start": 462.12, "end": 466.12, "text": " The other way of thinking about self-supervised learning is that it's really a prediction", "tokens": [50364, 407, 2698, 12, 48172, 24420, 2539, 393, 312, 1194, 295, 382, 257, 636, 281, 12701, 16949, 490, 264, 1412, 50680, 50680, 1228, 364, 12509, 1399, 13, 50778, 50778, 407, 300, 12509, 1399, 775, 406, 534, 3651, 257, 688, 295, 1952, 13176, 13, 50998, 50998, 400, 370, 1564, 291, 483, 613, 12509, 16949, 11, 586, 291, 393, 1333, 295, 352, 2286, 293, 3847, 428, 51214, 51214, 2316, 365, 613, 16949, 13, 51380, 51380, 440, 661, 636, 295, 1953, 466, 2698, 12, 48172, 24420, 2539, 307, 300, 309, 311, 534, 257, 17630, 51580, 51580], "temperature": 0.0, "avg_logprob": -0.08221865207590956, "compression_ratio": 1.7324561403508771, "no_speech_prob": 7.646196536370553e-06}, {"id": 110, "seek": 46612, "start": 466.12, "end": 472.16, "text": " problem where you're trying to predict a part of the data from the other parts of the data.", "tokens": [50364, 1154, 689, 291, 434, 1382, 281, 6069, 257, 644, 295, 264, 1412, 490, 264, 661, 3166, 295, 264, 1412, 13, 50666, 50666, 407, 291, 362, 512, 13095, 1412, 293, 291, 362, 512, 7633, 1412, 13, 50870, 50870, 400, 291, 393, 586, 47881, 257, 5633, 689, 2212, 264, 13095, 1412, 11, 291, 853, 281, 6069, 2139, 51110, 51110, 264, 7633, 1412, 420, 512, 4707, 295, 264, 7633, 1412, 13, 51276, 51276, 400, 370, 1238, 709, 257, 688, 295, 1333, 295, 264, 2698, 12, 48172, 24420, 7512, 393, 312, 19174, 294, 341, 1729, 51526, 51526, 8388, 13, 51656, 51656], "temperature": 0.0, "avg_logprob": -0.07798373097121114, "compression_ratio": 1.8584474885844748, "no_speech_prob": 1.1300303413008805e-05}, {"id": 111, "seek": 46612, "start": 472.16, "end": 476.24, "text": " So you have some observed data and you have some hidden data.", "tokens": [50364, 1154, 689, 291, 434, 1382, 281, 6069, 257, 644, 295, 264, 1412, 490, 264, 661, 3166, 295, 264, 1412, 13, 50666, 50666, 407, 291, 362, 512, 13095, 1412, 293, 291, 362, 512, 7633, 1412, 13, 50870, 50870, 400, 291, 393, 586, 47881, 257, 5633, 689, 2212, 264, 13095, 1412, 11, 291, 853, 281, 6069, 2139, 51110, 51110, 264, 7633, 1412, 420, 512, 4707, 295, 264, 7633, 1412, 13, 51276, 51276, 400, 370, 1238, 709, 257, 688, 295, 1333, 295, 264, 2698, 12, 48172, 24420, 7512, 393, 312, 19174, 294, 341, 1729, 51526, 51526, 8388, 13, 51656, 51656], "temperature": 0.0, "avg_logprob": -0.07798373097121114, "compression_ratio": 1.8584474885844748, "no_speech_prob": 1.1300303413008805e-05}, {"id": 112, "seek": 46612, "start": 476.24, "end": 481.04, "text": " And you can now formulate a task where given the observed data, you try to predict either", "tokens": [50364, 1154, 689, 291, 434, 1382, 281, 6069, 257, 644, 295, 264, 1412, 490, 264, 661, 3166, 295, 264, 1412, 13, 50666, 50666, 407, 291, 362, 512, 13095, 1412, 293, 291, 362, 512, 7633, 1412, 13, 50870, 50870, 400, 291, 393, 586, 47881, 257, 5633, 689, 2212, 264, 13095, 1412, 11, 291, 853, 281, 6069, 2139, 51110, 51110, 264, 7633, 1412, 420, 512, 4707, 295, 264, 7633, 1412, 13, 51276, 51276, 400, 370, 1238, 709, 257, 688, 295, 1333, 295, 264, 2698, 12, 48172, 24420, 7512, 393, 312, 19174, 294, 341, 1729, 51526, 51526, 8388, 13, 51656, 51656], "temperature": 0.0, "avg_logprob": -0.07798373097121114, "compression_ratio": 1.8584474885844748, "no_speech_prob": 1.1300303413008805e-05}, {"id": 113, "seek": 46612, "start": 481.04, "end": 484.36, "text": " the hidden data or some property of the hidden data.", "tokens": [50364, 1154, 689, 291, 434, 1382, 281, 6069, 257, 644, 295, 264, 1412, 490, 264, 661, 3166, 295, 264, 1412, 13, 50666, 50666, 407, 291, 362, 512, 13095, 1412, 293, 291, 362, 512, 7633, 1412, 13, 50870, 50870, 400, 291, 393, 586, 47881, 257, 5633, 689, 2212, 264, 13095, 1412, 11, 291, 853, 281, 6069, 2139, 51110, 51110, 264, 7633, 1412, 420, 512, 4707, 295, 264, 7633, 1412, 13, 51276, 51276, 400, 370, 1238, 709, 257, 688, 295, 1333, 295, 264, 2698, 12, 48172, 24420, 7512, 393, 312, 19174, 294, 341, 1729, 51526, 51526, 8388, 13, 51656, 51656], "temperature": 0.0, "avg_logprob": -0.07798373097121114, "compression_ratio": 1.8584474885844748, "no_speech_prob": 1.1300303413008805e-05}, {"id": 114, "seek": 46612, "start": 484.36, "end": 489.36, "text": " And so pretty much a lot of sort of the self-supervised techniques can be viewed in this particular", "tokens": [50364, 1154, 689, 291, 434, 1382, 281, 6069, 257, 644, 295, 264, 1412, 490, 264, 661, 3166, 295, 264, 1412, 13, 50666, 50666, 407, 291, 362, 512, 13095, 1412, 293, 291, 362, 512, 7633, 1412, 13, 50870, 50870, 400, 291, 393, 586, 47881, 257, 5633, 689, 2212, 264, 13095, 1412, 11, 291, 853, 281, 6069, 2139, 51110, 51110, 264, 7633, 1412, 420, 512, 4707, 295, 264, 7633, 1412, 13, 51276, 51276, 400, 370, 1238, 709, 257, 688, 295, 1333, 295, 264, 2698, 12, 48172, 24420, 7512, 393, 312, 19174, 294, 341, 1729, 51526, 51526, 8388, 13, 51656, 51656], "temperature": 0.0, "avg_logprob": -0.07798373097121114, "compression_ratio": 1.8584474885844748, "no_speech_prob": 1.1300303413008805e-05}, {"id": 115, "seek": 46612, "start": 489.36, "end": 491.96, "text": " framework.", "tokens": [50364, 1154, 689, 291, 434, 1382, 281, 6069, 257, 644, 295, 264, 1412, 490, 264, 661, 3166, 295, 264, 1412, 13, 50666, 50666, 407, 291, 362, 512, 13095, 1412, 293, 291, 362, 512, 7633, 1412, 13, 50870, 50870, 400, 291, 393, 586, 47881, 257, 5633, 689, 2212, 264, 13095, 1412, 11, 291, 853, 281, 6069, 2139, 51110, 51110, 264, 7633, 1412, 420, 512, 4707, 295, 264, 7633, 1412, 13, 51276, 51276, 400, 370, 1238, 709, 257, 688, 295, 1333, 295, 264, 2698, 12, 48172, 24420, 7512, 393, 312, 19174, 294, 341, 1729, 51526, 51526, 8388, 13, 51656, 51656], "temperature": 0.0, "avg_logprob": -0.07798373097121114, "compression_ratio": 1.8584474885844748, "no_speech_prob": 1.1300303413008805e-05}, {"id": 116, "seek": 49196, "start": 491.96, "end": 496.88, "text": " So the term sort of self-supervised learning, I really like to give this analogy, which", "tokens": [50364, 407, 264, 1433, 1333, 295, 2698, 12, 48172, 24420, 2539, 11, 286, 534, 411, 281, 976, 341, 21663, 11, 597, 50610, 50610, 307, 490, 10956, 413, 8391, 13, 50726, 50726, 407, 689, 750, 1333, 295, 9898, 281, 20206, 1296, 264, 1045, 2115, 11, 46533, 11, 2693, 12879, 24420, 11, 50966, 50966, 293, 2698, 12, 48172, 24420, 13, 51084, 51084, 400, 370, 294, 46533, 2539, 11, 291, 362, 11, 584, 11, 364, 4846, 8408, 293, 291, 434, 2212, 264, 1900, 3779, 51346, 51346, 337, 309, 11, 597, 307, 11, 584, 11, 516, 281, 312, 264, 7645, 8408, 13, 51522, 51522, 682, 2693, 12879, 24420, 2539, 11, 291, 434, 2212, 341, 4846, 293, 309, 311, 406, 1850, 437, 534, 264, 2302, 51742, 51742], "temperature": 0.0, "avg_logprob": -0.1639414996635623, "compression_ratio": 1.8623481781376519, "no_speech_prob": 4.0293521124112885e-06}, {"id": 117, "seek": 49196, "start": 496.88, "end": 499.2, "text": " is from Virginia Dessa.", "tokens": [50364, 407, 264, 1433, 1333, 295, 2698, 12, 48172, 24420, 2539, 11, 286, 534, 411, 281, 976, 341, 21663, 11, 597, 50610, 50610, 307, 490, 10956, 413, 8391, 13, 50726, 50726, 407, 689, 750, 1333, 295, 9898, 281, 20206, 1296, 264, 1045, 2115, 11, 46533, 11, 2693, 12879, 24420, 11, 50966, 50966, 293, 2698, 12, 48172, 24420, 13, 51084, 51084, 400, 370, 294, 46533, 2539, 11, 291, 362, 11, 584, 11, 364, 4846, 8408, 293, 291, 434, 2212, 264, 1900, 3779, 51346, 51346, 337, 309, 11, 597, 307, 11, 584, 11, 516, 281, 312, 264, 7645, 8408, 13, 51522, 51522, 682, 2693, 12879, 24420, 2539, 11, 291, 434, 2212, 341, 4846, 293, 309, 311, 406, 1850, 437, 534, 264, 2302, 51742, 51742], "temperature": 0.0, "avg_logprob": -0.1639414996635623, "compression_ratio": 1.8623481781376519, "no_speech_prob": 4.0293521124112885e-06}, {"id": 118, "seek": 49196, "start": 499.2, "end": 504.0, "text": " So where she sort of tries to distinguish between the three terms, supervised, unsupervised,", "tokens": [50364, 407, 264, 1433, 1333, 295, 2698, 12, 48172, 24420, 2539, 11, 286, 534, 411, 281, 976, 341, 21663, 11, 597, 50610, 50610, 307, 490, 10956, 413, 8391, 13, 50726, 50726, 407, 689, 750, 1333, 295, 9898, 281, 20206, 1296, 264, 1045, 2115, 11, 46533, 11, 2693, 12879, 24420, 11, 50966, 50966, 293, 2698, 12, 48172, 24420, 13, 51084, 51084, 400, 370, 294, 46533, 2539, 11, 291, 362, 11, 584, 11, 364, 4846, 8408, 293, 291, 434, 2212, 264, 1900, 3779, 51346, 51346, 337, 309, 11, 597, 307, 11, 584, 11, 516, 281, 312, 264, 7645, 8408, 13, 51522, 51522, 682, 2693, 12879, 24420, 2539, 11, 291, 434, 2212, 341, 4846, 293, 309, 311, 406, 1850, 437, 534, 264, 2302, 51742, 51742], "temperature": 0.0, "avg_logprob": -0.1639414996635623, "compression_ratio": 1.8623481781376519, "no_speech_prob": 4.0293521124112885e-06}, {"id": 119, "seek": 49196, "start": 504.0, "end": 506.35999999999996, "text": " and self-supervised.", "tokens": [50364, 407, 264, 1433, 1333, 295, 2698, 12, 48172, 24420, 2539, 11, 286, 534, 411, 281, 976, 341, 21663, 11, 597, 50610, 50610, 307, 490, 10956, 413, 8391, 13, 50726, 50726, 407, 689, 750, 1333, 295, 9898, 281, 20206, 1296, 264, 1045, 2115, 11, 46533, 11, 2693, 12879, 24420, 11, 50966, 50966, 293, 2698, 12, 48172, 24420, 13, 51084, 51084, 400, 370, 294, 46533, 2539, 11, 291, 362, 11, 584, 11, 364, 4846, 8408, 293, 291, 434, 2212, 264, 1900, 3779, 51346, 51346, 337, 309, 11, 597, 307, 11, 584, 11, 516, 281, 312, 264, 7645, 8408, 13, 51522, 51522, 682, 2693, 12879, 24420, 2539, 11, 291, 434, 2212, 341, 4846, 293, 309, 311, 406, 1850, 437, 534, 264, 2302, 51742, 51742], "temperature": 0.0, "avg_logprob": -0.1639414996635623, "compression_ratio": 1.8623481781376519, "no_speech_prob": 4.0293521124112885e-06}, {"id": 120, "seek": 49196, "start": 506.35999999999996, "end": 511.59999999999997, "text": " And so in supervised learning, you have, say, an input cow and you're given the exact target", "tokens": [50364, 407, 264, 1433, 1333, 295, 2698, 12, 48172, 24420, 2539, 11, 286, 534, 411, 281, 976, 341, 21663, 11, 597, 50610, 50610, 307, 490, 10956, 413, 8391, 13, 50726, 50726, 407, 689, 750, 1333, 295, 9898, 281, 20206, 1296, 264, 1045, 2115, 11, 46533, 11, 2693, 12879, 24420, 11, 50966, 50966, 293, 2698, 12, 48172, 24420, 13, 51084, 51084, 400, 370, 294, 46533, 2539, 11, 291, 362, 11, 584, 11, 364, 4846, 8408, 293, 291, 434, 2212, 264, 1900, 3779, 51346, 51346, 337, 309, 11, 597, 307, 11, 584, 11, 516, 281, 312, 264, 7645, 8408, 13, 51522, 51522, 682, 2693, 12879, 24420, 2539, 11, 291, 434, 2212, 341, 4846, 293, 309, 311, 406, 1850, 437, 534, 264, 2302, 51742, 51742], "temperature": 0.0, "avg_logprob": -0.1639414996635623, "compression_ratio": 1.8623481781376519, "no_speech_prob": 4.0293521124112885e-06}, {"id": 121, "seek": 49196, "start": 511.59999999999997, "end": 515.12, "text": " for it, which is, say, going to be the label cow.", "tokens": [50364, 407, 264, 1433, 1333, 295, 2698, 12, 48172, 24420, 2539, 11, 286, 534, 411, 281, 976, 341, 21663, 11, 597, 50610, 50610, 307, 490, 10956, 413, 8391, 13, 50726, 50726, 407, 689, 750, 1333, 295, 9898, 281, 20206, 1296, 264, 1045, 2115, 11, 46533, 11, 2693, 12879, 24420, 11, 50966, 50966, 293, 2698, 12, 48172, 24420, 13, 51084, 51084, 400, 370, 294, 46533, 2539, 11, 291, 362, 11, 584, 11, 364, 4846, 8408, 293, 291, 434, 2212, 264, 1900, 3779, 51346, 51346, 337, 309, 11, 597, 307, 11, 584, 11, 516, 281, 312, 264, 7645, 8408, 13, 51522, 51522, 682, 2693, 12879, 24420, 2539, 11, 291, 434, 2212, 341, 4846, 293, 309, 311, 406, 1850, 437, 534, 264, 2302, 51742, 51742], "temperature": 0.0, "avg_logprob": -0.1639414996635623, "compression_ratio": 1.8623481781376519, "no_speech_prob": 4.0293521124112885e-06}, {"id": 122, "seek": 49196, "start": 515.12, "end": 519.52, "text": " In unsupervised learning, you're given this input and it's not clear what really the entire", "tokens": [50364, 407, 264, 1433, 1333, 295, 2698, 12, 48172, 24420, 2539, 11, 286, 534, 411, 281, 976, 341, 21663, 11, 597, 50610, 50610, 307, 490, 10956, 413, 8391, 13, 50726, 50726, 407, 689, 750, 1333, 295, 9898, 281, 20206, 1296, 264, 1045, 2115, 11, 46533, 11, 2693, 12879, 24420, 11, 50966, 50966, 293, 2698, 12, 48172, 24420, 13, 51084, 51084, 400, 370, 294, 46533, 2539, 11, 291, 362, 11, 584, 11, 364, 4846, 8408, 293, 291, 434, 2212, 264, 1900, 3779, 51346, 51346, 337, 309, 11, 597, 307, 11, 584, 11, 516, 281, 312, 264, 7645, 8408, 13, 51522, 51522, 682, 2693, 12879, 24420, 2539, 11, 291, 434, 2212, 341, 4846, 293, 309, 311, 406, 1850, 437, 534, 264, 2302, 51742, 51742], "temperature": 0.0, "avg_logprob": -0.1639414996635623, "compression_ratio": 1.8623481781376519, "no_speech_prob": 4.0293521124112885e-06}, {"id": 123, "seek": 51952, "start": 519.52, "end": 524.12, "text": " target is, what exactly is the objective function or so on.", "tokens": [50364, 3779, 307, 11, 437, 2293, 307, 264, 10024, 2445, 420, 370, 322, 13, 50594, 50594, 16348, 12, 48172, 24420, 2539, 307, 1333, 295, 264, 1433, 597, 307, 16494, 586, 544, 293, 544, 13, 50930, 50930, 400, 264, 1558, 307, 300, 264, 7645, 534, 1487, 490, 2139, 257, 598, 12, 905, 14112, 2937, 1072, 1860, 420, 598, 12, 905, 14112, 2937, 51164, 51164, 644, 295, 264, 1412, 2564, 13, 51246, 51246, 407, 534, 439, 295, 264, 1347, 307, 294, 264, 1412, 293, 291, 434, 534, 1382, 281, 6069, 1333, 295, 51448, 51448, 6069, 2139, 3166, 295, 309, 420, 7221, 295, 264, 1412, 13, 51706, 51706], "temperature": 0.0, "avg_logprob": -0.11601235731592718, "compression_ratio": 1.7675438596491229, "no_speech_prob": 1.184273151011439e-05}, {"id": 124, "seek": 51952, "start": 524.12, "end": 530.84, "text": " Self-supervised learning is sort of the term which is preferred now more and more.", "tokens": [50364, 3779, 307, 11, 437, 2293, 307, 264, 10024, 2445, 420, 370, 322, 13, 50594, 50594, 16348, 12, 48172, 24420, 2539, 307, 1333, 295, 264, 1433, 597, 307, 16494, 586, 544, 293, 544, 13, 50930, 50930, 400, 264, 1558, 307, 300, 264, 7645, 534, 1487, 490, 2139, 257, 598, 12, 905, 14112, 2937, 1072, 1860, 420, 598, 12, 905, 14112, 2937, 51164, 51164, 644, 295, 264, 1412, 2564, 13, 51246, 51246, 407, 534, 439, 295, 264, 1347, 307, 294, 264, 1412, 293, 291, 434, 534, 1382, 281, 6069, 1333, 295, 51448, 51448, 6069, 2139, 3166, 295, 309, 420, 7221, 295, 264, 1412, 13, 51706, 51706], "temperature": 0.0, "avg_logprob": -0.11601235731592718, "compression_ratio": 1.7675438596491229, "no_speech_prob": 1.184273151011439e-05}, {"id": 125, "seek": 51952, "start": 530.84, "end": 535.52, "text": " And the idea is that the label really comes from either a co-occurring modality or co-occurring", "tokens": [50364, 3779, 307, 11, 437, 2293, 307, 264, 10024, 2445, 420, 370, 322, 13, 50594, 50594, 16348, 12, 48172, 24420, 2539, 307, 1333, 295, 264, 1433, 597, 307, 16494, 586, 544, 293, 544, 13, 50930, 50930, 400, 264, 1558, 307, 300, 264, 7645, 534, 1487, 490, 2139, 257, 598, 12, 905, 14112, 2937, 1072, 1860, 420, 598, 12, 905, 14112, 2937, 51164, 51164, 644, 295, 264, 1412, 2564, 13, 51246, 51246, 407, 534, 439, 295, 264, 1347, 307, 294, 264, 1412, 293, 291, 434, 534, 1382, 281, 6069, 1333, 295, 51448, 51448, 6069, 2139, 3166, 295, 309, 420, 7221, 295, 264, 1412, 13, 51706, 51706], "temperature": 0.0, "avg_logprob": -0.11601235731592718, "compression_ratio": 1.7675438596491229, "no_speech_prob": 1.184273151011439e-05}, {"id": 126, "seek": 51952, "start": 535.52, "end": 537.16, "text": " part of the data itself.", "tokens": [50364, 3779, 307, 11, 437, 2293, 307, 264, 10024, 2445, 420, 370, 322, 13, 50594, 50594, 16348, 12, 48172, 24420, 2539, 307, 1333, 295, 264, 1433, 597, 307, 16494, 586, 544, 293, 544, 13, 50930, 50930, 400, 264, 1558, 307, 300, 264, 7645, 534, 1487, 490, 2139, 257, 598, 12, 905, 14112, 2937, 1072, 1860, 420, 598, 12, 905, 14112, 2937, 51164, 51164, 644, 295, 264, 1412, 2564, 13, 51246, 51246, 407, 534, 439, 295, 264, 1347, 307, 294, 264, 1412, 293, 291, 434, 534, 1382, 281, 6069, 1333, 295, 51448, 51448, 6069, 2139, 3166, 295, 309, 420, 7221, 295, 264, 1412, 13, 51706, 51706], "temperature": 0.0, "avg_logprob": -0.11601235731592718, "compression_ratio": 1.7675438596491229, "no_speech_prob": 1.184273151011439e-05}, {"id": 127, "seek": 51952, "start": 537.16, "end": 541.1999999999999, "text": " So really all of the power is in the data and you're really trying to predict sort of", "tokens": [50364, 3779, 307, 11, 437, 2293, 307, 264, 10024, 2445, 420, 370, 322, 13, 50594, 50594, 16348, 12, 48172, 24420, 2539, 307, 1333, 295, 264, 1433, 597, 307, 16494, 586, 544, 293, 544, 13, 50930, 50930, 400, 264, 1558, 307, 300, 264, 7645, 534, 1487, 490, 2139, 257, 598, 12, 905, 14112, 2937, 1072, 1860, 420, 598, 12, 905, 14112, 2937, 51164, 51164, 644, 295, 264, 1412, 2564, 13, 51246, 51246, 407, 534, 439, 295, 264, 1347, 307, 294, 264, 1412, 293, 291, 434, 534, 1382, 281, 6069, 1333, 295, 51448, 51448, 6069, 2139, 3166, 295, 309, 420, 7221, 295, 264, 1412, 13, 51706, 51706], "temperature": 0.0, "avg_logprob": -0.11601235731592718, "compression_ratio": 1.7675438596491229, "no_speech_prob": 1.184273151011439e-05}, {"id": 128, "seek": 51952, "start": 541.1999999999999, "end": 546.36, "text": " predict either parts of it or properties of the data.", "tokens": [50364, 3779, 307, 11, 437, 2293, 307, 264, 10024, 2445, 420, 370, 322, 13, 50594, 50594, 16348, 12, 48172, 24420, 2539, 307, 1333, 295, 264, 1433, 597, 307, 16494, 586, 544, 293, 544, 13, 50930, 50930, 400, 264, 1558, 307, 300, 264, 7645, 534, 1487, 490, 2139, 257, 598, 12, 905, 14112, 2937, 1072, 1860, 420, 598, 12, 905, 14112, 2937, 51164, 51164, 644, 295, 264, 1412, 2564, 13, 51246, 51246, 407, 534, 439, 295, 264, 1347, 307, 294, 264, 1412, 293, 291, 434, 534, 1382, 281, 6069, 1333, 295, 51448, 51448, 6069, 2139, 3166, 295, 309, 420, 7221, 295, 264, 1412, 13, 51706, 51706], "temperature": 0.0, "avg_logprob": -0.11601235731592718, "compression_ratio": 1.7675438596491229, "no_speech_prob": 1.184273151011439e-05}, {"id": 129, "seek": 54636, "start": 546.36, "end": 551.44, "text": " So some very sort of standard and successful examples of this are, say, either the Word", "tokens": [50364, 407, 512, 588, 1333, 295, 3832, 293, 4406, 5110, 295, 341, 366, 11, 584, 11, 2139, 264, 8725, 50618, 50618, 281, 691, 3045, 2316, 11, 689, 2212, 341, 11, 584, 11, 257, 8174, 11, 337, 1365, 11, 264, 3857, 12696, 322, 264, 3803, 11, 291, 434, 50992, 50992, 2212, 257, 644, 295, 264, 8174, 300, 291, 11441, 11, 370, 597, 307, 294, 341, 1389, 21335, 382, 264, 4319, 51242, 51242, 420, 264, 2503, 13, 51316, 51316, 400, 550, 291, 362, 257, 644, 295, 264, 8174, 11, 257, 1349, 294, 341, 1389, 11, 597, 307, 406, 13095, 11, 51568, 51568, 597, 291, 1333, 295, 6479, 490, 341, 2302, 2316, 13, 51738, 51738], "temperature": 0.0, "avg_logprob": -0.1469352350825757, "compression_ratio": 1.831896551724138, "no_speech_prob": 7.888974323577713e-06}, {"id": 130, "seek": 54636, "start": 551.44, "end": 558.92, "text": " to Vec model, where given this, say, a sentence, for example, the cat sits on the mat, you're", "tokens": [50364, 407, 512, 588, 1333, 295, 3832, 293, 4406, 5110, 295, 341, 366, 11, 584, 11, 2139, 264, 8725, 50618, 50618, 281, 691, 3045, 2316, 11, 689, 2212, 341, 11, 584, 11, 257, 8174, 11, 337, 1365, 11, 264, 3857, 12696, 322, 264, 3803, 11, 291, 434, 50992, 50992, 2212, 257, 644, 295, 264, 8174, 300, 291, 11441, 11, 370, 597, 307, 294, 341, 1389, 21335, 382, 264, 4319, 51242, 51242, 420, 264, 2503, 13, 51316, 51316, 400, 550, 291, 362, 257, 644, 295, 264, 8174, 11, 257, 1349, 294, 341, 1389, 11, 597, 307, 406, 13095, 11, 51568, 51568, 597, 291, 1333, 295, 6479, 490, 341, 2302, 2316, 13, 51738, 51738], "temperature": 0.0, "avg_logprob": -0.1469352350825757, "compression_ratio": 1.831896551724138, "no_speech_prob": 7.888974323577713e-06}, {"id": 131, "seek": 54636, "start": 558.92, "end": 563.92, "text": " given a part of the sentence that you observe, so which is in this case labeled as the context", "tokens": [50364, 407, 512, 588, 1333, 295, 3832, 293, 4406, 5110, 295, 341, 366, 11, 584, 11, 2139, 264, 8725, 50618, 50618, 281, 691, 3045, 2316, 11, 689, 2212, 341, 11, 584, 11, 257, 8174, 11, 337, 1365, 11, 264, 3857, 12696, 322, 264, 3803, 11, 291, 434, 50992, 50992, 2212, 257, 644, 295, 264, 8174, 300, 291, 11441, 11, 370, 597, 307, 294, 341, 1389, 21335, 382, 264, 4319, 51242, 51242, 420, 264, 2503, 13, 51316, 51316, 400, 550, 291, 362, 257, 644, 295, 264, 8174, 11, 257, 1349, 294, 341, 1389, 11, 597, 307, 406, 13095, 11, 51568, 51568, 597, 291, 1333, 295, 6479, 490, 341, 2302, 2316, 13, 51738, 51738], "temperature": 0.0, "avg_logprob": -0.1469352350825757, "compression_ratio": 1.831896551724138, "no_speech_prob": 7.888974323577713e-06}, {"id": 132, "seek": 54636, "start": 563.92, "end": 565.4, "text": " or the history.", "tokens": [50364, 407, 512, 588, 1333, 295, 3832, 293, 4406, 5110, 295, 341, 366, 11, 584, 11, 2139, 264, 8725, 50618, 50618, 281, 691, 3045, 2316, 11, 689, 2212, 341, 11, 584, 11, 257, 8174, 11, 337, 1365, 11, 264, 3857, 12696, 322, 264, 3803, 11, 291, 434, 50992, 50992, 2212, 257, 644, 295, 264, 8174, 300, 291, 11441, 11, 370, 597, 307, 294, 341, 1389, 21335, 382, 264, 4319, 51242, 51242, 420, 264, 2503, 13, 51316, 51316, 400, 550, 291, 362, 257, 644, 295, 264, 8174, 11, 257, 1349, 294, 341, 1389, 11, 597, 307, 406, 13095, 11, 51568, 51568, 597, 291, 1333, 295, 6479, 490, 341, 2302, 2316, 13, 51738, 51738], "temperature": 0.0, "avg_logprob": -0.1469352350825757, "compression_ratio": 1.831896551724138, "no_speech_prob": 7.888974323577713e-06}, {"id": 133, "seek": 54636, "start": 565.4, "end": 570.44, "text": " And then you have a part of the sentence, a word in this case, which is not observed,", "tokens": [50364, 407, 512, 588, 1333, 295, 3832, 293, 4406, 5110, 295, 341, 366, 11, 584, 11, 2139, 264, 8725, 50618, 50618, 281, 691, 3045, 2316, 11, 689, 2212, 341, 11, 584, 11, 257, 8174, 11, 337, 1365, 11, 264, 3857, 12696, 322, 264, 3803, 11, 291, 434, 50992, 50992, 2212, 257, 644, 295, 264, 8174, 300, 291, 11441, 11, 370, 597, 307, 294, 341, 1389, 21335, 382, 264, 4319, 51242, 51242, 420, 264, 2503, 13, 51316, 51316, 400, 550, 291, 362, 257, 644, 295, 264, 8174, 11, 257, 1349, 294, 341, 1389, 11, 597, 307, 406, 13095, 11, 51568, 51568, 597, 291, 1333, 295, 6479, 490, 341, 2302, 2316, 13, 51738, 51738], "temperature": 0.0, "avg_logprob": -0.1469352350825757, "compression_ratio": 1.831896551724138, "no_speech_prob": 7.888974323577713e-06}, {"id": 134, "seek": 54636, "start": 570.44, "end": 573.84, "text": " which you sort of hide from this entire model.", "tokens": [50364, 407, 512, 588, 1333, 295, 3832, 293, 4406, 5110, 295, 341, 366, 11, 584, 11, 2139, 264, 8725, 50618, 50618, 281, 691, 3045, 2316, 11, 689, 2212, 341, 11, 584, 11, 257, 8174, 11, 337, 1365, 11, 264, 3857, 12696, 322, 264, 3803, 11, 291, 434, 50992, 50992, 2212, 257, 644, 295, 264, 8174, 300, 291, 11441, 11, 370, 597, 307, 294, 341, 1389, 21335, 382, 264, 4319, 51242, 51242, 420, 264, 2503, 13, 51316, 51316, 400, 550, 291, 362, 257, 644, 295, 264, 8174, 11, 257, 1349, 294, 341, 1389, 11, 597, 307, 406, 13095, 11, 51568, 51568, 597, 291, 1333, 295, 6479, 490, 341, 2302, 2316, 13, 51738, 51738], "temperature": 0.0, "avg_logprob": -0.1469352350825757, "compression_ratio": 1.831896551724138, "no_speech_prob": 7.888974323577713e-06}, {"id": 135, "seek": 57384, "start": 573.84, "end": 578.64, "text": " And given this context, you ask the model to predict this target.", "tokens": [50364, 400, 2212, 341, 4319, 11, 291, 1029, 264, 2316, 281, 6069, 341, 3779, 13, 50604, 50604, 400, 370, 291, 362, 428, 2698, 12, 48172, 24420, 10024, 11, 291, 393, 17522, 309, 294, 257, 1729, 6700, 11, 50879, 50879, 293, 586, 291, 486, 1466, 257, 10290, 337, 428, 4846, 1412, 13, 51052, 51052, 400, 8725, 281, 691, 3045, 575, 668, 11, 286, 914, 11, 309, 575, 767, 4898, 257, 688, 295, 6228, 294, 5673, 295, 5821, 13, 51335, 51335, 400, 341, 2302, 1333, 295, 35521, 2316, 575, 7547, 257, 688, 295, 589, 294, 3820, 5201, 51542, 51542, 382, 731, 13, 51674, 51674], "temperature": 0.0, "avg_logprob": -0.1147029932262828, "compression_ratio": 1.6313725490196078, "no_speech_prob": 9.368127393827308e-06}, {"id": 136, "seek": 57384, "start": 578.64, "end": 584.14, "text": " And so you have your self-supervised objective, you can minimize it in a particular fashion,", "tokens": [50364, 400, 2212, 341, 4319, 11, 291, 1029, 264, 2316, 281, 6069, 341, 3779, 13, 50604, 50604, 400, 370, 291, 362, 428, 2698, 12, 48172, 24420, 10024, 11, 291, 393, 17522, 309, 294, 257, 1729, 6700, 11, 50879, 50879, 293, 586, 291, 486, 1466, 257, 10290, 337, 428, 4846, 1412, 13, 51052, 51052, 400, 8725, 281, 691, 3045, 575, 668, 11, 286, 914, 11, 309, 575, 767, 4898, 257, 688, 295, 6228, 294, 5673, 295, 5821, 13, 51335, 51335, 400, 341, 2302, 1333, 295, 35521, 2316, 575, 7547, 257, 688, 295, 589, 294, 3820, 5201, 51542, 51542, 382, 731, 13, 51674, 51674], "temperature": 0.0, "avg_logprob": -0.1147029932262828, "compression_ratio": 1.6313725490196078, "no_speech_prob": 9.368127393827308e-06}, {"id": 137, "seek": 57384, "start": 584.14, "end": 587.6, "text": " and now you will learn a representation for your input data.", "tokens": [50364, 400, 2212, 341, 4319, 11, 291, 1029, 264, 2316, 281, 6069, 341, 3779, 13, 50604, 50604, 400, 370, 291, 362, 428, 2698, 12, 48172, 24420, 10024, 11, 291, 393, 17522, 309, 294, 257, 1729, 6700, 11, 50879, 50879, 293, 586, 291, 486, 1466, 257, 10290, 337, 428, 4846, 1412, 13, 51052, 51052, 400, 8725, 281, 691, 3045, 575, 668, 11, 286, 914, 11, 309, 575, 767, 4898, 257, 688, 295, 6228, 294, 5673, 295, 5821, 13, 51335, 51335, 400, 341, 2302, 1333, 295, 35521, 2316, 575, 7547, 257, 688, 295, 589, 294, 3820, 5201, 51542, 51542, 382, 731, 13, 51674, 51674], "temperature": 0.0, "avg_logprob": -0.1147029932262828, "compression_ratio": 1.6313725490196078, "no_speech_prob": 9.368127393827308e-06}, {"id": 138, "seek": 57384, "start": 587.6, "end": 593.26, "text": " And Word to Vec has been, I mean, it has actually shown a lot of promise in variety of applications.", "tokens": [50364, 400, 2212, 341, 4319, 11, 291, 1029, 264, 2316, 281, 6069, 341, 3779, 13, 50604, 50604, 400, 370, 291, 362, 428, 2698, 12, 48172, 24420, 10024, 11, 291, 393, 17522, 309, 294, 257, 1729, 6700, 11, 50879, 50879, 293, 586, 291, 486, 1466, 257, 10290, 337, 428, 4846, 1412, 13, 51052, 51052, 400, 8725, 281, 691, 3045, 575, 668, 11, 286, 914, 11, 309, 575, 767, 4898, 257, 688, 295, 6228, 294, 5673, 295, 5821, 13, 51335, 51335, 400, 341, 2302, 1333, 295, 35521, 2316, 575, 7547, 257, 688, 295, 589, 294, 3820, 5201, 51542, 51542, 382, 731, 13, 51674, 51674], "temperature": 0.0, "avg_logprob": -0.1147029932262828, "compression_ratio": 1.6313725490196078, "no_speech_prob": 9.368127393827308e-06}, {"id": 139, "seek": 57384, "start": 593.26, "end": 597.4, "text": " And this entire sort of predictive model has inspired a lot of work in computer vision", "tokens": [50364, 400, 2212, 341, 4319, 11, 291, 1029, 264, 2316, 281, 6069, 341, 3779, 13, 50604, 50604, 400, 370, 291, 362, 428, 2698, 12, 48172, 24420, 10024, 11, 291, 393, 17522, 309, 294, 257, 1729, 6700, 11, 50879, 50879, 293, 586, 291, 486, 1466, 257, 10290, 337, 428, 4846, 1412, 13, 51052, 51052, 400, 8725, 281, 691, 3045, 575, 668, 11, 286, 914, 11, 309, 575, 767, 4898, 257, 688, 295, 6228, 294, 5673, 295, 5821, 13, 51335, 51335, 400, 341, 2302, 1333, 295, 35521, 2316, 575, 7547, 257, 688, 295, 589, 294, 3820, 5201, 51542, 51542, 382, 731, 13, 51674, 51674], "temperature": 0.0, "avg_logprob": -0.1147029932262828, "compression_ratio": 1.6313725490196078, "no_speech_prob": 9.368127393827308e-06}, {"id": 140, "seek": 57384, "start": 597.4, "end": 600.0400000000001, "text": " as well.", "tokens": [50364, 400, 2212, 341, 4319, 11, 291, 1029, 264, 2316, 281, 6069, 341, 3779, 13, 50604, 50604, 400, 370, 291, 362, 428, 2698, 12, 48172, 24420, 10024, 11, 291, 393, 17522, 309, 294, 257, 1729, 6700, 11, 50879, 50879, 293, 586, 291, 486, 1466, 257, 10290, 337, 428, 4846, 1412, 13, 51052, 51052, 400, 8725, 281, 691, 3045, 575, 668, 11, 286, 914, 11, 309, 575, 767, 4898, 257, 688, 295, 6228, 294, 5673, 295, 5821, 13, 51335, 51335, 400, 341, 2302, 1333, 295, 35521, 2316, 575, 7547, 257, 688, 295, 589, 294, 3820, 5201, 51542, 51542, 382, 731, 13, 51674, 51674], "temperature": 0.0, "avg_logprob": -0.1147029932262828, "compression_ratio": 1.6313725490196078, "no_speech_prob": 9.368127393827308e-06}, {"id": 141, "seek": 60004, "start": 600.04, "end": 605.28, "text": " The success of self-supervised learning is sort of undebatable in natural language processing.", "tokens": [50364, 440, 2245, 295, 2698, 12, 48172, 24420, 2539, 307, 1333, 295, 40981, 11980, 712, 294, 3303, 2856, 9007, 13, 50626, 50626, 407, 294, 6096, 11, 456, 390, 341, 534, 4406, 2316, 1219, 363, 31479, 11, 597, 1936, 307, 257, 1254, 50948, 50948, 295, 257, 45249, 8399, 22660, 19866, 13, 51060, 51060, 400, 341, 2316, 575, 1333, 295, 8894, 1602, 264, 2372, 295, 721, 300, 291, 393, 360, 294, 426, 45196, 51282, 51282, 365, 5567, 2372, 295, 1412, 13, 51358, 51358, 400, 257, 688, 295, 561, 818, 341, 264, 29903, 31890, 1623, 295, 426, 45196, 13, 51616, 51616], "temperature": 0.0, "avg_logprob": -0.10893132951524523, "compression_ratio": 1.5528455284552845, "no_speech_prob": 8.01316764409421e-06}, {"id": 142, "seek": 60004, "start": 605.28, "end": 611.7199999999999, "text": " So in 2018, there was this really successful model called BERT, which basically is a form", "tokens": [50364, 440, 2245, 295, 2698, 12, 48172, 24420, 2539, 307, 1333, 295, 40981, 11980, 712, 294, 3303, 2856, 9007, 13, 50626, 50626, 407, 294, 6096, 11, 456, 390, 341, 534, 4406, 2316, 1219, 363, 31479, 11, 597, 1936, 307, 257, 1254, 50948, 50948, 295, 257, 45249, 8399, 22660, 19866, 13, 51060, 51060, 400, 341, 2316, 575, 1333, 295, 8894, 1602, 264, 2372, 295, 721, 300, 291, 393, 360, 294, 426, 45196, 51282, 51282, 365, 5567, 2372, 295, 1412, 13, 51358, 51358, 400, 257, 688, 295, 561, 818, 341, 264, 29903, 31890, 1623, 295, 426, 45196, 13, 51616, 51616], "temperature": 0.0, "avg_logprob": -0.10893132951524523, "compression_ratio": 1.5528455284552845, "no_speech_prob": 8.01316764409421e-06}, {"id": 143, "seek": 60004, "start": 611.7199999999999, "end": 613.9599999999999, "text": " of a masked autoencoder.", "tokens": [50364, 440, 2245, 295, 2698, 12, 48172, 24420, 2539, 307, 1333, 295, 40981, 11980, 712, 294, 3303, 2856, 9007, 13, 50626, 50626, 407, 294, 6096, 11, 456, 390, 341, 534, 4406, 2316, 1219, 363, 31479, 11, 597, 1936, 307, 257, 1254, 50948, 50948, 295, 257, 45249, 8399, 22660, 19866, 13, 51060, 51060, 400, 341, 2316, 575, 1333, 295, 8894, 1602, 264, 2372, 295, 721, 300, 291, 393, 360, 294, 426, 45196, 51282, 51282, 365, 5567, 2372, 295, 1412, 13, 51358, 51358, 400, 257, 688, 295, 561, 818, 341, 264, 29903, 31890, 1623, 295, 426, 45196, 13, 51616, 51616], "temperature": 0.0, "avg_logprob": -0.10893132951524523, "compression_ratio": 1.5528455284552845, "no_speech_prob": 8.01316764409421e-06}, {"id": 144, "seek": 60004, "start": 613.9599999999999, "end": 618.4, "text": " And this model has sort of revolutionized the amount of things that you can do in NLP", "tokens": [50364, 440, 2245, 295, 2698, 12, 48172, 24420, 2539, 307, 1333, 295, 40981, 11980, 712, 294, 3303, 2856, 9007, 13, 50626, 50626, 407, 294, 6096, 11, 456, 390, 341, 534, 4406, 2316, 1219, 363, 31479, 11, 597, 1936, 307, 257, 1254, 50948, 50948, 295, 257, 45249, 8399, 22660, 19866, 13, 51060, 51060, 400, 341, 2316, 575, 1333, 295, 8894, 1602, 264, 2372, 295, 721, 300, 291, 393, 360, 294, 426, 45196, 51282, 51282, 365, 5567, 2372, 295, 1412, 13, 51358, 51358, 400, 257, 688, 295, 561, 818, 341, 264, 29903, 31890, 1623, 295, 426, 45196, 13, 51616, 51616], "temperature": 0.0, "avg_logprob": -0.10893132951524523, "compression_ratio": 1.5528455284552845, "no_speech_prob": 8.01316764409421e-06}, {"id": 145, "seek": 60004, "start": 618.4, "end": 619.92, "text": " with limited amount of data.", "tokens": [50364, 440, 2245, 295, 2698, 12, 48172, 24420, 2539, 307, 1333, 295, 40981, 11980, 712, 294, 3303, 2856, 9007, 13, 50626, 50626, 407, 294, 6096, 11, 456, 390, 341, 534, 4406, 2316, 1219, 363, 31479, 11, 597, 1936, 307, 257, 1254, 50948, 50948, 295, 257, 45249, 8399, 22660, 19866, 13, 51060, 51060, 400, 341, 2316, 575, 1333, 295, 8894, 1602, 264, 2372, 295, 721, 300, 291, 393, 360, 294, 426, 45196, 51282, 51282, 365, 5567, 2372, 295, 1412, 13, 51358, 51358, 400, 257, 688, 295, 561, 818, 341, 264, 29903, 31890, 1623, 295, 426, 45196, 13, 51616, 51616], "temperature": 0.0, "avg_logprob": -0.10893132951524523, "compression_ratio": 1.5528455284552845, "no_speech_prob": 8.01316764409421e-06}, {"id": 146, "seek": 60004, "start": 619.92, "end": 625.0799999999999, "text": " And a lot of people call this the ImageNet moment of NLP.", "tokens": [50364, 440, 2245, 295, 2698, 12, 48172, 24420, 2539, 307, 1333, 295, 40981, 11980, 712, 294, 3303, 2856, 9007, 13, 50626, 50626, 407, 294, 6096, 11, 456, 390, 341, 534, 4406, 2316, 1219, 363, 31479, 11, 597, 1936, 307, 257, 1254, 50948, 50948, 295, 257, 45249, 8399, 22660, 19866, 13, 51060, 51060, 400, 341, 2316, 575, 1333, 295, 8894, 1602, 264, 2372, 295, 721, 300, 291, 393, 360, 294, 426, 45196, 51282, 51282, 365, 5567, 2372, 295, 1412, 13, 51358, 51358, 400, 257, 688, 295, 561, 818, 341, 264, 29903, 31890, 1623, 295, 426, 45196, 13, 51616, 51616], "temperature": 0.0, "avg_logprob": -0.10893132951524523, "compression_ratio": 1.5528455284552845, "no_speech_prob": 8.01316764409421e-06}, {"id": 147, "seek": 62508, "start": 625.08, "end": 630.64, "text": " So in this talk, we'll sort of, again, to motivate why we want to use self-supervised", "tokens": [50364, 407, 294, 341, 751, 11, 321, 603, 1333, 295, 11, 797, 11, 281, 28497, 983, 321, 528, 281, 764, 2698, 12, 48172, 24420, 50642, 50642, 2539, 13, 50692, 50692, 492, 366, 534, 516, 281, 1879, 322, 1333, 295, 577, 291, 393, 574, 412, 1412, 293, 291, 393, 764, 18163, 51056, 51056, 293, 13280, 295, 264, 1412, 281, 47881, 2698, 12, 48172, 24420, 9608, 11, 577, 291, 393, 13982, 51257, 51257, 3866, 1072, 16110, 13, 51307, 51307, 400, 286, 603, 751, 257, 707, 857, 544, 466, 437, 341, 1433, 1072, 16110, 1355, 11, 420, 3877, 294, 51566, 51566, 264, 1412, 281, 1333, 295, 1466, 264, 33358, 13, 51830, 51830], "temperature": 0.0, "avg_logprob": -0.11120770194313744, "compression_ratio": 1.7622950819672132, "no_speech_prob": 1.0287901204719674e-05}, {"id": 148, "seek": 62508, "start": 630.64, "end": 631.64, "text": " learning.", "tokens": [50364, 407, 294, 341, 751, 11, 321, 603, 1333, 295, 11, 797, 11, 281, 28497, 983, 321, 528, 281, 764, 2698, 12, 48172, 24420, 50642, 50642, 2539, 13, 50692, 50692, 492, 366, 534, 516, 281, 1879, 322, 1333, 295, 577, 291, 393, 574, 412, 1412, 293, 291, 393, 764, 18163, 51056, 51056, 293, 13280, 295, 264, 1412, 281, 47881, 2698, 12, 48172, 24420, 9608, 11, 577, 291, 393, 13982, 51257, 51257, 3866, 1072, 16110, 13, 51307, 51307, 400, 286, 603, 751, 257, 707, 857, 544, 466, 437, 341, 1433, 1072, 16110, 1355, 11, 420, 3877, 294, 51566, 51566, 264, 1412, 281, 1333, 295, 1466, 264, 33358, 13, 51830, 51830], "temperature": 0.0, "avg_logprob": -0.11120770194313744, "compression_ratio": 1.7622950819672132, "no_speech_prob": 1.0287901204719674e-05}, {"id": 149, "seek": 62508, "start": 631.64, "end": 638.9200000000001, "text": " We are really going to focus on sort of how you can look at data and you can use observations", "tokens": [50364, 407, 294, 341, 751, 11, 321, 603, 1333, 295, 11, 797, 11, 281, 28497, 983, 321, 528, 281, 764, 2698, 12, 48172, 24420, 50642, 50642, 2539, 13, 50692, 50692, 492, 366, 534, 516, 281, 1879, 322, 1333, 295, 577, 291, 393, 574, 412, 1412, 293, 291, 393, 764, 18163, 51056, 51056, 293, 13280, 295, 264, 1412, 281, 47881, 2698, 12, 48172, 24420, 9608, 11, 577, 291, 393, 13982, 51257, 51257, 3866, 1072, 16110, 13, 51307, 51307, 400, 286, 603, 751, 257, 707, 857, 544, 466, 437, 341, 1433, 1072, 16110, 1355, 11, 420, 3877, 294, 51566, 51566, 264, 1412, 281, 1333, 295, 1466, 264, 33358, 13, 51830, 51830], "temperature": 0.0, "avg_logprob": -0.11120770194313744, "compression_ratio": 1.7622950819672132, "no_speech_prob": 1.0287901204719674e-05}, {"id": 150, "seek": 62508, "start": 638.9200000000001, "end": 642.94, "text": " and interactions of the data to formulate self-supervised tasks, how you can leverage", "tokens": [50364, 407, 294, 341, 751, 11, 321, 603, 1333, 295, 11, 797, 11, 281, 28497, 983, 321, 528, 281, 764, 2698, 12, 48172, 24420, 50642, 50642, 2539, 13, 50692, 50692, 492, 366, 534, 516, 281, 1879, 322, 1333, 295, 577, 291, 393, 574, 412, 1412, 293, 291, 393, 764, 18163, 51056, 51056, 293, 13280, 295, 264, 1412, 281, 47881, 2698, 12, 48172, 24420, 9608, 11, 577, 291, 393, 13982, 51257, 51257, 3866, 1072, 16110, 13, 51307, 51307, 400, 286, 603, 751, 257, 707, 857, 544, 466, 437, 341, 1433, 1072, 16110, 1355, 11, 420, 3877, 294, 51566, 51566, 264, 1412, 281, 1333, 295, 1466, 264, 33358, 13, 51830, 51830], "temperature": 0.0, "avg_logprob": -0.11120770194313744, "compression_ratio": 1.7622950819672132, "no_speech_prob": 1.0287901204719674e-05}, {"id": 151, "seek": 62508, "start": 642.94, "end": 643.94, "text": " multiple modalities.", "tokens": [50364, 407, 294, 341, 751, 11, 321, 603, 1333, 295, 11, 797, 11, 281, 28497, 983, 321, 528, 281, 764, 2698, 12, 48172, 24420, 50642, 50642, 2539, 13, 50692, 50692, 492, 366, 534, 516, 281, 1879, 322, 1333, 295, 577, 291, 393, 574, 412, 1412, 293, 291, 393, 764, 18163, 51056, 51056, 293, 13280, 295, 264, 1412, 281, 47881, 2698, 12, 48172, 24420, 9608, 11, 577, 291, 393, 13982, 51257, 51257, 3866, 1072, 16110, 13, 51307, 51307, 400, 286, 603, 751, 257, 707, 857, 544, 466, 437, 341, 1433, 1072, 16110, 1355, 11, 420, 3877, 294, 51566, 51566, 264, 1412, 281, 1333, 295, 1466, 264, 33358, 13, 51830, 51830], "temperature": 0.0, "avg_logprob": -0.11120770194313744, "compression_ratio": 1.7622950819672132, "no_speech_prob": 1.0287901204719674e-05}, {"id": 152, "seek": 62508, "start": 643.94, "end": 649.12, "text": " And I'll talk a little bit more about what this term modalities means, or structure in", "tokens": [50364, 407, 294, 341, 751, 11, 321, 603, 1333, 295, 11, 797, 11, 281, 28497, 983, 321, 528, 281, 764, 2698, 12, 48172, 24420, 50642, 50642, 2539, 13, 50692, 50692, 492, 366, 534, 516, 281, 1879, 322, 1333, 295, 577, 291, 393, 574, 412, 1412, 293, 291, 393, 764, 18163, 51056, 51056, 293, 13280, 295, 264, 1412, 281, 47881, 2698, 12, 48172, 24420, 9608, 11, 577, 291, 393, 13982, 51257, 51257, 3866, 1072, 16110, 13, 51307, 51307, 400, 286, 603, 751, 257, 707, 857, 544, 466, 437, 341, 1433, 1072, 16110, 1355, 11, 420, 3877, 294, 51566, 51566, 264, 1412, 281, 1333, 295, 1466, 264, 33358, 13, 51830, 51830], "temperature": 0.0, "avg_logprob": -0.11120770194313744, "compression_ratio": 1.7622950819672132, "no_speech_prob": 1.0287901204719674e-05}, {"id": 153, "seek": 62508, "start": 649.12, "end": 654.4000000000001, "text": " the data to sort of learn the representations.", "tokens": [50364, 407, 294, 341, 751, 11, 321, 603, 1333, 295, 11, 797, 11, 281, 28497, 983, 321, 528, 281, 764, 2698, 12, 48172, 24420, 50642, 50642, 2539, 13, 50692, 50692, 492, 366, 534, 516, 281, 1879, 322, 1333, 295, 577, 291, 393, 574, 412, 1412, 293, 291, 393, 764, 18163, 51056, 51056, 293, 13280, 295, 264, 1412, 281, 47881, 2698, 12, 48172, 24420, 9608, 11, 577, 291, 393, 13982, 51257, 51257, 3866, 1072, 16110, 13, 51307, 51307, 400, 286, 603, 751, 257, 707, 857, 544, 466, 437, 341, 1433, 1072, 16110, 1355, 11, 420, 3877, 294, 51566, 51566, 264, 1412, 281, 1333, 295, 1466, 264, 33358, 13, 51830, 51830], "temperature": 0.0, "avg_logprob": -0.11120770194313744, "compression_ratio": 1.7622950819672132, "no_speech_prob": 1.0287901204719674e-05}, {"id": 154, "seek": 65440, "start": 654.4, "end": 657.36, "text": " So let's move on to the context of computer vision.", "tokens": [50364, 407, 718, 311, 1286, 322, 281, 264, 4319, 295, 3820, 5201, 13, 50512, 50512, 400, 286, 603, 1333, 295, 586, 853, 281, 6964, 721, 300, 286, 600, 668, 1417, 466, 294, 257, 4748, 50708, 50708, 1090, 1496, 294, 544, 9859, 6700, 13, 50832, 50832, 2386, 1168, 13, 50882, 50882, 407, 2698, 12, 48172, 24420, 2539, 307, 1936, 445, 2693, 12879, 24420, 2539, 11, 558, 30, 51118, 51118, 1079, 13, 51168, 51168, 286, 914, 11, 2086, 11, 2086, 13, 51354, 51354, 286, 914, 11, 1936, 264, 1333, 295, 2135, 7300, 411, 2693, 12879, 24420, 307, 257, 1333, 295, 588, 22271, 51714, 51714, 7642, 1433, 13, 51764, 51764], "temperature": 0.0, "avg_logprob": -0.2158188466672544, "compression_ratio": 1.6470588235294117, "no_speech_prob": 1.862991484813392e-05}, {"id": 155, "seek": 65440, "start": 657.36, "end": 661.28, "text": " And I'll sort of now try to define things that I've been talking about in a slightly", "tokens": [50364, 407, 718, 311, 1286, 322, 281, 264, 4319, 295, 3820, 5201, 13, 50512, 50512, 400, 286, 603, 1333, 295, 586, 853, 281, 6964, 721, 300, 286, 600, 668, 1417, 466, 294, 257, 4748, 50708, 50708, 1090, 1496, 294, 544, 9859, 6700, 13, 50832, 50832, 2386, 1168, 13, 50882, 50882, 407, 2698, 12, 48172, 24420, 2539, 307, 1936, 445, 2693, 12879, 24420, 2539, 11, 558, 30, 51118, 51118, 1079, 13, 51168, 51168, 286, 914, 11, 2086, 11, 2086, 13, 51354, 51354, 286, 914, 11, 1936, 264, 1333, 295, 2135, 7300, 411, 2693, 12879, 24420, 307, 257, 1333, 295, 588, 22271, 51714, 51714, 7642, 1433, 13, 51764, 51764], "temperature": 0.0, "avg_logprob": -0.2158188466672544, "compression_ratio": 1.6470588235294117, "no_speech_prob": 1.862991484813392e-05}, {"id": 156, "seek": 65440, "start": 661.28, "end": 663.76, "text": " high level in more concrete fashion.", "tokens": [50364, 407, 718, 311, 1286, 322, 281, 264, 4319, 295, 3820, 5201, 13, 50512, 50512, 400, 286, 603, 1333, 295, 586, 853, 281, 6964, 721, 300, 286, 600, 668, 1417, 466, 294, 257, 4748, 50708, 50708, 1090, 1496, 294, 544, 9859, 6700, 13, 50832, 50832, 2386, 1168, 13, 50882, 50882, 407, 2698, 12, 48172, 24420, 2539, 307, 1936, 445, 2693, 12879, 24420, 2539, 11, 558, 30, 51118, 51118, 1079, 13, 51168, 51168, 286, 914, 11, 2086, 11, 2086, 13, 51354, 51354, 286, 914, 11, 1936, 264, 1333, 295, 2135, 7300, 411, 2693, 12879, 24420, 307, 257, 1333, 295, 588, 22271, 51714, 51714, 7642, 1433, 13, 51764, 51764], "temperature": 0.0, "avg_logprob": -0.2158188466672544, "compression_ratio": 1.6470588235294117, "no_speech_prob": 1.862991484813392e-05}, {"id": 157, "seek": 65440, "start": 663.76, "end": 664.76, "text": " First question.", "tokens": [50364, 407, 718, 311, 1286, 322, 281, 264, 4319, 295, 3820, 5201, 13, 50512, 50512, 400, 286, 603, 1333, 295, 586, 853, 281, 6964, 721, 300, 286, 600, 668, 1417, 466, 294, 257, 4748, 50708, 50708, 1090, 1496, 294, 544, 9859, 6700, 13, 50832, 50832, 2386, 1168, 13, 50882, 50882, 407, 2698, 12, 48172, 24420, 2539, 307, 1936, 445, 2693, 12879, 24420, 2539, 11, 558, 30, 51118, 51118, 1079, 13, 51168, 51168, 286, 914, 11, 2086, 11, 2086, 13, 51354, 51354, 286, 914, 11, 1936, 264, 1333, 295, 2135, 7300, 411, 2693, 12879, 24420, 307, 257, 1333, 295, 588, 22271, 51714, 51714, 7642, 1433, 13, 51764, 51764], "temperature": 0.0, "avg_logprob": -0.2158188466672544, "compression_ratio": 1.6470588235294117, "no_speech_prob": 1.862991484813392e-05}, {"id": 158, "seek": 65440, "start": 664.76, "end": 669.48, "text": " So self-supervised learning is basically just unsupervised learning, right?", "tokens": [50364, 407, 718, 311, 1286, 322, 281, 264, 4319, 295, 3820, 5201, 13, 50512, 50512, 400, 286, 603, 1333, 295, 586, 853, 281, 6964, 721, 300, 286, 600, 668, 1417, 466, 294, 257, 4748, 50708, 50708, 1090, 1496, 294, 544, 9859, 6700, 13, 50832, 50832, 2386, 1168, 13, 50882, 50882, 407, 2698, 12, 48172, 24420, 2539, 307, 1936, 445, 2693, 12879, 24420, 2539, 11, 558, 30, 51118, 51118, 1079, 13, 51168, 51168, 286, 914, 11, 2086, 11, 2086, 13, 51354, 51354, 286, 914, 11, 1936, 264, 1333, 295, 2135, 7300, 411, 2693, 12879, 24420, 307, 257, 1333, 295, 588, 22271, 51714, 51714, 7642, 1433, 13, 51764, 51764], "temperature": 0.0, "avg_logprob": -0.2158188466672544, "compression_ratio": 1.6470588235294117, "no_speech_prob": 1.862991484813392e-05}, {"id": 159, "seek": 65440, "start": 669.48, "end": 670.48, "text": " Yes.", "tokens": [50364, 407, 718, 311, 1286, 322, 281, 264, 4319, 295, 3820, 5201, 13, 50512, 50512, 400, 286, 603, 1333, 295, 586, 853, 281, 6964, 721, 300, 286, 600, 668, 1417, 466, 294, 257, 4748, 50708, 50708, 1090, 1496, 294, 544, 9859, 6700, 13, 50832, 50832, 2386, 1168, 13, 50882, 50882, 407, 2698, 12, 48172, 24420, 2539, 307, 1936, 445, 2693, 12879, 24420, 2539, 11, 558, 30, 51118, 51118, 1079, 13, 51168, 51168, 286, 914, 11, 2086, 11, 2086, 13, 51354, 51354, 286, 914, 11, 1936, 264, 1333, 295, 2135, 7300, 411, 2693, 12879, 24420, 307, 257, 1333, 295, 588, 22271, 51714, 51714, 7642, 1433, 13, 51764, 51764], "temperature": 0.0, "avg_logprob": -0.2158188466672544, "compression_ratio": 1.6470588235294117, "no_speech_prob": 1.862991484813392e-05}, {"id": 160, "seek": 65440, "start": 670.48, "end": 674.1999999999999, "text": " I mean, yes, yes.", "tokens": [50364, 407, 718, 311, 1286, 322, 281, 264, 4319, 295, 3820, 5201, 13, 50512, 50512, 400, 286, 603, 1333, 295, 586, 853, 281, 6964, 721, 300, 286, 600, 668, 1417, 466, 294, 257, 4748, 50708, 50708, 1090, 1496, 294, 544, 9859, 6700, 13, 50832, 50832, 2386, 1168, 13, 50882, 50882, 407, 2698, 12, 48172, 24420, 2539, 307, 1936, 445, 2693, 12879, 24420, 2539, 11, 558, 30, 51118, 51118, 1079, 13, 51168, 51168, 286, 914, 11, 2086, 11, 2086, 13, 51354, 51354, 286, 914, 11, 1936, 264, 1333, 295, 2135, 7300, 411, 2693, 12879, 24420, 307, 257, 1333, 295, 588, 22271, 51714, 51714, 7642, 1433, 13, 51764, 51764], "temperature": 0.0, "avg_logprob": -0.2158188466672544, "compression_ratio": 1.6470588235294117, "no_speech_prob": 1.862991484813392e-05}, {"id": 161, "seek": 65440, "start": 674.1999999999999, "end": 681.4, "text": " I mean, basically the sort of main differences like unsupervised is a sort of very poorly", "tokens": [50364, 407, 718, 311, 1286, 322, 281, 264, 4319, 295, 3820, 5201, 13, 50512, 50512, 400, 286, 603, 1333, 295, 586, 853, 281, 6964, 721, 300, 286, 600, 668, 1417, 466, 294, 257, 4748, 50708, 50708, 1090, 1496, 294, 544, 9859, 6700, 13, 50832, 50832, 2386, 1168, 13, 50882, 50882, 407, 2698, 12, 48172, 24420, 2539, 307, 1936, 445, 2693, 12879, 24420, 2539, 11, 558, 30, 51118, 51118, 1079, 13, 51168, 51168, 286, 914, 11, 2086, 11, 2086, 13, 51354, 51354, 286, 914, 11, 1936, 264, 1333, 295, 2135, 7300, 411, 2693, 12879, 24420, 307, 257, 1333, 295, 588, 22271, 51714, 51714, 7642, 1433, 13, 51764, 51764], "temperature": 0.0, "avg_logprob": -0.2158188466672544, "compression_ratio": 1.6470588235294117, "no_speech_prob": 1.862991484813392e-05}, {"id": 162, "seek": 65440, "start": 681.4, "end": 682.4, "text": " defined term.", "tokens": [50364, 407, 718, 311, 1286, 322, 281, 264, 4319, 295, 3820, 5201, 13, 50512, 50512, 400, 286, 603, 1333, 295, 586, 853, 281, 6964, 721, 300, 286, 600, 668, 1417, 466, 294, 257, 4748, 50708, 50708, 1090, 1496, 294, 544, 9859, 6700, 13, 50832, 50832, 2386, 1168, 13, 50882, 50882, 407, 2698, 12, 48172, 24420, 2539, 307, 1936, 445, 2693, 12879, 24420, 2539, 11, 558, 30, 51118, 51118, 1079, 13, 51168, 51168, 286, 914, 11, 2086, 11, 2086, 13, 51354, 51354, 286, 914, 11, 1936, 264, 1333, 295, 2135, 7300, 411, 2693, 12879, 24420, 307, 257, 1333, 295, 588, 22271, 51714, 51714, 7642, 1433, 13, 51764, 51764], "temperature": 0.0, "avg_logprob": -0.2158188466672544, "compression_ratio": 1.6470588235294117, "no_speech_prob": 1.862991484813392e-05}, {"id": 163, "seek": 68240, "start": 682.4, "end": 685.48, "text": " So what is supervised, but what is unsupervised?", "tokens": [50364, 407, 437, 307, 46533, 11, 457, 437, 307, 2693, 12879, 24420, 30, 50518, 50518, 407, 337, 1365, 11, 264, 21663, 2212, 538, 508, 270, 27332, 5746, 1035, 307, 456, 307, 257, 3857, 11, 457, 456, 307, 572, 7719, 50806, 50806, 1219, 517, 12, 18035, 13, 50924, 50924, 407, 300, 311, 264, 1778, 281, 1333, 295, 808, 411, 4382, 341, 1433, 544, 293, 544, 300, 309, 311, 534, 51134, 51134, 466, 1228, 264, 1412, 420, 264, 7221, 295, 264, 1412, 2564, 281, 808, 493, 365, 32675, 13, 51387, 51387, 407, 300, 311, 983, 2698, 12, 48172, 6763, 13, 51526, 51526, 407, 1580, 307, 18094, 309, 311, 257, 25993, 13, 51652, 51652, 1079, 11, 286, 2041, 13, 51788, 51788, 1079, 13, 51838, 51838], "temperature": 0.0, "avg_logprob": -0.2018546282760496, "compression_ratio": 1.75, "no_speech_prob": 0.00039008556632325053}, {"id": 164, "seek": 68240, "start": 685.48, "end": 691.24, "text": " So for example, the analogy given by Jitendra Malik is there is a cat, but there is no category", "tokens": [50364, 407, 437, 307, 46533, 11, 457, 437, 307, 2693, 12879, 24420, 30, 50518, 50518, 407, 337, 1365, 11, 264, 21663, 2212, 538, 508, 270, 27332, 5746, 1035, 307, 456, 307, 257, 3857, 11, 457, 456, 307, 572, 7719, 50806, 50806, 1219, 517, 12, 18035, 13, 50924, 50924, 407, 300, 311, 264, 1778, 281, 1333, 295, 808, 411, 4382, 341, 1433, 544, 293, 544, 300, 309, 311, 534, 51134, 51134, 466, 1228, 264, 1412, 420, 264, 7221, 295, 264, 1412, 2564, 281, 808, 493, 365, 32675, 13, 51387, 51387, 407, 300, 311, 983, 2698, 12, 48172, 6763, 13, 51526, 51526, 407, 1580, 307, 18094, 309, 311, 257, 25993, 13, 51652, 51652, 1079, 11, 286, 2041, 13, 51788, 51788, 1079, 13, 51838, 51838], "temperature": 0.0, "avg_logprob": -0.2018546282760496, "compression_ratio": 1.75, "no_speech_prob": 0.00039008556632325053}, {"id": 165, "seek": 68240, "start": 691.24, "end": 693.6, "text": " called un-cat.", "tokens": [50364, 407, 437, 307, 46533, 11, 457, 437, 307, 2693, 12879, 24420, 30, 50518, 50518, 407, 337, 1365, 11, 264, 21663, 2212, 538, 508, 270, 27332, 5746, 1035, 307, 456, 307, 257, 3857, 11, 457, 456, 307, 572, 7719, 50806, 50806, 1219, 517, 12, 18035, 13, 50924, 50924, 407, 300, 311, 264, 1778, 281, 1333, 295, 808, 411, 4382, 341, 1433, 544, 293, 544, 300, 309, 311, 534, 51134, 51134, 466, 1228, 264, 1412, 420, 264, 7221, 295, 264, 1412, 2564, 281, 808, 493, 365, 32675, 13, 51387, 51387, 407, 300, 311, 983, 2698, 12, 48172, 6763, 13, 51526, 51526, 407, 1580, 307, 18094, 309, 311, 257, 25993, 13, 51652, 51652, 1079, 11, 286, 2041, 13, 51788, 51788, 1079, 13, 51838, 51838], "temperature": 0.0, "avg_logprob": -0.2018546282760496, "compression_ratio": 1.75, "no_speech_prob": 0.00039008556632325053}, {"id": 166, "seek": 68240, "start": 693.6, "end": 697.8, "text": " So that's the reason to sort of come like prefer this term more and more that it's really", "tokens": [50364, 407, 437, 307, 46533, 11, 457, 437, 307, 2693, 12879, 24420, 30, 50518, 50518, 407, 337, 1365, 11, 264, 21663, 2212, 538, 508, 270, 27332, 5746, 1035, 307, 456, 307, 257, 3857, 11, 457, 456, 307, 572, 7719, 50806, 50806, 1219, 517, 12, 18035, 13, 50924, 50924, 407, 300, 311, 264, 1778, 281, 1333, 295, 808, 411, 4382, 341, 1433, 544, 293, 544, 300, 309, 311, 534, 51134, 51134, 466, 1228, 264, 1412, 420, 264, 7221, 295, 264, 1412, 2564, 281, 808, 493, 365, 32675, 13, 51387, 51387, 407, 300, 311, 983, 2698, 12, 48172, 6763, 13, 51526, 51526, 407, 1580, 307, 18094, 309, 311, 257, 25993, 13, 51652, 51652, 1079, 11, 286, 2041, 13, 51788, 51788, 1079, 13, 51838, 51838], "temperature": 0.0, "avg_logprob": -0.2018546282760496, "compression_ratio": 1.75, "no_speech_prob": 0.00039008556632325053}, {"id": 167, "seek": 68240, "start": 697.8, "end": 702.86, "text": " about using the data or the properties of the data itself to come up with supervision.", "tokens": [50364, 407, 437, 307, 46533, 11, 457, 437, 307, 2693, 12879, 24420, 30, 50518, 50518, 407, 337, 1365, 11, 264, 21663, 2212, 538, 508, 270, 27332, 5746, 1035, 307, 456, 307, 257, 3857, 11, 457, 456, 307, 572, 7719, 50806, 50806, 1219, 517, 12, 18035, 13, 50924, 50924, 407, 300, 311, 264, 1778, 281, 1333, 295, 808, 411, 4382, 341, 1433, 544, 293, 544, 300, 309, 311, 534, 51134, 51134, 466, 1228, 264, 1412, 420, 264, 7221, 295, 264, 1412, 2564, 281, 808, 493, 365, 32675, 13, 51387, 51387, 407, 300, 311, 983, 2698, 12, 48172, 6763, 13, 51526, 51526, 407, 1580, 307, 18094, 309, 311, 257, 25993, 13, 51652, 51652, 1079, 11, 286, 2041, 13, 51788, 51788, 1079, 13, 51838, 51838], "temperature": 0.0, "avg_logprob": -0.2018546282760496, "compression_ratio": 1.75, "no_speech_prob": 0.00039008556632325053}, {"id": 168, "seek": 68240, "start": 702.86, "end": 705.64, "text": " So that's why self-supervision.", "tokens": [50364, 407, 437, 307, 46533, 11, 457, 437, 307, 2693, 12879, 24420, 30, 50518, 50518, 407, 337, 1365, 11, 264, 21663, 2212, 538, 508, 270, 27332, 5746, 1035, 307, 456, 307, 257, 3857, 11, 457, 456, 307, 572, 7719, 50806, 50806, 1219, 517, 12, 18035, 13, 50924, 50924, 407, 300, 311, 264, 1778, 281, 1333, 295, 808, 411, 4382, 341, 1433, 544, 293, 544, 300, 309, 311, 534, 51134, 51134, 466, 1228, 264, 1412, 420, 264, 7221, 295, 264, 1412, 2564, 281, 808, 493, 365, 32675, 13, 51387, 51387, 407, 300, 311, 983, 2698, 12, 48172, 6763, 13, 51526, 51526, 407, 1580, 307, 18094, 309, 311, 257, 25993, 13, 51652, 51652, 1079, 11, 286, 2041, 13, 51788, 51788, 1079, 13, 51838, 51838], "temperature": 0.0, "avg_logprob": -0.2018546282760496, "compression_ratio": 1.75, "no_speech_prob": 0.00039008556632325053}, {"id": 169, "seek": 68240, "start": 705.64, "end": 708.16, "text": " So someone is suggesting it's a subset.", "tokens": [50364, 407, 437, 307, 46533, 11, 457, 437, 307, 2693, 12879, 24420, 30, 50518, 50518, 407, 337, 1365, 11, 264, 21663, 2212, 538, 508, 270, 27332, 5746, 1035, 307, 456, 307, 257, 3857, 11, 457, 456, 307, 572, 7719, 50806, 50806, 1219, 517, 12, 18035, 13, 50924, 50924, 407, 300, 311, 264, 1778, 281, 1333, 295, 808, 411, 4382, 341, 1433, 544, 293, 544, 300, 309, 311, 534, 51134, 51134, 466, 1228, 264, 1412, 420, 264, 7221, 295, 264, 1412, 2564, 281, 808, 493, 365, 32675, 13, 51387, 51387, 407, 300, 311, 983, 2698, 12, 48172, 6763, 13, 51526, 51526, 407, 1580, 307, 18094, 309, 311, 257, 25993, 13, 51652, 51652, 1079, 11, 286, 2041, 13, 51788, 51788, 1079, 13, 51838, 51838], "temperature": 0.0, "avg_logprob": -0.2018546282760496, "compression_ratio": 1.75, "no_speech_prob": 0.00039008556632325053}, {"id": 170, "seek": 68240, "start": 708.16, "end": 710.88, "text": " Yes, I guess.", "tokens": [50364, 407, 437, 307, 46533, 11, 457, 437, 307, 2693, 12879, 24420, 30, 50518, 50518, 407, 337, 1365, 11, 264, 21663, 2212, 538, 508, 270, 27332, 5746, 1035, 307, 456, 307, 257, 3857, 11, 457, 456, 307, 572, 7719, 50806, 50806, 1219, 517, 12, 18035, 13, 50924, 50924, 407, 300, 311, 264, 1778, 281, 1333, 295, 808, 411, 4382, 341, 1433, 544, 293, 544, 300, 309, 311, 534, 51134, 51134, 466, 1228, 264, 1412, 420, 264, 7221, 295, 264, 1412, 2564, 281, 808, 493, 365, 32675, 13, 51387, 51387, 407, 300, 311, 983, 2698, 12, 48172, 6763, 13, 51526, 51526, 407, 1580, 307, 18094, 309, 311, 257, 25993, 13, 51652, 51652, 1079, 11, 286, 2041, 13, 51788, 51788, 1079, 13, 51838, 51838], "temperature": 0.0, "avg_logprob": -0.2018546282760496, "compression_ratio": 1.75, "no_speech_prob": 0.00039008556632325053}, {"id": 171, "seek": 68240, "start": 710.88, "end": 711.88, "text": " Yes.", "tokens": [50364, 407, 437, 307, 46533, 11, 457, 437, 307, 2693, 12879, 24420, 30, 50518, 50518, 407, 337, 1365, 11, 264, 21663, 2212, 538, 508, 270, 27332, 5746, 1035, 307, 456, 307, 257, 3857, 11, 457, 456, 307, 572, 7719, 50806, 50806, 1219, 517, 12, 18035, 13, 50924, 50924, 407, 300, 311, 264, 1778, 281, 1333, 295, 808, 411, 4382, 341, 1433, 544, 293, 544, 300, 309, 311, 534, 51134, 51134, 466, 1228, 264, 1412, 420, 264, 7221, 295, 264, 1412, 2564, 281, 808, 493, 365, 32675, 13, 51387, 51387, 407, 300, 311, 983, 2698, 12, 48172, 6763, 13, 51526, 51526, 407, 1580, 307, 18094, 309, 311, 257, 25993, 13, 51652, 51652, 1079, 11, 286, 2041, 13, 51788, 51788, 1079, 13, 51838, 51838], "temperature": 0.0, "avg_logprob": -0.2018546282760496, "compression_ratio": 1.75, "no_speech_prob": 0.00039008556632325053}, {"id": 172, "seek": 71188, "start": 711.88, "end": 720.52, "text": " I mean, I guess my reason for calling it this is that the algorithms are essentially the", "tokens": [50364, 286, 914, 11, 286, 2041, 452, 1778, 337, 5141, 309, 341, 307, 300, 264, 14642, 366, 4476, 264, 50796, 50796, 912, 382, 46533, 2539, 14642, 365, 512, 26881, 13, 50974, 50974, 1436, 291, 434, 733, 295, 3097, 264, 1185, 281, 1466, 644, 295, 1080, 4846, 490, 1071, 644, 51192, 51192, 295, 264, 4846, 13, 51242, 51242, 407, 309, 311, 588, 2531, 281, 46533, 2539, 294, 867, 2098, 11, 3993, 300, 291, 643, 281, 4813, 51476, 51476, 15697, 1101, 13, 51614, 51614, 400, 264, 3671, 7719, 11, 498, 291, 528, 11, 815, 312, 709, 4833, 11, 597, 307, 733, 295, 364, 2734, 13, 51826, 51826], "temperature": 0.0, "avg_logprob": -0.0978190134156425, "compression_ratio": 1.6853932584269662, "no_speech_prob": 2.077257704513613e-05}, {"id": 173, "seek": 71188, "start": 720.52, "end": 724.08, "text": " same as supervised learning algorithms with some modifications.", "tokens": [50364, 286, 914, 11, 286, 2041, 452, 1778, 337, 5141, 309, 341, 307, 300, 264, 14642, 366, 4476, 264, 50796, 50796, 912, 382, 46533, 2539, 14642, 365, 512, 26881, 13, 50974, 50974, 1436, 291, 434, 733, 295, 3097, 264, 1185, 281, 1466, 644, 295, 1080, 4846, 490, 1071, 644, 51192, 51192, 295, 264, 4846, 13, 51242, 51242, 407, 309, 311, 588, 2531, 281, 46533, 2539, 294, 867, 2098, 11, 3993, 300, 291, 643, 281, 4813, 51476, 51476, 15697, 1101, 13, 51614, 51614, 400, 264, 3671, 7719, 11, 498, 291, 528, 11, 815, 312, 709, 4833, 11, 597, 307, 733, 295, 364, 2734, 13, 51826, 51826], "temperature": 0.0, "avg_logprob": -0.0978190134156425, "compression_ratio": 1.6853932584269662, "no_speech_prob": 2.077257704513613e-05}, {"id": 174, "seek": 71188, "start": 724.08, "end": 728.4399999999999, "text": " Because you're kind of training the system to learn part of its input from another part", "tokens": [50364, 286, 914, 11, 286, 2041, 452, 1778, 337, 5141, 309, 341, 307, 300, 264, 14642, 366, 4476, 264, 50796, 50796, 912, 382, 46533, 2539, 14642, 365, 512, 26881, 13, 50974, 50974, 1436, 291, 434, 733, 295, 3097, 264, 1185, 281, 1466, 644, 295, 1080, 4846, 490, 1071, 644, 51192, 51192, 295, 264, 4846, 13, 51242, 51242, 407, 309, 311, 588, 2531, 281, 46533, 2539, 294, 867, 2098, 11, 3993, 300, 291, 643, 281, 4813, 51476, 51476, 15697, 1101, 13, 51614, 51614, 400, 264, 3671, 7719, 11, 498, 291, 528, 11, 815, 312, 709, 4833, 11, 597, 307, 733, 295, 364, 2734, 13, 51826, 51826], "temperature": 0.0, "avg_logprob": -0.0978190134156425, "compression_ratio": 1.6853932584269662, "no_speech_prob": 2.077257704513613e-05}, {"id": 175, "seek": 71188, "start": 728.4399999999999, "end": 729.4399999999999, "text": " of the input.", "tokens": [50364, 286, 914, 11, 286, 2041, 452, 1778, 337, 5141, 309, 341, 307, 300, 264, 14642, 366, 4476, 264, 50796, 50796, 912, 382, 46533, 2539, 14642, 365, 512, 26881, 13, 50974, 50974, 1436, 291, 434, 733, 295, 3097, 264, 1185, 281, 1466, 644, 295, 1080, 4846, 490, 1071, 644, 51192, 51192, 295, 264, 4846, 13, 51242, 51242, 407, 309, 311, 588, 2531, 281, 46533, 2539, 294, 867, 2098, 11, 3993, 300, 291, 643, 281, 4813, 51476, 51476, 15697, 1101, 13, 51614, 51614, 400, 264, 3671, 7719, 11, 498, 291, 528, 11, 815, 312, 709, 4833, 11, 597, 307, 733, 295, 364, 2734, 13, 51826, 51826], "temperature": 0.0, "avg_logprob": -0.0978190134156425, "compression_ratio": 1.6853932584269662, "no_speech_prob": 2.077257704513613e-05}, {"id": 176, "seek": 71188, "start": 729.4399999999999, "end": 734.12, "text": " So it's very similar to supervised learning in many ways, except that you need to handle", "tokens": [50364, 286, 914, 11, 286, 2041, 452, 1778, 337, 5141, 309, 341, 307, 300, 264, 14642, 366, 4476, 264, 50796, 50796, 912, 382, 46533, 2539, 14642, 365, 512, 26881, 13, 50974, 50974, 1436, 291, 434, 733, 295, 3097, 264, 1185, 281, 1466, 644, 295, 1080, 4846, 490, 1071, 644, 51192, 51192, 295, 264, 4846, 13, 51242, 51242, 407, 309, 311, 588, 2531, 281, 46533, 2539, 294, 867, 2098, 11, 3993, 300, 291, 643, 281, 4813, 51476, 51476, 15697, 1101, 13, 51614, 51614, 400, 264, 3671, 7719, 11, 498, 291, 528, 11, 815, 312, 709, 4833, 11, 597, 307, 733, 295, 364, 2734, 13, 51826, 51826], "temperature": 0.0, "avg_logprob": -0.0978190134156425, "compression_ratio": 1.6853932584269662, "no_speech_prob": 2.077257704513613e-05}, {"id": 177, "seek": 71188, "start": 734.12, "end": 736.88, "text": " uncertainty better.", "tokens": [50364, 286, 914, 11, 286, 2041, 452, 1778, 337, 5141, 309, 341, 307, 300, 264, 14642, 366, 4476, 264, 50796, 50796, 912, 382, 46533, 2539, 14642, 365, 512, 26881, 13, 50974, 50974, 1436, 291, 434, 733, 295, 3097, 264, 1185, 281, 1466, 644, 295, 1080, 4846, 490, 1071, 644, 51192, 51192, 295, 264, 4846, 13, 51242, 51242, 407, 309, 311, 588, 2531, 281, 46533, 2539, 294, 867, 2098, 11, 3993, 300, 291, 643, 281, 4813, 51476, 51476, 15697, 1101, 13, 51614, 51614, 400, 264, 3671, 7719, 11, 498, 291, 528, 11, 815, 312, 709, 4833, 11, 597, 307, 733, 295, 364, 2734, 13, 51826, 51826], "temperature": 0.0, "avg_logprob": -0.0978190134156425, "compression_ratio": 1.6853932584269662, "no_speech_prob": 2.077257704513613e-05}, {"id": 178, "seek": 71188, "start": 736.88, "end": 741.12, "text": " And the negative category, if you want, may be much larger, which is kind of an issue.", "tokens": [50364, 286, 914, 11, 286, 2041, 452, 1778, 337, 5141, 309, 341, 307, 300, 264, 14642, 366, 4476, 264, 50796, 50796, 912, 382, 46533, 2539, 14642, 365, 512, 26881, 13, 50974, 50974, 1436, 291, 434, 733, 295, 3097, 264, 1185, 281, 1466, 644, 295, 1080, 4846, 490, 1071, 644, 51192, 51192, 295, 264, 4846, 13, 51242, 51242, 407, 309, 311, 588, 2531, 281, 46533, 2539, 294, 867, 2098, 11, 3993, 300, 291, 643, 281, 4813, 51476, 51476, 15697, 1101, 13, 51614, 51614, 400, 264, 3671, 7719, 11, 498, 291, 528, 11, 815, 312, 709, 4833, 11, 597, 307, 733, 295, 364, 2734, 13, 51826, 51826], "temperature": 0.0, "avg_logprob": -0.0978190134156425, "compression_ratio": 1.6853932584269662, "no_speech_prob": 2.077257704513613e-05}, {"id": 179, "seek": 74112, "start": 741.12, "end": 746.92, "text": " But unsupervised learning is really not very well defined.", "tokens": [50364, 583, 2693, 12879, 24420, 2539, 307, 534, 406, 588, 731, 7642, 13, 50654, 50654, 16348, 12, 48172, 24420, 2539, 307, 733, 295, 257, 1101, 7642, 3410, 13, 50806, 50806, 467, 311, 406, 7696, 1850, 13, 50856, 50856, 467, 311, 257, 25993, 295, 2693, 12879, 24420, 13, 51296, 51296, 407, 2684, 2286, 11, 286, 603, 586, 1333, 295, 853, 281, 751, 466, 2698, 12, 48172, 24420, 2539, 544, 294, 264, 51510, 51510, 4319, 295, 5201, 13, 51636, 51636], "temperature": 0.0, "avg_logprob": -0.1706271594083762, "compression_ratio": 1.7005988023952097, "no_speech_prob": 1.218419311044272e-05}, {"id": 180, "seek": 74112, "start": 746.92, "end": 749.96, "text": " Self-supervised learning is kind of a better defined concept.", "tokens": [50364, 583, 2693, 12879, 24420, 2539, 307, 534, 406, 588, 731, 7642, 13, 50654, 50654, 16348, 12, 48172, 24420, 2539, 307, 733, 295, 257, 1101, 7642, 3410, 13, 50806, 50806, 467, 311, 406, 7696, 1850, 13, 50856, 50856, 467, 311, 257, 25993, 295, 2693, 12879, 24420, 13, 51296, 51296, 407, 2684, 2286, 11, 286, 603, 586, 1333, 295, 853, 281, 751, 466, 2698, 12, 48172, 24420, 2539, 544, 294, 264, 51510, 51510, 4319, 295, 5201, 13, 51636, 51636], "temperature": 0.0, "avg_logprob": -0.1706271594083762, "compression_ratio": 1.7005988023952097, "no_speech_prob": 1.218419311044272e-05}, {"id": 181, "seek": 74112, "start": 749.96, "end": 750.96, "text": " It's not entirely clear.", "tokens": [50364, 583, 2693, 12879, 24420, 2539, 307, 534, 406, 588, 731, 7642, 13, 50654, 50654, 16348, 12, 48172, 24420, 2539, 307, 733, 295, 257, 1101, 7642, 3410, 13, 50806, 50806, 467, 311, 406, 7696, 1850, 13, 50856, 50856, 467, 311, 257, 25993, 295, 2693, 12879, 24420, 13, 51296, 51296, 407, 2684, 2286, 11, 286, 603, 586, 1333, 295, 853, 281, 751, 466, 2698, 12, 48172, 24420, 2539, 544, 294, 264, 51510, 51510, 4319, 295, 5201, 13, 51636, 51636], "temperature": 0.0, "avg_logprob": -0.1706271594083762, "compression_ratio": 1.7005988023952097, "no_speech_prob": 1.218419311044272e-05}, {"id": 182, "seek": 74112, "start": 750.96, "end": 759.76, "text": " It's a subset of unsupervised.", "tokens": [50364, 583, 2693, 12879, 24420, 2539, 307, 534, 406, 588, 731, 7642, 13, 50654, 50654, 16348, 12, 48172, 24420, 2539, 307, 733, 295, 257, 1101, 7642, 3410, 13, 50806, 50806, 467, 311, 406, 7696, 1850, 13, 50856, 50856, 467, 311, 257, 25993, 295, 2693, 12879, 24420, 13, 51296, 51296, 407, 2684, 2286, 11, 286, 603, 586, 1333, 295, 853, 281, 751, 466, 2698, 12, 48172, 24420, 2539, 544, 294, 264, 51510, 51510, 4319, 295, 5201, 13, 51636, 51636], "temperature": 0.0, "avg_logprob": -0.1706271594083762, "compression_ratio": 1.7005988023952097, "no_speech_prob": 1.218419311044272e-05}, {"id": 183, "seek": 74112, "start": 759.76, "end": 764.04, "text": " So moving ahead, I'll now sort of try to talk about self-supervised learning more in the", "tokens": [50364, 583, 2693, 12879, 24420, 2539, 307, 534, 406, 588, 731, 7642, 13, 50654, 50654, 16348, 12, 48172, 24420, 2539, 307, 733, 295, 257, 1101, 7642, 3410, 13, 50806, 50806, 467, 311, 406, 7696, 1850, 13, 50856, 50856, 467, 311, 257, 25993, 295, 2693, 12879, 24420, 13, 51296, 51296, 407, 2684, 2286, 11, 286, 603, 586, 1333, 295, 853, 281, 751, 466, 2698, 12, 48172, 24420, 2539, 544, 294, 264, 51510, 51510, 4319, 295, 5201, 13, 51636, 51636], "temperature": 0.0, "avg_logprob": -0.1706271594083762, "compression_ratio": 1.7005988023952097, "no_speech_prob": 1.218419311044272e-05}, {"id": 184, "seek": 74112, "start": 764.04, "end": 766.5600000000001, "text": " context of vision.", "tokens": [50364, 583, 2693, 12879, 24420, 2539, 307, 534, 406, 588, 731, 7642, 13, 50654, 50654, 16348, 12, 48172, 24420, 2539, 307, 733, 295, 257, 1101, 7642, 3410, 13, 50806, 50806, 467, 311, 406, 7696, 1850, 13, 50856, 50856, 467, 311, 257, 25993, 295, 2693, 12879, 24420, 13, 51296, 51296, 407, 2684, 2286, 11, 286, 603, 586, 1333, 295, 853, 281, 751, 466, 2698, 12, 48172, 24420, 2539, 544, 294, 264, 51510, 51510, 4319, 295, 5201, 13, 51636, 51636], "temperature": 0.0, "avg_logprob": -0.1706271594083762, "compression_ratio": 1.7005988023952097, "no_speech_prob": 1.218419311044272e-05}, {"id": 185, "seek": 76656, "start": 766.56, "end": 773.0, "text": " In vision, a lot of these sort of prediction problems have been framed as pretext tasks.", "tokens": [50364, 682, 5201, 11, 257, 688, 295, 613, 1333, 295, 17630, 2740, 362, 668, 30420, 382, 659, 25111, 9608, 13, 50686, 50686, 407, 257, 688, 295, 264, 5201, 14642, 1333, 295, 11, 293, 341, 1433, 1487, 544, 490, 7546, 11, 490, 341, 51099, 51099, 1729, 3035, 538, 14256, 314, 27457, 13, 51234, 51234, 400, 264, 1558, 510, 390, 300, 291, 362, 257, 2487, 5633, 420, 264, 1333, 295, 5633, 300, 291, 534, 1127, 51524, 51524, 466, 412, 264, 917, 11, 411, 3256, 21538, 13, 51658, 51658], "temperature": 0.0, "avg_logprob": -0.14082529352999282, "compression_ratio": 1.6074766355140186, "no_speech_prob": 9.515892088529654e-06}, {"id": 186, "seek": 76656, "start": 773.0, "end": 781.26, "text": " So a lot of the vision algorithms sort of, and this term comes more from 2015, from this", "tokens": [50364, 682, 5201, 11, 257, 688, 295, 613, 1333, 295, 17630, 2740, 362, 668, 30420, 382, 659, 25111, 9608, 13, 50686, 50686, 407, 257, 688, 295, 264, 5201, 14642, 1333, 295, 11, 293, 341, 1433, 1487, 544, 490, 7546, 11, 490, 341, 51099, 51099, 1729, 3035, 538, 14256, 314, 27457, 13, 51234, 51234, 400, 264, 1558, 510, 390, 300, 291, 362, 257, 2487, 5633, 420, 264, 1333, 295, 5633, 300, 291, 534, 1127, 51524, 51524, 466, 412, 264, 917, 11, 411, 3256, 21538, 13, 51658, 51658], "temperature": 0.0, "avg_logprob": -0.14082529352999282, "compression_ratio": 1.6074766355140186, "no_speech_prob": 9.515892088529654e-06}, {"id": 187, "seek": 76656, "start": 781.26, "end": 783.9599999999999, "text": " particular paper by Carl Torsch.", "tokens": [50364, 682, 5201, 11, 257, 688, 295, 613, 1333, 295, 17630, 2740, 362, 668, 30420, 382, 659, 25111, 9608, 13, 50686, 50686, 407, 257, 688, 295, 264, 5201, 14642, 1333, 295, 11, 293, 341, 1433, 1487, 544, 490, 7546, 11, 490, 341, 51099, 51099, 1729, 3035, 538, 14256, 314, 27457, 13, 51234, 51234, 400, 264, 1558, 510, 390, 300, 291, 362, 257, 2487, 5633, 420, 264, 1333, 295, 5633, 300, 291, 534, 1127, 51524, 51524, 466, 412, 264, 917, 11, 411, 3256, 21538, 13, 51658, 51658], "temperature": 0.0, "avg_logprob": -0.14082529352999282, "compression_ratio": 1.6074766355140186, "no_speech_prob": 9.515892088529654e-06}, {"id": 188, "seek": 76656, "start": 783.9599999999999, "end": 789.76, "text": " And the idea here was that you have a text task or the sort of task that you really care", "tokens": [50364, 682, 5201, 11, 257, 688, 295, 613, 1333, 295, 17630, 2740, 362, 668, 30420, 382, 659, 25111, 9608, 13, 50686, 50686, 407, 257, 688, 295, 264, 5201, 14642, 1333, 295, 11, 293, 341, 1433, 1487, 544, 490, 7546, 11, 490, 341, 51099, 51099, 1729, 3035, 538, 14256, 314, 27457, 13, 51234, 51234, 400, 264, 1558, 510, 390, 300, 291, 362, 257, 2487, 5633, 420, 264, 1333, 295, 5633, 300, 291, 534, 1127, 51524, 51524, 466, 412, 264, 917, 11, 411, 3256, 21538, 13, 51658, 51658], "temperature": 0.0, "avg_logprob": -0.14082529352999282, "compression_ratio": 1.6074766355140186, "no_speech_prob": 9.515892088529654e-06}, {"id": 189, "seek": 76656, "start": 789.76, "end": 792.4399999999999, "text": " about at the end, like image classification.", "tokens": [50364, 682, 5201, 11, 257, 688, 295, 613, 1333, 295, 17630, 2740, 362, 668, 30420, 382, 659, 25111, 9608, 13, 50686, 50686, 407, 257, 688, 295, 264, 5201, 14642, 1333, 295, 11, 293, 341, 1433, 1487, 544, 490, 7546, 11, 490, 341, 51099, 51099, 1729, 3035, 538, 14256, 314, 27457, 13, 51234, 51234, 400, 264, 1558, 510, 390, 300, 291, 362, 257, 2487, 5633, 420, 264, 1333, 295, 5633, 300, 291, 534, 1127, 51524, 51524, 466, 412, 264, 917, 11, 411, 3256, 21538, 13, 51658, 51658], "temperature": 0.0, "avg_logprob": -0.14082529352999282, "compression_ratio": 1.6074766355140186, "no_speech_prob": 9.515892088529654e-06}, {"id": 190, "seek": 79244, "start": 792.44, "end": 798.36, "text": " But of course, you don't have a lot of data for that, or you want to solve a task before", "tokens": [50364, 583, 295, 1164, 11, 291, 500, 380, 362, 257, 688, 295, 1412, 337, 300, 11, 420, 291, 528, 281, 5039, 257, 5633, 949, 50660, 50660, 516, 281, 264, 957, 5633, 11, 370, 257, 659, 25111, 5633, 13, 50830, 50830, 407, 341, 659, 25111, 5633, 307, 257, 17630, 5633, 300, 291, 366, 12606, 11, 457, 309, 311, 406, 2049, 264, 51068, 51068, 957, 5633, 300, 291, 534, 1127, 466, 13, 51216, 51216, 407, 291, 603, 5039, 341, 1729, 5633, 281, 1466, 257, 10290, 11, 293, 550, 291, 603, 2721, 51448, 51448, 483, 428, 30621, 5633, 689, 291, 528, 281, 764, 341, 10290, 281, 2042, 746, 51636, 51636, 10995, 13, 51686, 51686, 407, 613, 659, 25111, 9608, 366, 1333, 295, 4074, 13, 51772, 51772], "temperature": 0.0, "avg_logprob": -0.12847938076142343, "compression_ratio": 1.9362549800796813, "no_speech_prob": 1.3211250006861519e-05}, {"id": 191, "seek": 79244, "start": 798.36, "end": 801.7600000000001, "text": " going to the real task, so a pretext task.", "tokens": [50364, 583, 295, 1164, 11, 291, 500, 380, 362, 257, 688, 295, 1412, 337, 300, 11, 420, 291, 528, 281, 5039, 257, 5633, 949, 50660, 50660, 516, 281, 264, 957, 5633, 11, 370, 257, 659, 25111, 5633, 13, 50830, 50830, 407, 341, 659, 25111, 5633, 307, 257, 17630, 5633, 300, 291, 366, 12606, 11, 457, 309, 311, 406, 2049, 264, 51068, 51068, 957, 5633, 300, 291, 534, 1127, 466, 13, 51216, 51216, 407, 291, 603, 5039, 341, 1729, 5633, 281, 1466, 257, 10290, 11, 293, 550, 291, 603, 2721, 51448, 51448, 483, 428, 30621, 5633, 689, 291, 528, 281, 764, 341, 10290, 281, 2042, 746, 51636, 51636, 10995, 13, 51686, 51686, 407, 613, 659, 25111, 9608, 366, 1333, 295, 4074, 13, 51772, 51772], "temperature": 0.0, "avg_logprob": -0.12847938076142343, "compression_ratio": 1.9362549800796813, "no_speech_prob": 1.3211250006861519e-05}, {"id": 192, "seek": 79244, "start": 801.7600000000001, "end": 806.5200000000001, "text": " So this pretext task is a prediction task that you are solving, but it's not often the", "tokens": [50364, 583, 295, 1164, 11, 291, 500, 380, 362, 257, 688, 295, 1412, 337, 300, 11, 420, 291, 528, 281, 5039, 257, 5633, 949, 50660, 50660, 516, 281, 264, 957, 5633, 11, 370, 257, 659, 25111, 5633, 13, 50830, 50830, 407, 341, 659, 25111, 5633, 307, 257, 17630, 5633, 300, 291, 366, 12606, 11, 457, 309, 311, 406, 2049, 264, 51068, 51068, 957, 5633, 300, 291, 534, 1127, 466, 13, 51216, 51216, 407, 291, 603, 5039, 341, 1729, 5633, 281, 1466, 257, 10290, 11, 293, 550, 291, 603, 2721, 51448, 51448, 483, 428, 30621, 5633, 689, 291, 528, 281, 764, 341, 10290, 281, 2042, 746, 51636, 51636, 10995, 13, 51686, 51686, 407, 613, 659, 25111, 9608, 366, 1333, 295, 4074, 13, 51772, 51772], "temperature": 0.0, "avg_logprob": -0.12847938076142343, "compression_ratio": 1.9362549800796813, "no_speech_prob": 1.3211250006861519e-05}, {"id": 193, "seek": 79244, "start": 806.5200000000001, "end": 809.48, "text": " real task that you really care about.", "tokens": [50364, 583, 295, 1164, 11, 291, 500, 380, 362, 257, 688, 295, 1412, 337, 300, 11, 420, 291, 528, 281, 5039, 257, 5633, 949, 50660, 50660, 516, 281, 264, 957, 5633, 11, 370, 257, 659, 25111, 5633, 13, 50830, 50830, 407, 341, 659, 25111, 5633, 307, 257, 17630, 5633, 300, 291, 366, 12606, 11, 457, 309, 311, 406, 2049, 264, 51068, 51068, 957, 5633, 300, 291, 534, 1127, 466, 13, 51216, 51216, 407, 291, 603, 5039, 341, 1729, 5633, 281, 1466, 257, 10290, 11, 293, 550, 291, 603, 2721, 51448, 51448, 483, 428, 30621, 5633, 689, 291, 528, 281, 764, 341, 10290, 281, 2042, 746, 51636, 51636, 10995, 13, 51686, 51686, 407, 613, 659, 25111, 9608, 366, 1333, 295, 4074, 13, 51772, 51772], "temperature": 0.0, "avg_logprob": -0.12847938076142343, "compression_ratio": 1.9362549800796813, "no_speech_prob": 1.3211250006861519e-05}, {"id": 194, "seek": 79244, "start": 809.48, "end": 814.12, "text": " So you'll solve this particular task to learn a representation, and then you'll finally", "tokens": [50364, 583, 295, 1164, 11, 291, 500, 380, 362, 257, 688, 295, 1412, 337, 300, 11, 420, 291, 528, 281, 5039, 257, 5633, 949, 50660, 50660, 516, 281, 264, 957, 5633, 11, 370, 257, 659, 25111, 5633, 13, 50830, 50830, 407, 341, 659, 25111, 5633, 307, 257, 17630, 5633, 300, 291, 366, 12606, 11, 457, 309, 311, 406, 2049, 264, 51068, 51068, 957, 5633, 300, 291, 534, 1127, 466, 13, 51216, 51216, 407, 291, 603, 5039, 341, 1729, 5633, 281, 1466, 257, 10290, 11, 293, 550, 291, 603, 2721, 51448, 51448, 483, 428, 30621, 5633, 689, 291, 528, 281, 764, 341, 10290, 281, 2042, 746, 51636, 51636, 10995, 13, 51686, 51686, 407, 613, 659, 25111, 9608, 366, 1333, 295, 4074, 13, 51772, 51772], "temperature": 0.0, "avg_logprob": -0.12847938076142343, "compression_ratio": 1.9362549800796813, "no_speech_prob": 1.3211250006861519e-05}, {"id": 195, "seek": 79244, "start": 814.12, "end": 817.8800000000001, "text": " get your downstream task where you want to use this representation to perform something", "tokens": [50364, 583, 295, 1164, 11, 291, 500, 380, 362, 257, 688, 295, 1412, 337, 300, 11, 420, 291, 528, 281, 5039, 257, 5633, 949, 50660, 50660, 516, 281, 264, 957, 5633, 11, 370, 257, 659, 25111, 5633, 13, 50830, 50830, 407, 341, 659, 25111, 5633, 307, 257, 17630, 5633, 300, 291, 366, 12606, 11, 457, 309, 311, 406, 2049, 264, 51068, 51068, 957, 5633, 300, 291, 534, 1127, 466, 13, 51216, 51216, 407, 291, 603, 5039, 341, 1729, 5633, 281, 1466, 257, 10290, 11, 293, 550, 291, 603, 2721, 51448, 51448, 483, 428, 30621, 5633, 689, 291, 528, 281, 764, 341, 10290, 281, 2042, 746, 51636, 51636, 10995, 13, 51686, 51686, 407, 613, 659, 25111, 9608, 366, 1333, 295, 4074, 13, 51772, 51772], "temperature": 0.0, "avg_logprob": -0.12847938076142343, "compression_ratio": 1.9362549800796813, "no_speech_prob": 1.3211250006861519e-05}, {"id": 196, "seek": 79244, "start": 817.8800000000001, "end": 818.8800000000001, "text": " meaningful.", "tokens": [50364, 583, 295, 1164, 11, 291, 500, 380, 362, 257, 688, 295, 1412, 337, 300, 11, 420, 291, 528, 281, 5039, 257, 5633, 949, 50660, 50660, 516, 281, 264, 957, 5633, 11, 370, 257, 659, 25111, 5633, 13, 50830, 50830, 407, 341, 659, 25111, 5633, 307, 257, 17630, 5633, 300, 291, 366, 12606, 11, 457, 309, 311, 406, 2049, 264, 51068, 51068, 957, 5633, 300, 291, 534, 1127, 466, 13, 51216, 51216, 407, 291, 603, 5039, 341, 1729, 5633, 281, 1466, 257, 10290, 11, 293, 550, 291, 603, 2721, 51448, 51448, 483, 428, 30621, 5633, 689, 291, 528, 281, 764, 341, 10290, 281, 2042, 746, 51636, 51636, 10995, 13, 51686, 51686, 407, 613, 659, 25111, 9608, 366, 1333, 295, 4074, 13, 51772, 51772], "temperature": 0.0, "avg_logprob": -0.12847938076142343, "compression_ratio": 1.9362549800796813, "no_speech_prob": 1.3211250006861519e-05}, {"id": 197, "seek": 79244, "start": 818.8800000000001, "end": 820.6, "text": " So these pretext tasks are sort of funny.", "tokens": [50364, 583, 295, 1164, 11, 291, 500, 380, 362, 257, 688, 295, 1412, 337, 300, 11, 420, 291, 528, 281, 5039, 257, 5633, 949, 50660, 50660, 516, 281, 264, 957, 5633, 11, 370, 257, 659, 25111, 5633, 13, 50830, 50830, 407, 341, 659, 25111, 5633, 307, 257, 17630, 5633, 300, 291, 366, 12606, 11, 457, 309, 311, 406, 2049, 264, 51068, 51068, 957, 5633, 300, 291, 534, 1127, 466, 13, 51216, 51216, 407, 291, 603, 5039, 341, 1729, 5633, 281, 1466, 257, 10290, 11, 293, 550, 291, 603, 2721, 51448, 51448, 483, 428, 30621, 5633, 689, 291, 528, 281, 764, 341, 10290, 281, 2042, 746, 51636, 51636, 10995, 13, 51686, 51686, 407, 613, 659, 25111, 9608, 366, 1333, 295, 4074, 13, 51772, 51772], "temperature": 0.0, "avg_logprob": -0.12847938076142343, "compression_ratio": 1.9362549800796813, "no_speech_prob": 1.3211250006861519e-05}, {"id": 198, "seek": 82060, "start": 820.6, "end": 827.12, "text": " They're often fairly like people got very creative with sort of coming up with these", "tokens": [50364, 814, 434, 2049, 6457, 411, 561, 658, 588, 5880, 365, 1333, 295, 1348, 493, 365, 613, 50690, 50690, 659, 25111, 9608, 13, 50842, 50842, 407, 718, 311, 574, 412, 577, 291, 393, 6964, 257, 3840, 295, 659, 25111, 9608, 293, 437, 1184, 295, 613, 659, 25111, 51174, 51174, 9608, 307, 1382, 281, 360, 13, 51260, 51260, 400, 370, 291, 393, 764, 2139, 5267, 11, 960, 11, 960, 293, 1626, 562, 291, 434, 1382, 281, 360, 613, 721, 13, 51554, 51554, 400, 294, 1184, 1389, 11, 291, 603, 362, 257, 3840, 295, 13095, 1412, 11, 293, 291, 603, 853, 281, 2139, 6069, 7633, 51768, 51768], "temperature": 0.0, "avg_logprob": -0.08749732431375755, "compression_ratio": 1.780701754385965, "no_speech_prob": 6.3391216826858e-06}, {"id": 199, "seek": 82060, "start": 827.12, "end": 830.16, "text": " pretext tasks.", "tokens": [50364, 814, 434, 2049, 6457, 411, 561, 658, 588, 5880, 365, 1333, 295, 1348, 493, 365, 613, 50690, 50690, 659, 25111, 9608, 13, 50842, 50842, 407, 718, 311, 574, 412, 577, 291, 393, 6964, 257, 3840, 295, 659, 25111, 9608, 293, 437, 1184, 295, 613, 659, 25111, 51174, 51174, 9608, 307, 1382, 281, 360, 13, 51260, 51260, 400, 370, 291, 393, 764, 2139, 5267, 11, 960, 11, 960, 293, 1626, 562, 291, 434, 1382, 281, 360, 613, 721, 13, 51554, 51554, 400, 294, 1184, 1389, 11, 291, 603, 362, 257, 3840, 295, 13095, 1412, 11, 293, 291, 603, 853, 281, 2139, 6069, 7633, 51768, 51768], "temperature": 0.0, "avg_logprob": -0.08749732431375755, "compression_ratio": 1.780701754385965, "no_speech_prob": 6.3391216826858e-06}, {"id": 200, "seek": 82060, "start": 830.16, "end": 836.8000000000001, "text": " So let's look at how you can define a bunch of pretext tasks and what each of these pretext", "tokens": [50364, 814, 434, 2049, 6457, 411, 561, 658, 588, 5880, 365, 1333, 295, 1348, 493, 365, 613, 50690, 50690, 659, 25111, 9608, 13, 50842, 50842, 407, 718, 311, 574, 412, 577, 291, 393, 6964, 257, 3840, 295, 659, 25111, 9608, 293, 437, 1184, 295, 613, 659, 25111, 51174, 51174, 9608, 307, 1382, 281, 360, 13, 51260, 51260, 400, 370, 291, 393, 764, 2139, 5267, 11, 960, 11, 960, 293, 1626, 562, 291, 434, 1382, 281, 360, 613, 721, 13, 51554, 51554, 400, 294, 1184, 1389, 11, 291, 603, 362, 257, 3840, 295, 13095, 1412, 11, 293, 291, 603, 853, 281, 2139, 6069, 7633, 51768, 51768], "temperature": 0.0, "avg_logprob": -0.08749732431375755, "compression_ratio": 1.780701754385965, "no_speech_prob": 6.3391216826858e-06}, {"id": 201, "seek": 82060, "start": 836.8000000000001, "end": 838.52, "text": " tasks is trying to do.", "tokens": [50364, 814, 434, 2049, 6457, 411, 561, 658, 588, 5880, 365, 1333, 295, 1348, 493, 365, 613, 50690, 50690, 659, 25111, 9608, 13, 50842, 50842, 407, 718, 311, 574, 412, 577, 291, 393, 6964, 257, 3840, 295, 659, 25111, 9608, 293, 437, 1184, 295, 613, 659, 25111, 51174, 51174, 9608, 307, 1382, 281, 360, 13, 51260, 51260, 400, 370, 291, 393, 764, 2139, 5267, 11, 960, 11, 960, 293, 1626, 562, 291, 434, 1382, 281, 360, 613, 721, 13, 51554, 51554, 400, 294, 1184, 1389, 11, 291, 603, 362, 257, 3840, 295, 13095, 1412, 11, 293, 291, 603, 853, 281, 2139, 6069, 7633, 51768, 51768], "temperature": 0.0, "avg_logprob": -0.08749732431375755, "compression_ratio": 1.780701754385965, "no_speech_prob": 6.3391216826858e-06}, {"id": 202, "seek": 82060, "start": 838.52, "end": 844.4, "text": " And so you can use either images, video, video and sound when you're trying to do these things.", "tokens": [50364, 814, 434, 2049, 6457, 411, 561, 658, 588, 5880, 365, 1333, 295, 1348, 493, 365, 613, 50690, 50690, 659, 25111, 9608, 13, 50842, 50842, 407, 718, 311, 574, 412, 577, 291, 393, 6964, 257, 3840, 295, 659, 25111, 9608, 293, 437, 1184, 295, 613, 659, 25111, 51174, 51174, 9608, 307, 1382, 281, 360, 13, 51260, 51260, 400, 370, 291, 393, 764, 2139, 5267, 11, 960, 11, 960, 293, 1626, 562, 291, 434, 1382, 281, 360, 613, 721, 13, 51554, 51554, 400, 294, 1184, 1389, 11, 291, 603, 362, 257, 3840, 295, 13095, 1412, 11, 293, 291, 603, 853, 281, 2139, 6069, 7633, 51768, 51768], "temperature": 0.0, "avg_logprob": -0.08749732431375755, "compression_ratio": 1.780701754385965, "no_speech_prob": 6.3391216826858e-06}, {"id": 203, "seek": 82060, "start": 844.4, "end": 848.6800000000001, "text": " And in each case, you'll have a bunch of observed data, and you'll try to either predict hidden", "tokens": [50364, 814, 434, 2049, 6457, 411, 561, 658, 588, 5880, 365, 1333, 295, 1348, 493, 365, 613, 50690, 50690, 659, 25111, 9608, 13, 50842, 50842, 407, 718, 311, 574, 412, 577, 291, 393, 6964, 257, 3840, 295, 659, 25111, 9608, 293, 437, 1184, 295, 613, 659, 25111, 51174, 51174, 9608, 307, 1382, 281, 360, 13, 51260, 51260, 400, 370, 291, 393, 764, 2139, 5267, 11, 960, 11, 960, 293, 1626, 562, 291, 434, 1382, 281, 360, 613, 721, 13, 51554, 51554, 400, 294, 1184, 1389, 11, 291, 603, 362, 257, 3840, 295, 13095, 1412, 11, 293, 291, 603, 853, 281, 2139, 6069, 7633, 51768, 51768], "temperature": 0.0, "avg_logprob": -0.08749732431375755, "compression_ratio": 1.780701754385965, "no_speech_prob": 6.3391216826858e-06}, {"id": 204, "seek": 84868, "start": 848.68, "end": 851.9599999999999, "text": " data or you'll try to predict the property of the hidden data.", "tokens": [50364, 1412, 420, 291, 603, 853, 281, 6069, 264, 4707, 295, 264, 7633, 1412, 13, 50528, 50528, 400, 341, 1333, 295, 11365, 16423, 257, 3840, 295, 11587, 13, 50784, 50784, 407, 718, 311, 574, 412, 577, 291, 393, 764, 5267, 281, 6964, 746, 411, 257, 659, 25111, 5633, 13, 51121, 51121, 407, 264, 3035, 300, 7268, 341, 1433, 659, 25111, 5633, 1361, 493, 365, 341, 6457, 1333, 295, 4074, 51384, 51384, 3170, 11, 457, 437, 291, 360, 307, 291, 747, 584, 732, 3256, 26531, 13, 51742, 51742], "temperature": 0.0, "avg_logprob": -0.14183630726554178, "compression_ratio": 1.6064814814814814, "no_speech_prob": 3.1381046028400306e-06}, {"id": 205, "seek": 84868, "start": 851.9599999999999, "end": 857.0799999999999, "text": " And this sort of distinguishes a bunch of approaches.", "tokens": [50364, 1412, 420, 291, 603, 853, 281, 6069, 264, 4707, 295, 264, 7633, 1412, 13, 50528, 50528, 400, 341, 1333, 295, 11365, 16423, 257, 3840, 295, 11587, 13, 50784, 50784, 407, 718, 311, 574, 412, 577, 291, 393, 764, 5267, 281, 6964, 746, 411, 257, 659, 25111, 5633, 13, 51121, 51121, 407, 264, 3035, 300, 7268, 341, 1433, 659, 25111, 5633, 1361, 493, 365, 341, 6457, 1333, 295, 4074, 51384, 51384, 3170, 11, 457, 437, 291, 360, 307, 291, 747, 584, 732, 3256, 26531, 13, 51742, 51742], "temperature": 0.0, "avg_logprob": -0.14183630726554178, "compression_ratio": 1.6064814814814814, "no_speech_prob": 3.1381046028400306e-06}, {"id": 206, "seek": 84868, "start": 857.0799999999999, "end": 863.8199999999999, "text": " So let's look at how you can use images to define something like a pretext task.", "tokens": [50364, 1412, 420, 291, 603, 853, 281, 6069, 264, 4707, 295, 264, 7633, 1412, 13, 50528, 50528, 400, 341, 1333, 295, 11365, 16423, 257, 3840, 295, 11587, 13, 50784, 50784, 407, 718, 311, 574, 412, 577, 291, 393, 764, 5267, 281, 6964, 746, 411, 257, 659, 25111, 5633, 13, 51121, 51121, 407, 264, 3035, 300, 7268, 341, 1433, 659, 25111, 5633, 1361, 493, 365, 341, 6457, 1333, 295, 4074, 51384, 51384, 3170, 11, 457, 437, 291, 360, 307, 291, 747, 584, 732, 3256, 26531, 13, 51742, 51742], "temperature": 0.0, "avg_logprob": -0.14183630726554178, "compression_ratio": 1.6064814814814814, "no_speech_prob": 3.1381046028400306e-06}, {"id": 207, "seek": 84868, "start": 863.8199999999999, "end": 869.0799999999999, "text": " So the paper that introduced this term pretext task came up with this fairly sort of funny", "tokens": [50364, 1412, 420, 291, 603, 853, 281, 6069, 264, 4707, 295, 264, 7633, 1412, 13, 50528, 50528, 400, 341, 1333, 295, 11365, 16423, 257, 3840, 295, 11587, 13, 50784, 50784, 407, 718, 311, 574, 412, 577, 291, 393, 764, 5267, 281, 6964, 746, 411, 257, 659, 25111, 5633, 13, 51121, 51121, 407, 264, 3035, 300, 7268, 341, 1433, 659, 25111, 5633, 1361, 493, 365, 341, 6457, 1333, 295, 4074, 51384, 51384, 3170, 11, 457, 437, 291, 360, 307, 291, 747, 584, 732, 3256, 26531, 13, 51742, 51742], "temperature": 0.0, "avg_logprob": -0.14183630726554178, "compression_ratio": 1.6064814814814814, "no_speech_prob": 3.1381046028400306e-06}, {"id": 208, "seek": 84868, "start": 869.0799999999999, "end": 876.24, "text": " method, but what you do is you take say two image patches.", "tokens": [50364, 1412, 420, 291, 603, 853, 281, 6069, 264, 4707, 295, 264, 7633, 1412, 13, 50528, 50528, 400, 341, 1333, 295, 11365, 16423, 257, 3840, 295, 11587, 13, 50784, 50784, 407, 718, 311, 574, 412, 577, 291, 393, 764, 5267, 281, 6964, 746, 411, 257, 659, 25111, 5633, 13, 51121, 51121, 407, 264, 3035, 300, 7268, 341, 1433, 659, 25111, 5633, 1361, 493, 365, 341, 6457, 1333, 295, 4074, 51384, 51384, 3170, 11, 457, 437, 291, 360, 307, 291, 747, 584, 732, 3256, 26531, 13, 51742, 51742], "temperature": 0.0, "avg_logprob": -0.14183630726554178, "compression_ratio": 1.6064814814814814, "no_speech_prob": 3.1381046028400306e-06}, {"id": 209, "seek": 87624, "start": 876.24, "end": 880.5600000000001, "text": " Basically take the network and you ask the network to predict what is the relative position", "tokens": [50364, 8537, 747, 264, 3209, 293, 291, 1029, 264, 3209, 281, 6069, 437, 307, 264, 4972, 2535, 50580, 50580, 295, 1184, 9972, 365, 3104, 281, 264, 661, 13, 50726, 50726, 407, 294, 341, 1389, 11, 584, 286, 700, 6889, 257, 3344, 9972, 293, 586, 286, 6889, 1071, 2182, 9972, 13, 51015, 51015, 407, 437, 286, 360, 307, 286, 1936, 3154, 2128, 1293, 295, 613, 26531, 807, 257, 395, 7129, 293, 286, 362, 51248, 51248, 257, 1508, 9902, 300, 307, 516, 281, 5039, 364, 3180, 636, 21538, 1154, 13, 51482, 51482, 400, 577, 360, 286, 483, 264, 7645, 337, 341, 21538, 1154, 30, 51594, 51594], "temperature": 0.0, "avg_logprob": -0.15532184782482328, "compression_ratio": 1.7569721115537849, "no_speech_prob": 1.750229057506658e-05}, {"id": 210, "seek": 87624, "start": 880.5600000000001, "end": 883.48, "text": " of each patch with respect to the other.", "tokens": [50364, 8537, 747, 264, 3209, 293, 291, 1029, 264, 3209, 281, 6069, 437, 307, 264, 4972, 2535, 50580, 50580, 295, 1184, 9972, 365, 3104, 281, 264, 661, 13, 50726, 50726, 407, 294, 341, 1389, 11, 584, 286, 700, 6889, 257, 3344, 9972, 293, 586, 286, 6889, 1071, 2182, 9972, 13, 51015, 51015, 407, 437, 286, 360, 307, 286, 1936, 3154, 2128, 1293, 295, 613, 26531, 807, 257, 395, 7129, 293, 286, 362, 51248, 51248, 257, 1508, 9902, 300, 307, 516, 281, 5039, 364, 3180, 636, 21538, 1154, 13, 51482, 51482, 400, 577, 360, 286, 483, 264, 7645, 337, 341, 21538, 1154, 30, 51594, 51594], "temperature": 0.0, "avg_logprob": -0.15532184782482328, "compression_ratio": 1.7569721115537849, "no_speech_prob": 1.750229057506658e-05}, {"id": 211, "seek": 87624, "start": 883.48, "end": 889.26, "text": " So in this case, say I first sample a blue patch and now I sample another red patch.", "tokens": [50364, 8537, 747, 264, 3209, 293, 291, 1029, 264, 3209, 281, 6069, 437, 307, 264, 4972, 2535, 50580, 50580, 295, 1184, 9972, 365, 3104, 281, 264, 661, 13, 50726, 50726, 407, 294, 341, 1389, 11, 584, 286, 700, 6889, 257, 3344, 9972, 293, 586, 286, 6889, 1071, 2182, 9972, 13, 51015, 51015, 407, 437, 286, 360, 307, 286, 1936, 3154, 2128, 1293, 295, 613, 26531, 807, 257, 395, 7129, 293, 286, 362, 51248, 51248, 257, 1508, 9902, 300, 307, 516, 281, 5039, 364, 3180, 636, 21538, 1154, 13, 51482, 51482, 400, 577, 360, 286, 483, 264, 7645, 337, 341, 21538, 1154, 30, 51594, 51594], "temperature": 0.0, "avg_logprob": -0.15532184782482328, "compression_ratio": 1.7569721115537849, "no_speech_prob": 1.750229057506658e-05}, {"id": 212, "seek": 87624, "start": 889.26, "end": 893.92, "text": " So what I do is I basically feed forward both of these patches through a comnet and I have", "tokens": [50364, 8537, 747, 264, 3209, 293, 291, 1029, 264, 3209, 281, 6069, 437, 307, 264, 4972, 2535, 50580, 50580, 295, 1184, 9972, 365, 3104, 281, 264, 661, 13, 50726, 50726, 407, 294, 341, 1389, 11, 584, 286, 700, 6889, 257, 3344, 9972, 293, 586, 286, 6889, 1071, 2182, 9972, 13, 51015, 51015, 407, 437, 286, 360, 307, 286, 1936, 3154, 2128, 1293, 295, 613, 26531, 807, 257, 395, 7129, 293, 286, 362, 51248, 51248, 257, 1508, 9902, 300, 307, 516, 281, 5039, 364, 3180, 636, 21538, 1154, 13, 51482, 51482, 400, 577, 360, 286, 483, 264, 7645, 337, 341, 21538, 1154, 30, 51594, 51594], "temperature": 0.0, "avg_logprob": -0.15532184782482328, "compression_ratio": 1.7569721115537849, "no_speech_prob": 1.750229057506658e-05}, {"id": 213, "seek": 87624, "start": 893.92, "end": 898.6, "text": " a classifier that is going to solve an eight way classification problem.", "tokens": [50364, 8537, 747, 264, 3209, 293, 291, 1029, 264, 3209, 281, 6069, 437, 307, 264, 4972, 2535, 50580, 50580, 295, 1184, 9972, 365, 3104, 281, 264, 661, 13, 50726, 50726, 407, 294, 341, 1389, 11, 584, 286, 700, 6889, 257, 3344, 9972, 293, 586, 286, 6889, 1071, 2182, 9972, 13, 51015, 51015, 407, 437, 286, 360, 307, 286, 1936, 3154, 2128, 1293, 295, 613, 26531, 807, 257, 395, 7129, 293, 286, 362, 51248, 51248, 257, 1508, 9902, 300, 307, 516, 281, 5039, 364, 3180, 636, 21538, 1154, 13, 51482, 51482, 400, 577, 360, 286, 483, 264, 7645, 337, 341, 21538, 1154, 30, 51594, 51594], "temperature": 0.0, "avg_logprob": -0.15532184782482328, "compression_ratio": 1.7569721115537849, "no_speech_prob": 1.750229057506658e-05}, {"id": 214, "seek": 87624, "start": 898.6, "end": 900.84, "text": " And how do I get the label for this classification problem?", "tokens": [50364, 8537, 747, 264, 3209, 293, 291, 1029, 264, 3209, 281, 6069, 437, 307, 264, 4972, 2535, 50580, 50580, 295, 1184, 9972, 365, 3104, 281, 264, 661, 13, 50726, 50726, 407, 294, 341, 1389, 11, 584, 286, 700, 6889, 257, 3344, 9972, 293, 586, 286, 6889, 1071, 2182, 9972, 13, 51015, 51015, 407, 437, 286, 360, 307, 286, 1936, 3154, 2128, 1293, 295, 613, 26531, 807, 257, 395, 7129, 293, 286, 362, 51248, 51248, 257, 1508, 9902, 300, 307, 516, 281, 5039, 364, 3180, 636, 21538, 1154, 13, 51482, 51482, 400, 577, 360, 286, 483, 264, 7645, 337, 341, 21538, 1154, 30, 51594, 51594], "temperature": 0.0, "avg_logprob": -0.15532184782482328, "compression_ratio": 1.7569721115537849, "no_speech_prob": 1.750229057506658e-05}, {"id": 215, "seek": 90084, "start": 900.84, "end": 906.4, "text": " Well, I just look at where the red patch is located with respect to the blue patch.", "tokens": [50364, 1042, 11, 286, 445, 574, 412, 689, 264, 2182, 9972, 307, 6870, 365, 3104, 281, 264, 3344, 9972, 13, 50642, 50642, 400, 300, 311, 309, 13, 50692, 50692, 407, 412, 264, 917, 295, 309, 11, 291, 434, 445, 32884, 11, 291, 434, 445, 12606, 364, 3180, 636, 21538, 50866, 50866, 5633, 13, 50916, 50916, 509, 600, 658, 428, 16949, 538, 1936, 884, 341, 1333, 295, 12382, 1748, 341, 4707, 295, 264, 51142, 51142, 4846, 1412, 13, 51226, 51226, 400, 300, 311, 309, 13, 51276, 51276, 823, 291, 393, 764, 341, 281, 1936, 3847, 341, 2302, 395, 7129, 13, 51580, 51580], "temperature": 0.0, "avg_logprob": -0.14793157577514648, "compression_ratio": 1.6415929203539823, "no_speech_prob": 1.1015878271791735e-06}, {"id": 216, "seek": 90084, "start": 906.4, "end": 907.4, "text": " And that's it.", "tokens": [50364, 1042, 11, 286, 445, 574, 412, 689, 264, 2182, 9972, 307, 6870, 365, 3104, 281, 264, 3344, 9972, 13, 50642, 50642, 400, 300, 311, 309, 13, 50692, 50692, 407, 412, 264, 917, 295, 309, 11, 291, 434, 445, 32884, 11, 291, 434, 445, 12606, 364, 3180, 636, 21538, 50866, 50866, 5633, 13, 50916, 50916, 509, 600, 658, 428, 16949, 538, 1936, 884, 341, 1333, 295, 12382, 1748, 341, 4707, 295, 264, 51142, 51142, 4846, 1412, 13, 51226, 51226, 400, 300, 311, 309, 13, 51276, 51276, 823, 291, 393, 764, 341, 281, 1936, 3847, 341, 2302, 395, 7129, 13, 51580, 51580], "temperature": 0.0, "avg_logprob": -0.14793157577514648, "compression_ratio": 1.6415929203539823, "no_speech_prob": 1.1015878271791735e-06}, {"id": 217, "seek": 90084, "start": 907.4, "end": 910.88, "text": " So at the end of it, you're just predicting, you're just solving an eight way classification", "tokens": [50364, 1042, 11, 286, 445, 574, 412, 689, 264, 2182, 9972, 307, 6870, 365, 3104, 281, 264, 3344, 9972, 13, 50642, 50642, 400, 300, 311, 309, 13, 50692, 50692, 407, 412, 264, 917, 295, 309, 11, 291, 434, 445, 32884, 11, 291, 434, 445, 12606, 364, 3180, 636, 21538, 50866, 50866, 5633, 13, 50916, 50916, 509, 600, 658, 428, 16949, 538, 1936, 884, 341, 1333, 295, 12382, 1748, 341, 4707, 295, 264, 51142, 51142, 4846, 1412, 13, 51226, 51226, 400, 300, 311, 309, 13, 51276, 51276, 823, 291, 393, 764, 341, 281, 1936, 3847, 341, 2302, 395, 7129, 13, 51580, 51580], "temperature": 0.0, "avg_logprob": -0.14793157577514648, "compression_ratio": 1.6415929203539823, "no_speech_prob": 1.1015878271791735e-06}, {"id": 218, "seek": 90084, "start": 910.88, "end": 911.88, "text": " task.", "tokens": [50364, 1042, 11, 286, 445, 574, 412, 689, 264, 2182, 9972, 307, 6870, 365, 3104, 281, 264, 3344, 9972, 13, 50642, 50642, 400, 300, 311, 309, 13, 50692, 50692, 407, 412, 264, 917, 295, 309, 11, 291, 434, 445, 32884, 11, 291, 434, 445, 12606, 364, 3180, 636, 21538, 50866, 50866, 5633, 13, 50916, 50916, 509, 600, 658, 428, 16949, 538, 1936, 884, 341, 1333, 295, 12382, 1748, 341, 4707, 295, 264, 51142, 51142, 4846, 1412, 13, 51226, 51226, 400, 300, 311, 309, 13, 51276, 51276, 823, 291, 393, 764, 341, 281, 1936, 3847, 341, 2302, 395, 7129, 13, 51580, 51580], "temperature": 0.0, "avg_logprob": -0.14793157577514648, "compression_ratio": 1.6415929203539823, "no_speech_prob": 1.1015878271791735e-06}, {"id": 219, "seek": 90084, "start": 911.88, "end": 916.4, "text": " You've got your labels by basically doing this sort of exploiting this property of the", "tokens": [50364, 1042, 11, 286, 445, 574, 412, 689, 264, 2182, 9972, 307, 6870, 365, 3104, 281, 264, 3344, 9972, 13, 50642, 50642, 400, 300, 311, 309, 13, 50692, 50692, 407, 412, 264, 917, 295, 309, 11, 291, 434, 445, 32884, 11, 291, 434, 445, 12606, 364, 3180, 636, 21538, 50866, 50866, 5633, 13, 50916, 50916, 509, 600, 658, 428, 16949, 538, 1936, 884, 341, 1333, 295, 12382, 1748, 341, 4707, 295, 264, 51142, 51142, 4846, 1412, 13, 51226, 51226, 400, 300, 311, 309, 13, 51276, 51276, 823, 291, 393, 764, 341, 281, 1936, 3847, 341, 2302, 395, 7129, 13, 51580, 51580], "temperature": 0.0, "avg_logprob": -0.14793157577514648, "compression_ratio": 1.6415929203539823, "no_speech_prob": 1.1015878271791735e-06}, {"id": 220, "seek": 90084, "start": 916.4, "end": 918.08, "text": " input data.", "tokens": [50364, 1042, 11, 286, 445, 574, 412, 689, 264, 2182, 9972, 307, 6870, 365, 3104, 281, 264, 3344, 9972, 13, 50642, 50642, 400, 300, 311, 309, 13, 50692, 50692, 407, 412, 264, 917, 295, 309, 11, 291, 434, 445, 32884, 11, 291, 434, 445, 12606, 364, 3180, 636, 21538, 50866, 50866, 5633, 13, 50916, 50916, 509, 600, 658, 428, 16949, 538, 1936, 884, 341, 1333, 295, 12382, 1748, 341, 4707, 295, 264, 51142, 51142, 4846, 1412, 13, 51226, 51226, 400, 300, 311, 309, 13, 51276, 51276, 823, 291, 393, 764, 341, 281, 1936, 3847, 341, 2302, 395, 7129, 13, 51580, 51580], "temperature": 0.0, "avg_logprob": -0.14793157577514648, "compression_ratio": 1.6415929203539823, "no_speech_prob": 1.1015878271791735e-06}, {"id": 221, "seek": 90084, "start": 918.08, "end": 919.08, "text": " And that's it.", "tokens": [50364, 1042, 11, 286, 445, 574, 412, 689, 264, 2182, 9972, 307, 6870, 365, 3104, 281, 264, 3344, 9972, 13, 50642, 50642, 400, 300, 311, 309, 13, 50692, 50692, 407, 412, 264, 917, 295, 309, 11, 291, 434, 445, 32884, 11, 291, 434, 445, 12606, 364, 3180, 636, 21538, 50866, 50866, 5633, 13, 50916, 50916, 509, 600, 658, 428, 16949, 538, 1936, 884, 341, 1333, 295, 12382, 1748, 341, 4707, 295, 264, 51142, 51142, 4846, 1412, 13, 51226, 51226, 400, 300, 311, 309, 13, 51276, 51276, 823, 291, 393, 764, 341, 281, 1936, 3847, 341, 2302, 395, 7129, 13, 51580, 51580], "temperature": 0.0, "avg_logprob": -0.14793157577514648, "compression_ratio": 1.6415929203539823, "no_speech_prob": 1.1015878271791735e-06}, {"id": 222, "seek": 90084, "start": 919.08, "end": 925.1600000000001, "text": " Now you can use this to basically train this entire comnet.", "tokens": [50364, 1042, 11, 286, 445, 574, 412, 689, 264, 2182, 9972, 307, 6870, 365, 3104, 281, 264, 3344, 9972, 13, 50642, 50642, 400, 300, 311, 309, 13, 50692, 50692, 407, 412, 264, 917, 295, 309, 11, 291, 434, 445, 32884, 11, 291, 434, 445, 12606, 364, 3180, 636, 21538, 50866, 50866, 5633, 13, 50916, 50916, 509, 600, 658, 428, 16949, 538, 1936, 884, 341, 1333, 295, 12382, 1748, 341, 4707, 295, 264, 51142, 51142, 4846, 1412, 13, 51226, 51226, 400, 300, 311, 309, 13, 51276, 51276, 823, 291, 393, 764, 341, 281, 1936, 3847, 341, 2302, 395, 7129, 13, 51580, 51580], "temperature": 0.0, "avg_logprob": -0.14793157577514648, "compression_ratio": 1.6415929203539823, "no_speech_prob": 1.1015878271791735e-06}, {"id": 223, "seek": 92516, "start": 925.16, "end": 933.16, "text": " So to look at it in a different way, it's only solving a very small classification problem.", "tokens": [50364, 407, 281, 574, 412, 309, 294, 257, 819, 636, 11, 309, 311, 787, 12606, 257, 588, 1359, 21538, 1154, 13, 50764, 50764, 467, 311, 445, 12606, 1936, 3180, 1944, 9253, 295, 257, 1154, 13, 50994, 50994, 49908, 1547, 11, 884, 341, 1333, 295, 659, 25111, 5633, 767, 27152, 746, 6457, 10585, 13, 51304, 51304, 407, 264, 472, 636, 281, 574, 412, 437, 341, 3209, 575, 3264, 307, 281, 574, 412, 437, 309, 33095, 51574, 51574, 527, 23831, 12512, 293, 1080, 5056, 10290, 13, 51778, 51778], "temperature": 0.0, "avg_logprob": -0.12397535916032462, "compression_ratio": 1.6751054852320675, "no_speech_prob": 7.071803793223808e-06}, {"id": 224, "seek": 92516, "start": 933.16, "end": 937.76, "text": " It's just solving basically eight possible locations of a problem.", "tokens": [50364, 407, 281, 574, 412, 309, 294, 257, 819, 636, 11, 309, 311, 787, 12606, 257, 588, 1359, 21538, 1154, 13, 50764, 50764, 467, 311, 445, 12606, 1936, 3180, 1944, 9253, 295, 257, 1154, 13, 50994, 50994, 49908, 1547, 11, 884, 341, 1333, 295, 659, 25111, 5633, 767, 27152, 746, 6457, 10585, 13, 51304, 51304, 407, 264, 472, 636, 281, 574, 412, 437, 341, 3209, 575, 3264, 307, 281, 574, 412, 437, 309, 33095, 51574, 51574, 527, 23831, 12512, 293, 1080, 5056, 10290, 13, 51778, 51778], "temperature": 0.0, "avg_logprob": -0.12397535916032462, "compression_ratio": 1.6751054852320675, "no_speech_prob": 7.071803793223808e-06}, {"id": 225, "seek": 92516, "start": 937.76, "end": 943.9599999999999, "text": " Surprisingly enough, doing this sort of pretext task actually learns something fairly reasonable.", "tokens": [50364, 407, 281, 574, 412, 309, 294, 257, 819, 636, 11, 309, 311, 787, 12606, 257, 588, 1359, 21538, 1154, 13, 50764, 50764, 467, 311, 445, 12606, 1936, 3180, 1944, 9253, 295, 257, 1154, 13, 50994, 50994, 49908, 1547, 11, 884, 341, 1333, 295, 659, 25111, 5633, 767, 27152, 746, 6457, 10585, 13, 51304, 51304, 407, 264, 472, 636, 281, 574, 412, 437, 341, 3209, 575, 3264, 307, 281, 574, 412, 437, 309, 33095, 51574, 51574, 527, 23831, 12512, 293, 1080, 5056, 10290, 13, 51778, 51778], "temperature": 0.0, "avg_logprob": -0.12397535916032462, "compression_ratio": 1.6751054852320675, "no_speech_prob": 7.071803793223808e-06}, {"id": 226, "seek": 92516, "start": 943.9599999999999, "end": 949.36, "text": " So the one way to look at what this network has learned is to look at what it considers", "tokens": [50364, 407, 281, 574, 412, 309, 294, 257, 819, 636, 11, 309, 311, 787, 12606, 257, 588, 1359, 21538, 1154, 13, 50764, 50764, 467, 311, 445, 12606, 1936, 3180, 1944, 9253, 295, 257, 1154, 13, 50994, 50994, 49908, 1547, 11, 884, 341, 1333, 295, 659, 25111, 5633, 767, 27152, 746, 6457, 10585, 13, 51304, 51304, 407, 264, 472, 636, 281, 574, 412, 437, 341, 3209, 575, 3264, 307, 281, 574, 412, 437, 309, 33095, 51574, 51574, 527, 23831, 12512, 293, 1080, 5056, 10290, 13, 51778, 51778], "temperature": 0.0, "avg_logprob": -0.12397535916032462, "compression_ratio": 1.6751054852320675, "no_speech_prob": 7.071803793223808e-06}, {"id": 227, "seek": 92516, "start": 949.36, "end": 953.4399999999999, "text": " our nearest neighbors and its visual representation.", "tokens": [50364, 407, 281, 574, 412, 309, 294, 257, 819, 636, 11, 309, 311, 787, 12606, 257, 588, 1359, 21538, 1154, 13, 50764, 50764, 467, 311, 445, 12606, 1936, 3180, 1944, 9253, 295, 257, 1154, 13, 50994, 50994, 49908, 1547, 11, 884, 341, 1333, 295, 659, 25111, 5633, 767, 27152, 746, 6457, 10585, 13, 51304, 51304, 407, 264, 472, 636, 281, 574, 412, 437, 341, 3209, 575, 3264, 307, 281, 574, 412, 437, 309, 33095, 51574, 51574, 527, 23831, 12512, 293, 1080, 5056, 10290, 13, 51778, 51778], "temperature": 0.0, "avg_logprob": -0.12397535916032462, "compression_ratio": 1.6751054852320675, "no_speech_prob": 7.071803793223808e-06}, {"id": 228, "seek": 95344, "start": 953.44, "end": 958.6800000000001, "text": " So to explain this plot a little bit more, on the left hand side, you have the input", "tokens": [50364, 407, 281, 2903, 341, 7542, 257, 707, 857, 544, 11, 322, 264, 1411, 1011, 1252, 11, 291, 362, 264, 4846, 50626, 50626, 9972, 13, 50676, 50676, 407, 291, 3154, 2128, 341, 4846, 9972, 807, 300, 24859, 13, 50866, 50866, 400, 291, 1936, 8947, 257, 3840, 295, 26531, 322, 264, 1412, 11, 322, 428, 1412, 992, 13, 51102, 51102, 407, 294, 341, 1389, 11, 29903, 31890, 13, 51206, 51206, 400, 291, 14722, 4111, 33358, 337, 1184, 295, 613, 26531, 13, 51376, 51376, 823, 337, 264, 1729, 4846, 9972, 300, 291, 2845, 807, 264, 395, 7129, 11, 291, 14722, 264, 23831, 51600, 51600, 12512, 295, 439, 264, 26531, 490, 264, 1412, 992, 13, 51742, 51742], "temperature": 0.0, "avg_logprob": -0.14612411830736244, "compression_ratio": 1.8353413654618473, "no_speech_prob": 6.240696166059934e-06}, {"id": 229, "seek": 95344, "start": 958.6800000000001, "end": 959.6800000000001, "text": " patch.", "tokens": [50364, 407, 281, 2903, 341, 7542, 257, 707, 857, 544, 11, 322, 264, 1411, 1011, 1252, 11, 291, 362, 264, 4846, 50626, 50626, 9972, 13, 50676, 50676, 407, 291, 3154, 2128, 341, 4846, 9972, 807, 300, 24859, 13, 50866, 50866, 400, 291, 1936, 8947, 257, 3840, 295, 26531, 322, 264, 1412, 11, 322, 428, 1412, 992, 13, 51102, 51102, 407, 294, 341, 1389, 11, 29903, 31890, 13, 51206, 51206, 400, 291, 14722, 4111, 33358, 337, 1184, 295, 613, 26531, 13, 51376, 51376, 823, 337, 264, 1729, 4846, 9972, 300, 291, 2845, 807, 264, 395, 7129, 11, 291, 14722, 264, 23831, 51600, 51600, 12512, 295, 439, 264, 26531, 490, 264, 1412, 992, 13, 51742, 51742], "temperature": 0.0, "avg_logprob": -0.14612411830736244, "compression_ratio": 1.8353413654618473, "no_speech_prob": 6.240696166059934e-06}, {"id": 230, "seek": 95344, "start": 959.6800000000001, "end": 963.48, "text": " So you feed forward this input patch through that CNN.", "tokens": [50364, 407, 281, 2903, 341, 7542, 257, 707, 857, 544, 11, 322, 264, 1411, 1011, 1252, 11, 291, 362, 264, 4846, 50626, 50626, 9972, 13, 50676, 50676, 407, 291, 3154, 2128, 341, 4846, 9972, 807, 300, 24859, 13, 50866, 50866, 400, 291, 1936, 8947, 257, 3840, 295, 26531, 322, 264, 1412, 11, 322, 428, 1412, 992, 13, 51102, 51102, 407, 294, 341, 1389, 11, 29903, 31890, 13, 51206, 51206, 400, 291, 14722, 4111, 33358, 337, 1184, 295, 613, 26531, 13, 51376, 51376, 823, 337, 264, 1729, 4846, 9972, 300, 291, 2845, 807, 264, 395, 7129, 11, 291, 14722, 264, 23831, 51600, 51600, 12512, 295, 439, 264, 26531, 490, 264, 1412, 992, 13, 51742, 51742], "temperature": 0.0, "avg_logprob": -0.14612411830736244, "compression_ratio": 1.8353413654618473, "no_speech_prob": 6.240696166059934e-06}, {"id": 231, "seek": 95344, "start": 963.48, "end": 968.2, "text": " And you basically extract a bunch of patches on the data, on your data set.", "tokens": [50364, 407, 281, 2903, 341, 7542, 257, 707, 857, 544, 11, 322, 264, 1411, 1011, 1252, 11, 291, 362, 264, 4846, 50626, 50626, 9972, 13, 50676, 50676, 407, 291, 3154, 2128, 341, 4846, 9972, 807, 300, 24859, 13, 50866, 50866, 400, 291, 1936, 8947, 257, 3840, 295, 26531, 322, 264, 1412, 11, 322, 428, 1412, 992, 13, 51102, 51102, 407, 294, 341, 1389, 11, 29903, 31890, 13, 51206, 51206, 400, 291, 14722, 4111, 33358, 337, 1184, 295, 613, 26531, 13, 51376, 51376, 823, 337, 264, 1729, 4846, 9972, 300, 291, 2845, 807, 264, 395, 7129, 11, 291, 14722, 264, 23831, 51600, 51600, 12512, 295, 439, 264, 26531, 490, 264, 1412, 992, 13, 51742, 51742], "temperature": 0.0, "avg_logprob": -0.14612411830736244, "compression_ratio": 1.8353413654618473, "no_speech_prob": 6.240696166059934e-06}, {"id": 232, "seek": 95344, "start": 968.2, "end": 970.2800000000001, "text": " So in this case, ImageNet.", "tokens": [50364, 407, 281, 2903, 341, 7542, 257, 707, 857, 544, 11, 322, 264, 1411, 1011, 1252, 11, 291, 362, 264, 4846, 50626, 50626, 9972, 13, 50676, 50676, 407, 291, 3154, 2128, 341, 4846, 9972, 807, 300, 24859, 13, 50866, 50866, 400, 291, 1936, 8947, 257, 3840, 295, 26531, 322, 264, 1412, 11, 322, 428, 1412, 992, 13, 51102, 51102, 407, 294, 341, 1389, 11, 29903, 31890, 13, 51206, 51206, 400, 291, 14722, 4111, 33358, 337, 1184, 295, 613, 26531, 13, 51376, 51376, 823, 337, 264, 1729, 4846, 9972, 300, 291, 2845, 807, 264, 395, 7129, 11, 291, 14722, 264, 23831, 51600, 51600, 12512, 295, 439, 264, 26531, 490, 264, 1412, 992, 13, 51742, 51742], "temperature": 0.0, "avg_logprob": -0.14612411830736244, "compression_ratio": 1.8353413654618473, "no_speech_prob": 6.240696166059934e-06}, {"id": 233, "seek": 95344, "start": 970.2800000000001, "end": 973.6800000000001, "text": " And you compute feature representations for each of these patches.", "tokens": [50364, 407, 281, 2903, 341, 7542, 257, 707, 857, 544, 11, 322, 264, 1411, 1011, 1252, 11, 291, 362, 264, 4846, 50626, 50626, 9972, 13, 50676, 50676, 407, 291, 3154, 2128, 341, 4846, 9972, 807, 300, 24859, 13, 50866, 50866, 400, 291, 1936, 8947, 257, 3840, 295, 26531, 322, 264, 1412, 11, 322, 428, 1412, 992, 13, 51102, 51102, 407, 294, 341, 1389, 11, 29903, 31890, 13, 51206, 51206, 400, 291, 14722, 4111, 33358, 337, 1184, 295, 613, 26531, 13, 51376, 51376, 823, 337, 264, 1729, 4846, 9972, 300, 291, 2845, 807, 264, 395, 7129, 11, 291, 14722, 264, 23831, 51600, 51600, 12512, 295, 439, 264, 26531, 490, 264, 1412, 992, 13, 51742, 51742], "temperature": 0.0, "avg_logprob": -0.14612411830736244, "compression_ratio": 1.8353413654618473, "no_speech_prob": 6.240696166059934e-06}, {"id": 234, "seek": 95344, "start": 973.6800000000001, "end": 978.1600000000001, "text": " Now for the particular input patch that you send through the comnet, you compute the nearest", "tokens": [50364, 407, 281, 2903, 341, 7542, 257, 707, 857, 544, 11, 322, 264, 1411, 1011, 1252, 11, 291, 362, 264, 4846, 50626, 50626, 9972, 13, 50676, 50676, 407, 291, 3154, 2128, 341, 4846, 9972, 807, 300, 24859, 13, 50866, 50866, 400, 291, 1936, 8947, 257, 3840, 295, 26531, 322, 264, 1412, 11, 322, 428, 1412, 992, 13, 51102, 51102, 407, 294, 341, 1389, 11, 29903, 31890, 13, 51206, 51206, 400, 291, 14722, 4111, 33358, 337, 1184, 295, 613, 26531, 13, 51376, 51376, 823, 337, 264, 1729, 4846, 9972, 300, 291, 2845, 807, 264, 395, 7129, 11, 291, 14722, 264, 23831, 51600, 51600, 12512, 295, 439, 264, 26531, 490, 264, 1412, 992, 13, 51742, 51742], "temperature": 0.0, "avg_logprob": -0.14612411830736244, "compression_ratio": 1.8353413654618473, "no_speech_prob": 6.240696166059934e-06}, {"id": 235, "seek": 95344, "start": 978.1600000000001, "end": 981.0, "text": " neighbors of all the patches from the data set.", "tokens": [50364, 407, 281, 2903, 341, 7542, 257, 707, 857, 544, 11, 322, 264, 1411, 1011, 1252, 11, 291, 362, 264, 4846, 50626, 50626, 9972, 13, 50676, 50676, 407, 291, 3154, 2128, 341, 4846, 9972, 807, 300, 24859, 13, 50866, 50866, 400, 291, 1936, 8947, 257, 3840, 295, 26531, 322, 264, 1412, 11, 322, 428, 1412, 992, 13, 51102, 51102, 407, 294, 341, 1389, 11, 29903, 31890, 13, 51206, 51206, 400, 291, 14722, 4111, 33358, 337, 1184, 295, 613, 26531, 13, 51376, 51376, 823, 337, 264, 1729, 4846, 9972, 300, 291, 2845, 807, 264, 395, 7129, 11, 291, 14722, 264, 23831, 51600, 51600, 12512, 295, 439, 264, 26531, 490, 264, 1412, 992, 13, 51742, 51742], "temperature": 0.0, "avg_logprob": -0.14612411830736244, "compression_ratio": 1.8353413654618473, "no_speech_prob": 6.240696166059934e-06}, {"id": 236, "seek": 98100, "start": 981.0, "end": 984.96, "text": " And you can use three different networks to compute the feature representations.", "tokens": [50364, 400, 291, 393, 764, 1045, 819, 9590, 281, 14722, 264, 4111, 33358, 13, 50562, 50562, 407, 264, 700, 7738, 307, 264, 4972, 26381, 659, 25111, 5633, 13, 50746, 50746, 400, 264, 1150, 7738, 307, 1936, 257, 16979, 5883, 1602, 5202, 31890, 13, 50938, 50938, 400, 550, 264, 2636, 7738, 307, 1936, 29903, 31890, 659, 12, 17227, 2001, 5202, 31890, 13, 51226, 51226, 407, 498, 291, 1333, 295, 574, 412, 437, 341, 4972, 26381, 5633, 307, 23384, 11, 309, 311, 534, 51516, 51516, 1075, 281, 915, 588, 665, 26531, 11, 26531, 300, 366, 14800, 420, 588, 1998, 281, 264, 4846, 9972, 13, 51840, 51840], "temperature": 0.0, "avg_logprob": -0.14022935231526693, "compression_ratio": 1.7790697674418605, "no_speech_prob": 2.111149842676241e-05}, {"id": 237, "seek": 98100, "start": 984.96, "end": 988.64, "text": " So the first column is the relative positioning pretext task.", "tokens": [50364, 400, 291, 393, 764, 1045, 819, 9590, 281, 14722, 264, 4111, 33358, 13, 50562, 50562, 407, 264, 700, 7738, 307, 264, 4972, 26381, 659, 25111, 5633, 13, 50746, 50746, 400, 264, 1150, 7738, 307, 1936, 257, 16979, 5883, 1602, 5202, 31890, 13, 50938, 50938, 400, 550, 264, 2636, 7738, 307, 1936, 29903, 31890, 659, 12, 17227, 2001, 5202, 31890, 13, 51226, 51226, 407, 498, 291, 1333, 295, 574, 412, 437, 341, 4972, 26381, 5633, 307, 23384, 11, 309, 311, 534, 51516, 51516, 1075, 281, 915, 588, 665, 26531, 11, 26531, 300, 366, 14800, 420, 588, 1998, 281, 264, 4846, 9972, 13, 51840, 51840], "temperature": 0.0, "avg_logprob": -0.14022935231526693, "compression_ratio": 1.7790697674418605, "no_speech_prob": 2.111149842676241e-05}, {"id": 238, "seek": 98100, "start": 988.64, "end": 992.48, "text": " And the second column is basically a randomly initialized AlexNet.", "tokens": [50364, 400, 291, 393, 764, 1045, 819, 9590, 281, 14722, 264, 4111, 33358, 13, 50562, 50562, 407, 264, 700, 7738, 307, 264, 4972, 26381, 659, 25111, 5633, 13, 50746, 50746, 400, 264, 1150, 7738, 307, 1936, 257, 16979, 5883, 1602, 5202, 31890, 13, 50938, 50938, 400, 550, 264, 2636, 7738, 307, 1936, 29903, 31890, 659, 12, 17227, 2001, 5202, 31890, 13, 51226, 51226, 407, 498, 291, 1333, 295, 574, 412, 437, 341, 4972, 26381, 5633, 307, 23384, 11, 309, 311, 534, 51516, 51516, 1075, 281, 915, 588, 665, 26531, 11, 26531, 300, 366, 14800, 420, 588, 1998, 281, 264, 4846, 9972, 13, 51840, 51840], "temperature": 0.0, "avg_logprob": -0.14022935231526693, "compression_ratio": 1.7790697674418605, "no_speech_prob": 2.111149842676241e-05}, {"id": 239, "seek": 98100, "start": 992.48, "end": 998.24, "text": " And then the third column is basically ImageNet pre-trained AlexNet.", "tokens": [50364, 400, 291, 393, 764, 1045, 819, 9590, 281, 14722, 264, 4111, 33358, 13, 50562, 50562, 407, 264, 700, 7738, 307, 264, 4972, 26381, 659, 25111, 5633, 13, 50746, 50746, 400, 264, 1150, 7738, 307, 1936, 257, 16979, 5883, 1602, 5202, 31890, 13, 50938, 50938, 400, 550, 264, 2636, 7738, 307, 1936, 29903, 31890, 659, 12, 17227, 2001, 5202, 31890, 13, 51226, 51226, 407, 498, 291, 1333, 295, 574, 412, 437, 341, 4972, 26381, 5633, 307, 23384, 11, 309, 311, 534, 51516, 51516, 1075, 281, 915, 588, 665, 26531, 11, 26531, 300, 366, 14800, 420, 588, 1998, 281, 264, 4846, 9972, 13, 51840, 51840], "temperature": 0.0, "avg_logprob": -0.14022935231526693, "compression_ratio": 1.7790697674418605, "no_speech_prob": 2.111149842676241e-05}, {"id": 240, "seek": 98100, "start": 998.24, "end": 1004.04, "text": " So if you sort of look at what this relative positioning task is capturing, it's really", "tokens": [50364, 400, 291, 393, 764, 1045, 819, 9590, 281, 14722, 264, 4111, 33358, 13, 50562, 50562, 407, 264, 700, 7738, 307, 264, 4972, 26381, 659, 25111, 5633, 13, 50746, 50746, 400, 264, 1150, 7738, 307, 1936, 257, 16979, 5883, 1602, 5202, 31890, 13, 50938, 50938, 400, 550, 264, 2636, 7738, 307, 1936, 29903, 31890, 659, 12, 17227, 2001, 5202, 31890, 13, 51226, 51226, 407, 498, 291, 1333, 295, 574, 412, 437, 341, 4972, 26381, 5633, 307, 23384, 11, 309, 311, 534, 51516, 51516, 1075, 281, 915, 588, 665, 26531, 11, 26531, 300, 366, 14800, 420, 588, 1998, 281, 264, 4846, 9972, 13, 51840, 51840], "temperature": 0.0, "avg_logprob": -0.14022935231526693, "compression_ratio": 1.7790697674418605, "no_speech_prob": 2.111149842676241e-05}, {"id": 241, "seek": 98100, "start": 1004.04, "end": 1010.52, "text": " able to find very good patches, patches that are identical or very close to the input patch.", "tokens": [50364, 400, 291, 393, 764, 1045, 819, 9590, 281, 14722, 264, 4111, 33358, 13, 50562, 50562, 407, 264, 700, 7738, 307, 264, 4972, 26381, 659, 25111, 5633, 13, 50746, 50746, 400, 264, 1150, 7738, 307, 1936, 257, 16979, 5883, 1602, 5202, 31890, 13, 50938, 50938, 400, 550, 264, 2636, 7738, 307, 1936, 29903, 31890, 659, 12, 17227, 2001, 5202, 31890, 13, 51226, 51226, 407, 498, 291, 1333, 295, 574, 412, 437, 341, 4972, 26381, 5633, 307, 23384, 11, 309, 311, 534, 51516, 51516, 1075, 281, 915, 588, 665, 26531, 11, 26531, 300, 366, 14800, 420, 588, 1998, 281, 264, 4846, 9972, 13, 51840, 51840], "temperature": 0.0, "avg_logprob": -0.14022935231526693, "compression_ratio": 1.7790697674418605, "no_speech_prob": 2.111149842676241e-05}, {"id": 242, "seek": 101052, "start": 1010.52, "end": 1014.56, "text": " And you also see that it's, for example, like in the row of the cat.", "tokens": [50364, 400, 291, 611, 536, 300, 309, 311, 11, 337, 1365, 11, 411, 294, 264, 5386, 295, 264, 3857, 13, 50566, 50566, 407, 300, 311, 264, 6409, 5386, 13, 50649, 50649, 509, 393, 536, 300, 309, 311, 767, 1075, 281, 2573, 484, 309, 311, 4748, 33270, 394, 281, 584, 264, 2017, 13, 50844, 50844, 407, 264, 4846, 3857, 390, 2211, 293, 2418, 11, 457, 309, 311, 767, 1075, 281, 1888, 484, 11111, 597, 51048, 51048, 366, 406, 445, 2211, 293, 2418, 13, 51156, 51156, 407, 309, 311, 534, 884, 746, 13, 51222, 51222, 467, 311, 412, 1935, 1075, 281, 1778, 466, 26531, 382, 257, 1379, 13, 51448, 51448, 407, 983, 820, 341, 10290, 360, 1340, 597, 307, 47982, 30, 51738, 51738], "temperature": 0.0, "avg_logprob": -0.10204122887283075, "compression_ratio": 1.779527559055118, "no_speech_prob": 1.5936097042867914e-05}, {"id": 243, "seek": 101052, "start": 1014.56, "end": 1016.22, "text": " So that's the fourth row.", "tokens": [50364, 400, 291, 611, 536, 300, 309, 311, 11, 337, 1365, 11, 411, 294, 264, 5386, 295, 264, 3857, 13, 50566, 50566, 407, 300, 311, 264, 6409, 5386, 13, 50649, 50649, 509, 393, 536, 300, 309, 311, 767, 1075, 281, 2573, 484, 309, 311, 4748, 33270, 394, 281, 584, 264, 2017, 13, 50844, 50844, 407, 264, 4846, 3857, 390, 2211, 293, 2418, 11, 457, 309, 311, 767, 1075, 281, 1888, 484, 11111, 597, 51048, 51048, 366, 406, 445, 2211, 293, 2418, 13, 51156, 51156, 407, 309, 311, 534, 884, 746, 13, 51222, 51222, 467, 311, 412, 1935, 1075, 281, 1778, 466, 26531, 382, 257, 1379, 13, 51448, 51448, 407, 983, 820, 341, 10290, 360, 1340, 597, 307, 47982, 30, 51738, 51738], "temperature": 0.0, "avg_logprob": -0.10204122887283075, "compression_ratio": 1.779527559055118, "no_speech_prob": 1.5936097042867914e-05}, {"id": 244, "seek": 101052, "start": 1016.22, "end": 1020.12, "text": " You can see that it's actually able to figure out it's slightly invariant to say the color.", "tokens": [50364, 400, 291, 611, 536, 300, 309, 311, 11, 337, 1365, 11, 411, 294, 264, 5386, 295, 264, 3857, 13, 50566, 50566, 407, 300, 311, 264, 6409, 5386, 13, 50649, 50649, 509, 393, 536, 300, 309, 311, 767, 1075, 281, 2573, 484, 309, 311, 4748, 33270, 394, 281, 584, 264, 2017, 13, 50844, 50844, 407, 264, 4846, 3857, 390, 2211, 293, 2418, 11, 457, 309, 311, 767, 1075, 281, 1888, 484, 11111, 597, 51048, 51048, 366, 406, 445, 2211, 293, 2418, 13, 51156, 51156, 407, 309, 311, 534, 884, 746, 13, 51222, 51222, 467, 311, 412, 1935, 1075, 281, 1778, 466, 26531, 382, 257, 1379, 13, 51448, 51448, 407, 983, 820, 341, 10290, 360, 1340, 597, 307, 47982, 30, 51738, 51738], "temperature": 0.0, "avg_logprob": -0.10204122887283075, "compression_ratio": 1.779527559055118, "no_speech_prob": 1.5936097042867914e-05}, {"id": 245, "seek": 101052, "start": 1020.12, "end": 1024.2, "text": " So the input cat was black and white, but it's actually able to pick out cats which", "tokens": [50364, 400, 291, 611, 536, 300, 309, 311, 11, 337, 1365, 11, 411, 294, 264, 5386, 295, 264, 3857, 13, 50566, 50566, 407, 300, 311, 264, 6409, 5386, 13, 50649, 50649, 509, 393, 536, 300, 309, 311, 767, 1075, 281, 2573, 484, 309, 311, 4748, 33270, 394, 281, 584, 264, 2017, 13, 50844, 50844, 407, 264, 4846, 3857, 390, 2211, 293, 2418, 11, 457, 309, 311, 767, 1075, 281, 1888, 484, 11111, 597, 51048, 51048, 366, 406, 445, 2211, 293, 2418, 13, 51156, 51156, 407, 309, 311, 534, 884, 746, 13, 51222, 51222, 467, 311, 412, 1935, 1075, 281, 1778, 466, 26531, 382, 257, 1379, 13, 51448, 51448, 407, 983, 820, 341, 10290, 360, 1340, 597, 307, 47982, 30, 51738, 51738], "temperature": 0.0, "avg_logprob": -0.10204122887283075, "compression_ratio": 1.779527559055118, "no_speech_prob": 1.5936097042867914e-05}, {"id": 246, "seek": 101052, "start": 1024.2, "end": 1026.36, "text": " are not just black and white.", "tokens": [50364, 400, 291, 611, 536, 300, 309, 311, 11, 337, 1365, 11, 411, 294, 264, 5386, 295, 264, 3857, 13, 50566, 50566, 407, 300, 311, 264, 6409, 5386, 13, 50649, 50649, 509, 393, 536, 300, 309, 311, 767, 1075, 281, 2573, 484, 309, 311, 4748, 33270, 394, 281, 584, 264, 2017, 13, 50844, 50844, 407, 264, 4846, 3857, 390, 2211, 293, 2418, 11, 457, 309, 311, 767, 1075, 281, 1888, 484, 11111, 597, 51048, 51048, 366, 406, 445, 2211, 293, 2418, 13, 51156, 51156, 407, 309, 311, 534, 884, 746, 13, 51222, 51222, 467, 311, 412, 1935, 1075, 281, 1778, 466, 26531, 382, 257, 1379, 13, 51448, 51448, 407, 983, 820, 341, 10290, 360, 1340, 597, 307, 47982, 30, 51738, 51738], "temperature": 0.0, "avg_logprob": -0.10204122887283075, "compression_ratio": 1.779527559055118, "no_speech_prob": 1.5936097042867914e-05}, {"id": 247, "seek": 101052, "start": 1026.36, "end": 1027.68, "text": " So it's really doing something.", "tokens": [50364, 400, 291, 611, 536, 300, 309, 311, 11, 337, 1365, 11, 411, 294, 264, 5386, 295, 264, 3857, 13, 50566, 50566, 407, 300, 311, 264, 6409, 5386, 13, 50649, 50649, 509, 393, 536, 300, 309, 311, 767, 1075, 281, 2573, 484, 309, 311, 4748, 33270, 394, 281, 584, 264, 2017, 13, 50844, 50844, 407, 264, 4846, 3857, 390, 2211, 293, 2418, 11, 457, 309, 311, 767, 1075, 281, 1888, 484, 11111, 597, 51048, 51048, 366, 406, 445, 2211, 293, 2418, 13, 51156, 51156, 407, 309, 311, 534, 884, 746, 13, 51222, 51222, 467, 311, 412, 1935, 1075, 281, 1778, 466, 26531, 382, 257, 1379, 13, 51448, 51448, 407, 983, 820, 341, 10290, 360, 1340, 597, 307, 47982, 30, 51738, 51738], "temperature": 0.0, "avg_logprob": -0.10204122887283075, "compression_ratio": 1.779527559055118, "no_speech_prob": 1.5936097042867914e-05}, {"id": 248, "seek": 101052, "start": 1027.68, "end": 1032.2, "text": " It's at least able to reason about patches as a whole.", "tokens": [50364, 400, 291, 611, 536, 300, 309, 311, 11, 337, 1365, 11, 411, 294, 264, 5386, 295, 264, 3857, 13, 50566, 50566, 407, 300, 311, 264, 6409, 5386, 13, 50649, 50649, 509, 393, 536, 300, 309, 311, 767, 1075, 281, 2573, 484, 309, 311, 4748, 33270, 394, 281, 584, 264, 2017, 13, 50844, 50844, 407, 264, 4846, 3857, 390, 2211, 293, 2418, 11, 457, 309, 311, 767, 1075, 281, 1888, 484, 11111, 597, 51048, 51048, 366, 406, 445, 2211, 293, 2418, 13, 51156, 51156, 407, 309, 311, 534, 884, 746, 13, 51222, 51222, 467, 311, 412, 1935, 1075, 281, 1778, 466, 26531, 382, 257, 1379, 13, 51448, 51448, 407, 983, 820, 341, 10290, 360, 1340, 597, 307, 47982, 30, 51738, 51738], "temperature": 0.0, "avg_logprob": -0.10204122887283075, "compression_ratio": 1.779527559055118, "no_speech_prob": 1.5936097042867914e-05}, {"id": 249, "seek": 101052, "start": 1032.2, "end": 1038.0, "text": " So why should this representation do anything which is semantic?", "tokens": [50364, 400, 291, 611, 536, 300, 309, 311, 11, 337, 1365, 11, 411, 294, 264, 5386, 295, 264, 3857, 13, 50566, 50566, 407, 300, 311, 264, 6409, 5386, 13, 50649, 50649, 509, 393, 536, 300, 309, 311, 767, 1075, 281, 2573, 484, 309, 311, 4748, 33270, 394, 281, 584, 264, 2017, 13, 50844, 50844, 407, 264, 4846, 3857, 390, 2211, 293, 2418, 11, 457, 309, 311, 767, 1075, 281, 1888, 484, 11111, 597, 51048, 51048, 366, 406, 445, 2211, 293, 2418, 13, 51156, 51156, 407, 309, 311, 534, 884, 746, 13, 51222, 51222, 467, 311, 412, 1935, 1075, 281, 1778, 466, 26531, 382, 257, 1379, 13, 51448, 51448, 407, 983, 820, 341, 10290, 360, 1340, 597, 307, 47982, 30, 51738, 51738], "temperature": 0.0, "avg_logprob": -0.10204122887283075, "compression_ratio": 1.779527559055118, "no_speech_prob": 1.5936097042867914e-05}, {"id": 250, "seek": 103800, "start": 1038.0, "end": 1042.92, "text": " So the nearest neighbor visualization technique is good at telling you what this representation", "tokens": [50364, 407, 264, 23831, 5987, 25801, 6532, 307, 665, 412, 3585, 291, 437, 341, 10290, 50610, 50610, 1901, 575, 11828, 13, 50698, 50698, 407, 294, 341, 1389, 11, 437, 321, 393, 41956, 584, 307, 300, 341, 4972, 9972, 10290, 50982, 50982, 575, 3264, 281, 1333, 295, 14644, 257, 3840, 295, 613, 2654, 26531, 1214, 11, 2654, 26531, 51236, 51236, 300, 362, 9810, 264, 912, 8967, 13, 51384, 51384, 400, 370, 570, 309, 307, 1075, 281, 1778, 466, 613, 2654, 26531, 11, 1310, 309, 311, 767, 1075, 51592, 51592, 281, 1778, 466, 264, 3256, 570, 3256, 393, 1333, 295, 312, 19174, 382, 257, 3840, 295, 2654, 26531, 51814, 51814], "temperature": 0.0, "avg_logprob": -0.08674655704323304, "compression_ratio": 1.9169811320754717, "no_speech_prob": 2.7263936317467596e-06}, {"id": 251, "seek": 103800, "start": 1042.92, "end": 1044.68, "text": " space has captured.", "tokens": [50364, 407, 264, 23831, 5987, 25801, 6532, 307, 665, 412, 3585, 291, 437, 341, 10290, 50610, 50610, 1901, 575, 11828, 13, 50698, 50698, 407, 294, 341, 1389, 11, 437, 321, 393, 41956, 584, 307, 300, 341, 4972, 9972, 10290, 50982, 50982, 575, 3264, 281, 1333, 295, 14644, 257, 3840, 295, 613, 2654, 26531, 1214, 11, 2654, 26531, 51236, 51236, 300, 362, 9810, 264, 912, 8967, 13, 51384, 51384, 400, 370, 570, 309, 307, 1075, 281, 1778, 466, 613, 2654, 26531, 11, 1310, 309, 311, 767, 1075, 51592, 51592, 281, 1778, 466, 264, 3256, 570, 3256, 393, 1333, 295, 312, 19174, 382, 257, 3840, 295, 2654, 26531, 51814, 51814], "temperature": 0.0, "avg_logprob": -0.08674655704323304, "compression_ratio": 1.9169811320754717, "no_speech_prob": 2.7263936317467596e-06}, {"id": 252, "seek": 103800, "start": 1044.68, "end": 1050.36, "text": " So in this case, what we can confidently say is that this relative patch representation", "tokens": [50364, 407, 264, 23831, 5987, 25801, 6532, 307, 665, 412, 3585, 291, 437, 341, 10290, 50610, 50610, 1901, 575, 11828, 13, 50698, 50698, 407, 294, 341, 1389, 11, 437, 321, 393, 41956, 584, 307, 300, 341, 4972, 9972, 10290, 50982, 50982, 575, 3264, 281, 1333, 295, 14644, 257, 3840, 295, 613, 2654, 26531, 1214, 11, 2654, 26531, 51236, 51236, 300, 362, 9810, 264, 912, 8967, 13, 51384, 51384, 400, 370, 570, 309, 307, 1075, 281, 1778, 466, 613, 2654, 26531, 11, 1310, 309, 311, 767, 1075, 51592, 51592, 281, 1778, 466, 264, 3256, 570, 3256, 393, 1333, 295, 312, 19174, 382, 257, 3840, 295, 2654, 26531, 51814, 51814], "temperature": 0.0, "avg_logprob": -0.08674655704323304, "compression_ratio": 1.9169811320754717, "no_speech_prob": 2.7263936317467596e-06}, {"id": 253, "seek": 103800, "start": 1050.36, "end": 1055.44, "text": " has learned to sort of associate a bunch of these local patches together, local patches", "tokens": [50364, 407, 264, 23831, 5987, 25801, 6532, 307, 665, 412, 3585, 291, 437, 341, 10290, 50610, 50610, 1901, 575, 11828, 13, 50698, 50698, 407, 294, 341, 1389, 11, 437, 321, 393, 41956, 584, 307, 300, 341, 4972, 9972, 10290, 50982, 50982, 575, 3264, 281, 1333, 295, 14644, 257, 3840, 295, 613, 2654, 26531, 1214, 11, 2654, 26531, 51236, 51236, 300, 362, 9810, 264, 912, 8967, 13, 51384, 51384, 400, 370, 570, 309, 307, 1075, 281, 1778, 466, 613, 2654, 26531, 11, 1310, 309, 311, 767, 1075, 51592, 51592, 281, 1778, 466, 264, 3256, 570, 3256, 393, 1333, 295, 312, 19174, 382, 257, 3840, 295, 2654, 26531, 51814, 51814], "temperature": 0.0, "avg_logprob": -0.08674655704323304, "compression_ratio": 1.9169811320754717, "no_speech_prob": 2.7263936317467596e-06}, {"id": 254, "seek": 103800, "start": 1055.44, "end": 1058.4, "text": " that have roughly the same appearance.", "tokens": [50364, 407, 264, 23831, 5987, 25801, 6532, 307, 665, 412, 3585, 291, 437, 341, 10290, 50610, 50610, 1901, 575, 11828, 13, 50698, 50698, 407, 294, 341, 1389, 11, 437, 321, 393, 41956, 584, 307, 300, 341, 4972, 9972, 10290, 50982, 50982, 575, 3264, 281, 1333, 295, 14644, 257, 3840, 295, 613, 2654, 26531, 1214, 11, 2654, 26531, 51236, 51236, 300, 362, 9810, 264, 912, 8967, 13, 51384, 51384, 400, 370, 570, 309, 307, 1075, 281, 1778, 466, 613, 2654, 26531, 11, 1310, 309, 311, 767, 1075, 51592, 51592, 281, 1778, 466, 264, 3256, 570, 3256, 393, 1333, 295, 312, 19174, 382, 257, 3840, 295, 2654, 26531, 51814, 51814], "temperature": 0.0, "avg_logprob": -0.08674655704323304, "compression_ratio": 1.9169811320754717, "no_speech_prob": 2.7263936317467596e-06}, {"id": 255, "seek": 103800, "start": 1058.4, "end": 1062.56, "text": " And so because it is able to reason about these local patches, maybe it's actually able", "tokens": [50364, 407, 264, 23831, 5987, 25801, 6532, 307, 665, 412, 3585, 291, 437, 341, 10290, 50610, 50610, 1901, 575, 11828, 13, 50698, 50698, 407, 294, 341, 1389, 11, 437, 321, 393, 41956, 584, 307, 300, 341, 4972, 9972, 10290, 50982, 50982, 575, 3264, 281, 1333, 295, 14644, 257, 3840, 295, 613, 2654, 26531, 1214, 11, 2654, 26531, 51236, 51236, 300, 362, 9810, 264, 912, 8967, 13, 51384, 51384, 400, 370, 570, 309, 307, 1075, 281, 1778, 466, 613, 2654, 26531, 11, 1310, 309, 311, 767, 1075, 51592, 51592, 281, 1778, 466, 264, 3256, 570, 3256, 393, 1333, 295, 312, 19174, 382, 257, 3840, 295, 2654, 26531, 51814, 51814], "temperature": 0.0, "avg_logprob": -0.08674655704323304, "compression_ratio": 1.9169811320754717, "no_speech_prob": 2.7263936317467596e-06}, {"id": 256, "seek": 103800, "start": 1062.56, "end": 1067.0, "text": " to reason about the image because image can sort of be viewed as a bunch of local patches", "tokens": [50364, 407, 264, 23831, 5987, 25801, 6532, 307, 665, 412, 3585, 291, 437, 341, 10290, 50610, 50610, 1901, 575, 11828, 13, 50698, 50698, 407, 294, 341, 1389, 11, 437, 321, 393, 41956, 584, 307, 300, 341, 4972, 9972, 10290, 50982, 50982, 575, 3264, 281, 1333, 295, 14644, 257, 3840, 295, 613, 2654, 26531, 1214, 11, 2654, 26531, 51236, 51236, 300, 362, 9810, 264, 912, 8967, 13, 51384, 51384, 400, 370, 570, 309, 307, 1075, 281, 1778, 466, 613, 2654, 26531, 11, 1310, 309, 311, 767, 1075, 51592, 51592, 281, 1778, 466, 264, 3256, 570, 3256, 393, 1333, 295, 312, 19174, 382, 257, 3840, 295, 2654, 26531, 51814, 51814], "temperature": 0.0, "avg_logprob": -0.08674655704323304, "compression_ratio": 1.9169811320754717, "no_speech_prob": 2.7263936317467596e-06}, {"id": 257, "seek": 106700, "start": 1067.0, "end": 1068.0, "text": " together.", "tokens": [50364, 1214, 13, 50414, 50414, 407, 309, 311, 1075, 281, 1333, 295, 829, 613, 26531, 294, 472, 644, 295, 264, 10290, 1901, 13, 50854, 50854, 823, 561, 362, 11, 411, 286, 848, 11, 561, 362, 5768, 6457, 5880, 365, 264, 3685, 295, 659, 25111, 51078, 51078, 9608, 436, 360, 13, 51144, 51144, 407, 1071, 1333, 295, 3743, 659, 25111, 5633, 307, 32884, 44796, 295, 364, 3256, 13, 51422, 51422, 400, 341, 11, 370, 341, 5633, 307, 588, 15325, 13, 51613, 51613, 509, 362, 364, 3256, 13, 51688, 51688], "temperature": 0.0, "avg_logprob": -0.11896507391768894, "compression_ratio": 1.6682926829268292, "no_speech_prob": 1.6187248547794297e-05}, {"id": 258, "seek": 106700, "start": 1068.0, "end": 1076.8, "text": " So it's able to sort of put these patches in one part of the representation space.", "tokens": [50364, 1214, 13, 50414, 50414, 407, 309, 311, 1075, 281, 1333, 295, 829, 613, 26531, 294, 472, 644, 295, 264, 10290, 1901, 13, 50854, 50854, 823, 561, 362, 11, 411, 286, 848, 11, 561, 362, 5768, 6457, 5880, 365, 264, 3685, 295, 659, 25111, 51078, 51078, 9608, 436, 360, 13, 51144, 51144, 407, 1071, 1333, 295, 3743, 659, 25111, 5633, 307, 32884, 44796, 295, 364, 3256, 13, 51422, 51422, 400, 341, 11, 370, 341, 5633, 307, 588, 15325, 13, 51613, 51613, 509, 362, 364, 3256, 13, 51688, 51688], "temperature": 0.0, "avg_logprob": -0.11896507391768894, "compression_ratio": 1.6682926829268292, "no_speech_prob": 1.6187248547794297e-05}, {"id": 259, "seek": 106700, "start": 1076.8, "end": 1081.28, "text": " Now people have, like I said, people have gotten fairly creative with the kinds of pretext", "tokens": [50364, 1214, 13, 50414, 50414, 407, 309, 311, 1075, 281, 1333, 295, 829, 613, 26531, 294, 472, 644, 295, 264, 10290, 1901, 13, 50854, 50854, 823, 561, 362, 11, 411, 286, 848, 11, 561, 362, 5768, 6457, 5880, 365, 264, 3685, 295, 659, 25111, 51078, 51078, 9608, 436, 360, 13, 51144, 51144, 407, 1071, 1333, 295, 3743, 659, 25111, 5633, 307, 32884, 44796, 295, 364, 3256, 13, 51422, 51422, 400, 341, 11, 370, 341, 5633, 307, 588, 15325, 13, 51613, 51613, 509, 362, 364, 3256, 13, 51688, 51688], "temperature": 0.0, "avg_logprob": -0.11896507391768894, "compression_ratio": 1.6682926829268292, "no_speech_prob": 1.6187248547794297e-05}, {"id": 260, "seek": 106700, "start": 1081.28, "end": 1082.6, "text": " tasks they do.", "tokens": [50364, 1214, 13, 50414, 50414, 407, 309, 311, 1075, 281, 1333, 295, 829, 613, 26531, 294, 472, 644, 295, 264, 10290, 1901, 13, 50854, 50854, 823, 561, 362, 11, 411, 286, 848, 11, 561, 362, 5768, 6457, 5880, 365, 264, 3685, 295, 659, 25111, 51078, 51078, 9608, 436, 360, 13, 51144, 51144, 407, 1071, 1333, 295, 3743, 659, 25111, 5633, 307, 32884, 44796, 295, 364, 3256, 13, 51422, 51422, 400, 341, 11, 370, 341, 5633, 307, 588, 15325, 13, 51613, 51613, 509, 362, 364, 3256, 13, 51688, 51688], "temperature": 0.0, "avg_logprob": -0.11896507391768894, "compression_ratio": 1.6682926829268292, "no_speech_prob": 1.6187248547794297e-05}, {"id": 261, "seek": 106700, "start": 1082.6, "end": 1088.16, "text": " So another sort of popular pretext task is predicting rotations of an image.", "tokens": [50364, 1214, 13, 50414, 50414, 407, 309, 311, 1075, 281, 1333, 295, 829, 613, 26531, 294, 472, 644, 295, 264, 10290, 1901, 13, 50854, 50854, 823, 561, 362, 11, 411, 286, 848, 11, 561, 362, 5768, 6457, 5880, 365, 264, 3685, 295, 659, 25111, 51078, 51078, 9608, 436, 360, 13, 51144, 51144, 407, 1071, 1333, 295, 3743, 659, 25111, 5633, 307, 32884, 44796, 295, 364, 3256, 13, 51422, 51422, 400, 341, 11, 370, 341, 5633, 307, 588, 15325, 13, 51613, 51613, 509, 362, 364, 3256, 13, 51688, 51688], "temperature": 0.0, "avg_logprob": -0.11896507391768894, "compression_ratio": 1.6682926829268292, "no_speech_prob": 1.6187248547794297e-05}, {"id": 262, "seek": 106700, "start": 1088.16, "end": 1091.98, "text": " And this, so this task is very straightforward.", "tokens": [50364, 1214, 13, 50414, 50414, 407, 309, 311, 1075, 281, 1333, 295, 829, 613, 26531, 294, 472, 644, 295, 264, 10290, 1901, 13, 50854, 50854, 823, 561, 362, 11, 411, 286, 848, 11, 561, 362, 5768, 6457, 5880, 365, 264, 3685, 295, 659, 25111, 51078, 51078, 9608, 436, 360, 13, 51144, 51144, 407, 1071, 1333, 295, 3743, 659, 25111, 5633, 307, 32884, 44796, 295, 364, 3256, 13, 51422, 51422, 400, 341, 11, 370, 341, 5633, 307, 588, 15325, 13, 51613, 51613, 509, 362, 364, 3256, 13, 51688, 51688], "temperature": 0.0, "avg_logprob": -0.11896507391768894, "compression_ratio": 1.6682926829268292, "no_speech_prob": 1.6187248547794297e-05}, {"id": 263, "seek": 106700, "start": 1091.98, "end": 1093.48, "text": " You have an image.", "tokens": [50364, 1214, 13, 50414, 50414, 407, 309, 311, 1075, 281, 1333, 295, 829, 613, 26531, 294, 472, 644, 295, 264, 10290, 1901, 13, 50854, 50854, 823, 561, 362, 11, 411, 286, 848, 11, 561, 362, 5768, 6457, 5880, 365, 264, 3685, 295, 659, 25111, 51078, 51078, 9608, 436, 360, 13, 51144, 51144, 407, 1071, 1333, 295, 3743, 659, 25111, 5633, 307, 32884, 44796, 295, 364, 3256, 13, 51422, 51422, 400, 341, 11, 370, 341, 5633, 307, 588, 15325, 13, 51613, 51613, 509, 362, 364, 3256, 13, 51688, 51688], "temperature": 0.0, "avg_logprob": -0.11896507391768894, "compression_ratio": 1.6682926829268292, "no_speech_prob": 1.6187248547794297e-05}, {"id": 264, "seek": 109348, "start": 1093.48, "end": 1099.64, "text": " You can either apply a rotation of 0 degrees, 90 degrees, 180 degrees, or 270 degrees to", "tokens": [50364, 509, 393, 2139, 3079, 257, 12447, 295, 1958, 5310, 11, 4289, 5310, 11, 11971, 5310, 11, 420, 40774, 5310, 281, 50672, 50672, 309, 13, 50724, 50724, 400, 1936, 291, 2845, 294, 300, 1729, 3256, 934, 9275, 257, 12447, 293, 291, 1029, 50982, 50982, 264, 3209, 281, 6069, 437, 390, 264, 1900, 12447, 6456, 281, 264, 3256, 13, 51185, 51185, 400, 309, 445, 39890, 257, 1451, 636, 21538, 1154, 13, 51340, 51340, 407, 309, 6069, 82, 1936, 2139, 498, 264, 12447, 307, 1958, 11, 4289, 11, 11971, 11, 420, 40774, 13, 51684, 51684], "temperature": 0.0, "avg_logprob": -0.12967954797947662, "compression_ratio": 1.7735849056603774, "no_speech_prob": 6.962065072002588e-06}, {"id": 265, "seek": 109348, "start": 1099.64, "end": 1100.68, "text": " it.", "tokens": [50364, 509, 393, 2139, 3079, 257, 12447, 295, 1958, 5310, 11, 4289, 5310, 11, 11971, 5310, 11, 420, 40774, 5310, 281, 50672, 50672, 309, 13, 50724, 50724, 400, 1936, 291, 2845, 294, 300, 1729, 3256, 934, 9275, 257, 12447, 293, 291, 1029, 50982, 50982, 264, 3209, 281, 6069, 437, 390, 264, 1900, 12447, 6456, 281, 264, 3256, 13, 51185, 51185, 400, 309, 445, 39890, 257, 1451, 636, 21538, 1154, 13, 51340, 51340, 407, 309, 6069, 82, 1936, 2139, 498, 264, 12447, 307, 1958, 11, 4289, 11, 11971, 11, 420, 40774, 13, 51684, 51684], "temperature": 0.0, "avg_logprob": -0.12967954797947662, "compression_ratio": 1.7735849056603774, "no_speech_prob": 6.962065072002588e-06}, {"id": 266, "seek": 109348, "start": 1100.68, "end": 1105.84, "text": " And basically you send in that particular image after applying a rotation and you ask", "tokens": [50364, 509, 393, 2139, 3079, 257, 12447, 295, 1958, 5310, 11, 4289, 5310, 11, 11971, 5310, 11, 420, 40774, 5310, 281, 50672, 50672, 309, 13, 50724, 50724, 400, 1936, 291, 2845, 294, 300, 1729, 3256, 934, 9275, 257, 12447, 293, 291, 1029, 50982, 50982, 264, 3209, 281, 6069, 437, 390, 264, 1900, 12447, 6456, 281, 264, 3256, 13, 51185, 51185, 400, 309, 445, 39890, 257, 1451, 636, 21538, 1154, 13, 51340, 51340, 407, 309, 6069, 82, 1936, 2139, 498, 264, 12447, 307, 1958, 11, 4289, 11, 11971, 11, 420, 40774, 13, 51684, 51684], "temperature": 0.0, "avg_logprob": -0.12967954797947662, "compression_ratio": 1.7735849056603774, "no_speech_prob": 6.962065072002588e-06}, {"id": 267, "seek": 109348, "start": 1105.84, "end": 1109.9, "text": " the network to predict what was the exact rotation applied to the image.", "tokens": [50364, 509, 393, 2139, 3079, 257, 12447, 295, 1958, 5310, 11, 4289, 5310, 11, 11971, 5310, 11, 420, 40774, 5310, 281, 50672, 50672, 309, 13, 50724, 50724, 400, 1936, 291, 2845, 294, 300, 1729, 3256, 934, 9275, 257, 12447, 293, 291, 1029, 50982, 50982, 264, 3209, 281, 6069, 437, 390, 264, 1900, 12447, 6456, 281, 264, 3256, 13, 51185, 51185, 400, 309, 445, 39890, 257, 1451, 636, 21538, 1154, 13, 51340, 51340, 407, 309, 6069, 82, 1936, 2139, 498, 264, 12447, 307, 1958, 11, 4289, 11, 11971, 11, 420, 40774, 13, 51684, 51684], "temperature": 0.0, "avg_logprob": -0.12967954797947662, "compression_ratio": 1.7735849056603774, "no_speech_prob": 6.962065072002588e-06}, {"id": 268, "seek": 109348, "start": 1109.9, "end": 1113.0, "text": " And it just solves a four way classification problem.", "tokens": [50364, 509, 393, 2139, 3079, 257, 12447, 295, 1958, 5310, 11, 4289, 5310, 11, 11971, 5310, 11, 420, 40774, 5310, 281, 50672, 50672, 309, 13, 50724, 50724, 400, 1936, 291, 2845, 294, 300, 1729, 3256, 934, 9275, 257, 12447, 293, 291, 1029, 50982, 50982, 264, 3209, 281, 6069, 437, 390, 264, 1900, 12447, 6456, 281, 264, 3256, 13, 51185, 51185, 400, 309, 445, 39890, 257, 1451, 636, 21538, 1154, 13, 51340, 51340, 407, 309, 6069, 82, 1936, 2139, 498, 264, 12447, 307, 1958, 11, 4289, 11, 11971, 11, 420, 40774, 13, 51684, 51684], "temperature": 0.0, "avg_logprob": -0.12967954797947662, "compression_ratio": 1.7735849056603774, "no_speech_prob": 6.962065072002588e-06}, {"id": 269, "seek": 109348, "start": 1113.0, "end": 1119.88, "text": " So it predicts basically either if the rotation is 0, 90, 180, or 270.", "tokens": [50364, 509, 393, 2139, 3079, 257, 12447, 295, 1958, 5310, 11, 4289, 5310, 11, 11971, 5310, 11, 420, 40774, 5310, 281, 50672, 50672, 309, 13, 50724, 50724, 400, 1936, 291, 2845, 294, 300, 1729, 3256, 934, 9275, 257, 12447, 293, 291, 1029, 50982, 50982, 264, 3209, 281, 6069, 437, 390, 264, 1900, 12447, 6456, 281, 264, 3256, 13, 51185, 51185, 400, 309, 445, 39890, 257, 1451, 636, 21538, 1154, 13, 51340, 51340, 407, 309, 6069, 82, 1936, 2139, 498, 264, 12447, 307, 1958, 11, 4289, 11, 11971, 11, 420, 40774, 13, 51684, 51684], "temperature": 0.0, "avg_logprob": -0.12967954797947662, "compression_ratio": 1.7735849056603774, "no_speech_prob": 6.962065072002588e-06}, {"id": 270, "seek": 111988, "start": 1119.88, "end": 1125.2, "text": " And this pretext task is actually one of the most popular pretext tasks now because it's", "tokens": [50364, 400, 341, 659, 25111, 5633, 307, 767, 472, 295, 264, 881, 3743, 659, 25111, 9608, 586, 570, 309, 311, 50630, 50630, 370, 1858, 281, 4445, 13, 50706, 50706, 509, 1936, 445, 747, 364, 3256, 13, 50802, 50802, 467, 311, 588, 11, 588, 2199, 13, 50902, 50902, 509, 500, 380, 534, 643, 281, 6889, 886, 867, 26531, 420, 5039, 604, 1333, 295, 6179, 551, 13, 51110, 51110, 467, 311, 257, 588, 3832, 9482, 293, 291, 393, 5039, 341, 13, 51244, 51244, 400, 309, 311, 1813, 6457, 3743, 586, 13, 51370, 51370, 407, 264, 3209, 307, 516, 281, 312, 1936, 8895, 13, 51475, 51475, 407, 264, 4111, 366, 8895, 294, 1668, 281, 5039, 341, 1154, 11, 558, 30, 51604, 51604], "temperature": 0.0, "avg_logprob": -0.10327707131703695, "compression_ratio": 1.7388059701492538, "no_speech_prob": 2.4680621208972298e-05}, {"id": 271, "seek": 111988, "start": 1125.2, "end": 1126.72, "text": " so easy to implement.", "tokens": [50364, 400, 341, 659, 25111, 5633, 307, 767, 472, 295, 264, 881, 3743, 659, 25111, 9608, 586, 570, 309, 311, 50630, 50630, 370, 1858, 281, 4445, 13, 50706, 50706, 509, 1936, 445, 747, 364, 3256, 13, 50802, 50802, 467, 311, 588, 11, 588, 2199, 13, 50902, 50902, 509, 500, 380, 534, 643, 281, 6889, 886, 867, 26531, 420, 5039, 604, 1333, 295, 6179, 551, 13, 51110, 51110, 467, 311, 257, 588, 3832, 9482, 293, 291, 393, 5039, 341, 13, 51244, 51244, 400, 309, 311, 1813, 6457, 3743, 586, 13, 51370, 51370, 407, 264, 3209, 307, 516, 281, 312, 1936, 8895, 13, 51475, 51475, 407, 264, 4111, 366, 8895, 294, 1668, 281, 5039, 341, 1154, 11, 558, 30, 51604, 51604], "temperature": 0.0, "avg_logprob": -0.10327707131703695, "compression_ratio": 1.7388059701492538, "no_speech_prob": 2.4680621208972298e-05}, {"id": 272, "seek": 111988, "start": 1126.72, "end": 1128.64, "text": " You basically just take an image.", "tokens": [50364, 400, 341, 659, 25111, 5633, 307, 767, 472, 295, 264, 881, 3743, 659, 25111, 9608, 586, 570, 309, 311, 50630, 50630, 370, 1858, 281, 4445, 13, 50706, 50706, 509, 1936, 445, 747, 364, 3256, 13, 50802, 50802, 467, 311, 588, 11, 588, 2199, 13, 50902, 50902, 509, 500, 380, 534, 643, 281, 6889, 886, 867, 26531, 420, 5039, 604, 1333, 295, 6179, 551, 13, 51110, 51110, 467, 311, 257, 588, 3832, 9482, 293, 291, 393, 5039, 341, 13, 51244, 51244, 400, 309, 311, 1813, 6457, 3743, 586, 13, 51370, 51370, 407, 264, 3209, 307, 516, 281, 312, 1936, 8895, 13, 51475, 51475, 407, 264, 4111, 366, 8895, 294, 1668, 281, 5039, 341, 1154, 11, 558, 30, 51604, 51604], "temperature": 0.0, "avg_logprob": -0.10327707131703695, "compression_ratio": 1.7388059701492538, "no_speech_prob": 2.4680621208972298e-05}, {"id": 273, "seek": 111988, "start": 1128.64, "end": 1130.64, "text": " It's very, very simple.", "tokens": [50364, 400, 341, 659, 25111, 5633, 307, 767, 472, 295, 264, 881, 3743, 659, 25111, 9608, 586, 570, 309, 311, 50630, 50630, 370, 1858, 281, 4445, 13, 50706, 50706, 509, 1936, 445, 747, 364, 3256, 13, 50802, 50802, 467, 311, 588, 11, 588, 2199, 13, 50902, 50902, 509, 500, 380, 534, 643, 281, 6889, 886, 867, 26531, 420, 5039, 604, 1333, 295, 6179, 551, 13, 51110, 51110, 467, 311, 257, 588, 3832, 9482, 293, 291, 393, 5039, 341, 13, 51244, 51244, 400, 309, 311, 1813, 6457, 3743, 586, 13, 51370, 51370, 407, 264, 3209, 307, 516, 281, 312, 1936, 8895, 13, 51475, 51475, 407, 264, 4111, 366, 8895, 294, 1668, 281, 5039, 341, 1154, 11, 558, 30, 51604, 51604], "temperature": 0.0, "avg_logprob": -0.10327707131703695, "compression_ratio": 1.7388059701492538, "no_speech_prob": 2.4680621208972298e-05}, {"id": 274, "seek": 111988, "start": 1130.64, "end": 1134.8000000000002, "text": " You don't really need to sample too many patches or solve any sort of complicated thing.", "tokens": [50364, 400, 341, 659, 25111, 5633, 307, 767, 472, 295, 264, 881, 3743, 659, 25111, 9608, 586, 570, 309, 311, 50630, 50630, 370, 1858, 281, 4445, 13, 50706, 50706, 509, 1936, 445, 747, 364, 3256, 13, 50802, 50802, 467, 311, 588, 11, 588, 2199, 13, 50902, 50902, 509, 500, 380, 534, 643, 281, 6889, 886, 867, 26531, 420, 5039, 604, 1333, 295, 6179, 551, 13, 51110, 51110, 467, 311, 257, 588, 3832, 9482, 293, 291, 393, 5039, 341, 13, 51244, 51244, 400, 309, 311, 1813, 6457, 3743, 586, 13, 51370, 51370, 407, 264, 3209, 307, 516, 281, 312, 1936, 8895, 13, 51475, 51475, 407, 264, 4111, 366, 8895, 294, 1668, 281, 5039, 341, 1154, 11, 558, 30, 51604, 51604], "temperature": 0.0, "avg_logprob": -0.10327707131703695, "compression_ratio": 1.7388059701492538, "no_speech_prob": 2.4680621208972298e-05}, {"id": 275, "seek": 111988, "start": 1134.8000000000002, "end": 1137.48, "text": " It's a very standard architecture and you can solve this.", "tokens": [50364, 400, 341, 659, 25111, 5633, 307, 767, 472, 295, 264, 881, 3743, 659, 25111, 9608, 586, 570, 309, 311, 50630, 50630, 370, 1858, 281, 4445, 13, 50706, 50706, 509, 1936, 445, 747, 364, 3256, 13, 50802, 50802, 467, 311, 588, 11, 588, 2199, 13, 50902, 50902, 509, 500, 380, 534, 643, 281, 6889, 886, 867, 26531, 420, 5039, 604, 1333, 295, 6179, 551, 13, 51110, 51110, 467, 311, 257, 588, 3832, 9482, 293, 291, 393, 5039, 341, 13, 51244, 51244, 400, 309, 311, 1813, 6457, 3743, 586, 13, 51370, 51370, 407, 264, 3209, 307, 516, 281, 312, 1936, 8895, 13, 51475, 51475, 407, 264, 4111, 366, 8895, 294, 1668, 281, 5039, 341, 1154, 11, 558, 30, 51604, 51604], "temperature": 0.0, "avg_logprob": -0.10327707131703695, "compression_ratio": 1.7388059701492538, "no_speech_prob": 2.4680621208972298e-05}, {"id": 276, "seek": 111988, "start": 1137.48, "end": 1140.0, "text": " And it's become fairly popular now.", "tokens": [50364, 400, 341, 659, 25111, 5633, 307, 767, 472, 295, 264, 881, 3743, 659, 25111, 9608, 586, 570, 309, 311, 50630, 50630, 370, 1858, 281, 4445, 13, 50706, 50706, 509, 1936, 445, 747, 364, 3256, 13, 50802, 50802, 467, 311, 588, 11, 588, 2199, 13, 50902, 50902, 509, 500, 380, 534, 643, 281, 6889, 886, 867, 26531, 420, 5039, 604, 1333, 295, 6179, 551, 13, 51110, 51110, 467, 311, 257, 588, 3832, 9482, 293, 291, 393, 5039, 341, 13, 51244, 51244, 400, 309, 311, 1813, 6457, 3743, 586, 13, 51370, 51370, 407, 264, 3209, 307, 516, 281, 312, 1936, 8895, 13, 51475, 51475, 407, 264, 4111, 366, 8895, 294, 1668, 281, 5039, 341, 1154, 11, 558, 30, 51604, 51604], "temperature": 0.0, "avg_logprob": -0.10327707131703695, "compression_ratio": 1.7388059701492538, "no_speech_prob": 2.4680621208972298e-05}, {"id": 277, "seek": 111988, "start": 1140.0, "end": 1142.1000000000001, "text": " So the network is going to be basically trained.", "tokens": [50364, 400, 341, 659, 25111, 5633, 307, 767, 472, 295, 264, 881, 3743, 659, 25111, 9608, 586, 570, 309, 311, 50630, 50630, 370, 1858, 281, 4445, 13, 50706, 50706, 509, 1936, 445, 747, 364, 3256, 13, 50802, 50802, 467, 311, 588, 11, 588, 2199, 13, 50902, 50902, 509, 500, 380, 534, 643, 281, 6889, 886, 867, 26531, 420, 5039, 604, 1333, 295, 6179, 551, 13, 51110, 51110, 467, 311, 257, 588, 3832, 9482, 293, 291, 393, 5039, 341, 13, 51244, 51244, 400, 309, 311, 1813, 6457, 3743, 586, 13, 51370, 51370, 407, 264, 3209, 307, 516, 281, 312, 1936, 8895, 13, 51475, 51475, 407, 264, 4111, 366, 8895, 294, 1668, 281, 5039, 341, 1154, 11, 558, 30, 51604, 51604], "temperature": 0.0, "avg_logprob": -0.10327707131703695, "compression_ratio": 1.7388059701492538, "no_speech_prob": 2.4680621208972298e-05}, {"id": 278, "seek": 111988, "start": 1142.1000000000001, "end": 1144.68, "text": " So the feature are trained in order to solve this problem, right?", "tokens": [50364, 400, 341, 659, 25111, 5633, 307, 767, 472, 295, 264, 881, 3743, 659, 25111, 9608, 586, 570, 309, 311, 50630, 50630, 370, 1858, 281, 4445, 13, 50706, 50706, 509, 1936, 445, 747, 364, 3256, 13, 50802, 50802, 467, 311, 588, 11, 588, 2199, 13, 50902, 50902, 509, 500, 380, 534, 643, 281, 6889, 886, 867, 26531, 420, 5039, 604, 1333, 295, 6179, 551, 13, 51110, 51110, 467, 311, 257, 588, 3832, 9482, 293, 291, 393, 5039, 341, 13, 51244, 51244, 400, 309, 311, 1813, 6457, 3743, 586, 13, 51370, 51370, 407, 264, 3209, 307, 516, 281, 312, 1936, 8895, 13, 51475, 51475, 407, 264, 4111, 366, 8895, 294, 1668, 281, 5039, 341, 1154, 11, 558, 30, 51604, 51604], "temperature": 0.0, "avg_logprob": -0.10327707131703695, "compression_ratio": 1.7388059701492538, "no_speech_prob": 2.4680621208972298e-05}, {"id": 279, "seek": 114468, "start": 1144.68, "end": 1151.2, "text": " So the output will be somehow dependent on the specific task someone is going to be picking", "tokens": [50364, 407, 264, 5598, 486, 312, 6063, 12334, 322, 264, 2685, 5633, 1580, 307, 516, 281, 312, 8867, 50690, 50690, 6063, 11, 558, 30, 50750, 50750, 1079, 13, 50800, 50800, 407, 341, 307, 11, 797, 11, 341, 307, 257, 659, 25111, 5633, 13, 50909, 50909, 407, 321, 366, 406, 534, 3102, 294, 32884, 264, 44796, 295, 364, 3256, 13, 51076, 51076, 492, 366, 445, 1228, 341, 5633, 382, 257, 29690, 281, 1466, 512, 4122, 370, 300, 322, 264, 30621, 51316, 51316, 5633, 11, 584, 562, 1580, 2709, 505, 257, 4714, 21335, 5267, 295, 257, 3857, 11, 321, 393, 550, 764, 341, 51544, 51544, 659, 12, 17227, 2001, 4111, 10290, 281, 360, 300, 1729, 5633, 13, 51748, 51748], "temperature": 0.0, "avg_logprob": -0.16505238161248675, "compression_ratio": 1.7397769516728625, "no_speech_prob": 6.047790975571843e-06}, {"id": 280, "seek": 114468, "start": 1151.2, "end": 1152.4, "text": " somehow, right?", "tokens": [50364, 407, 264, 5598, 486, 312, 6063, 12334, 322, 264, 2685, 5633, 1580, 307, 516, 281, 312, 8867, 50690, 50690, 6063, 11, 558, 30, 50750, 50750, 1079, 13, 50800, 50800, 407, 341, 307, 11, 797, 11, 341, 307, 257, 659, 25111, 5633, 13, 50909, 50909, 407, 321, 366, 406, 534, 3102, 294, 32884, 264, 44796, 295, 364, 3256, 13, 51076, 51076, 492, 366, 445, 1228, 341, 5633, 382, 257, 29690, 281, 1466, 512, 4122, 370, 300, 322, 264, 30621, 51316, 51316, 5633, 11, 584, 562, 1580, 2709, 505, 257, 4714, 21335, 5267, 295, 257, 3857, 11, 321, 393, 550, 764, 341, 51544, 51544, 659, 12, 17227, 2001, 4111, 10290, 281, 360, 300, 1729, 5633, 13, 51748, 51748], "temperature": 0.0, "avg_logprob": -0.16505238161248675, "compression_ratio": 1.7397769516728625, "no_speech_prob": 6.047790975571843e-06}, {"id": 281, "seek": 114468, "start": 1152.4, "end": 1153.4, "text": " Yes.", "tokens": [50364, 407, 264, 5598, 486, 312, 6063, 12334, 322, 264, 2685, 5633, 1580, 307, 516, 281, 312, 8867, 50690, 50690, 6063, 11, 558, 30, 50750, 50750, 1079, 13, 50800, 50800, 407, 341, 307, 11, 797, 11, 341, 307, 257, 659, 25111, 5633, 13, 50909, 50909, 407, 321, 366, 406, 534, 3102, 294, 32884, 264, 44796, 295, 364, 3256, 13, 51076, 51076, 492, 366, 445, 1228, 341, 5633, 382, 257, 29690, 281, 1466, 512, 4122, 370, 300, 322, 264, 30621, 51316, 51316, 5633, 11, 584, 562, 1580, 2709, 505, 257, 4714, 21335, 5267, 295, 257, 3857, 11, 321, 393, 550, 764, 341, 51544, 51544, 659, 12, 17227, 2001, 4111, 10290, 281, 360, 300, 1729, 5633, 13, 51748, 51748], "temperature": 0.0, "avg_logprob": -0.16505238161248675, "compression_ratio": 1.7397769516728625, "no_speech_prob": 6.047790975571843e-06}, {"id": 282, "seek": 114468, "start": 1153.4, "end": 1155.5800000000002, "text": " So this is, again, this is a pretext task.", "tokens": [50364, 407, 264, 5598, 486, 312, 6063, 12334, 322, 264, 2685, 5633, 1580, 307, 516, 281, 312, 8867, 50690, 50690, 6063, 11, 558, 30, 50750, 50750, 1079, 13, 50800, 50800, 407, 341, 307, 11, 797, 11, 341, 307, 257, 659, 25111, 5633, 13, 50909, 50909, 407, 321, 366, 406, 534, 3102, 294, 32884, 264, 44796, 295, 364, 3256, 13, 51076, 51076, 492, 366, 445, 1228, 341, 5633, 382, 257, 29690, 281, 1466, 512, 4122, 370, 300, 322, 264, 30621, 51316, 51316, 5633, 11, 584, 562, 1580, 2709, 505, 257, 4714, 21335, 5267, 295, 257, 3857, 11, 321, 393, 550, 764, 341, 51544, 51544, 659, 12, 17227, 2001, 4111, 10290, 281, 360, 300, 1729, 5633, 13, 51748, 51748], "temperature": 0.0, "avg_logprob": -0.16505238161248675, "compression_ratio": 1.7397769516728625, "no_speech_prob": 6.047790975571843e-06}, {"id": 283, "seek": 114468, "start": 1155.5800000000002, "end": 1158.92, "text": " So we are not really interested in predicting the rotations of an image.", "tokens": [50364, 407, 264, 5598, 486, 312, 6063, 12334, 322, 264, 2685, 5633, 1580, 307, 516, 281, 312, 8867, 50690, 50690, 6063, 11, 558, 30, 50750, 50750, 1079, 13, 50800, 50800, 407, 341, 307, 11, 797, 11, 341, 307, 257, 659, 25111, 5633, 13, 50909, 50909, 407, 321, 366, 406, 534, 3102, 294, 32884, 264, 44796, 295, 364, 3256, 13, 51076, 51076, 492, 366, 445, 1228, 341, 5633, 382, 257, 29690, 281, 1466, 512, 4122, 370, 300, 322, 264, 30621, 51316, 51316, 5633, 11, 584, 562, 1580, 2709, 505, 257, 4714, 21335, 5267, 295, 257, 3857, 11, 321, 393, 550, 764, 341, 51544, 51544, 659, 12, 17227, 2001, 4111, 10290, 281, 360, 300, 1729, 5633, 13, 51748, 51748], "temperature": 0.0, "avg_logprob": -0.16505238161248675, "compression_ratio": 1.7397769516728625, "no_speech_prob": 6.047790975571843e-06}, {"id": 284, "seek": 114468, "start": 1158.92, "end": 1163.72, "text": " We are just using this task as a proxy to learn some features so that on the downstream", "tokens": [50364, 407, 264, 5598, 486, 312, 6063, 12334, 322, 264, 2685, 5633, 1580, 307, 516, 281, 312, 8867, 50690, 50690, 6063, 11, 558, 30, 50750, 50750, 1079, 13, 50800, 50800, 407, 341, 307, 11, 797, 11, 341, 307, 257, 659, 25111, 5633, 13, 50909, 50909, 407, 321, 366, 406, 534, 3102, 294, 32884, 264, 44796, 295, 364, 3256, 13, 51076, 51076, 492, 366, 445, 1228, 341, 5633, 382, 257, 29690, 281, 1466, 512, 4122, 370, 300, 322, 264, 30621, 51316, 51316, 5633, 11, 584, 562, 1580, 2709, 505, 257, 4714, 21335, 5267, 295, 257, 3857, 11, 321, 393, 550, 764, 341, 51544, 51544, 659, 12, 17227, 2001, 4111, 10290, 281, 360, 300, 1729, 5633, 13, 51748, 51748], "temperature": 0.0, "avg_logprob": -0.16505238161248675, "compression_ratio": 1.7397769516728625, "no_speech_prob": 6.047790975571843e-06}, {"id": 285, "seek": 114468, "start": 1163.72, "end": 1168.28, "text": " task, say when someone gives us a thousand labeled images of a cat, we can then use this", "tokens": [50364, 407, 264, 5598, 486, 312, 6063, 12334, 322, 264, 2685, 5633, 1580, 307, 516, 281, 312, 8867, 50690, 50690, 6063, 11, 558, 30, 50750, 50750, 1079, 13, 50800, 50800, 407, 341, 307, 11, 797, 11, 341, 307, 257, 659, 25111, 5633, 13, 50909, 50909, 407, 321, 366, 406, 534, 3102, 294, 32884, 264, 44796, 295, 364, 3256, 13, 51076, 51076, 492, 366, 445, 1228, 341, 5633, 382, 257, 29690, 281, 1466, 512, 4122, 370, 300, 322, 264, 30621, 51316, 51316, 5633, 11, 584, 562, 1580, 2709, 505, 257, 4714, 21335, 5267, 295, 257, 3857, 11, 321, 393, 550, 764, 341, 51544, 51544, 659, 12, 17227, 2001, 4111, 10290, 281, 360, 300, 1729, 5633, 13, 51748, 51748], "temperature": 0.0, "avg_logprob": -0.16505238161248675, "compression_ratio": 1.7397769516728625, "no_speech_prob": 6.047790975571843e-06}, {"id": 286, "seek": 114468, "start": 1168.28, "end": 1172.3600000000001, "text": " pre-trained feature representation to do that particular task.", "tokens": [50364, 407, 264, 5598, 486, 312, 6063, 12334, 322, 264, 2685, 5633, 1580, 307, 516, 281, 312, 8867, 50690, 50690, 6063, 11, 558, 30, 50750, 50750, 1079, 13, 50800, 50800, 407, 341, 307, 11, 797, 11, 341, 307, 257, 659, 25111, 5633, 13, 50909, 50909, 407, 321, 366, 406, 534, 3102, 294, 32884, 264, 44796, 295, 364, 3256, 13, 51076, 51076, 492, 366, 445, 1228, 341, 5633, 382, 257, 29690, 281, 1466, 512, 4122, 370, 300, 322, 264, 30621, 51316, 51316, 5633, 11, 584, 562, 1580, 2709, 505, 257, 4714, 21335, 5267, 295, 257, 3857, 11, 321, 393, 550, 764, 341, 51544, 51544, 659, 12, 17227, 2001, 4111, 10290, 281, 360, 300, 1729, 5633, 13, 51748, 51748], "temperature": 0.0, "avg_logprob": -0.16505238161248675, "compression_ratio": 1.7397769516728625, "no_speech_prob": 6.047790975571843e-06}, {"id": 287, "seek": 117236, "start": 1172.36, "end": 1176.56, "text": " So these pretext tasks are often really not going to make a lot of semantic sense.", "tokens": [50364, 407, 613, 659, 25111, 9608, 366, 2049, 534, 406, 516, 281, 652, 257, 688, 295, 47982, 2020, 13, 50574, 50574, 400, 300, 311, 1333, 295, 264, 1778, 337, 5141, 552, 659, 25111, 570, 291, 362, 257, 30621, 50846, 50846, 5633, 689, 291, 767, 362, 512, 47982, 420, 512, 7645, 300, 291, 767, 458, 307, 665, 13, 51098, 51098, 865, 11, 3231, 13, 51258, 51258, 1545, 576, 264, 32884, 44796, 976, 505, 604, 1333, 295, 4420, 33358, 30, 51564, 51564, 1079, 13, 51614, 51614], "temperature": 0.0, "avg_logprob": -0.21497333751005285, "compression_ratio": 1.6388888888888888, "no_speech_prob": 2.5866362193482928e-05}, {"id": 288, "seek": 117236, "start": 1176.56, "end": 1182.0, "text": " And that's sort of the reason for calling them pretext because you have a downstream", "tokens": [50364, 407, 613, 659, 25111, 9608, 366, 2049, 534, 406, 516, 281, 652, 257, 688, 295, 47982, 2020, 13, 50574, 50574, 400, 300, 311, 1333, 295, 264, 1778, 337, 5141, 552, 659, 25111, 570, 291, 362, 257, 30621, 50846, 50846, 5633, 689, 291, 767, 362, 512, 47982, 420, 512, 7645, 300, 291, 767, 458, 307, 665, 13, 51098, 51098, 865, 11, 3231, 13, 51258, 51258, 1545, 576, 264, 32884, 44796, 976, 505, 604, 1333, 295, 4420, 33358, 30, 51564, 51564, 1079, 13, 51614, 51614], "temperature": 0.0, "avg_logprob": -0.21497333751005285, "compression_ratio": 1.6388888888888888, "no_speech_prob": 2.5866362193482928e-05}, {"id": 289, "seek": 117236, "start": 1182.0, "end": 1187.04, "text": " task where you actually have some semantic or some label that you actually know is good.", "tokens": [50364, 407, 613, 659, 25111, 9608, 366, 2049, 534, 406, 516, 281, 652, 257, 688, 295, 47982, 2020, 13, 50574, 50574, 400, 300, 311, 1333, 295, 264, 1778, 337, 5141, 552, 659, 25111, 570, 291, 362, 257, 30621, 50846, 50846, 5633, 689, 291, 767, 362, 512, 47982, 420, 512, 7645, 300, 291, 767, 458, 307, 665, 13, 51098, 51098, 865, 11, 3231, 13, 51258, 51258, 1545, 576, 264, 32884, 44796, 976, 505, 604, 1333, 295, 4420, 33358, 30, 51564, 51564, 1079, 13, 51614, 51614], "temperature": 0.0, "avg_logprob": -0.21497333751005285, "compression_ratio": 1.6388888888888888, "no_speech_prob": 2.5866362193482928e-05}, {"id": 290, "seek": 117236, "start": 1187.04, "end": 1190.24, "text": " Yeah, thanks.", "tokens": [50364, 407, 613, 659, 25111, 9608, 366, 2049, 534, 406, 516, 281, 652, 257, 688, 295, 47982, 2020, 13, 50574, 50574, 400, 300, 311, 1333, 295, 264, 1778, 337, 5141, 552, 659, 25111, 570, 291, 362, 257, 30621, 50846, 50846, 5633, 689, 291, 767, 362, 512, 47982, 420, 512, 7645, 300, 291, 767, 458, 307, 665, 13, 51098, 51098, 865, 11, 3231, 13, 51258, 51258, 1545, 576, 264, 32884, 44796, 976, 505, 604, 1333, 295, 4420, 33358, 30, 51564, 51564, 1079, 13, 51614, 51614], "temperature": 0.0, "avg_logprob": -0.21497333751005285, "compression_ratio": 1.6388888888888888, "no_speech_prob": 2.5866362193482928e-05}, {"id": 291, "seek": 117236, "start": 1190.24, "end": 1196.36, "text": " Why would the predicting rotations give us any sort of useful representations?", "tokens": [50364, 407, 613, 659, 25111, 9608, 366, 2049, 534, 406, 516, 281, 652, 257, 688, 295, 47982, 2020, 13, 50574, 50574, 400, 300, 311, 1333, 295, 264, 1778, 337, 5141, 552, 659, 25111, 570, 291, 362, 257, 30621, 50846, 50846, 5633, 689, 291, 767, 362, 512, 47982, 420, 512, 7645, 300, 291, 767, 458, 307, 665, 13, 51098, 51098, 865, 11, 3231, 13, 51258, 51258, 1545, 576, 264, 32884, 44796, 976, 505, 604, 1333, 295, 4420, 33358, 30, 51564, 51564, 1079, 13, 51614, 51614], "temperature": 0.0, "avg_logprob": -0.21497333751005285, "compression_ratio": 1.6388888888888888, "no_speech_prob": 2.5866362193482928e-05}, {"id": 292, "seek": 117236, "start": 1196.36, "end": 1197.36, "text": " Yes.", "tokens": [50364, 407, 613, 659, 25111, 9608, 366, 2049, 534, 406, 516, 281, 652, 257, 688, 295, 47982, 2020, 13, 50574, 50574, 400, 300, 311, 1333, 295, 264, 1778, 337, 5141, 552, 659, 25111, 570, 291, 362, 257, 30621, 50846, 50846, 5633, 689, 291, 767, 362, 512, 47982, 420, 512, 7645, 300, 291, 767, 458, 307, 665, 13, 51098, 51098, 865, 11, 3231, 13, 51258, 51258, 1545, 576, 264, 32884, 44796, 976, 505, 604, 1333, 295, 4420, 33358, 30, 51564, 51564, 1079, 13, 51614, 51614], "temperature": 0.0, "avg_logprob": -0.21497333751005285, "compression_ratio": 1.6388888888888888, "no_speech_prob": 2.5866362193482928e-05}, {"id": 293, "seek": 119736, "start": 1197.36, "end": 1202.7199999999998, "text": " So in fact, when this paper came out, this was the question of many, many people.", "tokens": [50364, 407, 294, 1186, 11, 562, 341, 3035, 1361, 484, 11, 341, 390, 264, 1168, 295, 867, 11, 867, 561, 13, 50632, 50632, 400, 309, 390, 452, 1168, 382, 731, 13, 50770, 50770, 18360, 19020, 11, 341, 767, 1985, 534, 731, 13, 50972, 50972, 400, 1333, 295, 452, 24002, 337, 341, 575, 1936, 668, 300, 294, 1668, 281, 6069, 437, 1333, 295, 51250, 51250, 264, 12447, 295, 364, 2657, 307, 11, 309, 2203, 281, 9810, 1223, 437, 264, 13180, 366, 11, 51472, 51472, 437, 1333, 295, 512, 10392, 294, 341, 3256, 366, 13, 51622, 51622], "temperature": 0.0, "avg_logprob": -0.16716480255126953, "compression_ratio": 1.6946902654867257, "no_speech_prob": 4.468994666240178e-05}, {"id": 294, "seek": 119736, "start": 1202.7199999999998, "end": 1205.4799999999998, "text": " And it was my question as well.", "tokens": [50364, 407, 294, 1186, 11, 562, 341, 3035, 1361, 484, 11, 341, 390, 264, 1168, 295, 867, 11, 867, 561, 13, 50632, 50632, 400, 309, 390, 452, 1168, 382, 731, 13, 50770, 50770, 18360, 19020, 11, 341, 767, 1985, 534, 731, 13, 50972, 50972, 400, 1333, 295, 452, 24002, 337, 341, 575, 1936, 668, 300, 294, 1668, 281, 6069, 437, 1333, 295, 51250, 51250, 264, 12447, 295, 364, 2657, 307, 11, 309, 2203, 281, 9810, 1223, 437, 264, 13180, 366, 11, 51472, 51472, 437, 1333, 295, 512, 10392, 294, 341, 3256, 366, 13, 51622, 51622], "temperature": 0.0, "avg_logprob": -0.16716480255126953, "compression_ratio": 1.6946902654867257, "no_speech_prob": 4.468994666240178e-05}, {"id": 295, "seek": 119736, "start": 1205.4799999999998, "end": 1209.52, "text": " Imperatively, this actually works really well.", "tokens": [50364, 407, 294, 1186, 11, 562, 341, 3035, 1361, 484, 11, 341, 390, 264, 1168, 295, 867, 11, 867, 561, 13, 50632, 50632, 400, 309, 390, 452, 1168, 382, 731, 13, 50770, 50770, 18360, 19020, 11, 341, 767, 1985, 534, 731, 13, 50972, 50972, 400, 1333, 295, 452, 24002, 337, 341, 575, 1936, 668, 300, 294, 1668, 281, 6069, 437, 1333, 295, 51250, 51250, 264, 12447, 295, 364, 2657, 307, 11, 309, 2203, 281, 9810, 1223, 437, 264, 13180, 366, 11, 51472, 51472, 437, 1333, 295, 512, 10392, 294, 341, 3256, 366, 13, 51622, 51622], "temperature": 0.0, "avg_logprob": -0.16716480255126953, "compression_ratio": 1.6946902654867257, "no_speech_prob": 4.468994666240178e-05}, {"id": 296, "seek": 119736, "start": 1209.52, "end": 1215.08, "text": " And sort of my intuition for this has basically been that in order to predict what sort of", "tokens": [50364, 407, 294, 1186, 11, 562, 341, 3035, 1361, 484, 11, 341, 390, 264, 1168, 295, 867, 11, 867, 561, 13, 50632, 50632, 400, 309, 390, 452, 1168, 382, 731, 13, 50770, 50770, 18360, 19020, 11, 341, 767, 1985, 534, 731, 13, 50972, 50972, 400, 1333, 295, 452, 24002, 337, 341, 575, 1936, 668, 300, 294, 1668, 281, 6069, 437, 1333, 295, 51250, 51250, 264, 12447, 295, 364, 2657, 307, 11, 309, 2203, 281, 9810, 1223, 437, 264, 13180, 366, 11, 51472, 51472, 437, 1333, 295, 512, 10392, 294, 341, 3256, 366, 13, 51622, 51622], "temperature": 0.0, "avg_logprob": -0.16716480255126953, "compression_ratio": 1.6946902654867257, "no_speech_prob": 4.468994666240178e-05}, {"id": 297, "seek": 119736, "start": 1215.08, "end": 1219.52, "text": " the rotation of an object is, it needs to roughly understand what the boundaries are,", "tokens": [50364, 407, 294, 1186, 11, 562, 341, 3035, 1361, 484, 11, 341, 390, 264, 1168, 295, 867, 11, 867, 561, 13, 50632, 50632, 400, 309, 390, 452, 1168, 382, 731, 13, 50770, 50770, 18360, 19020, 11, 341, 767, 1985, 534, 731, 13, 50972, 50972, 400, 1333, 295, 452, 24002, 337, 341, 575, 1936, 668, 300, 294, 1668, 281, 6069, 437, 1333, 295, 51250, 51250, 264, 12447, 295, 364, 2657, 307, 11, 309, 2203, 281, 9810, 1223, 437, 264, 13180, 366, 11, 51472, 51472, 437, 1333, 295, 512, 10392, 294, 341, 3256, 366, 13, 51622, 51622], "temperature": 0.0, "avg_logprob": -0.16716480255126953, "compression_ratio": 1.6946902654867257, "no_speech_prob": 4.468994666240178e-05}, {"id": 298, "seek": 119736, "start": 1219.52, "end": 1222.52, "text": " what sort of some concepts in this image are.", "tokens": [50364, 407, 294, 1186, 11, 562, 341, 3035, 1361, 484, 11, 341, 390, 264, 1168, 295, 867, 11, 867, 561, 13, 50632, 50632, 400, 309, 390, 452, 1168, 382, 731, 13, 50770, 50770, 18360, 19020, 11, 341, 767, 1985, 534, 731, 13, 50972, 50972, 400, 1333, 295, 452, 24002, 337, 341, 575, 1936, 668, 300, 294, 1668, 281, 6069, 437, 1333, 295, 51250, 51250, 264, 12447, 295, 364, 2657, 307, 11, 309, 2203, 281, 9810, 1223, 437, 264, 13180, 366, 11, 51472, 51472, 437, 1333, 295, 512, 10392, 294, 341, 3256, 366, 13, 51622, 51622], "temperature": 0.0, "avg_logprob": -0.16716480255126953, "compression_ratio": 1.6946902654867257, "no_speech_prob": 4.468994666240178e-05}, {"id": 299, "seek": 122252, "start": 1222.52, "end": 1228.04, "text": " For example, to predict that this particular image is rotated by 180 degrees, it needs", "tokens": [50364, 1171, 1365, 11, 281, 6069, 300, 341, 1729, 3256, 307, 42146, 538, 11971, 5310, 11, 309, 2203, 50640, 50640, 281, 412, 1935, 5521, 420, 1333, 295, 37630, 473, 264, 5443, 490, 264, 4932, 420, 264, 5443, 490, 264, 50938, 50938, 1281, 420, 412, 1935, 1223, 300, 337, 257, 4230, 11, 264, 5510, 366, 5101, 406, 2507, 264, 2159, 13, 51288, 51288, 314, 4856, 500, 380, 1852, 39880, 11, 436, 1852, 22167, 13, 51478, 51478, 407, 309, 1333, 295, 2203, 281, 1778, 466, 512, 721, 26947, 356, 13, 51670, 51670], "temperature": 0.0, "avg_logprob": -0.16286587977147365, "compression_ratio": 1.6428571428571428, "no_speech_prob": 2.3186627004179172e-05}, {"id": 300, "seek": 122252, "start": 1228.04, "end": 1234.0, "text": " to at least recognize or sort of segregate the sky from the sand or the sky from the", "tokens": [50364, 1171, 1365, 11, 281, 6069, 300, 341, 1729, 3256, 307, 42146, 538, 11971, 5310, 11, 309, 2203, 50640, 50640, 281, 412, 1935, 5521, 420, 1333, 295, 37630, 473, 264, 5443, 490, 264, 4932, 420, 264, 5443, 490, 264, 50938, 50938, 1281, 420, 412, 1935, 1223, 300, 337, 257, 4230, 11, 264, 5510, 366, 5101, 406, 2507, 264, 2159, 13, 51288, 51288, 314, 4856, 500, 380, 1852, 39880, 11, 436, 1852, 22167, 13, 51478, 51478, 407, 309, 1333, 295, 2203, 281, 1778, 466, 512, 721, 26947, 356, 13, 51670, 51670], "temperature": 0.0, "avg_logprob": -0.16286587977147365, "compression_ratio": 1.6428571428571428, "no_speech_prob": 2.3186627004179172e-05}, {"id": 301, "seek": 122252, "start": 1234.0, "end": 1241.0, "text": " water or at least understand that for a tree, the leaves are generally not below the bar.", "tokens": [50364, 1171, 1365, 11, 281, 6069, 300, 341, 1729, 3256, 307, 42146, 538, 11971, 5310, 11, 309, 2203, 50640, 50640, 281, 412, 1935, 5521, 420, 1333, 295, 37630, 473, 264, 5443, 490, 264, 4932, 420, 264, 5443, 490, 264, 50938, 50938, 1281, 420, 412, 1935, 1223, 300, 337, 257, 4230, 11, 264, 5510, 366, 5101, 406, 2507, 264, 2159, 13, 51288, 51288, 314, 4856, 500, 380, 1852, 39880, 11, 436, 1852, 22167, 13, 51478, 51478, 407, 309, 1333, 295, 2203, 281, 1778, 466, 512, 721, 26947, 356, 13, 51670, 51670], "temperature": 0.0, "avg_logprob": -0.16286587977147365, "compression_ratio": 1.6428571428571428, "no_speech_prob": 2.3186627004179172e-05}, {"id": 302, "seek": 122252, "start": 1241.0, "end": 1244.8, "text": " Trees don't grow downwards, they grow upwards.", "tokens": [50364, 1171, 1365, 11, 281, 6069, 300, 341, 1729, 3256, 307, 42146, 538, 11971, 5310, 11, 309, 2203, 50640, 50640, 281, 412, 1935, 5521, 420, 1333, 295, 37630, 473, 264, 5443, 490, 264, 4932, 420, 264, 5443, 490, 264, 50938, 50938, 1281, 420, 412, 1935, 1223, 300, 337, 257, 4230, 11, 264, 5510, 366, 5101, 406, 2507, 264, 2159, 13, 51288, 51288, 314, 4856, 500, 380, 1852, 39880, 11, 436, 1852, 22167, 13, 51478, 51478, 407, 309, 1333, 295, 2203, 281, 1778, 466, 512, 721, 26947, 356, 13, 51670, 51670], "temperature": 0.0, "avg_logprob": -0.16286587977147365, "compression_ratio": 1.6428571428571428, "no_speech_prob": 2.3186627004179172e-05}, {"id": 303, "seek": 122252, "start": 1244.8, "end": 1248.6399999999999, "text": " So it sort of needs to reason about some things implicitly.", "tokens": [50364, 1171, 1365, 11, 281, 6069, 300, 341, 1729, 3256, 307, 42146, 538, 11971, 5310, 11, 309, 2203, 50640, 50640, 281, 412, 1935, 5521, 420, 1333, 295, 37630, 473, 264, 5443, 490, 264, 4932, 420, 264, 5443, 490, 264, 50938, 50938, 1281, 420, 412, 1935, 1223, 300, 337, 257, 4230, 11, 264, 5510, 366, 5101, 406, 2507, 264, 2159, 13, 51288, 51288, 314, 4856, 500, 380, 1852, 39880, 11, 436, 1852, 22167, 13, 51478, 51478, 407, 309, 1333, 295, 2203, 281, 1778, 466, 512, 721, 26947, 356, 13, 51670, 51670], "temperature": 0.0, "avg_logprob": -0.16286587977147365, "compression_ratio": 1.6428571428571428, "no_speech_prob": 2.3186627004179172e-05}, {"id": 304, "seek": 124864, "start": 1248.64, "end": 1252.88, "text": " It's not super clear what it really needs to do, but this task empirically works very", "tokens": [50364, 467, 311, 406, 1687, 1850, 437, 309, 534, 2203, 281, 360, 11, 457, 341, 5633, 25790, 984, 1985, 588, 50576, 50576, 731, 13, 50664, 50664, 8646, 341, 787, 668, 3031, 420, 1985, 382, 257, 5633, 365, 411, 257, 27706, 21538, 420, 575, 51060, 51060, 668, 3031, 322, 411, 257, 10957, 4373, 295, 14708, 412, 597, 264, 3256, 307, 42146, 30, 51294, 51294, 1079, 13, 51344, 51344, 407, 291, 393, 360, 1293, 9606, 13, 51460, 51460, 407, 291, 393, 1333, 295, 3488, 264, 1230, 295, 41275, 291, 528, 293, 382, 291, 1936, 652, 309, 51702, 51702], "temperature": 0.0, "avg_logprob": -0.16983537575633256, "compression_ratio": 1.6419213973799127, "no_speech_prob": 3.7633348256349564e-05}, {"id": 305, "seek": 124864, "start": 1252.88, "end": 1254.64, "text": " well.", "tokens": [50364, 467, 311, 406, 1687, 1850, 437, 309, 534, 2203, 281, 360, 11, 457, 341, 5633, 25790, 984, 1985, 588, 50576, 50576, 731, 13, 50664, 50664, 8646, 341, 787, 668, 3031, 420, 1985, 382, 257, 5633, 365, 411, 257, 27706, 21538, 420, 575, 51060, 51060, 668, 3031, 322, 411, 257, 10957, 4373, 295, 14708, 412, 597, 264, 3256, 307, 42146, 30, 51294, 51294, 1079, 13, 51344, 51344, 407, 291, 393, 360, 1293, 9606, 13, 51460, 51460, 407, 291, 393, 1333, 295, 3488, 264, 1230, 295, 41275, 291, 528, 293, 382, 291, 1936, 652, 309, 51702, 51702], "temperature": 0.0, "avg_logprob": -0.16983537575633256, "compression_ratio": 1.6419213973799127, "no_speech_prob": 3.7633348256349564e-05}, {"id": 306, "seek": 124864, "start": 1254.64, "end": 1262.5600000000002, "text": " Has this only been tried or works as a task with like a discrete classification or has", "tokens": [50364, 467, 311, 406, 1687, 1850, 437, 309, 534, 2203, 281, 360, 11, 457, 341, 5633, 25790, 984, 1985, 588, 50576, 50576, 731, 13, 50664, 50664, 8646, 341, 787, 668, 3031, 420, 1985, 382, 257, 5633, 365, 411, 257, 27706, 21538, 420, 575, 51060, 51060, 668, 3031, 322, 411, 257, 10957, 4373, 295, 14708, 412, 597, 264, 3256, 307, 42146, 30, 51294, 51294, 1079, 13, 51344, 51344, 407, 291, 393, 360, 1293, 9606, 13, 51460, 51460, 407, 291, 393, 1333, 295, 3488, 264, 1230, 295, 41275, 291, 528, 293, 382, 291, 1936, 652, 309, 51702, 51702], "temperature": 0.0, "avg_logprob": -0.16983537575633256, "compression_ratio": 1.6419213973799127, "no_speech_prob": 3.7633348256349564e-05}, {"id": 307, "seek": 124864, "start": 1262.5600000000002, "end": 1267.24, "text": " been tried on like a continuous scale of angles at which the image is rotated?", "tokens": [50364, 467, 311, 406, 1687, 1850, 437, 309, 534, 2203, 281, 360, 11, 457, 341, 5633, 25790, 984, 1985, 588, 50576, 50576, 731, 13, 50664, 50664, 8646, 341, 787, 668, 3031, 420, 1985, 382, 257, 5633, 365, 411, 257, 27706, 21538, 420, 575, 51060, 51060, 668, 3031, 322, 411, 257, 10957, 4373, 295, 14708, 412, 597, 264, 3256, 307, 42146, 30, 51294, 51294, 1079, 13, 51344, 51344, 407, 291, 393, 360, 1293, 9606, 13, 51460, 51460, 407, 291, 393, 1333, 295, 3488, 264, 1230, 295, 41275, 291, 528, 293, 382, 291, 1936, 652, 309, 51702, 51702], "temperature": 0.0, "avg_logprob": -0.16983537575633256, "compression_ratio": 1.6419213973799127, "no_speech_prob": 3.7633348256349564e-05}, {"id": 308, "seek": 124864, "start": 1267.24, "end": 1268.24, "text": " Yes.", "tokens": [50364, 467, 311, 406, 1687, 1850, 437, 309, 534, 2203, 281, 360, 11, 457, 341, 5633, 25790, 984, 1985, 588, 50576, 50576, 731, 13, 50664, 50664, 8646, 341, 787, 668, 3031, 420, 1985, 382, 257, 5633, 365, 411, 257, 27706, 21538, 420, 575, 51060, 51060, 668, 3031, 322, 411, 257, 10957, 4373, 295, 14708, 412, 597, 264, 3256, 307, 42146, 30, 51294, 51294, 1079, 13, 51344, 51344, 407, 291, 393, 360, 1293, 9606, 13, 51460, 51460, 407, 291, 393, 1333, 295, 3488, 264, 1230, 295, 41275, 291, 528, 293, 382, 291, 1936, 652, 309, 51702, 51702], "temperature": 0.0, "avg_logprob": -0.16983537575633256, "compression_ratio": 1.6419213973799127, "no_speech_prob": 3.7633348256349564e-05}, {"id": 309, "seek": 124864, "start": 1268.24, "end": 1270.5600000000002, "text": " So you can do both versions.", "tokens": [50364, 467, 311, 406, 1687, 1850, 437, 309, 534, 2203, 281, 360, 11, 457, 341, 5633, 25790, 984, 1985, 588, 50576, 50576, 731, 13, 50664, 50664, 8646, 341, 787, 668, 3031, 420, 1985, 382, 257, 5633, 365, 411, 257, 27706, 21538, 420, 575, 51060, 51060, 668, 3031, 322, 411, 257, 10957, 4373, 295, 14708, 412, 597, 264, 3256, 307, 42146, 30, 51294, 51294, 1079, 13, 51344, 51344, 407, 291, 393, 360, 1293, 9606, 13, 51460, 51460, 407, 291, 393, 1333, 295, 3488, 264, 1230, 295, 41275, 291, 528, 293, 382, 291, 1936, 652, 309, 51702, 51702], "temperature": 0.0, "avg_logprob": -0.16983537575633256, "compression_ratio": 1.6419213973799127, "no_speech_prob": 3.7633348256349564e-05}, {"id": 310, "seek": 124864, "start": 1270.5600000000002, "end": 1275.4, "text": " So you can sort of increase the number of bins you want and as you basically make it", "tokens": [50364, 467, 311, 406, 1687, 1850, 437, 309, 534, 2203, 281, 360, 11, 457, 341, 5633, 25790, 984, 1985, 588, 50576, 50576, 731, 13, 50664, 50664, 8646, 341, 787, 668, 3031, 420, 1985, 382, 257, 5633, 365, 411, 257, 27706, 21538, 420, 575, 51060, 51060, 668, 3031, 322, 411, 257, 10957, 4373, 295, 14708, 412, 597, 264, 3256, 307, 42146, 30, 51294, 51294, 1079, 13, 51344, 51344, 407, 291, 393, 360, 1293, 9606, 13, 51460, 51460, 407, 291, 393, 1333, 295, 3488, 264, 1230, 295, 41275, 291, 528, 293, 382, 291, 1936, 652, 309, 51702, 51702], "temperature": 0.0, "avg_logprob": -0.16983537575633256, "compression_ratio": 1.6419213973799127, "no_speech_prob": 3.7633348256349564e-05}, {"id": 311, "seek": 127540, "start": 1275.4, "end": 1279.3600000000001, "text": " very, very large, you're approaching more of a regression problem where you have a continuous", "tokens": [50364, 588, 11, 588, 2416, 11, 291, 434, 14908, 544, 295, 257, 24590, 1154, 689, 291, 362, 257, 10957, 50562, 50562, 7006, 13, 50612, 50612, 682, 3124, 11, 613, 1451, 1333, 295, 14708, 589, 1238, 731, 13, 50862, 50862, 286, 914, 11, 5662, 2709, 16885, 5311, 13, 51094, 51094, 821, 311, 257, 1168, 466, 264, 3894, 4137, 13, 51208, 51208, 1012, 775, 264, 23831, 7630, 589, 294, 341, 4319, 30, 51348, 51348, 1144, 291, 1190, 633, 9972, 11, 1184, 9972, 807, 264, 24859, 30, 51526, 51526, 1079, 13, 51581, 51581, 407, 341, 307, 445, 337, 25801, 13, 51658, 51658, 639, 307, 445, 337, 1333, 295, 3701, 13, 51753, 51753], "temperature": 0.0, "avg_logprob": -0.20411513935435902, "compression_ratio": 1.5663082437275986, "no_speech_prob": 4.264464951120317e-05}, {"id": 312, "seek": 127540, "start": 1279.3600000000001, "end": 1280.3600000000001, "text": " variable.", "tokens": [50364, 588, 11, 588, 2416, 11, 291, 434, 14908, 544, 295, 257, 24590, 1154, 689, 291, 362, 257, 10957, 50562, 50562, 7006, 13, 50612, 50612, 682, 3124, 11, 613, 1451, 1333, 295, 14708, 589, 1238, 731, 13, 50862, 50862, 286, 914, 11, 5662, 2709, 16885, 5311, 13, 51094, 51094, 821, 311, 257, 1168, 466, 264, 3894, 4137, 13, 51208, 51208, 1012, 775, 264, 23831, 7630, 589, 294, 341, 4319, 30, 51348, 51348, 1144, 291, 1190, 633, 9972, 11, 1184, 9972, 807, 264, 24859, 30, 51526, 51526, 1079, 13, 51581, 51581, 407, 341, 307, 445, 337, 25801, 13, 51658, 51658, 639, 307, 445, 337, 1333, 295, 3701, 13, 51753, 51753], "temperature": 0.0, "avg_logprob": -0.20411513935435902, "compression_ratio": 1.5663082437275986, "no_speech_prob": 4.264464951120317e-05}, {"id": 313, "seek": 127540, "start": 1280.3600000000001, "end": 1285.3600000000001, "text": " In practice, these four sort of angles work pretty well.", "tokens": [50364, 588, 11, 588, 2416, 11, 291, 434, 14908, 544, 295, 257, 24590, 1154, 689, 291, 362, 257, 10957, 50562, 50562, 7006, 13, 50612, 50612, 682, 3124, 11, 613, 1451, 1333, 295, 14708, 589, 1238, 731, 13, 50862, 50862, 286, 914, 11, 5662, 2709, 16885, 5311, 13, 51094, 51094, 821, 311, 257, 1168, 466, 264, 3894, 4137, 13, 51208, 51208, 1012, 775, 264, 23831, 7630, 589, 294, 341, 4319, 30, 51348, 51348, 1144, 291, 1190, 633, 9972, 11, 1184, 9972, 807, 264, 24859, 30, 51526, 51526, 1079, 13, 51581, 51581, 407, 341, 307, 445, 337, 25801, 13, 51658, 51658, 639, 307, 445, 337, 1333, 295, 3701, 13, 51753, 51753], "temperature": 0.0, "avg_logprob": -0.20411513935435902, "compression_ratio": 1.5663082437275986, "no_speech_prob": 4.264464951120317e-05}, {"id": 314, "seek": 127540, "start": 1285.3600000000001, "end": 1290.0, "text": " I mean, increasing gives marginal benefits.", "tokens": [50364, 588, 11, 588, 2416, 11, 291, 434, 14908, 544, 295, 257, 24590, 1154, 689, 291, 362, 257, 10957, 50562, 50562, 7006, 13, 50612, 50612, 682, 3124, 11, 613, 1451, 1333, 295, 14708, 589, 1238, 731, 13, 50862, 50862, 286, 914, 11, 5662, 2709, 16885, 5311, 13, 51094, 51094, 821, 311, 257, 1168, 466, 264, 3894, 4137, 13, 51208, 51208, 1012, 775, 264, 23831, 7630, 589, 294, 341, 4319, 30, 51348, 51348, 1144, 291, 1190, 633, 9972, 11, 1184, 9972, 807, 264, 24859, 30, 51526, 51526, 1079, 13, 51581, 51581, 407, 341, 307, 445, 337, 25801, 13, 51658, 51658, 639, 307, 445, 337, 1333, 295, 3701, 13, 51753, 51753], "temperature": 0.0, "avg_logprob": -0.20411513935435902, "compression_ratio": 1.5663082437275986, "no_speech_prob": 4.264464951120317e-05}, {"id": 315, "seek": 127540, "start": 1290.0, "end": 1292.2800000000002, "text": " There's a question about the previous slide.", "tokens": [50364, 588, 11, 588, 2416, 11, 291, 434, 14908, 544, 295, 257, 24590, 1154, 689, 291, 362, 257, 10957, 50562, 50562, 7006, 13, 50612, 50612, 682, 3124, 11, 613, 1451, 1333, 295, 14708, 589, 1238, 731, 13, 50862, 50862, 286, 914, 11, 5662, 2709, 16885, 5311, 13, 51094, 51094, 821, 311, 257, 1168, 466, 264, 3894, 4137, 13, 51208, 51208, 1012, 775, 264, 23831, 7630, 589, 294, 341, 4319, 30, 51348, 51348, 1144, 291, 1190, 633, 9972, 11, 1184, 9972, 807, 264, 24859, 30, 51526, 51526, 1079, 13, 51581, 51581, 407, 341, 307, 445, 337, 25801, 13, 51658, 51658, 639, 307, 445, 337, 1333, 295, 3701, 13, 51753, 51753], "temperature": 0.0, "avg_logprob": -0.20411513935435902, "compression_ratio": 1.5663082437275986, "no_speech_prob": 4.264464951120317e-05}, {"id": 316, "seek": 127540, "start": 1292.2800000000002, "end": 1295.0800000000002, "text": " How does the nearest neighborhood work in this context?", "tokens": [50364, 588, 11, 588, 2416, 11, 291, 434, 14908, 544, 295, 257, 24590, 1154, 689, 291, 362, 257, 10957, 50562, 50562, 7006, 13, 50612, 50612, 682, 3124, 11, 613, 1451, 1333, 295, 14708, 589, 1238, 731, 13, 50862, 50862, 286, 914, 11, 5662, 2709, 16885, 5311, 13, 51094, 51094, 821, 311, 257, 1168, 466, 264, 3894, 4137, 13, 51208, 51208, 1012, 775, 264, 23831, 7630, 589, 294, 341, 4319, 30, 51348, 51348, 1144, 291, 1190, 633, 9972, 11, 1184, 9972, 807, 264, 24859, 30, 51526, 51526, 1079, 13, 51581, 51581, 407, 341, 307, 445, 337, 25801, 13, 51658, 51658, 639, 307, 445, 337, 1333, 295, 3701, 13, 51753, 51753], "temperature": 0.0, "avg_logprob": -0.20411513935435902, "compression_ratio": 1.5663082437275986, "no_speech_prob": 4.264464951120317e-05}, {"id": 317, "seek": 127540, "start": 1295.0800000000002, "end": 1298.64, "text": " Do you run every patch, each patch through the CNN?", "tokens": [50364, 588, 11, 588, 2416, 11, 291, 434, 14908, 544, 295, 257, 24590, 1154, 689, 291, 362, 257, 10957, 50562, 50562, 7006, 13, 50612, 50612, 682, 3124, 11, 613, 1451, 1333, 295, 14708, 589, 1238, 731, 13, 50862, 50862, 286, 914, 11, 5662, 2709, 16885, 5311, 13, 51094, 51094, 821, 311, 257, 1168, 466, 264, 3894, 4137, 13, 51208, 51208, 1012, 775, 264, 23831, 7630, 589, 294, 341, 4319, 30, 51348, 51348, 1144, 291, 1190, 633, 9972, 11, 1184, 9972, 807, 264, 24859, 30, 51526, 51526, 1079, 13, 51581, 51581, 407, 341, 307, 445, 337, 25801, 13, 51658, 51658, 639, 307, 445, 337, 1333, 295, 3701, 13, 51753, 51753], "temperature": 0.0, "avg_logprob": -0.20411513935435902, "compression_ratio": 1.5663082437275986, "no_speech_prob": 4.264464951120317e-05}, {"id": 318, "seek": 127540, "start": 1298.64, "end": 1299.74, "text": " Yes.", "tokens": [50364, 588, 11, 588, 2416, 11, 291, 434, 14908, 544, 295, 257, 24590, 1154, 689, 291, 362, 257, 10957, 50562, 50562, 7006, 13, 50612, 50612, 682, 3124, 11, 613, 1451, 1333, 295, 14708, 589, 1238, 731, 13, 50862, 50862, 286, 914, 11, 5662, 2709, 16885, 5311, 13, 51094, 51094, 821, 311, 257, 1168, 466, 264, 3894, 4137, 13, 51208, 51208, 1012, 775, 264, 23831, 7630, 589, 294, 341, 4319, 30, 51348, 51348, 1144, 291, 1190, 633, 9972, 11, 1184, 9972, 807, 264, 24859, 30, 51526, 51526, 1079, 13, 51581, 51581, 407, 341, 307, 445, 337, 25801, 13, 51658, 51658, 639, 307, 445, 337, 1333, 295, 3701, 13, 51753, 51753], "temperature": 0.0, "avg_logprob": -0.20411513935435902, "compression_ratio": 1.5663082437275986, "no_speech_prob": 4.264464951120317e-05}, {"id": 319, "seek": 127540, "start": 1299.74, "end": 1301.2800000000002, "text": " So this is just for visualization.", "tokens": [50364, 588, 11, 588, 2416, 11, 291, 434, 14908, 544, 295, 257, 24590, 1154, 689, 291, 362, 257, 10957, 50562, 50562, 7006, 13, 50612, 50612, 682, 3124, 11, 613, 1451, 1333, 295, 14708, 589, 1238, 731, 13, 50862, 50862, 286, 914, 11, 5662, 2709, 16885, 5311, 13, 51094, 51094, 821, 311, 257, 1168, 466, 264, 3894, 4137, 13, 51208, 51208, 1012, 775, 264, 23831, 7630, 589, 294, 341, 4319, 30, 51348, 51348, 1144, 291, 1190, 633, 9972, 11, 1184, 9972, 807, 264, 24859, 30, 51526, 51526, 1079, 13, 51581, 51581, 407, 341, 307, 445, 337, 25801, 13, 51658, 51658, 639, 307, 445, 337, 1333, 295, 3701, 13, 51753, 51753], "temperature": 0.0, "avg_logprob": -0.20411513935435902, "compression_ratio": 1.5663082437275986, "no_speech_prob": 4.264464951120317e-05}, {"id": 320, "seek": 127540, "start": 1301.2800000000002, "end": 1303.18, "text": " This is just for sort of understanding.", "tokens": [50364, 588, 11, 588, 2416, 11, 291, 434, 14908, 544, 295, 257, 24590, 1154, 689, 291, 362, 257, 10957, 50562, 50562, 7006, 13, 50612, 50612, 682, 3124, 11, 613, 1451, 1333, 295, 14708, 589, 1238, 731, 13, 50862, 50862, 286, 914, 11, 5662, 2709, 16885, 5311, 13, 51094, 51094, 821, 311, 257, 1168, 466, 264, 3894, 4137, 13, 51208, 51208, 1012, 775, 264, 23831, 7630, 589, 294, 341, 4319, 30, 51348, 51348, 1144, 291, 1190, 633, 9972, 11, 1184, 9972, 807, 264, 24859, 30, 51526, 51526, 1079, 13, 51581, 51581, 407, 341, 307, 445, 337, 25801, 13, 51658, 51658, 639, 307, 445, 337, 1333, 295, 3701, 13, 51753, 51753], "temperature": 0.0, "avg_logprob": -0.20411513935435902, "compression_ratio": 1.5663082437275986, "no_speech_prob": 4.264464951120317e-05}, {"id": 321, "seek": 130318, "start": 1303.18, "end": 1308.64, "text": " So although it is like sort of expensive to compute this, it gives you a very good idea", "tokens": [50364, 407, 4878, 309, 307, 411, 1333, 295, 5124, 281, 14722, 341, 11, 309, 2709, 291, 257, 588, 665, 1558, 50637, 50637, 295, 437, 264, 10290, 575, 3264, 13, 50725, 50725, 407, 437, 264, 16552, 630, 390, 1936, 8947, 257, 3840, 295, 26531, 490, 1184, 3256, 11, 9810, 50977, 50977, 1266, 281, 4949, 26531, 13, 51075, 51075, 400, 370, 322, 257, 1359, 992, 295, 5267, 13, 51220, 51220, 407, 286, 519, 294, 341, 1389, 11, 309, 390, 411, 2625, 281, 2319, 11, 1360, 5267, 13, 51386, 51386, 400, 550, 291, 1936, 445, 14722, 23831, 12512, 322, 729, 26531, 295, 729, 5267, 13, 51729, 51729], "temperature": 0.0, "avg_logprob": -0.18735909234909784, "compression_ratio": 1.6814516129032258, "no_speech_prob": 6.143971404526383e-06}, {"id": 322, "seek": 130318, "start": 1308.64, "end": 1310.4, "text": " of what the representation has learned.", "tokens": [50364, 407, 4878, 309, 307, 411, 1333, 295, 5124, 281, 14722, 341, 11, 309, 2709, 291, 257, 588, 665, 1558, 50637, 50637, 295, 437, 264, 10290, 575, 3264, 13, 50725, 50725, 407, 437, 264, 16552, 630, 390, 1936, 8947, 257, 3840, 295, 26531, 490, 1184, 3256, 11, 9810, 50977, 50977, 1266, 281, 4949, 26531, 13, 51075, 51075, 400, 370, 322, 257, 1359, 992, 295, 5267, 13, 51220, 51220, 407, 286, 519, 294, 341, 1389, 11, 309, 390, 411, 2625, 281, 2319, 11, 1360, 5267, 13, 51386, 51386, 400, 550, 291, 1936, 445, 14722, 23831, 12512, 322, 729, 26531, 295, 729, 5267, 13, 51729, 51729], "temperature": 0.0, "avg_logprob": -0.18735909234909784, "compression_ratio": 1.6814516129032258, "no_speech_prob": 6.143971404526383e-06}, {"id": 323, "seek": 130318, "start": 1310.4, "end": 1315.44, "text": " So what the authors did was basically extract a bunch of patches from each image, roughly", "tokens": [50364, 407, 4878, 309, 307, 411, 1333, 295, 5124, 281, 14722, 341, 11, 309, 2709, 291, 257, 588, 665, 1558, 50637, 50637, 295, 437, 264, 10290, 575, 3264, 13, 50725, 50725, 407, 437, 264, 16552, 630, 390, 1936, 8947, 257, 3840, 295, 26531, 490, 1184, 3256, 11, 9810, 50977, 50977, 1266, 281, 4949, 26531, 13, 51075, 51075, 400, 370, 322, 257, 1359, 992, 295, 5267, 13, 51220, 51220, 407, 286, 519, 294, 341, 1389, 11, 309, 390, 411, 2625, 281, 2319, 11, 1360, 5267, 13, 51386, 51386, 400, 550, 291, 1936, 445, 14722, 23831, 12512, 322, 729, 26531, 295, 729, 5267, 13, 51729, 51729], "temperature": 0.0, "avg_logprob": -0.18735909234909784, "compression_ratio": 1.6814516129032258, "no_speech_prob": 6.143971404526383e-06}, {"id": 324, "seek": 130318, "start": 1315.44, "end": 1317.4, "text": " 10 to nine patches.", "tokens": [50364, 407, 4878, 309, 307, 411, 1333, 295, 5124, 281, 14722, 341, 11, 309, 2709, 291, 257, 588, 665, 1558, 50637, 50637, 295, 437, 264, 10290, 575, 3264, 13, 50725, 50725, 407, 437, 264, 16552, 630, 390, 1936, 8947, 257, 3840, 295, 26531, 490, 1184, 3256, 11, 9810, 50977, 50977, 1266, 281, 4949, 26531, 13, 51075, 51075, 400, 370, 322, 257, 1359, 992, 295, 5267, 13, 51220, 51220, 407, 286, 519, 294, 341, 1389, 11, 309, 390, 411, 2625, 281, 2319, 11, 1360, 5267, 13, 51386, 51386, 400, 550, 291, 1936, 445, 14722, 23831, 12512, 322, 729, 26531, 295, 729, 5267, 13, 51729, 51729], "temperature": 0.0, "avg_logprob": -0.18735909234909784, "compression_ratio": 1.6814516129032258, "no_speech_prob": 6.143971404526383e-06}, {"id": 325, "seek": 130318, "start": 1317.4, "end": 1320.3, "text": " And so on a small set of images.", "tokens": [50364, 407, 4878, 309, 307, 411, 1333, 295, 5124, 281, 14722, 341, 11, 309, 2709, 291, 257, 588, 665, 1558, 50637, 50637, 295, 437, 264, 10290, 575, 3264, 13, 50725, 50725, 407, 437, 264, 16552, 630, 390, 1936, 8947, 257, 3840, 295, 26531, 490, 1184, 3256, 11, 9810, 50977, 50977, 1266, 281, 4949, 26531, 13, 51075, 51075, 400, 370, 322, 257, 1359, 992, 295, 5267, 13, 51220, 51220, 407, 286, 519, 294, 341, 1389, 11, 309, 390, 411, 2625, 281, 2319, 11, 1360, 5267, 13, 51386, 51386, 400, 550, 291, 1936, 445, 14722, 23831, 12512, 322, 729, 26531, 295, 729, 5267, 13, 51729, 51729], "temperature": 0.0, "avg_logprob": -0.18735909234909784, "compression_ratio": 1.6814516129032258, "no_speech_prob": 6.143971404526383e-06}, {"id": 326, "seek": 130318, "start": 1320.3, "end": 1323.6200000000001, "text": " So I think in this case, it was like 50 to 100,000 images.", "tokens": [50364, 407, 4878, 309, 307, 411, 1333, 295, 5124, 281, 14722, 341, 11, 309, 2709, 291, 257, 588, 665, 1558, 50637, 50637, 295, 437, 264, 10290, 575, 3264, 13, 50725, 50725, 407, 437, 264, 16552, 630, 390, 1936, 8947, 257, 3840, 295, 26531, 490, 1184, 3256, 11, 9810, 50977, 50977, 1266, 281, 4949, 26531, 13, 51075, 51075, 400, 370, 322, 257, 1359, 992, 295, 5267, 13, 51220, 51220, 407, 286, 519, 294, 341, 1389, 11, 309, 390, 411, 2625, 281, 2319, 11, 1360, 5267, 13, 51386, 51386, 400, 550, 291, 1936, 445, 14722, 23831, 12512, 322, 729, 26531, 295, 729, 5267, 13, 51729, 51729], "temperature": 0.0, "avg_logprob": -0.18735909234909784, "compression_ratio": 1.6814516129032258, "no_speech_prob": 6.143971404526383e-06}, {"id": 327, "seek": 130318, "start": 1323.6200000000001, "end": 1330.48, "text": " And then you basically just compute nearest neighbors on those patches of those images.", "tokens": [50364, 407, 4878, 309, 307, 411, 1333, 295, 5124, 281, 14722, 341, 11, 309, 2709, 291, 257, 588, 665, 1558, 50637, 50637, 295, 437, 264, 10290, 575, 3264, 13, 50725, 50725, 407, 437, 264, 16552, 630, 390, 1936, 8947, 257, 3840, 295, 26531, 490, 1184, 3256, 11, 9810, 50977, 50977, 1266, 281, 4949, 26531, 13, 51075, 51075, 400, 370, 322, 257, 1359, 992, 295, 5267, 13, 51220, 51220, 407, 286, 519, 294, 341, 1389, 11, 309, 390, 411, 2625, 281, 2319, 11, 1360, 5267, 13, 51386, 51386, 400, 550, 291, 1936, 445, 14722, 23831, 12512, 322, 729, 26531, 295, 729, 5267, 13, 51729, 51729], "temperature": 0.0, "avg_logprob": -0.18735909234909784, "compression_ratio": 1.6814516129032258, "no_speech_prob": 6.143971404526383e-06}, {"id": 328, "seek": 133048, "start": 1330.48, "end": 1333.56, "text": " Is that clear?", "tokens": [50364, 1119, 300, 1850, 30, 50518, 50518, 865, 11, 300, 311, 309, 13, 50696, 50696, 407, 1071, 5633, 11, 597, 307, 611, 6457, 3743, 307, 1219, 2017, 2144, 13, 50990, 50990, 407, 294, 341, 1389, 11, 2212, 257, 677, 3772, 37088, 3256, 11, 291, 1936, 853, 281, 6069, 264, 4577, 295, 51298, 51298, 300, 3256, 13, 51348, 51348, 407, 291, 393, 534, 47881, 341, 5633, 337, 604, 3256, 13, 51468, 51468, 509, 393, 747, 364, 3256, 11, 291, 393, 4159, 1080, 2017, 11, 293, 291, 393, 1029, 257, 3209, 281, 1936, 51708, 51708], "temperature": 0.0, "avg_logprob": -0.15918311666935048, "compression_ratio": 1.6782178217821782, "no_speech_prob": 4.75692177133169e-05}, {"id": 329, "seek": 133048, "start": 1333.56, "end": 1337.1200000000001, "text": " Yeah, that's it.", "tokens": [50364, 1119, 300, 1850, 30, 50518, 50518, 865, 11, 300, 311, 309, 13, 50696, 50696, 407, 1071, 5633, 11, 597, 307, 611, 6457, 3743, 307, 1219, 2017, 2144, 13, 50990, 50990, 407, 294, 341, 1389, 11, 2212, 257, 677, 3772, 37088, 3256, 11, 291, 1936, 853, 281, 6069, 264, 4577, 295, 51298, 51298, 300, 3256, 13, 51348, 51348, 407, 291, 393, 534, 47881, 341, 5633, 337, 604, 3256, 13, 51468, 51468, 509, 393, 747, 364, 3256, 11, 291, 393, 4159, 1080, 2017, 11, 293, 291, 393, 1029, 257, 3209, 281, 1936, 51708, 51708], "temperature": 0.0, "avg_logprob": -0.15918311666935048, "compression_ratio": 1.6782178217821782, "no_speech_prob": 4.75692177133169e-05}, {"id": 330, "seek": 133048, "start": 1337.1200000000001, "end": 1343.0, "text": " So another task, which is also fairly popular is called colorization.", "tokens": [50364, 1119, 300, 1850, 30, 50518, 50518, 865, 11, 300, 311, 309, 13, 50696, 50696, 407, 1071, 5633, 11, 597, 307, 611, 6457, 3743, 307, 1219, 2017, 2144, 13, 50990, 50990, 407, 294, 341, 1389, 11, 2212, 257, 677, 3772, 37088, 3256, 11, 291, 1936, 853, 281, 6069, 264, 4577, 295, 51298, 51298, 300, 3256, 13, 51348, 51348, 407, 291, 393, 534, 47881, 341, 5633, 337, 604, 3256, 13, 51468, 51468, 509, 393, 747, 364, 3256, 11, 291, 393, 4159, 1080, 2017, 11, 293, 291, 393, 1029, 257, 3209, 281, 1936, 51708, 51708], "temperature": 0.0, "avg_logprob": -0.15918311666935048, "compression_ratio": 1.6782178217821782, "no_speech_prob": 4.75692177133169e-05}, {"id": 331, "seek": 133048, "start": 1343.0, "end": 1349.16, "text": " So in this case, given a grayscale image, you basically try to predict the colors of", "tokens": [50364, 1119, 300, 1850, 30, 50518, 50518, 865, 11, 300, 311, 309, 13, 50696, 50696, 407, 1071, 5633, 11, 597, 307, 611, 6457, 3743, 307, 1219, 2017, 2144, 13, 50990, 50990, 407, 294, 341, 1389, 11, 2212, 257, 677, 3772, 37088, 3256, 11, 291, 1936, 853, 281, 6069, 264, 4577, 295, 51298, 51298, 300, 3256, 13, 51348, 51348, 407, 291, 393, 534, 47881, 341, 5633, 337, 604, 3256, 13, 51468, 51468, 509, 393, 747, 364, 3256, 11, 291, 393, 4159, 1080, 2017, 11, 293, 291, 393, 1029, 257, 3209, 281, 1936, 51708, 51708], "temperature": 0.0, "avg_logprob": -0.15918311666935048, "compression_ratio": 1.6782178217821782, "no_speech_prob": 4.75692177133169e-05}, {"id": 332, "seek": 133048, "start": 1349.16, "end": 1350.16, "text": " that image.", "tokens": [50364, 1119, 300, 1850, 30, 50518, 50518, 865, 11, 300, 311, 309, 13, 50696, 50696, 407, 1071, 5633, 11, 597, 307, 611, 6457, 3743, 307, 1219, 2017, 2144, 13, 50990, 50990, 407, 294, 341, 1389, 11, 2212, 257, 677, 3772, 37088, 3256, 11, 291, 1936, 853, 281, 6069, 264, 4577, 295, 51298, 51298, 300, 3256, 13, 51348, 51348, 407, 291, 393, 534, 47881, 341, 5633, 337, 604, 3256, 13, 51468, 51468, 509, 393, 747, 364, 3256, 11, 291, 393, 4159, 1080, 2017, 11, 293, 291, 393, 1029, 257, 3209, 281, 1936, 51708, 51708], "temperature": 0.0, "avg_logprob": -0.15918311666935048, "compression_ratio": 1.6782178217821782, "no_speech_prob": 4.75692177133169e-05}, {"id": 333, "seek": 133048, "start": 1350.16, "end": 1352.56, "text": " So you can really formulate this task for any image.", "tokens": [50364, 1119, 300, 1850, 30, 50518, 50518, 865, 11, 300, 311, 309, 13, 50696, 50696, 407, 1071, 5633, 11, 597, 307, 611, 6457, 3743, 307, 1219, 2017, 2144, 13, 50990, 50990, 407, 294, 341, 1389, 11, 2212, 257, 677, 3772, 37088, 3256, 11, 291, 1936, 853, 281, 6069, 264, 4577, 295, 51298, 51298, 300, 3256, 13, 51348, 51348, 407, 291, 393, 534, 47881, 341, 5633, 337, 604, 3256, 13, 51468, 51468, 509, 393, 747, 364, 3256, 11, 291, 393, 4159, 1080, 2017, 11, 293, 291, 393, 1029, 257, 3209, 281, 1936, 51708, 51708], "temperature": 0.0, "avg_logprob": -0.15918311666935048, "compression_ratio": 1.6782178217821782, "no_speech_prob": 4.75692177133169e-05}, {"id": 334, "seek": 133048, "start": 1352.56, "end": 1357.3600000000001, "text": " You can take an image, you can remove its color, and you can ask a network to basically", "tokens": [50364, 1119, 300, 1850, 30, 50518, 50518, 865, 11, 300, 311, 309, 13, 50696, 50696, 407, 1071, 5633, 11, 597, 307, 611, 6457, 3743, 307, 1219, 2017, 2144, 13, 50990, 50990, 407, 294, 341, 1389, 11, 2212, 257, 677, 3772, 37088, 3256, 11, 291, 1936, 853, 281, 6069, 264, 4577, 295, 51298, 51298, 300, 3256, 13, 51348, 51348, 407, 291, 393, 534, 47881, 341, 5633, 337, 604, 3256, 13, 51468, 51468, 509, 393, 747, 364, 3256, 11, 291, 393, 4159, 1080, 2017, 11, 293, 291, 393, 1029, 257, 3209, 281, 1936, 51708, 51708], "temperature": 0.0, "avg_logprob": -0.15918311666935048, "compression_ratio": 1.6782178217821782, "no_speech_prob": 4.75692177133169e-05}, {"id": 335, "seek": 135736, "start": 1357.36, "end": 1361.7199999999998, "text": " predict the color from this black and white or sort of grayscale image.", "tokens": [50364, 6069, 264, 2017, 490, 341, 2211, 293, 2418, 420, 1333, 295, 677, 3772, 37088, 3256, 13, 50582, 50582, 400, 341, 5633, 538, 2564, 307, 406, 382, 11, 309, 311, 767, 4420, 294, 512, 3104, 13, 50870, 50870, 407, 257, 688, 295, 411, 1331, 6233, 11, 562, 291, 1333, 295, 536, 552, 2017, 1602, 11, 370, 411, 6233, 3347, 51156, 51156, 294, 584, 264, 3356, 82, 420, 2217, 82, 11, 562, 456, 390, 406, 257, 688, 295, 2017, 2899, 11, 291, 393, 767, 51414, 51414, 362, 341, 5633, 534, 1333, 295, 312, 6456, 456, 13, 51552, 51552, 407, 294, 512, 636, 11, 309, 767, 307, 544, 4420, 813, 661, 659, 25111, 9608, 13, 51828, 51828], "temperature": 0.0, "avg_logprob": -0.10911771346782816, "compression_ratio": 1.7459677419354838, "no_speech_prob": 5.594238700723508e-06}, {"id": 336, "seek": 135736, "start": 1361.7199999999998, "end": 1367.4799999999998, "text": " And this task by itself is not as, it's actually useful in some respect.", "tokens": [50364, 6069, 264, 2017, 490, 341, 2211, 293, 2418, 420, 1333, 295, 677, 3772, 37088, 3256, 13, 50582, 50582, 400, 341, 5633, 538, 2564, 307, 406, 382, 11, 309, 311, 767, 4420, 294, 512, 3104, 13, 50870, 50870, 407, 257, 688, 295, 411, 1331, 6233, 11, 562, 291, 1333, 295, 536, 552, 2017, 1602, 11, 370, 411, 6233, 3347, 51156, 51156, 294, 584, 264, 3356, 82, 420, 2217, 82, 11, 562, 456, 390, 406, 257, 688, 295, 2017, 2899, 11, 291, 393, 767, 51414, 51414, 362, 341, 5633, 534, 1333, 295, 312, 6456, 456, 13, 51552, 51552, 407, 294, 512, 636, 11, 309, 767, 307, 544, 4420, 813, 661, 659, 25111, 9608, 13, 51828, 51828], "temperature": 0.0, "avg_logprob": -0.10911771346782816, "compression_ratio": 1.7459677419354838, "no_speech_prob": 5.594238700723508e-06}, {"id": 337, "seek": 135736, "start": 1367.4799999999998, "end": 1373.1999999999998, "text": " So a lot of like old movies, when you sort of see them colorized, so like movies shot", "tokens": [50364, 6069, 264, 2017, 490, 341, 2211, 293, 2418, 420, 1333, 295, 677, 3772, 37088, 3256, 13, 50582, 50582, 400, 341, 5633, 538, 2564, 307, 406, 382, 11, 309, 311, 767, 4420, 294, 512, 3104, 13, 50870, 50870, 407, 257, 688, 295, 411, 1331, 6233, 11, 562, 291, 1333, 295, 536, 552, 2017, 1602, 11, 370, 411, 6233, 3347, 51156, 51156, 294, 584, 264, 3356, 82, 420, 2217, 82, 11, 562, 456, 390, 406, 257, 688, 295, 2017, 2899, 11, 291, 393, 767, 51414, 51414, 362, 341, 5633, 534, 1333, 295, 312, 6456, 456, 13, 51552, 51552, 407, 294, 512, 636, 11, 309, 767, 307, 544, 4420, 813, 661, 659, 25111, 9608, 13, 51828, 51828], "temperature": 0.0, "avg_logprob": -0.10911771346782816, "compression_ratio": 1.7459677419354838, "no_speech_prob": 5.594238700723508e-06}, {"id": 338, "seek": 135736, "start": 1373.1999999999998, "end": 1378.36, "text": " in say the 40s or 30s, when there was not a lot of color technology, you can actually", "tokens": [50364, 6069, 264, 2017, 490, 341, 2211, 293, 2418, 420, 1333, 295, 677, 3772, 37088, 3256, 13, 50582, 50582, 400, 341, 5633, 538, 2564, 307, 406, 382, 11, 309, 311, 767, 4420, 294, 512, 3104, 13, 50870, 50870, 407, 257, 688, 295, 411, 1331, 6233, 11, 562, 291, 1333, 295, 536, 552, 2017, 1602, 11, 370, 411, 6233, 3347, 51156, 51156, 294, 584, 264, 3356, 82, 420, 2217, 82, 11, 562, 456, 390, 406, 257, 688, 295, 2017, 2899, 11, 291, 393, 767, 51414, 51414, 362, 341, 5633, 534, 1333, 295, 312, 6456, 456, 13, 51552, 51552, 407, 294, 512, 636, 11, 309, 767, 307, 544, 4420, 813, 661, 659, 25111, 9608, 13, 51828, 51828], "temperature": 0.0, "avg_logprob": -0.10911771346782816, "compression_ratio": 1.7459677419354838, "no_speech_prob": 5.594238700723508e-06}, {"id": 339, "seek": 135736, "start": 1378.36, "end": 1381.12, "text": " have this task really sort of be applied there.", "tokens": [50364, 6069, 264, 2017, 490, 341, 2211, 293, 2418, 420, 1333, 295, 677, 3772, 37088, 3256, 13, 50582, 50582, 400, 341, 5633, 538, 2564, 307, 406, 382, 11, 309, 311, 767, 4420, 294, 512, 3104, 13, 50870, 50870, 407, 257, 688, 295, 411, 1331, 6233, 11, 562, 291, 1333, 295, 536, 552, 2017, 1602, 11, 370, 411, 6233, 3347, 51156, 51156, 294, 584, 264, 3356, 82, 420, 2217, 82, 11, 562, 456, 390, 406, 257, 688, 295, 2017, 2899, 11, 291, 393, 767, 51414, 51414, 362, 341, 5633, 534, 1333, 295, 312, 6456, 456, 13, 51552, 51552, 407, 294, 512, 636, 11, 309, 767, 307, 544, 4420, 813, 661, 659, 25111, 9608, 13, 51828, 51828], "temperature": 0.0, "avg_logprob": -0.10911771346782816, "compression_ratio": 1.7459677419354838, "no_speech_prob": 5.594238700723508e-06}, {"id": 340, "seek": 135736, "start": 1381.12, "end": 1386.6399999999999, "text": " So in some way, it actually is more useful than other pretext tasks.", "tokens": [50364, 6069, 264, 2017, 490, 341, 2211, 293, 2418, 420, 1333, 295, 677, 3772, 37088, 3256, 13, 50582, 50582, 400, 341, 5633, 538, 2564, 307, 406, 382, 11, 309, 311, 767, 4420, 294, 512, 3104, 13, 50870, 50870, 407, 257, 688, 295, 411, 1331, 6233, 11, 562, 291, 1333, 295, 536, 552, 2017, 1602, 11, 370, 411, 6233, 3347, 51156, 51156, 294, 584, 264, 3356, 82, 420, 2217, 82, 11, 562, 456, 390, 406, 257, 688, 295, 2017, 2899, 11, 291, 393, 767, 51414, 51414, 362, 341, 5633, 534, 1333, 295, 312, 6456, 456, 13, 51552, 51552, 407, 294, 512, 636, 11, 309, 767, 307, 544, 4420, 813, 661, 659, 25111, 9608, 13, 51828, 51828], "temperature": 0.0, "avg_logprob": -0.10911771346782816, "compression_ratio": 1.7459677419354838, "no_speech_prob": 5.594238700723508e-06}, {"id": 341, "seek": 138664, "start": 1386.64, "end": 1388.8000000000002, "text": " And why does this task learn something meaningful?", "tokens": [50364, 400, 983, 775, 341, 5633, 1466, 746, 10995, 30, 50472, 50472, 1042, 11, 309, 2203, 281, 1333, 295, 5521, 300, 5852, 366, 3092, 13, 50654, 50654, 467, 2203, 281, 1223, 437, 264, 1333, 295, 2657, 10479, 307, 294, 1668, 281, 2017, 309, 6457, 50892, 50892, 731, 13, 50942, 50942, 400, 370, 294, 3124, 11, 341, 575, 586, 1333, 295, 668, 10913, 281, 264, 960, 9274, 13, 51158, 51158, 400, 456, 366, 257, 688, 295, 1524, 493, 1985, 322, 1333, 295, 2017, 2144, 2564, 13, 51436, 51436, 467, 311, 1880, 570, 286, 519, 264, 2017, 18350, 307, 406, 15957, 3142, 11, 558, 30, 51642, 51642, 286, 914, 11, 309, 311, 406, 15957, 3142, 11, 2086, 13, 51721, 51721], "temperature": 0.0, "avg_logprob": -0.2090650606556099, "compression_ratio": 1.7169117647058822, "no_speech_prob": 9.972141015168745e-06}, {"id": 342, "seek": 138664, "start": 1388.8000000000002, "end": 1392.44, "text": " Well, it needs to sort of recognize that trees are green.", "tokens": [50364, 400, 983, 775, 341, 5633, 1466, 746, 10995, 30, 50472, 50472, 1042, 11, 309, 2203, 281, 1333, 295, 5521, 300, 5852, 366, 3092, 13, 50654, 50654, 467, 2203, 281, 1223, 437, 264, 1333, 295, 2657, 10479, 307, 294, 1668, 281, 2017, 309, 6457, 50892, 50892, 731, 13, 50942, 50942, 400, 370, 294, 3124, 11, 341, 575, 586, 1333, 295, 668, 10913, 281, 264, 960, 9274, 13, 51158, 51158, 400, 456, 366, 257, 688, 295, 1524, 493, 1985, 322, 1333, 295, 2017, 2144, 2564, 13, 51436, 51436, 467, 311, 1880, 570, 286, 519, 264, 2017, 18350, 307, 406, 15957, 3142, 11, 558, 30, 51642, 51642, 286, 914, 11, 309, 311, 406, 15957, 3142, 11, 2086, 13, 51721, 51721], "temperature": 0.0, "avg_logprob": -0.2090650606556099, "compression_ratio": 1.7169117647058822, "no_speech_prob": 9.972141015168745e-06}, {"id": 343, "seek": 138664, "start": 1392.44, "end": 1397.2, "text": " It needs to understand what the sort of object categories is in order to color it fairly", "tokens": [50364, 400, 983, 775, 341, 5633, 1466, 746, 10995, 30, 50472, 50472, 1042, 11, 309, 2203, 281, 1333, 295, 5521, 300, 5852, 366, 3092, 13, 50654, 50654, 467, 2203, 281, 1223, 437, 264, 1333, 295, 2657, 10479, 307, 294, 1668, 281, 2017, 309, 6457, 50892, 50892, 731, 13, 50942, 50942, 400, 370, 294, 3124, 11, 341, 575, 586, 1333, 295, 668, 10913, 281, 264, 960, 9274, 13, 51158, 51158, 400, 456, 366, 257, 688, 295, 1524, 493, 1985, 322, 1333, 295, 2017, 2144, 2564, 13, 51436, 51436, 467, 311, 1880, 570, 286, 519, 264, 2017, 18350, 307, 406, 15957, 3142, 11, 558, 30, 51642, 51642, 286, 914, 11, 309, 311, 406, 15957, 3142, 11, 2086, 13, 51721, 51721], "temperature": 0.0, "avg_logprob": -0.2090650606556099, "compression_ratio": 1.7169117647058822, "no_speech_prob": 9.972141015168745e-06}, {"id": 344, "seek": 138664, "start": 1397.2, "end": 1398.2, "text": " well.", "tokens": [50364, 400, 983, 775, 341, 5633, 1466, 746, 10995, 30, 50472, 50472, 1042, 11, 309, 2203, 281, 1333, 295, 5521, 300, 5852, 366, 3092, 13, 50654, 50654, 467, 2203, 281, 1223, 437, 264, 1333, 295, 2657, 10479, 307, 294, 1668, 281, 2017, 309, 6457, 50892, 50892, 731, 13, 50942, 50942, 400, 370, 294, 3124, 11, 341, 575, 586, 1333, 295, 668, 10913, 281, 264, 960, 9274, 13, 51158, 51158, 400, 456, 366, 257, 688, 295, 1524, 493, 1985, 322, 1333, 295, 2017, 2144, 2564, 13, 51436, 51436, 467, 311, 1880, 570, 286, 519, 264, 2017, 18350, 307, 406, 15957, 3142, 11, 558, 30, 51642, 51642, 286, 914, 11, 309, 311, 406, 15957, 3142, 11, 2086, 13, 51721, 51721], "temperature": 0.0, "avg_logprob": -0.2090650606556099, "compression_ratio": 1.7169117647058822, "no_speech_prob": 9.972141015168745e-06}, {"id": 345, "seek": 138664, "start": 1398.2, "end": 1402.5200000000002, "text": " And so in practice, this has now sort of been extended to the video domain.", "tokens": [50364, 400, 983, 775, 341, 5633, 1466, 746, 10995, 30, 50472, 50472, 1042, 11, 309, 2203, 281, 1333, 295, 5521, 300, 5852, 366, 3092, 13, 50654, 50654, 467, 2203, 281, 1223, 437, 264, 1333, 295, 2657, 10479, 307, 294, 1668, 281, 2017, 309, 6457, 50892, 50892, 731, 13, 50942, 50942, 400, 370, 294, 3124, 11, 341, 575, 586, 1333, 295, 668, 10913, 281, 264, 960, 9274, 13, 51158, 51158, 400, 456, 366, 257, 688, 295, 1524, 493, 1985, 322, 1333, 295, 2017, 2144, 2564, 13, 51436, 51436, 467, 311, 1880, 570, 286, 519, 264, 2017, 18350, 307, 406, 15957, 3142, 11, 558, 30, 51642, 51642, 286, 914, 11, 309, 311, 406, 15957, 3142, 11, 2086, 13, 51721, 51721], "temperature": 0.0, "avg_logprob": -0.2090650606556099, "compression_ratio": 1.7169117647058822, "no_speech_prob": 9.972141015168745e-06}, {"id": 346, "seek": 138664, "start": 1402.5200000000002, "end": 1408.0800000000002, "text": " And there are a lot of follow up works on sort of colorization itself.", "tokens": [50364, 400, 983, 775, 341, 5633, 1466, 746, 10995, 30, 50472, 50472, 1042, 11, 309, 2203, 281, 1333, 295, 5521, 300, 5852, 366, 3092, 13, 50654, 50654, 467, 2203, 281, 1223, 437, 264, 1333, 295, 2657, 10479, 307, 294, 1668, 281, 2017, 309, 6457, 50892, 50892, 731, 13, 50942, 50942, 400, 370, 294, 3124, 11, 341, 575, 586, 1333, 295, 668, 10913, 281, 264, 960, 9274, 13, 51158, 51158, 400, 456, 366, 257, 688, 295, 1524, 493, 1985, 322, 1333, 295, 2017, 2144, 2564, 13, 51436, 51436, 467, 311, 1880, 570, 286, 519, 264, 2017, 18350, 307, 406, 15957, 3142, 11, 558, 30, 51642, 51642, 286, 914, 11, 309, 311, 406, 15957, 3142, 11, 2086, 13, 51721, 51721], "temperature": 0.0, "avg_logprob": -0.2090650606556099, "compression_ratio": 1.7169117647058822, "no_speech_prob": 9.972141015168745e-06}, {"id": 347, "seek": 138664, "start": 1408.0800000000002, "end": 1412.2, "text": " It's interesting because I think the color mapping is not deterministic, right?", "tokens": [50364, 400, 983, 775, 341, 5633, 1466, 746, 10995, 30, 50472, 50472, 1042, 11, 309, 2203, 281, 1333, 295, 5521, 300, 5852, 366, 3092, 13, 50654, 50654, 467, 2203, 281, 1223, 437, 264, 1333, 295, 2657, 10479, 307, 294, 1668, 281, 2017, 309, 6457, 50892, 50892, 731, 13, 50942, 50942, 400, 370, 294, 3124, 11, 341, 575, 586, 1333, 295, 668, 10913, 281, 264, 960, 9274, 13, 51158, 51158, 400, 456, 366, 257, 688, 295, 1524, 493, 1985, 322, 1333, 295, 2017, 2144, 2564, 13, 51436, 51436, 467, 311, 1880, 570, 286, 519, 264, 2017, 18350, 307, 406, 15957, 3142, 11, 558, 30, 51642, 51642, 286, 914, 11, 309, 311, 406, 15957, 3142, 11, 2086, 13, 51721, 51721], "temperature": 0.0, "avg_logprob": -0.2090650606556099, "compression_ratio": 1.7169117647058822, "no_speech_prob": 9.972141015168745e-06}, {"id": 348, "seek": 138664, "start": 1412.2, "end": 1413.7800000000002, "text": " I mean, it's not deterministic, yes.", "tokens": [50364, 400, 983, 775, 341, 5633, 1466, 746, 10995, 30, 50472, 50472, 1042, 11, 309, 2203, 281, 1333, 295, 5521, 300, 5852, 366, 3092, 13, 50654, 50654, 467, 2203, 281, 1223, 437, 264, 1333, 295, 2657, 10479, 307, 294, 1668, 281, 2017, 309, 6457, 50892, 50892, 731, 13, 50942, 50942, 400, 370, 294, 3124, 11, 341, 575, 586, 1333, 295, 668, 10913, 281, 264, 960, 9274, 13, 51158, 51158, 400, 456, 366, 257, 688, 295, 1524, 493, 1985, 322, 1333, 295, 2017, 2144, 2564, 13, 51436, 51436, 467, 311, 1880, 570, 286, 519, 264, 2017, 18350, 307, 406, 15957, 3142, 11, 558, 30, 51642, 51642, 286, 914, 11, 309, 311, 406, 15957, 3142, 11, 2086, 13, 51721, 51721], "temperature": 0.0, "avg_logprob": -0.2090650606556099, "compression_ratio": 1.7169117647058822, "no_speech_prob": 9.972141015168745e-06}, {"id": 349, "seek": 141378, "start": 1413.78, "end": 1419.8799999999999, "text": " So there are several possible true solutions, right?", "tokens": [50364, 407, 456, 366, 2940, 1944, 2074, 6547, 11, 558, 30, 50669, 50669, 1079, 13, 50719, 50719, 407, 264, 5883, 3035, 390, 1936, 1333, 295, 29939, 257, 15957, 3142, 18350, 13, 50946, 50946, 407, 291, 645, 12606, 2139, 257, 21538, 420, 257, 24590, 1154, 13, 51140, 51140, 407, 291, 787, 727, 362, 584, 257, 3344, 14332, 21925, 13, 51307, 51307, 400, 498, 291, 727, 1128, 1333, 295, 6069, 257, 10855, 14332, 21925, 13, 51529, 51529, 400, 370, 437, 4590, 493, 2737, 390, 337, 257, 688, 295, 10479, 11, 597, 362, 819, 3685, 51732, 51732, 295, 4577, 13, 51784, 51784], "temperature": 0.0, "avg_logprob": -0.1357577323913574, "compression_ratio": 1.685483870967742, "no_speech_prob": 1.3005928849452175e-05}, {"id": 350, "seek": 141378, "start": 1419.8799999999999, "end": 1420.8799999999999, "text": " Yes.", "tokens": [50364, 407, 456, 366, 2940, 1944, 2074, 6547, 11, 558, 30, 50669, 50669, 1079, 13, 50719, 50719, 407, 264, 5883, 3035, 390, 1936, 1333, 295, 29939, 257, 15957, 3142, 18350, 13, 50946, 50946, 407, 291, 645, 12606, 2139, 257, 21538, 420, 257, 24590, 1154, 13, 51140, 51140, 407, 291, 787, 727, 362, 584, 257, 3344, 14332, 21925, 13, 51307, 51307, 400, 498, 291, 727, 1128, 1333, 295, 6069, 257, 10855, 14332, 21925, 13, 51529, 51529, 400, 370, 437, 4590, 493, 2737, 390, 337, 257, 688, 295, 10479, 11, 597, 362, 819, 3685, 51732, 51732, 295, 4577, 13, 51784, 51784], "temperature": 0.0, "avg_logprob": -0.1357577323913574, "compression_ratio": 1.685483870967742, "no_speech_prob": 1.3005928849452175e-05}, {"id": 351, "seek": 141378, "start": 1420.8799999999999, "end": 1425.42, "text": " So the initial paper was basically sort of proposing a deterministic mapping.", "tokens": [50364, 407, 456, 366, 2940, 1944, 2074, 6547, 11, 558, 30, 50669, 50669, 1079, 13, 50719, 50719, 407, 264, 5883, 3035, 390, 1936, 1333, 295, 29939, 257, 15957, 3142, 18350, 13, 50946, 50946, 407, 291, 645, 12606, 2139, 257, 21538, 420, 257, 24590, 1154, 13, 51140, 51140, 407, 291, 787, 727, 362, 584, 257, 3344, 14332, 21925, 13, 51307, 51307, 400, 498, 291, 727, 1128, 1333, 295, 6069, 257, 10855, 14332, 21925, 13, 51529, 51529, 400, 370, 437, 4590, 493, 2737, 390, 337, 257, 688, 295, 10479, 11, 597, 362, 819, 3685, 51732, 51732, 295, 4577, 13, 51784, 51784], "temperature": 0.0, "avg_logprob": -0.1357577323913574, "compression_ratio": 1.685483870967742, "no_speech_prob": 1.3005928849452175e-05}, {"id": 352, "seek": 141378, "start": 1425.42, "end": 1429.3, "text": " So you were solving either a classification or a regression problem.", "tokens": [50364, 407, 456, 366, 2940, 1944, 2074, 6547, 11, 558, 30, 50669, 50669, 1079, 13, 50719, 50719, 407, 264, 5883, 3035, 390, 1936, 1333, 295, 29939, 257, 15957, 3142, 18350, 13, 50946, 50946, 407, 291, 645, 12606, 2139, 257, 21538, 420, 257, 24590, 1154, 13, 51140, 51140, 407, 291, 787, 727, 362, 584, 257, 3344, 14332, 21925, 13, 51307, 51307, 400, 498, 291, 727, 1128, 1333, 295, 6069, 257, 10855, 14332, 21925, 13, 51529, 51529, 400, 370, 437, 4590, 493, 2737, 390, 337, 257, 688, 295, 10479, 11, 597, 362, 819, 3685, 51732, 51732, 295, 4577, 13, 51784, 51784], "temperature": 0.0, "avg_logprob": -0.1357577323913574, "compression_ratio": 1.685483870967742, "no_speech_prob": 1.3005928849452175e-05}, {"id": 353, "seek": 141378, "start": 1429.3, "end": 1432.6399999999999, "text": " So you only could have say a blue colored umbrella.", "tokens": [50364, 407, 456, 366, 2940, 1944, 2074, 6547, 11, 558, 30, 50669, 50669, 1079, 13, 50719, 50719, 407, 264, 5883, 3035, 390, 1936, 1333, 295, 29939, 257, 15957, 3142, 18350, 13, 50946, 50946, 407, 291, 645, 12606, 2139, 257, 21538, 420, 257, 24590, 1154, 13, 51140, 51140, 407, 291, 787, 727, 362, 584, 257, 3344, 14332, 21925, 13, 51307, 51307, 400, 498, 291, 727, 1128, 1333, 295, 6069, 257, 10855, 14332, 21925, 13, 51529, 51529, 400, 370, 437, 4590, 493, 2737, 390, 337, 257, 688, 295, 10479, 11, 597, 362, 819, 3685, 51732, 51732, 295, 4577, 13, 51784, 51784], "temperature": 0.0, "avg_logprob": -0.1357577323913574, "compression_ratio": 1.685483870967742, "no_speech_prob": 1.3005928849452175e-05}, {"id": 354, "seek": 141378, "start": 1432.6399999999999, "end": 1437.08, "text": " And if you could never sort of predict a gray colored umbrella.", "tokens": [50364, 407, 456, 366, 2940, 1944, 2074, 6547, 11, 558, 30, 50669, 50669, 1079, 13, 50719, 50719, 407, 264, 5883, 3035, 390, 1936, 1333, 295, 29939, 257, 15957, 3142, 18350, 13, 50946, 50946, 407, 291, 645, 12606, 2139, 257, 21538, 420, 257, 24590, 1154, 13, 51140, 51140, 407, 291, 787, 727, 362, 584, 257, 3344, 14332, 21925, 13, 51307, 51307, 400, 498, 291, 727, 1128, 1333, 295, 6069, 257, 10855, 14332, 21925, 13, 51529, 51529, 400, 370, 437, 4590, 493, 2737, 390, 337, 257, 688, 295, 10479, 11, 597, 362, 819, 3685, 51732, 51732, 295, 4577, 13, 51784, 51784], "temperature": 0.0, "avg_logprob": -0.1357577323913574, "compression_ratio": 1.685483870967742, "no_speech_prob": 1.3005928849452175e-05}, {"id": 355, "seek": 141378, "start": 1437.08, "end": 1441.1399999999999, "text": " And so what ended up happening was for a lot of categories, which have different kinds", "tokens": [50364, 407, 456, 366, 2940, 1944, 2074, 6547, 11, 558, 30, 50669, 50669, 1079, 13, 50719, 50719, 407, 264, 5883, 3035, 390, 1936, 1333, 295, 29939, 257, 15957, 3142, 18350, 13, 50946, 50946, 407, 291, 645, 12606, 2139, 257, 21538, 420, 257, 24590, 1154, 13, 51140, 51140, 407, 291, 787, 727, 362, 584, 257, 3344, 14332, 21925, 13, 51307, 51307, 400, 498, 291, 727, 1128, 1333, 295, 6069, 257, 10855, 14332, 21925, 13, 51529, 51529, 400, 370, 437, 4590, 493, 2737, 390, 337, 257, 688, 295, 10479, 11, 597, 362, 819, 3685, 51732, 51732, 295, 4577, 13, 51784, 51784], "temperature": 0.0, "avg_logprob": -0.1357577323913574, "compression_ratio": 1.685483870967742, "no_speech_prob": 1.3005928849452175e-05}, {"id": 356, "seek": 141378, "start": 1441.1399999999999, "end": 1442.18, "text": " of colors.", "tokens": [50364, 407, 456, 366, 2940, 1944, 2074, 6547, 11, 558, 30, 50669, 50669, 1079, 13, 50719, 50719, 407, 264, 5883, 3035, 390, 1936, 1333, 295, 29939, 257, 15957, 3142, 18350, 13, 50946, 50946, 407, 291, 645, 12606, 2139, 257, 21538, 420, 257, 24590, 1154, 13, 51140, 51140, 407, 291, 787, 727, 362, 584, 257, 3344, 14332, 21925, 13, 51307, 51307, 400, 498, 291, 727, 1128, 1333, 295, 6069, 257, 10855, 14332, 21925, 13, 51529, 51529, 400, 370, 437, 4590, 493, 2737, 390, 337, 257, 688, 295, 10479, 11, 597, 362, 819, 3685, 51732, 51732, 295, 4577, 13, 51784, 51784], "temperature": 0.0, "avg_logprob": -0.1357577323913574, "compression_ratio": 1.685483870967742, "no_speech_prob": 1.3005928849452175e-05}, {"id": 357, "seek": 144218, "start": 1442.18, "end": 1446.8, "text": " So for example, let's assume say you have a ball and that ball can appear either in", "tokens": [50364, 407, 337, 1365, 11, 718, 311, 6552, 584, 291, 362, 257, 2594, 293, 300, 2594, 393, 4204, 2139, 294, 50595, 50595, 264, 2182, 11, 3344, 420, 3092, 4577, 13, 50693, 50693, 440, 3209, 576, 1333, 295, 6069, 300, 281, 312, 10855, 570, 731, 11, 286, 914, 11, 300, 311, 1333, 50859, 50859, 295, 264, 914, 295, 439, 295, 613, 721, 13, 50941, 50941, 407, 300, 311, 264, 1151, 309, 393, 360, 13, 51073, 51073, 821, 390, 1524, 493, 589, 490, 4389, 48202, 88, 3322, 311, 1594, 294, 15682, 23967, 11, 597, 3031, 281, 1333, 295, 808, 51345, 51345, 493, 365, 3034, 1478, 8399, 2058, 378, 433, 13, 51447, 51447, 407, 291, 767, 632, 257, 48994, 7006, 293, 550, 291, 576, 362, 9521, 2017, 2144, 13, 51644, 51644, 407, 294, 3124, 11, 291, 393, 1936, 360, 11587, 411, 300, 13, 51816, 51816], "temperature": 0.0, "avg_logprob": -0.15449147791295617, "compression_ratio": 1.6888888888888889, "no_speech_prob": 2.5465191356488504e-05}, {"id": 358, "seek": 144218, "start": 1446.8, "end": 1448.76, "text": " the red, blue or green colors.", "tokens": [50364, 407, 337, 1365, 11, 718, 311, 6552, 584, 291, 362, 257, 2594, 293, 300, 2594, 393, 4204, 2139, 294, 50595, 50595, 264, 2182, 11, 3344, 420, 3092, 4577, 13, 50693, 50693, 440, 3209, 576, 1333, 295, 6069, 300, 281, 312, 10855, 570, 731, 11, 286, 914, 11, 300, 311, 1333, 50859, 50859, 295, 264, 914, 295, 439, 295, 613, 721, 13, 50941, 50941, 407, 300, 311, 264, 1151, 309, 393, 360, 13, 51073, 51073, 821, 390, 1524, 493, 589, 490, 4389, 48202, 88, 3322, 311, 1594, 294, 15682, 23967, 11, 597, 3031, 281, 1333, 295, 808, 51345, 51345, 493, 365, 3034, 1478, 8399, 2058, 378, 433, 13, 51447, 51447, 407, 291, 767, 632, 257, 48994, 7006, 293, 550, 291, 576, 362, 9521, 2017, 2144, 13, 51644, 51644, 407, 294, 3124, 11, 291, 393, 1936, 360, 11587, 411, 300, 13, 51816, 51816], "temperature": 0.0, "avg_logprob": -0.15449147791295617, "compression_ratio": 1.6888888888888889, "no_speech_prob": 2.5465191356488504e-05}, {"id": 359, "seek": 144218, "start": 1448.76, "end": 1452.0800000000002, "text": " The network would sort of predict that to be gray because well, I mean, that's sort", "tokens": [50364, 407, 337, 1365, 11, 718, 311, 6552, 584, 291, 362, 257, 2594, 293, 300, 2594, 393, 4204, 2139, 294, 50595, 50595, 264, 2182, 11, 3344, 420, 3092, 4577, 13, 50693, 50693, 440, 3209, 576, 1333, 295, 6069, 300, 281, 312, 10855, 570, 731, 11, 286, 914, 11, 300, 311, 1333, 50859, 50859, 295, 264, 914, 295, 439, 295, 613, 721, 13, 50941, 50941, 407, 300, 311, 264, 1151, 309, 393, 360, 13, 51073, 51073, 821, 390, 1524, 493, 589, 490, 4389, 48202, 88, 3322, 311, 1594, 294, 15682, 23967, 11, 597, 3031, 281, 1333, 295, 808, 51345, 51345, 493, 365, 3034, 1478, 8399, 2058, 378, 433, 13, 51447, 51447, 407, 291, 767, 632, 257, 48994, 7006, 293, 550, 291, 576, 362, 9521, 2017, 2144, 13, 51644, 51644, 407, 294, 3124, 11, 291, 393, 1936, 360, 11587, 411, 300, 13, 51816, 51816], "temperature": 0.0, "avg_logprob": -0.15449147791295617, "compression_ratio": 1.6888888888888889, "no_speech_prob": 2.5465191356488504e-05}, {"id": 360, "seek": 144218, "start": 1452.0800000000002, "end": 1453.72, "text": " of the mean of all of these things.", "tokens": [50364, 407, 337, 1365, 11, 718, 311, 6552, 584, 291, 362, 257, 2594, 293, 300, 2594, 393, 4204, 2139, 294, 50595, 50595, 264, 2182, 11, 3344, 420, 3092, 4577, 13, 50693, 50693, 440, 3209, 576, 1333, 295, 6069, 300, 281, 312, 10855, 570, 731, 11, 286, 914, 11, 300, 311, 1333, 50859, 50859, 295, 264, 914, 295, 439, 295, 613, 721, 13, 50941, 50941, 407, 300, 311, 264, 1151, 309, 393, 360, 13, 51073, 51073, 821, 390, 1524, 493, 589, 490, 4389, 48202, 88, 3322, 311, 1594, 294, 15682, 23967, 11, 597, 3031, 281, 1333, 295, 808, 51345, 51345, 493, 365, 3034, 1478, 8399, 2058, 378, 433, 13, 51447, 51447, 407, 291, 767, 632, 257, 48994, 7006, 293, 550, 291, 576, 362, 9521, 2017, 2144, 13, 51644, 51644, 407, 294, 3124, 11, 291, 393, 1936, 360, 11587, 411, 300, 13, 51816, 51816], "temperature": 0.0, "avg_logprob": -0.15449147791295617, "compression_ratio": 1.6888888888888889, "no_speech_prob": 2.5465191356488504e-05}, {"id": 361, "seek": 144218, "start": 1453.72, "end": 1456.3600000000001, "text": " So that's the best it can do.", "tokens": [50364, 407, 337, 1365, 11, 718, 311, 6552, 584, 291, 362, 257, 2594, 293, 300, 2594, 393, 4204, 2139, 294, 50595, 50595, 264, 2182, 11, 3344, 420, 3092, 4577, 13, 50693, 50693, 440, 3209, 576, 1333, 295, 6069, 300, 281, 312, 10855, 570, 731, 11, 286, 914, 11, 300, 311, 1333, 50859, 50859, 295, 264, 914, 295, 439, 295, 613, 721, 13, 50941, 50941, 407, 300, 311, 264, 1151, 309, 393, 360, 13, 51073, 51073, 821, 390, 1524, 493, 589, 490, 4389, 48202, 88, 3322, 311, 1594, 294, 15682, 23967, 11, 597, 3031, 281, 1333, 295, 808, 51345, 51345, 493, 365, 3034, 1478, 8399, 2058, 378, 433, 13, 51447, 51447, 407, 291, 767, 632, 257, 48994, 7006, 293, 550, 291, 576, 362, 9521, 2017, 2144, 13, 51644, 51644, 407, 294, 3124, 11, 291, 393, 1936, 360, 11587, 411, 300, 13, 51816, 51816], "temperature": 0.0, "avg_logprob": -0.15449147791295617, "compression_ratio": 1.6888888888888889, "no_speech_prob": 2.5465191356488504e-05}, {"id": 362, "seek": 144218, "start": 1456.3600000000001, "end": 1461.8, "text": " There was follow up work from David Forsythe's group in UIUC, which tried to sort of come", "tokens": [50364, 407, 337, 1365, 11, 718, 311, 6552, 584, 291, 362, 257, 2594, 293, 300, 2594, 393, 4204, 2139, 294, 50595, 50595, 264, 2182, 11, 3344, 420, 3092, 4577, 13, 50693, 50693, 440, 3209, 576, 1333, 295, 6069, 300, 281, 312, 10855, 570, 731, 11, 286, 914, 11, 300, 311, 1333, 50859, 50859, 295, 264, 914, 295, 439, 295, 613, 721, 13, 50941, 50941, 407, 300, 311, 264, 1151, 309, 393, 360, 13, 51073, 51073, 821, 390, 1524, 493, 589, 490, 4389, 48202, 88, 3322, 311, 1594, 294, 15682, 23967, 11, 597, 3031, 281, 1333, 295, 808, 51345, 51345, 493, 365, 3034, 1478, 8399, 2058, 378, 433, 13, 51447, 51447, 407, 291, 767, 632, 257, 48994, 7006, 293, 550, 291, 576, 362, 9521, 2017, 2144, 13, 51644, 51644, 407, 294, 3124, 11, 291, 393, 1936, 360, 11587, 411, 300, 13, 51816, 51816], "temperature": 0.0, "avg_logprob": -0.15449147791295617, "compression_ratio": 1.6888888888888889, "no_speech_prob": 2.5465191356488504e-05}, {"id": 363, "seek": 144218, "start": 1461.8, "end": 1463.8400000000001, "text": " up with variational auto encoders.", "tokens": [50364, 407, 337, 1365, 11, 718, 311, 6552, 584, 291, 362, 257, 2594, 293, 300, 2594, 393, 4204, 2139, 294, 50595, 50595, 264, 2182, 11, 3344, 420, 3092, 4577, 13, 50693, 50693, 440, 3209, 576, 1333, 295, 6069, 300, 281, 312, 10855, 570, 731, 11, 286, 914, 11, 300, 311, 1333, 50859, 50859, 295, 264, 914, 295, 439, 295, 613, 721, 13, 50941, 50941, 407, 300, 311, 264, 1151, 309, 393, 360, 13, 51073, 51073, 821, 390, 1524, 493, 589, 490, 4389, 48202, 88, 3322, 311, 1594, 294, 15682, 23967, 11, 597, 3031, 281, 1333, 295, 808, 51345, 51345, 493, 365, 3034, 1478, 8399, 2058, 378, 433, 13, 51447, 51447, 407, 291, 767, 632, 257, 48994, 7006, 293, 550, 291, 576, 362, 9521, 2017, 2144, 13, 51644, 51644, 407, 294, 3124, 11, 291, 393, 1936, 360, 11587, 411, 300, 13, 51816, 51816], "temperature": 0.0, "avg_logprob": -0.15449147791295617, "compression_ratio": 1.6888888888888889, "no_speech_prob": 2.5465191356488504e-05}, {"id": 364, "seek": 144218, "start": 1463.8400000000001, "end": 1467.78, "text": " So you actually had a latent variable and then you would have diverse colorization.", "tokens": [50364, 407, 337, 1365, 11, 718, 311, 6552, 584, 291, 362, 257, 2594, 293, 300, 2594, 393, 4204, 2139, 294, 50595, 50595, 264, 2182, 11, 3344, 420, 3092, 4577, 13, 50693, 50693, 440, 3209, 576, 1333, 295, 6069, 300, 281, 312, 10855, 570, 731, 11, 286, 914, 11, 300, 311, 1333, 50859, 50859, 295, 264, 914, 295, 439, 295, 613, 721, 13, 50941, 50941, 407, 300, 311, 264, 1151, 309, 393, 360, 13, 51073, 51073, 821, 390, 1524, 493, 589, 490, 4389, 48202, 88, 3322, 311, 1594, 294, 15682, 23967, 11, 597, 3031, 281, 1333, 295, 808, 51345, 51345, 493, 365, 3034, 1478, 8399, 2058, 378, 433, 13, 51447, 51447, 407, 291, 767, 632, 257, 48994, 7006, 293, 550, 291, 576, 362, 9521, 2017, 2144, 13, 51644, 51644, 407, 294, 3124, 11, 291, 393, 1936, 360, 11587, 411, 300, 13, 51816, 51816], "temperature": 0.0, "avg_logprob": -0.15449147791295617, "compression_ratio": 1.6888888888888889, "no_speech_prob": 2.5465191356488504e-05}, {"id": 365, "seek": 144218, "start": 1467.78, "end": 1471.22, "text": " So in practice, you can basically do approaches like that.", "tokens": [50364, 407, 337, 1365, 11, 718, 311, 6552, 584, 291, 362, 257, 2594, 293, 300, 2594, 393, 4204, 2139, 294, 50595, 50595, 264, 2182, 11, 3344, 420, 3092, 4577, 13, 50693, 50693, 440, 3209, 576, 1333, 295, 6069, 300, 281, 312, 10855, 570, 731, 11, 286, 914, 11, 300, 311, 1333, 50859, 50859, 295, 264, 914, 295, 439, 295, 613, 721, 13, 50941, 50941, 407, 300, 311, 264, 1151, 309, 393, 360, 13, 51073, 51073, 821, 390, 1524, 493, 589, 490, 4389, 48202, 88, 3322, 311, 1594, 294, 15682, 23967, 11, 597, 3031, 281, 1333, 295, 808, 51345, 51345, 493, 365, 3034, 1478, 8399, 2058, 378, 433, 13, 51447, 51447, 407, 291, 767, 632, 257, 48994, 7006, 293, 550, 291, 576, 362, 9521, 2017, 2144, 13, 51644, 51644, 407, 294, 3124, 11, 291, 393, 1936, 360, 11587, 411, 300, 13, 51816, 51816], "temperature": 0.0, "avg_logprob": -0.15449147791295617, "compression_ratio": 1.6888888888888889, "no_speech_prob": 2.5465191356488504e-05}, {"id": 366, "seek": 147122, "start": 1471.22, "end": 1473.92, "text": " So you can actually have now a green colored ball.", "tokens": [50364, 407, 291, 393, 767, 362, 586, 257, 3092, 14332, 2594, 13, 50499, 50499, 400, 570, 291, 434, 884, 300, 337, 264, 2302, 4145, 11, 291, 393, 767, 362, 8398, 2017, 1109, 50650, 50650, 295, 264, 2302, 4145, 13, 50700, 50700, 865, 13, 50750, 50750, 663, 311, 437, 286, 519, 321, 600, 668, 1417, 365, 4956, 13, 50887, 50887, 14159, 321, 362, 411, 512, 18350, 300, 1709, 490, 472, 281, 867, 11, 550, 321, 820, 2826, 411, 51171, 51171, 257, 48994, 7006, 2316, 11, 597, 2089, 505, 281, 2826, 257, 3866, 3827, 2212, 300, 321, 362, 51402, 51402, 264, 912, 4846, 13, 51496, 51496, 1779, 13, 51546, 51546, 865, 13, 51663, 51663], "temperature": 0.0, "avg_logprob": -0.23956405167031078, "compression_ratio": 1.6956521739130435, "no_speech_prob": 1.9823466573143378e-05}, {"id": 367, "seek": 147122, "start": 1473.92, "end": 1476.94, "text": " And because you're doing that for the entire scene, you can actually have consistent colorings", "tokens": [50364, 407, 291, 393, 767, 362, 586, 257, 3092, 14332, 2594, 13, 50499, 50499, 400, 570, 291, 434, 884, 300, 337, 264, 2302, 4145, 11, 291, 393, 767, 362, 8398, 2017, 1109, 50650, 50650, 295, 264, 2302, 4145, 13, 50700, 50700, 865, 13, 50750, 50750, 663, 311, 437, 286, 519, 321, 600, 668, 1417, 365, 4956, 13, 50887, 50887, 14159, 321, 362, 411, 512, 18350, 300, 1709, 490, 472, 281, 867, 11, 550, 321, 820, 2826, 411, 51171, 51171, 257, 48994, 7006, 2316, 11, 597, 2089, 505, 281, 2826, 257, 3866, 3827, 2212, 300, 321, 362, 51402, 51402, 264, 912, 4846, 13, 51496, 51496, 1779, 13, 51546, 51546, 865, 13, 51663, 51663], "temperature": 0.0, "avg_logprob": -0.23956405167031078, "compression_ratio": 1.6956521739130435, "no_speech_prob": 1.9823466573143378e-05}, {"id": 368, "seek": 147122, "start": 1476.94, "end": 1477.94, "text": " of the entire scene.", "tokens": [50364, 407, 291, 393, 767, 362, 586, 257, 3092, 14332, 2594, 13, 50499, 50499, 400, 570, 291, 434, 884, 300, 337, 264, 2302, 4145, 11, 291, 393, 767, 362, 8398, 2017, 1109, 50650, 50650, 295, 264, 2302, 4145, 13, 50700, 50700, 865, 13, 50750, 50750, 663, 311, 437, 286, 519, 321, 600, 668, 1417, 365, 4956, 13, 50887, 50887, 14159, 321, 362, 411, 512, 18350, 300, 1709, 490, 472, 281, 867, 11, 550, 321, 820, 2826, 411, 51171, 51171, 257, 48994, 7006, 2316, 11, 597, 2089, 505, 281, 2826, 257, 3866, 3827, 2212, 300, 321, 362, 51402, 51402, 264, 912, 4846, 13, 51496, 51496, 1779, 13, 51546, 51546, 865, 13, 51663, 51663], "temperature": 0.0, "avg_logprob": -0.23956405167031078, "compression_ratio": 1.6956521739130435, "no_speech_prob": 1.9823466573143378e-05}, {"id": 369, "seek": 147122, "start": 1477.94, "end": 1478.94, "text": " Yeah.", "tokens": [50364, 407, 291, 393, 767, 362, 586, 257, 3092, 14332, 2594, 13, 50499, 50499, 400, 570, 291, 434, 884, 300, 337, 264, 2302, 4145, 11, 291, 393, 767, 362, 8398, 2017, 1109, 50650, 50650, 295, 264, 2302, 4145, 13, 50700, 50700, 865, 13, 50750, 50750, 663, 311, 437, 286, 519, 321, 600, 668, 1417, 365, 4956, 13, 50887, 50887, 14159, 321, 362, 411, 512, 18350, 300, 1709, 490, 472, 281, 867, 11, 550, 321, 820, 2826, 411, 51171, 51171, 257, 48994, 7006, 2316, 11, 597, 2089, 505, 281, 2826, 257, 3866, 3827, 2212, 300, 321, 362, 51402, 51402, 264, 912, 4846, 13, 51496, 51496, 1779, 13, 51546, 51546, 865, 13, 51663, 51663], "temperature": 0.0, "avg_logprob": -0.23956405167031078, "compression_ratio": 1.6956521739130435, "no_speech_prob": 1.9823466573143378e-05}, {"id": 370, "seek": 147122, "start": 1478.94, "end": 1481.68, "text": " That's what I think we've been talking with Jan.", "tokens": [50364, 407, 291, 393, 767, 362, 586, 257, 3092, 14332, 2594, 13, 50499, 50499, 400, 570, 291, 434, 884, 300, 337, 264, 2302, 4145, 11, 291, 393, 767, 362, 8398, 2017, 1109, 50650, 50650, 295, 264, 2302, 4145, 13, 50700, 50700, 865, 13, 50750, 50750, 663, 311, 437, 286, 519, 321, 600, 668, 1417, 365, 4956, 13, 50887, 50887, 14159, 321, 362, 411, 512, 18350, 300, 1709, 490, 472, 281, 867, 11, 550, 321, 820, 2826, 411, 51171, 51171, 257, 48994, 7006, 2316, 11, 597, 2089, 505, 281, 2826, 257, 3866, 3827, 2212, 300, 321, 362, 51402, 51402, 264, 912, 4846, 13, 51496, 51496, 1779, 13, 51546, 51546, 865, 13, 51663, 51663], "temperature": 0.0, "avg_logprob": -0.23956405167031078, "compression_ratio": 1.6956521739130435, "no_speech_prob": 1.9823466573143378e-05}, {"id": 371, "seek": 147122, "start": 1481.68, "end": 1487.3600000000001, "text": " Whenever we have like some mapping that goes from one to many, then we should choose like", "tokens": [50364, 407, 291, 393, 767, 362, 586, 257, 3092, 14332, 2594, 13, 50499, 50499, 400, 570, 291, 434, 884, 300, 337, 264, 2302, 4145, 11, 291, 393, 767, 362, 8398, 2017, 1109, 50650, 50650, 295, 264, 2302, 4145, 13, 50700, 50700, 865, 13, 50750, 50750, 663, 311, 437, 286, 519, 321, 600, 668, 1417, 365, 4956, 13, 50887, 50887, 14159, 321, 362, 411, 512, 18350, 300, 1709, 490, 472, 281, 867, 11, 550, 321, 820, 2826, 411, 51171, 51171, 257, 48994, 7006, 2316, 11, 597, 2089, 505, 281, 2826, 257, 3866, 3827, 2212, 300, 321, 362, 51402, 51402, 264, 912, 4846, 13, 51496, 51496, 1779, 13, 51546, 51546, 865, 13, 51663, 51663], "temperature": 0.0, "avg_logprob": -0.23956405167031078, "compression_ratio": 1.6956521739130435, "no_speech_prob": 1.9823466573143378e-05}, {"id": 372, "seek": 147122, "start": 1487.3600000000001, "end": 1491.98, "text": " a latent variable model, which allow us to choose a multiple solution given that we have", "tokens": [50364, 407, 291, 393, 767, 362, 586, 257, 3092, 14332, 2594, 13, 50499, 50499, 400, 570, 291, 434, 884, 300, 337, 264, 2302, 4145, 11, 291, 393, 767, 362, 8398, 2017, 1109, 50650, 50650, 295, 264, 2302, 4145, 13, 50700, 50700, 865, 13, 50750, 50750, 663, 311, 437, 286, 519, 321, 600, 668, 1417, 365, 4956, 13, 50887, 50887, 14159, 321, 362, 411, 512, 18350, 300, 1709, 490, 472, 281, 867, 11, 550, 321, 820, 2826, 411, 51171, 51171, 257, 48994, 7006, 2316, 11, 597, 2089, 505, 281, 2826, 257, 3866, 3827, 2212, 300, 321, 362, 51402, 51402, 264, 912, 4846, 13, 51496, 51496, 1779, 13, 51546, 51546, 865, 13, 51663, 51663], "temperature": 0.0, "avg_logprob": -0.23956405167031078, "compression_ratio": 1.6956521739130435, "no_speech_prob": 1.9823466573143378e-05}, {"id": 373, "seek": 147122, "start": 1491.98, "end": 1493.8600000000001, "text": " the same input.", "tokens": [50364, 407, 291, 393, 767, 362, 586, 257, 3092, 14332, 2594, 13, 50499, 50499, 400, 570, 291, 434, 884, 300, 337, 264, 2302, 4145, 11, 291, 393, 767, 362, 8398, 2017, 1109, 50650, 50650, 295, 264, 2302, 4145, 13, 50700, 50700, 865, 13, 50750, 50750, 663, 311, 437, 286, 519, 321, 600, 668, 1417, 365, 4956, 13, 50887, 50887, 14159, 321, 362, 411, 512, 18350, 300, 1709, 490, 472, 281, 867, 11, 550, 321, 820, 2826, 411, 51171, 51171, 257, 48994, 7006, 2316, 11, 597, 2089, 505, 281, 2826, 257, 3866, 3827, 2212, 300, 321, 362, 51402, 51402, 264, 912, 4846, 13, 51496, 51496, 1779, 13, 51546, 51546, 865, 13, 51663, 51663], "temperature": 0.0, "avg_logprob": -0.23956405167031078, "compression_ratio": 1.6956521739130435, "no_speech_prob": 1.9823466573143378e-05}, {"id": 374, "seek": 147122, "start": 1493.8600000000001, "end": 1494.8600000000001, "text": " Right.", "tokens": [50364, 407, 291, 393, 767, 362, 586, 257, 3092, 14332, 2594, 13, 50499, 50499, 400, 570, 291, 434, 884, 300, 337, 264, 2302, 4145, 11, 291, 393, 767, 362, 8398, 2017, 1109, 50650, 50650, 295, 264, 2302, 4145, 13, 50700, 50700, 865, 13, 50750, 50750, 663, 311, 437, 286, 519, 321, 600, 668, 1417, 365, 4956, 13, 50887, 50887, 14159, 321, 362, 411, 512, 18350, 300, 1709, 490, 472, 281, 867, 11, 550, 321, 820, 2826, 411, 51171, 51171, 257, 48994, 7006, 2316, 11, 597, 2089, 505, 281, 2826, 257, 3866, 3827, 2212, 300, 321, 362, 51402, 51402, 264, 912, 4846, 13, 51496, 51496, 1779, 13, 51546, 51546, 865, 13, 51663, 51663], "temperature": 0.0, "avg_logprob": -0.23956405167031078, "compression_ratio": 1.6956521739130435, "no_speech_prob": 1.9823466573143378e-05}, {"id": 375, "seek": 147122, "start": 1494.8600000000001, "end": 1497.2, "text": " Yeah.", "tokens": [50364, 407, 291, 393, 767, 362, 586, 257, 3092, 14332, 2594, 13, 50499, 50499, 400, 570, 291, 434, 884, 300, 337, 264, 2302, 4145, 11, 291, 393, 767, 362, 8398, 2017, 1109, 50650, 50650, 295, 264, 2302, 4145, 13, 50700, 50700, 865, 13, 50750, 50750, 663, 311, 437, 286, 519, 321, 600, 668, 1417, 365, 4956, 13, 50887, 50887, 14159, 321, 362, 411, 512, 18350, 300, 1709, 490, 472, 281, 867, 11, 550, 321, 820, 2826, 411, 51171, 51171, 257, 48994, 7006, 2316, 11, 597, 2089, 505, 281, 2826, 257, 3866, 3827, 2212, 300, 321, 362, 51402, 51402, 264, 912, 4846, 13, 51496, 51496, 1779, 13, 51546, 51546, 865, 13, 51663, 51663], "temperature": 0.0, "avg_logprob": -0.23956405167031078, "compression_ratio": 1.6956521739130435, "no_speech_prob": 1.9823466573143378e-05}, {"id": 376, "seek": 149720, "start": 1497.2, "end": 1503.64, "text": " So I think the reason why people did not really focus a lot on that particular aspect in this", "tokens": [50364, 407, 286, 519, 264, 1778, 983, 561, 630, 406, 534, 1879, 257, 688, 322, 300, 1729, 4171, 294, 341, 50686, 50686, 1389, 390, 412, 1935, 646, 294, 264, 786, 11, 472, 11, 309, 390, 406, 1850, 437, 390, 1364, 293, 437, 390, 50988, 50988, 406, 13, 51038, 51038, 400, 1150, 11, 341, 390, 920, 257, 659, 25111, 5633, 293, 561, 645, 406, 534, 5922, 466, 51228, 51228, 264, 2017, 2144, 3125, 13, 51298, 51298, 3432, 645, 544, 5922, 466, 264, 10290, 3125, 13, 51412, 51412, 583, 286, 519, 586, 257, 688, 295, 505, 1223, 300, 1293, 295, 552, 366, 6457, 1333, 295, 9601, 281, 472, 51660, 51660], "temperature": 0.0, "avg_logprob": -0.12452499144667879, "compression_ratio": 1.7943548387096775, "no_speech_prob": 4.683150473283604e-05}, {"id": 377, "seek": 149720, "start": 1503.64, "end": 1509.68, "text": " case was at least back in the day, one, it was not clear what was working and what was", "tokens": [50364, 407, 286, 519, 264, 1778, 983, 561, 630, 406, 534, 1879, 257, 688, 322, 300, 1729, 4171, 294, 341, 50686, 50686, 1389, 390, 412, 1935, 646, 294, 264, 786, 11, 472, 11, 309, 390, 406, 1850, 437, 390, 1364, 293, 437, 390, 50988, 50988, 406, 13, 51038, 51038, 400, 1150, 11, 341, 390, 920, 257, 659, 25111, 5633, 293, 561, 645, 406, 534, 5922, 466, 51228, 51228, 264, 2017, 2144, 3125, 13, 51298, 51298, 3432, 645, 544, 5922, 466, 264, 10290, 3125, 13, 51412, 51412, 583, 286, 519, 586, 257, 688, 295, 505, 1223, 300, 1293, 295, 552, 366, 6457, 1333, 295, 9601, 281, 472, 51660, 51660], "temperature": 0.0, "avg_logprob": -0.12452499144667879, "compression_ratio": 1.7943548387096775, "no_speech_prob": 4.683150473283604e-05}, {"id": 378, "seek": 149720, "start": 1509.68, "end": 1510.68, "text": " not.", "tokens": [50364, 407, 286, 519, 264, 1778, 983, 561, 630, 406, 534, 1879, 257, 688, 322, 300, 1729, 4171, 294, 341, 50686, 50686, 1389, 390, 412, 1935, 646, 294, 264, 786, 11, 472, 11, 309, 390, 406, 1850, 437, 390, 1364, 293, 437, 390, 50988, 50988, 406, 13, 51038, 51038, 400, 1150, 11, 341, 390, 920, 257, 659, 25111, 5633, 293, 561, 645, 406, 534, 5922, 466, 51228, 51228, 264, 2017, 2144, 3125, 13, 51298, 51298, 3432, 645, 544, 5922, 466, 264, 10290, 3125, 13, 51412, 51412, 583, 286, 519, 586, 257, 688, 295, 505, 1223, 300, 1293, 295, 552, 366, 6457, 1333, 295, 9601, 281, 472, 51660, 51660], "temperature": 0.0, "avg_logprob": -0.12452499144667879, "compression_ratio": 1.7943548387096775, "no_speech_prob": 4.683150473283604e-05}, {"id": 379, "seek": 149720, "start": 1510.68, "end": 1514.48, "text": " And second, this was still a pretext task and people were not really concerned about", "tokens": [50364, 407, 286, 519, 264, 1778, 983, 561, 630, 406, 534, 1879, 257, 688, 322, 300, 1729, 4171, 294, 341, 50686, 50686, 1389, 390, 412, 1935, 646, 294, 264, 786, 11, 472, 11, 309, 390, 406, 1850, 437, 390, 1364, 293, 437, 390, 50988, 50988, 406, 13, 51038, 51038, 400, 1150, 11, 341, 390, 920, 257, 659, 25111, 5633, 293, 561, 645, 406, 534, 5922, 466, 51228, 51228, 264, 2017, 2144, 3125, 13, 51298, 51298, 3432, 645, 544, 5922, 466, 264, 10290, 3125, 13, 51412, 51412, 583, 286, 519, 586, 257, 688, 295, 505, 1223, 300, 1293, 295, 552, 366, 6457, 1333, 295, 9601, 281, 472, 51660, 51660], "temperature": 0.0, "avg_logprob": -0.12452499144667879, "compression_ratio": 1.7943548387096775, "no_speech_prob": 4.683150473283604e-05}, {"id": 380, "seek": 149720, "start": 1514.48, "end": 1515.88, "text": " the colorization quality.", "tokens": [50364, 407, 286, 519, 264, 1778, 983, 561, 630, 406, 534, 1879, 257, 688, 322, 300, 1729, 4171, 294, 341, 50686, 50686, 1389, 390, 412, 1935, 646, 294, 264, 786, 11, 472, 11, 309, 390, 406, 1850, 437, 390, 1364, 293, 437, 390, 50988, 50988, 406, 13, 51038, 51038, 400, 1150, 11, 341, 390, 920, 257, 659, 25111, 5633, 293, 561, 645, 406, 534, 5922, 466, 51228, 51228, 264, 2017, 2144, 3125, 13, 51298, 51298, 3432, 645, 544, 5922, 466, 264, 10290, 3125, 13, 51412, 51412, 583, 286, 519, 586, 257, 688, 295, 505, 1223, 300, 1293, 295, 552, 366, 6457, 1333, 295, 9601, 281, 472, 51660, 51660], "temperature": 0.0, "avg_logprob": -0.12452499144667879, "compression_ratio": 1.7943548387096775, "no_speech_prob": 4.683150473283604e-05}, {"id": 381, "seek": 149720, "start": 1515.88, "end": 1518.16, "text": " People were more concerned about the representation quality.", "tokens": [50364, 407, 286, 519, 264, 1778, 983, 561, 630, 406, 534, 1879, 257, 688, 322, 300, 1729, 4171, 294, 341, 50686, 50686, 1389, 390, 412, 1935, 646, 294, 264, 786, 11, 472, 11, 309, 390, 406, 1850, 437, 390, 1364, 293, 437, 390, 50988, 50988, 406, 13, 51038, 51038, 400, 1150, 11, 341, 390, 920, 257, 659, 25111, 5633, 293, 561, 645, 406, 534, 5922, 466, 51228, 51228, 264, 2017, 2144, 3125, 13, 51298, 51298, 3432, 645, 544, 5922, 466, 264, 10290, 3125, 13, 51412, 51412, 583, 286, 519, 586, 257, 688, 295, 505, 1223, 300, 1293, 295, 552, 366, 6457, 1333, 295, 9601, 281, 472, 51660, 51660], "temperature": 0.0, "avg_logprob": -0.12452499144667879, "compression_ratio": 1.7943548387096775, "no_speech_prob": 4.683150473283604e-05}, {"id": 382, "seek": 149720, "start": 1518.16, "end": 1523.1200000000001, "text": " But I think now a lot of us understand that both of them are fairly sort of tied to one", "tokens": [50364, 407, 286, 519, 264, 1778, 983, 561, 630, 406, 534, 1879, 257, 688, 322, 300, 1729, 4171, 294, 341, 50686, 50686, 1389, 390, 412, 1935, 646, 294, 264, 786, 11, 472, 11, 309, 390, 406, 1850, 437, 390, 1364, 293, 437, 390, 50988, 50988, 406, 13, 51038, 51038, 400, 1150, 11, 341, 390, 920, 257, 659, 25111, 5633, 293, 561, 645, 406, 534, 5922, 466, 51228, 51228, 264, 2017, 2144, 3125, 13, 51298, 51298, 3432, 645, 544, 5922, 466, 264, 10290, 3125, 13, 51412, 51412, 583, 286, 519, 586, 257, 688, 295, 505, 1223, 300, 1293, 295, 552, 366, 6457, 1333, 295, 9601, 281, 472, 51660, 51660], "temperature": 0.0, "avg_logprob": -0.12452499144667879, "compression_ratio": 1.7943548387096775, "no_speech_prob": 4.683150473283604e-05}, {"id": 383, "seek": 152312, "start": 1523.12, "end": 1528.1999999999998, "text": " another, that you really need to have this sort of non-deterministic mapping to get something", "tokens": [50364, 1071, 11, 300, 291, 534, 643, 281, 362, 341, 1333, 295, 2107, 12, 49136, 259, 3142, 18350, 281, 483, 746, 50618, 50618, 544, 484, 295, 264, 1412, 13, 50692, 50692, 286, 536, 13, 50742, 50742, 2561, 13, 50792, 50792, 400, 2721, 11, 370, 341, 307, 11, 293, 286, 12328, 337, 341, 3036, 13, 51064, 51064, 467, 311, 490, 264, 3035, 13, 51114, 51114, 286, 519, 309, 390, 2295, 8669, 13, 51232, 51232, 583, 370, 341, 307, 1071, 5633, 11, 597, 307, 411, 4319, 8399, 2058, 378, 433, 13, 51402, 51402, 407, 264, 1558, 307, 1936, 26805, 1238, 709, 490, 584, 8725, 17, 303, 66, 13, 51615, 51615, 407, 291, 6479, 257, 1729, 644, 295, 264, 3256, 13, 51738, 51738], "temperature": 0.0, "avg_logprob": -0.2113651244108342, "compression_ratio": 1.569811320754717, "no_speech_prob": 4.22271432398702e-06}, {"id": 384, "seek": 152312, "start": 1528.1999999999998, "end": 1529.6799999999998, "text": " more out of the data.", "tokens": [50364, 1071, 11, 300, 291, 534, 643, 281, 362, 341, 1333, 295, 2107, 12, 49136, 259, 3142, 18350, 281, 483, 746, 50618, 50618, 544, 484, 295, 264, 1412, 13, 50692, 50692, 286, 536, 13, 50742, 50742, 2561, 13, 50792, 50792, 400, 2721, 11, 370, 341, 307, 11, 293, 286, 12328, 337, 341, 3036, 13, 51064, 51064, 467, 311, 490, 264, 3035, 13, 51114, 51114, 286, 519, 309, 390, 2295, 8669, 13, 51232, 51232, 583, 370, 341, 307, 1071, 5633, 11, 597, 307, 411, 4319, 8399, 2058, 378, 433, 13, 51402, 51402, 407, 264, 1558, 307, 1936, 26805, 1238, 709, 490, 584, 8725, 17, 303, 66, 13, 51615, 51615, 407, 291, 6479, 257, 1729, 644, 295, 264, 3256, 13, 51738, 51738], "temperature": 0.0, "avg_logprob": -0.2113651244108342, "compression_ratio": 1.569811320754717, "no_speech_prob": 4.22271432398702e-06}, {"id": 385, "seek": 152312, "start": 1529.6799999999998, "end": 1530.6799999999998, "text": " I see.", "tokens": [50364, 1071, 11, 300, 291, 534, 643, 281, 362, 341, 1333, 295, 2107, 12, 49136, 259, 3142, 18350, 281, 483, 746, 50618, 50618, 544, 484, 295, 264, 1412, 13, 50692, 50692, 286, 536, 13, 50742, 50742, 2561, 13, 50792, 50792, 400, 2721, 11, 370, 341, 307, 11, 293, 286, 12328, 337, 341, 3036, 13, 51064, 51064, 467, 311, 490, 264, 3035, 13, 51114, 51114, 286, 519, 309, 390, 2295, 8669, 13, 51232, 51232, 583, 370, 341, 307, 1071, 5633, 11, 597, 307, 411, 4319, 8399, 2058, 378, 433, 13, 51402, 51402, 407, 264, 1558, 307, 1936, 26805, 1238, 709, 490, 584, 8725, 17, 303, 66, 13, 51615, 51615, 407, 291, 6479, 257, 1729, 644, 295, 264, 3256, 13, 51738, 51738], "temperature": 0.0, "avg_logprob": -0.2113651244108342, "compression_ratio": 1.569811320754717, "no_speech_prob": 4.22271432398702e-06}, {"id": 386, "seek": 152312, "start": 1530.6799999999998, "end": 1531.6799999999998, "text": " Thanks.", "tokens": [50364, 1071, 11, 300, 291, 534, 643, 281, 362, 341, 1333, 295, 2107, 12, 49136, 259, 3142, 18350, 281, 483, 746, 50618, 50618, 544, 484, 295, 264, 1412, 13, 50692, 50692, 286, 536, 13, 50742, 50742, 2561, 13, 50792, 50792, 400, 2721, 11, 370, 341, 307, 11, 293, 286, 12328, 337, 341, 3036, 13, 51064, 51064, 467, 311, 490, 264, 3035, 13, 51114, 51114, 286, 519, 309, 390, 2295, 8669, 13, 51232, 51232, 583, 370, 341, 307, 1071, 5633, 11, 597, 307, 411, 4319, 8399, 2058, 378, 433, 13, 51402, 51402, 407, 264, 1558, 307, 1936, 26805, 1238, 709, 490, 584, 8725, 17, 303, 66, 13, 51615, 51615, 407, 291, 6479, 257, 1729, 644, 295, 264, 3256, 13, 51738, 51738], "temperature": 0.0, "avg_logprob": -0.2113651244108342, "compression_ratio": 1.569811320754717, "no_speech_prob": 4.22271432398702e-06}, {"id": 387, "seek": 152312, "start": 1531.6799999999998, "end": 1537.12, "text": " And finally, so this is, and I apologize for this picture.", "tokens": [50364, 1071, 11, 300, 291, 534, 643, 281, 362, 341, 1333, 295, 2107, 12, 49136, 259, 3142, 18350, 281, 483, 746, 50618, 50618, 544, 484, 295, 264, 1412, 13, 50692, 50692, 286, 536, 13, 50742, 50742, 2561, 13, 50792, 50792, 400, 2721, 11, 370, 341, 307, 11, 293, 286, 12328, 337, 341, 3036, 13, 51064, 51064, 467, 311, 490, 264, 3035, 13, 51114, 51114, 286, 519, 309, 390, 2295, 8669, 13, 51232, 51232, 583, 370, 341, 307, 1071, 5633, 11, 597, 307, 411, 4319, 8399, 2058, 378, 433, 13, 51402, 51402, 407, 264, 1558, 307, 1936, 26805, 1238, 709, 490, 584, 8725, 17, 303, 66, 13, 51615, 51615, 407, 291, 6479, 257, 1729, 644, 295, 264, 3256, 13, 51738, 51738], "temperature": 0.0, "avg_logprob": -0.2113651244108342, "compression_ratio": 1.569811320754717, "no_speech_prob": 4.22271432398702e-06}, {"id": 388, "seek": 152312, "start": 1537.12, "end": 1538.12, "text": " It's from the paper.", "tokens": [50364, 1071, 11, 300, 291, 534, 643, 281, 362, 341, 1333, 295, 2107, 12, 49136, 259, 3142, 18350, 281, 483, 746, 50618, 50618, 544, 484, 295, 264, 1412, 13, 50692, 50692, 286, 536, 13, 50742, 50742, 2561, 13, 50792, 50792, 400, 2721, 11, 370, 341, 307, 11, 293, 286, 12328, 337, 341, 3036, 13, 51064, 51064, 467, 311, 490, 264, 3035, 13, 51114, 51114, 286, 519, 309, 390, 2295, 8669, 13, 51232, 51232, 583, 370, 341, 307, 1071, 5633, 11, 597, 307, 411, 4319, 8399, 2058, 378, 433, 13, 51402, 51402, 407, 264, 1558, 307, 1936, 26805, 1238, 709, 490, 584, 8725, 17, 303, 66, 13, 51615, 51615, 407, 291, 6479, 257, 1729, 644, 295, 264, 3256, 13, 51738, 51738], "temperature": 0.0, "avg_logprob": -0.2113651244108342, "compression_ratio": 1.569811320754717, "no_speech_prob": 4.22271432398702e-06}, {"id": 389, "seek": 152312, "start": 1538.12, "end": 1540.4799999999998, "text": " I think it was low resolution.", "tokens": [50364, 1071, 11, 300, 291, 534, 643, 281, 362, 341, 1333, 295, 2107, 12, 49136, 259, 3142, 18350, 281, 483, 746, 50618, 50618, 544, 484, 295, 264, 1412, 13, 50692, 50692, 286, 536, 13, 50742, 50742, 2561, 13, 50792, 50792, 400, 2721, 11, 370, 341, 307, 11, 293, 286, 12328, 337, 341, 3036, 13, 51064, 51064, 467, 311, 490, 264, 3035, 13, 51114, 51114, 286, 519, 309, 390, 2295, 8669, 13, 51232, 51232, 583, 370, 341, 307, 1071, 5633, 11, 597, 307, 411, 4319, 8399, 2058, 378, 433, 13, 51402, 51402, 407, 264, 1558, 307, 1936, 26805, 1238, 709, 490, 584, 8725, 17, 303, 66, 13, 51615, 51615, 407, 291, 6479, 257, 1729, 644, 295, 264, 3256, 13, 51738, 51738], "temperature": 0.0, "avg_logprob": -0.2113651244108342, "compression_ratio": 1.569811320754717, "no_speech_prob": 4.22271432398702e-06}, {"id": 390, "seek": 152312, "start": 1540.4799999999998, "end": 1543.8799999999999, "text": " But so this is another task, which is like context auto encoders.", "tokens": [50364, 1071, 11, 300, 291, 534, 643, 281, 362, 341, 1333, 295, 2107, 12, 49136, 259, 3142, 18350, 281, 483, 746, 50618, 50618, 544, 484, 295, 264, 1412, 13, 50692, 50692, 286, 536, 13, 50742, 50742, 2561, 13, 50792, 50792, 400, 2721, 11, 370, 341, 307, 11, 293, 286, 12328, 337, 341, 3036, 13, 51064, 51064, 467, 311, 490, 264, 3035, 13, 51114, 51114, 286, 519, 309, 390, 2295, 8669, 13, 51232, 51232, 583, 370, 341, 307, 1071, 5633, 11, 597, 307, 411, 4319, 8399, 2058, 378, 433, 13, 51402, 51402, 407, 264, 1558, 307, 1936, 26805, 1238, 709, 490, 584, 8725, 17, 303, 66, 13, 51615, 51615, 407, 291, 6479, 257, 1729, 644, 295, 264, 3256, 13, 51738, 51738], "temperature": 0.0, "avg_logprob": -0.2113651244108342, "compression_ratio": 1.569811320754717, "no_speech_prob": 4.22271432398702e-06}, {"id": 391, "seek": 152312, "start": 1543.8799999999999, "end": 1548.1399999999999, "text": " So the idea is basically borrowed pretty much from say Word2vec.", "tokens": [50364, 1071, 11, 300, 291, 534, 643, 281, 362, 341, 1333, 295, 2107, 12, 49136, 259, 3142, 18350, 281, 483, 746, 50618, 50618, 544, 484, 295, 264, 1412, 13, 50692, 50692, 286, 536, 13, 50742, 50742, 2561, 13, 50792, 50792, 400, 2721, 11, 370, 341, 307, 11, 293, 286, 12328, 337, 341, 3036, 13, 51064, 51064, 467, 311, 490, 264, 3035, 13, 51114, 51114, 286, 519, 309, 390, 2295, 8669, 13, 51232, 51232, 583, 370, 341, 307, 1071, 5633, 11, 597, 307, 411, 4319, 8399, 2058, 378, 433, 13, 51402, 51402, 407, 264, 1558, 307, 1936, 26805, 1238, 709, 490, 584, 8725, 17, 303, 66, 13, 51615, 51615, 407, 291, 6479, 257, 1729, 644, 295, 264, 3256, 13, 51738, 51738], "temperature": 0.0, "avg_logprob": -0.2113651244108342, "compression_ratio": 1.569811320754717, "no_speech_prob": 4.22271432398702e-06}, {"id": 392, "seek": 152312, "start": 1548.1399999999999, "end": 1550.6, "text": " So you hide a particular part of the image.", "tokens": [50364, 1071, 11, 300, 291, 534, 643, 281, 362, 341, 1333, 295, 2107, 12, 49136, 259, 3142, 18350, 281, 483, 746, 50618, 50618, 544, 484, 295, 264, 1412, 13, 50692, 50692, 286, 536, 13, 50742, 50742, 2561, 13, 50792, 50792, 400, 2721, 11, 370, 341, 307, 11, 293, 286, 12328, 337, 341, 3036, 13, 51064, 51064, 467, 311, 490, 264, 3035, 13, 51114, 51114, 286, 519, 309, 390, 2295, 8669, 13, 51232, 51232, 583, 370, 341, 307, 1071, 5633, 11, 597, 307, 411, 4319, 8399, 2058, 378, 433, 13, 51402, 51402, 407, 264, 1558, 307, 1936, 26805, 1238, 709, 490, 584, 8725, 17, 303, 66, 13, 51615, 51615, 407, 291, 6479, 257, 1729, 644, 295, 264, 3256, 13, 51738, 51738], "temperature": 0.0, "avg_logprob": -0.2113651244108342, "compression_ratio": 1.569811320754717, "no_speech_prob": 4.22271432398702e-06}, {"id": 393, "seek": 155060, "start": 1550.6, "end": 1554.8799999999999, "text": " And now given the surrounding part of the image, you need to predict what was hidden.", "tokens": [50364, 400, 586, 2212, 264, 11498, 644, 295, 264, 3256, 11, 291, 643, 281, 6069, 437, 390, 7633, 13, 50578, 50578, 407, 309, 311, 534, 1333, 295, 264, 2836, 294, 264, 8247, 82, 5633, 13, 50828, 50828, 400, 983, 820, 341, 589, 30, 50910, 50910, 1042, 11, 309, 311, 412, 1935, 1382, 281, 1778, 466, 437, 6565, 366, 1974, 13, 51108, 51108, 407, 5163, 393, 1190, 322, 264, 11344, 420, 411, 7446, 366, 1936, 4603, 295, 411, 9309, 293, 51434, 51434, 4966, 281, 264, 2727, 13, 51484, 51484, 814, 434, 3442, 281, 362, 8077, 293, 370, 322, 13, 51576, 51576, 407, 309, 2203, 281, 1466, 746, 544, 466, 411, 264, 26947, 3877, 295, 264, 1412, 538, 51808, 51808], "temperature": 0.0, "avg_logprob": -0.12000359607343915, "compression_ratio": 1.6666666666666667, "no_speech_prob": 5.014564976590918e-06}, {"id": 394, "seek": 155060, "start": 1554.8799999999999, "end": 1559.8799999999999, "text": " So it's really sort of the fill in the blanks task.", "tokens": [50364, 400, 586, 2212, 264, 11498, 644, 295, 264, 3256, 11, 291, 643, 281, 6069, 437, 390, 7633, 13, 50578, 50578, 407, 309, 311, 534, 1333, 295, 264, 2836, 294, 264, 8247, 82, 5633, 13, 50828, 50828, 400, 983, 820, 341, 589, 30, 50910, 50910, 1042, 11, 309, 311, 412, 1935, 1382, 281, 1778, 466, 437, 6565, 366, 1974, 13, 51108, 51108, 407, 5163, 393, 1190, 322, 264, 11344, 420, 411, 7446, 366, 1936, 4603, 295, 411, 9309, 293, 51434, 51434, 4966, 281, 264, 2727, 13, 51484, 51484, 814, 434, 3442, 281, 362, 8077, 293, 370, 322, 13, 51576, 51576, 407, 309, 2203, 281, 1466, 746, 544, 466, 411, 264, 26947, 3877, 295, 264, 1412, 538, 51808, 51808], "temperature": 0.0, "avg_logprob": -0.12000359607343915, "compression_ratio": 1.6666666666666667, "no_speech_prob": 5.014564976590918e-06}, {"id": 395, "seek": 155060, "start": 1559.8799999999999, "end": 1561.52, "text": " And why should this work?", "tokens": [50364, 400, 586, 2212, 264, 11498, 644, 295, 264, 3256, 11, 291, 643, 281, 6069, 437, 390, 7633, 13, 50578, 50578, 407, 309, 311, 534, 1333, 295, 264, 2836, 294, 264, 8247, 82, 5633, 13, 50828, 50828, 400, 983, 820, 341, 589, 30, 50910, 50910, 1042, 11, 309, 311, 412, 1935, 1382, 281, 1778, 466, 437, 6565, 366, 1974, 13, 51108, 51108, 407, 5163, 393, 1190, 322, 264, 11344, 420, 411, 7446, 366, 1936, 4603, 295, 411, 9309, 293, 51434, 51434, 4966, 281, 264, 2727, 13, 51484, 51484, 814, 434, 3442, 281, 362, 8077, 293, 370, 322, 13, 51576, 51576, 407, 309, 2203, 281, 1466, 746, 544, 466, 411, 264, 26947, 3877, 295, 264, 1412, 538, 51808, 51808], "temperature": 0.0, "avg_logprob": -0.12000359607343915, "compression_ratio": 1.6666666666666667, "no_speech_prob": 5.014564976590918e-06}, {"id": 396, "seek": 155060, "start": 1561.52, "end": 1565.48, "text": " Well, it's at least trying to reason about what objects are present.", "tokens": [50364, 400, 586, 2212, 264, 11498, 644, 295, 264, 3256, 11, 291, 643, 281, 6069, 437, 390, 7633, 13, 50578, 50578, 407, 309, 311, 534, 1333, 295, 264, 2836, 294, 264, 8247, 82, 5633, 13, 50828, 50828, 400, 983, 820, 341, 589, 30, 50910, 50910, 1042, 11, 309, 311, 412, 1935, 1382, 281, 1778, 466, 437, 6565, 366, 1974, 13, 51108, 51108, 407, 5163, 393, 1190, 322, 264, 11344, 420, 411, 7446, 366, 1936, 4603, 295, 411, 9309, 293, 51434, 51434, 4966, 281, 264, 2727, 13, 51484, 51484, 814, 434, 3442, 281, 362, 8077, 293, 370, 322, 13, 51576, 51576, 407, 309, 2203, 281, 1466, 746, 544, 466, 411, 264, 26947, 3877, 295, 264, 1412, 538, 51808, 51808], "temperature": 0.0, "avg_logprob": -0.12000359607343915, "compression_ratio": 1.6666666666666667, "no_speech_prob": 5.014564976590918e-06}, {"id": 397, "seek": 155060, "start": 1565.48, "end": 1572.0, "text": " So cars can run on the roads or like buildings are basically consist of like windows and", "tokens": [50364, 400, 586, 2212, 264, 11498, 644, 295, 264, 3256, 11, 291, 643, 281, 6069, 437, 390, 7633, 13, 50578, 50578, 407, 309, 311, 534, 1333, 295, 264, 2836, 294, 264, 8247, 82, 5633, 13, 50828, 50828, 400, 983, 820, 341, 589, 30, 50910, 50910, 1042, 11, 309, 311, 412, 1935, 1382, 281, 1778, 466, 437, 6565, 366, 1974, 13, 51108, 51108, 407, 5163, 393, 1190, 322, 264, 11344, 420, 411, 7446, 366, 1936, 4603, 295, 411, 9309, 293, 51434, 51434, 4966, 281, 264, 2727, 13, 51484, 51484, 814, 434, 3442, 281, 362, 8077, 293, 370, 322, 13, 51576, 51576, 407, 309, 2203, 281, 1466, 746, 544, 466, 411, 264, 26947, 3877, 295, 264, 1412, 538, 51808, 51808], "temperature": 0.0, "avg_logprob": -0.12000359607343915, "compression_ratio": 1.6666666666666667, "no_speech_prob": 5.014564976590918e-06}, {"id": 398, "seek": 155060, "start": 1572.0, "end": 1573.0, "text": " closer to the ground.", "tokens": [50364, 400, 586, 2212, 264, 11498, 644, 295, 264, 3256, 11, 291, 643, 281, 6069, 437, 390, 7633, 13, 50578, 50578, 407, 309, 311, 534, 1333, 295, 264, 2836, 294, 264, 8247, 82, 5633, 13, 50828, 50828, 400, 983, 820, 341, 589, 30, 50910, 50910, 1042, 11, 309, 311, 412, 1935, 1382, 281, 1778, 466, 437, 6565, 366, 1974, 13, 51108, 51108, 407, 5163, 393, 1190, 322, 264, 11344, 420, 411, 7446, 366, 1936, 4603, 295, 411, 9309, 293, 51434, 51434, 4966, 281, 264, 2727, 13, 51484, 51484, 814, 434, 3442, 281, 362, 8077, 293, 370, 322, 13, 51576, 51576, 407, 309, 2203, 281, 1466, 746, 544, 466, 411, 264, 26947, 3877, 295, 264, 1412, 538, 51808, 51808], "temperature": 0.0, "avg_logprob": -0.12000359607343915, "compression_ratio": 1.6666666666666667, "no_speech_prob": 5.014564976590918e-06}, {"id": 399, "seek": 155060, "start": 1573.0, "end": 1574.84, "text": " They're supposed to have doors and so on.", "tokens": [50364, 400, 586, 2212, 264, 11498, 644, 295, 264, 3256, 11, 291, 643, 281, 6069, 437, 390, 7633, 13, 50578, 50578, 407, 309, 311, 534, 1333, 295, 264, 2836, 294, 264, 8247, 82, 5633, 13, 50828, 50828, 400, 983, 820, 341, 589, 30, 50910, 50910, 1042, 11, 309, 311, 412, 1935, 1382, 281, 1778, 466, 437, 6565, 366, 1974, 13, 51108, 51108, 407, 5163, 393, 1190, 322, 264, 11344, 420, 411, 7446, 366, 1936, 4603, 295, 411, 9309, 293, 51434, 51434, 4966, 281, 264, 2727, 13, 51484, 51484, 814, 434, 3442, 281, 362, 8077, 293, 370, 322, 13, 51576, 51576, 407, 309, 2203, 281, 1466, 746, 544, 466, 411, 264, 26947, 3877, 295, 264, 1412, 538, 51808, 51808], "temperature": 0.0, "avg_logprob": -0.12000359607343915, "compression_ratio": 1.6666666666666667, "no_speech_prob": 5.014564976590918e-06}, {"id": 400, "seek": 155060, "start": 1574.84, "end": 1579.48, "text": " So it needs to learn something more about like the implicit structure of the data by", "tokens": [50364, 400, 586, 2212, 264, 11498, 644, 295, 264, 3256, 11, 291, 643, 281, 6069, 437, 390, 7633, 13, 50578, 50578, 407, 309, 311, 534, 1333, 295, 264, 2836, 294, 264, 8247, 82, 5633, 13, 50828, 50828, 400, 983, 820, 341, 589, 30, 50910, 50910, 1042, 11, 309, 311, 412, 1935, 1382, 281, 1778, 466, 437, 6565, 366, 1974, 13, 51108, 51108, 407, 5163, 393, 1190, 322, 264, 11344, 420, 411, 7446, 366, 1936, 4603, 295, 411, 9309, 293, 51434, 51434, 4966, 281, 264, 2727, 13, 51484, 51484, 814, 434, 3442, 281, 362, 8077, 293, 370, 322, 13, 51576, 51576, 407, 309, 2203, 281, 1466, 746, 544, 466, 411, 264, 26947, 3877, 295, 264, 1412, 538, 51808, 51808], "temperature": 0.0, "avg_logprob": -0.12000359607343915, "compression_ratio": 1.6666666666666667, "no_speech_prob": 5.014564976590918e-06}, {"id": 401, "seek": 157948, "start": 1579.48, "end": 1583.24, "text": " performing this task.", "tokens": [50364, 10205, 341, 5633, 13, 50552, 50552, 407, 341, 390, 445, 466, 5267, 13, 50700, 50700, 400, 586, 286, 603, 1333, 295, 751, 466, 437, 366, 264, 661, 9608, 300, 291, 393, 360, 294, 960, 13, 50982, 50982, 407, 294, 960, 11, 264, 1333, 295, 2135, 4009, 295, 32675, 307, 341, 10710, 295, 42881, 507, 295, 12083, 13, 51393, 51393, 407, 12083, 1936, 362, 364, 26387, 1668, 294, 552, 13, 51576, 51576, 400, 291, 528, 281, 1333, 295, 764, 300, 1668, 281, 483, 746, 13, 51734, 51734], "temperature": 0.0, "avg_logprob": -0.09370703046972101, "compression_ratio": 1.6376811594202898, "no_speech_prob": 1.028916085488163e-05}, {"id": 402, "seek": 157948, "start": 1583.24, "end": 1586.2, "text": " So this was just about images.", "tokens": [50364, 10205, 341, 5633, 13, 50552, 50552, 407, 341, 390, 445, 466, 5267, 13, 50700, 50700, 400, 586, 286, 603, 1333, 295, 751, 466, 437, 366, 264, 661, 9608, 300, 291, 393, 360, 294, 960, 13, 50982, 50982, 407, 294, 960, 11, 264, 1333, 295, 2135, 4009, 295, 32675, 307, 341, 10710, 295, 42881, 507, 295, 12083, 13, 51393, 51393, 407, 12083, 1936, 362, 364, 26387, 1668, 294, 552, 13, 51576, 51576, 400, 291, 528, 281, 1333, 295, 764, 300, 1668, 281, 483, 746, 13, 51734, 51734], "temperature": 0.0, "avg_logprob": -0.09370703046972101, "compression_ratio": 1.6376811594202898, "no_speech_prob": 1.028916085488163e-05}, {"id": 403, "seek": 157948, "start": 1586.2, "end": 1591.84, "text": " And now I'll sort of talk about what are the other tasks that you can do in video.", "tokens": [50364, 10205, 341, 5633, 13, 50552, 50552, 407, 341, 390, 445, 466, 5267, 13, 50700, 50700, 400, 586, 286, 603, 1333, 295, 751, 466, 437, 366, 264, 661, 9608, 300, 291, 393, 360, 294, 960, 13, 50982, 50982, 407, 294, 960, 11, 264, 1333, 295, 2135, 4009, 295, 32675, 307, 341, 10710, 295, 42881, 507, 295, 12083, 13, 51393, 51393, 407, 12083, 1936, 362, 364, 26387, 1668, 294, 552, 13, 51576, 51576, 400, 291, 528, 281, 1333, 295, 764, 300, 1668, 281, 483, 746, 13, 51734, 51734], "temperature": 0.0, "avg_logprob": -0.09370703046972101, "compression_ratio": 1.6376811594202898, "no_speech_prob": 1.028916085488163e-05}, {"id": 404, "seek": 157948, "start": 1591.84, "end": 1600.06, "text": " So in video, the sort of main source of supervision is this notion of sequentiality of frames.", "tokens": [50364, 10205, 341, 5633, 13, 50552, 50552, 407, 341, 390, 445, 466, 5267, 13, 50700, 50700, 400, 586, 286, 603, 1333, 295, 751, 466, 437, 366, 264, 661, 9608, 300, 291, 393, 360, 294, 960, 13, 50982, 50982, 407, 294, 960, 11, 264, 1333, 295, 2135, 4009, 295, 32675, 307, 341, 10710, 295, 42881, 507, 295, 12083, 13, 51393, 51393, 407, 12083, 1936, 362, 364, 26387, 1668, 294, 552, 13, 51576, 51576, 400, 291, 528, 281, 1333, 295, 764, 300, 1668, 281, 483, 746, 13, 51734, 51734], "temperature": 0.0, "avg_logprob": -0.09370703046972101, "compression_ratio": 1.6376811594202898, "no_speech_prob": 1.028916085488163e-05}, {"id": 405, "seek": 157948, "start": 1600.06, "end": 1603.72, "text": " So frames basically have an inherent order in them.", "tokens": [50364, 10205, 341, 5633, 13, 50552, 50552, 407, 341, 390, 445, 466, 5267, 13, 50700, 50700, 400, 586, 286, 603, 1333, 295, 751, 466, 437, 366, 264, 661, 9608, 300, 291, 393, 360, 294, 960, 13, 50982, 50982, 407, 294, 960, 11, 264, 1333, 295, 2135, 4009, 295, 32675, 307, 341, 10710, 295, 42881, 507, 295, 12083, 13, 51393, 51393, 407, 12083, 1936, 362, 364, 26387, 1668, 294, 552, 13, 51576, 51576, 400, 291, 528, 281, 1333, 295, 764, 300, 1668, 281, 483, 746, 13, 51734, 51734], "temperature": 0.0, "avg_logprob": -0.09370703046972101, "compression_ratio": 1.6376811594202898, "no_speech_prob": 1.028916085488163e-05}, {"id": 406, "seek": 157948, "start": 1603.72, "end": 1606.88, "text": " And you want to sort of use that order to get something.", "tokens": [50364, 10205, 341, 5633, 13, 50552, 50552, 407, 341, 390, 445, 466, 5267, 13, 50700, 50700, 400, 586, 286, 603, 1333, 295, 751, 466, 437, 366, 264, 661, 9608, 300, 291, 393, 360, 294, 960, 13, 50982, 50982, 407, 294, 960, 11, 264, 1333, 295, 2135, 4009, 295, 32675, 307, 341, 10710, 295, 42881, 507, 295, 12083, 13, 51393, 51393, 407, 12083, 1936, 362, 364, 26387, 1668, 294, 552, 13, 51576, 51576, 400, 291, 528, 281, 1333, 295, 764, 300, 1668, 281, 483, 746, 13, 51734, 51734], "temperature": 0.0, "avg_logprob": -0.09370703046972101, "compression_ratio": 1.6376811594202898, "no_speech_prob": 1.028916085488163e-05}, {"id": 407, "seek": 160688, "start": 1606.88, "end": 1611.2800000000002, "text": " For example, say predict the order of frames or fill in the blanks and a bunch of sort", "tokens": [50364, 1171, 1365, 11, 584, 6069, 264, 1668, 295, 12083, 420, 2836, 294, 264, 8247, 82, 293, 257, 3840, 295, 1333, 50584, 50584, 295, 661, 659, 25111, 9608, 300, 366, 439, 12334, 322, 42881, 3687, 13, 50792, 50792, 407, 510, 286, 603, 1333, 295, 751, 466, 472, 295, 264, 1985, 300, 286, 630, 294, 6549, 11, 597, 390, 466, 51108, 51108, 32884, 264, 8219, 379, 3006, 420, 18424, 1668, 295, 12083, 13, 51316, 51316, 639, 307, 588, 709, 7547, 490, 3071, 589, 300, 13633, 293, 1936, 2357, 630, 322, 1333, 51565, 51565, 295, 42881, 21739, 295, 12083, 807, 8712, 488, 2539, 13, 51748, 51748], "temperature": 0.0, "avg_logprob": -0.1259247825259254, "compression_ratio": 1.6902985074626866, "no_speech_prob": 1.1300087862764485e-05}, {"id": 408, "seek": 160688, "start": 1611.2800000000002, "end": 1615.44, "text": " of other pretext tasks that are all dependent on sequential nature.", "tokens": [50364, 1171, 1365, 11, 584, 6069, 264, 1668, 295, 12083, 420, 2836, 294, 264, 8247, 82, 293, 257, 3840, 295, 1333, 50584, 50584, 295, 661, 659, 25111, 9608, 300, 366, 439, 12334, 322, 42881, 3687, 13, 50792, 50792, 407, 510, 286, 603, 1333, 295, 751, 466, 472, 295, 264, 1985, 300, 286, 630, 294, 6549, 11, 597, 390, 466, 51108, 51108, 32884, 264, 8219, 379, 3006, 420, 18424, 1668, 295, 12083, 13, 51316, 51316, 639, 307, 588, 709, 7547, 490, 3071, 589, 300, 13633, 293, 1936, 2357, 630, 322, 1333, 51565, 51565, 295, 42881, 21739, 295, 12083, 807, 8712, 488, 2539, 13, 51748, 51748], "temperature": 0.0, "avg_logprob": -0.1259247825259254, "compression_ratio": 1.6902985074626866, "no_speech_prob": 1.1300087862764485e-05}, {"id": 409, "seek": 160688, "start": 1615.44, "end": 1621.7600000000002, "text": " So here I'll sort of talk about one of the works that I did in 2016, which was about", "tokens": [50364, 1171, 1365, 11, 584, 6069, 264, 1668, 295, 12083, 420, 2836, 294, 264, 8247, 82, 293, 257, 3840, 295, 1333, 50584, 50584, 295, 661, 659, 25111, 9608, 300, 366, 439, 12334, 322, 42881, 3687, 13, 50792, 50792, 407, 510, 286, 603, 1333, 295, 751, 466, 472, 295, 264, 1985, 300, 286, 630, 294, 6549, 11, 597, 390, 466, 51108, 51108, 32884, 264, 8219, 379, 3006, 420, 18424, 1668, 295, 12083, 13, 51316, 51316, 639, 307, 588, 709, 7547, 490, 3071, 589, 300, 13633, 293, 1936, 2357, 630, 322, 1333, 51565, 51565, 295, 42881, 21739, 295, 12083, 807, 8712, 488, 2539, 13, 51748, 51748], "temperature": 0.0, "avg_logprob": -0.1259247825259254, "compression_ratio": 1.6902985074626866, "no_speech_prob": 1.1300087862764485e-05}, {"id": 410, "seek": 160688, "start": 1621.7600000000002, "end": 1625.92, "text": " predicting the temporally correct or incorrect order of frames.", "tokens": [50364, 1171, 1365, 11, 584, 6069, 264, 1668, 295, 12083, 420, 2836, 294, 264, 8247, 82, 293, 257, 3840, 295, 1333, 50584, 50584, 295, 661, 659, 25111, 9608, 300, 366, 439, 12334, 322, 42881, 3687, 13, 50792, 50792, 407, 510, 286, 603, 1333, 295, 751, 466, 472, 295, 264, 1985, 300, 286, 630, 294, 6549, 11, 597, 390, 466, 51108, 51108, 32884, 264, 8219, 379, 3006, 420, 18424, 1668, 295, 12083, 13, 51316, 51316, 639, 307, 588, 709, 7547, 490, 3071, 589, 300, 13633, 293, 1936, 2357, 630, 322, 1333, 51565, 51565, 295, 42881, 21739, 295, 12083, 807, 8712, 488, 2539, 13, 51748, 51748], "temperature": 0.0, "avg_logprob": -0.1259247825259254, "compression_ratio": 1.6902985074626866, "no_speech_prob": 1.1300087862764485e-05}, {"id": 411, "seek": 160688, "start": 1625.92, "end": 1630.9, "text": " This is very much inspired from earlier work that Yan and basically others did on sort", "tokens": [50364, 1171, 1365, 11, 584, 6069, 264, 1668, 295, 12083, 420, 2836, 294, 264, 8247, 82, 293, 257, 3840, 295, 1333, 50584, 50584, 295, 661, 659, 25111, 9608, 300, 366, 439, 12334, 322, 42881, 3687, 13, 50792, 50792, 407, 510, 286, 603, 1333, 295, 751, 466, 472, 295, 264, 1985, 300, 286, 630, 294, 6549, 11, 597, 390, 466, 51108, 51108, 32884, 264, 8219, 379, 3006, 420, 18424, 1668, 295, 12083, 13, 51316, 51316, 639, 307, 588, 709, 7547, 490, 3071, 589, 300, 13633, 293, 1936, 2357, 630, 322, 1333, 51565, 51565, 295, 42881, 21739, 295, 12083, 807, 8712, 488, 2539, 13, 51748, 51748], "temperature": 0.0, "avg_logprob": -0.1259247825259254, "compression_ratio": 1.6902985074626866, "no_speech_prob": 1.1300087862764485e-05}, {"id": 412, "seek": 160688, "start": 1630.9, "end": 1634.5600000000002, "text": " of sequential ordering of frames through contrastive learning.", "tokens": [50364, 1171, 1365, 11, 584, 6069, 264, 1668, 295, 12083, 420, 2836, 294, 264, 8247, 82, 293, 257, 3840, 295, 1333, 50584, 50584, 295, 661, 659, 25111, 9608, 300, 366, 439, 12334, 322, 42881, 3687, 13, 50792, 50792, 407, 510, 286, 603, 1333, 295, 751, 466, 472, 295, 264, 1985, 300, 286, 630, 294, 6549, 11, 597, 390, 466, 51108, 51108, 32884, 264, 8219, 379, 3006, 420, 18424, 1668, 295, 12083, 13, 51316, 51316, 639, 307, 588, 709, 7547, 490, 3071, 589, 300, 13633, 293, 1936, 2357, 630, 322, 1333, 51565, 51565, 295, 42881, 21739, 295, 12083, 807, 8712, 488, 2539, 13, 51748, 51748], "temperature": 0.0, "avg_logprob": -0.1259247825259254, "compression_ratio": 1.6902985074626866, "no_speech_prob": 1.1300087862764485e-05}, {"id": 413, "seek": 163456, "start": 1634.56, "end": 1639.6, "text": " And I'll talk about those towards the end when I actually talk about contrastive learning.", "tokens": [50364, 400, 286, 603, 751, 466, 729, 3030, 264, 917, 562, 286, 767, 751, 466, 8712, 488, 2539, 13, 50616, 50616, 407, 294, 341, 1729, 589, 11, 321, 645, 588, 709, 7547, 538, 411, 264, 659, 25111, 9608, 797, 13, 50898, 50898, 400, 321, 5039, 257, 17434, 21538, 1154, 13, 51064, 51064, 407, 2212, 257, 3840, 295, 12083, 11, 321, 8947, 1045, 12083, 13, 51202, 51202, 400, 498, 321, 8947, 552, 294, 264, 558, 1668, 11, 321, 7645, 552, 1804, 472, 13, 51434, 51434, 400, 498, 321, 39426, 552, 11, 1936, 321, 7645, 552, 382, 4018, 13, 51586, 51586, 400, 370, 586, 321, 643, 281, 5039, 257, 17434, 21538, 1154, 281, 6069, 1968, 746, 307, 402, 33974, 51792, 51792], "temperature": 0.0, "avg_logprob": -0.09538784027099609, "compression_ratio": 1.8455882352941178, "no_speech_prob": 1.7602502566660405e-06}, {"id": 414, "seek": 163456, "start": 1639.6, "end": 1645.24, "text": " So in this particular work, we were very much inspired by like the pretext tasks again.", "tokens": [50364, 400, 286, 603, 751, 466, 729, 3030, 264, 917, 562, 286, 767, 751, 466, 8712, 488, 2539, 13, 50616, 50616, 407, 294, 341, 1729, 589, 11, 321, 645, 588, 709, 7547, 538, 411, 264, 659, 25111, 9608, 797, 13, 50898, 50898, 400, 321, 5039, 257, 17434, 21538, 1154, 13, 51064, 51064, 407, 2212, 257, 3840, 295, 12083, 11, 321, 8947, 1045, 12083, 13, 51202, 51202, 400, 498, 321, 8947, 552, 294, 264, 558, 1668, 11, 321, 7645, 552, 1804, 472, 13, 51434, 51434, 400, 498, 321, 39426, 552, 11, 1936, 321, 7645, 552, 382, 4018, 13, 51586, 51586, 400, 370, 586, 321, 643, 281, 5039, 257, 17434, 21538, 1154, 281, 6069, 1968, 746, 307, 402, 33974, 51792, 51792], "temperature": 0.0, "avg_logprob": -0.09538784027099609, "compression_ratio": 1.8455882352941178, "no_speech_prob": 1.7602502566660405e-06}, {"id": 415, "seek": 163456, "start": 1645.24, "end": 1648.56, "text": " And we solve a binary classification problem.", "tokens": [50364, 400, 286, 603, 751, 466, 729, 3030, 264, 917, 562, 286, 767, 751, 466, 8712, 488, 2539, 13, 50616, 50616, 407, 294, 341, 1729, 589, 11, 321, 645, 588, 709, 7547, 538, 411, 264, 659, 25111, 9608, 797, 13, 50898, 50898, 400, 321, 5039, 257, 17434, 21538, 1154, 13, 51064, 51064, 407, 2212, 257, 3840, 295, 12083, 11, 321, 8947, 1045, 12083, 13, 51202, 51202, 400, 498, 321, 8947, 552, 294, 264, 558, 1668, 11, 321, 7645, 552, 1804, 472, 13, 51434, 51434, 400, 498, 321, 39426, 552, 11, 1936, 321, 7645, 552, 382, 4018, 13, 51586, 51586, 400, 370, 586, 321, 643, 281, 5039, 257, 17434, 21538, 1154, 281, 6069, 1968, 746, 307, 402, 33974, 51792, 51792], "temperature": 0.0, "avg_logprob": -0.09538784027099609, "compression_ratio": 1.8455882352941178, "no_speech_prob": 1.7602502566660405e-06}, {"id": 416, "seek": 163456, "start": 1648.56, "end": 1651.32, "text": " So given a bunch of frames, we extract three frames.", "tokens": [50364, 400, 286, 603, 751, 466, 729, 3030, 264, 917, 562, 286, 767, 751, 466, 8712, 488, 2539, 13, 50616, 50616, 407, 294, 341, 1729, 589, 11, 321, 645, 588, 709, 7547, 538, 411, 264, 659, 25111, 9608, 797, 13, 50898, 50898, 400, 321, 5039, 257, 17434, 21538, 1154, 13, 51064, 51064, 407, 2212, 257, 3840, 295, 12083, 11, 321, 8947, 1045, 12083, 13, 51202, 51202, 400, 498, 321, 8947, 552, 294, 264, 558, 1668, 11, 321, 7645, 552, 1804, 472, 13, 51434, 51434, 400, 498, 321, 39426, 552, 11, 1936, 321, 7645, 552, 382, 4018, 13, 51586, 51586, 400, 370, 586, 321, 643, 281, 5039, 257, 17434, 21538, 1154, 281, 6069, 1968, 746, 307, 402, 33974, 51792, 51792], "temperature": 0.0, "avg_logprob": -0.09538784027099609, "compression_ratio": 1.8455882352941178, "no_speech_prob": 1.7602502566660405e-06}, {"id": 417, "seek": 163456, "start": 1651.32, "end": 1655.96, "text": " And if we extract them in the right order, we label them plus one.", "tokens": [50364, 400, 286, 603, 751, 466, 729, 3030, 264, 917, 562, 286, 767, 751, 466, 8712, 488, 2539, 13, 50616, 50616, 407, 294, 341, 1729, 589, 11, 321, 645, 588, 709, 7547, 538, 411, 264, 659, 25111, 9608, 797, 13, 50898, 50898, 400, 321, 5039, 257, 17434, 21538, 1154, 13, 51064, 51064, 407, 2212, 257, 3840, 295, 12083, 11, 321, 8947, 1045, 12083, 13, 51202, 51202, 400, 498, 321, 8947, 552, 294, 264, 558, 1668, 11, 321, 7645, 552, 1804, 472, 13, 51434, 51434, 400, 498, 321, 39426, 552, 11, 1936, 321, 7645, 552, 382, 4018, 13, 51586, 51586, 400, 370, 586, 321, 643, 281, 5039, 257, 17434, 21538, 1154, 281, 6069, 1968, 746, 307, 402, 33974, 51792, 51792], "temperature": 0.0, "avg_logprob": -0.09538784027099609, "compression_ratio": 1.8455882352941178, "no_speech_prob": 1.7602502566660405e-06}, {"id": 418, "seek": 163456, "start": 1655.96, "end": 1659.0, "text": " And if we shuffle them, basically we label them as zero.", "tokens": [50364, 400, 286, 603, 751, 466, 729, 3030, 264, 917, 562, 286, 767, 751, 466, 8712, 488, 2539, 13, 50616, 50616, 407, 294, 341, 1729, 589, 11, 321, 645, 588, 709, 7547, 538, 411, 264, 659, 25111, 9608, 797, 13, 50898, 50898, 400, 321, 5039, 257, 17434, 21538, 1154, 13, 51064, 51064, 407, 2212, 257, 3840, 295, 12083, 11, 321, 8947, 1045, 12083, 13, 51202, 51202, 400, 498, 321, 8947, 552, 294, 264, 558, 1668, 11, 321, 7645, 552, 1804, 472, 13, 51434, 51434, 400, 498, 321, 39426, 552, 11, 1936, 321, 7645, 552, 382, 4018, 13, 51586, 51586, 400, 370, 586, 321, 643, 281, 5039, 257, 17434, 21538, 1154, 281, 6069, 1968, 746, 307, 402, 33974, 51792, 51792], "temperature": 0.0, "avg_logprob": -0.09538784027099609, "compression_ratio": 1.8455882352941178, "no_speech_prob": 1.7602502566660405e-06}, {"id": 419, "seek": 163456, "start": 1659.0, "end": 1663.12, "text": " And so now we need to solve a binary classification problem to predict whether something is shuffled", "tokens": [50364, 400, 286, 603, 751, 466, 729, 3030, 264, 917, 562, 286, 767, 751, 466, 8712, 488, 2539, 13, 50616, 50616, 407, 294, 341, 1729, 589, 11, 321, 645, 588, 709, 7547, 538, 411, 264, 659, 25111, 9608, 797, 13, 50898, 50898, 400, 321, 5039, 257, 17434, 21538, 1154, 13, 51064, 51064, 407, 2212, 257, 3840, 295, 12083, 11, 321, 8947, 1045, 12083, 13, 51202, 51202, 400, 498, 321, 8947, 552, 294, 264, 558, 1668, 11, 321, 7645, 552, 1804, 472, 13, 51434, 51434, 400, 498, 321, 39426, 552, 11, 1936, 321, 7645, 552, 382, 4018, 13, 51586, 51586, 400, 370, 586, 321, 643, 281, 5039, 257, 17434, 21538, 1154, 281, 6069, 1968, 746, 307, 402, 33974, 51792, 51792], "temperature": 0.0, "avg_logprob": -0.09538784027099609, "compression_ratio": 1.8455882352941178, "no_speech_prob": 1.7602502566660405e-06}, {"id": 420, "seek": 166312, "start": 1663.12, "end": 1665.32, "text": " or not.", "tokens": [50364, 420, 406, 13, 50474, 50474, 400, 264, 1778, 341, 1333, 295, 1985, 307, 570, 11, 370, 2212, 1045, 12083, 11, 718, 311, 519, 295, 552, 50882, 50882, 382, 1936, 722, 11, 2808, 293, 917, 13, 51017, 51017, 639, 3209, 534, 9898, 281, 1466, 11, 2212, 257, 722, 293, 917, 935, 11, 307, 341, 935, 257, 7363, 51328, 51328, 1333, 295, 44902, 399, 295, 613, 722, 293, 917, 2793, 30, 51460, 51460, 407, 309, 534, 9898, 281, 1333, 295, 44902, 473, 19565, 613, 4122, 2212, 341, 5056, 51774, 51774], "temperature": 0.0, "avg_logprob": -0.1607576158311632, "compression_ratio": 1.797979797979798, "no_speech_prob": 7.183083198469831e-06}, {"id": 421, "seek": 166312, "start": 1665.32, "end": 1673.4799999999998, "text": " And the reason this sort of works is because, so given three frames, let's think of them", "tokens": [50364, 420, 406, 13, 50474, 50474, 400, 264, 1778, 341, 1333, 295, 1985, 307, 570, 11, 370, 2212, 1045, 12083, 11, 718, 311, 519, 295, 552, 50882, 50882, 382, 1936, 722, 11, 2808, 293, 917, 13, 51017, 51017, 639, 3209, 534, 9898, 281, 1466, 11, 2212, 257, 722, 293, 917, 935, 11, 307, 341, 935, 257, 7363, 51328, 51328, 1333, 295, 44902, 399, 295, 613, 722, 293, 917, 2793, 30, 51460, 51460, 407, 309, 534, 9898, 281, 1333, 295, 44902, 473, 19565, 613, 4122, 2212, 341, 5056, 51774, 51774], "temperature": 0.0, "avg_logprob": -0.1607576158311632, "compression_ratio": 1.797979797979798, "no_speech_prob": 7.183083198469831e-06}, {"id": 422, "seek": 166312, "start": 1673.4799999999998, "end": 1676.1799999999998, "text": " as basically start, middle and end.", "tokens": [50364, 420, 406, 13, 50474, 50474, 400, 264, 1778, 341, 1333, 295, 1985, 307, 570, 11, 370, 2212, 1045, 12083, 11, 718, 311, 519, 295, 552, 50882, 50882, 382, 1936, 722, 11, 2808, 293, 917, 13, 51017, 51017, 639, 3209, 534, 9898, 281, 1466, 11, 2212, 257, 722, 293, 917, 935, 11, 307, 341, 935, 257, 7363, 51328, 51328, 1333, 295, 44902, 399, 295, 613, 722, 293, 917, 2793, 30, 51460, 51460, 407, 309, 534, 9898, 281, 1333, 295, 44902, 473, 19565, 613, 4122, 2212, 341, 5056, 51774, 51774], "temperature": 0.0, "avg_logprob": -0.1607576158311632, "compression_ratio": 1.797979797979798, "no_speech_prob": 7.183083198469831e-06}, {"id": 423, "seek": 166312, "start": 1676.1799999999998, "end": 1682.3999999999999, "text": " This network really tries to learn, given a start and end point, is this point a valid", "tokens": [50364, 420, 406, 13, 50474, 50474, 400, 264, 1778, 341, 1333, 295, 1985, 307, 570, 11, 370, 2212, 1045, 12083, 11, 718, 311, 519, 295, 552, 50882, 50882, 382, 1936, 722, 11, 2808, 293, 917, 13, 51017, 51017, 639, 3209, 534, 9898, 281, 1466, 11, 2212, 257, 722, 293, 917, 935, 11, 307, 341, 935, 257, 7363, 51328, 51328, 1333, 295, 44902, 399, 295, 613, 722, 293, 917, 2793, 30, 51460, 51460, 407, 309, 534, 9898, 281, 1333, 295, 44902, 473, 19565, 613, 4122, 2212, 341, 5056, 51774, 51774], "temperature": 0.0, "avg_logprob": -0.1607576158311632, "compression_ratio": 1.797979797979798, "no_speech_prob": 7.183083198469831e-06}, {"id": 424, "seek": 166312, "start": 1682.3999999999999, "end": 1685.04, "text": " sort of interpolation of these start and end points?", "tokens": [50364, 420, 406, 13, 50474, 50474, 400, 264, 1778, 341, 1333, 295, 1985, 307, 570, 11, 370, 2212, 1045, 12083, 11, 718, 311, 519, 295, 552, 50882, 50882, 382, 1936, 722, 11, 2808, 293, 917, 13, 51017, 51017, 639, 3209, 534, 9898, 281, 1466, 11, 2212, 257, 722, 293, 917, 935, 11, 307, 341, 935, 257, 7363, 51328, 51328, 1333, 295, 44902, 399, 295, 613, 722, 293, 917, 2793, 30, 51460, 51460, 407, 309, 534, 9898, 281, 1333, 295, 44902, 473, 19565, 613, 4122, 2212, 341, 5056, 51774, 51774], "temperature": 0.0, "avg_logprob": -0.1607576158311632, "compression_ratio": 1.797979797979798, "no_speech_prob": 7.183083198469831e-06}, {"id": 425, "seek": 166312, "start": 1685.04, "end": 1691.32, "text": " So it really tries to sort of interpolate smoothly these features given this visual", "tokens": [50364, 420, 406, 13, 50474, 50474, 400, 264, 1778, 341, 1333, 295, 1985, 307, 570, 11, 370, 2212, 1045, 12083, 11, 718, 311, 519, 295, 552, 50882, 50882, 382, 1936, 722, 11, 2808, 293, 917, 13, 51017, 51017, 639, 3209, 534, 9898, 281, 1466, 11, 2212, 257, 722, 293, 917, 935, 11, 307, 341, 935, 257, 7363, 51328, 51328, 1333, 295, 44902, 399, 295, 613, 722, 293, 917, 2793, 30, 51460, 51460, 407, 309, 534, 9898, 281, 1333, 295, 44902, 473, 19565, 613, 4122, 2212, 341, 5056, 51774, 51774], "temperature": 0.0, "avg_logprob": -0.1607576158311632, "compression_ratio": 1.797979797979798, "no_speech_prob": 7.183083198469831e-06}, {"id": 426, "seek": 169132, "start": 1691.32, "end": 1693.76, "text": " input.", "tokens": [50364, 4846, 13, 50486, 50486, 407, 264, 3209, 307, 6457, 15325, 13, 50600, 50600, 467, 311, 257, 1333, 295, 1376, 14657, 318, 2918, 1130, 3209, 13, 50722, 50722, 509, 362, 1045, 12083, 13, 50812, 50812, 509, 3154, 2128, 1184, 472, 295, 552, 21761, 13, 50942, 50942, 509, 1588, 7186, 473, 264, 4122, 300, 291, 12701, 490, 613, 1045, 12083, 13, 51090, 51090, 400, 550, 291, 2042, 257, 17434, 21538, 1154, 13, 51215, 51215, 407, 291, 6069, 1968, 341, 551, 307, 3006, 420, 18424, 11, 1968, 309, 311, 1936, 402, 33974, 51458, 51458, 420, 406, 402, 33974, 13, 51538, 51538, 509, 393, 1936, 17522, 341, 365, 3278, 30867, 4470, 13, 51722, 51722], "temperature": 0.0, "avg_logprob": -0.13705626555851527, "compression_ratio": 1.7335907335907337, "no_speech_prob": 2.885317189793568e-05}, {"id": 427, "seek": 169132, "start": 1693.76, "end": 1696.04, "text": " So the network is fairly straightforward.", "tokens": [50364, 4846, 13, 50486, 50486, 407, 264, 3209, 307, 6457, 15325, 13, 50600, 50600, 467, 311, 257, 1333, 295, 1376, 14657, 318, 2918, 1130, 3209, 13, 50722, 50722, 509, 362, 1045, 12083, 13, 50812, 50812, 509, 3154, 2128, 1184, 472, 295, 552, 21761, 13, 50942, 50942, 509, 1588, 7186, 473, 264, 4122, 300, 291, 12701, 490, 613, 1045, 12083, 13, 51090, 51090, 400, 550, 291, 2042, 257, 17434, 21538, 1154, 13, 51215, 51215, 407, 291, 6069, 1968, 341, 551, 307, 3006, 420, 18424, 11, 1968, 309, 311, 1936, 402, 33974, 51458, 51458, 420, 406, 402, 33974, 13, 51538, 51538, 509, 393, 1936, 17522, 341, 365, 3278, 30867, 4470, 13, 51722, 51722], "temperature": 0.0, "avg_logprob": -0.13705626555851527, "compression_ratio": 1.7335907335907337, "no_speech_prob": 2.885317189793568e-05}, {"id": 428, "seek": 169132, "start": 1696.04, "end": 1698.48, "text": " It's a sort of triplet Siamese network.", "tokens": [50364, 4846, 13, 50486, 50486, 407, 264, 3209, 307, 6457, 15325, 13, 50600, 50600, 467, 311, 257, 1333, 295, 1376, 14657, 318, 2918, 1130, 3209, 13, 50722, 50722, 509, 362, 1045, 12083, 13, 50812, 50812, 509, 3154, 2128, 1184, 472, 295, 552, 21761, 13, 50942, 50942, 509, 1588, 7186, 473, 264, 4122, 300, 291, 12701, 490, 613, 1045, 12083, 13, 51090, 51090, 400, 550, 291, 2042, 257, 17434, 21538, 1154, 13, 51215, 51215, 407, 291, 6069, 1968, 341, 551, 307, 3006, 420, 18424, 11, 1968, 309, 311, 1936, 402, 33974, 51458, 51458, 420, 406, 402, 33974, 13, 51538, 51538, 509, 393, 1936, 17522, 341, 365, 3278, 30867, 4470, 13, 51722, 51722], "temperature": 0.0, "avg_logprob": -0.13705626555851527, "compression_ratio": 1.7335907335907337, "no_speech_prob": 2.885317189793568e-05}, {"id": 429, "seek": 169132, "start": 1698.48, "end": 1700.28, "text": " You have three frames.", "tokens": [50364, 4846, 13, 50486, 50486, 407, 264, 3209, 307, 6457, 15325, 13, 50600, 50600, 467, 311, 257, 1333, 295, 1376, 14657, 318, 2918, 1130, 3209, 13, 50722, 50722, 509, 362, 1045, 12083, 13, 50812, 50812, 509, 3154, 2128, 1184, 472, 295, 552, 21761, 13, 50942, 50942, 509, 1588, 7186, 473, 264, 4122, 300, 291, 12701, 490, 613, 1045, 12083, 13, 51090, 51090, 400, 550, 291, 2042, 257, 17434, 21538, 1154, 13, 51215, 51215, 407, 291, 6069, 1968, 341, 551, 307, 3006, 420, 18424, 11, 1968, 309, 311, 1936, 402, 33974, 51458, 51458, 420, 406, 402, 33974, 13, 51538, 51538, 509, 393, 1936, 17522, 341, 365, 3278, 30867, 4470, 13, 51722, 51722], "temperature": 0.0, "avg_logprob": -0.13705626555851527, "compression_ratio": 1.7335907335907337, "no_speech_prob": 2.885317189793568e-05}, {"id": 430, "seek": 169132, "start": 1700.28, "end": 1702.8799999999999, "text": " You feed forward each one of them independently.", "tokens": [50364, 4846, 13, 50486, 50486, 407, 264, 3209, 307, 6457, 15325, 13, 50600, 50600, 467, 311, 257, 1333, 295, 1376, 14657, 318, 2918, 1130, 3209, 13, 50722, 50722, 509, 362, 1045, 12083, 13, 50812, 50812, 509, 3154, 2128, 1184, 472, 295, 552, 21761, 13, 50942, 50942, 509, 1588, 7186, 473, 264, 4122, 300, 291, 12701, 490, 613, 1045, 12083, 13, 51090, 51090, 400, 550, 291, 2042, 257, 17434, 21538, 1154, 13, 51215, 51215, 407, 291, 6069, 1968, 341, 551, 307, 3006, 420, 18424, 11, 1968, 309, 311, 1936, 402, 33974, 51458, 51458, 420, 406, 402, 33974, 13, 51538, 51538, 509, 393, 1936, 17522, 341, 365, 3278, 30867, 4470, 13, 51722, 51722], "temperature": 0.0, "avg_logprob": -0.13705626555851527, "compression_ratio": 1.7335907335907337, "no_speech_prob": 2.885317189793568e-05}, {"id": 431, "seek": 169132, "start": 1702.8799999999999, "end": 1705.84, "text": " You concatenate the features that you obtain from these three frames.", "tokens": [50364, 4846, 13, 50486, 50486, 407, 264, 3209, 307, 6457, 15325, 13, 50600, 50600, 467, 311, 257, 1333, 295, 1376, 14657, 318, 2918, 1130, 3209, 13, 50722, 50722, 509, 362, 1045, 12083, 13, 50812, 50812, 509, 3154, 2128, 1184, 472, 295, 552, 21761, 13, 50942, 50942, 509, 1588, 7186, 473, 264, 4122, 300, 291, 12701, 490, 613, 1045, 12083, 13, 51090, 51090, 400, 550, 291, 2042, 257, 17434, 21538, 1154, 13, 51215, 51215, 407, 291, 6069, 1968, 341, 551, 307, 3006, 420, 18424, 11, 1968, 309, 311, 1936, 402, 33974, 51458, 51458, 420, 406, 402, 33974, 13, 51538, 51538, 509, 393, 1936, 17522, 341, 365, 3278, 30867, 4470, 13, 51722, 51722], "temperature": 0.0, "avg_logprob": -0.13705626555851527, "compression_ratio": 1.7335907335907337, "no_speech_prob": 2.885317189793568e-05}, {"id": 432, "seek": 169132, "start": 1705.84, "end": 1708.34, "text": " And then you perform a binary classification problem.", "tokens": [50364, 4846, 13, 50486, 50486, 407, 264, 3209, 307, 6457, 15325, 13, 50600, 50600, 467, 311, 257, 1333, 295, 1376, 14657, 318, 2918, 1130, 3209, 13, 50722, 50722, 509, 362, 1045, 12083, 13, 50812, 50812, 509, 3154, 2128, 1184, 472, 295, 552, 21761, 13, 50942, 50942, 509, 1588, 7186, 473, 264, 4122, 300, 291, 12701, 490, 613, 1045, 12083, 13, 51090, 51090, 400, 550, 291, 2042, 257, 17434, 21538, 1154, 13, 51215, 51215, 407, 291, 6069, 1968, 341, 551, 307, 3006, 420, 18424, 11, 1968, 309, 311, 1936, 402, 33974, 51458, 51458, 420, 406, 402, 33974, 13, 51538, 51538, 509, 393, 1936, 17522, 341, 365, 3278, 30867, 4470, 13, 51722, 51722], "temperature": 0.0, "avg_logprob": -0.13705626555851527, "compression_ratio": 1.7335907335907337, "no_speech_prob": 2.885317189793568e-05}, {"id": 433, "seek": 169132, "start": 1708.34, "end": 1713.2, "text": " So you predict whether this thing is correct or incorrect, whether it's basically shuffled", "tokens": [50364, 4846, 13, 50486, 50486, 407, 264, 3209, 307, 6457, 15325, 13, 50600, 50600, 467, 311, 257, 1333, 295, 1376, 14657, 318, 2918, 1130, 3209, 13, 50722, 50722, 509, 362, 1045, 12083, 13, 50812, 50812, 509, 3154, 2128, 1184, 472, 295, 552, 21761, 13, 50942, 50942, 509, 1588, 7186, 473, 264, 4122, 300, 291, 12701, 490, 613, 1045, 12083, 13, 51090, 51090, 400, 550, 291, 2042, 257, 17434, 21538, 1154, 13, 51215, 51215, 407, 291, 6069, 1968, 341, 551, 307, 3006, 420, 18424, 11, 1968, 309, 311, 1936, 402, 33974, 51458, 51458, 420, 406, 402, 33974, 13, 51538, 51538, 509, 393, 1936, 17522, 341, 365, 3278, 30867, 4470, 13, 51722, 51722], "temperature": 0.0, "avg_logprob": -0.13705626555851527, "compression_ratio": 1.7335907335907337, "no_speech_prob": 2.885317189793568e-05}, {"id": 434, "seek": 169132, "start": 1713.2, "end": 1714.8, "text": " or not shuffled.", "tokens": [50364, 4846, 13, 50486, 50486, 407, 264, 3209, 307, 6457, 15325, 13, 50600, 50600, 467, 311, 257, 1333, 295, 1376, 14657, 318, 2918, 1130, 3209, 13, 50722, 50722, 509, 362, 1045, 12083, 13, 50812, 50812, 509, 3154, 2128, 1184, 472, 295, 552, 21761, 13, 50942, 50942, 509, 1588, 7186, 473, 264, 4122, 300, 291, 12701, 490, 613, 1045, 12083, 13, 51090, 51090, 400, 550, 291, 2042, 257, 17434, 21538, 1154, 13, 51215, 51215, 407, 291, 6069, 1968, 341, 551, 307, 3006, 420, 18424, 11, 1968, 309, 311, 1936, 402, 33974, 51458, 51458, 420, 406, 402, 33974, 13, 51538, 51538, 509, 393, 1936, 17522, 341, 365, 3278, 30867, 4470, 13, 51722, 51722], "temperature": 0.0, "avg_logprob": -0.13705626555851527, "compression_ratio": 1.7335907335907337, "no_speech_prob": 2.885317189793568e-05}, {"id": 435, "seek": 169132, "start": 1714.8, "end": 1718.48, "text": " You can basically minimize this with cross entropy loss.", "tokens": [50364, 4846, 13, 50486, 50486, 407, 264, 3209, 307, 6457, 15325, 13, 50600, 50600, 467, 311, 257, 1333, 295, 1376, 14657, 318, 2918, 1130, 3209, 13, 50722, 50722, 509, 362, 1045, 12083, 13, 50812, 50812, 509, 3154, 2128, 1184, 472, 295, 552, 21761, 13, 50942, 50942, 509, 1588, 7186, 473, 264, 4122, 300, 291, 12701, 490, 613, 1045, 12083, 13, 51090, 51090, 400, 550, 291, 2042, 257, 17434, 21538, 1154, 13, 51215, 51215, 407, 291, 6069, 1968, 341, 551, 307, 3006, 420, 18424, 11, 1968, 309, 311, 1936, 402, 33974, 51458, 51458, 420, 406, 402, 33974, 13, 51538, 51538, 509, 393, 1936, 17522, 341, 365, 3278, 30867, 4470, 13, 51722, 51722], "temperature": 0.0, "avg_logprob": -0.13705626555851527, "compression_ratio": 1.7335907335907337, "no_speech_prob": 2.885317189793568e-05}, {"id": 436, "seek": 171848, "start": 1718.48, "end": 1723.2, "text": " And you can train this entire network end to end.", "tokens": [50364, 400, 291, 393, 3847, 341, 2302, 3209, 917, 281, 917, 13, 50600, 50600, 407, 797, 11, 411, 286, 632, 2835, 3071, 11, 23831, 5987, 307, 1333, 295, 257, 665, 636, 281, 23273, 50874, 50874, 437, 613, 9590, 366, 2539, 13, 50992, 50992, 407, 321, 6263, 4059, 589, 293, 321, 1936, 2956, 412, 264, 23831, 12512, 295, 12083, 13, 51316, 51316, 407, 322, 264, 1411, 12, 5543, 1252, 11, 291, 362, 257, 14581, 3920, 13, 51446, 51446, 509, 3154, 2128, 300, 3920, 13, 51504, 51504, 509, 483, 257, 4111, 13, 51554, 51554, 400, 550, 291, 1936, 574, 412, 264, 23831, 12512, 294, 300, 4111, 10290, 13, 51778, 51778], "temperature": 0.0, "avg_logprob": -0.10664561910366793, "compression_ratio": 1.7903225806451613, "no_speech_prob": 9.368238352180924e-06}, {"id": 437, "seek": 171848, "start": 1723.2, "end": 1728.68, "text": " So again, like I had mentioned earlier, nearest neighbor is sort of a good way to visualize", "tokens": [50364, 400, 291, 393, 3847, 341, 2302, 3209, 917, 281, 917, 13, 50600, 50600, 407, 797, 11, 411, 286, 632, 2835, 3071, 11, 23831, 5987, 307, 1333, 295, 257, 665, 636, 281, 23273, 50874, 50874, 437, 613, 9590, 366, 2539, 13, 50992, 50992, 407, 321, 6263, 4059, 589, 293, 321, 1936, 2956, 412, 264, 23831, 12512, 295, 12083, 13, 51316, 51316, 407, 322, 264, 1411, 12, 5543, 1252, 11, 291, 362, 257, 14581, 3920, 13, 51446, 51446, 509, 3154, 2128, 300, 3920, 13, 51504, 51504, 509, 483, 257, 4111, 13, 51554, 51554, 400, 550, 291, 1936, 574, 412, 264, 23831, 12512, 294, 300, 4111, 10290, 13, 51778, 51778], "temperature": 0.0, "avg_logprob": -0.10664561910366793, "compression_ratio": 1.7903225806451613, "no_speech_prob": 9.368238352180924e-06}, {"id": 438, "seek": 171848, "start": 1728.68, "end": 1731.04, "text": " what these networks are learning.", "tokens": [50364, 400, 291, 393, 3847, 341, 2302, 3209, 917, 281, 917, 13, 50600, 50600, 407, 797, 11, 411, 286, 632, 2835, 3071, 11, 23831, 5987, 307, 1333, 295, 257, 665, 636, 281, 23273, 50874, 50874, 437, 613, 9590, 366, 2539, 13, 50992, 50992, 407, 321, 6263, 4059, 589, 293, 321, 1936, 2956, 412, 264, 23831, 12512, 295, 12083, 13, 51316, 51316, 407, 322, 264, 1411, 12, 5543, 1252, 11, 291, 362, 257, 14581, 3920, 13, 51446, 51446, 509, 3154, 2128, 300, 3920, 13, 51504, 51504, 509, 483, 257, 4111, 13, 51554, 51554, 400, 550, 291, 1936, 574, 412, 264, 23831, 12512, 294, 300, 4111, 10290, 13, 51778, 51778], "temperature": 0.0, "avg_logprob": -0.10664561910366793, "compression_ratio": 1.7903225806451613, "no_speech_prob": 9.368238352180924e-06}, {"id": 439, "seek": 171848, "start": 1731.04, "end": 1737.52, "text": " So we followed prior work and we basically looked at the nearest neighbors of frames.", "tokens": [50364, 400, 291, 393, 3847, 341, 2302, 3209, 917, 281, 917, 13, 50600, 50600, 407, 797, 11, 411, 286, 632, 2835, 3071, 11, 23831, 5987, 307, 1333, 295, 257, 665, 636, 281, 23273, 50874, 50874, 437, 613, 9590, 366, 2539, 13, 50992, 50992, 407, 321, 6263, 4059, 589, 293, 321, 1936, 2956, 412, 264, 23831, 12512, 295, 12083, 13, 51316, 51316, 407, 322, 264, 1411, 12, 5543, 1252, 11, 291, 362, 257, 14581, 3920, 13, 51446, 51446, 509, 3154, 2128, 300, 3920, 13, 51504, 51504, 509, 483, 257, 4111, 13, 51554, 51554, 400, 550, 291, 1936, 574, 412, 264, 23831, 12512, 294, 300, 4111, 10290, 13, 51778, 51778], "temperature": 0.0, "avg_logprob": -0.10664561910366793, "compression_ratio": 1.7903225806451613, "no_speech_prob": 9.368238352180924e-06}, {"id": 440, "seek": 171848, "start": 1737.52, "end": 1740.1200000000001, "text": " So on the left-hand side, you have a query frame.", "tokens": [50364, 400, 291, 393, 3847, 341, 2302, 3209, 917, 281, 917, 13, 50600, 50600, 407, 797, 11, 411, 286, 632, 2835, 3071, 11, 23831, 5987, 307, 1333, 295, 257, 665, 636, 281, 23273, 50874, 50874, 437, 613, 9590, 366, 2539, 13, 50992, 50992, 407, 321, 6263, 4059, 589, 293, 321, 1936, 2956, 412, 264, 23831, 12512, 295, 12083, 13, 51316, 51316, 407, 322, 264, 1411, 12, 5543, 1252, 11, 291, 362, 257, 14581, 3920, 13, 51446, 51446, 509, 3154, 2128, 300, 3920, 13, 51504, 51504, 509, 483, 257, 4111, 13, 51554, 51554, 400, 550, 291, 1936, 574, 412, 264, 23831, 12512, 294, 300, 4111, 10290, 13, 51778, 51778], "temperature": 0.0, "avg_logprob": -0.10664561910366793, "compression_ratio": 1.7903225806451613, "no_speech_prob": 9.368238352180924e-06}, {"id": 441, "seek": 171848, "start": 1740.1200000000001, "end": 1741.28, "text": " You feed forward that frame.", "tokens": [50364, 400, 291, 393, 3847, 341, 2302, 3209, 917, 281, 917, 13, 50600, 50600, 407, 797, 11, 411, 286, 632, 2835, 3071, 11, 23831, 5987, 307, 1333, 295, 257, 665, 636, 281, 23273, 50874, 50874, 437, 613, 9590, 366, 2539, 13, 50992, 50992, 407, 321, 6263, 4059, 589, 293, 321, 1936, 2956, 412, 264, 23831, 12512, 295, 12083, 13, 51316, 51316, 407, 322, 264, 1411, 12, 5543, 1252, 11, 291, 362, 257, 14581, 3920, 13, 51446, 51446, 509, 3154, 2128, 300, 3920, 13, 51504, 51504, 509, 483, 257, 4111, 13, 51554, 51554, 400, 550, 291, 1936, 574, 412, 264, 23831, 12512, 294, 300, 4111, 10290, 13, 51778, 51778], "temperature": 0.0, "avg_logprob": -0.10664561910366793, "compression_ratio": 1.7903225806451613, "no_speech_prob": 9.368238352180924e-06}, {"id": 442, "seek": 171848, "start": 1741.28, "end": 1742.28, "text": " You get a feature.", "tokens": [50364, 400, 291, 393, 3847, 341, 2302, 3209, 917, 281, 917, 13, 50600, 50600, 407, 797, 11, 411, 286, 632, 2835, 3071, 11, 23831, 5987, 307, 1333, 295, 257, 665, 636, 281, 23273, 50874, 50874, 437, 613, 9590, 366, 2539, 13, 50992, 50992, 407, 321, 6263, 4059, 589, 293, 321, 1936, 2956, 412, 264, 23831, 12512, 295, 12083, 13, 51316, 51316, 407, 322, 264, 1411, 12, 5543, 1252, 11, 291, 362, 257, 14581, 3920, 13, 51446, 51446, 509, 3154, 2128, 300, 3920, 13, 51504, 51504, 509, 483, 257, 4111, 13, 51554, 51554, 400, 550, 291, 1936, 574, 412, 264, 23831, 12512, 294, 300, 4111, 10290, 13, 51778, 51778], "temperature": 0.0, "avg_logprob": -0.10664561910366793, "compression_ratio": 1.7903225806451613, "no_speech_prob": 9.368238352180924e-06}, {"id": 443, "seek": 171848, "start": 1742.28, "end": 1746.76, "text": " And then you basically look at the nearest neighbors in that feature representation.", "tokens": [50364, 400, 291, 393, 3847, 341, 2302, 3209, 917, 281, 917, 13, 50600, 50600, 407, 797, 11, 411, 286, 632, 2835, 3071, 11, 23831, 5987, 307, 1333, 295, 257, 665, 636, 281, 23273, 50874, 50874, 437, 613, 9590, 366, 2539, 13, 50992, 50992, 407, 321, 6263, 4059, 589, 293, 321, 1936, 2956, 412, 264, 23831, 12512, 295, 12083, 13, 51316, 51316, 407, 322, 264, 1411, 12, 5543, 1252, 11, 291, 362, 257, 14581, 3920, 13, 51446, 51446, 509, 3154, 2128, 300, 3920, 13, 51504, 51504, 509, 483, 257, 4111, 13, 51554, 51554, 400, 550, 291, 1936, 574, 412, 264, 23831, 12512, 294, 300, 4111, 10290, 13, 51778, 51778], "temperature": 0.0, "avg_logprob": -0.10664561910366793, "compression_ratio": 1.7903225806451613, "no_speech_prob": 9.368238352180924e-06}, {"id": 444, "seek": 174676, "start": 1746.76, "end": 1751.92, "text": " And we'll do that for ImageNet, Shuffle and Learn, and then random features.", "tokens": [50364, 400, 321, 603, 360, 300, 337, 29903, 31890, 11, 1160, 21665, 293, 17216, 11, 293, 550, 4974, 4122, 13, 50622, 50622, 407, 437, 291, 11441, 307, 456, 311, 257, 588, 17417, 2649, 1296, 437, 29903, 31890, 11, 1160, 21665, 11, 50916, 50916, 293, 37603, 976, 291, 13, 51006, 51006, 407, 264, 700, 5386, 11, 498, 291, 574, 412, 264, 1333, 295, 9222, 4145, 11, 29903, 31890, 307, 534, 665, 412, 15213, 51292, 51292, 484, 300, 309, 311, 257, 9222, 4145, 13, 51386, 51386, 440, 23831, 5987, 309, 19817, 977, 1542, 588, 819, 490, 264, 5883, 3256, 300, 321, 600, 51694, 51694, 2212, 13, 51744, 51744], "temperature": 0.0, "avg_logprob": -0.17370159826546072, "compression_ratio": 1.6694560669456067, "no_speech_prob": 2.0261054487491492e-06}, {"id": 445, "seek": 174676, "start": 1751.92, "end": 1757.8, "text": " So what you observe is there's a very stark difference between what ImageNet, Shuffle,", "tokens": [50364, 400, 321, 603, 360, 300, 337, 29903, 31890, 11, 1160, 21665, 293, 17216, 11, 293, 550, 4974, 4122, 13, 50622, 50622, 407, 437, 291, 11441, 307, 456, 311, 257, 588, 17417, 2649, 1296, 437, 29903, 31890, 11, 1160, 21665, 11, 50916, 50916, 293, 37603, 976, 291, 13, 51006, 51006, 407, 264, 700, 5386, 11, 498, 291, 574, 412, 264, 1333, 295, 9222, 4145, 11, 29903, 31890, 307, 534, 665, 412, 15213, 51292, 51292, 484, 300, 309, 311, 257, 9222, 4145, 13, 51386, 51386, 440, 23831, 5987, 309, 19817, 977, 1542, 588, 819, 490, 264, 5883, 3256, 300, 321, 600, 51694, 51694, 2212, 13, 51744, 51744], "temperature": 0.0, "avg_logprob": -0.17370159826546072, "compression_ratio": 1.6694560669456067, "no_speech_prob": 2.0261054487491492e-06}, {"id": 446, "seek": 174676, "start": 1757.8, "end": 1759.6, "text": " and Random give you.", "tokens": [50364, 400, 321, 603, 360, 300, 337, 29903, 31890, 11, 1160, 21665, 293, 17216, 11, 293, 550, 4974, 4122, 13, 50622, 50622, 407, 437, 291, 11441, 307, 456, 311, 257, 588, 17417, 2649, 1296, 437, 29903, 31890, 11, 1160, 21665, 11, 50916, 50916, 293, 37603, 976, 291, 13, 51006, 51006, 407, 264, 700, 5386, 11, 498, 291, 574, 412, 264, 1333, 295, 9222, 4145, 11, 29903, 31890, 307, 534, 665, 412, 15213, 51292, 51292, 484, 300, 309, 311, 257, 9222, 4145, 13, 51386, 51386, 440, 23831, 5987, 309, 19817, 977, 1542, 588, 819, 490, 264, 5883, 3256, 300, 321, 600, 51694, 51694, 2212, 13, 51744, 51744], "temperature": 0.0, "avg_logprob": -0.17370159826546072, "compression_ratio": 1.6694560669456067, "no_speech_prob": 2.0261054487491492e-06}, {"id": 447, "seek": 174676, "start": 1759.6, "end": 1765.32, "text": " So the first row, if you look at the sort of gym scene, ImageNet is really good at figuring", "tokens": [50364, 400, 321, 603, 360, 300, 337, 29903, 31890, 11, 1160, 21665, 293, 17216, 11, 293, 550, 4974, 4122, 13, 50622, 50622, 407, 437, 291, 11441, 307, 456, 311, 257, 588, 17417, 2649, 1296, 437, 29903, 31890, 11, 1160, 21665, 11, 50916, 50916, 293, 37603, 976, 291, 13, 51006, 51006, 407, 264, 700, 5386, 11, 498, 291, 574, 412, 264, 1333, 295, 9222, 4145, 11, 29903, 31890, 307, 534, 665, 412, 15213, 51292, 51292, 484, 300, 309, 311, 257, 9222, 4145, 13, 51386, 51386, 440, 23831, 5987, 309, 19817, 977, 1542, 588, 819, 490, 264, 5883, 3256, 300, 321, 600, 51694, 51694, 2212, 13, 51744, 51744], "temperature": 0.0, "avg_logprob": -0.17370159826546072, "compression_ratio": 1.6694560669456067, "no_speech_prob": 2.0261054487491492e-06}, {"id": 448, "seek": 174676, "start": 1765.32, "end": 1767.2, "text": " out that it's a gym scene.", "tokens": [50364, 400, 321, 603, 360, 300, 337, 29903, 31890, 11, 1160, 21665, 293, 17216, 11, 293, 550, 4974, 4122, 13, 50622, 50622, 407, 437, 291, 11441, 307, 456, 311, 257, 588, 17417, 2649, 1296, 437, 29903, 31890, 11, 1160, 21665, 11, 50916, 50916, 293, 37603, 976, 291, 13, 51006, 51006, 407, 264, 700, 5386, 11, 498, 291, 574, 412, 264, 1333, 295, 9222, 4145, 11, 29903, 31890, 307, 534, 665, 412, 15213, 51292, 51292, 484, 300, 309, 311, 257, 9222, 4145, 13, 51386, 51386, 440, 23831, 5987, 309, 19817, 977, 1542, 588, 819, 490, 264, 5883, 3256, 300, 321, 600, 51694, 51694, 2212, 13, 51744, 51744], "temperature": 0.0, "avg_logprob": -0.17370159826546072, "compression_ratio": 1.6694560669456067, "no_speech_prob": 2.0261054487491492e-06}, {"id": 449, "seek": 174676, "start": 1767.2, "end": 1773.36, "text": " The nearest neighbor it retrieves looks very different from the initial image that we've", "tokens": [50364, 400, 321, 603, 360, 300, 337, 29903, 31890, 11, 1160, 21665, 293, 17216, 11, 293, 550, 4974, 4122, 13, 50622, 50622, 407, 437, 291, 11441, 307, 456, 311, 257, 588, 17417, 2649, 1296, 437, 29903, 31890, 11, 1160, 21665, 11, 50916, 50916, 293, 37603, 976, 291, 13, 51006, 51006, 407, 264, 700, 5386, 11, 498, 291, 574, 412, 264, 1333, 295, 9222, 4145, 11, 29903, 31890, 307, 534, 665, 412, 15213, 51292, 51292, 484, 300, 309, 311, 257, 9222, 4145, 13, 51386, 51386, 440, 23831, 5987, 309, 19817, 977, 1542, 588, 819, 490, 264, 5883, 3256, 300, 321, 600, 51694, 51694, 2212, 13, 51744, 51744], "temperature": 0.0, "avg_logprob": -0.17370159826546072, "compression_ratio": 1.6694560669456067, "no_speech_prob": 2.0261054487491492e-06}, {"id": 450, "seek": 174676, "start": 1773.36, "end": 1774.36, "text": " given.", "tokens": [50364, 400, 321, 603, 360, 300, 337, 29903, 31890, 11, 1160, 21665, 293, 17216, 11, 293, 550, 4974, 4122, 13, 50622, 50622, 407, 437, 291, 11441, 307, 456, 311, 257, 588, 17417, 2649, 1296, 437, 29903, 31890, 11, 1160, 21665, 11, 50916, 50916, 293, 37603, 976, 291, 13, 51006, 51006, 407, 264, 700, 5386, 11, 498, 291, 574, 412, 264, 1333, 295, 9222, 4145, 11, 29903, 31890, 307, 534, 665, 412, 15213, 51292, 51292, 484, 300, 309, 311, 257, 9222, 4145, 13, 51386, 51386, 440, 23831, 5987, 309, 19817, 977, 1542, 588, 819, 490, 264, 5883, 3256, 300, 321, 600, 51694, 51694, 2212, 13, 51744, 51744], "temperature": 0.0, "avg_logprob": -0.17370159826546072, "compression_ratio": 1.6694560669456067, "no_speech_prob": 2.0261054487491492e-06}, {"id": 451, "seek": 177436, "start": 1774.36, "end": 1777.1599999999999, "text": " The floor is much better lit.", "tokens": [50364, 440, 4123, 307, 709, 1101, 7997, 13, 50504, 50504, 682, 264, 14581, 11, 264, 4123, 390, 767, 2211, 13, 50686, 50686, 400, 264, 1900, 5380, 885, 10332, 307, 406, 534, 264, 912, 11, 457, 29903, 31890, 307, 1333, 50898, 50898, 295, 534, 665, 412, 45339, 341, 2302, 47982, 7719, 293, 534, 1333, 295, 5062, 294, 3683, 51186, 51186, 819, 9222, 8026, 1214, 1998, 538, 294, 264, 10290, 1901, 13, 51444, 51444, 440, 912, 551, 1333, 295, 1709, 337, 264, 5386, 2507, 13, 51574, 51574, 407, 291, 362, 364, 15942, 4145, 293, 29903, 31890, 307, 4258, 1075, 281, 1333, 295, 1888, 493, 322, 51800, 51800], "temperature": 0.0, "avg_logprob": -0.10757997800719063, "compression_ratio": 1.6940298507462686, "no_speech_prob": 6.854150797153125e-06}, {"id": 452, "seek": 177436, "start": 1777.1599999999999, "end": 1780.8, "text": " In the query, the floor was actually black.", "tokens": [50364, 440, 4123, 307, 709, 1101, 7997, 13, 50504, 50504, 682, 264, 14581, 11, 264, 4123, 390, 767, 2211, 13, 50686, 50686, 400, 264, 1900, 5380, 885, 10332, 307, 406, 534, 264, 912, 11, 457, 29903, 31890, 307, 1333, 50898, 50898, 295, 534, 665, 412, 45339, 341, 2302, 47982, 7719, 293, 534, 1333, 295, 5062, 294, 3683, 51186, 51186, 819, 9222, 8026, 1214, 1998, 538, 294, 264, 10290, 1901, 13, 51444, 51444, 440, 912, 551, 1333, 295, 1709, 337, 264, 5386, 2507, 13, 51574, 51574, 407, 291, 362, 364, 15942, 4145, 293, 29903, 31890, 307, 4258, 1075, 281, 1333, 295, 1888, 493, 322, 51800, 51800], "temperature": 0.0, "avg_logprob": -0.10757997800719063, "compression_ratio": 1.6940298507462686, "no_speech_prob": 6.854150797153125e-06}, {"id": 453, "seek": 177436, "start": 1780.8, "end": 1785.04, "text": " And the exact exercise being performed is not really the same, but ImageNet is sort", "tokens": [50364, 440, 4123, 307, 709, 1101, 7997, 13, 50504, 50504, 682, 264, 14581, 11, 264, 4123, 390, 767, 2211, 13, 50686, 50686, 400, 264, 1900, 5380, 885, 10332, 307, 406, 534, 264, 912, 11, 457, 29903, 31890, 307, 1333, 50898, 50898, 295, 534, 665, 412, 45339, 341, 2302, 47982, 7719, 293, 534, 1333, 295, 5062, 294, 3683, 51186, 51186, 819, 9222, 8026, 1214, 1998, 538, 294, 264, 10290, 1901, 13, 51444, 51444, 440, 912, 551, 1333, 295, 1709, 337, 264, 5386, 2507, 13, 51574, 51574, 407, 291, 362, 364, 15942, 4145, 293, 29903, 31890, 307, 4258, 1075, 281, 1333, 295, 1888, 493, 322, 51800, 51800], "temperature": 0.0, "avg_logprob": -0.10757997800719063, "compression_ratio": 1.6940298507462686, "no_speech_prob": 6.854150797153125e-06}, {"id": 454, "seek": 177436, "start": 1785.04, "end": 1790.8, "text": " of really good at collapsing this entire semantic category and really sort of bringing in various", "tokens": [50364, 440, 4123, 307, 709, 1101, 7997, 13, 50504, 50504, 682, 264, 14581, 11, 264, 4123, 390, 767, 2211, 13, 50686, 50686, 400, 264, 1900, 5380, 885, 10332, 307, 406, 534, 264, 912, 11, 457, 29903, 31890, 307, 1333, 50898, 50898, 295, 534, 665, 412, 45339, 341, 2302, 47982, 7719, 293, 534, 1333, 295, 5062, 294, 3683, 51186, 51186, 819, 9222, 8026, 1214, 1998, 538, 294, 264, 10290, 1901, 13, 51444, 51444, 440, 912, 551, 1333, 295, 1709, 337, 264, 5386, 2507, 13, 51574, 51574, 407, 291, 362, 364, 15942, 4145, 293, 29903, 31890, 307, 4258, 1075, 281, 1333, 295, 1888, 493, 322, 51800, 51800], "temperature": 0.0, "avg_logprob": -0.10757997800719063, "compression_ratio": 1.6940298507462686, "no_speech_prob": 6.854150797153125e-06}, {"id": 455, "seek": 177436, "start": 1790.8, "end": 1795.9599999999998, "text": " different gym scenes together close by in the representation space.", "tokens": [50364, 440, 4123, 307, 709, 1101, 7997, 13, 50504, 50504, 682, 264, 14581, 11, 264, 4123, 390, 767, 2211, 13, 50686, 50686, 400, 264, 1900, 5380, 885, 10332, 307, 406, 534, 264, 912, 11, 457, 29903, 31890, 307, 1333, 50898, 50898, 295, 534, 665, 412, 45339, 341, 2302, 47982, 7719, 293, 534, 1333, 295, 5062, 294, 3683, 51186, 51186, 819, 9222, 8026, 1214, 1998, 538, 294, 264, 10290, 1901, 13, 51444, 51444, 440, 912, 551, 1333, 295, 1709, 337, 264, 5386, 2507, 13, 51574, 51574, 407, 291, 362, 364, 15942, 4145, 293, 29903, 31890, 307, 4258, 1075, 281, 1333, 295, 1888, 493, 322, 51800, 51800], "temperature": 0.0, "avg_logprob": -0.10757997800719063, "compression_ratio": 1.6940298507462686, "no_speech_prob": 6.854150797153125e-06}, {"id": 456, "seek": 177436, "start": 1795.9599999999998, "end": 1798.56, "text": " The same thing sort of goes for the row below.", "tokens": [50364, 440, 4123, 307, 709, 1101, 7997, 13, 50504, 50504, 682, 264, 14581, 11, 264, 4123, 390, 767, 2211, 13, 50686, 50686, 400, 264, 1900, 5380, 885, 10332, 307, 406, 534, 264, 912, 11, 457, 29903, 31890, 307, 1333, 50898, 50898, 295, 534, 665, 412, 45339, 341, 2302, 47982, 7719, 293, 534, 1333, 295, 5062, 294, 3683, 51186, 51186, 819, 9222, 8026, 1214, 1998, 538, 294, 264, 10290, 1901, 13, 51444, 51444, 440, 912, 551, 1333, 295, 1709, 337, 264, 5386, 2507, 13, 51574, 51574, 407, 291, 362, 364, 15942, 4145, 293, 29903, 31890, 307, 4258, 1075, 281, 1333, 295, 1888, 493, 322, 51800, 51800], "temperature": 0.0, "avg_logprob": -0.10757997800719063, "compression_ratio": 1.6940298507462686, "no_speech_prob": 6.854150797153125e-06}, {"id": 457, "seek": 177436, "start": 1798.56, "end": 1803.08, "text": " So you have an outdoor scene and ImageNet is immediately able to sort of pick up on", "tokens": [50364, 440, 4123, 307, 709, 1101, 7997, 13, 50504, 50504, 682, 264, 14581, 11, 264, 4123, 390, 767, 2211, 13, 50686, 50686, 400, 264, 1900, 5380, 885, 10332, 307, 406, 534, 264, 912, 11, 457, 29903, 31890, 307, 1333, 50898, 50898, 295, 534, 665, 412, 45339, 341, 2302, 47982, 7719, 293, 534, 1333, 295, 5062, 294, 3683, 51186, 51186, 819, 9222, 8026, 1214, 1998, 538, 294, 264, 10290, 1901, 13, 51444, 51444, 440, 912, 551, 1333, 295, 1709, 337, 264, 5386, 2507, 13, 51574, 51574, 407, 291, 362, 364, 15942, 4145, 293, 29903, 31890, 307, 4258, 1075, 281, 1333, 295, 1888, 493, 322, 51800, 51800], "temperature": 0.0, "avg_logprob": -0.10757997800719063, "compression_ratio": 1.6940298507462686, "no_speech_prob": 6.854150797153125e-06}, {"id": 458, "seek": 180308, "start": 1803.08, "end": 1804.36, "text": " that outdoor part of it.", "tokens": [50364, 300, 15942, 644, 295, 309, 13, 50428, 50428, 467, 311, 1075, 281, 2573, 484, 300, 456, 307, 8054, 293, 370, 322, 13, 50560, 50560, 400, 309, 1333, 295, 5607, 613, 732, 2793, 1214, 294, 264, 4111, 1901, 13, 50824, 50824, 759, 291, 574, 412, 11, 584, 11, 264, 1333, 295, 558, 1761, 11, 264, 23831, 12512, 19817, 937, 538, 264, 4974, 51094, 51094, 3209, 11, 291, 536, 300, 309, 534, 16109, 322, 264, 2017, 13, 51298, 51298, 407, 294, 264, 1192, 5386, 11, 309, 311, 534, 1333, 295, 8416, 322, 264, 2211, 4123, 13, 51452, 51452, 467, 311, 534, 1237, 412, 1310, 1333, 295, 264, 2211, 2017, 294, 341, 3256, 13, 51680, 51680, 400, 300, 311, 577, 309, 311, 19817, 798, 1080, 23831, 5987, 13, 51778, 51778], "temperature": 0.0, "avg_logprob": -0.12603007176125697, "compression_ratio": 1.8682170542635659, "no_speech_prob": 6.540268259414006e-06}, {"id": 459, "seek": 180308, "start": 1804.36, "end": 1807.0, "text": " It's able to figure out that there is grass and so on.", "tokens": [50364, 300, 15942, 644, 295, 309, 13, 50428, 50428, 467, 311, 1075, 281, 2573, 484, 300, 456, 307, 8054, 293, 370, 322, 13, 50560, 50560, 400, 309, 1333, 295, 5607, 613, 732, 2793, 1214, 294, 264, 4111, 1901, 13, 50824, 50824, 759, 291, 574, 412, 11, 584, 11, 264, 1333, 295, 558, 1761, 11, 264, 23831, 12512, 19817, 937, 538, 264, 4974, 51094, 51094, 3209, 11, 291, 536, 300, 309, 534, 16109, 322, 264, 2017, 13, 51298, 51298, 407, 294, 264, 1192, 5386, 11, 309, 311, 534, 1333, 295, 8416, 322, 264, 2211, 4123, 13, 51452, 51452, 467, 311, 534, 1237, 412, 1310, 1333, 295, 264, 2211, 2017, 294, 341, 3256, 13, 51680, 51680, 400, 300, 311, 577, 309, 311, 19817, 798, 1080, 23831, 5987, 13, 51778, 51778], "temperature": 0.0, "avg_logprob": -0.12603007176125697, "compression_ratio": 1.8682170542635659, "no_speech_prob": 6.540268259414006e-06}, {"id": 460, "seek": 180308, "start": 1807.0, "end": 1812.28, "text": " And it sort of brings these two points together in the feature space.", "tokens": [50364, 300, 15942, 644, 295, 309, 13, 50428, 50428, 467, 311, 1075, 281, 2573, 484, 300, 456, 307, 8054, 293, 370, 322, 13, 50560, 50560, 400, 309, 1333, 295, 5607, 613, 732, 2793, 1214, 294, 264, 4111, 1901, 13, 50824, 50824, 759, 291, 574, 412, 11, 584, 11, 264, 1333, 295, 558, 1761, 11, 264, 23831, 12512, 19817, 937, 538, 264, 4974, 51094, 51094, 3209, 11, 291, 536, 300, 309, 534, 16109, 322, 264, 2017, 13, 51298, 51298, 407, 294, 264, 1192, 5386, 11, 309, 311, 534, 1333, 295, 8416, 322, 264, 2211, 4123, 13, 51452, 51452, 467, 311, 534, 1237, 412, 1310, 1333, 295, 264, 2211, 2017, 294, 341, 3256, 13, 51680, 51680, 400, 300, 311, 577, 309, 311, 19817, 798, 1080, 23831, 5987, 13, 51778, 51778], "temperature": 0.0, "avg_logprob": -0.12603007176125697, "compression_ratio": 1.8682170542635659, "no_speech_prob": 6.540268259414006e-06}, {"id": 461, "seek": 180308, "start": 1812.28, "end": 1817.6799999999998, "text": " If you look at, say, the sort of rightmost, the nearest neighbors retrieved by the random", "tokens": [50364, 300, 15942, 644, 295, 309, 13, 50428, 50428, 467, 311, 1075, 281, 2573, 484, 300, 456, 307, 8054, 293, 370, 322, 13, 50560, 50560, 400, 309, 1333, 295, 5607, 613, 732, 2793, 1214, 294, 264, 4111, 1901, 13, 50824, 50824, 759, 291, 574, 412, 11, 584, 11, 264, 1333, 295, 558, 1761, 11, 264, 23831, 12512, 19817, 937, 538, 264, 4974, 51094, 51094, 3209, 11, 291, 536, 300, 309, 534, 16109, 322, 264, 2017, 13, 51298, 51298, 407, 294, 264, 1192, 5386, 11, 309, 311, 534, 1333, 295, 8416, 322, 264, 2211, 4123, 13, 51452, 51452, 467, 311, 534, 1237, 412, 1310, 1333, 295, 264, 2211, 2017, 294, 341, 3256, 13, 51680, 51680, 400, 300, 311, 577, 309, 311, 19817, 798, 1080, 23831, 5987, 13, 51778, 51778], "temperature": 0.0, "avg_logprob": -0.12603007176125697, "compression_ratio": 1.8682170542635659, "no_speech_prob": 6.540268259414006e-06}, {"id": 462, "seek": 180308, "start": 1817.6799999999998, "end": 1821.76, "text": " network, you see that it really focuses on the color.", "tokens": [50364, 300, 15942, 644, 295, 309, 13, 50428, 50428, 467, 311, 1075, 281, 2573, 484, 300, 456, 307, 8054, 293, 370, 322, 13, 50560, 50560, 400, 309, 1333, 295, 5607, 613, 732, 2793, 1214, 294, 264, 4111, 1901, 13, 50824, 50824, 759, 291, 574, 412, 11, 584, 11, 264, 1333, 295, 558, 1761, 11, 264, 23831, 12512, 19817, 937, 538, 264, 4974, 51094, 51094, 3209, 11, 291, 536, 300, 309, 534, 16109, 322, 264, 2017, 13, 51298, 51298, 407, 294, 264, 1192, 5386, 11, 309, 311, 534, 1333, 295, 8416, 322, 264, 2211, 4123, 13, 51452, 51452, 467, 311, 534, 1237, 412, 1310, 1333, 295, 264, 2211, 2017, 294, 341, 3256, 13, 51680, 51680, 400, 300, 311, 577, 309, 311, 19817, 798, 1080, 23831, 5987, 13, 51778, 51778], "temperature": 0.0, "avg_logprob": -0.12603007176125697, "compression_ratio": 1.8682170542635659, "no_speech_prob": 6.540268259414006e-06}, {"id": 463, "seek": 180308, "start": 1821.76, "end": 1824.84, "text": " So in the top row, it's really sort of focusing on the black floor.", "tokens": [50364, 300, 15942, 644, 295, 309, 13, 50428, 50428, 467, 311, 1075, 281, 2573, 484, 300, 456, 307, 8054, 293, 370, 322, 13, 50560, 50560, 400, 309, 1333, 295, 5607, 613, 732, 2793, 1214, 294, 264, 4111, 1901, 13, 50824, 50824, 759, 291, 574, 412, 11, 584, 11, 264, 1333, 295, 558, 1761, 11, 264, 23831, 12512, 19817, 937, 538, 264, 4974, 51094, 51094, 3209, 11, 291, 536, 300, 309, 534, 16109, 322, 264, 2017, 13, 51298, 51298, 407, 294, 264, 1192, 5386, 11, 309, 311, 534, 1333, 295, 8416, 322, 264, 2211, 4123, 13, 51452, 51452, 467, 311, 534, 1237, 412, 1310, 1333, 295, 264, 2211, 2017, 294, 341, 3256, 13, 51680, 51680, 400, 300, 311, 577, 309, 311, 19817, 798, 1080, 23831, 5987, 13, 51778, 51778], "temperature": 0.0, "avg_logprob": -0.12603007176125697, "compression_ratio": 1.8682170542635659, "no_speech_prob": 6.540268259414006e-06}, {"id": 464, "seek": 180308, "start": 1824.84, "end": 1829.3999999999999, "text": " It's really looking at maybe sort of the black color in this image.", "tokens": [50364, 300, 15942, 644, 295, 309, 13, 50428, 50428, 467, 311, 1075, 281, 2573, 484, 300, 456, 307, 8054, 293, 370, 322, 13, 50560, 50560, 400, 309, 1333, 295, 5607, 613, 732, 2793, 1214, 294, 264, 4111, 1901, 13, 50824, 50824, 759, 291, 574, 412, 11, 584, 11, 264, 1333, 295, 558, 1761, 11, 264, 23831, 12512, 19817, 937, 538, 264, 4974, 51094, 51094, 3209, 11, 291, 536, 300, 309, 534, 16109, 322, 264, 2017, 13, 51298, 51298, 407, 294, 264, 1192, 5386, 11, 309, 311, 534, 1333, 295, 8416, 322, 264, 2211, 4123, 13, 51452, 51452, 467, 311, 534, 1237, 412, 1310, 1333, 295, 264, 2211, 2017, 294, 341, 3256, 13, 51680, 51680, 400, 300, 311, 577, 309, 311, 19817, 798, 1080, 23831, 5987, 13, 51778, 51778], "temperature": 0.0, "avg_logprob": -0.12603007176125697, "compression_ratio": 1.8682170542635659, "no_speech_prob": 6.540268259414006e-06}, {"id": 465, "seek": 180308, "start": 1829.3999999999999, "end": 1831.36, "text": " And that's how it's retrieving its nearest neighbor.", "tokens": [50364, 300, 15942, 644, 295, 309, 13, 50428, 50428, 467, 311, 1075, 281, 2573, 484, 300, 456, 307, 8054, 293, 370, 322, 13, 50560, 50560, 400, 309, 1333, 295, 5607, 613, 732, 2793, 1214, 294, 264, 4111, 1901, 13, 50824, 50824, 759, 291, 574, 412, 11, 584, 11, 264, 1333, 295, 558, 1761, 11, 264, 23831, 12512, 19817, 937, 538, 264, 4974, 51094, 51094, 3209, 11, 291, 536, 300, 309, 534, 16109, 322, 264, 2017, 13, 51298, 51298, 407, 294, 264, 1192, 5386, 11, 309, 311, 534, 1333, 295, 8416, 322, 264, 2211, 4123, 13, 51452, 51452, 467, 311, 534, 1237, 412, 1310, 1333, 295, 264, 2211, 2017, 294, 341, 3256, 13, 51680, 51680, 400, 300, 311, 577, 309, 311, 19817, 798, 1080, 23831, 5987, 13, 51778, 51778], "temperature": 0.0, "avg_logprob": -0.12603007176125697, "compression_ratio": 1.8682170542635659, "no_speech_prob": 6.540268259414006e-06}, {"id": 466, "seek": 183136, "start": 1831.36, "end": 1836.56, "text": " If you look at the shuffle and learn, the nearest neighbors, they're fairly odd.", "tokens": [50364, 759, 291, 574, 412, 264, 39426, 293, 1466, 11, 264, 23831, 12512, 11, 436, 434, 6457, 7401, 13, 50624, 50624, 467, 311, 406, 4258, 1850, 1968, 309, 311, 8416, 322, 264, 2017, 420, 1968, 309, 311, 8416, 322, 300, 50812, 50812, 2302, 47982, 3410, 13, 50946, 50946, 400, 370, 322, 11, 1333, 295, 3052, 22085, 13, 51082, 51082, 400, 934, 1237, 412, 257, 688, 295, 613, 5110, 11, 321, 8932, 484, 300, 309, 390, 534, 1237, 51272, 51272, 412, 264, 10774, 295, 264, 954, 13, 51386, 51386, 407, 498, 291, 574, 412, 294, 264, 1192, 5386, 11, 264, 954, 307, 884, 1333, 295, 364, 14119, 11, 307, 14119, 760, 13, 51608, 51608, 400, 300, 311, 1333, 295, 264, 23831, 5987, 19817, 937, 382, 731, 13, 51752, 51752], "temperature": 0.0, "avg_logprob": -0.12957748886226683, "compression_ratio": 1.8801498127340823, "no_speech_prob": 3.905425728589762e-06}, {"id": 467, "seek": 183136, "start": 1836.56, "end": 1840.32, "text": " It's not immediately clear whether it's focusing on the color or whether it's focusing on that", "tokens": [50364, 759, 291, 574, 412, 264, 39426, 293, 1466, 11, 264, 23831, 12512, 11, 436, 434, 6457, 7401, 13, 50624, 50624, 467, 311, 406, 4258, 1850, 1968, 309, 311, 8416, 322, 264, 2017, 420, 1968, 309, 311, 8416, 322, 300, 50812, 50812, 2302, 47982, 3410, 13, 50946, 50946, 400, 370, 322, 11, 1333, 295, 3052, 22085, 13, 51082, 51082, 400, 934, 1237, 412, 257, 688, 295, 613, 5110, 11, 321, 8932, 484, 300, 309, 390, 534, 1237, 51272, 51272, 412, 264, 10774, 295, 264, 954, 13, 51386, 51386, 407, 498, 291, 574, 412, 294, 264, 1192, 5386, 11, 264, 954, 307, 884, 1333, 295, 364, 14119, 11, 307, 14119, 760, 13, 51608, 51608, 400, 300, 311, 1333, 295, 264, 23831, 5987, 19817, 937, 382, 731, 13, 51752, 51752], "temperature": 0.0, "avg_logprob": -0.12957748886226683, "compression_ratio": 1.8801498127340823, "no_speech_prob": 3.905425728589762e-06}, {"id": 468, "seek": 183136, "start": 1840.32, "end": 1843.0, "text": " entire semantic concept.", "tokens": [50364, 759, 291, 574, 412, 264, 39426, 293, 1466, 11, 264, 23831, 12512, 11, 436, 434, 6457, 7401, 13, 50624, 50624, 467, 311, 406, 4258, 1850, 1968, 309, 311, 8416, 322, 264, 2017, 420, 1968, 309, 311, 8416, 322, 300, 50812, 50812, 2302, 47982, 3410, 13, 50946, 50946, 400, 370, 322, 11, 1333, 295, 3052, 22085, 13, 51082, 51082, 400, 934, 1237, 412, 257, 688, 295, 613, 5110, 11, 321, 8932, 484, 300, 309, 390, 534, 1237, 51272, 51272, 412, 264, 10774, 295, 264, 954, 13, 51386, 51386, 407, 498, 291, 574, 412, 294, 264, 1192, 5386, 11, 264, 954, 307, 884, 1333, 295, 364, 14119, 11, 307, 14119, 760, 13, 51608, 51608, 400, 300, 311, 1333, 295, 264, 23831, 5987, 19817, 937, 382, 731, 13, 51752, 51752], "temperature": 0.0, "avg_logprob": -0.12957748886226683, "compression_ratio": 1.8801498127340823, "no_speech_prob": 3.905425728589762e-06}, {"id": 469, "seek": 183136, "start": 1843.0, "end": 1845.7199999999998, "text": " And so on, sort of further inspection.", "tokens": [50364, 759, 291, 574, 412, 264, 39426, 293, 1466, 11, 264, 23831, 12512, 11, 436, 434, 6457, 7401, 13, 50624, 50624, 467, 311, 406, 4258, 1850, 1968, 309, 311, 8416, 322, 264, 2017, 420, 1968, 309, 311, 8416, 322, 300, 50812, 50812, 2302, 47982, 3410, 13, 50946, 50946, 400, 370, 322, 11, 1333, 295, 3052, 22085, 13, 51082, 51082, 400, 934, 1237, 412, 257, 688, 295, 613, 5110, 11, 321, 8932, 484, 300, 309, 390, 534, 1237, 51272, 51272, 412, 264, 10774, 295, 264, 954, 13, 51386, 51386, 407, 498, 291, 574, 412, 294, 264, 1192, 5386, 11, 264, 954, 307, 884, 1333, 295, 364, 14119, 11, 307, 14119, 760, 13, 51608, 51608, 400, 300, 311, 1333, 295, 264, 23831, 5987, 19817, 937, 382, 731, 13, 51752, 51752], "temperature": 0.0, "avg_logprob": -0.12957748886226683, "compression_ratio": 1.8801498127340823, "no_speech_prob": 3.905425728589762e-06}, {"id": 470, "seek": 183136, "start": 1845.7199999999998, "end": 1849.52, "text": " And after looking at a lot of these examples, we figured out that it was really looking", "tokens": [50364, 759, 291, 574, 412, 264, 39426, 293, 1466, 11, 264, 23831, 12512, 11, 436, 434, 6457, 7401, 13, 50624, 50624, 467, 311, 406, 4258, 1850, 1968, 309, 311, 8416, 322, 264, 2017, 420, 1968, 309, 311, 8416, 322, 300, 50812, 50812, 2302, 47982, 3410, 13, 50946, 50946, 400, 370, 322, 11, 1333, 295, 3052, 22085, 13, 51082, 51082, 400, 934, 1237, 412, 257, 688, 295, 613, 5110, 11, 321, 8932, 484, 300, 309, 390, 534, 1237, 51272, 51272, 412, 264, 10774, 295, 264, 954, 13, 51386, 51386, 407, 498, 291, 574, 412, 294, 264, 1192, 5386, 11, 264, 954, 307, 884, 1333, 295, 364, 14119, 11, 307, 14119, 760, 13, 51608, 51608, 400, 300, 311, 1333, 295, 264, 23831, 5987, 19817, 937, 382, 731, 13, 51752, 51752], "temperature": 0.0, "avg_logprob": -0.12957748886226683, "compression_ratio": 1.8801498127340823, "no_speech_prob": 3.905425728589762e-06}, {"id": 471, "seek": 183136, "start": 1849.52, "end": 1851.8, "text": " at the pose of the person.", "tokens": [50364, 759, 291, 574, 412, 264, 39426, 293, 1466, 11, 264, 23831, 12512, 11, 436, 434, 6457, 7401, 13, 50624, 50624, 467, 311, 406, 4258, 1850, 1968, 309, 311, 8416, 322, 264, 2017, 420, 1968, 309, 311, 8416, 322, 300, 50812, 50812, 2302, 47982, 3410, 13, 50946, 50946, 400, 370, 322, 11, 1333, 295, 3052, 22085, 13, 51082, 51082, 400, 934, 1237, 412, 257, 688, 295, 613, 5110, 11, 321, 8932, 484, 300, 309, 390, 534, 1237, 51272, 51272, 412, 264, 10774, 295, 264, 954, 13, 51386, 51386, 407, 498, 291, 574, 412, 294, 264, 1192, 5386, 11, 264, 954, 307, 884, 1333, 295, 364, 14119, 11, 307, 14119, 760, 13, 51608, 51608, 400, 300, 311, 1333, 295, 264, 23831, 5987, 19817, 937, 382, 731, 13, 51752, 51752], "temperature": 0.0, "avg_logprob": -0.12957748886226683, "compression_ratio": 1.8801498127340823, "no_speech_prob": 3.905425728589762e-06}, {"id": 472, "seek": 183136, "start": 1851.8, "end": 1856.24, "text": " So if you look at in the top row, the person is doing sort of an upside, is upside down.", "tokens": [50364, 759, 291, 574, 412, 264, 39426, 293, 1466, 11, 264, 23831, 12512, 11, 436, 434, 6457, 7401, 13, 50624, 50624, 467, 311, 406, 4258, 1850, 1968, 309, 311, 8416, 322, 264, 2017, 420, 1968, 309, 311, 8416, 322, 300, 50812, 50812, 2302, 47982, 3410, 13, 50946, 50946, 400, 370, 322, 11, 1333, 295, 3052, 22085, 13, 51082, 51082, 400, 934, 1237, 412, 257, 688, 295, 613, 5110, 11, 321, 8932, 484, 300, 309, 390, 534, 1237, 51272, 51272, 412, 264, 10774, 295, 264, 954, 13, 51386, 51386, 407, 498, 291, 574, 412, 294, 264, 1192, 5386, 11, 264, 954, 307, 884, 1333, 295, 364, 14119, 11, 307, 14119, 760, 13, 51608, 51608, 400, 300, 311, 1333, 295, 264, 23831, 5987, 19817, 937, 382, 731, 13, 51752, 51752], "temperature": 0.0, "avg_logprob": -0.12957748886226683, "compression_ratio": 1.8801498127340823, "no_speech_prob": 3.905425728589762e-06}, {"id": 473, "seek": 183136, "start": 1856.24, "end": 1859.12, "text": " And that's sort of the nearest neighbor retrieved as well.", "tokens": [50364, 759, 291, 574, 412, 264, 39426, 293, 1466, 11, 264, 23831, 12512, 11, 436, 434, 6457, 7401, 13, 50624, 50624, 467, 311, 406, 4258, 1850, 1968, 309, 311, 8416, 322, 264, 2017, 420, 1968, 309, 311, 8416, 322, 300, 50812, 50812, 2302, 47982, 3410, 13, 50946, 50946, 400, 370, 322, 11, 1333, 295, 3052, 22085, 13, 51082, 51082, 400, 934, 1237, 412, 257, 688, 295, 613, 5110, 11, 321, 8932, 484, 300, 309, 390, 534, 1237, 51272, 51272, 412, 264, 10774, 295, 264, 954, 13, 51386, 51386, 407, 498, 291, 574, 412, 294, 264, 1192, 5386, 11, 264, 954, 307, 884, 1333, 295, 364, 14119, 11, 307, 14119, 760, 13, 51608, 51608, 400, 300, 311, 1333, 295, 264, 23831, 5987, 19817, 937, 382, 731, 13, 51752, 51752], "temperature": 0.0, "avg_logprob": -0.12957748886226683, "compression_ratio": 1.8801498127340823, "no_speech_prob": 3.905425728589762e-06}, {"id": 474, "seek": 185912, "start": 1859.12, "end": 1863.4399999999998, "text": " And in the second row, also the person is sort of has their foot in a, like has their", "tokens": [50364, 400, 294, 264, 1150, 5386, 11, 611, 264, 954, 307, 1333, 295, 575, 641, 2671, 294, 257, 11, 411, 575, 641, 50580, 50580, 3521, 294, 257, 1729, 636, 13, 50674, 50674, 400, 309, 311, 534, 1382, 281, 1333, 295, 483, 456, 365, 1080, 23831, 5987, 13, 50838, 50838, 400, 309, 311, 1333, 295, 26258, 264, 2302, 4145, 13, 50938, 50938, 407, 309, 311, 406, 534, 5178, 322, 264, 3678, 13, 51148, 51148, 400, 562, 321, 645, 1953, 466, 341, 11, 983, 576, 257, 3209, 754, 853, 281, 360, 746, 295, 51332, 51332, 341, 1333, 30, 51382, 51382, 1042, 11, 321, 2956, 11, 321, 1194, 646, 281, 527, 659, 25111, 5633, 13, 51552, 51552, 407, 264, 659, 25111, 5633, 390, 32884, 264, 1668, 420, 1936, 32884, 1968, 721, 366, 51816, 51816], "temperature": 0.0, "avg_logprob": -0.15091228485107422, "compression_ratio": 1.792982456140351, "no_speech_prob": 3.905422090610955e-06}, {"id": 475, "seek": 185912, "start": 1863.4399999999998, "end": 1865.32, "text": " feet in a particular way.", "tokens": [50364, 400, 294, 264, 1150, 5386, 11, 611, 264, 954, 307, 1333, 295, 575, 641, 2671, 294, 257, 11, 411, 575, 641, 50580, 50580, 3521, 294, 257, 1729, 636, 13, 50674, 50674, 400, 309, 311, 534, 1382, 281, 1333, 295, 483, 456, 365, 1080, 23831, 5987, 13, 50838, 50838, 400, 309, 311, 1333, 295, 26258, 264, 2302, 4145, 13, 50938, 50938, 407, 309, 311, 406, 534, 5178, 322, 264, 3678, 13, 51148, 51148, 400, 562, 321, 645, 1953, 466, 341, 11, 983, 576, 257, 3209, 754, 853, 281, 360, 746, 295, 51332, 51332, 341, 1333, 30, 51382, 51382, 1042, 11, 321, 2956, 11, 321, 1194, 646, 281, 527, 659, 25111, 5633, 13, 51552, 51552, 407, 264, 659, 25111, 5633, 390, 32884, 264, 1668, 420, 1936, 32884, 1968, 721, 366, 51816, 51816], "temperature": 0.0, "avg_logprob": -0.15091228485107422, "compression_ratio": 1.792982456140351, "no_speech_prob": 3.905422090610955e-06}, {"id": 476, "seek": 185912, "start": 1865.32, "end": 1868.6, "text": " And it's really trying to sort of get there with its nearest neighbor.", "tokens": [50364, 400, 294, 264, 1150, 5386, 11, 611, 264, 954, 307, 1333, 295, 575, 641, 2671, 294, 257, 11, 411, 575, 641, 50580, 50580, 3521, 294, 257, 1729, 636, 13, 50674, 50674, 400, 309, 311, 534, 1382, 281, 1333, 295, 483, 456, 365, 1080, 23831, 5987, 13, 50838, 50838, 400, 309, 311, 1333, 295, 26258, 264, 2302, 4145, 13, 50938, 50938, 407, 309, 311, 406, 534, 5178, 322, 264, 3678, 13, 51148, 51148, 400, 562, 321, 645, 1953, 466, 341, 11, 983, 576, 257, 3209, 754, 853, 281, 360, 746, 295, 51332, 51332, 341, 1333, 30, 51382, 51382, 1042, 11, 321, 2956, 11, 321, 1194, 646, 281, 527, 659, 25111, 5633, 13, 51552, 51552, 407, 264, 659, 25111, 5633, 390, 32884, 264, 1668, 420, 1936, 32884, 1968, 721, 366, 51816, 51816], "temperature": 0.0, "avg_logprob": -0.15091228485107422, "compression_ratio": 1.792982456140351, "no_speech_prob": 3.905422090610955e-06}, {"id": 477, "seek": 185912, "start": 1868.6, "end": 1870.6, "text": " And it's sort of ignoring the entire scene.", "tokens": [50364, 400, 294, 264, 1150, 5386, 11, 611, 264, 954, 307, 1333, 295, 575, 641, 2671, 294, 257, 11, 411, 575, 641, 50580, 50580, 3521, 294, 257, 1729, 636, 13, 50674, 50674, 400, 309, 311, 534, 1382, 281, 1333, 295, 483, 456, 365, 1080, 23831, 5987, 13, 50838, 50838, 400, 309, 311, 1333, 295, 26258, 264, 2302, 4145, 13, 50938, 50938, 407, 309, 311, 406, 534, 5178, 322, 264, 3678, 13, 51148, 51148, 400, 562, 321, 645, 1953, 466, 341, 11, 983, 576, 257, 3209, 754, 853, 281, 360, 746, 295, 51332, 51332, 341, 1333, 30, 51382, 51382, 1042, 11, 321, 2956, 11, 321, 1194, 646, 281, 527, 659, 25111, 5633, 13, 51552, 51552, 407, 264, 659, 25111, 5633, 390, 32884, 264, 1668, 420, 1936, 32884, 1968, 721, 366, 51816, 51816], "temperature": 0.0, "avg_logprob": -0.15091228485107422, "compression_ratio": 1.792982456140351, "no_speech_prob": 3.905422090610955e-06}, {"id": 478, "seek": 185912, "start": 1870.6, "end": 1874.8, "text": " So it's not really focused on the background.", "tokens": [50364, 400, 294, 264, 1150, 5386, 11, 611, 264, 954, 307, 1333, 295, 575, 641, 2671, 294, 257, 11, 411, 575, 641, 50580, 50580, 3521, 294, 257, 1729, 636, 13, 50674, 50674, 400, 309, 311, 534, 1382, 281, 1333, 295, 483, 456, 365, 1080, 23831, 5987, 13, 50838, 50838, 400, 309, 311, 1333, 295, 26258, 264, 2302, 4145, 13, 50938, 50938, 407, 309, 311, 406, 534, 5178, 322, 264, 3678, 13, 51148, 51148, 400, 562, 321, 645, 1953, 466, 341, 11, 983, 576, 257, 3209, 754, 853, 281, 360, 746, 295, 51332, 51332, 341, 1333, 30, 51382, 51382, 1042, 11, 321, 2956, 11, 321, 1194, 646, 281, 527, 659, 25111, 5633, 13, 51552, 51552, 407, 264, 659, 25111, 5633, 390, 32884, 264, 1668, 420, 1936, 32884, 1968, 721, 366, 51816, 51816], "temperature": 0.0, "avg_logprob": -0.15091228485107422, "compression_ratio": 1.792982456140351, "no_speech_prob": 3.905422090610955e-06}, {"id": 479, "seek": 185912, "start": 1874.8, "end": 1878.4799999999998, "text": " And when we were thinking about this, why would a network even try to do something of", "tokens": [50364, 400, 294, 264, 1150, 5386, 11, 611, 264, 954, 307, 1333, 295, 575, 641, 2671, 294, 257, 11, 411, 575, 641, 50580, 50580, 3521, 294, 257, 1729, 636, 13, 50674, 50674, 400, 309, 311, 534, 1382, 281, 1333, 295, 483, 456, 365, 1080, 23831, 5987, 13, 50838, 50838, 400, 309, 311, 1333, 295, 26258, 264, 2302, 4145, 13, 50938, 50938, 407, 309, 311, 406, 534, 5178, 322, 264, 3678, 13, 51148, 51148, 400, 562, 321, 645, 1953, 466, 341, 11, 983, 576, 257, 3209, 754, 853, 281, 360, 746, 295, 51332, 51332, 341, 1333, 30, 51382, 51382, 1042, 11, 321, 2956, 11, 321, 1194, 646, 281, 527, 659, 25111, 5633, 13, 51552, 51552, 407, 264, 659, 25111, 5633, 390, 32884, 264, 1668, 420, 1936, 32884, 1968, 721, 366, 51816, 51816], "temperature": 0.0, "avg_logprob": -0.15091228485107422, "compression_ratio": 1.792982456140351, "no_speech_prob": 3.905422090610955e-06}, {"id": 480, "seek": 185912, "start": 1878.4799999999998, "end": 1879.4799999999998, "text": " this sort?", "tokens": [50364, 400, 294, 264, 1150, 5386, 11, 611, 264, 954, 307, 1333, 295, 575, 641, 2671, 294, 257, 11, 411, 575, 641, 50580, 50580, 3521, 294, 257, 1729, 636, 13, 50674, 50674, 400, 309, 311, 534, 1382, 281, 1333, 295, 483, 456, 365, 1080, 23831, 5987, 13, 50838, 50838, 400, 309, 311, 1333, 295, 26258, 264, 2302, 4145, 13, 50938, 50938, 407, 309, 311, 406, 534, 5178, 322, 264, 3678, 13, 51148, 51148, 400, 562, 321, 645, 1953, 466, 341, 11, 983, 576, 257, 3209, 754, 853, 281, 360, 746, 295, 51332, 51332, 341, 1333, 30, 51382, 51382, 1042, 11, 321, 2956, 11, 321, 1194, 646, 281, 527, 659, 25111, 5633, 13, 51552, 51552, 407, 264, 659, 25111, 5633, 390, 32884, 264, 1668, 420, 1936, 32884, 1968, 721, 366, 51816, 51816], "temperature": 0.0, "avg_logprob": -0.15091228485107422, "compression_ratio": 1.792982456140351, "no_speech_prob": 3.905422090610955e-06}, {"id": 481, "seek": 185912, "start": 1879.4799999999998, "end": 1882.8799999999999, "text": " Well, we looked, we thought back to our pretext task.", "tokens": [50364, 400, 294, 264, 1150, 5386, 11, 611, 264, 954, 307, 1333, 295, 575, 641, 2671, 294, 257, 11, 411, 575, 641, 50580, 50580, 3521, 294, 257, 1729, 636, 13, 50674, 50674, 400, 309, 311, 534, 1382, 281, 1333, 295, 483, 456, 365, 1080, 23831, 5987, 13, 50838, 50838, 400, 309, 311, 1333, 295, 26258, 264, 2302, 4145, 13, 50938, 50938, 407, 309, 311, 406, 534, 5178, 322, 264, 3678, 13, 51148, 51148, 400, 562, 321, 645, 1953, 466, 341, 11, 983, 576, 257, 3209, 754, 853, 281, 360, 746, 295, 51332, 51332, 341, 1333, 30, 51382, 51382, 1042, 11, 321, 2956, 11, 321, 1194, 646, 281, 527, 659, 25111, 5633, 13, 51552, 51552, 407, 264, 659, 25111, 5633, 390, 32884, 264, 1668, 420, 1936, 32884, 1968, 721, 366, 51816, 51816], "temperature": 0.0, "avg_logprob": -0.15091228485107422, "compression_ratio": 1.792982456140351, "no_speech_prob": 3.905422090610955e-06}, {"id": 482, "seek": 185912, "start": 1882.8799999999999, "end": 1888.1599999999999, "text": " So the pretext task was predicting the order or basically predicting whether things are", "tokens": [50364, 400, 294, 264, 1150, 5386, 11, 611, 264, 954, 307, 1333, 295, 575, 641, 2671, 294, 257, 11, 411, 575, 641, 50580, 50580, 3521, 294, 257, 1729, 636, 13, 50674, 50674, 400, 309, 311, 534, 1382, 281, 1333, 295, 483, 456, 365, 1080, 23831, 5987, 13, 50838, 50838, 400, 309, 311, 1333, 295, 26258, 264, 2302, 4145, 13, 50938, 50938, 407, 309, 311, 406, 534, 5178, 322, 264, 3678, 13, 51148, 51148, 400, 562, 321, 645, 1953, 466, 341, 11, 983, 576, 257, 3209, 754, 853, 281, 360, 746, 295, 51332, 51332, 341, 1333, 30, 51382, 51382, 1042, 11, 321, 2956, 11, 321, 1194, 646, 281, 527, 659, 25111, 5633, 13, 51552, 51552, 407, 264, 659, 25111, 5633, 390, 32884, 264, 1668, 420, 1936, 32884, 1968, 721, 366, 51816, 51816], "temperature": 0.0, "avg_logprob": -0.15091228485107422, "compression_ratio": 1.792982456140351, "no_speech_prob": 3.905422090610955e-06}, {"id": 483, "seek": 188816, "start": 1888.16, "end": 1889.48, "text": " in the right order or not.", "tokens": [50364, 294, 264, 558, 1668, 420, 406, 13, 50430, 50430, 400, 281, 360, 341, 11, 291, 534, 643, 281, 1879, 322, 437, 307, 2684, 294, 264, 4145, 420, 1333, 295, 264, 11, 50744, 50744, 294, 341, 1389, 11, 264, 561, 13, 50842, 50842, 407, 498, 291, 1879, 322, 264, 3678, 11, 291, 603, 1128, 312, 1075, 281, 1867, 341, 1168, 6457, 51022, 51022, 731, 570, 731, 11, 264, 3678, 1177, 380, 1319, 257, 688, 1296, 1045, 12083, 300, 366, 51248, 51248, 2726, 1333, 295, 1998, 538, 294, 257, 960, 13, 51346, 51346, 440, 787, 551, 300, 1333, 295, 2962, 307, 264, 954, 420, 264, 1333, 295, 721, 300, 366, 2684, 51506, 51506, 294, 300, 960, 13, 51583, 51583], "temperature": 0.0, "avg_logprob": -0.1404487064906529, "compression_ratio": 1.792828685258964, "no_speech_prob": 1.6700612832210027e-05}, {"id": 484, "seek": 188816, "start": 1889.48, "end": 1895.76, "text": " And to do this, you really need to focus on what is moving in the scene or sort of the,", "tokens": [50364, 294, 264, 558, 1668, 420, 406, 13, 50430, 50430, 400, 281, 360, 341, 11, 291, 534, 643, 281, 1879, 322, 437, 307, 2684, 294, 264, 4145, 420, 1333, 295, 264, 11, 50744, 50744, 294, 341, 1389, 11, 264, 561, 13, 50842, 50842, 407, 498, 291, 1879, 322, 264, 3678, 11, 291, 603, 1128, 312, 1075, 281, 1867, 341, 1168, 6457, 51022, 51022, 731, 570, 731, 11, 264, 3678, 1177, 380, 1319, 257, 688, 1296, 1045, 12083, 300, 366, 51248, 51248, 2726, 1333, 295, 1998, 538, 294, 257, 960, 13, 51346, 51346, 440, 787, 551, 300, 1333, 295, 2962, 307, 264, 954, 420, 264, 1333, 295, 721, 300, 366, 2684, 51506, 51506, 294, 300, 960, 13, 51583, 51583], "temperature": 0.0, "avg_logprob": -0.1404487064906529, "compression_ratio": 1.792828685258964, "no_speech_prob": 1.6700612832210027e-05}, {"id": 485, "seek": 188816, "start": 1895.76, "end": 1897.72, "text": " in this case, the people.", "tokens": [50364, 294, 264, 558, 1668, 420, 406, 13, 50430, 50430, 400, 281, 360, 341, 11, 291, 534, 643, 281, 1879, 322, 437, 307, 2684, 294, 264, 4145, 420, 1333, 295, 264, 11, 50744, 50744, 294, 341, 1389, 11, 264, 561, 13, 50842, 50842, 407, 498, 291, 1879, 322, 264, 3678, 11, 291, 603, 1128, 312, 1075, 281, 1867, 341, 1168, 6457, 51022, 51022, 731, 570, 731, 11, 264, 3678, 1177, 380, 1319, 257, 688, 1296, 1045, 12083, 300, 366, 51248, 51248, 2726, 1333, 295, 1998, 538, 294, 257, 960, 13, 51346, 51346, 440, 787, 551, 300, 1333, 295, 2962, 307, 264, 954, 420, 264, 1333, 295, 721, 300, 366, 2684, 51506, 51506, 294, 300, 960, 13, 51583, 51583], "temperature": 0.0, "avg_logprob": -0.1404487064906529, "compression_ratio": 1.792828685258964, "no_speech_prob": 1.6700612832210027e-05}, {"id": 486, "seek": 188816, "start": 1897.72, "end": 1901.3200000000002, "text": " So if you focus on the background, you'll never be able to answer this question fairly", "tokens": [50364, 294, 264, 558, 1668, 420, 406, 13, 50430, 50430, 400, 281, 360, 341, 11, 291, 534, 643, 281, 1879, 322, 437, 307, 2684, 294, 264, 4145, 420, 1333, 295, 264, 11, 50744, 50744, 294, 341, 1389, 11, 264, 561, 13, 50842, 50842, 407, 498, 291, 1879, 322, 264, 3678, 11, 291, 603, 1128, 312, 1075, 281, 1867, 341, 1168, 6457, 51022, 51022, 731, 570, 731, 11, 264, 3678, 1177, 380, 1319, 257, 688, 1296, 1045, 12083, 300, 366, 51248, 51248, 2726, 1333, 295, 1998, 538, 294, 257, 960, 13, 51346, 51346, 440, 787, 551, 300, 1333, 295, 2962, 307, 264, 954, 420, 264, 1333, 295, 721, 300, 366, 2684, 51506, 51506, 294, 300, 960, 13, 51583, 51583], "temperature": 0.0, "avg_logprob": -0.1404487064906529, "compression_ratio": 1.792828685258964, "no_speech_prob": 1.6700612832210027e-05}, {"id": 487, "seek": 188816, "start": 1901.3200000000002, "end": 1905.8400000000001, "text": " well because well, the background doesn't change a lot between three frames that are", "tokens": [50364, 294, 264, 558, 1668, 420, 406, 13, 50430, 50430, 400, 281, 360, 341, 11, 291, 534, 643, 281, 1879, 322, 437, 307, 2684, 294, 264, 4145, 420, 1333, 295, 264, 11, 50744, 50744, 294, 341, 1389, 11, 264, 561, 13, 50842, 50842, 407, 498, 291, 1879, 322, 264, 3678, 11, 291, 603, 1128, 312, 1075, 281, 1867, 341, 1168, 6457, 51022, 51022, 731, 570, 731, 11, 264, 3678, 1177, 380, 1319, 257, 688, 1296, 1045, 12083, 300, 366, 51248, 51248, 2726, 1333, 295, 1998, 538, 294, 257, 960, 13, 51346, 51346, 440, 787, 551, 300, 1333, 295, 2962, 307, 264, 954, 420, 264, 1333, 295, 721, 300, 366, 2684, 51506, 51506, 294, 300, 960, 13, 51583, 51583], "temperature": 0.0, "avg_logprob": -0.1404487064906529, "compression_ratio": 1.792828685258964, "no_speech_prob": 1.6700612832210027e-05}, {"id": 488, "seek": 188816, "start": 1905.8400000000001, "end": 1907.8000000000002, "text": " taken sort of close by in a video.", "tokens": [50364, 294, 264, 558, 1668, 420, 406, 13, 50430, 50430, 400, 281, 360, 341, 11, 291, 534, 643, 281, 1879, 322, 437, 307, 2684, 294, 264, 4145, 420, 1333, 295, 264, 11, 50744, 50744, 294, 341, 1389, 11, 264, 561, 13, 50842, 50842, 407, 498, 291, 1879, 322, 264, 3678, 11, 291, 603, 1128, 312, 1075, 281, 1867, 341, 1168, 6457, 51022, 51022, 731, 570, 731, 11, 264, 3678, 1177, 380, 1319, 257, 688, 1296, 1045, 12083, 300, 366, 51248, 51248, 2726, 1333, 295, 1998, 538, 294, 257, 960, 13, 51346, 51346, 440, 787, 551, 300, 1333, 295, 2962, 307, 264, 954, 420, 264, 1333, 295, 721, 300, 366, 2684, 51506, 51506, 294, 300, 960, 13, 51583, 51583], "temperature": 0.0, "avg_logprob": -0.1404487064906529, "compression_ratio": 1.792828685258964, "no_speech_prob": 1.6700612832210027e-05}, {"id": 489, "seek": 188816, "start": 1907.8000000000002, "end": 1911.0, "text": " The only thing that sort of changes is the person or the sort of things that are moving", "tokens": [50364, 294, 264, 558, 1668, 420, 406, 13, 50430, 50430, 400, 281, 360, 341, 11, 291, 534, 643, 281, 1879, 322, 437, 307, 2684, 294, 264, 4145, 420, 1333, 295, 264, 11, 50744, 50744, 294, 341, 1389, 11, 264, 561, 13, 50842, 50842, 407, 498, 291, 1879, 322, 264, 3678, 11, 291, 603, 1128, 312, 1075, 281, 1867, 341, 1168, 6457, 51022, 51022, 731, 570, 731, 11, 264, 3678, 1177, 380, 1319, 257, 688, 1296, 1045, 12083, 300, 366, 51248, 51248, 2726, 1333, 295, 1998, 538, 294, 257, 960, 13, 51346, 51346, 440, 787, 551, 300, 1333, 295, 2962, 307, 264, 954, 420, 264, 1333, 295, 721, 300, 366, 2684, 51506, 51506, 294, 300, 960, 13, 51583, 51583], "temperature": 0.0, "avg_logprob": -0.1404487064906529, "compression_ratio": 1.792828685258964, "no_speech_prob": 1.6700612832210027e-05}, {"id": 490, "seek": 188816, "start": 1911.0, "end": 1912.5400000000002, "text": " in that video.", "tokens": [50364, 294, 264, 558, 1668, 420, 406, 13, 50430, 50430, 400, 281, 360, 341, 11, 291, 534, 643, 281, 1879, 322, 437, 307, 2684, 294, 264, 4145, 420, 1333, 295, 264, 11, 50744, 50744, 294, 341, 1389, 11, 264, 561, 13, 50842, 50842, 407, 498, 291, 1879, 322, 264, 3678, 11, 291, 603, 1128, 312, 1075, 281, 1867, 341, 1168, 6457, 51022, 51022, 731, 570, 731, 11, 264, 3678, 1177, 380, 1319, 257, 688, 1296, 1045, 12083, 300, 366, 51248, 51248, 2726, 1333, 295, 1998, 538, 294, 257, 960, 13, 51346, 51346, 440, 787, 551, 300, 1333, 295, 2962, 307, 264, 954, 420, 264, 1333, 295, 721, 300, 366, 2684, 51506, 51506, 294, 300, 960, 13, 51583, 51583], "temperature": 0.0, "avg_logprob": -0.1404487064906529, "compression_ratio": 1.792828685258964, "no_speech_prob": 1.6700612832210027e-05}, {"id": 491, "seek": 191254, "start": 1912.54, "end": 1918.1599999999999, "text": " So sort of accidentally, we basically trained a network that was really trying to sort of", "tokens": [50364, 407, 1333, 295, 15715, 11, 321, 1936, 8895, 257, 3209, 300, 390, 534, 1382, 281, 1333, 295, 50645, 50645, 574, 412, 721, 300, 366, 2684, 293, 550, 4590, 493, 8416, 322, 264, 10774, 295, 341, 11, 10774, 295, 561, 13, 50965, 50965, 823, 11, 295, 1164, 11, 341, 307, 452, 14174, 13, 51135, 51135, 492, 1415, 281, 16888, 341, 27778, 356, 13, 51331, 51331, 407, 437, 321, 630, 307, 321, 1890, 527, 10290, 293, 321, 2489, 10870, 309, 322, 341, 5633, 295, 1952, 51595, 51595, 2141, 935, 35701, 13, 51671, 51671, 407, 341, 5633, 307, 1936, 2212, 493, 1952, 13, 51819, 51819], "temperature": 0.0, "avg_logprob": -0.12566205171438363, "compression_ratio": 1.728395061728395, "no_speech_prob": 5.422040885605384e-06}, {"id": 492, "seek": 191254, "start": 1918.1599999999999, "end": 1924.56, "text": " look at things that are moving and then ended up focusing on the pose of this, pose of people.", "tokens": [50364, 407, 1333, 295, 15715, 11, 321, 1936, 8895, 257, 3209, 300, 390, 534, 1382, 281, 1333, 295, 50645, 50645, 574, 412, 721, 300, 366, 2684, 293, 550, 4590, 493, 8416, 322, 264, 10774, 295, 341, 11, 10774, 295, 561, 13, 50965, 50965, 823, 11, 295, 1164, 11, 341, 307, 452, 14174, 13, 51135, 51135, 492, 1415, 281, 16888, 341, 27778, 356, 13, 51331, 51331, 407, 437, 321, 630, 307, 321, 1890, 527, 10290, 293, 321, 2489, 10870, 309, 322, 341, 5633, 295, 1952, 51595, 51595, 2141, 935, 35701, 13, 51671, 51671, 407, 341, 5633, 307, 1936, 2212, 493, 1952, 13, 51819, 51819], "temperature": 0.0, "avg_logprob": -0.12566205171438363, "compression_ratio": 1.728395061728395, "no_speech_prob": 5.422040885605384e-06}, {"id": 493, "seek": 191254, "start": 1924.56, "end": 1927.96, "text": " Now, of course, this is my interpretation.", "tokens": [50364, 407, 1333, 295, 15715, 11, 321, 1936, 8895, 257, 3209, 300, 390, 534, 1382, 281, 1333, 295, 50645, 50645, 574, 412, 721, 300, 366, 2684, 293, 550, 4590, 493, 8416, 322, 264, 10774, 295, 341, 11, 10774, 295, 561, 13, 50965, 50965, 823, 11, 295, 1164, 11, 341, 307, 452, 14174, 13, 51135, 51135, 492, 1415, 281, 16888, 341, 27778, 356, 13, 51331, 51331, 407, 437, 321, 630, 307, 321, 1890, 527, 10290, 293, 321, 2489, 10870, 309, 322, 341, 5633, 295, 1952, 51595, 51595, 2141, 935, 35701, 13, 51671, 51671, 407, 341, 5633, 307, 1936, 2212, 493, 1952, 13, 51819, 51819], "temperature": 0.0, "avg_logprob": -0.12566205171438363, "compression_ratio": 1.728395061728395, "no_speech_prob": 5.422040885605384e-06}, {"id": 494, "seek": 191254, "start": 1927.96, "end": 1931.8799999999999, "text": " We wanted to verify this quantitatively.", "tokens": [50364, 407, 1333, 295, 15715, 11, 321, 1936, 8895, 257, 3209, 300, 390, 534, 1382, 281, 1333, 295, 50645, 50645, 574, 412, 721, 300, 366, 2684, 293, 550, 4590, 493, 8416, 322, 264, 10774, 295, 341, 11, 10774, 295, 561, 13, 50965, 50965, 823, 11, 295, 1164, 11, 341, 307, 452, 14174, 13, 51135, 51135, 492, 1415, 281, 16888, 341, 27778, 356, 13, 51331, 51331, 407, 437, 321, 630, 307, 321, 1890, 527, 10290, 293, 321, 2489, 10870, 309, 322, 341, 5633, 295, 1952, 51595, 51595, 2141, 935, 35701, 13, 51671, 51671, 407, 341, 5633, 307, 1936, 2212, 493, 1952, 13, 51819, 51819], "temperature": 0.0, "avg_logprob": -0.12566205171438363, "compression_ratio": 1.728395061728395, "no_speech_prob": 5.422040885605384e-06}, {"id": 495, "seek": 191254, "start": 1931.8799999999999, "end": 1937.1599999999999, "text": " So what we did is we took our representation and we fine tuned it on this task of human", "tokens": [50364, 407, 1333, 295, 15715, 11, 321, 1936, 8895, 257, 3209, 300, 390, 534, 1382, 281, 1333, 295, 50645, 50645, 574, 412, 721, 300, 366, 2684, 293, 550, 4590, 493, 8416, 322, 264, 10774, 295, 341, 11, 10774, 295, 561, 13, 50965, 50965, 823, 11, 295, 1164, 11, 341, 307, 452, 14174, 13, 51135, 51135, 492, 1415, 281, 16888, 341, 27778, 356, 13, 51331, 51331, 407, 437, 321, 630, 307, 321, 1890, 527, 10290, 293, 321, 2489, 10870, 309, 322, 341, 5633, 295, 1952, 51595, 51595, 2141, 935, 35701, 13, 51671, 51671, 407, 341, 5633, 307, 1936, 2212, 493, 1952, 13, 51819, 51819], "temperature": 0.0, "avg_logprob": -0.12566205171438363, "compression_ratio": 1.728395061728395, "no_speech_prob": 5.422040885605384e-06}, {"id": 496, "seek": 191254, "start": 1937.1599999999999, "end": 1938.68, "text": " key point estimation.", "tokens": [50364, 407, 1333, 295, 15715, 11, 321, 1936, 8895, 257, 3209, 300, 390, 534, 1382, 281, 1333, 295, 50645, 50645, 574, 412, 721, 300, 366, 2684, 293, 550, 4590, 493, 8416, 322, 264, 10774, 295, 341, 11, 10774, 295, 561, 13, 50965, 50965, 823, 11, 295, 1164, 11, 341, 307, 452, 14174, 13, 51135, 51135, 492, 1415, 281, 16888, 341, 27778, 356, 13, 51331, 51331, 407, 437, 321, 630, 307, 321, 1890, 527, 10290, 293, 321, 2489, 10870, 309, 322, 341, 5633, 295, 1952, 51595, 51595, 2141, 935, 35701, 13, 51671, 51671, 407, 341, 5633, 307, 1936, 2212, 493, 1952, 13, 51819, 51819], "temperature": 0.0, "avg_logprob": -0.12566205171438363, "compression_ratio": 1.728395061728395, "no_speech_prob": 5.422040885605384e-06}, {"id": 497, "seek": 191254, "start": 1938.68, "end": 1941.6399999999999, "text": " So this task is basically given up human.", "tokens": [50364, 407, 1333, 295, 15715, 11, 321, 1936, 8895, 257, 3209, 300, 390, 534, 1382, 281, 1333, 295, 50645, 50645, 574, 412, 721, 300, 366, 2684, 293, 550, 4590, 493, 8416, 322, 264, 10774, 295, 341, 11, 10774, 295, 561, 13, 50965, 50965, 823, 11, 295, 1164, 11, 341, 307, 452, 14174, 13, 51135, 51135, 492, 1415, 281, 16888, 341, 27778, 356, 13, 51331, 51331, 407, 437, 321, 630, 307, 321, 1890, 527, 10290, 293, 321, 2489, 10870, 309, 322, 341, 5633, 295, 1952, 51595, 51595, 2141, 935, 35701, 13, 51671, 51671, 407, 341, 5633, 307, 1936, 2212, 493, 1952, 13, 51819, 51819], "temperature": 0.0, "avg_logprob": -0.12566205171438363, "compression_ratio": 1.728395061728395, "no_speech_prob": 5.422040885605384e-06}, {"id": 498, "seek": 194164, "start": 1941.64, "end": 1945.5600000000002, "text": " You need to sort of predict where certain key points are.", "tokens": [50364, 509, 643, 281, 1333, 295, 6069, 689, 1629, 2141, 2793, 366, 13, 50560, 50560, 407, 264, 2141, 2793, 366, 516, 281, 312, 11, 436, 434, 7642, 382, 1936, 584, 264, 6690, 11, 264, 6189, 11, 50920, 50920, 264, 1411, 7948, 11, 558, 7948, 11, 558, 18507, 11, 1411, 18507, 11, 15043, 11, 293, 370, 322, 13, 51148, 51148, 407, 291, 1936, 362, 613, 3840, 295, 659, 37716, 2141, 2793, 293, 291, 3847, 257, 3209, 281, 1333, 51334, 51334, 295, 6069, 341, 13, 51384, 51384, 407, 341, 307, 534, 4420, 337, 746, 411, 11603, 420, 10774, 35701, 295, 257, 954, 13, 51744, 51744], "temperature": 0.0, "avg_logprob": -0.11948666205772987, "compression_ratio": 1.8407079646017699, "no_speech_prob": 1.1659032679744996e-05}, {"id": 499, "seek": 194164, "start": 1945.5600000000002, "end": 1952.76, "text": " So the key points are going to be, they're defined as basically say the nose, the neck,", "tokens": [50364, 509, 643, 281, 1333, 295, 6069, 689, 1629, 2141, 2793, 366, 13, 50560, 50560, 407, 264, 2141, 2793, 366, 516, 281, 312, 11, 436, 434, 7642, 382, 1936, 584, 264, 6690, 11, 264, 6189, 11, 50920, 50920, 264, 1411, 7948, 11, 558, 7948, 11, 558, 18507, 11, 1411, 18507, 11, 15043, 11, 293, 370, 322, 13, 51148, 51148, 407, 291, 1936, 362, 613, 3840, 295, 659, 37716, 2141, 2793, 293, 291, 3847, 257, 3209, 281, 1333, 51334, 51334, 295, 6069, 341, 13, 51384, 51384, 407, 341, 307, 534, 4420, 337, 746, 411, 11603, 420, 10774, 35701, 295, 257, 954, 13, 51744, 51744], "temperature": 0.0, "avg_logprob": -0.11948666205772987, "compression_ratio": 1.8407079646017699, "no_speech_prob": 1.1659032679744996e-05}, {"id": 500, "seek": 194164, "start": 1952.76, "end": 1957.3200000000002, "text": " the left shoulder, right shoulder, right elbow, left elbow, wrist, and so on.", "tokens": [50364, 509, 643, 281, 1333, 295, 6069, 689, 1629, 2141, 2793, 366, 13, 50560, 50560, 407, 264, 2141, 2793, 366, 516, 281, 312, 11, 436, 434, 7642, 382, 1936, 584, 264, 6690, 11, 264, 6189, 11, 50920, 50920, 264, 1411, 7948, 11, 558, 7948, 11, 558, 18507, 11, 1411, 18507, 11, 15043, 11, 293, 370, 322, 13, 51148, 51148, 407, 291, 1936, 362, 613, 3840, 295, 659, 37716, 2141, 2793, 293, 291, 3847, 257, 3209, 281, 1333, 51334, 51334, 295, 6069, 341, 13, 51384, 51384, 407, 341, 307, 534, 4420, 337, 746, 411, 11603, 420, 10774, 35701, 295, 257, 954, 13, 51744, 51744], "temperature": 0.0, "avg_logprob": -0.11948666205772987, "compression_ratio": 1.8407079646017699, "no_speech_prob": 1.1659032679744996e-05}, {"id": 501, "seek": 194164, "start": 1957.3200000000002, "end": 1961.0400000000002, "text": " So you basically have these bunch of predefined key points and you train a network to sort", "tokens": [50364, 509, 643, 281, 1333, 295, 6069, 689, 1629, 2141, 2793, 366, 13, 50560, 50560, 407, 264, 2141, 2793, 366, 516, 281, 312, 11, 436, 434, 7642, 382, 1936, 584, 264, 6690, 11, 264, 6189, 11, 50920, 50920, 264, 1411, 7948, 11, 558, 7948, 11, 558, 18507, 11, 1411, 18507, 11, 15043, 11, 293, 370, 322, 13, 51148, 51148, 407, 291, 1936, 362, 613, 3840, 295, 659, 37716, 2141, 2793, 293, 291, 3847, 257, 3209, 281, 1333, 51334, 51334, 295, 6069, 341, 13, 51384, 51384, 407, 341, 307, 534, 4420, 337, 746, 411, 11603, 420, 10774, 35701, 295, 257, 954, 13, 51744, 51744], "temperature": 0.0, "avg_logprob": -0.11948666205772987, "compression_ratio": 1.8407079646017699, "no_speech_prob": 1.1659032679744996e-05}, {"id": 502, "seek": 194164, "start": 1961.0400000000002, "end": 1962.0400000000002, "text": " of predict this.", "tokens": [50364, 509, 643, 281, 1333, 295, 6069, 689, 1629, 2141, 2793, 366, 13, 50560, 50560, 407, 264, 2141, 2793, 366, 516, 281, 312, 11, 436, 434, 7642, 382, 1936, 584, 264, 6690, 11, 264, 6189, 11, 50920, 50920, 264, 1411, 7948, 11, 558, 7948, 11, 558, 18507, 11, 1411, 18507, 11, 15043, 11, 293, 370, 322, 13, 51148, 51148, 407, 291, 1936, 362, 613, 3840, 295, 659, 37716, 2141, 2793, 293, 291, 3847, 257, 3209, 281, 1333, 51334, 51334, 295, 6069, 341, 13, 51384, 51384, 407, 341, 307, 534, 4420, 337, 746, 411, 11603, 420, 10774, 35701, 295, 257, 954, 13, 51744, 51744], "temperature": 0.0, "avg_logprob": -0.11948666205772987, "compression_ratio": 1.8407079646017699, "no_speech_prob": 1.1659032679744996e-05}, {"id": 503, "seek": 194164, "start": 1962.0400000000002, "end": 1969.24, "text": " So this is really useful for something like tracking or pose estimation of a person.", "tokens": [50364, 509, 643, 281, 1333, 295, 6069, 689, 1629, 2141, 2793, 366, 13, 50560, 50560, 407, 264, 2141, 2793, 366, 516, 281, 312, 11, 436, 434, 7642, 382, 1936, 584, 264, 6690, 11, 264, 6189, 11, 50920, 50920, 264, 1411, 7948, 11, 558, 7948, 11, 558, 18507, 11, 1411, 18507, 11, 15043, 11, 293, 370, 322, 13, 51148, 51148, 407, 291, 1936, 362, 613, 3840, 295, 659, 37716, 2141, 2793, 293, 291, 3847, 257, 3209, 281, 1333, 51334, 51334, 295, 6069, 341, 13, 51384, 51384, 407, 341, 307, 534, 4420, 337, 746, 411, 11603, 420, 10774, 35701, 295, 257, 954, 13, 51744, 51744], "temperature": 0.0, "avg_logprob": -0.11948666205772987, "compression_ratio": 1.8407079646017699, "no_speech_prob": 1.1659032679744996e-05}, {"id": 504, "seek": 196924, "start": 1969.24, "end": 1975.48, "text": " So we took our shuffle and learn self-supervised method and we fine tuned it on these two datasets", "tokens": [50364, 407, 321, 1890, 527, 39426, 293, 1466, 2698, 12, 48172, 24420, 3170, 293, 321, 2489, 10870, 309, 322, 613, 732, 42856, 50676, 50676, 1219, 3235, 618, 293, 14146, 9503, 13, 50814, 50814, 400, 321, 630, 264, 912, 551, 337, 29903, 31890, 46533, 3209, 13, 50978, 50978, 400, 341, 307, 646, 294, 264, 1708, 295, 5202, 31890, 13, 51063, 51063, 407, 5202, 31890, 390, 264, 9482, 300, 321, 1143, 13, 51232, 51232, 400, 294, 1333, 295, 6457, 17600, 11, 437, 321, 1352, 307, 300, 264, 2698, 12, 48172, 24420, 10290, 51566, 51566, 390, 588, 10043, 420, 754, 4748, 1101, 813, 29903, 31890, 46533, 10290, 412, 51816, 51816], "temperature": 0.0, "avg_logprob": -0.13464872925369828, "compression_ratio": 1.7297297297297298, "no_speech_prob": 7.766605449432973e-06}, {"id": 505, "seek": 196924, "start": 1975.48, "end": 1978.24, "text": " called Flick and MPII.", "tokens": [50364, 407, 321, 1890, 527, 39426, 293, 1466, 2698, 12, 48172, 24420, 3170, 293, 321, 2489, 10870, 309, 322, 613, 732, 42856, 50676, 50676, 1219, 3235, 618, 293, 14146, 9503, 13, 50814, 50814, 400, 321, 630, 264, 912, 551, 337, 29903, 31890, 46533, 3209, 13, 50978, 50978, 400, 341, 307, 646, 294, 264, 1708, 295, 5202, 31890, 13, 51063, 51063, 407, 5202, 31890, 390, 264, 9482, 300, 321, 1143, 13, 51232, 51232, 400, 294, 1333, 295, 6457, 17600, 11, 437, 321, 1352, 307, 300, 264, 2698, 12, 48172, 24420, 10290, 51566, 51566, 390, 588, 10043, 420, 754, 4748, 1101, 813, 29903, 31890, 46533, 10290, 412, 51816, 51816], "temperature": 0.0, "avg_logprob": -0.13464872925369828, "compression_ratio": 1.7297297297297298, "no_speech_prob": 7.766605449432973e-06}, {"id": 506, "seek": 196924, "start": 1978.24, "end": 1981.52, "text": " And we did the same thing for ImageNet supervised network.", "tokens": [50364, 407, 321, 1890, 527, 39426, 293, 1466, 2698, 12, 48172, 24420, 3170, 293, 321, 2489, 10870, 309, 322, 613, 732, 42856, 50676, 50676, 1219, 3235, 618, 293, 14146, 9503, 13, 50814, 50814, 400, 321, 630, 264, 912, 551, 337, 29903, 31890, 46533, 3209, 13, 50978, 50978, 400, 341, 307, 646, 294, 264, 1708, 295, 5202, 31890, 13, 51063, 51063, 407, 5202, 31890, 390, 264, 9482, 300, 321, 1143, 13, 51232, 51232, 400, 294, 1333, 295, 6457, 17600, 11, 437, 321, 1352, 307, 300, 264, 2698, 12, 48172, 24420, 10290, 51566, 51566, 390, 588, 10043, 420, 754, 4748, 1101, 813, 29903, 31890, 46533, 10290, 412, 51816, 51816], "temperature": 0.0, "avg_logprob": -0.13464872925369828, "compression_ratio": 1.7297297297297298, "no_speech_prob": 7.766605449432973e-06}, {"id": 507, "seek": 196924, "start": 1981.52, "end": 1983.22, "text": " And this is back in the days of AlexNet.", "tokens": [50364, 407, 321, 1890, 527, 39426, 293, 1466, 2698, 12, 48172, 24420, 3170, 293, 321, 2489, 10870, 309, 322, 613, 732, 42856, 50676, 50676, 1219, 3235, 618, 293, 14146, 9503, 13, 50814, 50814, 400, 321, 630, 264, 912, 551, 337, 29903, 31890, 46533, 3209, 13, 50978, 50978, 400, 341, 307, 646, 294, 264, 1708, 295, 5202, 31890, 13, 51063, 51063, 407, 5202, 31890, 390, 264, 9482, 300, 321, 1143, 13, 51232, 51232, 400, 294, 1333, 295, 6457, 17600, 11, 437, 321, 1352, 307, 300, 264, 2698, 12, 48172, 24420, 10290, 51566, 51566, 390, 588, 10043, 420, 754, 4748, 1101, 813, 29903, 31890, 46533, 10290, 412, 51816, 51816], "temperature": 0.0, "avg_logprob": -0.13464872925369828, "compression_ratio": 1.7297297297297298, "no_speech_prob": 7.766605449432973e-06}, {"id": 508, "seek": 196924, "start": 1983.22, "end": 1986.6, "text": " So AlexNet was the architecture that we used.", "tokens": [50364, 407, 321, 1890, 527, 39426, 293, 1466, 2698, 12, 48172, 24420, 3170, 293, 321, 2489, 10870, 309, 322, 613, 732, 42856, 50676, 50676, 1219, 3235, 618, 293, 14146, 9503, 13, 50814, 50814, 400, 321, 630, 264, 912, 551, 337, 29903, 31890, 46533, 3209, 13, 50978, 50978, 400, 341, 307, 646, 294, 264, 1708, 295, 5202, 31890, 13, 51063, 51063, 407, 5202, 31890, 390, 264, 9482, 300, 321, 1143, 13, 51232, 51232, 400, 294, 1333, 295, 6457, 17600, 11, 437, 321, 1352, 307, 300, 264, 2698, 12, 48172, 24420, 10290, 51566, 51566, 390, 588, 10043, 420, 754, 4748, 1101, 813, 29903, 31890, 46533, 10290, 412, 51816, 51816], "temperature": 0.0, "avg_logprob": -0.13464872925369828, "compression_ratio": 1.7297297297297298, "no_speech_prob": 7.766605449432973e-06}, {"id": 509, "seek": 196924, "start": 1986.6, "end": 1993.28, "text": " And in sort of fairly surprisingly, what we found is that the self-supervised representation", "tokens": [50364, 407, 321, 1890, 527, 39426, 293, 1466, 2698, 12, 48172, 24420, 3170, 293, 321, 2489, 10870, 309, 322, 613, 732, 42856, 50676, 50676, 1219, 3235, 618, 293, 14146, 9503, 13, 50814, 50814, 400, 321, 630, 264, 912, 551, 337, 29903, 31890, 46533, 3209, 13, 50978, 50978, 400, 341, 307, 646, 294, 264, 1708, 295, 5202, 31890, 13, 51063, 51063, 407, 5202, 31890, 390, 264, 9482, 300, 321, 1143, 13, 51232, 51232, 400, 294, 1333, 295, 6457, 17600, 11, 437, 321, 1352, 307, 300, 264, 2698, 12, 48172, 24420, 10290, 51566, 51566, 390, 588, 10043, 420, 754, 4748, 1101, 813, 29903, 31890, 46533, 10290, 412, 51816, 51816], "temperature": 0.0, "avg_logprob": -0.13464872925369828, "compression_ratio": 1.7297297297297298, "no_speech_prob": 7.766605449432973e-06}, {"id": 510, "seek": 196924, "start": 1993.28, "end": 1998.28, "text": " was very competitive or even slightly better than ImageNet supervised representation at", "tokens": [50364, 407, 321, 1890, 527, 39426, 293, 1466, 2698, 12, 48172, 24420, 3170, 293, 321, 2489, 10870, 309, 322, 613, 732, 42856, 50676, 50676, 1219, 3235, 618, 293, 14146, 9503, 13, 50814, 50814, 400, 321, 630, 264, 912, 551, 337, 29903, 31890, 46533, 3209, 13, 50978, 50978, 400, 341, 307, 646, 294, 264, 1708, 295, 5202, 31890, 13, 51063, 51063, 407, 5202, 31890, 390, 264, 9482, 300, 321, 1143, 13, 51232, 51232, 400, 294, 1333, 295, 6457, 17600, 11, 437, 321, 1352, 307, 300, 264, 2698, 12, 48172, 24420, 10290, 51566, 51566, 390, 588, 10043, 420, 754, 4748, 1101, 813, 29903, 31890, 46533, 10290, 412, 51816, 51816], "temperature": 0.0, "avg_logprob": -0.13464872925369828, "compression_ratio": 1.7297297297297298, "no_speech_prob": 7.766605449432973e-06}, {"id": 511, "seek": 199828, "start": 1998.28, "end": 2001.08, "text": " this task of key point estimation.", "tokens": [50364, 341, 5633, 295, 2141, 935, 35701, 13, 50504, 50504, 407, 294, 341, 1389, 11, 437, 286, 478, 13389, 307, 7171, 34, 11, 597, 307, 1859, 833, 264, 7605, 13, 50678, 50678, 407, 2946, 307, 1101, 13, 50766, 50766, 400, 291, 393, 536, 300, 309, 311, 10205, 6457, 731, 11, 597, 390, 588, 8830, 281, 505, 570, 51004, 51004, 321, 8782, 380, 534, 1194, 466, 341, 5633, 562, 321, 645, 14685, 527, 659, 25111, 5633, 13, 51212, 51212, 492, 534, 1194, 300, 884, 341, 659, 25111, 5633, 486, 854, 505, 1223, 5909, 1101, 13, 51476, 51476, 583, 309, 4523, 484, 300, 498, 411, 291, 393, 362, 1333, 295, 8830, 10070, 5413, 322, 437, 51702, 51702], "temperature": 0.0, "avg_logprob": -0.130837292506777, "compression_ratio": 1.7256317689530687, "no_speech_prob": 4.5657925511477515e-06}, {"id": 512, "seek": 199828, "start": 2001.08, "end": 2004.56, "text": " So in this case, what I'm measuring is AUC, which is area under the curve.", "tokens": [50364, 341, 5633, 295, 2141, 935, 35701, 13, 50504, 50504, 407, 294, 341, 1389, 11, 437, 286, 478, 13389, 307, 7171, 34, 11, 597, 307, 1859, 833, 264, 7605, 13, 50678, 50678, 407, 2946, 307, 1101, 13, 50766, 50766, 400, 291, 393, 536, 300, 309, 311, 10205, 6457, 731, 11, 597, 390, 588, 8830, 281, 505, 570, 51004, 51004, 321, 8782, 380, 534, 1194, 466, 341, 5633, 562, 321, 645, 14685, 527, 659, 25111, 5633, 13, 51212, 51212, 492, 534, 1194, 300, 884, 341, 659, 25111, 5633, 486, 854, 505, 1223, 5909, 1101, 13, 51476, 51476, 583, 309, 4523, 484, 300, 498, 411, 291, 393, 362, 1333, 295, 8830, 10070, 5413, 322, 437, 51702, 51702], "temperature": 0.0, "avg_logprob": -0.130837292506777, "compression_ratio": 1.7256317689530687, "no_speech_prob": 4.5657925511477515e-06}, {"id": 513, "seek": 199828, "start": 2004.56, "end": 2006.32, "text": " So higher is better.", "tokens": [50364, 341, 5633, 295, 2141, 935, 35701, 13, 50504, 50504, 407, 294, 341, 1389, 11, 437, 286, 478, 13389, 307, 7171, 34, 11, 597, 307, 1859, 833, 264, 7605, 13, 50678, 50678, 407, 2946, 307, 1101, 13, 50766, 50766, 400, 291, 393, 536, 300, 309, 311, 10205, 6457, 731, 11, 597, 390, 588, 8830, 281, 505, 570, 51004, 51004, 321, 8782, 380, 534, 1194, 466, 341, 5633, 562, 321, 645, 14685, 527, 659, 25111, 5633, 13, 51212, 51212, 492, 534, 1194, 300, 884, 341, 659, 25111, 5633, 486, 854, 505, 1223, 5909, 1101, 13, 51476, 51476, 583, 309, 4523, 484, 300, 498, 411, 291, 393, 362, 1333, 295, 8830, 10070, 5413, 322, 437, 51702, 51702], "temperature": 0.0, "avg_logprob": -0.130837292506777, "compression_ratio": 1.7256317689530687, "no_speech_prob": 4.5657925511477515e-06}, {"id": 514, "seek": 199828, "start": 2006.32, "end": 2011.08, "text": " And you can see that it's performing fairly well, which was very surprising to us because", "tokens": [50364, 341, 5633, 295, 2141, 935, 35701, 13, 50504, 50504, 407, 294, 341, 1389, 11, 437, 286, 478, 13389, 307, 7171, 34, 11, 597, 307, 1859, 833, 264, 7605, 13, 50678, 50678, 407, 2946, 307, 1101, 13, 50766, 50766, 400, 291, 393, 536, 300, 309, 311, 10205, 6457, 731, 11, 597, 390, 588, 8830, 281, 505, 570, 51004, 51004, 321, 8782, 380, 534, 1194, 466, 341, 5633, 562, 321, 645, 14685, 527, 659, 25111, 5633, 13, 51212, 51212, 492, 534, 1194, 300, 884, 341, 659, 25111, 5633, 486, 854, 505, 1223, 5909, 1101, 13, 51476, 51476, 583, 309, 4523, 484, 300, 498, 411, 291, 393, 362, 1333, 295, 8830, 10070, 5413, 322, 437, 51702, 51702], "temperature": 0.0, "avg_logprob": -0.130837292506777, "compression_ratio": 1.7256317689530687, "no_speech_prob": 4.5657925511477515e-06}, {"id": 515, "seek": 199828, "start": 2011.08, "end": 2015.24, "text": " we hadn't really thought about this task when we were designing our pretext task.", "tokens": [50364, 341, 5633, 295, 2141, 935, 35701, 13, 50504, 50504, 407, 294, 341, 1389, 11, 437, 286, 478, 13389, 307, 7171, 34, 11, 597, 307, 1859, 833, 264, 7605, 13, 50678, 50678, 407, 2946, 307, 1101, 13, 50766, 50766, 400, 291, 393, 536, 300, 309, 311, 10205, 6457, 731, 11, 597, 390, 588, 8830, 281, 505, 570, 51004, 51004, 321, 8782, 380, 534, 1194, 466, 341, 5633, 562, 321, 645, 14685, 527, 659, 25111, 5633, 13, 51212, 51212, 492, 534, 1194, 300, 884, 341, 659, 25111, 5633, 486, 854, 505, 1223, 5909, 1101, 13, 51476, 51476, 583, 309, 4523, 484, 300, 498, 411, 291, 393, 362, 1333, 295, 8830, 10070, 5413, 322, 437, 51702, 51702], "temperature": 0.0, "avg_logprob": -0.130837292506777, "compression_ratio": 1.7256317689530687, "no_speech_prob": 4.5657925511477515e-06}, {"id": 516, "seek": 199828, "start": 2015.24, "end": 2020.52, "text": " We really thought that doing this pretext task will help us understand actions better.", "tokens": [50364, 341, 5633, 295, 2141, 935, 35701, 13, 50504, 50504, 407, 294, 341, 1389, 11, 437, 286, 478, 13389, 307, 7171, 34, 11, 597, 307, 1859, 833, 264, 7605, 13, 50678, 50678, 407, 2946, 307, 1101, 13, 50766, 50766, 400, 291, 393, 536, 300, 309, 311, 10205, 6457, 731, 11, 597, 390, 588, 8830, 281, 505, 570, 51004, 51004, 321, 8782, 380, 534, 1194, 466, 341, 5633, 562, 321, 645, 14685, 527, 659, 25111, 5633, 13, 51212, 51212, 492, 534, 1194, 300, 884, 341, 659, 25111, 5633, 486, 854, 505, 1223, 5909, 1101, 13, 51476, 51476, 583, 309, 4523, 484, 300, 498, 411, 291, 393, 362, 1333, 295, 8830, 10070, 5413, 322, 437, 51702, 51702], "temperature": 0.0, "avg_logprob": -0.130837292506777, "compression_ratio": 1.7256317689530687, "no_speech_prob": 4.5657925511477515e-06}, {"id": 517, "seek": 199828, "start": 2020.52, "end": 2025.04, "text": " But it turns out that if like you can have sort of surprising outcomes depending on what", "tokens": [50364, 341, 5633, 295, 2141, 935, 35701, 13, 50504, 50504, 407, 294, 341, 1389, 11, 437, 286, 478, 13389, 307, 7171, 34, 11, 597, 307, 1859, 833, 264, 7605, 13, 50678, 50678, 407, 2946, 307, 1101, 13, 50766, 50766, 400, 291, 393, 536, 300, 309, 311, 10205, 6457, 731, 11, 597, 390, 588, 8830, 281, 505, 570, 51004, 51004, 321, 8782, 380, 534, 1194, 466, 341, 5633, 562, 321, 645, 14685, 527, 659, 25111, 5633, 13, 51212, 51212, 492, 534, 1194, 300, 884, 341, 659, 25111, 5633, 486, 854, 505, 1223, 5909, 1101, 13, 51476, 51476, 583, 309, 4523, 484, 300, 498, 411, 291, 393, 362, 1333, 295, 8830, 10070, 5413, 322, 437, 51702, 51702], "temperature": 0.0, "avg_logprob": -0.130837292506777, "compression_ratio": 1.7256317689530687, "no_speech_prob": 4.5657925511477515e-06}, {"id": 518, "seek": 202504, "start": 2025.04, "end": 2030.92, "text": " you ended up creating as a pretext task, so in this case, that was both estimation.", "tokens": [50364, 291, 4590, 493, 4084, 382, 257, 659, 25111, 5633, 11, 370, 294, 341, 1389, 11, 300, 390, 1293, 35701, 13, 50658, 50658, 407, 337, 341, 1365, 11, 291, 848, 291, 2489, 10870, 309, 322, 1952, 2141, 935, 35701, 13, 50998, 50998, 407, 307, 300, 733, 295, 411, 257, 46533, 1823, 412, 411, 1564, 291, 362, 428, 659, 25111, 33358, 30, 51436, 51436, 1079, 13, 51486, 51486, 407, 264, 15517, 1936, 5101, 1709, 411, 291, 360, 257, 659, 12, 16554, 773, 1823, 13, 51746, 51746], "temperature": 0.0, "avg_logprob": -0.19057606541833214, "compression_ratio": 1.6341463414634145, "no_speech_prob": 2.7534626497072168e-05}, {"id": 519, "seek": 202504, "start": 2030.92, "end": 2037.72, "text": " So for this example, you said you fine tuned it on human key point estimation.", "tokens": [50364, 291, 4590, 493, 4084, 382, 257, 659, 25111, 5633, 11, 370, 294, 341, 1389, 11, 300, 390, 1293, 35701, 13, 50658, 50658, 407, 337, 341, 1365, 11, 291, 848, 291, 2489, 10870, 309, 322, 1952, 2141, 935, 35701, 13, 50998, 50998, 407, 307, 300, 733, 295, 411, 257, 46533, 1823, 412, 411, 1564, 291, 362, 428, 659, 25111, 33358, 30, 51436, 51436, 1079, 13, 51486, 51486, 407, 264, 15517, 1936, 5101, 1709, 411, 291, 360, 257, 659, 12, 16554, 773, 1823, 13, 51746, 51746], "temperature": 0.0, "avg_logprob": -0.19057606541833214, "compression_ratio": 1.6341463414634145, "no_speech_prob": 2.7534626497072168e-05}, {"id": 520, "seek": 202504, "start": 2037.72, "end": 2046.48, "text": " So is that kind of like a supervised step at like once you have your pretext representations?", "tokens": [50364, 291, 4590, 493, 4084, 382, 257, 659, 25111, 5633, 11, 370, 294, 341, 1389, 11, 300, 390, 1293, 35701, 13, 50658, 50658, 407, 337, 341, 1365, 11, 291, 848, 291, 2489, 10870, 309, 322, 1952, 2141, 935, 35701, 13, 50998, 50998, 407, 307, 300, 733, 295, 411, 257, 46533, 1823, 412, 411, 1564, 291, 362, 428, 659, 25111, 33358, 30, 51436, 51436, 1079, 13, 51486, 51486, 407, 264, 15517, 1936, 5101, 1709, 411, 291, 360, 257, 659, 12, 16554, 773, 1823, 13, 51746, 51746], "temperature": 0.0, "avg_logprob": -0.19057606541833214, "compression_ratio": 1.6341463414634145, "no_speech_prob": 2.7534626497072168e-05}, {"id": 521, "seek": 202504, "start": 2046.48, "end": 2047.48, "text": " Yes.", "tokens": [50364, 291, 4590, 493, 4084, 382, 257, 659, 25111, 5633, 11, 370, 294, 341, 1389, 11, 300, 390, 1293, 35701, 13, 50658, 50658, 407, 337, 341, 1365, 11, 291, 848, 291, 2489, 10870, 309, 322, 1952, 2141, 935, 35701, 13, 50998, 50998, 407, 307, 300, 733, 295, 411, 257, 46533, 1823, 412, 411, 1564, 291, 362, 428, 659, 25111, 33358, 30, 51436, 51436, 1079, 13, 51486, 51486, 407, 264, 15517, 1936, 5101, 1709, 411, 291, 360, 257, 659, 12, 16554, 773, 1823, 13, 51746, 51746], "temperature": 0.0, "avg_logprob": -0.19057606541833214, "compression_ratio": 1.6341463414634145, "no_speech_prob": 2.7534626497072168e-05}, {"id": 522, "seek": 202504, "start": 2047.48, "end": 2052.68, "text": " So the pipeline basically generally goes like you do a pre-planning step.", "tokens": [50364, 291, 4590, 493, 4084, 382, 257, 659, 25111, 5633, 11, 370, 294, 341, 1389, 11, 300, 390, 1293, 35701, 13, 50658, 50658, 407, 337, 341, 1365, 11, 291, 848, 291, 2489, 10870, 309, 322, 1952, 2141, 935, 35701, 13, 50998, 50998, 407, 307, 300, 733, 295, 411, 257, 46533, 1823, 412, 411, 1564, 291, 362, 428, 659, 25111, 33358, 30, 51436, 51436, 1079, 13, 51486, 51486, 407, 264, 15517, 1936, 5101, 1709, 411, 291, 360, 257, 659, 12, 16554, 773, 1823, 13, 51746, 51746], "temperature": 0.0, "avg_logprob": -0.19057606541833214, "compression_ratio": 1.6341463414634145, "no_speech_prob": 2.7534626497072168e-05}, {"id": 523, "seek": 205268, "start": 2052.68, "end": 2057.74, "text": " So that can basically be say ImageNet supervision, which is predicting one of 1000 classes.", "tokens": [50364, 407, 300, 393, 1936, 312, 584, 29903, 31890, 32675, 11, 597, 307, 32884, 472, 295, 9714, 5359, 13, 50617, 50617, 400, 550, 291, 362, 257, 30621, 5633, 689, 291, 362, 257, 1326, 2372, 295, 16949, 13, 50760, 50760, 407, 291, 1936, 445, 11, 370, 294, 341, 1389, 11, 300, 311, 32884, 264, 1952, 2141, 2793, 13, 51024, 51024, 407, 341, 636, 295, 13344, 11, 437, 309, 775, 307, 309, 1936, 575, 11, 309, 2516, 257, 3840, 295, 659, 12, 17227, 2001, 51342, 51342, 9590, 293, 550, 309, 2489, 12, 83, 15001, 552, 1228, 264, 912, 46533, 1412, 412, 264, 917, 13, 51567, 51567, 400, 370, 437, 291, 434, 27479, 307, 577, 665, 390, 309, 498, 286, 1409, 490, 584, 29903, 31890, 46533, 51856, 51856], "temperature": 0.0, "avg_logprob": -0.1227516976613847, "compression_ratio": 1.7465753424657535, "no_speech_prob": 4.9367690735380165e-06}, {"id": 524, "seek": 205268, "start": 2057.74, "end": 2060.6, "text": " And then you have a downstream task where you have a few amount of labels.", "tokens": [50364, 407, 300, 393, 1936, 312, 584, 29903, 31890, 32675, 11, 597, 307, 32884, 472, 295, 9714, 5359, 13, 50617, 50617, 400, 550, 291, 362, 257, 30621, 5633, 689, 291, 362, 257, 1326, 2372, 295, 16949, 13, 50760, 50760, 407, 291, 1936, 445, 11, 370, 294, 341, 1389, 11, 300, 311, 32884, 264, 1952, 2141, 2793, 13, 51024, 51024, 407, 341, 636, 295, 13344, 11, 437, 309, 775, 307, 309, 1936, 575, 11, 309, 2516, 257, 3840, 295, 659, 12, 17227, 2001, 51342, 51342, 9590, 293, 550, 309, 2489, 12, 83, 15001, 552, 1228, 264, 912, 46533, 1412, 412, 264, 917, 13, 51567, 51567, 400, 370, 437, 291, 434, 27479, 307, 577, 665, 390, 309, 498, 286, 1409, 490, 584, 29903, 31890, 46533, 51856, 51856], "temperature": 0.0, "avg_logprob": -0.1227516976613847, "compression_ratio": 1.7465753424657535, "no_speech_prob": 4.9367690735380165e-06}, {"id": 525, "seek": 205268, "start": 2060.6, "end": 2065.8799999999997, "text": " So you basically just, so in this case, that's predicting the human key points.", "tokens": [50364, 407, 300, 393, 1936, 312, 584, 29903, 31890, 32675, 11, 597, 307, 32884, 472, 295, 9714, 5359, 13, 50617, 50617, 400, 550, 291, 362, 257, 30621, 5633, 689, 291, 362, 257, 1326, 2372, 295, 16949, 13, 50760, 50760, 407, 291, 1936, 445, 11, 370, 294, 341, 1389, 11, 300, 311, 32884, 264, 1952, 2141, 2793, 13, 51024, 51024, 407, 341, 636, 295, 13344, 11, 437, 309, 775, 307, 309, 1936, 575, 11, 309, 2516, 257, 3840, 295, 659, 12, 17227, 2001, 51342, 51342, 9590, 293, 550, 309, 2489, 12, 83, 15001, 552, 1228, 264, 912, 46533, 1412, 412, 264, 917, 13, 51567, 51567, 400, 370, 437, 291, 434, 27479, 307, 577, 665, 390, 309, 498, 286, 1409, 490, 584, 29903, 31890, 46533, 51856, 51856], "temperature": 0.0, "avg_logprob": -0.1227516976613847, "compression_ratio": 1.7465753424657535, "no_speech_prob": 4.9367690735380165e-06}, {"id": 526, "seek": 205268, "start": 2065.8799999999997, "end": 2072.24, "text": " So this way of evaluation, what it does is it basically has, it takes a bunch of pre-trained", "tokens": [50364, 407, 300, 393, 1936, 312, 584, 29903, 31890, 32675, 11, 597, 307, 32884, 472, 295, 9714, 5359, 13, 50617, 50617, 400, 550, 291, 362, 257, 30621, 5633, 689, 291, 362, 257, 1326, 2372, 295, 16949, 13, 50760, 50760, 407, 291, 1936, 445, 11, 370, 294, 341, 1389, 11, 300, 311, 32884, 264, 1952, 2141, 2793, 13, 51024, 51024, 407, 341, 636, 295, 13344, 11, 437, 309, 775, 307, 309, 1936, 575, 11, 309, 2516, 257, 3840, 295, 659, 12, 17227, 2001, 51342, 51342, 9590, 293, 550, 309, 2489, 12, 83, 15001, 552, 1228, 264, 912, 46533, 1412, 412, 264, 917, 13, 51567, 51567, 400, 370, 437, 291, 434, 27479, 307, 577, 665, 390, 309, 498, 286, 1409, 490, 584, 29903, 31890, 46533, 51856, 51856], "temperature": 0.0, "avg_logprob": -0.1227516976613847, "compression_ratio": 1.7465753424657535, "no_speech_prob": 4.9367690735380165e-06}, {"id": 527, "seek": 205268, "start": 2072.24, "end": 2076.74, "text": " networks and then it fine-tunes them using the same supervised data at the end.", "tokens": [50364, 407, 300, 393, 1936, 312, 584, 29903, 31890, 32675, 11, 597, 307, 32884, 472, 295, 9714, 5359, 13, 50617, 50617, 400, 550, 291, 362, 257, 30621, 5633, 689, 291, 362, 257, 1326, 2372, 295, 16949, 13, 50760, 50760, 407, 291, 1936, 445, 11, 370, 294, 341, 1389, 11, 300, 311, 32884, 264, 1952, 2141, 2793, 13, 51024, 51024, 407, 341, 636, 295, 13344, 11, 437, 309, 775, 307, 309, 1936, 575, 11, 309, 2516, 257, 3840, 295, 659, 12, 17227, 2001, 51342, 51342, 9590, 293, 550, 309, 2489, 12, 83, 15001, 552, 1228, 264, 912, 46533, 1412, 412, 264, 917, 13, 51567, 51567, 400, 370, 437, 291, 434, 27479, 307, 577, 665, 390, 309, 498, 286, 1409, 490, 584, 29903, 31890, 46533, 51856, 51856], "temperature": 0.0, "avg_logprob": -0.1227516976613847, "compression_ratio": 1.7465753424657535, "no_speech_prob": 4.9367690735380165e-06}, {"id": 528, "seek": 205268, "start": 2076.74, "end": 2082.52, "text": " And so what you're evaluating is how good was it if I started from say ImageNet supervised", "tokens": [50364, 407, 300, 393, 1936, 312, 584, 29903, 31890, 32675, 11, 597, 307, 32884, 472, 295, 9714, 5359, 13, 50617, 50617, 400, 550, 291, 362, 257, 30621, 5633, 689, 291, 362, 257, 1326, 2372, 295, 16949, 13, 50760, 50760, 407, 291, 1936, 445, 11, 370, 294, 341, 1389, 11, 300, 311, 32884, 264, 1952, 2141, 2793, 13, 51024, 51024, 407, 341, 636, 295, 13344, 11, 437, 309, 775, 307, 309, 1936, 575, 11, 309, 2516, 257, 3840, 295, 659, 12, 17227, 2001, 51342, 51342, 9590, 293, 550, 309, 2489, 12, 83, 15001, 552, 1228, 264, 912, 46533, 1412, 412, 264, 917, 13, 51567, 51567, 400, 370, 437, 291, 434, 27479, 307, 577, 665, 390, 309, 498, 286, 1409, 490, 584, 29903, 31890, 46533, 51856, 51856], "temperature": 0.0, "avg_logprob": -0.1227516976613847, "compression_ratio": 1.7465753424657535, "no_speech_prob": 4.9367690735380165e-06}, {"id": 529, "seek": 208252, "start": 2082.52, "end": 2086.88, "text": " network or a shuffle and learn network to perform this task of key point estimation.", "tokens": [50364, 3209, 420, 257, 39426, 293, 1466, 3209, 281, 2042, 341, 5633, 295, 2141, 935, 35701, 13, 50582, 50582, 1033, 13, 50632, 50632, 1044, 291, 13, 50682, 50682, 6998, 380, 309, 5861, 300, 309, 630, 341, 731, 1670, 39426, 293, 1466, 16109, 322, 264, 3678, 30, 51122, 51122, 407, 309, 767, 16109, 257, 688, 322, 264, 32058, 13, 51257, 51257, 407, 300, 311, 437, 286, 390, 1382, 281, 1333, 295, 808, 493, 365, 341, 751, 466, 294, 341, 1365, 13, 51472, 51472, 407, 498, 291, 574, 412, 411, 437, 264, 23831, 12512, 366, 11, 309, 311, 534, 1237, 412, 264, 954, 281, 51678, 51678, 808, 493, 365, 341, 11, 558, 30, 51732, 51732], "temperature": 0.0, "avg_logprob": -0.14762764646295914, "compression_ratio": 1.7265625, "no_speech_prob": 5.7384007959626615e-05}, {"id": 530, "seek": 208252, "start": 2086.88, "end": 2087.88, "text": " Okay.", "tokens": [50364, 3209, 420, 257, 39426, 293, 1466, 3209, 281, 2042, 341, 5633, 295, 2141, 935, 35701, 13, 50582, 50582, 1033, 13, 50632, 50632, 1044, 291, 13, 50682, 50682, 6998, 380, 309, 5861, 300, 309, 630, 341, 731, 1670, 39426, 293, 1466, 16109, 322, 264, 3678, 30, 51122, 51122, 407, 309, 767, 16109, 257, 688, 322, 264, 32058, 13, 51257, 51257, 407, 300, 311, 437, 286, 390, 1382, 281, 1333, 295, 808, 493, 365, 341, 751, 466, 294, 341, 1365, 13, 51472, 51472, 407, 498, 291, 574, 412, 411, 437, 264, 23831, 12512, 366, 11, 309, 311, 534, 1237, 412, 264, 954, 281, 51678, 51678, 808, 493, 365, 341, 11, 558, 30, 51732, 51732], "temperature": 0.0, "avg_logprob": -0.14762764646295914, "compression_ratio": 1.7265625, "no_speech_prob": 5.7384007959626615e-05}, {"id": 531, "seek": 208252, "start": 2087.88, "end": 2088.88, "text": " Thank you.", "tokens": [50364, 3209, 420, 257, 39426, 293, 1466, 3209, 281, 2042, 341, 5633, 295, 2141, 935, 35701, 13, 50582, 50582, 1033, 13, 50632, 50632, 1044, 291, 13, 50682, 50682, 6998, 380, 309, 5861, 300, 309, 630, 341, 731, 1670, 39426, 293, 1466, 16109, 322, 264, 3678, 30, 51122, 51122, 407, 309, 767, 16109, 257, 688, 322, 264, 32058, 13, 51257, 51257, 407, 300, 311, 437, 286, 390, 1382, 281, 1333, 295, 808, 493, 365, 341, 751, 466, 294, 341, 1365, 13, 51472, 51472, 407, 498, 291, 574, 412, 411, 437, 264, 23831, 12512, 366, 11, 309, 311, 534, 1237, 412, 264, 954, 281, 51678, 51678, 808, 493, 365, 341, 11, 558, 30, 51732, 51732], "temperature": 0.0, "avg_logprob": -0.14762764646295914, "compression_ratio": 1.7265625, "no_speech_prob": 5.7384007959626615e-05}, {"id": 532, "seek": 208252, "start": 2088.88, "end": 2097.68, "text": " Isn't it strange that it did this well since shuffle and learn focuses on the background?", "tokens": [50364, 3209, 420, 257, 39426, 293, 1466, 3209, 281, 2042, 341, 5633, 295, 2141, 935, 35701, 13, 50582, 50582, 1033, 13, 50632, 50632, 1044, 291, 13, 50682, 50682, 6998, 380, 309, 5861, 300, 309, 630, 341, 731, 1670, 39426, 293, 1466, 16109, 322, 264, 3678, 30, 51122, 51122, 407, 309, 767, 16109, 257, 688, 322, 264, 32058, 13, 51257, 51257, 407, 300, 311, 437, 286, 390, 1382, 281, 1333, 295, 808, 493, 365, 341, 751, 466, 294, 341, 1365, 13, 51472, 51472, 407, 498, 291, 574, 412, 411, 437, 264, 23831, 12512, 366, 11, 309, 311, 534, 1237, 412, 264, 954, 281, 51678, 51678, 808, 493, 365, 341, 11, 558, 30, 51732, 51732], "temperature": 0.0, "avg_logprob": -0.14762764646295914, "compression_ratio": 1.7265625, "no_speech_prob": 5.7384007959626615e-05}, {"id": 533, "seek": 208252, "start": 2097.68, "end": 2100.38, "text": " So it actually focuses a lot on the foreground.", "tokens": [50364, 3209, 420, 257, 39426, 293, 1466, 3209, 281, 2042, 341, 5633, 295, 2141, 935, 35701, 13, 50582, 50582, 1033, 13, 50632, 50632, 1044, 291, 13, 50682, 50682, 6998, 380, 309, 5861, 300, 309, 630, 341, 731, 1670, 39426, 293, 1466, 16109, 322, 264, 3678, 30, 51122, 51122, 407, 309, 767, 16109, 257, 688, 322, 264, 32058, 13, 51257, 51257, 407, 300, 311, 437, 286, 390, 1382, 281, 1333, 295, 808, 493, 365, 341, 751, 466, 294, 341, 1365, 13, 51472, 51472, 407, 498, 291, 574, 412, 411, 437, 264, 23831, 12512, 366, 11, 309, 311, 534, 1237, 412, 264, 954, 281, 51678, 51678, 808, 493, 365, 341, 11, 558, 30, 51732, 51732], "temperature": 0.0, "avg_logprob": -0.14762764646295914, "compression_ratio": 1.7265625, "no_speech_prob": 5.7384007959626615e-05}, {"id": 534, "seek": 208252, "start": 2100.38, "end": 2104.68, "text": " So that's what I was trying to sort of come up with this talk about in this example.", "tokens": [50364, 3209, 420, 257, 39426, 293, 1466, 3209, 281, 2042, 341, 5633, 295, 2141, 935, 35701, 13, 50582, 50582, 1033, 13, 50632, 50632, 1044, 291, 13, 50682, 50682, 6998, 380, 309, 5861, 300, 309, 630, 341, 731, 1670, 39426, 293, 1466, 16109, 322, 264, 3678, 30, 51122, 51122, 407, 309, 767, 16109, 257, 688, 322, 264, 32058, 13, 51257, 51257, 407, 300, 311, 437, 286, 390, 1382, 281, 1333, 295, 808, 493, 365, 341, 751, 466, 294, 341, 1365, 13, 51472, 51472, 407, 498, 291, 574, 412, 411, 437, 264, 23831, 12512, 366, 11, 309, 311, 534, 1237, 412, 264, 954, 281, 51678, 51678, 808, 493, 365, 341, 11, 558, 30, 51732, 51732], "temperature": 0.0, "avg_logprob": -0.14762764646295914, "compression_ratio": 1.7265625, "no_speech_prob": 5.7384007959626615e-05}, {"id": 535, "seek": 208252, "start": 2104.68, "end": 2108.8, "text": " So if you look at like what the nearest neighbors are, it's really looking at the person to", "tokens": [50364, 3209, 420, 257, 39426, 293, 1466, 3209, 281, 2042, 341, 5633, 295, 2141, 935, 35701, 13, 50582, 50582, 1033, 13, 50632, 50632, 1044, 291, 13, 50682, 50682, 6998, 380, 309, 5861, 300, 309, 630, 341, 731, 1670, 39426, 293, 1466, 16109, 322, 264, 3678, 30, 51122, 51122, 407, 309, 767, 16109, 257, 688, 322, 264, 32058, 13, 51257, 51257, 407, 300, 311, 437, 286, 390, 1382, 281, 1333, 295, 808, 493, 365, 341, 751, 466, 294, 341, 1365, 13, 51472, 51472, 407, 498, 291, 574, 412, 411, 437, 264, 23831, 12512, 366, 11, 309, 311, 534, 1237, 412, 264, 954, 281, 51678, 51678, 808, 493, 365, 341, 11, 558, 30, 51732, 51732], "temperature": 0.0, "avg_logprob": -0.14762764646295914, "compression_ratio": 1.7265625, "no_speech_prob": 5.7384007959626615e-05}, {"id": 536, "seek": 208252, "start": 2108.8, "end": 2109.88, "text": " come up with this, right?", "tokens": [50364, 3209, 420, 257, 39426, 293, 1466, 3209, 281, 2042, 341, 5633, 295, 2141, 935, 35701, 13, 50582, 50582, 1033, 13, 50632, 50632, 1044, 291, 13, 50682, 50682, 6998, 380, 309, 5861, 300, 309, 630, 341, 731, 1670, 39426, 293, 1466, 16109, 322, 264, 3678, 30, 51122, 51122, 407, 309, 767, 16109, 257, 688, 322, 264, 32058, 13, 51257, 51257, 407, 300, 311, 437, 286, 390, 1382, 281, 1333, 295, 808, 493, 365, 341, 751, 466, 294, 341, 1365, 13, 51472, 51472, 407, 498, 291, 574, 412, 411, 437, 264, 23831, 12512, 366, 11, 309, 311, 534, 1237, 412, 264, 954, 281, 51678, 51678, 808, 493, 365, 341, 11, 558, 30, 51732, 51732], "temperature": 0.0, "avg_logprob": -0.14762764646295914, "compression_ratio": 1.7265625, "no_speech_prob": 5.7384007959626615e-05}, {"id": 537, "seek": 210988, "start": 2109.88, "end": 2115.88, "text": " It's looking at the upside down person to sort of come up with its nearest neighbor.", "tokens": [50364, 467, 311, 1237, 412, 264, 14119, 760, 954, 281, 1333, 295, 808, 493, 365, 1080, 23831, 5987, 13, 50664, 50664, 400, 264, 1778, 307, 498, 291, 528, 281, 751, 466, 21739, 295, 12083, 11, 286, 534, 643, 281, 1879, 50898, 50898, 322, 721, 300, 1286, 13, 50948, 50948, 400, 294, 613, 2145, 11, 561, 366, 264, 721, 300, 1286, 13, 51090, 51090, 407, 498, 309, 16109, 322, 264, 3678, 11, 309, 767, 486, 406, 312, 1075, 281, 5039, 264, 39426, 293, 51276, 51276, 1466, 5633, 13, 51598, 51598], "temperature": 0.0, "avg_logprob": -0.12083232667711045, "compression_ratio": 1.6261682242990654, "no_speech_prob": 4.356817044026684e-06}, {"id": 538, "seek": 210988, "start": 2115.88, "end": 2120.56, "text": " And the reason is if you want to talk about ordering of frames, I really need to focus", "tokens": [50364, 467, 311, 1237, 412, 264, 14119, 760, 954, 281, 1333, 295, 808, 493, 365, 1080, 23831, 5987, 13, 50664, 50664, 400, 264, 1778, 307, 498, 291, 528, 281, 751, 466, 21739, 295, 12083, 11, 286, 534, 643, 281, 1879, 50898, 50898, 322, 721, 300, 1286, 13, 50948, 50948, 400, 294, 613, 2145, 11, 561, 366, 264, 721, 300, 1286, 13, 51090, 51090, 407, 498, 309, 16109, 322, 264, 3678, 11, 309, 767, 486, 406, 312, 1075, 281, 5039, 264, 39426, 293, 51276, 51276, 1466, 5633, 13, 51598, 51598], "temperature": 0.0, "avg_logprob": -0.12083232667711045, "compression_ratio": 1.6261682242990654, "no_speech_prob": 4.356817044026684e-06}, {"id": 539, "seek": 210988, "start": 2120.56, "end": 2121.56, "text": " on things that move.", "tokens": [50364, 467, 311, 1237, 412, 264, 14119, 760, 954, 281, 1333, 295, 808, 493, 365, 1080, 23831, 5987, 13, 50664, 50664, 400, 264, 1778, 307, 498, 291, 528, 281, 751, 466, 21739, 295, 12083, 11, 286, 534, 643, 281, 1879, 50898, 50898, 322, 721, 300, 1286, 13, 50948, 50948, 400, 294, 613, 2145, 11, 561, 366, 264, 721, 300, 1286, 13, 51090, 51090, 407, 498, 309, 16109, 322, 264, 3678, 11, 309, 767, 486, 406, 312, 1075, 281, 5039, 264, 39426, 293, 51276, 51276, 1466, 5633, 13, 51598, 51598], "temperature": 0.0, "avg_logprob": -0.12083232667711045, "compression_ratio": 1.6261682242990654, "no_speech_prob": 4.356817044026684e-06}, {"id": 540, "seek": 210988, "start": 2121.56, "end": 2124.4, "text": " And in these videos, people are the things that move.", "tokens": [50364, 467, 311, 1237, 412, 264, 14119, 760, 954, 281, 1333, 295, 808, 493, 365, 1080, 23831, 5987, 13, 50664, 50664, 400, 264, 1778, 307, 498, 291, 528, 281, 751, 466, 21739, 295, 12083, 11, 286, 534, 643, 281, 1879, 50898, 50898, 322, 721, 300, 1286, 13, 50948, 50948, 400, 294, 613, 2145, 11, 561, 366, 264, 721, 300, 1286, 13, 51090, 51090, 407, 498, 309, 16109, 322, 264, 3678, 11, 309, 767, 486, 406, 312, 1075, 281, 5039, 264, 39426, 293, 51276, 51276, 1466, 5633, 13, 51598, 51598], "temperature": 0.0, "avg_logprob": -0.12083232667711045, "compression_ratio": 1.6261682242990654, "no_speech_prob": 4.356817044026684e-06}, {"id": 541, "seek": 210988, "start": 2124.4, "end": 2128.12, "text": " So if it focuses on the background, it actually will not be able to solve the shuffle and", "tokens": [50364, 467, 311, 1237, 412, 264, 14119, 760, 954, 281, 1333, 295, 808, 493, 365, 1080, 23831, 5987, 13, 50664, 50664, 400, 264, 1778, 307, 498, 291, 528, 281, 751, 466, 21739, 295, 12083, 11, 286, 534, 643, 281, 1879, 50898, 50898, 322, 721, 300, 1286, 13, 50948, 50948, 400, 294, 613, 2145, 11, 561, 366, 264, 721, 300, 1286, 13, 51090, 51090, 407, 498, 309, 16109, 322, 264, 3678, 11, 309, 767, 486, 406, 312, 1075, 281, 5039, 264, 39426, 293, 51276, 51276, 1466, 5633, 13, 51598, 51598], "temperature": 0.0, "avg_logprob": -0.12083232667711045, "compression_ratio": 1.6261682242990654, "no_speech_prob": 4.356817044026684e-06}, {"id": 542, "seek": 210988, "start": 2128.12, "end": 2134.56, "text": " learn task.", "tokens": [50364, 467, 311, 1237, 412, 264, 14119, 760, 954, 281, 1333, 295, 808, 493, 365, 1080, 23831, 5987, 13, 50664, 50664, 400, 264, 1778, 307, 498, 291, 528, 281, 751, 466, 21739, 295, 12083, 11, 286, 534, 643, 281, 1879, 50898, 50898, 322, 721, 300, 1286, 13, 50948, 50948, 400, 294, 613, 2145, 11, 561, 366, 264, 721, 300, 1286, 13, 51090, 51090, 407, 498, 309, 16109, 322, 264, 3678, 11, 309, 767, 486, 406, 312, 1075, 281, 5039, 264, 39426, 293, 51276, 51276, 1466, 5633, 13, 51598, 51598], "temperature": 0.0, "avg_logprob": -0.12083232667711045, "compression_ratio": 1.6261682242990654, "no_speech_prob": 4.356817044026684e-06}, {"id": 543, "seek": 213456, "start": 2134.56, "end": 2140.2, "text": " So this was sort of surprising and it sort of goes to show that if you design your pretext", "tokens": [50364, 407, 341, 390, 1333, 295, 8830, 293, 309, 1333, 295, 1709, 281, 855, 300, 498, 291, 1715, 428, 659, 25111, 50646, 50646, 5633, 731, 11, 309, 486, 589, 731, 337, 257, 1629, 1333, 295, 992, 295, 30621, 9608, 13, 50967, 50967, 400, 456, 362, 668, 1333, 295, 6457, 1481, 7150, 1670, 550, 11, 597, 286, 600, 668, 1936, 466, 51298, 51298, 32884, 341, 1333, 295, 1228, 42881, 507, 293, 1333, 295, 32884, 1968, 721, 366, 51550, 51550, 294, 264, 3006, 1668, 420, 406, 13, 51632, 51632, 407, 341, 307, 7401, 562, 484, 9590, 11, 597, 1936, 2831, 813, 12606, 257, 17434, 21538, 51834, 51834], "temperature": 0.0, "avg_logprob": -0.12159171194400427, "compression_ratio": 1.7622641509433963, "no_speech_prob": 1.0952787306450773e-05}, {"id": 544, "seek": 213456, "start": 2140.2, "end": 2146.62, "text": " task well, it will work well for a certain sort of set of downstream tasks.", "tokens": [50364, 407, 341, 390, 1333, 295, 8830, 293, 309, 1333, 295, 1709, 281, 855, 300, 498, 291, 1715, 428, 659, 25111, 50646, 50646, 5633, 731, 11, 309, 486, 589, 731, 337, 257, 1629, 1333, 295, 992, 295, 30621, 9608, 13, 50967, 50967, 400, 456, 362, 668, 1333, 295, 6457, 1481, 7150, 1670, 550, 11, 597, 286, 600, 668, 1936, 466, 51298, 51298, 32884, 341, 1333, 295, 1228, 42881, 507, 293, 1333, 295, 32884, 1968, 721, 366, 51550, 51550, 294, 264, 3006, 1668, 420, 406, 13, 51632, 51632, 407, 341, 307, 7401, 562, 484, 9590, 11, 597, 1936, 2831, 813, 12606, 257, 17434, 21538, 51834, 51834], "temperature": 0.0, "avg_logprob": -0.12159171194400427, "compression_ratio": 1.7622641509433963, "no_speech_prob": 1.0952787306450773e-05}, {"id": 545, "seek": 213456, "start": 2146.62, "end": 2153.24, "text": " And there have been sort of fairly nice methods since then, which I've been basically about", "tokens": [50364, 407, 341, 390, 1333, 295, 8830, 293, 309, 1333, 295, 1709, 281, 855, 300, 498, 291, 1715, 428, 659, 25111, 50646, 50646, 5633, 731, 11, 309, 486, 589, 731, 337, 257, 1629, 1333, 295, 992, 295, 30621, 9608, 13, 50967, 50967, 400, 456, 362, 668, 1333, 295, 6457, 1481, 7150, 1670, 550, 11, 597, 286, 600, 668, 1936, 466, 51298, 51298, 32884, 341, 1333, 295, 1228, 42881, 507, 293, 1333, 295, 32884, 1968, 721, 366, 51550, 51550, 294, 264, 3006, 1668, 420, 406, 13, 51632, 51632, 407, 341, 307, 7401, 562, 484, 9590, 11, 597, 1936, 2831, 813, 12606, 257, 17434, 21538, 51834, 51834], "temperature": 0.0, "avg_logprob": -0.12159171194400427, "compression_ratio": 1.7622641509433963, "no_speech_prob": 1.0952787306450773e-05}, {"id": 546, "seek": 213456, "start": 2153.24, "end": 2158.2799999999997, "text": " predicting this sort of using sequentiality and sort of predicting whether things are", "tokens": [50364, 407, 341, 390, 1333, 295, 8830, 293, 309, 1333, 295, 1709, 281, 855, 300, 498, 291, 1715, 428, 659, 25111, 50646, 50646, 5633, 731, 11, 309, 486, 589, 731, 337, 257, 1629, 1333, 295, 992, 295, 30621, 9608, 13, 50967, 50967, 400, 456, 362, 668, 1333, 295, 6457, 1481, 7150, 1670, 550, 11, 597, 286, 600, 668, 1936, 466, 51298, 51298, 32884, 341, 1333, 295, 1228, 42881, 507, 293, 1333, 295, 32884, 1968, 721, 366, 51550, 51550, 294, 264, 3006, 1668, 420, 406, 13, 51632, 51632, 407, 341, 307, 7401, 562, 484, 9590, 11, 597, 1936, 2831, 813, 12606, 257, 17434, 21538, 51834, 51834], "temperature": 0.0, "avg_logprob": -0.12159171194400427, "compression_ratio": 1.7622641509433963, "no_speech_prob": 1.0952787306450773e-05}, {"id": 547, "seek": 213456, "start": 2158.2799999999997, "end": 2159.92, "text": " in the correct order or not.", "tokens": [50364, 407, 341, 390, 1333, 295, 8830, 293, 309, 1333, 295, 1709, 281, 855, 300, 498, 291, 1715, 428, 659, 25111, 50646, 50646, 5633, 731, 11, 309, 486, 589, 731, 337, 257, 1629, 1333, 295, 992, 295, 30621, 9608, 13, 50967, 50967, 400, 456, 362, 668, 1333, 295, 6457, 1481, 7150, 1670, 550, 11, 597, 286, 600, 668, 1936, 466, 51298, 51298, 32884, 341, 1333, 295, 1228, 42881, 507, 293, 1333, 295, 32884, 1968, 721, 366, 51550, 51550, 294, 264, 3006, 1668, 420, 406, 13, 51632, 51632, 407, 341, 307, 7401, 562, 484, 9590, 11, 597, 1936, 2831, 813, 12606, 257, 17434, 21538, 51834, 51834], "temperature": 0.0, "avg_logprob": -0.12159171194400427, "compression_ratio": 1.7622641509433963, "no_speech_prob": 1.0952787306450773e-05}, {"id": 548, "seek": 213456, "start": 2159.92, "end": 2163.96, "text": " So this is odd when out networks, which basically rather than solving a binary classification", "tokens": [50364, 407, 341, 390, 1333, 295, 8830, 293, 309, 1333, 295, 1709, 281, 855, 300, 498, 291, 1715, 428, 659, 25111, 50646, 50646, 5633, 731, 11, 309, 486, 589, 731, 337, 257, 1629, 1333, 295, 992, 295, 30621, 9608, 13, 50967, 50967, 400, 456, 362, 668, 1333, 295, 6457, 1481, 7150, 1670, 550, 11, 597, 286, 600, 668, 1936, 466, 51298, 51298, 32884, 341, 1333, 295, 1228, 42881, 507, 293, 1333, 295, 32884, 1968, 721, 366, 51550, 51550, 294, 264, 3006, 1668, 420, 406, 13, 51632, 51632, 407, 341, 307, 7401, 562, 484, 9590, 11, 597, 1936, 2831, 813, 12606, 257, 17434, 21538, 51834, 51834], "temperature": 0.0, "avg_logprob": -0.12159171194400427, "compression_ratio": 1.7622641509433963, "no_speech_prob": 1.0952787306450773e-05}, {"id": 549, "seek": 216396, "start": 2163.96, "end": 2171.7200000000003, "text": " problem, it actually tries to predict which of the frames is the one that is odd when", "tokens": [50364, 1154, 11, 309, 767, 9898, 281, 6069, 597, 295, 264, 12083, 307, 264, 472, 300, 307, 7401, 562, 50752, 50752, 484, 11, 264, 472, 300, 307, 1333, 295, 402, 33974, 13, 50940, 50940, 400, 341, 570, 291, 434, 1333, 295, 5662, 264, 2372, 295, 1589, 300, 291, 434, 32884, 51118, 51118, 412, 264, 5598, 11, 341, 1333, 295, 3209, 5314, 493, 884, 1101, 293, 1101, 13, 51340, 51340, 400, 309, 611, 1333, 295, 4112, 466, 544, 12083, 412, 257, 565, 13, 51618, 51618, 407, 586, 291, 600, 1612, 1333, 295, 5267, 293, 960, 13, 51754, 51754], "temperature": 0.0, "avg_logprob": -0.13260127087028659, "compression_ratio": 1.7671232876712328, "no_speech_prob": 5.338086793926777e-06}, {"id": 550, "seek": 216396, "start": 2171.7200000000003, "end": 2175.48, "text": " out, the one that is sort of shuffled.", "tokens": [50364, 1154, 11, 309, 767, 9898, 281, 6069, 597, 295, 264, 12083, 307, 264, 472, 300, 307, 7401, 562, 50752, 50752, 484, 11, 264, 472, 300, 307, 1333, 295, 402, 33974, 13, 50940, 50940, 400, 341, 570, 291, 434, 1333, 295, 5662, 264, 2372, 295, 1589, 300, 291, 434, 32884, 51118, 51118, 412, 264, 5598, 11, 341, 1333, 295, 3209, 5314, 493, 884, 1101, 293, 1101, 13, 51340, 51340, 400, 309, 611, 1333, 295, 4112, 466, 544, 12083, 412, 257, 565, 13, 51618, 51618, 407, 586, 291, 600, 1612, 1333, 295, 5267, 293, 960, 13, 51754, 51754], "temperature": 0.0, "avg_logprob": -0.13260127087028659, "compression_ratio": 1.7671232876712328, "no_speech_prob": 5.338086793926777e-06}, {"id": 551, "seek": 216396, "start": 2175.48, "end": 2179.04, "text": " And this because you're sort of increasing the amount of information that you're predicting", "tokens": [50364, 1154, 11, 309, 767, 9898, 281, 6069, 597, 295, 264, 12083, 307, 264, 472, 300, 307, 7401, 562, 50752, 50752, 484, 11, 264, 472, 300, 307, 1333, 295, 402, 33974, 13, 50940, 50940, 400, 341, 570, 291, 434, 1333, 295, 5662, 264, 2372, 295, 1589, 300, 291, 434, 32884, 51118, 51118, 412, 264, 5598, 11, 341, 1333, 295, 3209, 5314, 493, 884, 1101, 293, 1101, 13, 51340, 51340, 400, 309, 611, 1333, 295, 4112, 466, 544, 12083, 412, 257, 565, 13, 51618, 51618, 407, 586, 291, 600, 1612, 1333, 295, 5267, 293, 960, 13, 51754, 51754], "temperature": 0.0, "avg_logprob": -0.13260127087028659, "compression_ratio": 1.7671232876712328, "no_speech_prob": 5.338086793926777e-06}, {"id": 552, "seek": 216396, "start": 2179.04, "end": 2183.48, "text": " at the output, this sort of network ends up doing better and better.", "tokens": [50364, 1154, 11, 309, 767, 9898, 281, 6069, 597, 295, 264, 12083, 307, 264, 472, 300, 307, 7401, 562, 50752, 50752, 484, 11, 264, 472, 300, 307, 1333, 295, 402, 33974, 13, 50940, 50940, 400, 341, 570, 291, 434, 1333, 295, 5662, 264, 2372, 295, 1589, 300, 291, 434, 32884, 51118, 51118, 412, 264, 5598, 11, 341, 1333, 295, 3209, 5314, 493, 884, 1101, 293, 1101, 13, 51340, 51340, 400, 309, 611, 1333, 295, 4112, 466, 544, 12083, 412, 257, 565, 13, 51618, 51618, 407, 586, 291, 600, 1612, 1333, 295, 5267, 293, 960, 13, 51754, 51754], "temperature": 0.0, "avg_logprob": -0.13260127087028659, "compression_ratio": 1.7671232876712328, "no_speech_prob": 5.338086793926777e-06}, {"id": 553, "seek": 216396, "start": 2183.48, "end": 2189.04, "text": " And it also sort of reasons about more frames at a time.", "tokens": [50364, 1154, 11, 309, 767, 9898, 281, 6069, 597, 295, 264, 12083, 307, 264, 472, 300, 307, 7401, 562, 50752, 50752, 484, 11, 264, 472, 300, 307, 1333, 295, 402, 33974, 13, 50940, 50940, 400, 341, 570, 291, 434, 1333, 295, 5662, 264, 2372, 295, 1589, 300, 291, 434, 32884, 51118, 51118, 412, 264, 5598, 11, 341, 1333, 295, 3209, 5314, 493, 884, 1101, 293, 1101, 13, 51340, 51340, 400, 309, 611, 1333, 295, 4112, 466, 544, 12083, 412, 257, 565, 13, 51618, 51618, 407, 586, 291, 600, 1612, 1333, 295, 5267, 293, 960, 13, 51754, 51754], "temperature": 0.0, "avg_logprob": -0.13260127087028659, "compression_ratio": 1.7671232876712328, "no_speech_prob": 5.338086793926777e-06}, {"id": 554, "seek": 216396, "start": 2189.04, "end": 2191.76, "text": " So now you've seen sort of images and video.", "tokens": [50364, 1154, 11, 309, 767, 9898, 281, 6069, 597, 295, 264, 12083, 307, 264, 472, 300, 307, 7401, 562, 50752, 50752, 484, 11, 264, 472, 300, 307, 1333, 295, 402, 33974, 13, 50940, 50940, 400, 341, 570, 291, 434, 1333, 295, 5662, 264, 2372, 295, 1589, 300, 291, 434, 32884, 51118, 51118, 412, 264, 5598, 11, 341, 1333, 295, 3209, 5314, 493, 884, 1101, 293, 1101, 13, 51340, 51340, 400, 309, 611, 1333, 295, 4112, 466, 544, 12083, 412, 257, 565, 13, 51618, 51618, 407, 586, 291, 600, 1612, 1333, 295, 5267, 293, 960, 13, 51754, 51754], "temperature": 0.0, "avg_logprob": -0.13260127087028659, "compression_ratio": 1.7671232876712328, "no_speech_prob": 5.338086793926777e-06}, {"id": 555, "seek": 219176, "start": 2191.76, "end": 2196.32, "text": " There has been a lot of creative work at the sort of multimodal.", "tokens": [50364, 821, 575, 668, 257, 688, 295, 5880, 589, 412, 264, 1333, 295, 32972, 378, 304, 13, 50592, 50592, 407, 689, 291, 362, 732, 1072, 16110, 11, 960, 293, 1626, 420, 732, 27233, 15743, 13, 50848, 50848, 400, 613, 732, 362, 668, 1333, 295, 588, 3743, 293, 6457, 1481, 1333, 295, 589, 1348, 484, 295, 51154, 51154, 341, 13120, 13, 51256, 51256, 407, 264, 2141, 1333, 295, 6358, 294, 613, 1985, 307, 32884, 1968, 364, 3256, 420, 584, 257, 960, 51576, 51576, 7353, 23249, 281, 364, 6278, 7353, 13, 51755, 51755], "temperature": 0.0, "avg_logprob": -0.12526721539704697, "compression_ratio": 1.6744186046511629, "no_speech_prob": 8.664287634019274e-06}, {"id": 556, "seek": 219176, "start": 2196.32, "end": 2201.44, "text": " So where you have two modalities, video and sound or two sensory inputs.", "tokens": [50364, 821, 575, 668, 257, 688, 295, 5880, 589, 412, 264, 1333, 295, 32972, 378, 304, 13, 50592, 50592, 407, 689, 291, 362, 732, 1072, 16110, 11, 960, 293, 1626, 420, 732, 27233, 15743, 13, 50848, 50848, 400, 613, 732, 362, 668, 1333, 295, 588, 3743, 293, 6457, 1481, 1333, 295, 589, 1348, 484, 295, 51154, 51154, 341, 13120, 13, 51256, 51256, 407, 264, 2141, 1333, 295, 6358, 294, 613, 1985, 307, 32884, 1968, 364, 3256, 420, 584, 257, 960, 51576, 51576, 7353, 23249, 281, 364, 6278, 7353, 13, 51755, 51755], "temperature": 0.0, "avg_logprob": -0.12526721539704697, "compression_ratio": 1.6744186046511629, "no_speech_prob": 8.664287634019274e-06}, {"id": 557, "seek": 219176, "start": 2201.44, "end": 2207.5600000000004, "text": " And these two have been sort of very popular and fairly nice sort of work coming out of", "tokens": [50364, 821, 575, 668, 257, 688, 295, 5880, 589, 412, 264, 1333, 295, 32972, 378, 304, 13, 50592, 50592, 407, 689, 291, 362, 732, 1072, 16110, 11, 960, 293, 1626, 420, 732, 27233, 15743, 13, 50848, 50848, 400, 613, 732, 362, 668, 1333, 295, 588, 3743, 293, 6457, 1481, 1333, 295, 589, 1348, 484, 295, 51154, 51154, 341, 13120, 13, 51256, 51256, 407, 264, 2141, 1333, 295, 6358, 294, 613, 1985, 307, 32884, 1968, 364, 3256, 420, 584, 257, 960, 51576, 51576, 7353, 23249, 281, 364, 6278, 7353, 13, 51755, 51755], "temperature": 0.0, "avg_logprob": -0.12526721539704697, "compression_ratio": 1.6744186046511629, "no_speech_prob": 8.664287634019274e-06}, {"id": 558, "seek": 219176, "start": 2207.5600000000004, "end": 2209.6000000000004, "text": " this regime.", "tokens": [50364, 821, 575, 668, 257, 688, 295, 5880, 589, 412, 264, 1333, 295, 32972, 378, 304, 13, 50592, 50592, 407, 689, 291, 362, 732, 1072, 16110, 11, 960, 293, 1626, 420, 732, 27233, 15743, 13, 50848, 50848, 400, 613, 732, 362, 668, 1333, 295, 588, 3743, 293, 6457, 1481, 1333, 295, 589, 1348, 484, 295, 51154, 51154, 341, 13120, 13, 51256, 51256, 407, 264, 2141, 1333, 295, 6358, 294, 613, 1985, 307, 32884, 1968, 364, 3256, 420, 584, 257, 960, 51576, 51576, 7353, 23249, 281, 364, 6278, 7353, 13, 51755, 51755], "temperature": 0.0, "avg_logprob": -0.12526721539704697, "compression_ratio": 1.6744186046511629, "no_speech_prob": 8.664287634019274e-06}, {"id": 559, "seek": 219176, "start": 2209.6000000000004, "end": 2216.0, "text": " So the key sort of signal in these works is predicting whether an image or say a video", "tokens": [50364, 821, 575, 668, 257, 688, 295, 5880, 589, 412, 264, 1333, 295, 32972, 378, 304, 13, 50592, 50592, 407, 689, 291, 362, 732, 1072, 16110, 11, 960, 293, 1626, 420, 732, 27233, 15743, 13, 50848, 50848, 400, 613, 732, 362, 668, 1333, 295, 588, 3743, 293, 6457, 1481, 1333, 295, 589, 1348, 484, 295, 51154, 51154, 341, 13120, 13, 51256, 51256, 407, 264, 2141, 1333, 295, 6358, 294, 613, 1985, 307, 32884, 1968, 364, 3256, 420, 584, 257, 960, 51576, 51576, 7353, 23249, 281, 364, 6278, 7353, 13, 51755, 51755], "temperature": 0.0, "avg_logprob": -0.12526721539704697, "compression_ratio": 1.6744186046511629, "no_speech_prob": 8.664287634019274e-06}, {"id": 560, "seek": 219176, "start": 2216.0, "end": 2219.5800000000004, "text": " clip corresponds to an audio clip.", "tokens": [50364, 821, 575, 668, 257, 688, 295, 5880, 589, 412, 264, 1333, 295, 32972, 378, 304, 13, 50592, 50592, 407, 689, 291, 362, 732, 1072, 16110, 11, 960, 293, 1626, 420, 732, 27233, 15743, 13, 50848, 50848, 400, 613, 732, 362, 668, 1333, 295, 588, 3743, 293, 6457, 1481, 1333, 295, 589, 1348, 484, 295, 51154, 51154, 341, 13120, 13, 51256, 51256, 407, 264, 2141, 1333, 295, 6358, 294, 613, 1985, 307, 32884, 1968, 364, 3256, 420, 584, 257, 960, 51576, 51576, 7353, 23249, 281, 364, 6278, 7353, 13, 51755, 51755], "temperature": 0.0, "avg_logprob": -0.12526721539704697, "compression_ratio": 1.6744186046511629, "no_speech_prob": 8.664287634019274e-06}, {"id": 561, "seek": 221958, "start": 2219.58, "end": 2225.92, "text": " So the way you can sort of construct these tasks is to take a video and you can basically", "tokens": [50364, 407, 264, 636, 291, 393, 1333, 295, 7690, 613, 9608, 307, 281, 747, 257, 960, 293, 291, 393, 1936, 50681, 50681, 445, 6889, 604, 3920, 490, 309, 293, 14138, 747, 364, 6278, 2837, 293, 6889, 604, 644, 295, 50963, 50963, 300, 13, 51013, 51013, 400, 586, 264, 1154, 307, 1936, 281, 6069, 1968, 613, 721, 366, 11760, 420, 51177, 51177, 406, 13, 51357, 51357, 407, 4476, 2212, 341, 2302, 1333, 295, 960, 11, 584, 295, 257, 10206, 11, 291, 393, 6889, 264, 3920, 293, 51699, 51699], "temperature": 0.0, "avg_logprob": -0.13264834880828857, "compression_ratio": 1.7136150234741785, "no_speech_prob": 1.5206011994450819e-05}, {"id": 562, "seek": 221958, "start": 2225.92, "end": 2231.56, "text": " just sample any frame from it and similarly take an audio track and sample any part of", "tokens": [50364, 407, 264, 636, 291, 393, 1333, 295, 7690, 613, 9608, 307, 281, 747, 257, 960, 293, 291, 393, 1936, 50681, 50681, 445, 6889, 604, 3920, 490, 309, 293, 14138, 747, 364, 6278, 2837, 293, 6889, 604, 644, 295, 50963, 50963, 300, 13, 51013, 51013, 400, 586, 264, 1154, 307, 1936, 281, 6069, 1968, 613, 721, 366, 11760, 420, 51177, 51177, 406, 13, 51357, 51357, 407, 4476, 2212, 341, 2302, 1333, 295, 960, 11, 584, 295, 257, 10206, 11, 291, 393, 6889, 264, 3920, 293, 51699, 51699], "temperature": 0.0, "avg_logprob": -0.13264834880828857, "compression_ratio": 1.7136150234741785, "no_speech_prob": 1.5206011994450819e-05}, {"id": 563, "seek": 221958, "start": 2231.56, "end": 2232.56, "text": " that.", "tokens": [50364, 407, 264, 636, 291, 393, 1333, 295, 7690, 613, 9608, 307, 281, 747, 257, 960, 293, 291, 393, 1936, 50681, 50681, 445, 6889, 604, 3920, 490, 309, 293, 14138, 747, 364, 6278, 2837, 293, 6889, 604, 644, 295, 50963, 50963, 300, 13, 51013, 51013, 400, 586, 264, 1154, 307, 1936, 281, 6069, 1968, 613, 721, 366, 11760, 420, 51177, 51177, 406, 13, 51357, 51357, 407, 4476, 2212, 341, 2302, 1333, 295, 960, 11, 584, 295, 257, 10206, 11, 291, 393, 6889, 264, 3920, 293, 51699, 51699], "temperature": 0.0, "avg_logprob": -0.13264834880828857, "compression_ratio": 1.7136150234741785, "no_speech_prob": 1.5206011994450819e-05}, {"id": 564, "seek": 221958, "start": 2232.56, "end": 2235.84, "text": " And now the problem is basically to predict whether these things are corresponding or", "tokens": [50364, 407, 264, 636, 291, 393, 1333, 295, 7690, 613, 9608, 307, 281, 747, 257, 960, 293, 291, 393, 1936, 50681, 50681, 445, 6889, 604, 3920, 490, 309, 293, 14138, 747, 364, 6278, 2837, 293, 6889, 604, 644, 295, 50963, 50963, 300, 13, 51013, 51013, 400, 586, 264, 1154, 307, 1936, 281, 6069, 1968, 613, 721, 366, 11760, 420, 51177, 51177, 406, 13, 51357, 51357, 407, 4476, 2212, 341, 2302, 1333, 295, 960, 11, 584, 295, 257, 10206, 11, 291, 393, 6889, 264, 3920, 293, 51699, 51699], "temperature": 0.0, "avg_logprob": -0.13264834880828857, "compression_ratio": 1.7136150234741785, "no_speech_prob": 1.5206011994450819e-05}, {"id": 565, "seek": 221958, "start": 2235.84, "end": 2239.44, "text": " not.", "tokens": [50364, 407, 264, 636, 291, 393, 1333, 295, 7690, 613, 9608, 307, 281, 747, 257, 960, 293, 291, 393, 1936, 50681, 50681, 445, 6889, 604, 3920, 490, 309, 293, 14138, 747, 364, 6278, 2837, 293, 6889, 604, 644, 295, 50963, 50963, 300, 13, 51013, 51013, 400, 586, 264, 1154, 307, 1936, 281, 6069, 1968, 613, 721, 366, 11760, 420, 51177, 51177, 406, 13, 51357, 51357, 407, 4476, 2212, 341, 2302, 1333, 295, 960, 11, 584, 295, 257, 10206, 11, 291, 393, 6889, 264, 3920, 293, 51699, 51699], "temperature": 0.0, "avg_logprob": -0.13264834880828857, "compression_ratio": 1.7136150234741785, "no_speech_prob": 1.5206011994450819e-05}, {"id": 566, "seek": 221958, "start": 2239.44, "end": 2246.2799999999997, "text": " So essentially given this entire sort of video, say of a drum, you can sample the frame and", "tokens": [50364, 407, 264, 636, 291, 393, 1333, 295, 7690, 613, 9608, 307, 281, 747, 257, 960, 293, 291, 393, 1936, 50681, 50681, 445, 6889, 604, 3920, 490, 309, 293, 14138, 747, 364, 6278, 2837, 293, 6889, 604, 644, 295, 50963, 50963, 300, 13, 51013, 51013, 400, 586, 264, 1154, 307, 1936, 281, 6069, 1968, 613, 721, 366, 11760, 420, 51177, 51177, 406, 13, 51357, 51357, 407, 4476, 2212, 341, 2302, 1333, 295, 960, 11, 584, 295, 257, 10206, 11, 291, 393, 6889, 264, 3920, 293, 51699, 51699], "temperature": 0.0, "avg_logprob": -0.13264834880828857, "compression_ratio": 1.7136150234741785, "no_speech_prob": 1.5206011994450819e-05}, {"id": 567, "seek": 224628, "start": 2246.28, "end": 2249.84, "text": " the corresponding audio and call that the positive.", "tokens": [50364, 264, 11760, 6278, 293, 818, 300, 264, 3353, 13, 50542, 50542, 400, 294, 341, 1389, 11, 291, 1936, 747, 257, 819, 960, 293, 291, 747, 264, 6278, 490, 264, 10206, 50772, 50772, 960, 293, 300, 3643, 428, 3671, 13, 50892, 50892, 400, 370, 797, 11, 291, 393, 5039, 257, 17434, 21538, 1154, 538, 1940, 613, 3840, 295, 35127, 51084, 51084, 293, 40019, 13, 51309, 51309, 407, 264, 9482, 337, 341, 307, 6457, 15325, 13, 51466, 51466, 509, 747, 294, 364, 3256, 11, 291, 1320, 309, 807, 257, 5201, 1422, 3209, 13, 51670, 51670, 509, 362, 428, 6278, 11, 291, 1320, 309, 807, 364, 6278, 1422, 3209, 13, 51848, 51848], "temperature": 0.0, "avg_logprob": -0.11823632695653417, "compression_ratio": 1.8372093023255813, "no_speech_prob": 9.817867976380512e-06}, {"id": 568, "seek": 224628, "start": 2249.84, "end": 2254.44, "text": " And in this case, you basically take a different video and you take the audio from the drum", "tokens": [50364, 264, 11760, 6278, 293, 818, 300, 264, 3353, 13, 50542, 50542, 400, 294, 341, 1389, 11, 291, 1936, 747, 257, 819, 960, 293, 291, 747, 264, 6278, 490, 264, 10206, 50772, 50772, 960, 293, 300, 3643, 428, 3671, 13, 50892, 50892, 400, 370, 797, 11, 291, 393, 5039, 257, 17434, 21538, 1154, 538, 1940, 613, 3840, 295, 35127, 51084, 51084, 293, 40019, 13, 51309, 51309, 407, 264, 9482, 337, 341, 307, 6457, 15325, 13, 51466, 51466, 509, 747, 294, 364, 3256, 11, 291, 1320, 309, 807, 257, 5201, 1422, 3209, 13, 51670, 51670, 509, 362, 428, 6278, 11, 291, 1320, 309, 807, 364, 6278, 1422, 3209, 13, 51848, 51848], "temperature": 0.0, "avg_logprob": -0.11823632695653417, "compression_ratio": 1.8372093023255813, "no_speech_prob": 9.817867976380512e-06}, {"id": 569, "seek": 224628, "start": 2254.44, "end": 2256.84, "text": " video and that becomes your negative.", "tokens": [50364, 264, 11760, 6278, 293, 818, 300, 264, 3353, 13, 50542, 50542, 400, 294, 341, 1389, 11, 291, 1936, 747, 257, 819, 960, 293, 291, 747, 264, 6278, 490, 264, 10206, 50772, 50772, 960, 293, 300, 3643, 428, 3671, 13, 50892, 50892, 400, 370, 797, 11, 291, 393, 5039, 257, 17434, 21538, 1154, 538, 1940, 613, 3840, 295, 35127, 51084, 51084, 293, 40019, 13, 51309, 51309, 407, 264, 9482, 337, 341, 307, 6457, 15325, 13, 51466, 51466, 509, 747, 294, 364, 3256, 11, 291, 1320, 309, 807, 257, 5201, 1422, 3209, 13, 51670, 51670, 509, 362, 428, 6278, 11, 291, 1320, 309, 807, 364, 6278, 1422, 3209, 13, 51848, 51848], "temperature": 0.0, "avg_logprob": -0.11823632695653417, "compression_ratio": 1.8372093023255813, "no_speech_prob": 9.817867976380512e-06}, {"id": 570, "seek": 224628, "start": 2256.84, "end": 2260.6800000000003, "text": " And so again, you can solve a binary classification problem by taking these bunch of positives", "tokens": [50364, 264, 11760, 6278, 293, 818, 300, 264, 3353, 13, 50542, 50542, 400, 294, 341, 1389, 11, 291, 1936, 747, 257, 819, 960, 293, 291, 747, 264, 6278, 490, 264, 10206, 50772, 50772, 960, 293, 300, 3643, 428, 3671, 13, 50892, 50892, 400, 370, 797, 11, 291, 393, 5039, 257, 17434, 21538, 1154, 538, 1940, 613, 3840, 295, 35127, 51084, 51084, 293, 40019, 13, 51309, 51309, 407, 264, 9482, 337, 341, 307, 6457, 15325, 13, 51466, 51466, 509, 747, 294, 364, 3256, 11, 291, 1320, 309, 807, 257, 5201, 1422, 3209, 13, 51670, 51670, 509, 362, 428, 6278, 11, 291, 1320, 309, 807, 364, 6278, 1422, 3209, 13, 51848, 51848], "temperature": 0.0, "avg_logprob": -0.11823632695653417, "compression_ratio": 1.8372093023255813, "no_speech_prob": 9.817867976380512e-06}, {"id": 571, "seek": 224628, "start": 2260.6800000000003, "end": 2265.1800000000003, "text": " and negatives.", "tokens": [50364, 264, 11760, 6278, 293, 818, 300, 264, 3353, 13, 50542, 50542, 400, 294, 341, 1389, 11, 291, 1936, 747, 257, 819, 960, 293, 291, 747, 264, 6278, 490, 264, 10206, 50772, 50772, 960, 293, 300, 3643, 428, 3671, 13, 50892, 50892, 400, 370, 797, 11, 291, 393, 5039, 257, 17434, 21538, 1154, 538, 1940, 613, 3840, 295, 35127, 51084, 51084, 293, 40019, 13, 51309, 51309, 407, 264, 9482, 337, 341, 307, 6457, 15325, 13, 51466, 51466, 509, 747, 294, 364, 3256, 11, 291, 1320, 309, 807, 257, 5201, 1422, 3209, 13, 51670, 51670, 509, 362, 428, 6278, 11, 291, 1320, 309, 807, 364, 6278, 1422, 3209, 13, 51848, 51848], "temperature": 0.0, "avg_logprob": -0.11823632695653417, "compression_ratio": 1.8372093023255813, "no_speech_prob": 9.817867976380512e-06}, {"id": 572, "seek": 224628, "start": 2265.1800000000003, "end": 2268.32, "text": " So the architecture for this is fairly straightforward.", "tokens": [50364, 264, 11760, 6278, 293, 818, 300, 264, 3353, 13, 50542, 50542, 400, 294, 341, 1389, 11, 291, 1936, 747, 257, 819, 960, 293, 291, 747, 264, 6278, 490, 264, 10206, 50772, 50772, 960, 293, 300, 3643, 428, 3671, 13, 50892, 50892, 400, 370, 797, 11, 291, 393, 5039, 257, 17434, 21538, 1154, 538, 1940, 613, 3840, 295, 35127, 51084, 51084, 293, 40019, 13, 51309, 51309, 407, 264, 9482, 337, 341, 307, 6457, 15325, 13, 51466, 51466, 509, 747, 294, 364, 3256, 11, 291, 1320, 309, 807, 257, 5201, 1422, 3209, 13, 51670, 51670, 509, 362, 428, 6278, 11, 291, 1320, 309, 807, 364, 6278, 1422, 3209, 13, 51848, 51848], "temperature": 0.0, "avg_logprob": -0.11823632695653417, "compression_ratio": 1.8372093023255813, "no_speech_prob": 9.817867976380512e-06}, {"id": 573, "seek": 224628, "start": 2268.32, "end": 2272.4, "text": " You take in an image, you pass it through a vision sub network.", "tokens": [50364, 264, 11760, 6278, 293, 818, 300, 264, 3353, 13, 50542, 50542, 400, 294, 341, 1389, 11, 291, 1936, 747, 257, 819, 960, 293, 291, 747, 264, 6278, 490, 264, 10206, 50772, 50772, 960, 293, 300, 3643, 428, 3671, 13, 50892, 50892, 400, 370, 797, 11, 291, 393, 5039, 257, 17434, 21538, 1154, 538, 1940, 613, 3840, 295, 35127, 51084, 51084, 293, 40019, 13, 51309, 51309, 407, 264, 9482, 337, 341, 307, 6457, 15325, 13, 51466, 51466, 509, 747, 294, 364, 3256, 11, 291, 1320, 309, 807, 257, 5201, 1422, 3209, 13, 51670, 51670, 509, 362, 428, 6278, 11, 291, 1320, 309, 807, 364, 6278, 1422, 3209, 13, 51848, 51848], "temperature": 0.0, "avg_logprob": -0.11823632695653417, "compression_ratio": 1.8372093023255813, "no_speech_prob": 9.817867976380512e-06}, {"id": 574, "seek": 224628, "start": 2272.4, "end": 2275.96, "text": " You have your audio, you pass it through an audio sub network.", "tokens": [50364, 264, 11760, 6278, 293, 818, 300, 264, 3353, 13, 50542, 50542, 400, 294, 341, 1389, 11, 291, 1936, 747, 257, 819, 960, 293, 291, 747, 264, 6278, 490, 264, 10206, 50772, 50772, 960, 293, 300, 3643, 428, 3671, 13, 50892, 50892, 400, 370, 797, 11, 291, 393, 5039, 257, 17434, 21538, 1154, 538, 1940, 613, 3840, 295, 35127, 51084, 51084, 293, 40019, 13, 51309, 51309, 407, 264, 9482, 337, 341, 307, 6457, 15325, 13, 51466, 51466, 509, 747, 294, 364, 3256, 11, 291, 1320, 309, 807, 257, 5201, 1422, 3209, 13, 51670, 51670, 509, 362, 428, 6278, 11, 291, 1320, 309, 807, 364, 6278, 1422, 3209, 13, 51848, 51848], "temperature": 0.0, "avg_logprob": -0.11823632695653417, "compression_ratio": 1.8372093023255813, "no_speech_prob": 9.817867976380512e-06}, {"id": 575, "seek": 227596, "start": 2275.96, "end": 2278.28, "text": " You get 128 dimensional features for them.", "tokens": [50364, 509, 483, 29810, 18795, 4122, 337, 552, 13, 50480, 50480, 407, 611, 12240, 29432, 13, 50612, 50612, 1396, 291, 1333, 295, 31328, 552, 1214, 293, 362, 257, 17434, 21538, 1154, 1566, 1968, 50862, 50862, 613, 721, 6805, 420, 406, 13, 50957, 50957, 407, 412, 264, 917, 295, 309, 11, 309, 311, 445, 12606, 257, 2167, 17434, 1154, 13, 51288, 51288, 708, 309, 1333, 295, 3110, 307, 300, 291, 393, 767, 360, 257, 3840, 295, 1333, 295, 1481, 721, 562, 291, 51590, 51590, 3847, 9590, 341, 636, 13, 51674, 51674], "temperature": 0.0, "avg_logprob": -0.10233441027966174, "compression_ratio": 1.6008771929824561, "no_speech_prob": 4.7107732825679705e-06}, {"id": 576, "seek": 227596, "start": 2278.28, "end": 2280.92, "text": " So also embeddings.", "tokens": [50364, 509, 483, 29810, 18795, 4122, 337, 552, 13, 50480, 50480, 407, 611, 12240, 29432, 13, 50612, 50612, 1396, 291, 1333, 295, 31328, 552, 1214, 293, 362, 257, 17434, 21538, 1154, 1566, 1968, 50862, 50862, 613, 721, 6805, 420, 406, 13, 50957, 50957, 407, 412, 264, 917, 295, 309, 11, 309, 311, 445, 12606, 257, 2167, 17434, 1154, 13, 51288, 51288, 708, 309, 1333, 295, 3110, 307, 300, 291, 393, 767, 360, 257, 3840, 295, 1333, 295, 1481, 721, 562, 291, 51590, 51590, 3847, 9590, 341, 636, 13, 51674, 51674], "temperature": 0.0, "avg_logprob": -0.10233441027966174, "compression_ratio": 1.6008771929824561, "no_speech_prob": 4.7107732825679705e-06}, {"id": 577, "seek": 227596, "start": 2280.92, "end": 2285.92, "text": " Then you sort of fuse them together and have a binary classification problem saying whether", "tokens": [50364, 509, 483, 29810, 18795, 4122, 337, 552, 13, 50480, 50480, 407, 611, 12240, 29432, 13, 50612, 50612, 1396, 291, 1333, 295, 31328, 552, 1214, 293, 362, 257, 17434, 21538, 1154, 1566, 1968, 50862, 50862, 613, 721, 6805, 420, 406, 13, 50957, 50957, 407, 412, 264, 917, 295, 309, 11, 309, 311, 445, 12606, 257, 2167, 17434, 1154, 13, 51288, 51288, 708, 309, 1333, 295, 3110, 307, 300, 291, 393, 767, 360, 257, 3840, 295, 1333, 295, 1481, 721, 562, 291, 51590, 51590, 3847, 9590, 341, 636, 13, 51674, 51674], "temperature": 0.0, "avg_logprob": -0.10233441027966174, "compression_ratio": 1.6008771929824561, "no_speech_prob": 4.7107732825679705e-06}, {"id": 578, "seek": 227596, "start": 2285.92, "end": 2287.82, "text": " these things correspond or not.", "tokens": [50364, 509, 483, 29810, 18795, 4122, 337, 552, 13, 50480, 50480, 407, 611, 12240, 29432, 13, 50612, 50612, 1396, 291, 1333, 295, 31328, 552, 1214, 293, 362, 257, 17434, 21538, 1154, 1566, 1968, 50862, 50862, 613, 721, 6805, 420, 406, 13, 50957, 50957, 407, 412, 264, 917, 295, 309, 11, 309, 311, 445, 12606, 257, 2167, 17434, 1154, 13, 51288, 51288, 708, 309, 1333, 295, 3110, 307, 300, 291, 393, 767, 360, 257, 3840, 295, 1333, 295, 1481, 721, 562, 291, 51590, 51590, 3847, 9590, 341, 636, 13, 51674, 51674], "temperature": 0.0, "avg_logprob": -0.10233441027966174, "compression_ratio": 1.6008771929824561, "no_speech_prob": 4.7107732825679705e-06}, {"id": 579, "seek": 227596, "start": 2287.82, "end": 2294.44, "text": " So at the end of it, it's just solving a single binary problem.", "tokens": [50364, 509, 483, 29810, 18795, 4122, 337, 552, 13, 50480, 50480, 407, 611, 12240, 29432, 13, 50612, 50612, 1396, 291, 1333, 295, 31328, 552, 1214, 293, 362, 257, 17434, 21538, 1154, 1566, 1968, 50862, 50862, 613, 721, 6805, 420, 406, 13, 50957, 50957, 407, 412, 264, 917, 295, 309, 11, 309, 311, 445, 12606, 257, 2167, 17434, 1154, 13, 51288, 51288, 708, 309, 1333, 295, 3110, 307, 300, 291, 393, 767, 360, 257, 3840, 295, 1333, 295, 1481, 721, 562, 291, 51590, 51590, 3847, 9590, 341, 636, 13, 51674, 51674], "temperature": 0.0, "avg_logprob": -0.10233441027966174, "compression_ratio": 1.6008771929824561, "no_speech_prob": 4.7107732825679705e-06}, {"id": 580, "seek": 227596, "start": 2294.44, "end": 2300.48, "text": " What it sort of shows is that you can actually do a bunch of sort of nice things when you", "tokens": [50364, 509, 483, 29810, 18795, 4122, 337, 552, 13, 50480, 50480, 407, 611, 12240, 29432, 13, 50612, 50612, 1396, 291, 1333, 295, 31328, 552, 1214, 293, 362, 257, 17434, 21538, 1154, 1566, 1968, 50862, 50862, 613, 721, 6805, 420, 406, 13, 50957, 50957, 407, 412, 264, 917, 295, 309, 11, 309, 311, 445, 12606, 257, 2167, 17434, 1154, 13, 51288, 51288, 708, 309, 1333, 295, 3110, 307, 300, 291, 393, 767, 360, 257, 3840, 295, 1333, 295, 1481, 721, 562, 291, 51590, 51590, 3847, 9590, 341, 636, 13, 51674, 51674], "temperature": 0.0, "avg_logprob": -0.10233441027966174, "compression_ratio": 1.6008771929824561, "no_speech_prob": 4.7107732825679705e-06}, {"id": 581, "seek": 227596, "start": 2300.48, "end": 2302.16, "text": " train networks this way.", "tokens": [50364, 509, 483, 29810, 18795, 4122, 337, 552, 13, 50480, 50480, 407, 611, 12240, 29432, 13, 50612, 50612, 1396, 291, 1333, 295, 31328, 552, 1214, 293, 362, 257, 17434, 21538, 1154, 1566, 1968, 50862, 50862, 613, 721, 6805, 420, 406, 13, 50957, 50957, 407, 412, 264, 917, 295, 309, 11, 309, 311, 445, 12606, 257, 2167, 17434, 1154, 13, 51288, 51288, 708, 309, 1333, 295, 3110, 307, 300, 291, 393, 767, 360, 257, 3840, 295, 1333, 295, 1481, 721, 562, 291, 51590, 51590, 3847, 9590, 341, 636, 13, 51674, 51674], "temperature": 0.0, "avg_logprob": -0.10233441027966174, "compression_ratio": 1.6008771929824561, "no_speech_prob": 4.7107732825679705e-06}, {"id": 582, "seek": 230216, "start": 2302.16, "end": 2306.7999999999997, "text": " So you can answer the question, what is making a sound because the network really needs to", "tokens": [50364, 407, 291, 393, 1867, 264, 1168, 11, 437, 307, 1455, 257, 1626, 570, 264, 3209, 534, 2203, 281, 50596, 50596, 1879, 322, 584, 11, 281, 6069, 1968, 264, 1626, 307, 1348, 490, 341, 960, 13, 50802, 50802, 467, 611, 2203, 281, 5876, 437, 294, 264, 960, 1062, 312, 1455, 264, 1626, 13, 51012, 51012, 407, 498, 309, 311, 264, 1626, 295, 257, 7531, 11, 309, 2203, 281, 1333, 295, 1223, 437, 257, 7531, 9810, 51246, 51246, 1542, 411, 13, 51296, 51296, 1610, 498, 309, 311, 257, 10206, 11, 309, 1333, 295, 2203, 281, 9810, 5876, 437, 257, 10206, 307, 13, 51620, 51620], "temperature": 0.0, "avg_logprob": -0.08616805993593656, "compression_ratio": 1.8272727272727274, "no_speech_prob": 5.255262749415124e-06}, {"id": 583, "seek": 230216, "start": 2306.7999999999997, "end": 2310.92, "text": " focus on say, to predict whether the sound is coming from this video.", "tokens": [50364, 407, 291, 393, 1867, 264, 1168, 11, 437, 307, 1455, 257, 1626, 570, 264, 3209, 534, 2203, 281, 50596, 50596, 1879, 322, 584, 11, 281, 6069, 1968, 264, 1626, 307, 1348, 490, 341, 960, 13, 50802, 50802, 467, 611, 2203, 281, 5876, 437, 294, 264, 960, 1062, 312, 1455, 264, 1626, 13, 51012, 51012, 407, 498, 309, 311, 264, 1626, 295, 257, 7531, 11, 309, 2203, 281, 1333, 295, 1223, 437, 257, 7531, 9810, 51246, 51246, 1542, 411, 13, 51296, 51296, 1610, 498, 309, 311, 257, 10206, 11, 309, 1333, 295, 2203, 281, 9810, 5876, 437, 257, 10206, 307, 13, 51620, 51620], "temperature": 0.0, "avg_logprob": -0.08616805993593656, "compression_ratio": 1.8272727272727274, "no_speech_prob": 5.255262749415124e-06}, {"id": 584, "seek": 230216, "start": 2310.92, "end": 2315.12, "text": " It also needs to identify what in the video might be making the sound.", "tokens": [50364, 407, 291, 393, 1867, 264, 1168, 11, 437, 307, 1455, 257, 1626, 570, 264, 3209, 534, 2203, 281, 50596, 50596, 1879, 322, 584, 11, 281, 6069, 1968, 264, 1626, 307, 1348, 490, 341, 960, 13, 50802, 50802, 467, 611, 2203, 281, 5876, 437, 294, 264, 960, 1062, 312, 1455, 264, 1626, 13, 51012, 51012, 407, 498, 309, 311, 264, 1626, 295, 257, 7531, 11, 309, 2203, 281, 1333, 295, 1223, 437, 257, 7531, 9810, 51246, 51246, 1542, 411, 13, 51296, 51296, 1610, 498, 309, 311, 257, 10206, 11, 309, 1333, 295, 2203, 281, 9810, 5876, 437, 257, 10206, 307, 13, 51620, 51620], "temperature": 0.0, "avg_logprob": -0.08616805993593656, "compression_ratio": 1.8272727272727274, "no_speech_prob": 5.255262749415124e-06}, {"id": 585, "seek": 230216, "start": 2315.12, "end": 2319.7999999999997, "text": " So if it's the sound of a guitar, it needs to sort of understand what a guitar roughly", "tokens": [50364, 407, 291, 393, 1867, 264, 1168, 11, 437, 307, 1455, 257, 1626, 570, 264, 3209, 534, 2203, 281, 50596, 50596, 1879, 322, 584, 11, 281, 6069, 1968, 264, 1626, 307, 1348, 490, 341, 960, 13, 50802, 50802, 467, 611, 2203, 281, 5876, 437, 294, 264, 960, 1062, 312, 1455, 264, 1626, 13, 51012, 51012, 407, 498, 309, 311, 264, 1626, 295, 257, 7531, 11, 309, 2203, 281, 1333, 295, 1223, 437, 257, 7531, 9810, 51246, 51246, 1542, 411, 13, 51296, 51296, 1610, 498, 309, 311, 257, 10206, 11, 309, 1333, 295, 2203, 281, 9810, 5876, 437, 257, 10206, 307, 13, 51620, 51620], "temperature": 0.0, "avg_logprob": -0.08616805993593656, "compression_ratio": 1.8272727272727274, "no_speech_prob": 5.255262749415124e-06}, {"id": 586, "seek": 230216, "start": 2319.7999999999997, "end": 2320.7999999999997, "text": " looks like.", "tokens": [50364, 407, 291, 393, 1867, 264, 1168, 11, 437, 307, 1455, 257, 1626, 570, 264, 3209, 534, 2203, 281, 50596, 50596, 1879, 322, 584, 11, 281, 6069, 1968, 264, 1626, 307, 1348, 490, 341, 960, 13, 50802, 50802, 467, 611, 2203, 281, 5876, 437, 294, 264, 960, 1062, 312, 1455, 264, 1626, 13, 51012, 51012, 407, 498, 309, 311, 264, 1626, 295, 257, 7531, 11, 309, 2203, 281, 1333, 295, 1223, 437, 257, 7531, 9810, 51246, 51246, 1542, 411, 13, 51296, 51296, 1610, 498, 309, 311, 257, 10206, 11, 309, 1333, 295, 2203, 281, 9810, 5876, 437, 257, 10206, 307, 13, 51620, 51620], "temperature": 0.0, "avg_logprob": -0.08616805993593656, "compression_ratio": 1.8272727272727274, "no_speech_prob": 5.255262749415124e-06}, {"id": 587, "seek": 230216, "start": 2320.7999999999997, "end": 2327.2799999999997, "text": " Or if it's a drum, it sort of needs to roughly identify what a drum is.", "tokens": [50364, 407, 291, 393, 1867, 264, 1168, 11, 437, 307, 1455, 257, 1626, 570, 264, 3209, 534, 2203, 281, 50596, 50596, 1879, 322, 584, 11, 281, 6069, 1968, 264, 1626, 307, 1348, 490, 341, 960, 13, 50802, 50802, 467, 611, 2203, 281, 5876, 437, 294, 264, 960, 1062, 312, 1455, 264, 1626, 13, 51012, 51012, 407, 498, 309, 311, 264, 1626, 295, 257, 7531, 11, 309, 2203, 281, 1333, 295, 1223, 437, 257, 7531, 9810, 51246, 51246, 1542, 411, 13, 51296, 51296, 1610, 498, 309, 311, 257, 10206, 11, 309, 1333, 295, 2203, 281, 9810, 5876, 437, 257, 10206, 307, 13, 51620, 51620], "temperature": 0.0, "avg_logprob": -0.08616805993593656, "compression_ratio": 1.8272727272727274, "no_speech_prob": 5.255262749415124e-06}, {"id": 588, "seek": 232728, "start": 2327.28, "end": 2333.7200000000003, "text": " So in this particular case, the author sort of looked at visualizations for, in this case,", "tokens": [50364, 407, 294, 341, 1729, 1389, 11, 264, 3793, 1333, 295, 2956, 412, 5056, 14455, 337, 11, 294, 341, 1389, 11, 50686, 50686, 732, 12190, 13, 50736, 50736, 407, 291, 362, 257, 9211, 293, 257, 33088, 13, 50864, 50864, 400, 291, 574, 412, 445, 264, 960, 1589, 293, 1825, 1646, 13, 51084, 51084, 440, 3209, 1217, 1333, 295, 8137, 257, 588, 1090, 1333, 295, 5056, 7379, 322, 264, 9211, 293, 51483, 51483, 322, 264, 33088, 13, 51568, 51568, 400, 341, 307, 570, 562, 291, 1333, 295, 3154, 2128, 341, 3256, 11, 309, 3255, 300, 456, 366, 51744, 51744], "temperature": 0.0, "avg_logprob": -0.09810455399330216, "compression_ratio": 1.7212389380530972, "no_speech_prob": 3.089389792876318e-06}, {"id": 589, "seek": 232728, "start": 2333.7200000000003, "end": 2334.7200000000003, "text": " two instruments.", "tokens": [50364, 407, 294, 341, 1729, 1389, 11, 264, 3793, 1333, 295, 2956, 412, 5056, 14455, 337, 11, 294, 341, 1389, 11, 50686, 50686, 732, 12190, 13, 50736, 50736, 407, 291, 362, 257, 9211, 293, 257, 33088, 13, 50864, 50864, 400, 291, 574, 412, 445, 264, 960, 1589, 293, 1825, 1646, 13, 51084, 51084, 440, 3209, 1217, 1333, 295, 8137, 257, 588, 1090, 1333, 295, 5056, 7379, 322, 264, 9211, 293, 51483, 51483, 322, 264, 33088, 13, 51568, 51568, 400, 341, 307, 570, 562, 291, 1333, 295, 3154, 2128, 341, 3256, 11, 309, 3255, 300, 456, 366, 51744, 51744], "temperature": 0.0, "avg_logprob": -0.09810455399330216, "compression_ratio": 1.7212389380530972, "no_speech_prob": 3.089389792876318e-06}, {"id": 590, "seek": 232728, "start": 2334.7200000000003, "end": 2337.28, "text": " So you have a piano and a flute.", "tokens": [50364, 407, 294, 341, 1729, 1389, 11, 264, 3793, 1333, 295, 2956, 412, 5056, 14455, 337, 11, 294, 341, 1389, 11, 50686, 50686, 732, 12190, 13, 50736, 50736, 407, 291, 362, 257, 9211, 293, 257, 33088, 13, 50864, 50864, 400, 291, 574, 412, 445, 264, 960, 1589, 293, 1825, 1646, 13, 51084, 51084, 440, 3209, 1217, 1333, 295, 8137, 257, 588, 1090, 1333, 295, 5056, 7379, 322, 264, 9211, 293, 51483, 51483, 322, 264, 33088, 13, 51568, 51568, 400, 341, 307, 570, 562, 291, 1333, 295, 3154, 2128, 341, 3256, 11, 309, 3255, 300, 456, 366, 51744, 51744], "temperature": 0.0, "avg_logprob": -0.09810455399330216, "compression_ratio": 1.7212389380530972, "no_speech_prob": 3.089389792876318e-06}, {"id": 591, "seek": 232728, "start": 2337.28, "end": 2341.6800000000003, "text": " And you look at just the video information and nothing else.", "tokens": [50364, 407, 294, 341, 1729, 1389, 11, 264, 3793, 1333, 295, 2956, 412, 5056, 14455, 337, 11, 294, 341, 1389, 11, 50686, 50686, 732, 12190, 13, 50736, 50736, 407, 291, 362, 257, 9211, 293, 257, 33088, 13, 50864, 50864, 400, 291, 574, 412, 445, 264, 960, 1589, 293, 1825, 1646, 13, 51084, 51084, 440, 3209, 1217, 1333, 295, 8137, 257, 588, 1090, 1333, 295, 5056, 7379, 322, 264, 9211, 293, 51483, 51483, 322, 264, 33088, 13, 51568, 51568, 400, 341, 307, 570, 562, 291, 1333, 295, 3154, 2128, 341, 3256, 11, 309, 3255, 300, 456, 366, 51744, 51744], "temperature": 0.0, "avg_logprob": -0.09810455399330216, "compression_ratio": 1.7212389380530972, "no_speech_prob": 3.089389792876318e-06}, {"id": 592, "seek": 232728, "start": 2341.6800000000003, "end": 2349.6600000000003, "text": " The network already sort of puts a very high sort of visual importance on the piano and", "tokens": [50364, 407, 294, 341, 1729, 1389, 11, 264, 3793, 1333, 295, 2956, 412, 5056, 14455, 337, 11, 294, 341, 1389, 11, 50686, 50686, 732, 12190, 13, 50736, 50736, 407, 291, 362, 257, 9211, 293, 257, 33088, 13, 50864, 50864, 400, 291, 574, 412, 445, 264, 960, 1589, 293, 1825, 1646, 13, 51084, 51084, 440, 3209, 1217, 1333, 295, 8137, 257, 588, 1090, 1333, 295, 5056, 7379, 322, 264, 9211, 293, 51483, 51483, 322, 264, 33088, 13, 51568, 51568, 400, 341, 307, 570, 562, 291, 1333, 295, 3154, 2128, 341, 3256, 11, 309, 3255, 300, 456, 366, 51744, 51744], "temperature": 0.0, "avg_logprob": -0.09810455399330216, "compression_ratio": 1.7212389380530972, "no_speech_prob": 3.089389792876318e-06}, {"id": 593, "seek": 232728, "start": 2349.6600000000003, "end": 2351.36, "text": " on the flute.", "tokens": [50364, 407, 294, 341, 1729, 1389, 11, 264, 3793, 1333, 295, 2956, 412, 5056, 14455, 337, 11, 294, 341, 1389, 11, 50686, 50686, 732, 12190, 13, 50736, 50736, 407, 291, 362, 257, 9211, 293, 257, 33088, 13, 50864, 50864, 400, 291, 574, 412, 445, 264, 960, 1589, 293, 1825, 1646, 13, 51084, 51084, 440, 3209, 1217, 1333, 295, 8137, 257, 588, 1090, 1333, 295, 5056, 7379, 322, 264, 9211, 293, 51483, 51483, 322, 264, 33088, 13, 51568, 51568, 400, 341, 307, 570, 562, 291, 1333, 295, 3154, 2128, 341, 3256, 11, 309, 3255, 300, 456, 366, 51744, 51744], "temperature": 0.0, "avg_logprob": -0.09810455399330216, "compression_ratio": 1.7212389380530972, "no_speech_prob": 3.089389792876318e-06}, {"id": 594, "seek": 232728, "start": 2351.36, "end": 2354.88, "text": " And this is because when you sort of feed forward this image, it knows that there are", "tokens": [50364, 407, 294, 341, 1729, 1389, 11, 264, 3793, 1333, 295, 2956, 412, 5056, 14455, 337, 11, 294, 341, 1389, 11, 50686, 50686, 732, 12190, 13, 50736, 50736, 407, 291, 362, 257, 9211, 293, 257, 33088, 13, 50864, 50864, 400, 291, 574, 412, 445, 264, 960, 1589, 293, 1825, 1646, 13, 51084, 51084, 440, 3209, 1217, 1333, 295, 8137, 257, 588, 1090, 1333, 295, 5056, 7379, 322, 264, 9211, 293, 51483, 51483, 322, 264, 33088, 13, 51568, 51568, 400, 341, 307, 570, 562, 291, 1333, 295, 3154, 2128, 341, 3256, 11, 309, 3255, 300, 456, 366, 51744, 51744], "temperature": 0.0, "avg_logprob": -0.09810455399330216, "compression_ratio": 1.7212389380530972, "no_speech_prob": 3.089389792876318e-06}, {"id": 595, "seek": 235488, "start": 2354.88, "end": 2358.76, "text": " going to be these two kinds of things that can produce sounds.", "tokens": [50364, 516, 281, 312, 613, 732, 3685, 295, 721, 300, 393, 5258, 3263, 13, 50558, 50558, 407, 309, 534, 1333, 295, 27152, 281, 5876, 613, 3685, 295, 6565, 6772, 13, 50844, 50844, 1144, 291, 458, 466, 264, 4137, 949, 11, 5699, 291, 632, 264, 45216, 304, 2533, 670, 264, 6177, 340, 1342, 11, 51268, 51268, 360, 291, 458, 437, 307, 264, 28256, 2744, 337, 300, 6278, 6542, 30, 51436, 51436, 1449, 286, 478, 3102, 281, 458, 1968, 309, 1669, 2020, 281, 362, 257, 31167, 420, 257, 3732, 28256, 51686, 51686, 2744, 30, 51736, 51736], "temperature": 0.0, "avg_logprob": -0.18624353910747327, "compression_ratio": 1.6072874493927125, "no_speech_prob": 2.0775802113348618e-05}, {"id": 596, "seek": 235488, "start": 2358.76, "end": 2364.48, "text": " So it really sort of learns to identify these kinds of objects automatically.", "tokens": [50364, 516, 281, 312, 613, 732, 3685, 295, 721, 300, 393, 5258, 3263, 13, 50558, 50558, 407, 309, 534, 1333, 295, 27152, 281, 5876, 613, 3685, 295, 6565, 6772, 13, 50844, 50844, 1144, 291, 458, 466, 264, 4137, 949, 11, 5699, 291, 632, 264, 45216, 304, 2533, 670, 264, 6177, 340, 1342, 11, 51268, 51268, 360, 291, 458, 437, 307, 264, 28256, 2744, 337, 300, 6278, 6542, 30, 51436, 51436, 1449, 286, 478, 3102, 281, 458, 1968, 309, 1669, 2020, 281, 362, 257, 31167, 420, 257, 3732, 28256, 51686, 51686, 2744, 30, 51736, 51736], "temperature": 0.0, "avg_logprob": -0.18624353910747327, "compression_ratio": 1.6072874493927125, "no_speech_prob": 2.0775802113348618e-05}, {"id": 597, "seek": 235488, "start": 2364.48, "end": 2372.96, "text": " Do you know about the slide before, whenever you had the convolutional net over the spectrogram,", "tokens": [50364, 516, 281, 312, 613, 732, 3685, 295, 721, 300, 393, 5258, 3263, 13, 50558, 50558, 407, 309, 534, 1333, 295, 27152, 281, 5876, 613, 3685, 295, 6565, 6772, 13, 50844, 50844, 1144, 291, 458, 466, 264, 4137, 949, 11, 5699, 291, 632, 264, 45216, 304, 2533, 670, 264, 6177, 340, 1342, 11, 51268, 51268, 360, 291, 458, 437, 307, 264, 28256, 2744, 337, 300, 6278, 6542, 30, 51436, 51436, 1449, 286, 478, 3102, 281, 458, 1968, 309, 1669, 2020, 281, 362, 257, 31167, 420, 257, 3732, 28256, 51686, 51686, 2744, 30, 51736, 51736], "temperature": 0.0, "avg_logprob": -0.18624353910747327, "compression_ratio": 1.6072874493927125, "no_speech_prob": 2.0775802113348618e-05}, {"id": 598, "seek": 235488, "start": 2372.96, "end": 2376.32, "text": " do you know what is the kernel size for that audio component?", "tokens": [50364, 516, 281, 312, 613, 732, 3685, 295, 721, 300, 393, 5258, 3263, 13, 50558, 50558, 407, 309, 534, 1333, 295, 27152, 281, 5876, 613, 3685, 295, 6565, 6772, 13, 50844, 50844, 1144, 291, 458, 466, 264, 4137, 949, 11, 5699, 291, 632, 264, 45216, 304, 2533, 670, 264, 6177, 340, 1342, 11, 51268, 51268, 360, 291, 458, 437, 307, 264, 28256, 2744, 337, 300, 6278, 6542, 30, 51436, 51436, 1449, 286, 478, 3102, 281, 458, 1968, 309, 1669, 2020, 281, 362, 257, 31167, 420, 257, 3732, 28256, 51686, 51686, 2744, 30, 51736, 51736], "temperature": 0.0, "avg_logprob": -0.18624353910747327, "compression_ratio": 1.6072874493927125, "no_speech_prob": 2.0775802113348618e-05}, {"id": 599, "seek": 235488, "start": 2376.32, "end": 2381.32, "text": " Just I'm interested to know whether it makes sense to have a rectangular or a square kernel", "tokens": [50364, 516, 281, 312, 613, 732, 3685, 295, 721, 300, 393, 5258, 3263, 13, 50558, 50558, 407, 309, 534, 1333, 295, 27152, 281, 5876, 613, 3685, 295, 6565, 6772, 13, 50844, 50844, 1144, 291, 458, 466, 264, 4137, 949, 11, 5699, 291, 632, 264, 45216, 304, 2533, 670, 264, 6177, 340, 1342, 11, 51268, 51268, 360, 291, 458, 437, 307, 264, 28256, 2744, 337, 300, 6278, 6542, 30, 51436, 51436, 1449, 286, 478, 3102, 281, 458, 1968, 309, 1669, 2020, 281, 362, 257, 31167, 420, 257, 3732, 28256, 51686, 51686, 2744, 30, 51736, 51736], "temperature": 0.0, "avg_logprob": -0.18624353910747327, "compression_ratio": 1.6072874493927125, "no_speech_prob": 2.0775802113348618e-05}, {"id": 600, "seek": 235488, "start": 2381.32, "end": 2382.32, "text": " size?", "tokens": [50364, 516, 281, 312, 613, 732, 3685, 295, 721, 300, 393, 5258, 3263, 13, 50558, 50558, 407, 309, 534, 1333, 295, 27152, 281, 5876, 613, 3685, 295, 6565, 6772, 13, 50844, 50844, 1144, 291, 458, 466, 264, 4137, 949, 11, 5699, 291, 632, 264, 45216, 304, 2533, 670, 264, 6177, 340, 1342, 11, 51268, 51268, 360, 291, 458, 437, 307, 264, 28256, 2744, 337, 300, 6278, 6542, 30, 51436, 51436, 1449, 286, 478, 3102, 281, 458, 1968, 309, 1669, 2020, 281, 362, 257, 31167, 420, 257, 3732, 28256, 51686, 51686, 2744, 30, 51736, 51736], "temperature": 0.0, "avg_logprob": -0.18624353910747327, "compression_ratio": 1.6072874493927125, "no_speech_prob": 2.0775802113348618e-05}, {"id": 601, "seek": 238232, "start": 2382.32, "end": 2385.0, "text": " These are square kernels.", "tokens": [50364, 1981, 366, 3732, 23434, 1625, 13, 50498, 50498, 286, 914, 11, 586, 456, 366, 1333, 295, 544, 9689, 5245, 13, 50666, 50666, 407, 341, 307, 1936, 7447, 322, 264, 3565, 6177, 340, 1342, 13, 50802, 50802, 407, 309, 311, 920, 1011, 5611, 292, 13, 50904, 50904, 509, 643, 281, 4536, 577, 291, 434, 15866, 300, 6177, 340, 1342, 2293, 13, 51100, 51100, 3432, 362, 586, 8932, 484, 300, 291, 393, 767, 764, 264, 8936, 6278, 293, 291, 393, 767, 3079, 51288, 51288, 45216, 304, 15995, 3838, 322, 264, 8936, 6278, 6358, 13, 51488, 51488, 400, 337, 300, 11, 309, 311, 5101, 257, 1359, 4910, 13, 51590, 51590, 467, 534, 5946, 322, 437, 264, 11760, 960, 300, 291, 434, 1228, 13, 51770, 51770], "temperature": 0.0, "avg_logprob": -0.1656068217369818, "compression_ratio": 1.6955017301038062, "no_speech_prob": 4.331395757617429e-05}, {"id": 602, "seek": 238232, "start": 2385.0, "end": 2388.36, "text": " I mean, now there are sort of more improved models.", "tokens": [50364, 1981, 366, 3732, 23434, 1625, 13, 50498, 50498, 286, 914, 11, 586, 456, 366, 1333, 295, 544, 9689, 5245, 13, 50666, 50666, 407, 341, 307, 1936, 7447, 322, 264, 3565, 6177, 340, 1342, 13, 50802, 50802, 407, 309, 311, 920, 1011, 5611, 292, 13, 50904, 50904, 509, 643, 281, 4536, 577, 291, 434, 15866, 300, 6177, 340, 1342, 2293, 13, 51100, 51100, 3432, 362, 586, 8932, 484, 300, 291, 393, 767, 764, 264, 8936, 6278, 293, 291, 393, 767, 3079, 51288, 51288, 45216, 304, 15995, 3838, 322, 264, 8936, 6278, 6358, 13, 51488, 51488, 400, 337, 300, 11, 309, 311, 5101, 257, 1359, 4910, 13, 51590, 51590, 467, 534, 5946, 322, 437, 264, 11760, 960, 300, 291, 434, 1228, 13, 51770, 51770], "temperature": 0.0, "avg_logprob": -0.1656068217369818, "compression_ratio": 1.6955017301038062, "no_speech_prob": 4.331395757617429e-05}, {"id": 603, "seek": 238232, "start": 2388.36, "end": 2391.0800000000004, "text": " So this is basically operating on the log spectrogram.", "tokens": [50364, 1981, 366, 3732, 23434, 1625, 13, 50498, 50498, 286, 914, 11, 586, 456, 366, 1333, 295, 544, 9689, 5245, 13, 50666, 50666, 407, 341, 307, 1936, 7447, 322, 264, 3565, 6177, 340, 1342, 13, 50802, 50802, 407, 309, 311, 920, 1011, 5611, 292, 13, 50904, 50904, 509, 643, 281, 4536, 577, 291, 434, 15866, 300, 6177, 340, 1342, 2293, 13, 51100, 51100, 3432, 362, 586, 8932, 484, 300, 291, 393, 767, 764, 264, 8936, 6278, 293, 291, 393, 767, 3079, 51288, 51288, 45216, 304, 15995, 3838, 322, 264, 8936, 6278, 6358, 13, 51488, 51488, 400, 337, 300, 11, 309, 311, 5101, 257, 1359, 4910, 13, 51590, 51590, 467, 534, 5946, 322, 437, 264, 11760, 960, 300, 291, 434, 1228, 13, 51770, 51770], "temperature": 0.0, "avg_logprob": -0.1656068217369818, "compression_ratio": 1.6955017301038062, "no_speech_prob": 4.331395757617429e-05}, {"id": 604, "seek": 238232, "start": 2391.0800000000004, "end": 2393.1200000000003, "text": " So it's still handcrafted.", "tokens": [50364, 1981, 366, 3732, 23434, 1625, 13, 50498, 50498, 286, 914, 11, 586, 456, 366, 1333, 295, 544, 9689, 5245, 13, 50666, 50666, 407, 341, 307, 1936, 7447, 322, 264, 3565, 6177, 340, 1342, 13, 50802, 50802, 407, 309, 311, 920, 1011, 5611, 292, 13, 50904, 50904, 509, 643, 281, 4536, 577, 291, 434, 15866, 300, 6177, 340, 1342, 2293, 13, 51100, 51100, 3432, 362, 586, 8932, 484, 300, 291, 393, 767, 764, 264, 8936, 6278, 293, 291, 393, 767, 3079, 51288, 51288, 45216, 304, 15995, 3838, 322, 264, 8936, 6278, 6358, 13, 51488, 51488, 400, 337, 300, 11, 309, 311, 5101, 257, 1359, 4910, 13, 51590, 51590, 467, 534, 5946, 322, 437, 264, 11760, 960, 300, 291, 434, 1228, 13, 51770, 51770], "temperature": 0.0, "avg_logprob": -0.1656068217369818, "compression_ratio": 1.6955017301038062, "no_speech_prob": 4.331395757617429e-05}, {"id": 605, "seek": 238232, "start": 2393.1200000000003, "end": 2397.04, "text": " You need to decide how you're computing that spectrogram exactly.", "tokens": [50364, 1981, 366, 3732, 23434, 1625, 13, 50498, 50498, 286, 914, 11, 586, 456, 366, 1333, 295, 544, 9689, 5245, 13, 50666, 50666, 407, 341, 307, 1936, 7447, 322, 264, 3565, 6177, 340, 1342, 13, 50802, 50802, 407, 309, 311, 920, 1011, 5611, 292, 13, 50904, 50904, 509, 643, 281, 4536, 577, 291, 434, 15866, 300, 6177, 340, 1342, 2293, 13, 51100, 51100, 3432, 362, 586, 8932, 484, 300, 291, 393, 767, 764, 264, 8936, 6278, 293, 291, 393, 767, 3079, 51288, 51288, 45216, 304, 15995, 3838, 322, 264, 8936, 6278, 6358, 13, 51488, 51488, 400, 337, 300, 11, 309, 311, 5101, 257, 1359, 4910, 13, 51590, 51590, 467, 534, 5946, 322, 437, 264, 11760, 960, 300, 291, 434, 1228, 13, 51770, 51770], "temperature": 0.0, "avg_logprob": -0.1656068217369818, "compression_ratio": 1.6955017301038062, "no_speech_prob": 4.331395757617429e-05}, {"id": 606, "seek": 238232, "start": 2397.04, "end": 2400.8, "text": " People have now figured out that you can actually use the raw audio and you can actually apply", "tokens": [50364, 1981, 366, 3732, 23434, 1625, 13, 50498, 50498, 286, 914, 11, 586, 456, 366, 1333, 295, 544, 9689, 5245, 13, 50666, 50666, 407, 341, 307, 1936, 7447, 322, 264, 3565, 6177, 340, 1342, 13, 50802, 50802, 407, 309, 311, 920, 1011, 5611, 292, 13, 50904, 50904, 509, 643, 281, 4536, 577, 291, 434, 15866, 300, 6177, 340, 1342, 2293, 13, 51100, 51100, 3432, 362, 586, 8932, 484, 300, 291, 393, 767, 764, 264, 8936, 6278, 293, 291, 393, 767, 3079, 51288, 51288, 45216, 304, 15995, 3838, 322, 264, 8936, 6278, 6358, 13, 51488, 51488, 400, 337, 300, 11, 309, 311, 5101, 257, 1359, 4910, 13, 51590, 51590, 467, 534, 5946, 322, 437, 264, 11760, 960, 300, 291, 434, 1228, 13, 51770, 51770], "temperature": 0.0, "avg_logprob": -0.1656068217369818, "compression_ratio": 1.6955017301038062, "no_speech_prob": 4.331395757617429e-05}, {"id": 607, "seek": 238232, "start": 2400.8, "end": 2404.8, "text": " convolutional filters directly on the raw audio signal.", "tokens": [50364, 1981, 366, 3732, 23434, 1625, 13, 50498, 50498, 286, 914, 11, 586, 456, 366, 1333, 295, 544, 9689, 5245, 13, 50666, 50666, 407, 341, 307, 1936, 7447, 322, 264, 3565, 6177, 340, 1342, 13, 50802, 50802, 407, 309, 311, 920, 1011, 5611, 292, 13, 50904, 50904, 509, 643, 281, 4536, 577, 291, 434, 15866, 300, 6177, 340, 1342, 2293, 13, 51100, 51100, 3432, 362, 586, 8932, 484, 300, 291, 393, 767, 764, 264, 8936, 6278, 293, 291, 393, 767, 3079, 51288, 51288, 45216, 304, 15995, 3838, 322, 264, 8936, 6278, 6358, 13, 51488, 51488, 400, 337, 300, 11, 309, 311, 5101, 257, 1359, 4910, 13, 51590, 51590, 467, 534, 5946, 322, 437, 264, 11760, 960, 300, 291, 434, 1228, 13, 51770, 51770], "temperature": 0.0, "avg_logprob": -0.1656068217369818, "compression_ratio": 1.6955017301038062, "no_speech_prob": 4.331395757617429e-05}, {"id": 608, "seek": 238232, "start": 2404.8, "end": 2406.84, "text": " And for that, it's generally a small window.", "tokens": [50364, 1981, 366, 3732, 23434, 1625, 13, 50498, 50498, 286, 914, 11, 586, 456, 366, 1333, 295, 544, 9689, 5245, 13, 50666, 50666, 407, 341, 307, 1936, 7447, 322, 264, 3565, 6177, 340, 1342, 13, 50802, 50802, 407, 309, 311, 920, 1011, 5611, 292, 13, 50904, 50904, 509, 643, 281, 4536, 577, 291, 434, 15866, 300, 6177, 340, 1342, 2293, 13, 51100, 51100, 3432, 362, 586, 8932, 484, 300, 291, 393, 767, 764, 264, 8936, 6278, 293, 291, 393, 767, 3079, 51288, 51288, 45216, 304, 15995, 3838, 322, 264, 8936, 6278, 6358, 13, 51488, 51488, 400, 337, 300, 11, 309, 311, 5101, 257, 1359, 4910, 13, 51590, 51590, 467, 534, 5946, 322, 437, 264, 11760, 960, 300, 291, 434, 1228, 13, 51770, 51770], "temperature": 0.0, "avg_logprob": -0.1656068217369818, "compression_ratio": 1.6955017301038062, "no_speech_prob": 4.331395757617429e-05}, {"id": 609, "seek": 238232, "start": 2406.84, "end": 2410.44, "text": " It really depends on what the corresponding video that you're using.", "tokens": [50364, 1981, 366, 3732, 23434, 1625, 13, 50498, 50498, 286, 914, 11, 586, 456, 366, 1333, 295, 544, 9689, 5245, 13, 50666, 50666, 407, 341, 307, 1936, 7447, 322, 264, 3565, 6177, 340, 1342, 13, 50802, 50802, 407, 309, 311, 920, 1011, 5611, 292, 13, 50904, 50904, 509, 643, 281, 4536, 577, 291, 434, 15866, 300, 6177, 340, 1342, 2293, 13, 51100, 51100, 3432, 362, 586, 8932, 484, 300, 291, 393, 767, 764, 264, 8936, 6278, 293, 291, 393, 767, 3079, 51288, 51288, 45216, 304, 15995, 3838, 322, 264, 8936, 6278, 6358, 13, 51488, 51488, 400, 337, 300, 11, 309, 311, 5101, 257, 1359, 4910, 13, 51590, 51590, 467, 534, 5946, 322, 437, 264, 11760, 960, 300, 291, 434, 1228, 13, 51770, 51770], "temperature": 0.0, "avg_logprob": -0.1656068217369818, "compression_ratio": 1.6955017301038062, "no_speech_prob": 4.331395757617429e-05}, {"id": 610, "seek": 241044, "start": 2410.44, "end": 2420.0, "text": " So roughly about a second's worth of audio and a second's worth of video.", "tokens": [50364, 407, 9810, 466, 257, 1150, 311, 3163, 295, 6278, 293, 257, 1150, 311, 3163, 295, 960, 13, 50842, 50842, 407, 586, 300, 286, 600, 1333, 295, 4898, 291, 577, 456, 366, 411, 3866, 819, 5880, 2098, 51100, 51100, 295, 17827, 437, 257, 659, 25111, 5633, 307, 11, 718, 311, 853, 281, 536, 437, 257, 659, 25111, 5633, 27152, 13, 51448, 51448, 400, 577, 393, 291, 1333, 295, 11, 498, 286, 976, 291, 3552, 819, 659, 25111, 9608, 11, 577, 393, 291, 257, 4059, 72, 51768, 51768], "temperature": 0.0, "avg_logprob": -0.15437286550348456, "compression_ratio": 1.731578947368421, "no_speech_prob": 2.840695196937304e-05}, {"id": 611, "seek": 241044, "start": 2420.0, "end": 2425.16, "text": " So now that I've sort of shown you how there are like multiple different creative ways", "tokens": [50364, 407, 9810, 466, 257, 1150, 311, 3163, 295, 6278, 293, 257, 1150, 311, 3163, 295, 960, 13, 50842, 50842, 407, 586, 300, 286, 600, 1333, 295, 4898, 291, 577, 456, 366, 411, 3866, 819, 5880, 2098, 51100, 51100, 295, 17827, 437, 257, 659, 25111, 5633, 307, 11, 718, 311, 853, 281, 536, 437, 257, 659, 25111, 5633, 27152, 13, 51448, 51448, 400, 577, 393, 291, 1333, 295, 11, 498, 286, 976, 291, 3552, 819, 659, 25111, 9608, 11, 577, 393, 291, 257, 4059, 72, 51768, 51768], "temperature": 0.0, "avg_logprob": -0.15437286550348456, "compression_ratio": 1.731578947368421, "no_speech_prob": 2.840695196937304e-05}, {"id": 612, "seek": 241044, "start": 2425.16, "end": 2432.12, "text": " of defining what a pretext task is, let's try to see what a pretext task learns.", "tokens": [50364, 407, 9810, 466, 257, 1150, 311, 3163, 295, 6278, 293, 257, 1150, 311, 3163, 295, 960, 13, 50842, 50842, 407, 586, 300, 286, 600, 1333, 295, 4898, 291, 577, 456, 366, 411, 3866, 819, 5880, 2098, 51100, 51100, 295, 17827, 437, 257, 659, 25111, 5633, 307, 11, 718, 311, 853, 281, 536, 437, 257, 659, 25111, 5633, 27152, 13, 51448, 51448, 400, 577, 393, 291, 1333, 295, 11, 498, 286, 976, 291, 3552, 819, 659, 25111, 9608, 11, 577, 393, 291, 257, 4059, 72, 51768, 51768], "temperature": 0.0, "avg_logprob": -0.15437286550348456, "compression_ratio": 1.731578947368421, "no_speech_prob": 2.840695196937304e-05}, {"id": 613, "seek": 241044, "start": 2432.12, "end": 2438.52, "text": " And how can you sort of, if I give you 25 different pretext tasks, how can you a priori", "tokens": [50364, 407, 9810, 466, 257, 1150, 311, 3163, 295, 6278, 293, 257, 1150, 311, 3163, 295, 960, 13, 50842, 50842, 407, 586, 300, 286, 600, 1333, 295, 4898, 291, 577, 456, 366, 411, 3866, 819, 5880, 2098, 51100, 51100, 295, 17827, 437, 257, 659, 25111, 5633, 307, 11, 718, 311, 853, 281, 536, 437, 257, 659, 25111, 5633, 27152, 13, 51448, 51448, 400, 577, 393, 291, 1333, 295, 11, 498, 286, 976, 291, 3552, 819, 659, 25111, 9608, 11, 577, 393, 291, 257, 4059, 72, 51768, 51768], "temperature": 0.0, "avg_logprob": -0.15437286550348456, "compression_ratio": 1.731578947368421, "no_speech_prob": 2.840695196937304e-05}, {"id": 614, "seek": 243852, "start": 2438.52, "end": 2442.08, "text": " decide which one is the one that you want to use and what are they going to sort of", "tokens": [50364, 4536, 597, 472, 307, 264, 472, 300, 291, 528, 281, 764, 293, 437, 366, 436, 516, 281, 1333, 295, 50542, 50542, 1466, 30, 50666, 50666, 407, 264, 700, 551, 307, 659, 25111, 9608, 366, 767, 40705, 13, 50930, 50930, 407, 456, 390, 341, 534, 1481, 3035, 294, 6591, 300, 2956, 412, 732, 295, 613, 1333, 295, 9608, 13, 51236, 51236, 407, 4972, 2535, 390, 264, 700, 659, 25111, 5633, 286, 2825, 466, 11, 689, 291, 747, 732, 26531, 51472, 51472, 293, 291, 853, 281, 6069, 437, 641, 4972, 2535, 365, 3104, 281, 472, 1071, 307, 13, 51688, 51688], "temperature": 0.0, "avg_logprob": -0.11400167465209961, "compression_ratio": 1.7478991596638656, "no_speech_prob": 6.8541394284693524e-06}, {"id": 615, "seek": 243852, "start": 2442.08, "end": 2444.56, "text": " learn?", "tokens": [50364, 4536, 597, 472, 307, 264, 472, 300, 291, 528, 281, 764, 293, 437, 366, 436, 516, 281, 1333, 295, 50542, 50542, 1466, 30, 50666, 50666, 407, 264, 700, 551, 307, 659, 25111, 9608, 366, 767, 40705, 13, 50930, 50930, 407, 456, 390, 341, 534, 1481, 3035, 294, 6591, 300, 2956, 412, 732, 295, 613, 1333, 295, 9608, 13, 51236, 51236, 407, 4972, 2535, 390, 264, 700, 659, 25111, 5633, 286, 2825, 466, 11, 689, 291, 747, 732, 26531, 51472, 51472, 293, 291, 853, 281, 6069, 437, 641, 4972, 2535, 365, 3104, 281, 472, 1071, 307, 13, 51688, 51688], "temperature": 0.0, "avg_logprob": -0.11400167465209961, "compression_ratio": 1.7478991596638656, "no_speech_prob": 6.8541394284693524e-06}, {"id": 616, "seek": 243852, "start": 2444.56, "end": 2449.84, "text": " So the first thing is pretext tasks are actually complementary.", "tokens": [50364, 4536, 597, 472, 307, 264, 472, 300, 291, 528, 281, 764, 293, 437, 366, 436, 516, 281, 1333, 295, 50542, 50542, 1466, 30, 50666, 50666, 407, 264, 700, 551, 307, 659, 25111, 9608, 366, 767, 40705, 13, 50930, 50930, 407, 456, 390, 341, 534, 1481, 3035, 294, 6591, 300, 2956, 412, 732, 295, 613, 1333, 295, 9608, 13, 51236, 51236, 407, 4972, 2535, 390, 264, 700, 659, 25111, 5633, 286, 2825, 466, 11, 689, 291, 747, 732, 26531, 51472, 51472, 293, 291, 853, 281, 6069, 437, 641, 4972, 2535, 365, 3104, 281, 472, 1071, 307, 13, 51688, 51688], "temperature": 0.0, "avg_logprob": -0.11400167465209961, "compression_ratio": 1.7478991596638656, "no_speech_prob": 6.8541394284693524e-06}, {"id": 617, "seek": 243852, "start": 2449.84, "end": 2455.96, "text": " So there was this really nice paper in 2017 that looked at two of these sort of tasks.", "tokens": [50364, 4536, 597, 472, 307, 264, 472, 300, 291, 528, 281, 764, 293, 437, 366, 436, 516, 281, 1333, 295, 50542, 50542, 1466, 30, 50666, 50666, 407, 264, 700, 551, 307, 659, 25111, 9608, 366, 767, 40705, 13, 50930, 50930, 407, 456, 390, 341, 534, 1481, 3035, 294, 6591, 300, 2956, 412, 732, 295, 613, 1333, 295, 9608, 13, 51236, 51236, 407, 4972, 2535, 390, 264, 700, 659, 25111, 5633, 286, 2825, 466, 11, 689, 291, 747, 732, 26531, 51472, 51472, 293, 291, 853, 281, 6069, 437, 641, 4972, 2535, 365, 3104, 281, 472, 1071, 307, 13, 51688, 51688], "temperature": 0.0, "avg_logprob": -0.11400167465209961, "compression_ratio": 1.7478991596638656, "no_speech_prob": 6.8541394284693524e-06}, {"id": 618, "seek": 243852, "start": 2455.96, "end": 2460.68, "text": " So relative position was the first pretext task I talked about, where you take two patches", "tokens": [50364, 4536, 597, 472, 307, 264, 472, 300, 291, 528, 281, 764, 293, 437, 366, 436, 516, 281, 1333, 295, 50542, 50542, 1466, 30, 50666, 50666, 407, 264, 700, 551, 307, 659, 25111, 9608, 366, 767, 40705, 13, 50930, 50930, 407, 456, 390, 341, 534, 1481, 3035, 294, 6591, 300, 2956, 412, 732, 295, 613, 1333, 295, 9608, 13, 51236, 51236, 407, 4972, 2535, 390, 264, 700, 659, 25111, 5633, 286, 2825, 466, 11, 689, 291, 747, 732, 26531, 51472, 51472, 293, 291, 853, 281, 6069, 437, 641, 4972, 2535, 365, 3104, 281, 472, 1071, 307, 13, 51688, 51688], "temperature": 0.0, "avg_logprob": -0.11400167465209961, "compression_ratio": 1.7478991596638656, "no_speech_prob": 6.8541394284693524e-06}, {"id": 619, "seek": 243852, "start": 2460.68, "end": 2465.0, "text": " and you try to predict what their relative position with respect to one another is.", "tokens": [50364, 4536, 597, 472, 307, 264, 472, 300, 291, 528, 281, 764, 293, 437, 366, 436, 516, 281, 1333, 295, 50542, 50542, 1466, 30, 50666, 50666, 407, 264, 700, 551, 307, 659, 25111, 9608, 366, 767, 40705, 13, 50930, 50930, 407, 456, 390, 341, 534, 1481, 3035, 294, 6591, 300, 2956, 412, 732, 295, 613, 1333, 295, 9608, 13, 51236, 51236, 407, 4972, 2535, 390, 264, 700, 659, 25111, 5633, 286, 2825, 466, 11, 689, 291, 747, 732, 26531, 51472, 51472, 293, 291, 853, 281, 6069, 437, 641, 4972, 2535, 365, 3104, 281, 472, 1071, 307, 13, 51688, 51688], "temperature": 0.0, "avg_logprob": -0.11400167465209961, "compression_ratio": 1.7478991596638656, "no_speech_prob": 6.8541394284693524e-06}, {"id": 620, "seek": 246500, "start": 2465.0, "end": 2469.96, "text": " And colorization is basically taking a grayscale image and trying to predict its colors.", "tokens": [50364, 400, 2017, 2144, 307, 1936, 1940, 257, 677, 3772, 37088, 3256, 293, 1382, 281, 6069, 1080, 4577, 13, 50612, 50612, 400, 370, 437, 613, 16552, 4712, 307, 1936, 300, 498, 291, 3847, 257, 2167, 3209, 281, 360, 1293, 50860, 50860, 295, 613, 9608, 11, 281, 6069, 1293, 264, 2017, 1602, 5598, 382, 731, 382, 4972, 2535, 11, 291, 393, 51126, 51126, 767, 483, 16823, 294, 3389, 13, 51236, 51236, 407, 797, 11, 341, 307, 25509, 264, 912, 636, 286, 390, 1417, 466, 3071, 13, 51390, 51390, 509, 362, 257, 659, 12, 17227, 2001, 3209, 11, 293, 550, 291, 434, 1936, 27479, 309, 322, 364, 917, 5633, 13, 51635, 51635], "temperature": 0.0, "avg_logprob": -0.10442421887371992, "compression_ratio": 1.7058823529411764, "no_speech_prob": 2.0579848296620185e-06}, {"id": 621, "seek": 246500, "start": 2469.96, "end": 2474.92, "text": " And so what these authors showed is basically that if you train a single network to do both", "tokens": [50364, 400, 2017, 2144, 307, 1936, 1940, 257, 677, 3772, 37088, 3256, 293, 1382, 281, 6069, 1080, 4577, 13, 50612, 50612, 400, 370, 437, 613, 16552, 4712, 307, 1936, 300, 498, 291, 3847, 257, 2167, 3209, 281, 360, 1293, 50860, 50860, 295, 613, 9608, 11, 281, 6069, 1293, 264, 2017, 1602, 5598, 382, 731, 382, 4972, 2535, 11, 291, 393, 51126, 51126, 767, 483, 16823, 294, 3389, 13, 51236, 51236, 407, 797, 11, 341, 307, 25509, 264, 912, 636, 286, 390, 1417, 466, 3071, 13, 51390, 51390, 509, 362, 257, 659, 12, 17227, 2001, 3209, 11, 293, 550, 291, 434, 1936, 27479, 309, 322, 364, 917, 5633, 13, 51635, 51635], "temperature": 0.0, "avg_logprob": -0.10442421887371992, "compression_ratio": 1.7058823529411764, "no_speech_prob": 2.0579848296620185e-06}, {"id": 622, "seek": 246500, "start": 2474.92, "end": 2480.24, "text": " of these tasks, to predict both the colorized output as well as relative position, you can", "tokens": [50364, 400, 2017, 2144, 307, 1936, 1940, 257, 677, 3772, 37088, 3256, 293, 1382, 281, 6069, 1080, 4577, 13, 50612, 50612, 400, 370, 437, 613, 16552, 4712, 307, 1936, 300, 498, 291, 3847, 257, 2167, 3209, 281, 360, 1293, 50860, 50860, 295, 613, 9608, 11, 281, 6069, 1293, 264, 2017, 1602, 5598, 382, 731, 382, 4972, 2535, 11, 291, 393, 51126, 51126, 767, 483, 16823, 294, 3389, 13, 51236, 51236, 407, 797, 11, 341, 307, 25509, 264, 912, 636, 286, 390, 1417, 466, 3071, 13, 51390, 51390, 509, 362, 257, 659, 12, 17227, 2001, 3209, 11, 293, 550, 291, 434, 1936, 27479, 309, 322, 364, 917, 5633, 13, 51635, 51635], "temperature": 0.0, "avg_logprob": -0.10442421887371992, "compression_ratio": 1.7058823529411764, "no_speech_prob": 2.0579848296620185e-06}, {"id": 623, "seek": 246500, "start": 2480.24, "end": 2482.44, "text": " actually get gains in performance.", "tokens": [50364, 400, 2017, 2144, 307, 1936, 1940, 257, 677, 3772, 37088, 3256, 293, 1382, 281, 6069, 1080, 4577, 13, 50612, 50612, 400, 370, 437, 613, 16552, 4712, 307, 1936, 300, 498, 291, 3847, 257, 2167, 3209, 281, 360, 1293, 50860, 50860, 295, 613, 9608, 11, 281, 6069, 1293, 264, 2017, 1602, 5598, 382, 731, 382, 4972, 2535, 11, 291, 393, 51126, 51126, 767, 483, 16823, 294, 3389, 13, 51236, 51236, 407, 797, 11, 341, 307, 25509, 264, 912, 636, 286, 390, 1417, 466, 3071, 13, 51390, 51390, 509, 362, 257, 659, 12, 17227, 2001, 3209, 11, 293, 550, 291, 434, 1936, 27479, 309, 322, 364, 917, 5633, 13, 51635, 51635], "temperature": 0.0, "avg_logprob": -0.10442421887371992, "compression_ratio": 1.7058823529411764, "no_speech_prob": 2.0579848296620185e-06}, {"id": 624, "seek": 246500, "start": 2482.44, "end": 2485.52, "text": " So again, this is evaluated the same way I was talking about earlier.", "tokens": [50364, 400, 2017, 2144, 307, 1936, 1940, 257, 677, 3772, 37088, 3256, 293, 1382, 281, 6069, 1080, 4577, 13, 50612, 50612, 400, 370, 437, 613, 16552, 4712, 307, 1936, 300, 498, 291, 3847, 257, 2167, 3209, 281, 360, 1293, 50860, 50860, 295, 613, 9608, 11, 281, 6069, 1293, 264, 2017, 1602, 5598, 382, 731, 382, 4972, 2535, 11, 291, 393, 51126, 51126, 767, 483, 16823, 294, 3389, 13, 51236, 51236, 407, 797, 11, 341, 307, 25509, 264, 912, 636, 286, 390, 1417, 466, 3071, 13, 51390, 51390, 509, 362, 257, 659, 12, 17227, 2001, 3209, 11, 293, 550, 291, 434, 1936, 27479, 309, 322, 364, 917, 5633, 13, 51635, 51635], "temperature": 0.0, "avg_logprob": -0.10442421887371992, "compression_ratio": 1.7058823529411764, "no_speech_prob": 2.0579848296620185e-06}, {"id": 625, "seek": 246500, "start": 2485.52, "end": 2490.42, "text": " You have a pre-trained network, and then you're basically evaluating it on an end task.", "tokens": [50364, 400, 2017, 2144, 307, 1936, 1940, 257, 677, 3772, 37088, 3256, 293, 1382, 281, 6069, 1080, 4577, 13, 50612, 50612, 400, 370, 437, 613, 16552, 4712, 307, 1936, 300, 498, 291, 3847, 257, 2167, 3209, 281, 360, 1293, 50860, 50860, 295, 613, 9608, 11, 281, 6069, 1293, 264, 2017, 1602, 5598, 382, 731, 382, 4972, 2535, 11, 291, 393, 51126, 51126, 767, 483, 16823, 294, 3389, 13, 51236, 51236, 407, 797, 11, 341, 307, 25509, 264, 912, 636, 286, 390, 1417, 466, 3071, 13, 51390, 51390, 509, 362, 257, 659, 12, 17227, 2001, 3209, 11, 293, 550, 291, 434, 1936, 27479, 309, 322, 364, 917, 5633, 13, 51635, 51635], "temperature": 0.0, "avg_logprob": -0.10442421887371992, "compression_ratio": 1.7058823529411764, "no_speech_prob": 2.0579848296620185e-06}, {"id": 626, "seek": 249042, "start": 2490.42, "end": 2495.4, "text": " In this case, image net classification and detection benchmark.", "tokens": [50364, 682, 341, 1389, 11, 3256, 2533, 21538, 293, 17784, 18927, 13, 50613, 50613, 400, 294, 1293, 3331, 11, 291, 1333, 295, 393, 483, 16823, 538, 10205, 1293, 295, 613, 9608, 13, 50851, 50851, 407, 291, 483, 1151, 295, 1293, 13401, 13, 50969, 50969, 407, 294, 512, 636, 11, 437, 341, 611, 3110, 291, 307, 300, 257, 2167, 659, 25111, 5633, 815, 406, 312, 264, 51191, 51191, 558, 1867, 13, 51241, 51241, 407, 32884, 445, 2017, 420, 32884, 445, 4972, 2535, 815, 406, 312, 264, 558, 1867, 51459, 51459, 281, 1466, 2698, 12, 48172, 24420, 33358, 13, 51699, 51699], "temperature": 0.0, "avg_logprob": -0.11520784378051757, "compression_ratio": 1.7245762711864407, "no_speech_prob": 2.190731493101339e-06}, {"id": 627, "seek": 249042, "start": 2495.4, "end": 2500.16, "text": " And in both cases, you sort of can get gains by performing both of these tasks.", "tokens": [50364, 682, 341, 1389, 11, 3256, 2533, 21538, 293, 17784, 18927, 13, 50613, 50613, 400, 294, 1293, 3331, 11, 291, 1333, 295, 393, 483, 16823, 538, 10205, 1293, 295, 613, 9608, 13, 50851, 50851, 407, 291, 483, 1151, 295, 1293, 13401, 13, 50969, 50969, 407, 294, 512, 636, 11, 437, 341, 611, 3110, 291, 307, 300, 257, 2167, 659, 25111, 5633, 815, 406, 312, 264, 51191, 51191, 558, 1867, 13, 51241, 51241, 407, 32884, 445, 2017, 420, 32884, 445, 4972, 2535, 815, 406, 312, 264, 558, 1867, 51459, 51459, 281, 1466, 2698, 12, 48172, 24420, 33358, 13, 51699, 51699], "temperature": 0.0, "avg_logprob": -0.11520784378051757, "compression_ratio": 1.7245762711864407, "no_speech_prob": 2.190731493101339e-06}, {"id": 628, "seek": 249042, "start": 2500.16, "end": 2502.52, "text": " So you get best of both worlds.", "tokens": [50364, 682, 341, 1389, 11, 3256, 2533, 21538, 293, 17784, 18927, 13, 50613, 50613, 400, 294, 1293, 3331, 11, 291, 1333, 295, 393, 483, 16823, 538, 10205, 1293, 295, 613, 9608, 13, 50851, 50851, 407, 291, 483, 1151, 295, 1293, 13401, 13, 50969, 50969, 407, 294, 512, 636, 11, 437, 341, 611, 3110, 291, 307, 300, 257, 2167, 659, 25111, 5633, 815, 406, 312, 264, 51191, 51191, 558, 1867, 13, 51241, 51241, 407, 32884, 445, 2017, 420, 32884, 445, 4972, 2535, 815, 406, 312, 264, 558, 1867, 51459, 51459, 281, 1466, 2698, 12, 48172, 24420, 33358, 13, 51699, 51699], "temperature": 0.0, "avg_logprob": -0.11520784378051757, "compression_ratio": 1.7245762711864407, "no_speech_prob": 2.190731493101339e-06}, {"id": 629, "seek": 249042, "start": 2502.52, "end": 2506.96, "text": " So in some way, what this also shows you is that a single pretext task may not be the", "tokens": [50364, 682, 341, 1389, 11, 3256, 2533, 21538, 293, 17784, 18927, 13, 50613, 50613, 400, 294, 1293, 3331, 11, 291, 1333, 295, 393, 483, 16823, 538, 10205, 1293, 295, 613, 9608, 13, 50851, 50851, 407, 291, 483, 1151, 295, 1293, 13401, 13, 50969, 50969, 407, 294, 512, 636, 11, 437, 341, 611, 3110, 291, 307, 300, 257, 2167, 659, 25111, 5633, 815, 406, 312, 264, 51191, 51191, 558, 1867, 13, 51241, 51241, 407, 32884, 445, 2017, 420, 32884, 445, 4972, 2535, 815, 406, 312, 264, 558, 1867, 51459, 51459, 281, 1466, 2698, 12, 48172, 24420, 33358, 13, 51699, 51699], "temperature": 0.0, "avg_logprob": -0.11520784378051757, "compression_ratio": 1.7245762711864407, "no_speech_prob": 2.190731493101339e-06}, {"id": 630, "seek": 249042, "start": 2506.96, "end": 2507.96, "text": " right answer.", "tokens": [50364, 682, 341, 1389, 11, 3256, 2533, 21538, 293, 17784, 18927, 13, 50613, 50613, 400, 294, 1293, 3331, 11, 291, 1333, 295, 393, 483, 16823, 538, 10205, 1293, 295, 613, 9608, 13, 50851, 50851, 407, 291, 483, 1151, 295, 1293, 13401, 13, 50969, 50969, 407, 294, 512, 636, 11, 437, 341, 611, 3110, 291, 307, 300, 257, 2167, 659, 25111, 5633, 815, 406, 312, 264, 51191, 51191, 558, 1867, 13, 51241, 51241, 407, 32884, 445, 2017, 420, 32884, 445, 4972, 2535, 815, 406, 312, 264, 558, 1867, 51459, 51459, 281, 1466, 2698, 12, 48172, 24420, 33358, 13, 51699, 51699], "temperature": 0.0, "avg_logprob": -0.11520784378051757, "compression_ratio": 1.7245762711864407, "no_speech_prob": 2.190731493101339e-06}, {"id": 631, "seek": 249042, "start": 2507.96, "end": 2512.32, "text": " So predicting just color or predicting just relative position may not be the right answer", "tokens": [50364, 682, 341, 1389, 11, 3256, 2533, 21538, 293, 17784, 18927, 13, 50613, 50613, 400, 294, 1293, 3331, 11, 291, 1333, 295, 393, 483, 16823, 538, 10205, 1293, 295, 613, 9608, 13, 50851, 50851, 407, 291, 483, 1151, 295, 1293, 13401, 13, 50969, 50969, 407, 294, 512, 636, 11, 437, 341, 611, 3110, 291, 307, 300, 257, 2167, 659, 25111, 5633, 815, 406, 312, 264, 51191, 51191, 558, 1867, 13, 51241, 51241, 407, 32884, 445, 2017, 420, 32884, 445, 4972, 2535, 815, 406, 312, 264, 558, 1867, 51459, 51459, 281, 1466, 2698, 12, 48172, 24420, 33358, 13, 51699, 51699], "temperature": 0.0, "avg_logprob": -0.11520784378051757, "compression_ratio": 1.7245762711864407, "no_speech_prob": 2.190731493101339e-06}, {"id": 632, "seek": 249042, "start": 2512.32, "end": 2517.12, "text": " to learn self-supervised representations.", "tokens": [50364, 682, 341, 1389, 11, 3256, 2533, 21538, 293, 17784, 18927, 13, 50613, 50613, 400, 294, 1293, 3331, 11, 291, 1333, 295, 393, 483, 16823, 538, 10205, 1293, 295, 613, 9608, 13, 50851, 50851, 407, 291, 483, 1151, 295, 1293, 13401, 13, 50969, 50969, 407, 294, 512, 636, 11, 437, 341, 611, 3110, 291, 307, 300, 257, 2167, 659, 25111, 5633, 815, 406, 312, 264, 51191, 51191, 558, 1867, 13, 51241, 51241, 407, 32884, 445, 2017, 420, 32884, 445, 4972, 2535, 815, 406, 312, 264, 558, 1867, 51459, 51459, 281, 1466, 2698, 12, 48172, 24420, 33358, 13, 51699, 51699], "temperature": 0.0, "avg_logprob": -0.11520784378051757, "compression_ratio": 1.7245762711864407, "no_speech_prob": 2.190731493101339e-06}, {"id": 633, "seek": 251712, "start": 2517.12, "end": 2521.52, "text": " In fact, if you sort of reason about what information is being predicted, it really", "tokens": [50364, 682, 1186, 11, 498, 291, 1333, 295, 1778, 466, 437, 1589, 307, 885, 19147, 11, 309, 534, 50584, 50584, 21716, 257, 688, 2108, 9608, 13, 50702, 50702, 407, 2891, 365, 264, 4972, 2535, 5633, 11, 291, 434, 32884, 257, 6457, 2295, 1496, 1589, 13, 50964, 50964, 509, 434, 32884, 445, 1333, 295, 3180, 1944, 9253, 13, 51144, 51144, 407, 445, 364, 3180, 12, 676, 21538, 1154, 13, 51262, 51262, 1610, 337, 300, 39426, 293, 1466, 1154, 11, 291, 434, 32884, 1968, 721, 366, 402, 33974, 420, 51434, 51434, 406, 13, 51484, 51484, 407, 309, 311, 445, 257, 2199, 17434, 1154, 13, 51534, 51534, 407, 309, 311, 588, 1333, 295, 1570, 2372, 295, 1589, 300, 311, 885, 19147, 13, 51706, 51706], "temperature": 0.0, "avg_logprob": -0.14198311039658842, "compression_ratio": 1.9101123595505618, "no_speech_prob": 3.844854290946387e-06}, {"id": 634, "seek": 251712, "start": 2521.52, "end": 2523.88, "text": " varies a lot across tasks.", "tokens": [50364, 682, 1186, 11, 498, 291, 1333, 295, 1778, 466, 437, 1589, 307, 885, 19147, 11, 309, 534, 50584, 50584, 21716, 257, 688, 2108, 9608, 13, 50702, 50702, 407, 2891, 365, 264, 4972, 2535, 5633, 11, 291, 434, 32884, 257, 6457, 2295, 1496, 1589, 13, 50964, 50964, 509, 434, 32884, 445, 1333, 295, 3180, 1944, 9253, 13, 51144, 51144, 407, 445, 364, 3180, 12, 676, 21538, 1154, 13, 51262, 51262, 1610, 337, 300, 39426, 293, 1466, 1154, 11, 291, 434, 32884, 1968, 721, 366, 402, 33974, 420, 51434, 51434, 406, 13, 51484, 51484, 407, 309, 311, 445, 257, 2199, 17434, 1154, 13, 51534, 51534, 407, 309, 311, 588, 1333, 295, 1570, 2372, 295, 1589, 300, 311, 885, 19147, 13, 51706, 51706], "temperature": 0.0, "avg_logprob": -0.14198311039658842, "compression_ratio": 1.9101123595505618, "no_speech_prob": 3.844854290946387e-06}, {"id": 635, "seek": 251712, "start": 2523.88, "end": 2529.12, "text": " So starting with the relative position task, you're predicting a fairly low level information.", "tokens": [50364, 682, 1186, 11, 498, 291, 1333, 295, 1778, 466, 437, 1589, 307, 885, 19147, 11, 309, 534, 50584, 50584, 21716, 257, 688, 2108, 9608, 13, 50702, 50702, 407, 2891, 365, 264, 4972, 2535, 5633, 11, 291, 434, 32884, 257, 6457, 2295, 1496, 1589, 13, 50964, 50964, 509, 434, 32884, 445, 1333, 295, 3180, 1944, 9253, 13, 51144, 51144, 407, 445, 364, 3180, 12, 676, 21538, 1154, 13, 51262, 51262, 1610, 337, 300, 39426, 293, 1466, 1154, 11, 291, 434, 32884, 1968, 721, 366, 402, 33974, 420, 51434, 51434, 406, 13, 51484, 51484, 407, 309, 311, 445, 257, 2199, 17434, 1154, 13, 51534, 51534, 407, 309, 311, 588, 1333, 295, 1570, 2372, 295, 1589, 300, 311, 885, 19147, 13, 51706, 51706], "temperature": 0.0, "avg_logprob": -0.14198311039658842, "compression_ratio": 1.9101123595505618, "no_speech_prob": 3.844854290946387e-06}, {"id": 636, "seek": 251712, "start": 2529.12, "end": 2532.72, "text": " You're predicting just sort of eight possible locations.", "tokens": [50364, 682, 1186, 11, 498, 291, 1333, 295, 1778, 466, 437, 1589, 307, 885, 19147, 11, 309, 534, 50584, 50584, 21716, 257, 688, 2108, 9608, 13, 50702, 50702, 407, 2891, 365, 264, 4972, 2535, 5633, 11, 291, 434, 32884, 257, 6457, 2295, 1496, 1589, 13, 50964, 50964, 509, 434, 32884, 445, 1333, 295, 3180, 1944, 9253, 13, 51144, 51144, 407, 445, 364, 3180, 12, 676, 21538, 1154, 13, 51262, 51262, 1610, 337, 300, 39426, 293, 1466, 1154, 11, 291, 434, 32884, 1968, 721, 366, 402, 33974, 420, 51434, 51434, 406, 13, 51484, 51484, 407, 309, 311, 445, 257, 2199, 17434, 1154, 13, 51534, 51534, 407, 309, 311, 588, 1333, 295, 1570, 2372, 295, 1589, 300, 311, 885, 19147, 13, 51706, 51706], "temperature": 0.0, "avg_logprob": -0.14198311039658842, "compression_ratio": 1.9101123595505618, "no_speech_prob": 3.844854290946387e-06}, {"id": 637, "seek": 251712, "start": 2532.72, "end": 2535.08, "text": " So just an eight-way classification problem.", "tokens": [50364, 682, 1186, 11, 498, 291, 1333, 295, 1778, 466, 437, 1589, 307, 885, 19147, 11, 309, 534, 50584, 50584, 21716, 257, 688, 2108, 9608, 13, 50702, 50702, 407, 2891, 365, 264, 4972, 2535, 5633, 11, 291, 434, 32884, 257, 6457, 2295, 1496, 1589, 13, 50964, 50964, 509, 434, 32884, 445, 1333, 295, 3180, 1944, 9253, 13, 51144, 51144, 407, 445, 364, 3180, 12, 676, 21538, 1154, 13, 51262, 51262, 1610, 337, 300, 39426, 293, 1466, 1154, 11, 291, 434, 32884, 1968, 721, 366, 402, 33974, 420, 51434, 51434, 406, 13, 51484, 51484, 407, 309, 311, 445, 257, 2199, 17434, 1154, 13, 51534, 51534, 407, 309, 311, 588, 1333, 295, 1570, 2372, 295, 1589, 300, 311, 885, 19147, 13, 51706, 51706], "temperature": 0.0, "avg_logprob": -0.14198311039658842, "compression_ratio": 1.9101123595505618, "no_speech_prob": 3.844854290946387e-06}, {"id": 638, "seek": 251712, "start": 2535.08, "end": 2538.52, "text": " Or for that shuffle and learn problem, you're predicting whether things are shuffled or", "tokens": [50364, 682, 1186, 11, 498, 291, 1333, 295, 1778, 466, 437, 1589, 307, 885, 19147, 11, 309, 534, 50584, 50584, 21716, 257, 688, 2108, 9608, 13, 50702, 50702, 407, 2891, 365, 264, 4972, 2535, 5633, 11, 291, 434, 32884, 257, 6457, 2295, 1496, 1589, 13, 50964, 50964, 509, 434, 32884, 445, 1333, 295, 3180, 1944, 9253, 13, 51144, 51144, 407, 445, 364, 3180, 12, 676, 21538, 1154, 13, 51262, 51262, 1610, 337, 300, 39426, 293, 1466, 1154, 11, 291, 434, 32884, 1968, 721, 366, 402, 33974, 420, 51434, 51434, 406, 13, 51484, 51484, 407, 309, 311, 445, 257, 2199, 17434, 1154, 13, 51534, 51534, 407, 309, 311, 588, 1333, 295, 1570, 2372, 295, 1589, 300, 311, 885, 19147, 13, 51706, 51706], "temperature": 0.0, "avg_logprob": -0.14198311039658842, "compression_ratio": 1.9101123595505618, "no_speech_prob": 3.844854290946387e-06}, {"id": 639, "seek": 251712, "start": 2538.52, "end": 2539.52, "text": " not.", "tokens": [50364, 682, 1186, 11, 498, 291, 1333, 295, 1778, 466, 437, 1589, 307, 885, 19147, 11, 309, 534, 50584, 50584, 21716, 257, 688, 2108, 9608, 13, 50702, 50702, 407, 2891, 365, 264, 4972, 2535, 5633, 11, 291, 434, 32884, 257, 6457, 2295, 1496, 1589, 13, 50964, 50964, 509, 434, 32884, 445, 1333, 295, 3180, 1944, 9253, 13, 51144, 51144, 407, 445, 364, 3180, 12, 676, 21538, 1154, 13, 51262, 51262, 1610, 337, 300, 39426, 293, 1466, 1154, 11, 291, 434, 32884, 1968, 721, 366, 402, 33974, 420, 51434, 51434, 406, 13, 51484, 51484, 407, 309, 311, 445, 257, 2199, 17434, 1154, 13, 51534, 51534, 407, 309, 311, 588, 1333, 295, 1570, 2372, 295, 1589, 300, 311, 885, 19147, 13, 51706, 51706], "temperature": 0.0, "avg_logprob": -0.14198311039658842, "compression_ratio": 1.9101123595505618, "no_speech_prob": 3.844854290946387e-06}, {"id": 640, "seek": 251712, "start": 2539.52, "end": 2540.52, "text": " So it's just a simple binary problem.", "tokens": [50364, 682, 1186, 11, 498, 291, 1333, 295, 1778, 466, 437, 1589, 307, 885, 19147, 11, 309, 534, 50584, 50584, 21716, 257, 688, 2108, 9608, 13, 50702, 50702, 407, 2891, 365, 264, 4972, 2535, 5633, 11, 291, 434, 32884, 257, 6457, 2295, 1496, 1589, 13, 50964, 50964, 509, 434, 32884, 445, 1333, 295, 3180, 1944, 9253, 13, 51144, 51144, 407, 445, 364, 3180, 12, 676, 21538, 1154, 13, 51262, 51262, 1610, 337, 300, 39426, 293, 1466, 1154, 11, 291, 434, 32884, 1968, 721, 366, 402, 33974, 420, 51434, 51434, 406, 13, 51484, 51484, 407, 309, 311, 445, 257, 2199, 17434, 1154, 13, 51534, 51534, 407, 309, 311, 588, 1333, 295, 1570, 2372, 295, 1589, 300, 311, 885, 19147, 13, 51706, 51706], "temperature": 0.0, "avg_logprob": -0.14198311039658842, "compression_ratio": 1.9101123595505618, "no_speech_prob": 3.844854290946387e-06}, {"id": 641, "seek": 251712, "start": 2540.52, "end": 2543.96, "text": " So it's very sort of less amount of information that's being predicted.", "tokens": [50364, 682, 1186, 11, 498, 291, 1333, 295, 1778, 466, 437, 1589, 307, 885, 19147, 11, 309, 534, 50584, 50584, 21716, 257, 688, 2108, 9608, 13, 50702, 50702, 407, 2891, 365, 264, 4972, 2535, 5633, 11, 291, 434, 32884, 257, 6457, 2295, 1496, 1589, 13, 50964, 50964, 509, 434, 32884, 445, 1333, 295, 3180, 1944, 9253, 13, 51144, 51144, 407, 445, 364, 3180, 12, 676, 21538, 1154, 13, 51262, 51262, 1610, 337, 300, 39426, 293, 1466, 1154, 11, 291, 434, 32884, 1968, 721, 366, 402, 33974, 420, 51434, 51434, 406, 13, 51484, 51484, 407, 309, 311, 445, 257, 2199, 17434, 1154, 13, 51534, 51534, 407, 309, 311, 588, 1333, 295, 1570, 2372, 295, 1589, 300, 311, 885, 19147, 13, 51706, 51706], "temperature": 0.0, "avg_logprob": -0.14198311039658842, "compression_ratio": 1.9101123595505618, "no_speech_prob": 3.844854290946387e-06}, {"id": 642, "seek": 254396, "start": 2543.96, "end": 2548.96, "text": " Whereas if you look at on the extreme right, if you are trying to predict what is missing", "tokens": [50364, 13813, 498, 291, 574, 412, 322, 264, 8084, 558, 11, 498, 291, 366, 1382, 281, 6069, 437, 307, 5361, 50614, 50614, 294, 364, 3256, 293, 291, 434, 1382, 281, 31499, 264, 18668, 11, 291, 434, 32884, 257, 688, 295, 1589, 50852, 50852, 570, 300, 2302, 2424, 8306, 11, 286, 914, 11, 309, 393, 362, 257, 588, 11, 291, 393, 362, 588, 819, 51101, 51101, 8967, 1901, 13, 51151, 51151, 407, 498, 291, 362, 297, 18668, 11, 550, 291, 393, 1936, 362, 257, 688, 295, 819, 4190, 337, 300, 2302, 51418, 51418, 35521, 4458, 13, 51468, 51468, 407, 291, 434, 32884, 257, 688, 295, 1589, 456, 13, 51594, 51594, 407, 4476, 11, 341, 307, 472, 2199, 636, 295, 1953, 466, 659, 25111, 9608, 13, 51772, 51772], "temperature": 0.0, "avg_logprob": -0.11931481699305256, "compression_ratio": 1.934065934065934, "no_speech_prob": 3.785230092034908e-06}, {"id": 643, "seek": 254396, "start": 2548.96, "end": 2553.7200000000003, "text": " in an image and you're trying to reconstruct the pixels, you're predicting a lot of information", "tokens": [50364, 13813, 498, 291, 574, 412, 322, 264, 8084, 558, 11, 498, 291, 366, 1382, 281, 6069, 437, 307, 5361, 50614, 50614, 294, 364, 3256, 293, 291, 434, 1382, 281, 31499, 264, 18668, 11, 291, 434, 32884, 257, 688, 295, 1589, 50852, 50852, 570, 300, 2302, 2424, 8306, 11, 286, 914, 11, 309, 393, 362, 257, 588, 11, 291, 393, 362, 588, 819, 51101, 51101, 8967, 1901, 13, 51151, 51151, 407, 498, 291, 362, 297, 18668, 11, 550, 291, 393, 1936, 362, 257, 688, 295, 819, 4190, 337, 300, 2302, 51418, 51418, 35521, 4458, 13, 51468, 51468, 407, 291, 434, 32884, 257, 688, 295, 1589, 456, 13, 51594, 51594, 407, 4476, 11, 341, 307, 472, 2199, 636, 295, 1953, 466, 659, 25111, 9608, 13, 51772, 51772], "temperature": 0.0, "avg_logprob": -0.11931481699305256, "compression_ratio": 1.934065934065934, "no_speech_prob": 3.785230092034908e-06}, {"id": 644, "seek": 254396, "start": 2553.7200000000003, "end": 2558.7, "text": " because that entire box contains, I mean, it can have a very, you can have very different", "tokens": [50364, 13813, 498, 291, 574, 412, 322, 264, 8084, 558, 11, 498, 291, 366, 1382, 281, 6069, 437, 307, 5361, 50614, 50614, 294, 364, 3256, 293, 291, 434, 1382, 281, 31499, 264, 18668, 11, 291, 434, 32884, 257, 688, 295, 1589, 50852, 50852, 570, 300, 2302, 2424, 8306, 11, 286, 914, 11, 309, 393, 362, 257, 588, 11, 291, 393, 362, 588, 819, 51101, 51101, 8967, 1901, 13, 51151, 51151, 407, 498, 291, 362, 297, 18668, 11, 550, 291, 393, 1936, 362, 257, 688, 295, 819, 4190, 337, 300, 2302, 51418, 51418, 35521, 4458, 13, 51468, 51468, 407, 291, 434, 32884, 257, 688, 295, 1589, 456, 13, 51594, 51594, 407, 4476, 11, 341, 307, 472, 2199, 636, 295, 1953, 466, 659, 25111, 9608, 13, 51772, 51772], "temperature": 0.0, "avg_logprob": -0.11931481699305256, "compression_ratio": 1.934065934065934, "no_speech_prob": 3.785230092034908e-06}, {"id": 645, "seek": 254396, "start": 2558.7, "end": 2559.7, "text": " appearance space.", "tokens": [50364, 13813, 498, 291, 574, 412, 322, 264, 8084, 558, 11, 498, 291, 366, 1382, 281, 6069, 437, 307, 5361, 50614, 50614, 294, 364, 3256, 293, 291, 434, 1382, 281, 31499, 264, 18668, 11, 291, 434, 32884, 257, 688, 295, 1589, 50852, 50852, 570, 300, 2302, 2424, 8306, 11, 286, 914, 11, 309, 393, 362, 257, 588, 11, 291, 393, 362, 588, 819, 51101, 51101, 8967, 1901, 13, 51151, 51151, 407, 498, 291, 362, 297, 18668, 11, 550, 291, 393, 1936, 362, 257, 688, 295, 819, 4190, 337, 300, 2302, 51418, 51418, 35521, 4458, 13, 51468, 51468, 407, 291, 434, 32884, 257, 688, 295, 1589, 456, 13, 51594, 51594, 407, 4476, 11, 341, 307, 472, 2199, 636, 295, 1953, 466, 659, 25111, 9608, 13, 51772, 51772], "temperature": 0.0, "avg_logprob": -0.11931481699305256, "compression_ratio": 1.934065934065934, "no_speech_prob": 3.785230092034908e-06}, {"id": 646, "seek": 254396, "start": 2559.7, "end": 2565.04, "text": " So if you have n pixels, then you can basically have a lot of different values for that entire", "tokens": [50364, 13813, 498, 291, 574, 412, 322, 264, 8084, 558, 11, 498, 291, 366, 1382, 281, 6069, 437, 307, 5361, 50614, 50614, 294, 364, 3256, 293, 291, 434, 1382, 281, 31499, 264, 18668, 11, 291, 434, 32884, 257, 688, 295, 1589, 50852, 50852, 570, 300, 2302, 2424, 8306, 11, 286, 914, 11, 309, 393, 362, 257, 588, 11, 291, 393, 362, 588, 819, 51101, 51101, 8967, 1901, 13, 51151, 51151, 407, 498, 291, 362, 297, 18668, 11, 550, 291, 393, 1936, 362, 257, 688, 295, 819, 4190, 337, 300, 2302, 51418, 51418, 35521, 4458, 13, 51468, 51468, 407, 291, 434, 32884, 257, 688, 295, 1589, 456, 13, 51594, 51594, 407, 4476, 11, 341, 307, 472, 2199, 636, 295, 1953, 466, 659, 25111, 9608, 13, 51772, 51772], "temperature": 0.0, "avg_logprob": -0.11931481699305256, "compression_ratio": 1.934065934065934, "no_speech_prob": 3.785230092034908e-06}, {"id": 647, "seek": 254396, "start": 2565.04, "end": 2566.04, "text": " predictive region.", "tokens": [50364, 13813, 498, 291, 574, 412, 322, 264, 8084, 558, 11, 498, 291, 366, 1382, 281, 6069, 437, 307, 5361, 50614, 50614, 294, 364, 3256, 293, 291, 434, 1382, 281, 31499, 264, 18668, 11, 291, 434, 32884, 257, 688, 295, 1589, 50852, 50852, 570, 300, 2302, 2424, 8306, 11, 286, 914, 11, 309, 393, 362, 257, 588, 11, 291, 393, 362, 588, 819, 51101, 51101, 8967, 1901, 13, 51151, 51151, 407, 498, 291, 362, 297, 18668, 11, 550, 291, 393, 1936, 362, 257, 688, 295, 819, 4190, 337, 300, 2302, 51418, 51418, 35521, 4458, 13, 51468, 51468, 407, 291, 434, 32884, 257, 688, 295, 1589, 456, 13, 51594, 51594, 407, 4476, 11, 341, 307, 472, 2199, 636, 295, 1953, 466, 659, 25111, 9608, 13, 51772, 51772], "temperature": 0.0, "avg_logprob": -0.11931481699305256, "compression_ratio": 1.934065934065934, "no_speech_prob": 3.785230092034908e-06}, {"id": 648, "seek": 254396, "start": 2566.04, "end": 2568.56, "text": " So you're predicting a lot of information there.", "tokens": [50364, 13813, 498, 291, 574, 412, 322, 264, 8084, 558, 11, 498, 291, 366, 1382, 281, 6069, 437, 307, 5361, 50614, 50614, 294, 364, 3256, 293, 291, 434, 1382, 281, 31499, 264, 18668, 11, 291, 434, 32884, 257, 688, 295, 1589, 50852, 50852, 570, 300, 2302, 2424, 8306, 11, 286, 914, 11, 309, 393, 362, 257, 588, 11, 291, 393, 362, 588, 819, 51101, 51101, 8967, 1901, 13, 51151, 51151, 407, 498, 291, 362, 297, 18668, 11, 550, 291, 393, 1936, 362, 257, 688, 295, 819, 4190, 337, 300, 2302, 51418, 51418, 35521, 4458, 13, 51468, 51468, 407, 291, 434, 32884, 257, 688, 295, 1589, 456, 13, 51594, 51594, 407, 4476, 11, 341, 307, 472, 2199, 636, 295, 1953, 466, 659, 25111, 9608, 13, 51772, 51772], "temperature": 0.0, "avg_logprob": -0.11931481699305256, "compression_ratio": 1.934065934065934, "no_speech_prob": 3.785230092034908e-06}, {"id": 649, "seek": 254396, "start": 2568.56, "end": 2572.12, "text": " So essentially, this is one simple way of thinking about pretext tasks.", "tokens": [50364, 13813, 498, 291, 574, 412, 322, 264, 8084, 558, 11, 498, 291, 366, 1382, 281, 6069, 437, 307, 5361, 50614, 50614, 294, 364, 3256, 293, 291, 434, 1382, 281, 31499, 264, 18668, 11, 291, 434, 32884, 257, 688, 295, 1589, 50852, 50852, 570, 300, 2302, 2424, 8306, 11, 286, 914, 11, 309, 393, 362, 257, 588, 11, 291, 393, 362, 588, 819, 51101, 51101, 8967, 1901, 13, 51151, 51151, 407, 498, 291, 362, 297, 18668, 11, 550, 291, 393, 1936, 362, 257, 688, 295, 819, 4190, 337, 300, 2302, 51418, 51418, 35521, 4458, 13, 51468, 51468, 407, 291, 434, 32884, 257, 688, 295, 1589, 456, 13, 51594, 51594, 407, 4476, 11, 341, 307, 472, 2199, 636, 295, 1953, 466, 659, 25111, 9608, 13, 51772, 51772], "temperature": 0.0, "avg_logprob": -0.11931481699305256, "compression_ratio": 1.934065934065934, "no_speech_prob": 3.785230092034908e-06}, {"id": 650, "seek": 257212, "start": 2572.12, "end": 2574.44, "text": " How much information are you predicting?", "tokens": [50364, 1012, 709, 1589, 366, 291, 32884, 30, 50480, 50480, 400, 300, 393, 976, 291, 1217, 257, 665, 1558, 295, 1968, 291, 434, 767, 32884, 257, 688, 50766, 50766, 295, 1589, 13, 50816, 50816, 407, 1391, 300, 10290, 307, 767, 516, 281, 312, 1101, 13, 51084, 51084, 407, 294, 2674, 11, 341, 307, 1333, 295, 516, 281, 5934, 264, 958, 644, 295, 452, 751, 13, 51352, 51352, 509, 393, 519, 295, 341, 1333, 295, 32884, 544, 1589, 644, 322, 364, 10298, 13, 51582, 51582, 400, 286, 603, 751, 466, 1045, 819, 1333, 295, 10479, 294, 341, 13, 51722, 51722, 5135, 11, 732, 819, 10479, 13, 51832, 51832], "temperature": 0.0, "avg_logprob": -0.10736310923541034, "compression_ratio": 1.8489795918367347, "no_speech_prob": 1.3419607967080083e-05}, {"id": 651, "seek": 257212, "start": 2574.44, "end": 2580.16, "text": " And that can give you already a good idea of whether you're actually predicting a lot", "tokens": [50364, 1012, 709, 1589, 366, 291, 32884, 30, 50480, 50480, 400, 300, 393, 976, 291, 1217, 257, 665, 1558, 295, 1968, 291, 434, 767, 32884, 257, 688, 50766, 50766, 295, 1589, 13, 50816, 50816, 407, 1391, 300, 10290, 307, 767, 516, 281, 312, 1101, 13, 51084, 51084, 407, 294, 2674, 11, 341, 307, 1333, 295, 516, 281, 5934, 264, 958, 644, 295, 452, 751, 13, 51352, 51352, 509, 393, 519, 295, 341, 1333, 295, 32884, 544, 1589, 644, 322, 364, 10298, 13, 51582, 51582, 400, 286, 603, 751, 466, 1045, 819, 1333, 295, 10479, 294, 341, 13, 51722, 51722, 5135, 11, 732, 819, 10479, 13, 51832, 51832], "temperature": 0.0, "avg_logprob": -0.10736310923541034, "compression_ratio": 1.8489795918367347, "no_speech_prob": 1.3419607967080083e-05}, {"id": 652, "seek": 257212, "start": 2580.16, "end": 2581.16, "text": " of information.", "tokens": [50364, 1012, 709, 1589, 366, 291, 32884, 30, 50480, 50480, 400, 300, 393, 976, 291, 1217, 257, 665, 1558, 295, 1968, 291, 434, 767, 32884, 257, 688, 50766, 50766, 295, 1589, 13, 50816, 50816, 407, 1391, 300, 10290, 307, 767, 516, 281, 312, 1101, 13, 51084, 51084, 407, 294, 2674, 11, 341, 307, 1333, 295, 516, 281, 5934, 264, 958, 644, 295, 452, 751, 13, 51352, 51352, 509, 393, 519, 295, 341, 1333, 295, 32884, 544, 1589, 644, 322, 364, 10298, 13, 51582, 51582, 400, 286, 603, 751, 466, 1045, 819, 1333, 295, 10479, 294, 341, 13, 51722, 51722, 5135, 11, 732, 819, 10479, 13, 51832, 51832], "temperature": 0.0, "avg_logprob": -0.10736310923541034, "compression_ratio": 1.8489795918367347, "no_speech_prob": 1.3419607967080083e-05}, {"id": 653, "seek": 257212, "start": 2581.16, "end": 2586.52, "text": " So probably that representation is actually going to be better.", "tokens": [50364, 1012, 709, 1589, 366, 291, 32884, 30, 50480, 50480, 400, 300, 393, 976, 291, 1217, 257, 665, 1558, 295, 1968, 291, 434, 767, 32884, 257, 688, 50766, 50766, 295, 1589, 13, 50816, 50816, 407, 1391, 300, 10290, 307, 767, 516, 281, 312, 1101, 13, 51084, 51084, 407, 294, 2674, 11, 341, 307, 1333, 295, 516, 281, 5934, 264, 958, 644, 295, 452, 751, 13, 51352, 51352, 509, 393, 519, 295, 341, 1333, 295, 32884, 544, 1589, 644, 322, 364, 10298, 13, 51582, 51582, 400, 286, 603, 751, 466, 1045, 819, 1333, 295, 10479, 294, 341, 13, 51722, 51722, 5135, 11, 732, 819, 10479, 13, 51832, 51832], "temperature": 0.0, "avg_logprob": -0.10736310923541034, "compression_ratio": 1.8489795918367347, "no_speech_prob": 1.3419607967080083e-05}, {"id": 654, "seek": 257212, "start": 2586.52, "end": 2591.88, "text": " So in general, this is sort of going to guide the next part of my talk.", "tokens": [50364, 1012, 709, 1589, 366, 291, 32884, 30, 50480, 50480, 400, 300, 393, 976, 291, 1217, 257, 665, 1558, 295, 1968, 291, 434, 767, 32884, 257, 688, 50766, 50766, 295, 1589, 13, 50816, 50816, 407, 1391, 300, 10290, 307, 767, 516, 281, 312, 1101, 13, 51084, 51084, 407, 294, 2674, 11, 341, 307, 1333, 295, 516, 281, 5934, 264, 958, 644, 295, 452, 751, 13, 51352, 51352, 509, 393, 519, 295, 341, 1333, 295, 32884, 544, 1589, 644, 322, 364, 10298, 13, 51582, 51582, 400, 286, 603, 751, 466, 1045, 819, 1333, 295, 10479, 294, 341, 13, 51722, 51722, 5135, 11, 732, 819, 10479, 13, 51832, 51832], "temperature": 0.0, "avg_logprob": -0.10736310923541034, "compression_ratio": 1.8489795918367347, "no_speech_prob": 1.3419607967080083e-05}, {"id": 655, "seek": 257212, "start": 2591.88, "end": 2596.48, "text": " You can think of this sort of predicting more information part on an axis.", "tokens": [50364, 1012, 709, 1589, 366, 291, 32884, 30, 50480, 50480, 400, 300, 393, 976, 291, 1217, 257, 665, 1558, 295, 1968, 291, 434, 767, 32884, 257, 688, 50766, 50766, 295, 1589, 13, 50816, 50816, 407, 1391, 300, 10290, 307, 767, 516, 281, 312, 1101, 13, 51084, 51084, 407, 294, 2674, 11, 341, 307, 1333, 295, 516, 281, 5934, 264, 958, 644, 295, 452, 751, 13, 51352, 51352, 509, 393, 519, 295, 341, 1333, 295, 32884, 544, 1589, 644, 322, 364, 10298, 13, 51582, 51582, 400, 286, 603, 751, 466, 1045, 819, 1333, 295, 10479, 294, 341, 13, 51722, 51722, 5135, 11, 732, 819, 10479, 13, 51832, 51832], "temperature": 0.0, "avg_logprob": -0.10736310923541034, "compression_ratio": 1.8489795918367347, "no_speech_prob": 1.3419607967080083e-05}, {"id": 656, "seek": 257212, "start": 2596.48, "end": 2599.2799999999997, "text": " And I'll talk about three different sort of categories in this.", "tokens": [50364, 1012, 709, 1589, 366, 291, 32884, 30, 50480, 50480, 400, 300, 393, 976, 291, 1217, 257, 665, 1558, 295, 1968, 291, 434, 767, 32884, 257, 688, 50766, 50766, 295, 1589, 13, 50816, 50816, 407, 1391, 300, 10290, 307, 767, 516, 281, 312, 1101, 13, 51084, 51084, 407, 294, 2674, 11, 341, 307, 1333, 295, 516, 281, 5934, 264, 958, 644, 295, 452, 751, 13, 51352, 51352, 509, 393, 519, 295, 341, 1333, 295, 32884, 544, 1589, 644, 322, 364, 10298, 13, 51582, 51582, 400, 286, 603, 751, 466, 1045, 819, 1333, 295, 10479, 294, 341, 13, 51722, 51722, 5135, 11, 732, 819, 10479, 13, 51832, 51832], "temperature": 0.0, "avg_logprob": -0.10736310923541034, "compression_ratio": 1.8489795918367347, "no_speech_prob": 1.3419607967080083e-05}, {"id": 657, "seek": 257212, "start": 2599.2799999999997, "end": 2601.48, "text": " Actually, two different categories.", "tokens": [50364, 1012, 709, 1589, 366, 291, 32884, 30, 50480, 50480, 400, 300, 393, 976, 291, 1217, 257, 665, 1558, 295, 1968, 291, 434, 767, 32884, 257, 688, 50766, 50766, 295, 1589, 13, 50816, 50816, 407, 1391, 300, 10290, 307, 767, 516, 281, 312, 1101, 13, 51084, 51084, 407, 294, 2674, 11, 341, 307, 1333, 295, 516, 281, 5934, 264, 958, 644, 295, 452, 751, 13, 51352, 51352, 509, 393, 519, 295, 341, 1333, 295, 32884, 544, 1589, 644, 322, 364, 10298, 13, 51582, 51582, 400, 286, 603, 751, 466, 1045, 819, 1333, 295, 10479, 294, 341, 13, 51722, 51722, 5135, 11, 732, 819, 10479, 13, 51832, 51832], "temperature": 0.0, "avg_logprob": -0.10736310923541034, "compression_ratio": 1.8489795918367347, "no_speech_prob": 1.3419607967080083e-05}, {"id": 658, "seek": 260148, "start": 2601.48, "end": 2605.6, "text": " So pretext tasks is what I've been talking about till now, which is just predicting simple", "tokens": [50364, 407, 659, 25111, 9608, 307, 437, 286, 600, 668, 1417, 466, 4288, 586, 11, 597, 307, 445, 32884, 2199, 50570, 50570, 21538, 2740, 11, 411, 819, 5310, 295, 12447, 420, 370, 322, 13, 50844, 50844, 400, 1333, 295, 1286, 281, 8712, 488, 7150, 11, 597, 767, 6069, 82, 636, 544, 1589, 813, 51084, 51084, 613, 659, 25111, 9608, 13, 51180, 51180, 400, 294, 341, 1729, 751, 11, 286, 478, 767, 406, 516, 281, 751, 466, 1337, 1166, 5245, 11, 51400, 51400, 457, 1337, 1166, 5245, 6069, 544, 1589, 813, 584, 257, 7476, 8712, 488, 3170, 13, 51654, 51654], "temperature": 0.0, "avg_logprob": -0.13873218536376952, "compression_ratio": 1.8458333333333334, "no_speech_prob": 6.240697075554635e-06}, {"id": 659, "seek": 260148, "start": 2605.6, "end": 2611.08, "text": " classification problems, like different degrees of rotation or so on.", "tokens": [50364, 407, 659, 25111, 9608, 307, 437, 286, 600, 668, 1417, 466, 4288, 586, 11, 597, 307, 445, 32884, 2199, 50570, 50570, 21538, 2740, 11, 411, 819, 5310, 295, 12447, 420, 370, 322, 13, 50844, 50844, 400, 1333, 295, 1286, 281, 8712, 488, 7150, 11, 597, 767, 6069, 82, 636, 544, 1589, 813, 51084, 51084, 613, 659, 25111, 9608, 13, 51180, 51180, 400, 294, 341, 1729, 751, 11, 286, 478, 767, 406, 516, 281, 751, 466, 1337, 1166, 5245, 11, 51400, 51400, 457, 1337, 1166, 5245, 6069, 544, 1589, 813, 584, 257, 7476, 8712, 488, 3170, 13, 51654, 51654], "temperature": 0.0, "avg_logprob": -0.13873218536376952, "compression_ratio": 1.8458333333333334, "no_speech_prob": 6.240697075554635e-06}, {"id": 660, "seek": 260148, "start": 2611.08, "end": 2615.88, "text": " And sort of move to contrastive methods, which actually predicts way more information than", "tokens": [50364, 407, 659, 25111, 9608, 307, 437, 286, 600, 668, 1417, 466, 4288, 586, 11, 597, 307, 445, 32884, 2199, 50570, 50570, 21538, 2740, 11, 411, 819, 5310, 295, 12447, 420, 370, 322, 13, 50844, 50844, 400, 1333, 295, 1286, 281, 8712, 488, 7150, 11, 597, 767, 6069, 82, 636, 544, 1589, 813, 51084, 51084, 613, 659, 25111, 9608, 13, 51180, 51180, 400, 294, 341, 1729, 751, 11, 286, 478, 767, 406, 516, 281, 751, 466, 1337, 1166, 5245, 11, 51400, 51400, 457, 1337, 1166, 5245, 6069, 544, 1589, 813, 584, 257, 7476, 8712, 488, 3170, 13, 51654, 51654], "temperature": 0.0, "avg_logprob": -0.13873218536376952, "compression_ratio": 1.8458333333333334, "no_speech_prob": 6.240697075554635e-06}, {"id": 661, "seek": 260148, "start": 2615.88, "end": 2617.8, "text": " these pretext tasks.", "tokens": [50364, 407, 659, 25111, 9608, 307, 437, 286, 600, 668, 1417, 466, 4288, 586, 11, 597, 307, 445, 32884, 2199, 50570, 50570, 21538, 2740, 11, 411, 819, 5310, 295, 12447, 420, 370, 322, 13, 50844, 50844, 400, 1333, 295, 1286, 281, 8712, 488, 7150, 11, 597, 767, 6069, 82, 636, 544, 1589, 813, 51084, 51084, 613, 659, 25111, 9608, 13, 51180, 51180, 400, 294, 341, 1729, 751, 11, 286, 478, 767, 406, 516, 281, 751, 466, 1337, 1166, 5245, 11, 51400, 51400, 457, 1337, 1166, 5245, 6069, 544, 1589, 813, 584, 257, 7476, 8712, 488, 3170, 13, 51654, 51654], "temperature": 0.0, "avg_logprob": -0.13873218536376952, "compression_ratio": 1.8458333333333334, "no_speech_prob": 6.240697075554635e-06}, {"id": 662, "seek": 260148, "start": 2617.8, "end": 2622.2, "text": " And in this particular talk, I'm actually not going to talk about generative models,", "tokens": [50364, 407, 659, 25111, 9608, 307, 437, 286, 600, 668, 1417, 466, 4288, 586, 11, 597, 307, 445, 32884, 2199, 50570, 50570, 21538, 2740, 11, 411, 819, 5310, 295, 12447, 420, 370, 322, 13, 50844, 50844, 400, 1333, 295, 1286, 281, 8712, 488, 7150, 11, 597, 767, 6069, 82, 636, 544, 1589, 813, 51084, 51084, 613, 659, 25111, 9608, 13, 51180, 51180, 400, 294, 341, 1729, 751, 11, 286, 478, 767, 406, 516, 281, 751, 466, 1337, 1166, 5245, 11, 51400, 51400, 457, 1337, 1166, 5245, 6069, 544, 1589, 813, 584, 257, 7476, 8712, 488, 3170, 13, 51654, 51654], "temperature": 0.0, "avg_logprob": -0.13873218536376952, "compression_ratio": 1.8458333333333334, "no_speech_prob": 6.240697075554635e-06}, {"id": 663, "seek": 260148, "start": 2622.2, "end": 2627.28, "text": " but generative models predict more information than say a typical contrastive method.", "tokens": [50364, 407, 659, 25111, 9608, 307, 437, 286, 600, 668, 1417, 466, 4288, 586, 11, 597, 307, 445, 32884, 2199, 50570, 50570, 21538, 2740, 11, 411, 819, 5310, 295, 12447, 420, 370, 322, 13, 50844, 50844, 400, 1333, 295, 1286, 281, 8712, 488, 7150, 11, 597, 767, 6069, 82, 636, 544, 1589, 813, 51084, 51084, 613, 659, 25111, 9608, 13, 51180, 51180, 400, 294, 341, 1729, 751, 11, 286, 478, 767, 406, 516, 281, 751, 466, 1337, 1166, 5245, 11, 51400, 51400, 457, 1337, 1166, 5245, 6069, 544, 1589, 813, 584, 257, 7476, 8712, 488, 3170, 13, 51654, 51654], "temperature": 0.0, "avg_logprob": -0.13873218536376952, "compression_ratio": 1.8458333333333334, "no_speech_prob": 6.240697075554635e-06}, {"id": 664, "seek": 262728, "start": 2627.28, "end": 2632.36, "text": " And so this is basically one way of thinking about these classes of methods.", "tokens": [50364, 400, 370, 341, 307, 1936, 472, 636, 295, 1953, 466, 613, 5359, 295, 7150, 13, 50618, 50618, 14464, 13, 50668, 50668, 1012, 360, 321, 3847, 3866, 6119, 3097, 659, 12, 17227, 1760, 9608, 30, 50886, 50886, 1144, 321, 39426, 1412, 337, 1293, 9608, 30, 51006, 51006, 759, 3097, 16652, 11, 1582, 380, 309, 1477, 281, 34915, 25428, 30, 51212, 51212, 1779, 13, 51262, 51262, 407, 264, 2199, 636, 295, 884, 300, 307, 1936, 300, 291, 362, 11, 370, 291, 393, 1936, 18873, 51558, 51558, 15245, 279, 13, 51608, 51608, 407, 291, 393, 362, 264, 912, 3209, 13, 51692, 51692], "temperature": 0.0, "avg_logprob": -0.21512564102021775, "compression_ratio": 1.6553191489361703, "no_speech_prob": 1.9831237295875326e-05}, {"id": 665, "seek": 262728, "start": 2632.36, "end": 2633.36, "text": " Question.", "tokens": [50364, 400, 370, 341, 307, 1936, 472, 636, 295, 1953, 466, 613, 5359, 295, 7150, 13, 50618, 50618, 14464, 13, 50668, 50668, 1012, 360, 321, 3847, 3866, 6119, 3097, 659, 12, 17227, 1760, 9608, 30, 50886, 50886, 1144, 321, 39426, 1412, 337, 1293, 9608, 30, 51006, 51006, 759, 3097, 16652, 11, 1582, 380, 309, 1477, 281, 34915, 25428, 30, 51212, 51212, 1779, 13, 51262, 51262, 407, 264, 2199, 636, 295, 884, 300, 307, 1936, 300, 291, 362, 11, 370, 291, 393, 1936, 18873, 51558, 51558, 15245, 279, 13, 51608, 51608, 407, 291, 393, 362, 264, 912, 3209, 13, 51692, 51692], "temperature": 0.0, "avg_logprob": -0.21512564102021775, "compression_ratio": 1.6553191489361703, "no_speech_prob": 1.9831237295875326e-05}, {"id": 666, "seek": 262728, "start": 2633.36, "end": 2637.7200000000003, "text": " How do we train multiple pair training pre-training tasks?", "tokens": [50364, 400, 370, 341, 307, 1936, 472, 636, 295, 1953, 466, 613, 5359, 295, 7150, 13, 50618, 50618, 14464, 13, 50668, 50668, 1012, 360, 321, 3847, 3866, 6119, 3097, 659, 12, 17227, 1760, 9608, 30, 50886, 50886, 1144, 321, 39426, 1412, 337, 1293, 9608, 30, 51006, 51006, 759, 3097, 16652, 11, 1582, 380, 309, 1477, 281, 34915, 25428, 30, 51212, 51212, 1779, 13, 51262, 51262, 407, 264, 2199, 636, 295, 884, 300, 307, 1936, 300, 291, 362, 11, 370, 291, 393, 1936, 18873, 51558, 51558, 15245, 279, 13, 51608, 51608, 407, 291, 393, 362, 264, 912, 3209, 13, 51692, 51692], "temperature": 0.0, "avg_logprob": -0.21512564102021775, "compression_ratio": 1.6553191489361703, "no_speech_prob": 1.9831237295875326e-05}, {"id": 667, "seek": 262728, "start": 2637.7200000000003, "end": 2640.1200000000003, "text": " Do we shuffle data for both tasks?", "tokens": [50364, 400, 370, 341, 307, 1936, 472, 636, 295, 1953, 466, 613, 5359, 295, 7150, 13, 50618, 50618, 14464, 13, 50668, 50668, 1012, 360, 321, 3847, 3866, 6119, 3097, 659, 12, 17227, 1760, 9608, 30, 50886, 50886, 1144, 321, 39426, 1412, 337, 1293, 9608, 30, 51006, 51006, 759, 3097, 16652, 11, 1582, 380, 309, 1477, 281, 34915, 25428, 30, 51212, 51212, 1779, 13, 51262, 51262, 407, 264, 2199, 636, 295, 884, 300, 307, 1936, 300, 291, 362, 11, 370, 291, 393, 1936, 18873, 51558, 51558, 15245, 279, 13, 51608, 51608, 407, 291, 393, 362, 264, 912, 3209, 13, 51692, 51692], "temperature": 0.0, "avg_logprob": -0.21512564102021775, "compression_ratio": 1.6553191489361703, "no_speech_prob": 1.9831237295875326e-05}, {"id": 668, "seek": 262728, "start": 2640.1200000000003, "end": 2644.2400000000002, "text": " If training individually, won't it lead to catastrophic forgetting?", "tokens": [50364, 400, 370, 341, 307, 1936, 472, 636, 295, 1953, 466, 613, 5359, 295, 7150, 13, 50618, 50618, 14464, 13, 50668, 50668, 1012, 360, 321, 3847, 3866, 6119, 3097, 659, 12, 17227, 1760, 9608, 30, 50886, 50886, 1144, 321, 39426, 1412, 337, 1293, 9608, 30, 51006, 51006, 759, 3097, 16652, 11, 1582, 380, 309, 1477, 281, 34915, 25428, 30, 51212, 51212, 1779, 13, 51262, 51262, 407, 264, 2199, 636, 295, 884, 300, 307, 1936, 300, 291, 362, 11, 370, 291, 393, 1936, 18873, 51558, 51558, 15245, 279, 13, 51608, 51608, 407, 291, 393, 362, 264, 912, 3209, 13, 51692, 51692], "temperature": 0.0, "avg_logprob": -0.21512564102021775, "compression_ratio": 1.6553191489361703, "no_speech_prob": 1.9831237295875326e-05}, {"id": 669, "seek": 262728, "start": 2644.2400000000002, "end": 2645.2400000000002, "text": " Right.", "tokens": [50364, 400, 370, 341, 307, 1936, 472, 636, 295, 1953, 466, 613, 5359, 295, 7150, 13, 50618, 50618, 14464, 13, 50668, 50668, 1012, 360, 321, 3847, 3866, 6119, 3097, 659, 12, 17227, 1760, 9608, 30, 50886, 50886, 1144, 321, 39426, 1412, 337, 1293, 9608, 30, 51006, 51006, 759, 3097, 16652, 11, 1582, 380, 309, 1477, 281, 34915, 25428, 30, 51212, 51212, 1779, 13, 51262, 51262, 407, 264, 2199, 636, 295, 884, 300, 307, 1936, 300, 291, 362, 11, 370, 291, 393, 1936, 18873, 51558, 51558, 15245, 279, 13, 51608, 51608, 407, 291, 393, 362, 264, 912, 3209, 13, 51692, 51692], "temperature": 0.0, "avg_logprob": -0.21512564102021775, "compression_ratio": 1.6553191489361703, "no_speech_prob": 1.9831237295875326e-05}, {"id": 670, "seek": 262728, "start": 2645.2400000000002, "end": 2651.1600000000003, "text": " So the simple way of doing that is basically that you have, so you can basically alternate", "tokens": [50364, 400, 370, 341, 307, 1936, 472, 636, 295, 1953, 466, 613, 5359, 295, 7150, 13, 50618, 50618, 14464, 13, 50668, 50668, 1012, 360, 321, 3847, 3866, 6119, 3097, 659, 12, 17227, 1760, 9608, 30, 50886, 50886, 1144, 321, 39426, 1412, 337, 1293, 9608, 30, 51006, 51006, 759, 3097, 16652, 11, 1582, 380, 309, 1477, 281, 34915, 25428, 30, 51212, 51212, 1779, 13, 51262, 51262, 407, 264, 2199, 636, 295, 884, 300, 307, 1936, 300, 291, 362, 11, 370, 291, 393, 1936, 18873, 51558, 51558, 15245, 279, 13, 51608, 51608, 407, 291, 393, 362, 264, 912, 3209, 13, 51692, 51692], "temperature": 0.0, "avg_logprob": -0.21512564102021775, "compression_ratio": 1.6553191489361703, "no_speech_prob": 1.9831237295875326e-05}, {"id": 671, "seek": 262728, "start": 2651.1600000000003, "end": 2652.1600000000003, "text": " batches.", "tokens": [50364, 400, 370, 341, 307, 1936, 472, 636, 295, 1953, 466, 613, 5359, 295, 7150, 13, 50618, 50618, 14464, 13, 50668, 50668, 1012, 360, 321, 3847, 3866, 6119, 3097, 659, 12, 17227, 1760, 9608, 30, 50886, 50886, 1144, 321, 39426, 1412, 337, 1293, 9608, 30, 51006, 51006, 759, 3097, 16652, 11, 1582, 380, 309, 1477, 281, 34915, 25428, 30, 51212, 51212, 1779, 13, 51262, 51262, 407, 264, 2199, 636, 295, 884, 300, 307, 1936, 300, 291, 362, 11, 370, 291, 393, 1936, 18873, 51558, 51558, 15245, 279, 13, 51608, 51608, 407, 291, 393, 362, 264, 912, 3209, 13, 51692, 51692], "temperature": 0.0, "avg_logprob": -0.21512564102021775, "compression_ratio": 1.6553191489361703, "no_speech_prob": 1.9831237295875326e-05}, {"id": 672, "seek": 262728, "start": 2652.1600000000003, "end": 2653.84, "text": " So you can have the same network.", "tokens": [50364, 400, 370, 341, 307, 1936, 472, 636, 295, 1953, 466, 613, 5359, 295, 7150, 13, 50618, 50618, 14464, 13, 50668, 50668, 1012, 360, 321, 3847, 3866, 6119, 3097, 659, 12, 17227, 1760, 9608, 30, 50886, 50886, 1144, 321, 39426, 1412, 337, 1293, 9608, 30, 51006, 51006, 759, 3097, 16652, 11, 1582, 380, 309, 1477, 281, 34915, 25428, 30, 51212, 51212, 1779, 13, 51262, 51262, 407, 264, 2199, 636, 295, 884, 300, 307, 1936, 300, 291, 362, 11, 370, 291, 393, 1936, 18873, 51558, 51558, 15245, 279, 13, 51608, 51608, 407, 291, 393, 362, 264, 912, 3209, 13, 51692, 51692], "temperature": 0.0, "avg_logprob": -0.21512564102021775, "compression_ratio": 1.6553191489361703, "no_speech_prob": 1.9831237295875326e-05}, {"id": 673, "seek": 265384, "start": 2653.84, "end": 2657.56, "text": " And in one batch, you basically feed it black and white images, and you ask it to predict", "tokens": [50364, 400, 294, 472, 15245, 11, 291, 1936, 3154, 309, 2211, 293, 2418, 5267, 11, 293, 291, 1029, 309, 281, 6069, 50550, 50550, 264, 14332, 644, 295, 309, 13, 50634, 50634, 400, 294, 264, 1150, 15245, 11, 291, 1936, 3154, 309, 26531, 11, 293, 291, 1029, 309, 281, 360, 264, 4972, 50936, 50936, 2535, 9608, 13, 50986, 50986, 509, 1936, 362, 732, 819, 1378, 420, 4498, 4582, 7914, 412, 264, 1192, 13, 51362, 51362, 407, 291, 393, 1936, 18873, 1296, 613, 9608, 13, 51488, 51488, 708, 264, 16552, 295, 264, 3035, 630, 390, 767, 4748, 544, 16950, 13, 51786, 51786], "temperature": 0.0, "avg_logprob": -0.16459130768728727, "compression_ratio": 1.8076923076923077, "no_speech_prob": 9.223108463629615e-06}, {"id": 674, "seek": 265384, "start": 2657.56, "end": 2659.2400000000002, "text": " the colored part of it.", "tokens": [50364, 400, 294, 472, 15245, 11, 291, 1936, 3154, 309, 2211, 293, 2418, 5267, 11, 293, 291, 1029, 309, 281, 6069, 50550, 50550, 264, 14332, 644, 295, 309, 13, 50634, 50634, 400, 294, 264, 1150, 15245, 11, 291, 1936, 3154, 309, 26531, 11, 293, 291, 1029, 309, 281, 360, 264, 4972, 50936, 50936, 2535, 9608, 13, 50986, 50986, 509, 1936, 362, 732, 819, 1378, 420, 4498, 4582, 7914, 412, 264, 1192, 13, 51362, 51362, 407, 291, 393, 1936, 18873, 1296, 613, 9608, 13, 51488, 51488, 708, 264, 16552, 295, 264, 3035, 630, 390, 767, 4748, 544, 16950, 13, 51786, 51786], "temperature": 0.0, "avg_logprob": -0.16459130768728727, "compression_ratio": 1.8076923076923077, "no_speech_prob": 9.223108463629615e-06}, {"id": 675, "seek": 265384, "start": 2659.2400000000002, "end": 2665.28, "text": " And in the second batch, you basically feed it patches, and you ask it to do the relative", "tokens": [50364, 400, 294, 472, 15245, 11, 291, 1936, 3154, 309, 2211, 293, 2418, 5267, 11, 293, 291, 1029, 309, 281, 6069, 50550, 50550, 264, 14332, 644, 295, 309, 13, 50634, 50634, 400, 294, 264, 1150, 15245, 11, 291, 1936, 3154, 309, 26531, 11, 293, 291, 1029, 309, 281, 360, 264, 4972, 50936, 50936, 2535, 9608, 13, 50986, 50986, 509, 1936, 362, 732, 819, 1378, 420, 4498, 4582, 7914, 412, 264, 1192, 13, 51362, 51362, 407, 291, 393, 1936, 18873, 1296, 613, 9608, 13, 51488, 51488, 708, 264, 16552, 295, 264, 3035, 630, 390, 767, 4748, 544, 16950, 13, 51786, 51786], "temperature": 0.0, "avg_logprob": -0.16459130768728727, "compression_ratio": 1.8076923076923077, "no_speech_prob": 9.223108463629615e-06}, {"id": 676, "seek": 265384, "start": 2665.28, "end": 2666.28, "text": " position tasks.", "tokens": [50364, 400, 294, 472, 15245, 11, 291, 1936, 3154, 309, 2211, 293, 2418, 5267, 11, 293, 291, 1029, 309, 281, 6069, 50550, 50550, 264, 14332, 644, 295, 309, 13, 50634, 50634, 400, 294, 264, 1150, 15245, 11, 291, 1936, 3154, 309, 26531, 11, 293, 291, 1029, 309, 281, 360, 264, 4972, 50936, 50936, 2535, 9608, 13, 50986, 50986, 509, 1936, 362, 732, 819, 1378, 420, 4498, 4582, 7914, 412, 264, 1192, 13, 51362, 51362, 407, 291, 393, 1936, 18873, 1296, 613, 9608, 13, 51488, 51488, 708, 264, 16552, 295, 264, 3035, 630, 390, 767, 4748, 544, 16950, 13, 51786, 51786], "temperature": 0.0, "avg_logprob": -0.16459130768728727, "compression_ratio": 1.8076923076923077, "no_speech_prob": 9.223108463629615e-06}, {"id": 677, "seek": 265384, "start": 2666.28, "end": 2673.8, "text": " You basically have two different head or fully connected layers at the top.", "tokens": [50364, 400, 294, 472, 15245, 11, 291, 1936, 3154, 309, 2211, 293, 2418, 5267, 11, 293, 291, 1029, 309, 281, 6069, 50550, 50550, 264, 14332, 644, 295, 309, 13, 50634, 50634, 400, 294, 264, 1150, 15245, 11, 291, 1936, 3154, 309, 26531, 11, 293, 291, 1029, 309, 281, 360, 264, 4972, 50936, 50936, 2535, 9608, 13, 50986, 50986, 509, 1936, 362, 732, 819, 1378, 420, 4498, 4582, 7914, 412, 264, 1192, 13, 51362, 51362, 407, 291, 393, 1936, 18873, 1296, 613, 9608, 13, 51488, 51488, 708, 264, 16552, 295, 264, 3035, 630, 390, 767, 4748, 544, 16950, 13, 51786, 51786], "temperature": 0.0, "avg_logprob": -0.16459130768728727, "compression_ratio": 1.8076923076923077, "no_speech_prob": 9.223108463629615e-06}, {"id": 678, "seek": 265384, "start": 2673.8, "end": 2676.32, "text": " So you can basically alternate between these tasks.", "tokens": [50364, 400, 294, 472, 15245, 11, 291, 1936, 3154, 309, 2211, 293, 2418, 5267, 11, 293, 291, 1029, 309, 281, 6069, 50550, 50550, 264, 14332, 644, 295, 309, 13, 50634, 50634, 400, 294, 264, 1150, 15245, 11, 291, 1936, 3154, 309, 26531, 11, 293, 291, 1029, 309, 281, 360, 264, 4972, 50936, 50936, 2535, 9608, 13, 50986, 50986, 509, 1936, 362, 732, 819, 1378, 420, 4498, 4582, 7914, 412, 264, 1192, 13, 51362, 51362, 407, 291, 393, 1936, 18873, 1296, 613, 9608, 13, 51488, 51488, 708, 264, 16552, 295, 264, 3035, 630, 390, 767, 4748, 544, 16950, 13, 51786, 51786], "temperature": 0.0, "avg_logprob": -0.16459130768728727, "compression_ratio": 1.8076923076923077, "no_speech_prob": 9.223108463629615e-06}, {"id": 679, "seek": 265384, "start": 2676.32, "end": 2682.28, "text": " What the authors of the paper did was actually slightly more sophisticated.", "tokens": [50364, 400, 294, 472, 15245, 11, 291, 1936, 3154, 309, 2211, 293, 2418, 5267, 11, 293, 291, 1029, 309, 281, 6069, 50550, 50550, 264, 14332, 644, 295, 309, 13, 50634, 50634, 400, 294, 264, 1150, 15245, 11, 291, 1936, 3154, 309, 26531, 11, 293, 291, 1029, 309, 281, 360, 264, 4972, 50936, 50936, 2535, 9608, 13, 50986, 50986, 509, 1936, 362, 732, 819, 1378, 420, 4498, 4582, 7914, 412, 264, 1192, 13, 51362, 51362, 407, 291, 393, 1936, 18873, 1296, 613, 9608, 13, 51488, 51488, 708, 264, 16552, 295, 264, 3035, 630, 390, 767, 4748, 544, 16950, 13, 51786, 51786], "temperature": 0.0, "avg_logprob": -0.16459130768728727, "compression_ratio": 1.8076923076923077, "no_speech_prob": 9.223108463629615e-06}, {"id": 680, "seek": 268228, "start": 2682.28, "end": 2689.88, "text": " They basically had a sort of multitask network, which was three or four, depending on the", "tokens": [50364, 814, 1936, 632, 257, 1333, 295, 42338, 3863, 3209, 11, 597, 390, 1045, 420, 1451, 11, 5413, 322, 264, 50744, 50744, 1230, 295, 659, 25111, 9608, 291, 362, 13, 50848, 50848, 400, 291, 767, 5039, 439, 295, 552, 412, 1564, 13, 50944, 50944, 583, 456, 390, 1333, 295, 544, 3288, 3364, 5414, 2108, 613, 1451, 420, 1045, 11, 1451, 819, 51204, 51204, 9608, 9590, 13, 51304, 51304, 2421, 11, 286, 362, 257, 1168, 13, 51608, 51608], "temperature": 0.0, "avg_logprob": -0.25184973692282653, "compression_ratio": 1.5384615384615385, "no_speech_prob": 6.500176095869392e-05}, {"id": 681, "seek": 268228, "start": 2689.88, "end": 2691.96, "text": " number of pretext tasks you have.", "tokens": [50364, 814, 1936, 632, 257, 1333, 295, 42338, 3863, 3209, 11, 597, 390, 1045, 420, 1451, 11, 5413, 322, 264, 50744, 50744, 1230, 295, 659, 25111, 9608, 291, 362, 13, 50848, 50848, 400, 291, 767, 5039, 439, 295, 552, 412, 1564, 13, 50944, 50944, 583, 456, 390, 1333, 295, 544, 3288, 3364, 5414, 2108, 613, 1451, 420, 1045, 11, 1451, 819, 51204, 51204, 9608, 9590, 13, 51304, 51304, 2421, 11, 286, 362, 257, 1168, 13, 51608, 51608], "temperature": 0.0, "avg_logprob": -0.25184973692282653, "compression_ratio": 1.5384615384615385, "no_speech_prob": 6.500176095869392e-05}, {"id": 682, "seek": 268228, "start": 2691.96, "end": 2693.88, "text": " And you actually solve all of them at once.", "tokens": [50364, 814, 1936, 632, 257, 1333, 295, 42338, 3863, 3209, 11, 597, 390, 1045, 420, 1451, 11, 5413, 322, 264, 50744, 50744, 1230, 295, 659, 25111, 9608, 291, 362, 13, 50848, 50848, 400, 291, 767, 5039, 439, 295, 552, 412, 1564, 13, 50944, 50944, 583, 456, 390, 1333, 295, 544, 3288, 3364, 5414, 2108, 613, 1451, 420, 1045, 11, 1451, 819, 51204, 51204, 9608, 9590, 13, 51304, 51304, 2421, 11, 286, 362, 257, 1168, 13, 51608, 51608], "temperature": 0.0, "avg_logprob": -0.25184973692282653, "compression_ratio": 1.5384615384615385, "no_speech_prob": 6.500176095869392e-05}, {"id": 683, "seek": 268228, "start": 2693.88, "end": 2699.0800000000004, "text": " But there was sort of more involved weight sharing across these four or three, four different", "tokens": [50364, 814, 1936, 632, 257, 1333, 295, 42338, 3863, 3209, 11, 597, 390, 1045, 420, 1451, 11, 5413, 322, 264, 50744, 50744, 1230, 295, 659, 25111, 9608, 291, 362, 13, 50848, 50848, 400, 291, 767, 5039, 439, 295, 552, 412, 1564, 13, 50944, 50944, 583, 456, 390, 1333, 295, 544, 3288, 3364, 5414, 2108, 613, 1451, 420, 1045, 11, 1451, 819, 51204, 51204, 9608, 9590, 13, 51304, 51304, 2421, 11, 286, 362, 257, 1168, 13, 51608, 51608], "temperature": 0.0, "avg_logprob": -0.25184973692282653, "compression_ratio": 1.5384615384615385, "no_speech_prob": 6.500176095869392e-05}, {"id": 684, "seek": 268228, "start": 2699.0800000000004, "end": 2701.0800000000004, "text": " tasks networks.", "tokens": [50364, 814, 1936, 632, 257, 1333, 295, 42338, 3863, 3209, 11, 597, 390, 1045, 420, 1451, 11, 5413, 322, 264, 50744, 50744, 1230, 295, 659, 25111, 9608, 291, 362, 13, 50848, 50848, 400, 291, 767, 5039, 439, 295, 552, 412, 1564, 13, 50944, 50944, 583, 456, 390, 1333, 295, 544, 3288, 3364, 5414, 2108, 613, 1451, 420, 1045, 11, 1451, 819, 51204, 51204, 9608, 9590, 13, 51304, 51304, 2421, 11, 286, 362, 257, 1168, 13, 51608, 51608], "temperature": 0.0, "avg_logprob": -0.25184973692282653, "compression_ratio": 1.5384615384615385, "no_speech_prob": 6.500176095869392e-05}, {"id": 685, "seek": 268228, "start": 2701.0800000000004, "end": 2707.1600000000003, "text": " Hi, I have a question.", "tokens": [50364, 814, 1936, 632, 257, 1333, 295, 42338, 3863, 3209, 11, 597, 390, 1045, 420, 1451, 11, 5413, 322, 264, 50744, 50744, 1230, 295, 659, 25111, 9608, 291, 362, 13, 50848, 50848, 400, 291, 767, 5039, 439, 295, 552, 412, 1564, 13, 50944, 50944, 583, 456, 390, 1333, 295, 544, 3288, 3364, 5414, 2108, 613, 1451, 420, 1045, 11, 1451, 819, 51204, 51204, 9608, 9590, 13, 51304, 51304, 2421, 11, 286, 362, 257, 1168, 13, 51608, 51608], "temperature": 0.0, "avg_logprob": -0.25184973692282653, "compression_ratio": 1.5384615384615385, "no_speech_prob": 6.500176095869392e-05}, {"id": 686, "seek": 270716, "start": 2707.16, "end": 2712.6, "text": " So about the pretext tasks, what performance should we aim for in a pretext task?", "tokens": [50364, 407, 466, 264, 659, 25111, 9608, 11, 437, 3389, 820, 321, 5939, 337, 294, 257, 659, 25111, 5633, 30, 50636, 50636, 1133, 360, 321, 458, 300, 341, 307, 1547, 30, 50736, 50736, 1610, 562, 393, 321, 1590, 30, 50816, 50816, 400, 570, 6284, 11, 321, 1127, 466, 264, 3389, 322, 264, 30621, 13, 51006, 51006, 663, 311, 1168, 472, 13, 51072, 51072, 400, 1168, 732, 307, 291, 645, 4124, 466, 2295, 1589, 293, 544, 1589, 13, 51296, 51296, 1171, 1365, 11, 294, 264, 1389, 689, 291, 2835, 689, 291, 645, 32884, 1968, 309, 311, 294, 51524, 51524, 264, 3006, 8310, 420, 406, 11, 291, 727, 362, 611, 19147, 264, 3539, 4784, 11380, 295, 264, 51778, 51778, 5267, 13, 51828, 51828], "temperature": 0.0, "avg_logprob": -0.1522618278128202, "compression_ratio": 1.7695035460992907, "no_speech_prob": 6.706851127091795e-05}, {"id": 687, "seek": 270716, "start": 2712.6, "end": 2714.6, "text": " When do we know that this is enough?", "tokens": [50364, 407, 466, 264, 659, 25111, 9608, 11, 437, 3389, 820, 321, 5939, 337, 294, 257, 659, 25111, 5633, 30, 50636, 50636, 1133, 360, 321, 458, 300, 341, 307, 1547, 30, 50736, 50736, 1610, 562, 393, 321, 1590, 30, 50816, 50816, 400, 570, 6284, 11, 321, 1127, 466, 264, 3389, 322, 264, 30621, 13, 51006, 51006, 663, 311, 1168, 472, 13, 51072, 51072, 400, 1168, 732, 307, 291, 645, 4124, 466, 2295, 1589, 293, 544, 1589, 13, 51296, 51296, 1171, 1365, 11, 294, 264, 1389, 689, 291, 2835, 689, 291, 645, 32884, 1968, 309, 311, 294, 51524, 51524, 264, 3006, 8310, 420, 406, 11, 291, 727, 362, 611, 19147, 264, 3539, 4784, 11380, 295, 264, 51778, 51778, 5267, 13, 51828, 51828], "temperature": 0.0, "avg_logprob": -0.1522618278128202, "compression_ratio": 1.7695035460992907, "no_speech_prob": 6.706851127091795e-05}, {"id": 688, "seek": 270716, "start": 2714.6, "end": 2716.2, "text": " Or when can we stop?", "tokens": [50364, 407, 466, 264, 659, 25111, 9608, 11, 437, 3389, 820, 321, 5939, 337, 294, 257, 659, 25111, 5633, 30, 50636, 50636, 1133, 360, 321, 458, 300, 341, 307, 1547, 30, 50736, 50736, 1610, 562, 393, 321, 1590, 30, 50816, 50816, 400, 570, 6284, 11, 321, 1127, 466, 264, 3389, 322, 264, 30621, 13, 51006, 51006, 663, 311, 1168, 472, 13, 51072, 51072, 400, 1168, 732, 307, 291, 645, 4124, 466, 2295, 1589, 293, 544, 1589, 13, 51296, 51296, 1171, 1365, 11, 294, 264, 1389, 689, 291, 2835, 689, 291, 645, 32884, 1968, 309, 311, 294, 51524, 51524, 264, 3006, 8310, 420, 406, 11, 291, 727, 362, 611, 19147, 264, 3539, 4784, 11380, 295, 264, 51778, 51778, 5267, 13, 51828, 51828], "temperature": 0.0, "avg_logprob": -0.1522618278128202, "compression_ratio": 1.7695035460992907, "no_speech_prob": 6.706851127091795e-05}, {"id": 689, "seek": 270716, "start": 2716.2, "end": 2720.0, "text": " And because ultimately, we care about the performance on the downstream.", "tokens": [50364, 407, 466, 264, 659, 25111, 9608, 11, 437, 3389, 820, 321, 5939, 337, 294, 257, 659, 25111, 5633, 30, 50636, 50636, 1133, 360, 321, 458, 300, 341, 307, 1547, 30, 50736, 50736, 1610, 562, 393, 321, 1590, 30, 50816, 50816, 400, 570, 6284, 11, 321, 1127, 466, 264, 3389, 322, 264, 30621, 13, 51006, 51006, 663, 311, 1168, 472, 13, 51072, 51072, 400, 1168, 732, 307, 291, 645, 4124, 466, 2295, 1589, 293, 544, 1589, 13, 51296, 51296, 1171, 1365, 11, 294, 264, 1389, 689, 291, 2835, 689, 291, 645, 32884, 1968, 309, 311, 294, 51524, 51524, 264, 3006, 8310, 420, 406, 11, 291, 727, 362, 611, 19147, 264, 3539, 4784, 11380, 295, 264, 51778, 51778, 5267, 13, 51828, 51828], "temperature": 0.0, "avg_logprob": -0.1522618278128202, "compression_ratio": 1.7695035460992907, "no_speech_prob": 6.706851127091795e-05}, {"id": 690, "seek": 270716, "start": 2720.0, "end": 2721.3199999999997, "text": " That's question one.", "tokens": [50364, 407, 466, 264, 659, 25111, 9608, 11, 437, 3389, 820, 321, 5939, 337, 294, 257, 659, 25111, 5633, 30, 50636, 50636, 1133, 360, 321, 458, 300, 341, 307, 1547, 30, 50736, 50736, 1610, 562, 393, 321, 1590, 30, 50816, 50816, 400, 570, 6284, 11, 321, 1127, 466, 264, 3389, 322, 264, 30621, 13, 51006, 51006, 663, 311, 1168, 472, 13, 51072, 51072, 400, 1168, 732, 307, 291, 645, 4124, 466, 2295, 1589, 293, 544, 1589, 13, 51296, 51296, 1171, 1365, 11, 294, 264, 1389, 689, 291, 2835, 689, 291, 645, 32884, 1968, 309, 311, 294, 51524, 51524, 264, 3006, 8310, 420, 406, 11, 291, 727, 362, 611, 19147, 264, 3539, 4784, 11380, 295, 264, 51778, 51778, 5267, 13, 51828, 51828], "temperature": 0.0, "avg_logprob": -0.1522618278128202, "compression_ratio": 1.7695035460992907, "no_speech_prob": 6.706851127091795e-05}, {"id": 691, "seek": 270716, "start": 2721.3199999999997, "end": 2725.7999999999997, "text": " And question two is you were speaking about low information and more information.", "tokens": [50364, 407, 466, 264, 659, 25111, 9608, 11, 437, 3389, 820, 321, 5939, 337, 294, 257, 659, 25111, 5633, 30, 50636, 50636, 1133, 360, 321, 458, 300, 341, 307, 1547, 30, 50736, 50736, 1610, 562, 393, 321, 1590, 30, 50816, 50816, 400, 570, 6284, 11, 321, 1127, 466, 264, 3389, 322, 264, 30621, 13, 51006, 51006, 663, 311, 1168, 472, 13, 51072, 51072, 400, 1168, 732, 307, 291, 645, 4124, 466, 2295, 1589, 293, 544, 1589, 13, 51296, 51296, 1171, 1365, 11, 294, 264, 1389, 689, 291, 2835, 689, 291, 645, 32884, 1968, 309, 311, 294, 51524, 51524, 264, 3006, 8310, 420, 406, 11, 291, 727, 362, 611, 19147, 264, 3539, 4784, 11380, 295, 264, 51778, 51778, 5267, 13, 51828, 51828], "temperature": 0.0, "avg_logprob": -0.1522618278128202, "compression_ratio": 1.7695035460992907, "no_speech_prob": 6.706851127091795e-05}, {"id": 692, "seek": 270716, "start": 2725.7999999999997, "end": 2730.3599999999997, "text": " For example, in the case where you mentioned where you were predicting whether it's in", "tokens": [50364, 407, 466, 264, 659, 25111, 9608, 11, 437, 3389, 820, 321, 5939, 337, 294, 257, 659, 25111, 5633, 30, 50636, 50636, 1133, 360, 321, 458, 300, 341, 307, 1547, 30, 50736, 50736, 1610, 562, 393, 321, 1590, 30, 50816, 50816, 400, 570, 6284, 11, 321, 1127, 466, 264, 3389, 322, 264, 30621, 13, 51006, 51006, 663, 311, 1168, 472, 13, 51072, 51072, 400, 1168, 732, 307, 291, 645, 4124, 466, 2295, 1589, 293, 544, 1589, 13, 51296, 51296, 1171, 1365, 11, 294, 264, 1389, 689, 291, 2835, 689, 291, 645, 32884, 1968, 309, 311, 294, 51524, 51524, 264, 3006, 8310, 420, 406, 11, 291, 727, 362, 611, 19147, 264, 3539, 4784, 11380, 295, 264, 51778, 51778, 5267, 13, 51828, 51828], "temperature": 0.0, "avg_logprob": -0.1522618278128202, "compression_ratio": 1.7695035460992907, "no_speech_prob": 6.706851127091795e-05}, {"id": 693, "seek": 270716, "start": 2730.3599999999997, "end": 2735.44, "text": " the correct sequence or not, you could have also predicted the actual permutation of the", "tokens": [50364, 407, 466, 264, 659, 25111, 9608, 11, 437, 3389, 820, 321, 5939, 337, 294, 257, 659, 25111, 5633, 30, 50636, 50636, 1133, 360, 321, 458, 300, 341, 307, 1547, 30, 50736, 50736, 1610, 562, 393, 321, 1590, 30, 50816, 50816, 400, 570, 6284, 11, 321, 1127, 466, 264, 3389, 322, 264, 30621, 13, 51006, 51006, 663, 311, 1168, 472, 13, 51072, 51072, 400, 1168, 732, 307, 291, 645, 4124, 466, 2295, 1589, 293, 544, 1589, 13, 51296, 51296, 1171, 1365, 11, 294, 264, 1389, 689, 291, 2835, 689, 291, 645, 32884, 1968, 309, 311, 294, 51524, 51524, 264, 3006, 8310, 420, 406, 11, 291, 727, 362, 611, 19147, 264, 3539, 4784, 11380, 295, 264, 51778, 51778, 5267, 13, 51828, 51828], "temperature": 0.0, "avg_logprob": -0.1522618278128202, "compression_ratio": 1.7695035460992907, "no_speech_prob": 6.706851127091795e-05}, {"id": 694, "seek": 270716, "start": 2735.44, "end": 2736.44, "text": " images.", "tokens": [50364, 407, 466, 264, 659, 25111, 9608, 11, 437, 3389, 820, 321, 5939, 337, 294, 257, 659, 25111, 5633, 30, 50636, 50636, 1133, 360, 321, 458, 300, 341, 307, 1547, 30, 50736, 50736, 1610, 562, 393, 321, 1590, 30, 50816, 50816, 400, 570, 6284, 11, 321, 1127, 466, 264, 3389, 322, 264, 30621, 13, 51006, 51006, 663, 311, 1168, 472, 13, 51072, 51072, 400, 1168, 732, 307, 291, 645, 4124, 466, 2295, 1589, 293, 544, 1589, 13, 51296, 51296, 1171, 1365, 11, 294, 264, 1389, 689, 291, 2835, 689, 291, 645, 32884, 1968, 309, 311, 294, 51524, 51524, 264, 3006, 8310, 420, 406, 11, 291, 727, 362, 611, 19147, 264, 3539, 4784, 11380, 295, 264, 51778, 51778, 5267, 13, 51828, 51828], "temperature": 0.0, "avg_logprob": -0.1522618278128202, "compression_ratio": 1.7695035460992907, "no_speech_prob": 6.706851127091795e-05}, {"id": 695, "seek": 273644, "start": 2736.44, "end": 2743.12, "text": " So how do you decide between which task to follow and based on what?", "tokens": [50364, 407, 577, 360, 291, 4536, 1296, 597, 5633, 281, 1524, 293, 2361, 322, 437, 30, 50698, 50698, 407, 1293, 3166, 13, 50774, 50774, 440, 1150, 644, 295, 264, 1168, 11, 767, 11, 300, 311, 516, 281, 312, 294, 257, 1916, 295, 9788, 13, 50994, 50994, 407, 286, 603, 1333, 295, 25704, 281, 300, 1168, 11, 300, 472, 1780, 13, 51142, 51142, 583, 264, 700, 644, 11, 577, 709, 360, 291, 3847, 341, 2316, 322, 257, 659, 25111, 5633, 30, 51324, 51324, 407, 257, 1333, 295, 665, 1465, 295, 257, 659, 25111, 5633, 307, 300, 382, 428, 14170, 322, 264, 659, 25111, 5633, 51640, 51640, 24771, 11, 370, 382, 291, 483, 1101, 412, 32884, 1968, 721, 366, 402, 33974, 420, 406, 11, 420, 382, 51824, 51824], "temperature": 0.0, "avg_logprob": -0.15845717783049335, "compression_ratio": 1.7179487179487178, "no_speech_prob": 1.496998629590962e-05}, {"id": 696, "seek": 273644, "start": 2743.12, "end": 2744.64, "text": " So both parts.", "tokens": [50364, 407, 577, 360, 291, 4536, 1296, 597, 5633, 281, 1524, 293, 2361, 322, 437, 30, 50698, 50698, 407, 1293, 3166, 13, 50774, 50774, 440, 1150, 644, 295, 264, 1168, 11, 767, 11, 300, 311, 516, 281, 312, 294, 257, 1916, 295, 9788, 13, 50994, 50994, 407, 286, 603, 1333, 295, 25704, 281, 300, 1168, 11, 300, 472, 1780, 13, 51142, 51142, 583, 264, 700, 644, 11, 577, 709, 360, 291, 3847, 341, 2316, 322, 257, 659, 25111, 5633, 30, 51324, 51324, 407, 257, 1333, 295, 665, 1465, 295, 257, 659, 25111, 5633, 307, 300, 382, 428, 14170, 322, 264, 659, 25111, 5633, 51640, 51640, 24771, 11, 370, 382, 291, 483, 1101, 412, 32884, 1968, 721, 366, 402, 33974, 420, 406, 11, 420, 382, 51824, 51824], "temperature": 0.0, "avg_logprob": -0.15845717783049335, "compression_ratio": 1.7179487179487178, "no_speech_prob": 1.496998629590962e-05}, {"id": 697, "seek": 273644, "start": 2744.64, "end": 2749.04, "text": " The second part of the question, actually, that's going to be in a couple of slides.", "tokens": [50364, 407, 577, 360, 291, 4536, 1296, 597, 5633, 281, 1524, 293, 2361, 322, 437, 30, 50698, 50698, 407, 1293, 3166, 13, 50774, 50774, 440, 1150, 644, 295, 264, 1168, 11, 767, 11, 300, 311, 516, 281, 312, 294, 257, 1916, 295, 9788, 13, 50994, 50994, 407, 286, 603, 1333, 295, 25704, 281, 300, 1168, 11, 300, 472, 1780, 13, 51142, 51142, 583, 264, 700, 644, 11, 577, 709, 360, 291, 3847, 341, 2316, 322, 257, 659, 25111, 5633, 30, 51324, 51324, 407, 257, 1333, 295, 665, 1465, 295, 257, 659, 25111, 5633, 307, 300, 382, 428, 14170, 322, 264, 659, 25111, 5633, 51640, 51640, 24771, 11, 370, 382, 291, 483, 1101, 412, 32884, 1968, 721, 366, 402, 33974, 420, 406, 11, 420, 382, 51824, 51824], "temperature": 0.0, "avg_logprob": -0.15845717783049335, "compression_ratio": 1.7179487179487178, "no_speech_prob": 1.496998629590962e-05}, {"id": 698, "seek": 273644, "start": 2749.04, "end": 2752.0, "text": " So I'll sort of defer to that question, that one later.", "tokens": [50364, 407, 577, 360, 291, 4536, 1296, 597, 5633, 281, 1524, 293, 2361, 322, 437, 30, 50698, 50698, 407, 1293, 3166, 13, 50774, 50774, 440, 1150, 644, 295, 264, 1168, 11, 767, 11, 300, 311, 516, 281, 312, 294, 257, 1916, 295, 9788, 13, 50994, 50994, 407, 286, 603, 1333, 295, 25704, 281, 300, 1168, 11, 300, 472, 1780, 13, 51142, 51142, 583, 264, 700, 644, 11, 577, 709, 360, 291, 3847, 341, 2316, 322, 257, 659, 25111, 5633, 30, 51324, 51324, 407, 257, 1333, 295, 665, 1465, 295, 257, 659, 25111, 5633, 307, 300, 382, 428, 14170, 322, 264, 659, 25111, 5633, 51640, 51640, 24771, 11, 370, 382, 291, 483, 1101, 412, 32884, 1968, 721, 366, 402, 33974, 420, 406, 11, 420, 382, 51824, 51824], "temperature": 0.0, "avg_logprob": -0.15845717783049335, "compression_ratio": 1.7179487179487178, "no_speech_prob": 1.496998629590962e-05}, {"id": 699, "seek": 273644, "start": 2752.0, "end": 2755.64, "text": " But the first part, how much do you train this model on a pretext task?", "tokens": [50364, 407, 577, 360, 291, 4536, 1296, 597, 5633, 281, 1524, 293, 2361, 322, 437, 30, 50698, 50698, 407, 1293, 3166, 13, 50774, 50774, 440, 1150, 644, 295, 264, 1168, 11, 767, 11, 300, 311, 516, 281, 312, 294, 257, 1916, 295, 9788, 13, 50994, 50994, 407, 286, 603, 1333, 295, 25704, 281, 300, 1168, 11, 300, 472, 1780, 13, 51142, 51142, 583, 264, 700, 644, 11, 577, 709, 360, 291, 3847, 341, 2316, 322, 257, 659, 25111, 5633, 30, 51324, 51324, 407, 257, 1333, 295, 665, 1465, 295, 257, 659, 25111, 5633, 307, 300, 382, 428, 14170, 322, 264, 659, 25111, 5633, 51640, 51640, 24771, 11, 370, 382, 291, 483, 1101, 412, 32884, 1968, 721, 366, 402, 33974, 420, 406, 11, 420, 382, 51824, 51824], "temperature": 0.0, "avg_logprob": -0.15845717783049335, "compression_ratio": 1.7179487179487178, "no_speech_prob": 1.496998629590962e-05}, {"id": 700, "seek": 273644, "start": 2755.64, "end": 2761.96, "text": " So a sort of good sign of a pretext task is that as your accuracy on the pretext task", "tokens": [50364, 407, 577, 360, 291, 4536, 1296, 597, 5633, 281, 1524, 293, 2361, 322, 437, 30, 50698, 50698, 407, 1293, 3166, 13, 50774, 50774, 440, 1150, 644, 295, 264, 1168, 11, 767, 11, 300, 311, 516, 281, 312, 294, 257, 1916, 295, 9788, 13, 50994, 50994, 407, 286, 603, 1333, 295, 25704, 281, 300, 1168, 11, 300, 472, 1780, 13, 51142, 51142, 583, 264, 700, 644, 11, 577, 709, 360, 291, 3847, 341, 2316, 322, 257, 659, 25111, 5633, 30, 51324, 51324, 407, 257, 1333, 295, 665, 1465, 295, 257, 659, 25111, 5633, 307, 300, 382, 428, 14170, 322, 264, 659, 25111, 5633, 51640, 51640, 24771, 11, 370, 382, 291, 483, 1101, 412, 32884, 1968, 721, 366, 402, 33974, 420, 406, 11, 420, 382, 51824, 51824], "temperature": 0.0, "avg_logprob": -0.15845717783049335, "compression_ratio": 1.7179487179487178, "no_speech_prob": 1.496998629590962e-05}, {"id": 701, "seek": 273644, "start": 2761.96, "end": 2765.64, "text": " improves, so as you get better at predicting whether things are shuffled or not, or as", "tokens": [50364, 407, 577, 360, 291, 4536, 1296, 597, 5633, 281, 1524, 293, 2361, 322, 437, 30, 50698, 50698, 407, 1293, 3166, 13, 50774, 50774, 440, 1150, 644, 295, 264, 1168, 11, 767, 11, 300, 311, 516, 281, 312, 294, 257, 1916, 295, 9788, 13, 50994, 50994, 407, 286, 603, 1333, 295, 25704, 281, 300, 1168, 11, 300, 472, 1780, 13, 51142, 51142, 583, 264, 700, 644, 11, 577, 709, 360, 291, 3847, 341, 2316, 322, 257, 659, 25111, 5633, 30, 51324, 51324, 407, 257, 1333, 295, 665, 1465, 295, 257, 659, 25111, 5633, 307, 300, 382, 428, 14170, 322, 264, 659, 25111, 5633, 51640, 51640, 24771, 11, 370, 382, 291, 483, 1101, 412, 32884, 1968, 721, 366, 402, 33974, 420, 406, 11, 420, 382, 51824, 51824], "temperature": 0.0, "avg_logprob": -0.15845717783049335, "compression_ratio": 1.7179487179487178, "no_speech_prob": 1.496998629590962e-05}, {"id": 702, "seek": 276564, "start": 2765.64, "end": 2771.2799999999997, "text": " you get better at predicting rotations, the accuracy on the downstream semantic task will", "tokens": [50364, 291, 483, 1101, 412, 32884, 44796, 11, 264, 14170, 322, 264, 30621, 47982, 5633, 486, 50646, 50646, 611, 3470, 13, 50734, 50734, 407, 257, 665, 4978, 295, 9298, 337, 1936, 1228, 613, 659, 25111, 9608, 307, 281, 362, 257, 588, 2252, 51082, 51082, 659, 25111, 5633, 420, 853, 281, 652, 309, 382, 2252, 382, 1944, 13, 51258, 51258, 400, 550, 19719, 420, 5407, 264, 4470, 322, 300, 659, 25111, 5633, 370, 300, 428, 2572, 30621, 51548, 51548, 14170, 24771, 13, 51630, 51630, 407, 309, 311, 588, 38574, 13, 51762, 51762], "temperature": 0.0, "avg_logprob": -0.14262555993121603, "compression_ratio": 1.6991150442477876, "no_speech_prob": 5.9548292483668774e-06}, {"id": 703, "seek": 276564, "start": 2771.2799999999997, "end": 2773.04, "text": " also improve.", "tokens": [50364, 291, 483, 1101, 412, 32884, 44796, 11, 264, 14170, 322, 264, 30621, 47982, 5633, 486, 50646, 50646, 611, 3470, 13, 50734, 50734, 407, 257, 665, 4978, 295, 9298, 337, 1936, 1228, 613, 659, 25111, 9608, 307, 281, 362, 257, 588, 2252, 51082, 51082, 659, 25111, 5633, 420, 853, 281, 652, 309, 382, 2252, 382, 1944, 13, 51258, 51258, 400, 550, 19719, 420, 5407, 264, 4470, 322, 300, 659, 25111, 5633, 370, 300, 428, 2572, 30621, 51548, 51548, 14170, 24771, 13, 51630, 51630, 407, 309, 311, 588, 38574, 13, 51762, 51762], "temperature": 0.0, "avg_logprob": -0.14262555993121603, "compression_ratio": 1.6991150442477876, "no_speech_prob": 5.9548292483668774e-06}, {"id": 704, "seek": 276564, "start": 2773.04, "end": 2780.0, "text": " So a good rule of thumb for basically using these pretext tasks is to have a very difficult", "tokens": [50364, 291, 483, 1101, 412, 32884, 44796, 11, 264, 14170, 322, 264, 30621, 47982, 5633, 486, 50646, 50646, 611, 3470, 13, 50734, 50734, 407, 257, 665, 4978, 295, 9298, 337, 1936, 1228, 613, 659, 25111, 9608, 307, 281, 362, 257, 588, 2252, 51082, 51082, 659, 25111, 5633, 420, 853, 281, 652, 309, 382, 2252, 382, 1944, 13, 51258, 51258, 400, 550, 19719, 420, 5407, 264, 4470, 322, 300, 659, 25111, 5633, 370, 300, 428, 2572, 30621, 51548, 51548, 14170, 24771, 13, 51630, 51630, 407, 309, 311, 588, 38574, 13, 51762, 51762], "temperature": 0.0, "avg_logprob": -0.14262555993121603, "compression_ratio": 1.6991150442477876, "no_speech_prob": 5.9548292483668774e-06}, {"id": 705, "seek": 276564, "start": 2780.0, "end": 2783.52, "text": " pretext task or try to make it as difficult as possible.", "tokens": [50364, 291, 483, 1101, 412, 32884, 44796, 11, 264, 14170, 322, 264, 30621, 47982, 5633, 486, 50646, 50646, 611, 3470, 13, 50734, 50734, 407, 257, 665, 4978, 295, 9298, 337, 1936, 1228, 613, 659, 25111, 9608, 307, 281, 362, 257, 588, 2252, 51082, 51082, 659, 25111, 5633, 420, 853, 281, 652, 309, 382, 2252, 382, 1944, 13, 51258, 51258, 400, 550, 19719, 420, 5407, 264, 4470, 322, 300, 659, 25111, 5633, 370, 300, 428, 2572, 30621, 51548, 51548, 14170, 24771, 13, 51630, 51630, 407, 309, 311, 588, 38574, 13, 51762, 51762], "temperature": 0.0, "avg_logprob": -0.14262555993121603, "compression_ratio": 1.6991150442477876, "no_speech_prob": 5.9548292483668774e-06}, {"id": 706, "seek": 276564, "start": 2783.52, "end": 2789.3199999999997, "text": " And then optimize or reduce the loss on that pretext task so that your final downstream", "tokens": [50364, 291, 483, 1101, 412, 32884, 44796, 11, 264, 14170, 322, 264, 30621, 47982, 5633, 486, 50646, 50646, 611, 3470, 13, 50734, 50734, 407, 257, 665, 4978, 295, 9298, 337, 1936, 1228, 613, 659, 25111, 9608, 307, 281, 362, 257, 588, 2252, 51082, 51082, 659, 25111, 5633, 420, 853, 281, 652, 309, 382, 2252, 382, 1944, 13, 51258, 51258, 400, 550, 19719, 420, 5407, 264, 4470, 322, 300, 659, 25111, 5633, 370, 300, 428, 2572, 30621, 51548, 51548, 14170, 24771, 13, 51630, 51630, 407, 309, 311, 588, 38574, 13, 51762, 51762], "temperature": 0.0, "avg_logprob": -0.14262555993121603, "compression_ratio": 1.6991150442477876, "no_speech_prob": 5.9548292483668774e-06}, {"id": 707, "seek": 276564, "start": 2789.3199999999997, "end": 2790.96, "text": " accuracy improves.", "tokens": [50364, 291, 483, 1101, 412, 32884, 44796, 11, 264, 14170, 322, 264, 30621, 47982, 5633, 486, 50646, 50646, 611, 3470, 13, 50734, 50734, 407, 257, 665, 4978, 295, 9298, 337, 1936, 1228, 613, 659, 25111, 9608, 307, 281, 362, 257, 588, 2252, 51082, 51082, 659, 25111, 5633, 420, 853, 281, 652, 309, 382, 2252, 382, 1944, 13, 51258, 51258, 400, 550, 19719, 420, 5407, 264, 4470, 322, 300, 659, 25111, 5633, 370, 300, 428, 2572, 30621, 51548, 51548, 14170, 24771, 13, 51630, 51630, 407, 309, 311, 588, 38574, 13, 51762, 51762], "temperature": 0.0, "avg_logprob": -0.14262555993121603, "compression_ratio": 1.6991150442477876, "no_speech_prob": 5.9548292483668774e-06}, {"id": 708, "seek": 276564, "start": 2790.96, "end": 2793.6, "text": " So it's very correlated.", "tokens": [50364, 291, 483, 1101, 412, 32884, 44796, 11, 264, 14170, 322, 264, 30621, 47982, 5633, 486, 50646, 50646, 611, 3470, 13, 50734, 50734, 407, 257, 665, 4978, 295, 9298, 337, 1936, 1228, 613, 659, 25111, 9608, 307, 281, 362, 257, 588, 2252, 51082, 51082, 659, 25111, 5633, 420, 853, 281, 652, 309, 382, 2252, 382, 1944, 13, 51258, 51258, 400, 550, 19719, 420, 5407, 264, 4470, 322, 300, 659, 25111, 5633, 370, 300, 428, 2572, 30621, 51548, 51548, 14170, 24771, 13, 51630, 51630, 407, 309, 311, 588, 38574, 13, 51762, 51762], "temperature": 0.0, "avg_logprob": -0.14262555993121603, "compression_ratio": 1.6991150442477876, "no_speech_prob": 5.9548292483668774e-06}, {"id": 709, "seek": 279360, "start": 2793.6, "end": 2800.56, "text": " Right, so in practice, you'll actually train the entire pipeline each time, like the pretext", "tokens": [50364, 1779, 11, 370, 294, 3124, 11, 291, 603, 767, 3847, 264, 2302, 15517, 1184, 565, 11, 411, 264, 659, 25111, 50712, 50712, 293, 264, 30621, 293, 3481, 264, 3389, 13, 50824, 50824, 407, 309, 311, 406, 411, 291, 1590, 264, 659, 25111, 412, 257, 1629, 935, 293, 550, 3679, 670, 281, 787, 51012, 51012, 411, 30621, 420, 746, 13, 51084, 51084, 407, 300, 311, 5101, 577, 613, 7150, 366, 25509, 13, 51236, 51236, 583, 286, 2041, 562, 291, 434, 6416, 11, 291, 603, 1391, 360, 341, 15517, 3866, 1413, 13, 51502, 51502, 407, 613, 7150, 366, 1333, 295, 8895, 11, 411, 291, 360, 428, 659, 25111, 5633, 11, 550, 291, 1590, 11, 293, 51776, 51776], "temperature": 0.0, "avg_logprob": -0.16006345830411992, "compression_ratio": 1.8052434456928839, "no_speech_prob": 4.908375922241248e-05}, {"id": 710, "seek": 279360, "start": 2800.56, "end": 2802.7999999999997, "text": " and the downstream and measure the performance.", "tokens": [50364, 1779, 11, 370, 294, 3124, 11, 291, 603, 767, 3847, 264, 2302, 15517, 1184, 565, 11, 411, 264, 659, 25111, 50712, 50712, 293, 264, 30621, 293, 3481, 264, 3389, 13, 50824, 50824, 407, 309, 311, 406, 411, 291, 1590, 264, 659, 25111, 412, 257, 1629, 935, 293, 550, 3679, 670, 281, 787, 51012, 51012, 411, 30621, 420, 746, 13, 51084, 51084, 407, 300, 311, 5101, 577, 613, 7150, 366, 25509, 13, 51236, 51236, 583, 286, 2041, 562, 291, 434, 6416, 11, 291, 603, 1391, 360, 341, 15517, 3866, 1413, 13, 51502, 51502, 407, 613, 7150, 366, 1333, 295, 8895, 11, 411, 291, 360, 428, 659, 25111, 5633, 11, 550, 291, 1590, 11, 293, 51776, 51776], "temperature": 0.0, "avg_logprob": -0.16006345830411992, "compression_ratio": 1.8052434456928839, "no_speech_prob": 4.908375922241248e-05}, {"id": 711, "seek": 279360, "start": 2802.7999999999997, "end": 2806.56, "text": " So it's not like you stop the pretext at a certain point and then switch over to only", "tokens": [50364, 1779, 11, 370, 294, 3124, 11, 291, 603, 767, 3847, 264, 2302, 15517, 1184, 565, 11, 411, 264, 659, 25111, 50712, 50712, 293, 264, 30621, 293, 3481, 264, 3389, 13, 50824, 50824, 407, 309, 311, 406, 411, 291, 1590, 264, 659, 25111, 412, 257, 1629, 935, 293, 550, 3679, 670, 281, 787, 51012, 51012, 411, 30621, 420, 746, 13, 51084, 51084, 407, 300, 311, 5101, 577, 613, 7150, 366, 25509, 13, 51236, 51236, 583, 286, 2041, 562, 291, 434, 6416, 11, 291, 603, 1391, 360, 341, 15517, 3866, 1413, 13, 51502, 51502, 407, 613, 7150, 366, 1333, 295, 8895, 11, 411, 291, 360, 428, 659, 25111, 5633, 11, 550, 291, 1590, 11, 293, 51776, 51776], "temperature": 0.0, "avg_logprob": -0.16006345830411992, "compression_ratio": 1.8052434456928839, "no_speech_prob": 4.908375922241248e-05}, {"id": 712, "seek": 279360, "start": 2806.56, "end": 2808.0, "text": " like downstream or something.", "tokens": [50364, 1779, 11, 370, 294, 3124, 11, 291, 603, 767, 3847, 264, 2302, 15517, 1184, 565, 11, 411, 264, 659, 25111, 50712, 50712, 293, 264, 30621, 293, 3481, 264, 3389, 13, 50824, 50824, 407, 309, 311, 406, 411, 291, 1590, 264, 659, 25111, 412, 257, 1629, 935, 293, 550, 3679, 670, 281, 787, 51012, 51012, 411, 30621, 420, 746, 13, 51084, 51084, 407, 300, 311, 5101, 577, 613, 7150, 366, 25509, 13, 51236, 51236, 583, 286, 2041, 562, 291, 434, 6416, 11, 291, 603, 1391, 360, 341, 15517, 3866, 1413, 13, 51502, 51502, 407, 613, 7150, 366, 1333, 295, 8895, 11, 411, 291, 360, 428, 659, 25111, 5633, 11, 550, 291, 1590, 11, 293, 51776, 51776], "temperature": 0.0, "avg_logprob": -0.16006345830411992, "compression_ratio": 1.8052434456928839, "no_speech_prob": 4.908375922241248e-05}, {"id": 713, "seek": 279360, "start": 2808.0, "end": 2811.04, "text": " So that's generally how these methods are evaluated.", "tokens": [50364, 1779, 11, 370, 294, 3124, 11, 291, 603, 767, 3847, 264, 2302, 15517, 1184, 565, 11, 411, 264, 659, 25111, 50712, 50712, 293, 264, 30621, 293, 3481, 264, 3389, 13, 50824, 50824, 407, 309, 311, 406, 411, 291, 1590, 264, 659, 25111, 412, 257, 1629, 935, 293, 550, 3679, 670, 281, 787, 51012, 51012, 411, 30621, 420, 746, 13, 51084, 51084, 407, 300, 311, 5101, 577, 613, 7150, 366, 25509, 13, 51236, 51236, 583, 286, 2041, 562, 291, 434, 6416, 11, 291, 603, 1391, 360, 341, 15517, 3866, 1413, 13, 51502, 51502, 407, 613, 7150, 366, 1333, 295, 8895, 11, 411, 291, 360, 428, 659, 25111, 5633, 11, 550, 291, 1590, 11, 293, 51776, 51776], "temperature": 0.0, "avg_logprob": -0.16006345830411992, "compression_ratio": 1.8052434456928839, "no_speech_prob": 4.908375922241248e-05}, {"id": 714, "seek": 279360, "start": 2811.04, "end": 2816.36, "text": " But I guess when you're developing, you'll probably do this pipeline multiple times.", "tokens": [50364, 1779, 11, 370, 294, 3124, 11, 291, 603, 767, 3847, 264, 2302, 15517, 1184, 565, 11, 411, 264, 659, 25111, 50712, 50712, 293, 264, 30621, 293, 3481, 264, 3389, 13, 50824, 50824, 407, 309, 311, 406, 411, 291, 1590, 264, 659, 25111, 412, 257, 1629, 935, 293, 550, 3679, 670, 281, 787, 51012, 51012, 411, 30621, 420, 746, 13, 51084, 51084, 407, 300, 311, 5101, 577, 613, 7150, 366, 25509, 13, 51236, 51236, 583, 286, 2041, 562, 291, 434, 6416, 11, 291, 603, 1391, 360, 341, 15517, 3866, 1413, 13, 51502, 51502, 407, 613, 7150, 366, 1333, 295, 8895, 11, 411, 291, 360, 428, 659, 25111, 5633, 11, 550, 291, 1590, 11, 293, 51776, 51776], "temperature": 0.0, "avg_logprob": -0.16006345830411992, "compression_ratio": 1.8052434456928839, "no_speech_prob": 4.908375922241248e-05}, {"id": 715, "seek": 279360, "start": 2816.36, "end": 2821.8399999999997, "text": " So these methods are sort of trained, like you do your pretext task, then you stop, and", "tokens": [50364, 1779, 11, 370, 294, 3124, 11, 291, 603, 767, 3847, 264, 2302, 15517, 1184, 565, 11, 411, 264, 659, 25111, 50712, 50712, 293, 264, 30621, 293, 3481, 264, 3389, 13, 50824, 50824, 407, 309, 311, 406, 411, 291, 1590, 264, 659, 25111, 412, 257, 1629, 935, 293, 550, 3679, 670, 281, 787, 51012, 51012, 411, 30621, 420, 746, 13, 51084, 51084, 407, 300, 311, 5101, 577, 613, 7150, 366, 25509, 13, 51236, 51236, 583, 286, 2041, 562, 291, 434, 6416, 11, 291, 603, 1391, 360, 341, 15517, 3866, 1413, 13, 51502, 51502, 407, 613, 7150, 366, 1333, 295, 8895, 11, 411, 291, 360, 428, 659, 25111, 5633, 11, 550, 291, 1590, 11, 293, 51776, 51776], "temperature": 0.0, "avg_logprob": -0.16006345830411992, "compression_ratio": 1.8052434456928839, "no_speech_prob": 4.908375922241248e-05}, {"id": 716, "seek": 282184, "start": 2821.84, "end": 2823.96, "text": " then you perform your downstream evaluation task.", "tokens": [50364, 550, 291, 2042, 428, 30621, 13344, 5633, 13, 50470, 50470, 400, 300, 2709, 291, 264, 2572, 1333, 295, 13160, 295, 577, 665, 428, 659, 25111, 5633, 390, 13, 50684, 50684, 400, 300, 311, 309, 13, 50734, 50734, 509, 360, 341, 2302, 551, 1564, 13, 50840, 50840, 1779, 11, 1309, 291, 13, 51022, 51022, 400, 466, 264, 1150, 644, 295, 428, 1168, 11, 264, 544, 1589, 644, 11, 286, 603, 1333, 295, 808, 51266, 51266, 281, 309, 1780, 11, 264, 4784, 11380, 293, 370, 322, 13, 51504, 51504, 2205, 13, 51576, 51576, 407, 613, 366, 1333, 295, 264, 1045, 2135, 32191, 13, 51732, 51732], "temperature": 0.0, "avg_logprob": -0.21208051045735676, "compression_ratio": 1.6391304347826088, "no_speech_prob": 2.6841612452699337e-06}, {"id": 717, "seek": 282184, "start": 2823.96, "end": 2828.2400000000002, "text": " And that gives you the final sort of measurement of how good your pretext task was.", "tokens": [50364, 550, 291, 2042, 428, 30621, 13344, 5633, 13, 50470, 50470, 400, 300, 2709, 291, 264, 2572, 1333, 295, 13160, 295, 577, 665, 428, 659, 25111, 5633, 390, 13, 50684, 50684, 400, 300, 311, 309, 13, 50734, 50734, 509, 360, 341, 2302, 551, 1564, 13, 50840, 50840, 1779, 11, 1309, 291, 13, 51022, 51022, 400, 466, 264, 1150, 644, 295, 428, 1168, 11, 264, 544, 1589, 644, 11, 286, 603, 1333, 295, 808, 51266, 51266, 281, 309, 1780, 11, 264, 4784, 11380, 293, 370, 322, 13, 51504, 51504, 2205, 13, 51576, 51576, 407, 613, 366, 1333, 295, 264, 1045, 2135, 32191, 13, 51732, 51732], "temperature": 0.0, "avg_logprob": -0.21208051045735676, "compression_ratio": 1.6391304347826088, "no_speech_prob": 2.6841612452699337e-06}, {"id": 718, "seek": 282184, "start": 2828.2400000000002, "end": 2829.2400000000002, "text": " And that's it.", "tokens": [50364, 550, 291, 2042, 428, 30621, 13344, 5633, 13, 50470, 50470, 400, 300, 2709, 291, 264, 2572, 1333, 295, 13160, 295, 577, 665, 428, 659, 25111, 5633, 390, 13, 50684, 50684, 400, 300, 311, 309, 13, 50734, 50734, 509, 360, 341, 2302, 551, 1564, 13, 50840, 50840, 1779, 11, 1309, 291, 13, 51022, 51022, 400, 466, 264, 1150, 644, 295, 428, 1168, 11, 264, 544, 1589, 644, 11, 286, 603, 1333, 295, 808, 51266, 51266, 281, 309, 1780, 11, 264, 4784, 11380, 293, 370, 322, 13, 51504, 51504, 2205, 13, 51576, 51576, 407, 613, 366, 1333, 295, 264, 1045, 2135, 32191, 13, 51732, 51732], "temperature": 0.0, "avg_logprob": -0.21208051045735676, "compression_ratio": 1.6391304347826088, "no_speech_prob": 2.6841612452699337e-06}, {"id": 719, "seek": 282184, "start": 2829.2400000000002, "end": 2831.36, "text": " You do this entire thing once.", "tokens": [50364, 550, 291, 2042, 428, 30621, 13344, 5633, 13, 50470, 50470, 400, 300, 2709, 291, 264, 2572, 1333, 295, 13160, 295, 577, 665, 428, 659, 25111, 5633, 390, 13, 50684, 50684, 400, 300, 311, 309, 13, 50734, 50734, 509, 360, 341, 2302, 551, 1564, 13, 50840, 50840, 1779, 11, 1309, 291, 13, 51022, 51022, 400, 466, 264, 1150, 644, 295, 428, 1168, 11, 264, 544, 1589, 644, 11, 286, 603, 1333, 295, 808, 51266, 51266, 281, 309, 1780, 11, 264, 4784, 11380, 293, 370, 322, 13, 51504, 51504, 2205, 13, 51576, 51576, 407, 613, 366, 1333, 295, 264, 1045, 2135, 32191, 13, 51732, 51732], "temperature": 0.0, "avg_logprob": -0.21208051045735676, "compression_ratio": 1.6391304347826088, "no_speech_prob": 2.6841612452699337e-06}, {"id": 720, "seek": 282184, "start": 2831.36, "end": 2835.0, "text": " Right, thank you.", "tokens": [50364, 550, 291, 2042, 428, 30621, 13344, 5633, 13, 50470, 50470, 400, 300, 2709, 291, 264, 2572, 1333, 295, 13160, 295, 577, 665, 428, 659, 25111, 5633, 390, 13, 50684, 50684, 400, 300, 311, 309, 13, 50734, 50734, 509, 360, 341, 2302, 551, 1564, 13, 50840, 50840, 1779, 11, 1309, 291, 13, 51022, 51022, 400, 466, 264, 1150, 644, 295, 428, 1168, 11, 264, 544, 1589, 644, 11, 286, 603, 1333, 295, 808, 51266, 51266, 281, 309, 1780, 11, 264, 4784, 11380, 293, 370, 322, 13, 51504, 51504, 2205, 13, 51576, 51576, 407, 613, 366, 1333, 295, 264, 1045, 2135, 32191, 13, 51732, 51732], "temperature": 0.0, "avg_logprob": -0.21208051045735676, "compression_ratio": 1.6391304347826088, "no_speech_prob": 2.6841612452699337e-06}, {"id": 721, "seek": 282184, "start": 2835.0, "end": 2839.88, "text": " And about the second part of your question, the more information part, I'll sort of come", "tokens": [50364, 550, 291, 2042, 428, 30621, 13344, 5633, 13, 50470, 50470, 400, 300, 2709, 291, 264, 2572, 1333, 295, 13160, 295, 577, 665, 428, 659, 25111, 5633, 390, 13, 50684, 50684, 400, 300, 311, 309, 13, 50734, 50734, 509, 360, 341, 2302, 551, 1564, 13, 50840, 50840, 1779, 11, 1309, 291, 13, 51022, 51022, 400, 466, 264, 1150, 644, 295, 428, 1168, 11, 264, 544, 1589, 644, 11, 286, 603, 1333, 295, 808, 51266, 51266, 281, 309, 1780, 11, 264, 4784, 11380, 293, 370, 322, 13, 51504, 51504, 2205, 13, 51576, 51576, 407, 613, 366, 1333, 295, 264, 1045, 2135, 32191, 13, 51732, 51732], "temperature": 0.0, "avg_logprob": -0.21208051045735676, "compression_ratio": 1.6391304347826088, "no_speech_prob": 2.6841612452699337e-06}, {"id": 722, "seek": 282184, "start": 2839.88, "end": 2844.6400000000003, "text": " to it later, the permutation and so on.", "tokens": [50364, 550, 291, 2042, 428, 30621, 13344, 5633, 13, 50470, 50470, 400, 300, 2709, 291, 264, 2572, 1333, 295, 13160, 295, 577, 665, 428, 659, 25111, 5633, 390, 13, 50684, 50684, 400, 300, 311, 309, 13, 50734, 50734, 509, 360, 341, 2302, 551, 1564, 13, 50840, 50840, 1779, 11, 1309, 291, 13, 51022, 51022, 400, 466, 264, 1150, 644, 295, 428, 1168, 11, 264, 544, 1589, 644, 11, 286, 603, 1333, 295, 808, 51266, 51266, 281, 309, 1780, 11, 264, 4784, 11380, 293, 370, 322, 13, 51504, 51504, 2205, 13, 51576, 51576, 407, 613, 366, 1333, 295, 264, 1045, 2135, 32191, 13, 51732, 51732], "temperature": 0.0, "avg_logprob": -0.21208051045735676, "compression_ratio": 1.6391304347826088, "no_speech_prob": 2.6841612452699337e-06}, {"id": 723, "seek": 282184, "start": 2844.6400000000003, "end": 2846.08, "text": " Good.", "tokens": [50364, 550, 291, 2042, 428, 30621, 13344, 5633, 13, 50470, 50470, 400, 300, 2709, 291, 264, 2572, 1333, 295, 13160, 295, 577, 665, 428, 659, 25111, 5633, 390, 13, 50684, 50684, 400, 300, 311, 309, 13, 50734, 50734, 509, 360, 341, 2302, 551, 1564, 13, 50840, 50840, 1779, 11, 1309, 291, 13, 51022, 51022, 400, 466, 264, 1150, 644, 295, 428, 1168, 11, 264, 544, 1589, 644, 11, 286, 603, 1333, 295, 808, 51266, 51266, 281, 309, 1780, 11, 264, 4784, 11380, 293, 370, 322, 13, 51504, 51504, 2205, 13, 51576, 51576, 407, 613, 366, 1333, 295, 264, 1045, 2135, 32191, 13, 51732, 51732], "temperature": 0.0, "avg_logprob": -0.21208051045735676, "compression_ratio": 1.6391304347826088, "no_speech_prob": 2.6841612452699337e-06}, {"id": 724, "seek": 282184, "start": 2846.08, "end": 2849.2000000000003, "text": " So these are sort of the three main buckets.", "tokens": [50364, 550, 291, 2042, 428, 30621, 13344, 5633, 13, 50470, 50470, 400, 300, 2709, 291, 264, 2572, 1333, 295, 13160, 295, 577, 665, 428, 659, 25111, 5633, 390, 13, 50684, 50684, 400, 300, 311, 309, 13, 50734, 50734, 509, 360, 341, 2302, 551, 1564, 13, 50840, 50840, 1779, 11, 1309, 291, 13, 51022, 51022, 400, 466, 264, 1150, 644, 295, 428, 1168, 11, 264, 544, 1589, 644, 11, 286, 603, 1333, 295, 808, 51266, 51266, 281, 309, 1780, 11, 264, 4784, 11380, 293, 370, 322, 13, 51504, 51504, 2205, 13, 51576, 51576, 407, 613, 366, 1333, 295, 264, 1045, 2135, 32191, 13, 51732, 51732], "temperature": 0.0, "avg_logprob": -0.21208051045735676, "compression_ratio": 1.6391304347826088, "no_speech_prob": 2.6841612452699337e-06}, {"id": 725, "seek": 284920, "start": 2849.2, "end": 2854.56, "text": " And the first two are what are going to be covered basically now.", "tokens": [50364, 400, 264, 700, 732, 366, 437, 366, 516, 281, 312, 5343, 1936, 586, 13, 50632, 50632, 407, 341, 390, 1071, 589, 321, 630, 11, 597, 390, 1936, 466, 21589, 2698, 12, 48172, 24420, 2539, 13, 50892, 50892, 407, 294, 341, 1729, 589, 11, 321, 5178, 322, 732, 2740, 13, 51148, 51148, 1485, 390, 264, 2017, 2144, 1154, 300, 286, 2825, 466, 3071, 13, 51302, 51302, 400, 264, 1150, 307, 341, 544, 1333, 295, 411, 544, 1589, 17501, 295, 264, 4972, 2535, 51664, 51664, 5633, 13, 51714, 51714, 407, 341, 5633, 307, 1219, 361, 17156, 1607, 24138, 13, 51854, 51854], "temperature": 0.0, "avg_logprob": -0.0924261206447488, "compression_ratio": 1.6747967479674797, "no_speech_prob": 1.834158865676727e-05}, {"id": 726, "seek": 284920, "start": 2854.56, "end": 2859.7599999999998, "text": " So this was another work we did, which was basically about scaling self-supervised learning.", "tokens": [50364, 400, 264, 700, 732, 366, 437, 366, 516, 281, 312, 5343, 1936, 586, 13, 50632, 50632, 407, 341, 390, 1071, 589, 321, 630, 11, 597, 390, 1936, 466, 21589, 2698, 12, 48172, 24420, 2539, 13, 50892, 50892, 407, 294, 341, 1729, 589, 11, 321, 5178, 322, 732, 2740, 13, 51148, 51148, 1485, 390, 264, 2017, 2144, 1154, 300, 286, 2825, 466, 3071, 13, 51302, 51302, 400, 264, 1150, 307, 341, 544, 1333, 295, 411, 544, 1589, 17501, 295, 264, 4972, 2535, 51664, 51664, 5633, 13, 51714, 51714, 407, 341, 5633, 307, 1219, 361, 17156, 1607, 24138, 13, 51854, 51854], "temperature": 0.0, "avg_logprob": -0.0924261206447488, "compression_ratio": 1.6747967479674797, "no_speech_prob": 1.834158865676727e-05}, {"id": 727, "seek": 284920, "start": 2859.7599999999998, "end": 2864.8799999999997, "text": " So in this particular work, we focused on two problems.", "tokens": [50364, 400, 264, 700, 732, 366, 437, 366, 516, 281, 312, 5343, 1936, 586, 13, 50632, 50632, 407, 341, 390, 1071, 589, 321, 630, 11, 597, 390, 1936, 466, 21589, 2698, 12, 48172, 24420, 2539, 13, 50892, 50892, 407, 294, 341, 1729, 589, 11, 321, 5178, 322, 732, 2740, 13, 51148, 51148, 1485, 390, 264, 2017, 2144, 1154, 300, 286, 2825, 466, 3071, 13, 51302, 51302, 400, 264, 1150, 307, 341, 544, 1333, 295, 411, 544, 1589, 17501, 295, 264, 4972, 2535, 51664, 51664, 5633, 13, 51714, 51714, 407, 341, 5633, 307, 1219, 361, 17156, 1607, 24138, 13, 51854, 51854], "temperature": 0.0, "avg_logprob": -0.0924261206447488, "compression_ratio": 1.6747967479674797, "no_speech_prob": 1.834158865676727e-05}, {"id": 728, "seek": 284920, "start": 2864.8799999999997, "end": 2867.96, "text": " One was the colorization problem that I talked about earlier.", "tokens": [50364, 400, 264, 700, 732, 366, 437, 366, 516, 281, 312, 5343, 1936, 586, 13, 50632, 50632, 407, 341, 390, 1071, 589, 321, 630, 11, 597, 390, 1936, 466, 21589, 2698, 12, 48172, 24420, 2539, 13, 50892, 50892, 407, 294, 341, 1729, 589, 11, 321, 5178, 322, 732, 2740, 13, 51148, 51148, 1485, 390, 264, 2017, 2144, 1154, 300, 286, 2825, 466, 3071, 13, 51302, 51302, 400, 264, 1150, 307, 341, 544, 1333, 295, 411, 544, 1589, 17501, 295, 264, 4972, 2535, 51664, 51664, 5633, 13, 51714, 51714, 407, 341, 5633, 307, 1219, 361, 17156, 1607, 24138, 13, 51854, 51854], "temperature": 0.0, "avg_logprob": -0.0924261206447488, "compression_ratio": 1.6747967479674797, "no_speech_prob": 1.834158865676727e-05}, {"id": 729, "seek": 284920, "start": 2867.96, "end": 2875.2, "text": " And the second is this more sort of like more information variant of the relative position", "tokens": [50364, 400, 264, 700, 732, 366, 437, 366, 516, 281, 312, 5343, 1936, 586, 13, 50632, 50632, 407, 341, 390, 1071, 589, 321, 630, 11, 597, 390, 1936, 466, 21589, 2698, 12, 48172, 24420, 2539, 13, 50892, 50892, 407, 294, 341, 1729, 589, 11, 321, 5178, 322, 732, 2740, 13, 51148, 51148, 1485, 390, 264, 2017, 2144, 1154, 300, 286, 2825, 466, 3071, 13, 51302, 51302, 400, 264, 1150, 307, 341, 544, 1333, 295, 411, 544, 1589, 17501, 295, 264, 4972, 2535, 51664, 51664, 5633, 13, 51714, 51714, 407, 341, 5633, 307, 1219, 361, 17156, 1607, 24138, 13, 51854, 51854], "temperature": 0.0, "avg_logprob": -0.0924261206447488, "compression_ratio": 1.6747967479674797, "no_speech_prob": 1.834158865676727e-05}, {"id": 730, "seek": 284920, "start": 2875.2, "end": 2876.2, "text": " task.", "tokens": [50364, 400, 264, 700, 732, 366, 437, 366, 516, 281, 312, 5343, 1936, 586, 13, 50632, 50632, 407, 341, 390, 1071, 589, 321, 630, 11, 597, 390, 1936, 466, 21589, 2698, 12, 48172, 24420, 2539, 13, 50892, 50892, 407, 294, 341, 1729, 589, 11, 321, 5178, 322, 732, 2740, 13, 51148, 51148, 1485, 390, 264, 2017, 2144, 1154, 300, 286, 2825, 466, 3071, 13, 51302, 51302, 400, 264, 1150, 307, 341, 544, 1333, 295, 411, 544, 1589, 17501, 295, 264, 4972, 2535, 51664, 51664, 5633, 13, 51714, 51714, 407, 341, 5633, 307, 1219, 361, 17156, 1607, 24138, 13, 51854, 51854], "temperature": 0.0, "avg_logprob": -0.0924261206447488, "compression_ratio": 1.6747967479674797, "no_speech_prob": 1.834158865676727e-05}, {"id": 731, "seek": 284920, "start": 2876.2, "end": 2879.0, "text": " So this task is called jigsaw puzzles.", "tokens": [50364, 400, 264, 700, 732, 366, 437, 366, 516, 281, 312, 5343, 1936, 586, 13, 50632, 50632, 407, 341, 390, 1071, 589, 321, 630, 11, 597, 390, 1936, 466, 21589, 2698, 12, 48172, 24420, 2539, 13, 50892, 50892, 407, 294, 341, 1729, 589, 11, 321, 5178, 322, 732, 2740, 13, 51148, 51148, 1485, 390, 264, 2017, 2144, 1154, 300, 286, 2825, 466, 3071, 13, 51302, 51302, 400, 264, 1150, 307, 341, 544, 1333, 295, 411, 544, 1589, 17501, 295, 264, 4972, 2535, 51664, 51664, 5633, 13, 51714, 51714, 407, 341, 5633, 307, 1219, 361, 17156, 1607, 24138, 13, 51854, 51854], "temperature": 0.0, "avg_logprob": -0.0924261206447488, "compression_ratio": 1.6747967479674797, "no_speech_prob": 1.834158865676727e-05}, {"id": 732, "seek": 287900, "start": 2879.0, "end": 2883.24, "text": " The idea is that you take an image and you split it into multiple different patches,", "tokens": [50364, 440, 1558, 307, 300, 291, 747, 364, 3256, 293, 291, 7472, 309, 666, 3866, 819, 26531, 11, 50576, 50576, 293, 291, 853, 281, 6069, 2293, 11, 293, 550, 291, 39426, 613, 26531, 1936, 538, 257, 4784, 11380, 13, 50820, 50820, 400, 550, 291, 6069, 597, 4784, 11380, 390, 6456, 281, 264, 4846, 13, 50988, 50988, 407, 300, 311, 588, 2531, 281, 437, 1160, 7950, 296, 390, 18094, 3071, 13, 51194, 51194, 1057, 558, 13, 51354, 51354, 407, 264, 636, 291, 5039, 341, 1154, 307, 291, 747, 11, 584, 294, 341, 1389, 11, 1045, 26531, 13, 51612, 51612, 509, 3154, 2128, 1184, 472, 295, 613, 26531, 21761, 13, 51740, 51740], "temperature": 0.0, "avg_logprob": -0.1764166548445418, "compression_ratio": 1.7538461538461538, "no_speech_prob": 1.2805113328795414e-05}, {"id": 733, "seek": 287900, "start": 2883.24, "end": 2888.12, "text": " and you try to predict exactly, and then you shuffle these patches basically by a permutation.", "tokens": [50364, 440, 1558, 307, 300, 291, 747, 364, 3256, 293, 291, 7472, 309, 666, 3866, 819, 26531, 11, 50576, 50576, 293, 291, 853, 281, 6069, 2293, 11, 293, 550, 291, 39426, 613, 26531, 1936, 538, 257, 4784, 11380, 13, 50820, 50820, 400, 550, 291, 6069, 597, 4784, 11380, 390, 6456, 281, 264, 4846, 13, 50988, 50988, 407, 300, 311, 588, 2531, 281, 437, 1160, 7950, 296, 390, 18094, 3071, 13, 51194, 51194, 1057, 558, 13, 51354, 51354, 407, 264, 636, 291, 5039, 341, 1154, 307, 291, 747, 11, 584, 294, 341, 1389, 11, 1045, 26531, 13, 51612, 51612, 509, 3154, 2128, 1184, 472, 295, 613, 26531, 21761, 13, 51740, 51740], "temperature": 0.0, "avg_logprob": -0.1764166548445418, "compression_ratio": 1.7538461538461538, "no_speech_prob": 1.2805113328795414e-05}, {"id": 734, "seek": 287900, "start": 2888.12, "end": 2891.48, "text": " And then you predict which permutation was applied to the input.", "tokens": [50364, 440, 1558, 307, 300, 291, 747, 364, 3256, 293, 291, 7472, 309, 666, 3866, 819, 26531, 11, 50576, 50576, 293, 291, 853, 281, 6069, 2293, 11, 293, 550, 291, 39426, 613, 26531, 1936, 538, 257, 4784, 11380, 13, 50820, 50820, 400, 550, 291, 6069, 597, 4784, 11380, 390, 6456, 281, 264, 4846, 13, 50988, 50988, 407, 300, 311, 588, 2531, 281, 437, 1160, 7950, 296, 390, 18094, 3071, 13, 51194, 51194, 1057, 558, 13, 51354, 51354, 407, 264, 636, 291, 5039, 341, 1154, 307, 291, 747, 11, 584, 294, 341, 1389, 11, 1045, 26531, 13, 51612, 51612, 509, 3154, 2128, 1184, 472, 295, 613, 26531, 21761, 13, 51740, 51740], "temperature": 0.0, "avg_logprob": -0.1764166548445418, "compression_ratio": 1.7538461538461538, "no_speech_prob": 1.2805113328795414e-05}, {"id": 735, "seek": 287900, "start": 2891.48, "end": 2895.6, "text": " So that's very similar to what Shreyas was suggesting earlier.", "tokens": [50364, 440, 1558, 307, 300, 291, 747, 364, 3256, 293, 291, 7472, 309, 666, 3866, 819, 26531, 11, 50576, 50576, 293, 291, 853, 281, 6069, 2293, 11, 293, 550, 291, 39426, 613, 26531, 1936, 538, 257, 4784, 11380, 13, 50820, 50820, 400, 550, 291, 6069, 597, 4784, 11380, 390, 6456, 281, 264, 4846, 13, 50988, 50988, 407, 300, 311, 588, 2531, 281, 437, 1160, 7950, 296, 390, 18094, 3071, 13, 51194, 51194, 1057, 558, 13, 51354, 51354, 407, 264, 636, 291, 5039, 341, 1154, 307, 291, 747, 11, 584, 294, 341, 1389, 11, 1045, 26531, 13, 51612, 51612, 509, 3154, 2128, 1184, 472, 295, 613, 26531, 21761, 13, 51740, 51740], "temperature": 0.0, "avg_logprob": -0.1764166548445418, "compression_ratio": 1.7538461538461538, "no_speech_prob": 1.2805113328795414e-05}, {"id": 736, "seek": 287900, "start": 2895.6, "end": 2898.8, "text": " All right.", "tokens": [50364, 440, 1558, 307, 300, 291, 747, 364, 3256, 293, 291, 7472, 309, 666, 3866, 819, 26531, 11, 50576, 50576, 293, 291, 853, 281, 6069, 2293, 11, 293, 550, 291, 39426, 613, 26531, 1936, 538, 257, 4784, 11380, 13, 50820, 50820, 400, 550, 291, 6069, 597, 4784, 11380, 390, 6456, 281, 264, 4846, 13, 50988, 50988, 407, 300, 311, 588, 2531, 281, 437, 1160, 7950, 296, 390, 18094, 3071, 13, 51194, 51194, 1057, 558, 13, 51354, 51354, 407, 264, 636, 291, 5039, 341, 1154, 307, 291, 747, 11, 584, 294, 341, 1389, 11, 1045, 26531, 13, 51612, 51612, 509, 3154, 2128, 1184, 472, 295, 613, 26531, 21761, 13, 51740, 51740], "temperature": 0.0, "avg_logprob": -0.1764166548445418, "compression_ratio": 1.7538461538461538, "no_speech_prob": 1.2805113328795414e-05}, {"id": 737, "seek": 287900, "start": 2898.8, "end": 2903.96, "text": " So the way you solve this problem is you take, say in this case, three patches.", "tokens": [50364, 440, 1558, 307, 300, 291, 747, 364, 3256, 293, 291, 7472, 309, 666, 3866, 819, 26531, 11, 50576, 50576, 293, 291, 853, 281, 6069, 2293, 11, 293, 550, 291, 39426, 613, 26531, 1936, 538, 257, 4784, 11380, 13, 50820, 50820, 400, 550, 291, 6069, 597, 4784, 11380, 390, 6456, 281, 264, 4846, 13, 50988, 50988, 407, 300, 311, 588, 2531, 281, 437, 1160, 7950, 296, 390, 18094, 3071, 13, 51194, 51194, 1057, 558, 13, 51354, 51354, 407, 264, 636, 291, 5039, 341, 1154, 307, 291, 747, 11, 584, 294, 341, 1389, 11, 1045, 26531, 13, 51612, 51612, 509, 3154, 2128, 1184, 472, 295, 613, 26531, 21761, 13, 51740, 51740], "temperature": 0.0, "avg_logprob": -0.1764166548445418, "compression_ratio": 1.7538461538461538, "no_speech_prob": 1.2805113328795414e-05}, {"id": 738, "seek": 287900, "start": 2903.96, "end": 2906.52, "text": " You feed forward each one of these patches independently.", "tokens": [50364, 440, 1558, 307, 300, 291, 747, 364, 3256, 293, 291, 7472, 309, 666, 3866, 819, 26531, 11, 50576, 50576, 293, 291, 853, 281, 6069, 2293, 11, 293, 550, 291, 39426, 613, 26531, 1936, 538, 257, 4784, 11380, 13, 50820, 50820, 400, 550, 291, 6069, 597, 4784, 11380, 390, 6456, 281, 264, 4846, 13, 50988, 50988, 407, 300, 311, 588, 2531, 281, 437, 1160, 7950, 296, 390, 18094, 3071, 13, 51194, 51194, 1057, 558, 13, 51354, 51354, 407, 264, 636, 291, 5039, 341, 1154, 307, 291, 747, 11, 584, 294, 341, 1389, 11, 1045, 26531, 13, 51612, 51612, 509, 3154, 2128, 1184, 472, 295, 613, 26531, 21761, 13, 51740, 51740], "temperature": 0.0, "avg_logprob": -0.1764166548445418, "compression_ratio": 1.7538461538461538, "no_speech_prob": 1.2805113328795414e-05}, {"id": 739, "seek": 290652, "start": 2906.52, "end": 2910.92, "text": " You concatenate their feature, and then you classify which permutation was basically used", "tokens": [50364, 509, 1588, 7186, 473, 641, 4111, 11, 293, 550, 291, 33872, 597, 4784, 11380, 390, 1936, 1143, 50584, 50584, 281, 4784, 1169, 613, 4846, 26531, 13, 50744, 50744, 823, 264, 16552, 1143, 4949, 26531, 281, 5039, 341, 1154, 13, 50952, 50952, 400, 300, 311, 1936, 516, 281, 312, 4949, 36916, 11, 597, 307, 13898, 11, 1360, 1230, 295, 4784, 325, 763, 13, 51312, 51312, 2720, 1164, 11, 562, 291, 434, 1382, 281, 2042, 341, 21538, 412, 264, 917, 11, 341, 1355, 300, 51504, 51504, 428, 4498, 4582, 4583, 820, 362, 13898, 11, 1360, 5598, 22027, 11, 597, 307, 257, 588, 2416, 1230, 13, 51822, 51822], "temperature": 0.0, "avg_logprob": -0.105722534322293, "compression_ratio": 1.7307692307692308, "no_speech_prob": 4.8603515097056516e-06}, {"id": 740, "seek": 290652, "start": 2910.92, "end": 2914.12, "text": " to permute these input patches.", "tokens": [50364, 509, 1588, 7186, 473, 641, 4111, 11, 293, 550, 291, 33872, 597, 4784, 11380, 390, 1936, 1143, 50584, 50584, 281, 4784, 1169, 613, 4846, 26531, 13, 50744, 50744, 823, 264, 16552, 1143, 4949, 26531, 281, 5039, 341, 1154, 13, 50952, 50952, 400, 300, 311, 1936, 516, 281, 312, 4949, 36916, 11, 597, 307, 13898, 11, 1360, 1230, 295, 4784, 325, 763, 13, 51312, 51312, 2720, 1164, 11, 562, 291, 434, 1382, 281, 2042, 341, 21538, 412, 264, 917, 11, 341, 1355, 300, 51504, 51504, 428, 4498, 4582, 4583, 820, 362, 13898, 11, 1360, 5598, 22027, 11, 597, 307, 257, 588, 2416, 1230, 13, 51822, 51822], "temperature": 0.0, "avg_logprob": -0.105722534322293, "compression_ratio": 1.7307692307692308, "no_speech_prob": 4.8603515097056516e-06}, {"id": 741, "seek": 290652, "start": 2914.12, "end": 2918.28, "text": " Now the authors used nine patches to solve this problem.", "tokens": [50364, 509, 1588, 7186, 473, 641, 4111, 11, 293, 550, 291, 33872, 597, 4784, 11380, 390, 1936, 1143, 50584, 50584, 281, 4784, 1169, 613, 4846, 26531, 13, 50744, 50744, 823, 264, 16552, 1143, 4949, 26531, 281, 5039, 341, 1154, 13, 50952, 50952, 400, 300, 311, 1936, 516, 281, 312, 4949, 36916, 11, 597, 307, 13898, 11, 1360, 1230, 295, 4784, 325, 763, 13, 51312, 51312, 2720, 1164, 11, 562, 291, 434, 1382, 281, 2042, 341, 21538, 412, 264, 917, 11, 341, 1355, 300, 51504, 51504, 428, 4498, 4582, 4583, 820, 362, 13898, 11, 1360, 5598, 22027, 11, 597, 307, 257, 588, 2416, 1230, 13, 51822, 51822], "temperature": 0.0, "avg_logprob": -0.105722534322293, "compression_ratio": 1.7307692307692308, "no_speech_prob": 4.8603515097056516e-06}, {"id": 742, "seek": 290652, "start": 2918.28, "end": 2925.48, "text": " And that's basically going to be nine factorial, which is 360,000 number of permutations.", "tokens": [50364, 509, 1588, 7186, 473, 641, 4111, 11, 293, 550, 291, 33872, 597, 4784, 11380, 390, 1936, 1143, 50584, 50584, 281, 4784, 1169, 613, 4846, 26531, 13, 50744, 50744, 823, 264, 16552, 1143, 4949, 26531, 281, 5039, 341, 1154, 13, 50952, 50952, 400, 300, 311, 1936, 516, 281, 312, 4949, 36916, 11, 597, 307, 13898, 11, 1360, 1230, 295, 4784, 325, 763, 13, 51312, 51312, 2720, 1164, 11, 562, 291, 434, 1382, 281, 2042, 341, 21538, 412, 264, 917, 11, 341, 1355, 300, 51504, 51504, 428, 4498, 4582, 4583, 820, 362, 13898, 11, 1360, 5598, 22027, 11, 597, 307, 257, 588, 2416, 1230, 13, 51822, 51822], "temperature": 0.0, "avg_logprob": -0.105722534322293, "compression_ratio": 1.7307692307692308, "no_speech_prob": 4.8603515097056516e-06}, {"id": 743, "seek": 290652, "start": 2925.48, "end": 2929.32, "text": " Of course, when you're trying to perform this classification at the end, this means that", "tokens": [50364, 509, 1588, 7186, 473, 641, 4111, 11, 293, 550, 291, 33872, 597, 4784, 11380, 390, 1936, 1143, 50584, 50584, 281, 4784, 1169, 613, 4846, 26531, 13, 50744, 50744, 823, 264, 16552, 1143, 4949, 26531, 281, 5039, 341, 1154, 13, 50952, 50952, 400, 300, 311, 1936, 516, 281, 312, 4949, 36916, 11, 597, 307, 13898, 11, 1360, 1230, 295, 4784, 325, 763, 13, 51312, 51312, 2720, 1164, 11, 562, 291, 434, 1382, 281, 2042, 341, 21538, 412, 264, 917, 11, 341, 1355, 300, 51504, 51504, 428, 4498, 4582, 4583, 820, 362, 13898, 11, 1360, 5598, 22027, 11, 597, 307, 257, 588, 2416, 1230, 13, 51822, 51822], "temperature": 0.0, "avg_logprob": -0.105722534322293, "compression_ratio": 1.7307692307692308, "no_speech_prob": 4.8603515097056516e-06}, {"id": 744, "seek": 290652, "start": 2929.32, "end": 2935.68, "text": " your fully connected layer should have 360,000 output neurons, which is a very large number.", "tokens": [50364, 509, 1588, 7186, 473, 641, 4111, 11, 293, 550, 291, 33872, 597, 4784, 11380, 390, 1936, 1143, 50584, 50584, 281, 4784, 1169, 613, 4846, 26531, 13, 50744, 50744, 823, 264, 16552, 1143, 4949, 26531, 281, 5039, 341, 1154, 13, 50952, 50952, 400, 300, 311, 1936, 516, 281, 312, 4949, 36916, 11, 597, 307, 13898, 11, 1360, 1230, 295, 4784, 325, 763, 13, 51312, 51312, 2720, 1164, 11, 562, 291, 434, 1382, 281, 2042, 341, 21538, 412, 264, 917, 11, 341, 1355, 300, 51504, 51504, 428, 4498, 4582, 4583, 820, 362, 13898, 11, 1360, 5598, 22027, 11, 597, 307, 257, 588, 2416, 1230, 13, 51822, 51822], "temperature": 0.0, "avg_logprob": -0.105722534322293, "compression_ratio": 1.7307692307692308, "no_speech_prob": 4.8603515097056516e-06}, {"id": 745, "seek": 293568, "start": 2935.68, "end": 2942.7999999999997, "text": " So in practice, what the authors did was basically have a subset of permutations that they use.", "tokens": [50364, 407, 294, 3124, 11, 437, 264, 16552, 630, 390, 1936, 362, 257, 25993, 295, 4784, 325, 763, 300, 436, 764, 13, 50720, 50720, 407, 584, 436, 6889, 2319, 4784, 325, 763, 490, 264, 4949, 36916, 4784, 325, 763, 11, 293, 550, 445, 51010, 51010, 362, 341, 2042, 341, 2319, 636, 21538, 13, 51223, 51223, 407, 294, 512, 636, 11, 291, 393, 574, 412, 264, 2744, 295, 341, 25993, 382, 264, 1154, 14024, 420, 264, 51510, 51510, 2372, 295, 1589, 300, 291, 434, 32884, 13, 51621, 51621, 759, 291, 6069, 264, 1577, 4949, 36916, 551, 11, 291, 434, 767, 12606, 11, 291, 434, 1936, 51826, 51826], "temperature": 0.0, "avg_logprob": -0.14388136997401157, "compression_ratio": 1.8414634146341464, "no_speech_prob": 6.339102583297063e-06}, {"id": 746, "seek": 293568, "start": 2942.7999999999997, "end": 2948.6, "text": " So say they sample 100 permutations from the nine factorial permutations, and then just", "tokens": [50364, 407, 294, 3124, 11, 437, 264, 16552, 630, 390, 1936, 362, 257, 25993, 295, 4784, 325, 763, 300, 436, 764, 13, 50720, 50720, 407, 584, 436, 6889, 2319, 4784, 325, 763, 490, 264, 4949, 36916, 4784, 325, 763, 11, 293, 550, 445, 51010, 51010, 362, 341, 2042, 341, 2319, 636, 21538, 13, 51223, 51223, 407, 294, 512, 636, 11, 291, 393, 574, 412, 264, 2744, 295, 341, 25993, 382, 264, 1154, 14024, 420, 264, 51510, 51510, 2372, 295, 1589, 300, 291, 434, 32884, 13, 51621, 51621, 759, 291, 6069, 264, 1577, 4949, 36916, 551, 11, 291, 434, 767, 12606, 11, 291, 434, 1936, 51826, 51826], "temperature": 0.0, "avg_logprob": -0.14388136997401157, "compression_ratio": 1.8414634146341464, "no_speech_prob": 6.339102583297063e-06}, {"id": 747, "seek": 293568, "start": 2948.6, "end": 2952.8599999999997, "text": " have this perform this 100 way classification.", "tokens": [50364, 407, 294, 3124, 11, 437, 264, 16552, 630, 390, 1936, 362, 257, 25993, 295, 4784, 325, 763, 300, 436, 764, 13, 50720, 50720, 407, 584, 436, 6889, 2319, 4784, 325, 763, 490, 264, 4949, 36916, 4784, 325, 763, 11, 293, 550, 445, 51010, 51010, 362, 341, 2042, 341, 2319, 636, 21538, 13, 51223, 51223, 407, 294, 512, 636, 11, 291, 393, 574, 412, 264, 2744, 295, 341, 25993, 382, 264, 1154, 14024, 420, 264, 51510, 51510, 2372, 295, 1589, 300, 291, 434, 32884, 13, 51621, 51621, 759, 291, 6069, 264, 1577, 4949, 36916, 551, 11, 291, 434, 767, 12606, 11, 291, 434, 1936, 51826, 51826], "temperature": 0.0, "avg_logprob": -0.14388136997401157, "compression_ratio": 1.8414634146341464, "no_speech_prob": 6.339102583297063e-06}, {"id": 748, "seek": 293568, "start": 2952.8599999999997, "end": 2958.6, "text": " So in some way, you can look at the size of this subset as the problem complexity or the", "tokens": [50364, 407, 294, 3124, 11, 437, 264, 16552, 630, 390, 1936, 362, 257, 25993, 295, 4784, 325, 763, 300, 436, 764, 13, 50720, 50720, 407, 584, 436, 6889, 2319, 4784, 325, 763, 490, 264, 4949, 36916, 4784, 325, 763, 11, 293, 550, 445, 51010, 51010, 362, 341, 2042, 341, 2319, 636, 21538, 13, 51223, 51223, 407, 294, 512, 636, 11, 291, 393, 574, 412, 264, 2744, 295, 341, 25993, 382, 264, 1154, 14024, 420, 264, 51510, 51510, 2372, 295, 1589, 300, 291, 434, 32884, 13, 51621, 51621, 759, 291, 6069, 264, 1577, 4949, 36916, 551, 11, 291, 434, 767, 12606, 11, 291, 434, 1936, 51826, 51826], "temperature": 0.0, "avg_logprob": -0.14388136997401157, "compression_ratio": 1.8414634146341464, "no_speech_prob": 6.339102583297063e-06}, {"id": 749, "seek": 293568, "start": 2958.6, "end": 2960.8199999999997, "text": " amount of information that you're predicting.", "tokens": [50364, 407, 294, 3124, 11, 437, 264, 16552, 630, 390, 1936, 362, 257, 25993, 295, 4784, 325, 763, 300, 436, 764, 13, 50720, 50720, 407, 584, 436, 6889, 2319, 4784, 325, 763, 490, 264, 4949, 36916, 4784, 325, 763, 11, 293, 550, 445, 51010, 51010, 362, 341, 2042, 341, 2319, 636, 21538, 13, 51223, 51223, 407, 294, 512, 636, 11, 291, 393, 574, 412, 264, 2744, 295, 341, 25993, 382, 264, 1154, 14024, 420, 264, 51510, 51510, 2372, 295, 1589, 300, 291, 434, 32884, 13, 51621, 51621, 759, 291, 6069, 264, 1577, 4949, 36916, 551, 11, 291, 434, 767, 12606, 11, 291, 434, 1936, 51826, 51826], "temperature": 0.0, "avg_logprob": -0.14388136997401157, "compression_ratio": 1.8414634146341464, "no_speech_prob": 6.339102583297063e-06}, {"id": 750, "seek": 293568, "start": 2960.8199999999997, "end": 2964.9199999999996, "text": " If you predict the full nine factorial thing, you're actually solving, you're basically", "tokens": [50364, 407, 294, 3124, 11, 437, 264, 16552, 630, 390, 1936, 362, 257, 25993, 295, 4784, 325, 763, 300, 436, 764, 13, 50720, 50720, 407, 584, 436, 6889, 2319, 4784, 325, 763, 490, 264, 4949, 36916, 4784, 325, 763, 11, 293, 550, 445, 51010, 51010, 362, 341, 2042, 341, 2319, 636, 21538, 13, 51223, 51223, 407, 294, 512, 636, 11, 291, 393, 574, 412, 264, 2744, 295, 341, 25993, 382, 264, 1154, 14024, 420, 264, 51510, 51510, 2372, 295, 1589, 300, 291, 434, 32884, 13, 51621, 51621, 759, 291, 6069, 264, 1577, 4949, 36916, 551, 11, 291, 434, 767, 12606, 11, 291, 434, 1936, 51826, 51826], "temperature": 0.0, "avg_logprob": -0.14388136997401157, "compression_ratio": 1.8414634146341464, "no_speech_prob": 6.339102583297063e-06}, {"id": 751, "seek": 296492, "start": 2964.92, "end": 2967.28, "text": " predicting a lot of information at the output.", "tokens": [50364, 32884, 257, 688, 295, 1589, 412, 264, 5598, 13, 50482, 50482, 759, 291, 787, 1422, 6889, 11, 584, 732, 420, 1045, 4784, 325, 763, 11, 550, 291, 434, 1936, 406, 32884, 257, 688, 50668, 50668, 295, 1589, 13, 50718, 50718, 407, 264, 1154, 1936, 2170, 6081, 293, 6081, 382, 264, 2744, 295, 264, 25993, 8637, 13, 51024, 51024, 407, 294, 341, 3035, 11, 321, 1936, 1415, 281, 2979, 264, 2302, 3090, 295, 577, 709, 1589, 300, 51318, 51318, 291, 6069, 293, 577, 665, 307, 264, 2572, 10290, 300, 291, 1466, 13, 51532, 51532, 407, 294, 2115, 295, 13344, 11, 456, 366, 732, 2098, 281, 1333, 295, 13059, 1564, 291, 362, 257, 2698, 46533, 51852, 51852], "temperature": 0.0, "avg_logprob": -0.10113965548001803, "compression_ratio": 1.894736842105263, "no_speech_prob": 9.818224498303607e-06}, {"id": 752, "seek": 296492, "start": 2967.28, "end": 2971.0, "text": " If you only sub sample, say two or three permutations, then you're basically not predicting a lot", "tokens": [50364, 32884, 257, 688, 295, 1589, 412, 264, 5598, 13, 50482, 50482, 759, 291, 787, 1422, 6889, 11, 584, 732, 420, 1045, 4784, 325, 763, 11, 550, 291, 434, 1936, 406, 32884, 257, 688, 50668, 50668, 295, 1589, 13, 50718, 50718, 407, 264, 1154, 1936, 2170, 6081, 293, 6081, 382, 264, 2744, 295, 264, 25993, 8637, 13, 51024, 51024, 407, 294, 341, 3035, 11, 321, 1936, 1415, 281, 2979, 264, 2302, 3090, 295, 577, 709, 1589, 300, 51318, 51318, 291, 6069, 293, 577, 665, 307, 264, 2572, 10290, 300, 291, 1466, 13, 51532, 51532, 407, 294, 2115, 295, 13344, 11, 456, 366, 732, 2098, 281, 1333, 295, 13059, 1564, 291, 362, 257, 2698, 46533, 51852, 51852], "temperature": 0.0, "avg_logprob": -0.10113965548001803, "compression_ratio": 1.894736842105263, "no_speech_prob": 9.818224498303607e-06}, {"id": 753, "seek": 296492, "start": 2971.0, "end": 2972.0, "text": " of information.", "tokens": [50364, 32884, 257, 688, 295, 1589, 412, 264, 5598, 13, 50482, 50482, 759, 291, 787, 1422, 6889, 11, 584, 732, 420, 1045, 4784, 325, 763, 11, 550, 291, 434, 1936, 406, 32884, 257, 688, 50668, 50668, 295, 1589, 13, 50718, 50718, 407, 264, 1154, 1936, 2170, 6081, 293, 6081, 382, 264, 2744, 295, 264, 25993, 8637, 13, 51024, 51024, 407, 294, 341, 3035, 11, 321, 1936, 1415, 281, 2979, 264, 2302, 3090, 295, 577, 709, 1589, 300, 51318, 51318, 291, 6069, 293, 577, 665, 307, 264, 2572, 10290, 300, 291, 1466, 13, 51532, 51532, 407, 294, 2115, 295, 13344, 11, 456, 366, 732, 2098, 281, 1333, 295, 13059, 1564, 291, 362, 257, 2698, 46533, 51852, 51852], "temperature": 0.0, "avg_logprob": -0.10113965548001803, "compression_ratio": 1.894736842105263, "no_speech_prob": 9.818224498303607e-06}, {"id": 754, "seek": 296492, "start": 2972.0, "end": 2978.12, "text": " So the problem basically gets harder and harder as the size of the subset increases.", "tokens": [50364, 32884, 257, 688, 295, 1589, 412, 264, 5598, 13, 50482, 50482, 759, 291, 787, 1422, 6889, 11, 584, 732, 420, 1045, 4784, 325, 763, 11, 550, 291, 434, 1936, 406, 32884, 257, 688, 50668, 50668, 295, 1589, 13, 50718, 50718, 407, 264, 1154, 1936, 2170, 6081, 293, 6081, 382, 264, 2744, 295, 264, 25993, 8637, 13, 51024, 51024, 407, 294, 341, 3035, 11, 321, 1936, 1415, 281, 2979, 264, 2302, 3090, 295, 577, 709, 1589, 300, 51318, 51318, 291, 6069, 293, 577, 665, 307, 264, 2572, 10290, 300, 291, 1466, 13, 51532, 51532, 407, 294, 2115, 295, 13344, 11, 456, 366, 732, 2098, 281, 1333, 295, 13059, 1564, 291, 362, 257, 2698, 46533, 51852, 51852], "temperature": 0.0, "avg_logprob": -0.10113965548001803, "compression_ratio": 1.894736842105263, "no_speech_prob": 9.818224498303607e-06}, {"id": 755, "seek": 296492, "start": 2978.12, "end": 2984.0, "text": " So in this paper, we basically wanted to study the entire role of how much information that", "tokens": [50364, 32884, 257, 688, 295, 1589, 412, 264, 5598, 13, 50482, 50482, 759, 291, 787, 1422, 6889, 11, 584, 732, 420, 1045, 4784, 325, 763, 11, 550, 291, 434, 1936, 406, 32884, 257, 688, 50668, 50668, 295, 1589, 13, 50718, 50718, 407, 264, 1154, 1936, 2170, 6081, 293, 6081, 382, 264, 2744, 295, 264, 25993, 8637, 13, 51024, 51024, 407, 294, 341, 3035, 11, 321, 1936, 1415, 281, 2979, 264, 2302, 3090, 295, 577, 709, 1589, 300, 51318, 51318, 291, 6069, 293, 577, 665, 307, 264, 2572, 10290, 300, 291, 1466, 13, 51532, 51532, 407, 294, 2115, 295, 13344, 11, 456, 366, 732, 2098, 281, 1333, 295, 13059, 1564, 291, 362, 257, 2698, 46533, 51852, 51852], "temperature": 0.0, "avg_logprob": -0.10113965548001803, "compression_ratio": 1.894736842105263, "no_speech_prob": 9.818224498303607e-06}, {"id": 756, "seek": 296492, "start": 2984.0, "end": 2988.28, "text": " you predict and how good is the final representation that you learn.", "tokens": [50364, 32884, 257, 688, 295, 1589, 412, 264, 5598, 13, 50482, 50482, 759, 291, 787, 1422, 6889, 11, 584, 732, 420, 1045, 4784, 325, 763, 11, 550, 291, 434, 1936, 406, 32884, 257, 688, 50668, 50668, 295, 1589, 13, 50718, 50718, 407, 264, 1154, 1936, 2170, 6081, 293, 6081, 382, 264, 2744, 295, 264, 25993, 8637, 13, 51024, 51024, 407, 294, 341, 3035, 11, 321, 1936, 1415, 281, 2979, 264, 2302, 3090, 295, 577, 709, 1589, 300, 51318, 51318, 291, 6069, 293, 577, 665, 307, 264, 2572, 10290, 300, 291, 1466, 13, 51532, 51532, 407, 294, 2115, 295, 13344, 11, 456, 366, 732, 2098, 281, 1333, 295, 13059, 1564, 291, 362, 257, 2698, 46533, 51852, 51852], "temperature": 0.0, "avg_logprob": -0.10113965548001803, "compression_ratio": 1.894736842105263, "no_speech_prob": 9.818224498303607e-06}, {"id": 757, "seek": 296492, "start": 2988.28, "end": 2994.6800000000003, "text": " So in terms of evaluation, there are two ways to sort of evaluate once you have a self supervised", "tokens": [50364, 32884, 257, 688, 295, 1589, 412, 264, 5598, 13, 50482, 50482, 759, 291, 787, 1422, 6889, 11, 584, 732, 420, 1045, 4784, 325, 763, 11, 550, 291, 434, 1936, 406, 32884, 257, 688, 50668, 50668, 295, 1589, 13, 50718, 50718, 407, 264, 1154, 1936, 2170, 6081, 293, 6081, 382, 264, 2744, 295, 264, 25993, 8637, 13, 51024, 51024, 407, 294, 341, 3035, 11, 321, 1936, 1415, 281, 2979, 264, 2302, 3090, 295, 577, 709, 1589, 300, 51318, 51318, 291, 6069, 293, 577, 665, 307, 264, 2572, 10290, 300, 291, 1466, 13, 51532, 51532, 407, 294, 2115, 295, 13344, 11, 456, 366, 732, 2098, 281, 1333, 295, 13059, 1564, 291, 362, 257, 2698, 46533, 51852, 51852], "temperature": 0.0, "avg_logprob": -0.10113965548001803, "compression_ratio": 1.894736842105263, "no_speech_prob": 9.818224498303607e-06}, {"id": 758, "seek": 299468, "start": 2994.68, "end": 2996.08, "text": " written network.", "tokens": [50364, 3720, 3209, 13, 50434, 50434, 400, 456, 311, 920, 257, 688, 295, 7958, 322, 597, 472, 307, 2293, 264, 558, 3170, 281, 13059, 50608, 50608, 9590, 13, 50690, 50690, 407, 264, 700, 636, 307, 281, 1936, 2489, 10864, 439, 264, 7914, 295, 257, 3209, 13, 50899, 50899, 407, 291, 362, 257, 30621, 5633, 11, 584, 10774, 35701, 11, 420, 584, 3256, 21538, 13, 51164, 51164, 509, 3847, 341, 3209, 293, 291, 5623, 439, 264, 9834, 295, 341, 3209, 337, 264, 30621, 51362, 51362, 5633, 13, 51435, 51435, 440, 1150, 636, 307, 281, 445, 764, 428, 3209, 382, 257, 4111, 8947, 284, 13, 51645, 51645, 407, 291, 1936, 1190, 428, 5267, 807, 309, 11, 291, 483, 428, 4111, 10290, 11, 293, 586, 51826, 51826], "temperature": 0.0, "avg_logprob": -0.13174899291992187, "compression_ratio": 1.8280701754385964, "no_speech_prob": 5.422111826192122e-06}, {"id": 759, "seek": 299468, "start": 2996.08, "end": 2999.56, "text": " And there's still a lot of debate on which one is exactly the right method to evaluate", "tokens": [50364, 3720, 3209, 13, 50434, 50434, 400, 456, 311, 920, 257, 688, 295, 7958, 322, 597, 472, 307, 2293, 264, 558, 3170, 281, 13059, 50608, 50608, 9590, 13, 50690, 50690, 407, 264, 700, 636, 307, 281, 1936, 2489, 10864, 439, 264, 7914, 295, 257, 3209, 13, 50899, 50899, 407, 291, 362, 257, 30621, 5633, 11, 584, 10774, 35701, 11, 420, 584, 3256, 21538, 13, 51164, 51164, 509, 3847, 341, 3209, 293, 291, 5623, 439, 264, 9834, 295, 341, 3209, 337, 264, 30621, 51362, 51362, 5633, 13, 51435, 51435, 440, 1150, 636, 307, 281, 445, 764, 428, 3209, 382, 257, 4111, 8947, 284, 13, 51645, 51645, 407, 291, 1936, 1190, 428, 5267, 807, 309, 11, 291, 483, 428, 4111, 10290, 11, 293, 586, 51826, 51826], "temperature": 0.0, "avg_logprob": -0.13174899291992187, "compression_ratio": 1.8280701754385964, "no_speech_prob": 5.422111826192122e-06}, {"id": 760, "seek": 299468, "start": 2999.56, "end": 3001.2, "text": " networks.", "tokens": [50364, 3720, 3209, 13, 50434, 50434, 400, 456, 311, 920, 257, 688, 295, 7958, 322, 597, 472, 307, 2293, 264, 558, 3170, 281, 13059, 50608, 50608, 9590, 13, 50690, 50690, 407, 264, 700, 636, 307, 281, 1936, 2489, 10864, 439, 264, 7914, 295, 257, 3209, 13, 50899, 50899, 407, 291, 362, 257, 30621, 5633, 11, 584, 10774, 35701, 11, 420, 584, 3256, 21538, 13, 51164, 51164, 509, 3847, 341, 3209, 293, 291, 5623, 439, 264, 9834, 295, 341, 3209, 337, 264, 30621, 51362, 51362, 5633, 13, 51435, 51435, 440, 1150, 636, 307, 281, 445, 764, 428, 3209, 382, 257, 4111, 8947, 284, 13, 51645, 51645, 407, 291, 1936, 1190, 428, 5267, 807, 309, 11, 291, 483, 428, 4111, 10290, 11, 293, 586, 51826, 51826], "temperature": 0.0, "avg_logprob": -0.13174899291992187, "compression_ratio": 1.8280701754385964, "no_speech_prob": 5.422111826192122e-06}, {"id": 761, "seek": 299468, "start": 3001.2, "end": 3005.3799999999997, "text": " So the first way is to basically fine tune all the layers of a network.", "tokens": [50364, 3720, 3209, 13, 50434, 50434, 400, 456, 311, 920, 257, 688, 295, 7958, 322, 597, 472, 307, 2293, 264, 558, 3170, 281, 13059, 50608, 50608, 9590, 13, 50690, 50690, 407, 264, 700, 636, 307, 281, 1936, 2489, 10864, 439, 264, 7914, 295, 257, 3209, 13, 50899, 50899, 407, 291, 362, 257, 30621, 5633, 11, 584, 10774, 35701, 11, 420, 584, 3256, 21538, 13, 51164, 51164, 509, 3847, 341, 3209, 293, 291, 5623, 439, 264, 9834, 295, 341, 3209, 337, 264, 30621, 51362, 51362, 5633, 13, 51435, 51435, 440, 1150, 636, 307, 281, 445, 764, 428, 3209, 382, 257, 4111, 8947, 284, 13, 51645, 51645, 407, 291, 1936, 1190, 428, 5267, 807, 309, 11, 291, 483, 428, 4111, 10290, 11, 293, 586, 51826, 51826], "temperature": 0.0, "avg_logprob": -0.13174899291992187, "compression_ratio": 1.8280701754385964, "no_speech_prob": 5.422111826192122e-06}, {"id": 762, "seek": 299468, "start": 3005.3799999999997, "end": 3010.68, "text": " So you have a downstream task, say pose estimation, or say image classification.", "tokens": [50364, 3720, 3209, 13, 50434, 50434, 400, 456, 311, 920, 257, 688, 295, 7958, 322, 597, 472, 307, 2293, 264, 558, 3170, 281, 13059, 50608, 50608, 9590, 13, 50690, 50690, 407, 264, 700, 636, 307, 281, 1936, 2489, 10864, 439, 264, 7914, 295, 257, 3209, 13, 50899, 50899, 407, 291, 362, 257, 30621, 5633, 11, 584, 10774, 35701, 11, 420, 584, 3256, 21538, 13, 51164, 51164, 509, 3847, 341, 3209, 293, 291, 5623, 439, 264, 9834, 295, 341, 3209, 337, 264, 30621, 51362, 51362, 5633, 13, 51435, 51435, 440, 1150, 636, 307, 281, 445, 764, 428, 3209, 382, 257, 4111, 8947, 284, 13, 51645, 51645, 407, 291, 1936, 1190, 428, 5267, 807, 309, 11, 291, 483, 428, 4111, 10290, 11, 293, 586, 51826, 51826], "temperature": 0.0, "avg_logprob": -0.13174899291992187, "compression_ratio": 1.8280701754385964, "no_speech_prob": 5.422111826192122e-06}, {"id": 763, "seek": 299468, "start": 3010.68, "end": 3014.64, "text": " You train this network and you update all the parameters of this network for the downstream", "tokens": [50364, 3720, 3209, 13, 50434, 50434, 400, 456, 311, 920, 257, 688, 295, 7958, 322, 597, 472, 307, 2293, 264, 558, 3170, 281, 13059, 50608, 50608, 9590, 13, 50690, 50690, 407, 264, 700, 636, 307, 281, 1936, 2489, 10864, 439, 264, 7914, 295, 257, 3209, 13, 50899, 50899, 407, 291, 362, 257, 30621, 5633, 11, 584, 10774, 35701, 11, 420, 584, 3256, 21538, 13, 51164, 51164, 509, 3847, 341, 3209, 293, 291, 5623, 439, 264, 9834, 295, 341, 3209, 337, 264, 30621, 51362, 51362, 5633, 13, 51435, 51435, 440, 1150, 636, 307, 281, 445, 764, 428, 3209, 382, 257, 4111, 8947, 284, 13, 51645, 51645, 407, 291, 1936, 1190, 428, 5267, 807, 309, 11, 291, 483, 428, 4111, 10290, 11, 293, 586, 51826, 51826], "temperature": 0.0, "avg_logprob": -0.13174899291992187, "compression_ratio": 1.8280701754385964, "no_speech_prob": 5.422111826192122e-06}, {"id": 764, "seek": 299468, "start": 3014.64, "end": 3016.1, "text": " task.", "tokens": [50364, 3720, 3209, 13, 50434, 50434, 400, 456, 311, 920, 257, 688, 295, 7958, 322, 597, 472, 307, 2293, 264, 558, 3170, 281, 13059, 50608, 50608, 9590, 13, 50690, 50690, 407, 264, 700, 636, 307, 281, 1936, 2489, 10864, 439, 264, 7914, 295, 257, 3209, 13, 50899, 50899, 407, 291, 362, 257, 30621, 5633, 11, 584, 10774, 35701, 11, 420, 584, 3256, 21538, 13, 51164, 51164, 509, 3847, 341, 3209, 293, 291, 5623, 439, 264, 9834, 295, 341, 3209, 337, 264, 30621, 51362, 51362, 5633, 13, 51435, 51435, 440, 1150, 636, 307, 281, 445, 764, 428, 3209, 382, 257, 4111, 8947, 284, 13, 51645, 51645, 407, 291, 1936, 1190, 428, 5267, 807, 309, 11, 291, 483, 428, 4111, 10290, 11, 293, 586, 51826, 51826], "temperature": 0.0, "avg_logprob": -0.13174899291992187, "compression_ratio": 1.8280701754385964, "no_speech_prob": 5.422111826192122e-06}, {"id": 765, "seek": 299468, "start": 3016.1, "end": 3020.2999999999997, "text": " The second way is to just use your network as a feature extractor.", "tokens": [50364, 3720, 3209, 13, 50434, 50434, 400, 456, 311, 920, 257, 688, 295, 7958, 322, 597, 472, 307, 2293, 264, 558, 3170, 281, 13059, 50608, 50608, 9590, 13, 50690, 50690, 407, 264, 700, 636, 307, 281, 1936, 2489, 10864, 439, 264, 7914, 295, 257, 3209, 13, 50899, 50899, 407, 291, 362, 257, 30621, 5633, 11, 584, 10774, 35701, 11, 420, 584, 3256, 21538, 13, 51164, 51164, 509, 3847, 341, 3209, 293, 291, 5623, 439, 264, 9834, 295, 341, 3209, 337, 264, 30621, 51362, 51362, 5633, 13, 51435, 51435, 440, 1150, 636, 307, 281, 445, 764, 428, 3209, 382, 257, 4111, 8947, 284, 13, 51645, 51645, 407, 291, 1936, 1190, 428, 5267, 807, 309, 11, 291, 483, 428, 4111, 10290, 11, 293, 586, 51826, 51826], "temperature": 0.0, "avg_logprob": -0.13174899291992187, "compression_ratio": 1.8280701754385964, "no_speech_prob": 5.422111826192122e-06}, {"id": 766, "seek": 299468, "start": 3020.2999999999997, "end": 3023.9199999999996, "text": " So you basically run your images through it, you get your feature representation, and now", "tokens": [50364, 3720, 3209, 13, 50434, 50434, 400, 456, 311, 920, 257, 688, 295, 7958, 322, 597, 472, 307, 2293, 264, 558, 3170, 281, 13059, 50608, 50608, 9590, 13, 50690, 50690, 407, 264, 700, 636, 307, 281, 1936, 2489, 10864, 439, 264, 7914, 295, 257, 3209, 13, 50899, 50899, 407, 291, 362, 257, 30621, 5633, 11, 584, 10774, 35701, 11, 420, 584, 3256, 21538, 13, 51164, 51164, 509, 3847, 341, 3209, 293, 291, 5623, 439, 264, 9834, 295, 341, 3209, 337, 264, 30621, 51362, 51362, 5633, 13, 51435, 51435, 440, 1150, 636, 307, 281, 445, 764, 428, 3209, 382, 257, 4111, 8947, 284, 13, 51645, 51645, 407, 291, 1936, 1190, 428, 5267, 807, 309, 11, 291, 483, 428, 4111, 10290, 11, 293, 586, 51826, 51826], "temperature": 0.0, "avg_logprob": -0.13174899291992187, "compression_ratio": 1.8280701754385964, "no_speech_prob": 5.422111826192122e-06}, {"id": 767, "seek": 302392, "start": 3023.92, "end": 3028.6, "text": " you only train a linear classifier on top of that fixed feature representation.", "tokens": [50364, 291, 787, 3847, 257, 8213, 1508, 9902, 322, 1192, 295, 300, 6806, 4111, 10290, 13, 50598, 50598, 407, 294, 341, 1729, 589, 11, 321, 848, 300, 257, 665, 10290, 820, 5003, 257, 707, 50840, 50840, 2372, 295, 3097, 13, 50936, 50936, 407, 321, 40768, 1936, 337, 264, 1150, 644, 11, 597, 307, 445, 281, 3847, 257, 8213, 1508, 9902, 51146, 51146, 322, 1192, 295, 257, 3209, 8668, 382, 257, 4111, 8947, 284, 13, 51340, 51340, 407, 456, 366, 295, 1164, 11, 819, 6267, 293, 1014, 295, 1228, 1293, 7150, 13, 51542, 51542, 407, 264, 700, 3170, 300, 307, 2489, 15164, 439, 264, 7914, 307, 15083, 264, 2698, 46533, 51834, 51834], "temperature": 0.0, "avg_logprob": -0.09748596804482597, "compression_ratio": 1.8435114503816794, "no_speech_prob": 4.6377604121516924e-06}, {"id": 768, "seek": 302392, "start": 3028.6, "end": 3033.44, "text": " So in this particular work, we said that a good representation should transfer a little", "tokens": [50364, 291, 787, 3847, 257, 8213, 1508, 9902, 322, 1192, 295, 300, 6806, 4111, 10290, 13, 50598, 50598, 407, 294, 341, 1729, 589, 11, 321, 848, 300, 257, 665, 10290, 820, 5003, 257, 707, 50840, 50840, 2372, 295, 3097, 13, 50936, 50936, 407, 321, 40768, 1936, 337, 264, 1150, 644, 11, 597, 307, 445, 281, 3847, 257, 8213, 1508, 9902, 51146, 51146, 322, 1192, 295, 257, 3209, 8668, 382, 257, 4111, 8947, 284, 13, 51340, 51340, 407, 456, 366, 295, 1164, 11, 819, 6267, 293, 1014, 295, 1228, 1293, 7150, 13, 51542, 51542, 407, 264, 700, 3170, 300, 307, 2489, 15164, 439, 264, 7914, 307, 15083, 264, 2698, 46533, 51834, 51834], "temperature": 0.0, "avg_logprob": -0.09748596804482597, "compression_ratio": 1.8435114503816794, "no_speech_prob": 4.6377604121516924e-06}, {"id": 769, "seek": 302392, "start": 3033.44, "end": 3035.36, "text": " amount of training.", "tokens": [50364, 291, 787, 3847, 257, 8213, 1508, 9902, 322, 1192, 295, 300, 6806, 4111, 10290, 13, 50598, 50598, 407, 294, 341, 1729, 589, 11, 321, 848, 300, 257, 665, 10290, 820, 5003, 257, 707, 50840, 50840, 2372, 295, 3097, 13, 50936, 50936, 407, 321, 40768, 1936, 337, 264, 1150, 644, 11, 597, 307, 445, 281, 3847, 257, 8213, 1508, 9902, 51146, 51146, 322, 1192, 295, 257, 3209, 8668, 382, 257, 4111, 8947, 284, 13, 51340, 51340, 407, 456, 366, 295, 1164, 11, 819, 6267, 293, 1014, 295, 1228, 1293, 7150, 13, 51542, 51542, 407, 264, 700, 3170, 300, 307, 2489, 15164, 439, 264, 7914, 307, 15083, 264, 2698, 46533, 51834, 51834], "temperature": 0.0, "avg_logprob": -0.09748596804482597, "compression_ratio": 1.8435114503816794, "no_speech_prob": 4.6377604121516924e-06}, {"id": 770, "seek": 302392, "start": 3035.36, "end": 3039.56, "text": " So we opted basically for the second part, which is just to train a linear classifier", "tokens": [50364, 291, 787, 3847, 257, 8213, 1508, 9902, 322, 1192, 295, 300, 6806, 4111, 10290, 13, 50598, 50598, 407, 294, 341, 1729, 589, 11, 321, 848, 300, 257, 665, 10290, 820, 5003, 257, 707, 50840, 50840, 2372, 295, 3097, 13, 50936, 50936, 407, 321, 40768, 1936, 337, 264, 1150, 644, 11, 597, 307, 445, 281, 3847, 257, 8213, 1508, 9902, 51146, 51146, 322, 1192, 295, 257, 3209, 8668, 382, 257, 4111, 8947, 284, 13, 51340, 51340, 407, 456, 366, 295, 1164, 11, 819, 6267, 293, 1014, 295, 1228, 1293, 7150, 13, 51542, 51542, 407, 264, 700, 3170, 300, 307, 2489, 15164, 439, 264, 7914, 307, 15083, 264, 2698, 46533, 51834, 51834], "temperature": 0.0, "avg_logprob": -0.09748596804482597, "compression_ratio": 1.8435114503816794, "no_speech_prob": 4.6377604121516924e-06}, {"id": 771, "seek": 302392, "start": 3039.56, "end": 3043.44, "text": " on top of a network treated as a feature extractor.", "tokens": [50364, 291, 787, 3847, 257, 8213, 1508, 9902, 322, 1192, 295, 300, 6806, 4111, 10290, 13, 50598, 50598, 407, 294, 341, 1729, 589, 11, 321, 848, 300, 257, 665, 10290, 820, 5003, 257, 707, 50840, 50840, 2372, 295, 3097, 13, 50936, 50936, 407, 321, 40768, 1936, 337, 264, 1150, 644, 11, 597, 307, 445, 281, 3847, 257, 8213, 1508, 9902, 51146, 51146, 322, 1192, 295, 257, 3209, 8668, 382, 257, 4111, 8947, 284, 13, 51340, 51340, 407, 456, 366, 295, 1164, 11, 819, 6267, 293, 1014, 295, 1228, 1293, 7150, 13, 51542, 51542, 407, 264, 700, 3170, 300, 307, 2489, 15164, 439, 264, 7914, 307, 15083, 264, 2698, 46533, 51834, 51834], "temperature": 0.0, "avg_logprob": -0.09748596804482597, "compression_ratio": 1.8435114503816794, "no_speech_prob": 4.6377604121516924e-06}, {"id": 772, "seek": 302392, "start": 3043.44, "end": 3047.48, "text": " So there are of course, different pros and cons of using both methods.", "tokens": [50364, 291, 787, 3847, 257, 8213, 1508, 9902, 322, 1192, 295, 300, 6806, 4111, 10290, 13, 50598, 50598, 407, 294, 341, 1729, 589, 11, 321, 848, 300, 257, 665, 10290, 820, 5003, 257, 707, 50840, 50840, 2372, 295, 3097, 13, 50936, 50936, 407, 321, 40768, 1936, 337, 264, 1150, 644, 11, 597, 307, 445, 281, 3847, 257, 8213, 1508, 9902, 51146, 51146, 322, 1192, 295, 257, 3209, 8668, 382, 257, 4111, 8947, 284, 13, 51340, 51340, 407, 456, 366, 295, 1164, 11, 819, 6267, 293, 1014, 295, 1228, 1293, 7150, 13, 51542, 51542, 407, 264, 700, 3170, 300, 307, 2489, 15164, 439, 264, 7914, 307, 15083, 264, 2698, 46533, 51834, 51834], "temperature": 0.0, "avg_logprob": -0.09748596804482597, "compression_ratio": 1.8435114503816794, "no_speech_prob": 4.6377604121516924e-06}, {"id": 773, "seek": 302392, "start": 3047.48, "end": 3053.32, "text": " So the first method that is fine tuning all the layers is treating the self supervised", "tokens": [50364, 291, 787, 3847, 257, 8213, 1508, 9902, 322, 1192, 295, 300, 6806, 4111, 10290, 13, 50598, 50598, 407, 294, 341, 1729, 589, 11, 321, 848, 300, 257, 665, 10290, 820, 5003, 257, 707, 50840, 50840, 2372, 295, 3097, 13, 50936, 50936, 407, 321, 40768, 1936, 337, 264, 1150, 644, 11, 597, 307, 445, 281, 3847, 257, 8213, 1508, 9902, 51146, 51146, 322, 1192, 295, 257, 3209, 8668, 382, 257, 4111, 8947, 284, 13, 51340, 51340, 407, 456, 366, 295, 1164, 11, 819, 6267, 293, 1014, 295, 1228, 1293, 7150, 13, 51542, 51542, 407, 264, 700, 3170, 300, 307, 2489, 15164, 439, 264, 7914, 307, 15083, 264, 2698, 46533, 51834, 51834], "temperature": 0.0, "avg_logprob": -0.09748596804482597, "compression_ratio": 1.8435114503816794, "no_speech_prob": 4.6377604121516924e-06}, {"id": 774, "seek": 305332, "start": 3053.32, "end": 3057.96, "text": " network as an initialization, because you're basically updating the entire network.", "tokens": [50364, 3209, 382, 364, 5883, 2144, 11, 570, 291, 434, 1936, 25113, 264, 2302, 3209, 13, 50596, 50596, 407, 498, 428, 30621, 5633, 1936, 575, 584, 502, 2459, 5267, 11, 291, 434, 25113, 428, 2302, 50836, 50836, 3209, 337, 300, 502, 2459, 5267, 13, 50928, 50928, 13813, 294, 264, 1150, 1389, 11, 291, 434, 445, 3097, 588, 5567, 1230, 295, 9834, 322, 264, 6806, 51186, 51186, 4111, 8947, 284, 13, 51236, 51236, 407, 294, 512, 636, 11, 1936, 264, 1150, 472, 307, 13389, 577, 665, 295, 257, 4111, 307, 300, 291, 600, 51520, 51520, 3264, 13, 51570, 51570], "temperature": 0.0, "avg_logprob": -0.20534174370043207, "compression_ratio": 1.7966101694915255, "no_speech_prob": 1.3006795597902965e-05}, {"id": 775, "seek": 305332, "start": 3057.96, "end": 3062.76, "text": " So if your downstream task basically has say 1 million images, you're updating your entire", "tokens": [50364, 3209, 382, 364, 5883, 2144, 11, 570, 291, 434, 1936, 25113, 264, 2302, 3209, 13, 50596, 50596, 407, 498, 428, 30621, 5633, 1936, 575, 584, 502, 2459, 5267, 11, 291, 434, 25113, 428, 2302, 50836, 50836, 3209, 337, 300, 502, 2459, 5267, 13, 50928, 50928, 13813, 294, 264, 1150, 1389, 11, 291, 434, 445, 3097, 588, 5567, 1230, 295, 9834, 322, 264, 6806, 51186, 51186, 4111, 8947, 284, 13, 51236, 51236, 407, 294, 512, 636, 11, 1936, 264, 1150, 472, 307, 13389, 577, 665, 295, 257, 4111, 307, 300, 291, 600, 51520, 51520, 3264, 13, 51570, 51570], "temperature": 0.0, "avg_logprob": -0.20534174370043207, "compression_ratio": 1.7966101694915255, "no_speech_prob": 1.3006795597902965e-05}, {"id": 776, "seek": 305332, "start": 3062.76, "end": 3064.6000000000004, "text": " network for that 1 million images.", "tokens": [50364, 3209, 382, 364, 5883, 2144, 11, 570, 291, 434, 1936, 25113, 264, 2302, 3209, 13, 50596, 50596, 407, 498, 428, 30621, 5633, 1936, 575, 584, 502, 2459, 5267, 11, 291, 434, 25113, 428, 2302, 50836, 50836, 3209, 337, 300, 502, 2459, 5267, 13, 50928, 50928, 13813, 294, 264, 1150, 1389, 11, 291, 434, 445, 3097, 588, 5567, 1230, 295, 9834, 322, 264, 6806, 51186, 51186, 4111, 8947, 284, 13, 51236, 51236, 407, 294, 512, 636, 11, 1936, 264, 1150, 472, 307, 13389, 577, 665, 295, 257, 4111, 307, 300, 291, 600, 51520, 51520, 3264, 13, 51570, 51570], "temperature": 0.0, "avg_logprob": -0.20534174370043207, "compression_ratio": 1.7966101694915255, "no_speech_prob": 1.3006795597902965e-05}, {"id": 777, "seek": 305332, "start": 3064.6000000000004, "end": 3069.76, "text": " Whereas in the second case, you're just training very limited number of parameters on the fixed", "tokens": [50364, 3209, 382, 364, 5883, 2144, 11, 570, 291, 434, 1936, 25113, 264, 2302, 3209, 13, 50596, 50596, 407, 498, 428, 30621, 5633, 1936, 575, 584, 502, 2459, 5267, 11, 291, 434, 25113, 428, 2302, 50836, 50836, 3209, 337, 300, 502, 2459, 5267, 13, 50928, 50928, 13813, 294, 264, 1150, 1389, 11, 291, 434, 445, 3097, 588, 5567, 1230, 295, 9834, 322, 264, 6806, 51186, 51186, 4111, 8947, 284, 13, 51236, 51236, 407, 294, 512, 636, 11, 1936, 264, 1150, 472, 307, 13389, 577, 665, 295, 257, 4111, 307, 300, 291, 600, 51520, 51520, 3264, 13, 51570, 51570], "temperature": 0.0, "avg_logprob": -0.20534174370043207, "compression_ratio": 1.7966101694915255, "no_speech_prob": 1.3006795597902965e-05}, {"id": 778, "seek": 305332, "start": 3069.76, "end": 3070.76, "text": " feature extractor.", "tokens": [50364, 3209, 382, 364, 5883, 2144, 11, 570, 291, 434, 1936, 25113, 264, 2302, 3209, 13, 50596, 50596, 407, 498, 428, 30621, 5633, 1936, 575, 584, 502, 2459, 5267, 11, 291, 434, 25113, 428, 2302, 50836, 50836, 3209, 337, 300, 502, 2459, 5267, 13, 50928, 50928, 13813, 294, 264, 1150, 1389, 11, 291, 434, 445, 3097, 588, 5567, 1230, 295, 9834, 322, 264, 6806, 51186, 51186, 4111, 8947, 284, 13, 51236, 51236, 407, 294, 512, 636, 11, 1936, 264, 1150, 472, 307, 13389, 577, 665, 295, 257, 4111, 307, 300, 291, 600, 51520, 51520, 3264, 13, 51570, 51570], "temperature": 0.0, "avg_logprob": -0.20534174370043207, "compression_ratio": 1.7966101694915255, "no_speech_prob": 1.3006795597902965e-05}, {"id": 779, "seek": 305332, "start": 3070.76, "end": 3076.44, "text": " So in some way, basically the second one is measuring how good of a feature is that you've", "tokens": [50364, 3209, 382, 364, 5883, 2144, 11, 570, 291, 434, 1936, 25113, 264, 2302, 3209, 13, 50596, 50596, 407, 498, 428, 30621, 5633, 1936, 575, 584, 502, 2459, 5267, 11, 291, 434, 25113, 428, 2302, 50836, 50836, 3209, 337, 300, 502, 2459, 5267, 13, 50928, 50928, 13813, 294, 264, 1150, 1389, 11, 291, 434, 445, 3097, 588, 5567, 1230, 295, 9834, 322, 264, 6806, 51186, 51186, 4111, 8947, 284, 13, 51236, 51236, 407, 294, 512, 636, 11, 1936, 264, 1150, 472, 307, 13389, 577, 665, 295, 257, 4111, 307, 300, 291, 600, 51520, 51520, 3264, 13, 51570, 51570], "temperature": 0.0, "avg_logprob": -0.20534174370043207, "compression_ratio": 1.7966101694915255, "no_speech_prob": 1.3006795597902965e-05}, {"id": 780, "seek": 305332, "start": 3076.44, "end": 3077.44, "text": " learned.", "tokens": [50364, 3209, 382, 364, 5883, 2144, 11, 570, 291, 434, 1936, 25113, 264, 2302, 3209, 13, 50596, 50596, 407, 498, 428, 30621, 5633, 1936, 575, 584, 502, 2459, 5267, 11, 291, 434, 25113, 428, 2302, 50836, 50836, 3209, 337, 300, 502, 2459, 5267, 13, 50928, 50928, 13813, 294, 264, 1150, 1389, 11, 291, 434, 445, 3097, 588, 5567, 1230, 295, 9834, 322, 264, 6806, 51186, 51186, 4111, 8947, 284, 13, 51236, 51236, 407, 294, 512, 636, 11, 1936, 264, 1150, 472, 307, 13389, 577, 665, 295, 257, 4111, 307, 300, 291, 600, 51520, 51520, 3264, 13, 51570, 51570], "temperature": 0.0, "avg_logprob": -0.20534174370043207, "compression_ratio": 1.7966101694915255, "no_speech_prob": 1.3006795597902965e-05}, {"id": 781, "seek": 307744, "start": 3077.44, "end": 3084.48, "text": " All right, so the other thing that is sort of critical in evaluating self supervised", "tokens": [50364, 1057, 558, 11, 370, 264, 661, 551, 300, 307, 1333, 295, 4924, 294, 27479, 2698, 46533, 50716, 50716, 7150, 307, 281, 13059, 552, 322, 257, 3840, 295, 819, 9608, 13, 50902, 50902, 407, 3071, 11, 562, 286, 2825, 466, 300, 39426, 293, 1466, 589, 11, 286, 445, 4712, 291, 3542, 51094, 51094, 322, 10774, 35701, 13, 51144, 51144, 407, 322, 10774, 35701, 11, 309, 390, 884, 534, 731, 11, 457, 286, 767, 630, 406, 360, 534, 731, 51394, 51394, 322, 661, 9608, 411, 584, 3069, 11150, 13, 51528, 51528, 407, 294, 341, 1729, 13344, 11, 321, 1333, 295, 1415, 281, 3006, 300, 6146, 293, 321, 1415, 51736, 51736, 281, 1879, 322, 3866, 819, 9608, 13, 51860, 51860], "temperature": 0.0, "avg_logprob": -0.12933100371801554, "compression_ratio": 1.8049645390070923, "no_speech_prob": 2.6273693947587162e-05}, {"id": 782, "seek": 307744, "start": 3084.48, "end": 3088.2000000000003, "text": " methods is to evaluate them on a bunch of different tasks.", "tokens": [50364, 1057, 558, 11, 370, 264, 661, 551, 300, 307, 1333, 295, 4924, 294, 27479, 2698, 46533, 50716, 50716, 7150, 307, 281, 13059, 552, 322, 257, 3840, 295, 819, 9608, 13, 50902, 50902, 407, 3071, 11, 562, 286, 2825, 466, 300, 39426, 293, 1466, 589, 11, 286, 445, 4712, 291, 3542, 51094, 51094, 322, 10774, 35701, 13, 51144, 51144, 407, 322, 10774, 35701, 11, 309, 390, 884, 534, 731, 11, 457, 286, 767, 630, 406, 360, 534, 731, 51394, 51394, 322, 661, 9608, 411, 584, 3069, 11150, 13, 51528, 51528, 407, 294, 341, 1729, 13344, 11, 321, 1333, 295, 1415, 281, 3006, 300, 6146, 293, 321, 1415, 51736, 51736, 281, 1879, 322, 3866, 819, 9608, 13, 51860, 51860], "temperature": 0.0, "avg_logprob": -0.12933100371801554, "compression_ratio": 1.8049645390070923, "no_speech_prob": 2.6273693947587162e-05}, {"id": 783, "seek": 307744, "start": 3088.2000000000003, "end": 3092.04, "text": " So earlier, when I talked about that shuffle and learn work, I just showed you results", "tokens": [50364, 1057, 558, 11, 370, 264, 661, 551, 300, 307, 1333, 295, 4924, 294, 27479, 2698, 46533, 50716, 50716, 7150, 307, 281, 13059, 552, 322, 257, 3840, 295, 819, 9608, 13, 50902, 50902, 407, 3071, 11, 562, 286, 2825, 466, 300, 39426, 293, 1466, 589, 11, 286, 445, 4712, 291, 3542, 51094, 51094, 322, 10774, 35701, 13, 51144, 51144, 407, 322, 10774, 35701, 11, 309, 390, 884, 534, 731, 11, 457, 286, 767, 630, 406, 360, 534, 731, 51394, 51394, 322, 661, 9608, 411, 584, 3069, 11150, 13, 51528, 51528, 407, 294, 341, 1729, 13344, 11, 321, 1333, 295, 1415, 281, 3006, 300, 6146, 293, 321, 1415, 51736, 51736, 281, 1879, 322, 3866, 819, 9608, 13, 51860, 51860], "temperature": 0.0, "avg_logprob": -0.12933100371801554, "compression_ratio": 1.8049645390070923, "no_speech_prob": 2.6273693947587162e-05}, {"id": 784, "seek": 307744, "start": 3092.04, "end": 3093.04, "text": " on pose estimation.", "tokens": [50364, 1057, 558, 11, 370, 264, 661, 551, 300, 307, 1333, 295, 4924, 294, 27479, 2698, 46533, 50716, 50716, 7150, 307, 281, 13059, 552, 322, 257, 3840, 295, 819, 9608, 13, 50902, 50902, 407, 3071, 11, 562, 286, 2825, 466, 300, 39426, 293, 1466, 589, 11, 286, 445, 4712, 291, 3542, 51094, 51094, 322, 10774, 35701, 13, 51144, 51144, 407, 322, 10774, 35701, 11, 309, 390, 884, 534, 731, 11, 457, 286, 767, 630, 406, 360, 534, 731, 51394, 51394, 322, 661, 9608, 411, 584, 3069, 11150, 13, 51528, 51528, 407, 294, 341, 1729, 13344, 11, 321, 1333, 295, 1415, 281, 3006, 300, 6146, 293, 321, 1415, 51736, 51736, 281, 1879, 322, 3866, 819, 9608, 13, 51860, 51860], "temperature": 0.0, "avg_logprob": -0.12933100371801554, "compression_ratio": 1.8049645390070923, "no_speech_prob": 2.6273693947587162e-05}, {"id": 785, "seek": 307744, "start": 3093.04, "end": 3098.04, "text": " So on pose estimation, it was doing really well, but I actually did not do really well", "tokens": [50364, 1057, 558, 11, 370, 264, 661, 551, 300, 307, 1333, 295, 4924, 294, 27479, 2698, 46533, 50716, 50716, 7150, 307, 281, 13059, 552, 322, 257, 3840, 295, 819, 9608, 13, 50902, 50902, 407, 3071, 11, 562, 286, 2825, 466, 300, 39426, 293, 1466, 589, 11, 286, 445, 4712, 291, 3542, 51094, 51094, 322, 10774, 35701, 13, 51144, 51144, 407, 322, 10774, 35701, 11, 309, 390, 884, 534, 731, 11, 457, 286, 767, 630, 406, 360, 534, 731, 51394, 51394, 322, 661, 9608, 411, 584, 3069, 11150, 13, 51528, 51528, 407, 294, 341, 1729, 13344, 11, 321, 1333, 295, 1415, 281, 3006, 300, 6146, 293, 321, 1415, 51736, 51736, 281, 1879, 322, 3866, 819, 9608, 13, 51860, 51860], "temperature": 0.0, "avg_logprob": -0.12933100371801554, "compression_ratio": 1.8049645390070923, "no_speech_prob": 2.6273693947587162e-05}, {"id": 786, "seek": 307744, "start": 3098.04, "end": 3100.7200000000003, "text": " on other tasks like say action recognition.", "tokens": [50364, 1057, 558, 11, 370, 264, 661, 551, 300, 307, 1333, 295, 4924, 294, 27479, 2698, 46533, 50716, 50716, 7150, 307, 281, 13059, 552, 322, 257, 3840, 295, 819, 9608, 13, 50902, 50902, 407, 3071, 11, 562, 286, 2825, 466, 300, 39426, 293, 1466, 589, 11, 286, 445, 4712, 291, 3542, 51094, 51094, 322, 10774, 35701, 13, 51144, 51144, 407, 322, 10774, 35701, 11, 309, 390, 884, 534, 731, 11, 457, 286, 767, 630, 406, 360, 534, 731, 51394, 51394, 322, 661, 9608, 411, 584, 3069, 11150, 13, 51528, 51528, 407, 294, 341, 1729, 13344, 11, 321, 1333, 295, 1415, 281, 3006, 300, 6146, 293, 321, 1415, 51736, 51736, 281, 1879, 322, 3866, 819, 9608, 13, 51860, 51860], "temperature": 0.0, "avg_logprob": -0.12933100371801554, "compression_ratio": 1.8049645390070923, "no_speech_prob": 2.6273693947587162e-05}, {"id": 787, "seek": 307744, "start": 3100.7200000000003, "end": 3104.88, "text": " So in this particular evaluation, we sort of wanted to correct that mistake and we wanted", "tokens": [50364, 1057, 558, 11, 370, 264, 661, 551, 300, 307, 1333, 295, 4924, 294, 27479, 2698, 46533, 50716, 50716, 7150, 307, 281, 13059, 552, 322, 257, 3840, 295, 819, 9608, 13, 50902, 50902, 407, 3071, 11, 562, 286, 2825, 466, 300, 39426, 293, 1466, 589, 11, 286, 445, 4712, 291, 3542, 51094, 51094, 322, 10774, 35701, 13, 51144, 51144, 407, 322, 10774, 35701, 11, 309, 390, 884, 534, 731, 11, 457, 286, 767, 630, 406, 360, 534, 731, 51394, 51394, 322, 661, 9608, 411, 584, 3069, 11150, 13, 51528, 51528, 407, 294, 341, 1729, 13344, 11, 321, 1333, 295, 1415, 281, 3006, 300, 6146, 293, 321, 1415, 51736, 51736, 281, 1879, 322, 3866, 819, 9608, 13, 51860, 51860], "temperature": 0.0, "avg_logprob": -0.12933100371801554, "compression_ratio": 1.8049645390070923, "no_speech_prob": 2.6273693947587162e-05}, {"id": 788, "seek": 307744, "start": 3104.88, "end": 3107.36, "text": " to focus on multiple different tasks.", "tokens": [50364, 1057, 558, 11, 370, 264, 661, 551, 300, 307, 1333, 295, 4924, 294, 27479, 2698, 46533, 50716, 50716, 7150, 307, 281, 13059, 552, 322, 257, 3840, 295, 819, 9608, 13, 50902, 50902, 407, 3071, 11, 562, 286, 2825, 466, 300, 39426, 293, 1466, 589, 11, 286, 445, 4712, 291, 3542, 51094, 51094, 322, 10774, 35701, 13, 51144, 51144, 407, 322, 10774, 35701, 11, 309, 390, 884, 534, 731, 11, 457, 286, 767, 630, 406, 360, 534, 731, 51394, 51394, 322, 661, 9608, 411, 584, 3069, 11150, 13, 51528, 51528, 407, 294, 341, 1729, 13344, 11, 321, 1333, 295, 1415, 281, 3006, 300, 6146, 293, 321, 1415, 51736, 51736, 281, 1879, 322, 3866, 819, 9608, 13, 51860, 51860], "temperature": 0.0, "avg_logprob": -0.12933100371801554, "compression_ratio": 1.8049645390070923, "no_speech_prob": 2.6273693947587162e-05}, {"id": 789, "seek": 310736, "start": 3107.36, "end": 3112.1200000000003, "text": " So a variety of different tasks like say image classification, few short learning, object", "tokens": [50364, 407, 257, 5673, 295, 819, 9608, 411, 584, 3256, 21538, 11, 1326, 2099, 2539, 11, 2657, 50602, 50602, 17784, 11, 805, 35, 3701, 11, 17346, 11, 293, 370, 322, 13, 50798, 50798, 407, 321, 6964, 1936, 411, 257, 992, 295, 4949, 819, 9608, 13, 51069, 51069, 407, 264, 636, 281, 13059, 264, 33358, 307, 1936, 281, 8947, 6806, 4122, 13, 51338, 51338, 400, 291, 393, 8947, 613, 6806, 4122, 490, 819, 3166, 295, 264, 3209, 13, 51507, 51507, 407, 436, 393, 808, 1936, 490, 257, 4583, 597, 307, 588, 1998, 281, 264, 4846, 420, 490, 257, 588, 51706, 51706, 1090, 1496, 4583, 11, 597, 307, 588, 1998, 281, 264, 5598, 13, 51834, 51834], "temperature": 0.0, "avg_logprob": -0.12143420343813689, "compression_ratio": 1.8801498127340823, "no_speech_prob": 2.668632623681333e-05}, {"id": 790, "seek": 310736, "start": 3112.1200000000003, "end": 3116.04, "text": " detection, 3D understanding, navigation, and so on.", "tokens": [50364, 407, 257, 5673, 295, 819, 9608, 411, 584, 3256, 21538, 11, 1326, 2099, 2539, 11, 2657, 50602, 50602, 17784, 11, 805, 35, 3701, 11, 17346, 11, 293, 370, 322, 13, 50798, 50798, 407, 321, 6964, 1936, 411, 257, 992, 295, 4949, 819, 9608, 13, 51069, 51069, 407, 264, 636, 281, 13059, 264, 33358, 307, 1936, 281, 8947, 6806, 4122, 13, 51338, 51338, 400, 291, 393, 8947, 613, 6806, 4122, 490, 819, 3166, 295, 264, 3209, 13, 51507, 51507, 407, 436, 393, 808, 1936, 490, 257, 4583, 597, 307, 588, 1998, 281, 264, 4846, 420, 490, 257, 588, 51706, 51706, 1090, 1496, 4583, 11, 597, 307, 588, 1998, 281, 264, 5598, 13, 51834, 51834], "temperature": 0.0, "avg_logprob": -0.12143420343813689, "compression_ratio": 1.8801498127340823, "no_speech_prob": 2.668632623681333e-05}, {"id": 791, "seek": 310736, "start": 3116.04, "end": 3121.46, "text": " So we define basically like a set of nine different tasks.", "tokens": [50364, 407, 257, 5673, 295, 819, 9608, 411, 584, 3256, 21538, 11, 1326, 2099, 2539, 11, 2657, 50602, 50602, 17784, 11, 805, 35, 3701, 11, 17346, 11, 293, 370, 322, 13, 50798, 50798, 407, 321, 6964, 1936, 411, 257, 992, 295, 4949, 819, 9608, 13, 51069, 51069, 407, 264, 636, 281, 13059, 264, 33358, 307, 1936, 281, 8947, 6806, 4122, 13, 51338, 51338, 400, 291, 393, 8947, 613, 6806, 4122, 490, 819, 3166, 295, 264, 3209, 13, 51507, 51507, 407, 436, 393, 808, 1936, 490, 257, 4583, 597, 307, 588, 1998, 281, 264, 4846, 420, 490, 257, 588, 51706, 51706, 1090, 1496, 4583, 11, 597, 307, 588, 1998, 281, 264, 5598, 13, 51834, 51834], "temperature": 0.0, "avg_logprob": -0.12143420343813689, "compression_ratio": 1.8801498127340823, "no_speech_prob": 2.668632623681333e-05}, {"id": 792, "seek": 310736, "start": 3121.46, "end": 3126.84, "text": " So the way to evaluate the representations is basically to extract fixed features.", "tokens": [50364, 407, 257, 5673, 295, 819, 9608, 411, 584, 3256, 21538, 11, 1326, 2099, 2539, 11, 2657, 50602, 50602, 17784, 11, 805, 35, 3701, 11, 17346, 11, 293, 370, 322, 13, 50798, 50798, 407, 321, 6964, 1936, 411, 257, 992, 295, 4949, 819, 9608, 13, 51069, 51069, 407, 264, 636, 281, 13059, 264, 33358, 307, 1936, 281, 8947, 6806, 4122, 13, 51338, 51338, 400, 291, 393, 8947, 613, 6806, 4122, 490, 819, 3166, 295, 264, 3209, 13, 51507, 51507, 407, 436, 393, 808, 1936, 490, 257, 4583, 597, 307, 588, 1998, 281, 264, 4846, 420, 490, 257, 588, 51706, 51706, 1090, 1496, 4583, 11, 597, 307, 588, 1998, 281, 264, 5598, 13, 51834, 51834], "temperature": 0.0, "avg_logprob": -0.12143420343813689, "compression_ratio": 1.8801498127340823, "no_speech_prob": 2.668632623681333e-05}, {"id": 793, "seek": 310736, "start": 3126.84, "end": 3130.2200000000003, "text": " And you can extract these fixed features from different parts of the network.", "tokens": [50364, 407, 257, 5673, 295, 819, 9608, 411, 584, 3256, 21538, 11, 1326, 2099, 2539, 11, 2657, 50602, 50602, 17784, 11, 805, 35, 3701, 11, 17346, 11, 293, 370, 322, 13, 50798, 50798, 407, 321, 6964, 1936, 411, 257, 992, 295, 4949, 819, 9608, 13, 51069, 51069, 407, 264, 636, 281, 13059, 264, 33358, 307, 1936, 281, 8947, 6806, 4122, 13, 51338, 51338, 400, 291, 393, 8947, 613, 6806, 4122, 490, 819, 3166, 295, 264, 3209, 13, 51507, 51507, 407, 436, 393, 808, 1936, 490, 257, 4583, 597, 307, 588, 1998, 281, 264, 4846, 420, 490, 257, 588, 51706, 51706, 1090, 1496, 4583, 11, 597, 307, 588, 1998, 281, 264, 5598, 13, 51834, 51834], "temperature": 0.0, "avg_logprob": -0.12143420343813689, "compression_ratio": 1.8801498127340823, "no_speech_prob": 2.668632623681333e-05}, {"id": 794, "seek": 310736, "start": 3130.2200000000003, "end": 3134.2000000000003, "text": " So they can come basically from a layer which is very close to the input or from a very", "tokens": [50364, 407, 257, 5673, 295, 819, 9608, 411, 584, 3256, 21538, 11, 1326, 2099, 2539, 11, 2657, 50602, 50602, 17784, 11, 805, 35, 3701, 11, 17346, 11, 293, 370, 322, 13, 50798, 50798, 407, 321, 6964, 1936, 411, 257, 992, 295, 4949, 819, 9608, 13, 51069, 51069, 407, 264, 636, 281, 13059, 264, 33358, 307, 1936, 281, 8947, 6806, 4122, 13, 51338, 51338, 400, 291, 393, 8947, 613, 6806, 4122, 490, 819, 3166, 295, 264, 3209, 13, 51507, 51507, 407, 436, 393, 808, 1936, 490, 257, 4583, 597, 307, 588, 1998, 281, 264, 4846, 420, 490, 257, 588, 51706, 51706, 1090, 1496, 4583, 11, 597, 307, 588, 1998, 281, 264, 5598, 13, 51834, 51834], "temperature": 0.0, "avg_logprob": -0.12143420343813689, "compression_ratio": 1.8801498127340823, "no_speech_prob": 2.668632623681333e-05}, {"id": 795, "seek": 310736, "start": 3134.2000000000003, "end": 3136.76, "text": " high level layer, which is very close to the output.", "tokens": [50364, 407, 257, 5673, 295, 819, 9608, 411, 584, 3256, 21538, 11, 1326, 2099, 2539, 11, 2657, 50602, 50602, 17784, 11, 805, 35, 3701, 11, 17346, 11, 293, 370, 322, 13, 50798, 50798, 407, 321, 6964, 1936, 411, 257, 992, 295, 4949, 819, 9608, 13, 51069, 51069, 407, 264, 636, 281, 13059, 264, 33358, 307, 1936, 281, 8947, 6806, 4122, 13, 51338, 51338, 400, 291, 393, 8947, 613, 6806, 4122, 490, 819, 3166, 295, 264, 3209, 13, 51507, 51507, 407, 436, 393, 808, 1936, 490, 257, 4583, 597, 307, 588, 1998, 281, 264, 4846, 420, 490, 257, 588, 51706, 51706, 1090, 1496, 4583, 11, 597, 307, 588, 1998, 281, 264, 5598, 13, 51834, 51834], "temperature": 0.0, "avg_logprob": -0.12143420343813689, "compression_ratio": 1.8801498127340823, "no_speech_prob": 2.668632623681333e-05}, {"id": 796, "seek": 313676, "start": 3136.76, "end": 3139.88, "text": " And then this way you're sort of measuring the semanticness of each of these different", "tokens": [50364, 400, 550, 341, 636, 291, 434, 1333, 295, 13389, 264, 47982, 1287, 295, 1184, 295, 613, 819, 50520, 50520, 7914, 13, 50688, 50688, 400, 264, 1333, 295, 3832, 551, 321, 630, 337, 257, 688, 295, 613, 12050, 390, 281, 764, 364, 3256, 50894, 50894, 21538, 5633, 281, 1333, 295, 1223, 437, 307, 516, 322, 13, 51116, 51116, 407, 264, 3256, 21538, 5633, 307, 322, 341, 1412, 992, 1219, 3286, 34, 11, 597, 307, 6457, 3832, 51400, 51400, 337, 17784, 293, 21538, 13, 51522, 51522, 400, 264, 1558, 307, 281, 6069, 1968, 364, 3256, 575, 472, 295, 945, 5359, 13, 51830, 51830], "temperature": 0.0, "avg_logprob": -0.12535031327923524, "compression_ratio": 1.8312236286919832, "no_speech_prob": 4.637705842469586e-06}, {"id": 797, "seek": 313676, "start": 3139.88, "end": 3143.2400000000002, "text": " layers.", "tokens": [50364, 400, 550, 341, 636, 291, 434, 1333, 295, 13389, 264, 47982, 1287, 295, 1184, 295, 613, 819, 50520, 50520, 7914, 13, 50688, 50688, 400, 264, 1333, 295, 3832, 551, 321, 630, 337, 257, 688, 295, 613, 12050, 390, 281, 764, 364, 3256, 50894, 50894, 21538, 5633, 281, 1333, 295, 1223, 437, 307, 516, 322, 13, 51116, 51116, 407, 264, 3256, 21538, 5633, 307, 322, 341, 1412, 992, 1219, 3286, 34, 11, 597, 307, 6457, 3832, 51400, 51400, 337, 17784, 293, 21538, 13, 51522, 51522, 400, 264, 1558, 307, 281, 6069, 1968, 364, 3256, 575, 472, 295, 945, 5359, 13, 51830, 51830], "temperature": 0.0, "avg_logprob": -0.12535031327923524, "compression_ratio": 1.8312236286919832, "no_speech_prob": 4.637705842469586e-06}, {"id": 798, "seek": 313676, "start": 3143.2400000000002, "end": 3147.36, "text": " And the sort of standard thing we did for a lot of these experiments was to use an image", "tokens": [50364, 400, 550, 341, 636, 291, 434, 1333, 295, 13389, 264, 47982, 1287, 295, 1184, 295, 613, 819, 50520, 50520, 7914, 13, 50688, 50688, 400, 264, 1333, 295, 3832, 551, 321, 630, 337, 257, 688, 295, 613, 12050, 390, 281, 764, 364, 3256, 50894, 50894, 21538, 5633, 281, 1333, 295, 1223, 437, 307, 516, 322, 13, 51116, 51116, 407, 264, 3256, 21538, 5633, 307, 322, 341, 1412, 992, 1219, 3286, 34, 11, 597, 307, 6457, 3832, 51400, 51400, 337, 17784, 293, 21538, 13, 51522, 51522, 400, 264, 1558, 307, 281, 6069, 1968, 364, 3256, 575, 472, 295, 945, 5359, 13, 51830, 51830], "temperature": 0.0, "avg_logprob": -0.12535031327923524, "compression_ratio": 1.8312236286919832, "no_speech_prob": 4.637705842469586e-06}, {"id": 799, "seek": 313676, "start": 3147.36, "end": 3151.8, "text": " classification task to sort of understand what is going on.", "tokens": [50364, 400, 550, 341, 636, 291, 434, 1333, 295, 13389, 264, 47982, 1287, 295, 1184, 295, 613, 819, 50520, 50520, 7914, 13, 50688, 50688, 400, 264, 1333, 295, 3832, 551, 321, 630, 337, 257, 688, 295, 613, 12050, 390, 281, 764, 364, 3256, 50894, 50894, 21538, 5633, 281, 1333, 295, 1223, 437, 307, 516, 322, 13, 51116, 51116, 407, 264, 3256, 21538, 5633, 307, 322, 341, 1412, 992, 1219, 3286, 34, 11, 597, 307, 6457, 3832, 51400, 51400, 337, 17784, 293, 21538, 13, 51522, 51522, 400, 264, 1558, 307, 281, 6069, 1968, 364, 3256, 575, 472, 295, 945, 5359, 13, 51830, 51830], "temperature": 0.0, "avg_logprob": -0.12535031327923524, "compression_ratio": 1.8312236286919832, "no_speech_prob": 4.637705842469586e-06}, {"id": 800, "seek": 313676, "start": 3151.8, "end": 3157.48, "text": " So the image classification task is on this data set called BoC, which is fairly standard", "tokens": [50364, 400, 550, 341, 636, 291, 434, 1333, 295, 13389, 264, 47982, 1287, 295, 1184, 295, 613, 819, 50520, 50520, 7914, 13, 50688, 50688, 400, 264, 1333, 295, 3832, 551, 321, 630, 337, 257, 688, 295, 613, 12050, 390, 281, 764, 364, 3256, 50894, 50894, 21538, 5633, 281, 1333, 295, 1223, 437, 307, 516, 322, 13, 51116, 51116, 407, 264, 3256, 21538, 5633, 307, 322, 341, 1412, 992, 1219, 3286, 34, 11, 597, 307, 6457, 3832, 51400, 51400, 337, 17784, 293, 21538, 13, 51522, 51522, 400, 264, 1558, 307, 281, 6069, 1968, 364, 3256, 575, 472, 295, 945, 5359, 13, 51830, 51830], "temperature": 0.0, "avg_logprob": -0.12535031327923524, "compression_ratio": 1.8312236286919832, "no_speech_prob": 4.637705842469586e-06}, {"id": 801, "seek": 313676, "start": 3157.48, "end": 3159.92, "text": " for detection and classification.", "tokens": [50364, 400, 550, 341, 636, 291, 434, 1333, 295, 13389, 264, 47982, 1287, 295, 1184, 295, 613, 819, 50520, 50520, 7914, 13, 50688, 50688, 400, 264, 1333, 295, 3832, 551, 321, 630, 337, 257, 688, 295, 613, 12050, 390, 281, 764, 364, 3256, 50894, 50894, 21538, 5633, 281, 1333, 295, 1223, 437, 307, 516, 322, 13, 51116, 51116, 407, 264, 3256, 21538, 5633, 307, 322, 341, 1412, 992, 1219, 3286, 34, 11, 597, 307, 6457, 3832, 51400, 51400, 337, 17784, 293, 21538, 13, 51522, 51522, 400, 264, 1558, 307, 281, 6069, 1968, 364, 3256, 575, 472, 295, 945, 5359, 13, 51830, 51830], "temperature": 0.0, "avg_logprob": -0.12535031327923524, "compression_ratio": 1.8312236286919832, "no_speech_prob": 4.637705842469586e-06}, {"id": 802, "seek": 313676, "start": 3159.92, "end": 3166.0800000000004, "text": " And the idea is to predict whether an image has one of 20 classes.", "tokens": [50364, 400, 550, 341, 636, 291, 434, 1333, 295, 13389, 264, 47982, 1287, 295, 1184, 295, 613, 819, 50520, 50520, 7914, 13, 50688, 50688, 400, 264, 1333, 295, 3832, 551, 321, 630, 337, 257, 688, 295, 613, 12050, 390, 281, 764, 364, 3256, 50894, 50894, 21538, 5633, 281, 1333, 295, 1223, 437, 307, 516, 322, 13, 51116, 51116, 407, 264, 3256, 21538, 5633, 307, 322, 341, 1412, 992, 1219, 3286, 34, 11, 597, 307, 6457, 3832, 51400, 51400, 337, 17784, 293, 21538, 13, 51522, 51522, 400, 264, 1558, 307, 281, 6069, 1968, 364, 3256, 575, 472, 295, 945, 5359, 13, 51830, 51830], "temperature": 0.0, "avg_logprob": -0.12535031327923524, "compression_ratio": 1.8312236286919832, "no_speech_prob": 4.637705842469586e-06}, {"id": 803, "seek": 316608, "start": 3166.08, "end": 3169.68, "text": " So an image can actually have more than one class.", "tokens": [50364, 407, 364, 3256, 393, 767, 362, 544, 813, 472, 1508, 13, 50544, 50544, 1171, 1365, 11, 411, 300, 3036, 295, 257, 954, 365, 257, 3000, 300, 575, 1293, 954, 293, 3000, 13, 50796, 50796, 407, 341, 3209, 586, 2203, 281, 5521, 1293, 264, 6565, 294, 309, 13, 50944, 50944, 407, 309, 311, 4748, 6081, 813, 29903, 31890, 689, 291, 1936, 643, 281, 787, 1333, 295, 5876, 51192, 51192, 472, 295, 264, 2141, 6565, 294, 264, 3256, 13, 51526, 51526, 407, 264, 700, 551, 321, 630, 390, 1936, 281, 16888, 264, 17291, 11, 1968, 5662, 51712, 51712], "temperature": 0.0, "avg_logprob": -0.09841737941819795, "compression_ratio": 1.6477732793522266, "no_speech_prob": 1.2029217032250017e-05}, {"id": 804, "seek": 316608, "start": 3169.68, "end": 3174.72, "text": " For example, like that picture of a person with a dog that has both person and dog.", "tokens": [50364, 407, 364, 3256, 393, 767, 362, 544, 813, 472, 1508, 13, 50544, 50544, 1171, 1365, 11, 411, 300, 3036, 295, 257, 954, 365, 257, 3000, 300, 575, 1293, 954, 293, 3000, 13, 50796, 50796, 407, 341, 3209, 586, 2203, 281, 5521, 1293, 264, 6565, 294, 309, 13, 50944, 50944, 407, 309, 311, 4748, 6081, 813, 29903, 31890, 689, 291, 1936, 643, 281, 787, 1333, 295, 5876, 51192, 51192, 472, 295, 264, 2141, 6565, 294, 264, 3256, 13, 51526, 51526, 407, 264, 700, 551, 321, 630, 390, 1936, 281, 16888, 264, 17291, 11, 1968, 5662, 51712, 51712], "temperature": 0.0, "avg_logprob": -0.09841737941819795, "compression_ratio": 1.6477732793522266, "no_speech_prob": 1.2029217032250017e-05}, {"id": 805, "seek": 316608, "start": 3174.72, "end": 3177.68, "text": " So this network now needs to recognize both the objects in it.", "tokens": [50364, 407, 364, 3256, 393, 767, 362, 544, 813, 472, 1508, 13, 50544, 50544, 1171, 1365, 11, 411, 300, 3036, 295, 257, 954, 365, 257, 3000, 300, 575, 1293, 954, 293, 3000, 13, 50796, 50796, 407, 341, 3209, 586, 2203, 281, 5521, 1293, 264, 6565, 294, 309, 13, 50944, 50944, 407, 309, 311, 4748, 6081, 813, 29903, 31890, 689, 291, 1936, 643, 281, 787, 1333, 295, 5876, 51192, 51192, 472, 295, 264, 2141, 6565, 294, 264, 3256, 13, 51526, 51526, 407, 264, 700, 551, 321, 630, 390, 1936, 281, 16888, 264, 17291, 11, 1968, 5662, 51712, 51712], "temperature": 0.0, "avg_logprob": -0.09841737941819795, "compression_ratio": 1.6477732793522266, "no_speech_prob": 1.2029217032250017e-05}, {"id": 806, "seek": 316608, "start": 3177.68, "end": 3182.64, "text": " So it's slightly harder than ImageNet where you basically need to only sort of identify", "tokens": [50364, 407, 364, 3256, 393, 767, 362, 544, 813, 472, 1508, 13, 50544, 50544, 1171, 1365, 11, 411, 300, 3036, 295, 257, 954, 365, 257, 3000, 300, 575, 1293, 954, 293, 3000, 13, 50796, 50796, 407, 341, 3209, 586, 2203, 281, 5521, 1293, 264, 6565, 294, 309, 13, 50944, 50944, 407, 309, 311, 4748, 6081, 813, 29903, 31890, 689, 291, 1936, 643, 281, 787, 1333, 295, 5876, 51192, 51192, 472, 295, 264, 2141, 6565, 294, 264, 3256, 13, 51526, 51526, 407, 264, 700, 551, 321, 630, 390, 1936, 281, 16888, 264, 17291, 11, 1968, 5662, 51712, 51712], "temperature": 0.0, "avg_logprob": -0.09841737941819795, "compression_ratio": 1.6477732793522266, "no_speech_prob": 1.2029217032250017e-05}, {"id": 807, "seek": 316608, "start": 3182.64, "end": 3189.3199999999997, "text": " one of the key objects in the image.", "tokens": [50364, 407, 364, 3256, 393, 767, 362, 544, 813, 472, 1508, 13, 50544, 50544, 1171, 1365, 11, 411, 300, 3036, 295, 257, 954, 365, 257, 3000, 300, 575, 1293, 954, 293, 3000, 13, 50796, 50796, 407, 341, 3209, 586, 2203, 281, 5521, 1293, 264, 6565, 294, 309, 13, 50944, 50944, 407, 309, 311, 4748, 6081, 813, 29903, 31890, 689, 291, 1936, 643, 281, 787, 1333, 295, 5876, 51192, 51192, 472, 295, 264, 2141, 6565, 294, 264, 3256, 13, 51526, 51526, 407, 264, 700, 551, 321, 630, 390, 1936, 281, 16888, 264, 17291, 11, 1968, 5662, 51712, 51712], "temperature": 0.0, "avg_logprob": -0.09841737941819795, "compression_ratio": 1.6477732793522266, "no_speech_prob": 1.2029217032250017e-05}, {"id": 808, "seek": 316608, "start": 3189.3199999999997, "end": 3193.04, "text": " So the first thing we did was basically to verify the hypothesis, whether increasing", "tokens": [50364, 407, 364, 3256, 393, 767, 362, 544, 813, 472, 1508, 13, 50544, 50544, 1171, 1365, 11, 411, 300, 3036, 295, 257, 954, 365, 257, 3000, 300, 575, 1293, 954, 293, 3000, 13, 50796, 50796, 407, 341, 3209, 586, 2203, 281, 5521, 1293, 264, 6565, 294, 309, 13, 50944, 50944, 407, 309, 311, 4748, 6081, 813, 29903, 31890, 689, 291, 1936, 643, 281, 787, 1333, 295, 5876, 51192, 51192, 472, 295, 264, 2141, 6565, 294, 264, 3256, 13, 51526, 51526, 407, 264, 700, 551, 321, 630, 390, 1936, 281, 16888, 264, 17291, 11, 1968, 5662, 51712, 51712], "temperature": 0.0, "avg_logprob": -0.09841737941819795, "compression_ratio": 1.6477732793522266, "no_speech_prob": 1.2029217032250017e-05}, {"id": 809, "seek": 319304, "start": 3193.04, "end": 3198.56, "text": " the amount of information predicted actually results in better representations.", "tokens": [50364, 264, 2372, 295, 1589, 19147, 767, 3542, 294, 1101, 33358, 13, 50640, 50640, 407, 322, 264, 2031, 12, 24633, 11, 321, 434, 5662, 264, 1230, 295, 4784, 325, 763, 300, 321, 434, 1228, 281, 1936, 50908, 50908, 3847, 527, 3209, 13, 50958, 50958, 407, 300, 311, 516, 490, 2319, 281, 1266, 11, 1360, 13, 51058, 51058, 400, 322, 264, 288, 12, 24633, 11, 321, 434, 1936, 13389, 264, 30621, 5003, 3389, 295, 613, 51322, 51322, 659, 12, 17227, 2001, 33358, 13, 51415, 51415, 400, 309, 311, 12690, 1228, 257, 20678, 1219, 4471, 11, 597, 307, 914, 4274, 18356, 13, 51640, 51640], "temperature": 0.0, "avg_logprob": -0.1466382406290295, "compression_ratio": 1.7479338842975207, "no_speech_prob": 1.3630841749545652e-05}, {"id": 810, "seek": 319304, "start": 3198.56, "end": 3203.92, "text": " So on the x-axis, we're increasing the number of permutations that we're using to basically", "tokens": [50364, 264, 2372, 295, 1589, 19147, 767, 3542, 294, 1101, 33358, 13, 50640, 50640, 407, 322, 264, 2031, 12, 24633, 11, 321, 434, 5662, 264, 1230, 295, 4784, 325, 763, 300, 321, 434, 1228, 281, 1936, 50908, 50908, 3847, 527, 3209, 13, 50958, 50958, 407, 300, 311, 516, 490, 2319, 281, 1266, 11, 1360, 13, 51058, 51058, 400, 322, 264, 288, 12, 24633, 11, 321, 434, 1936, 13389, 264, 30621, 5003, 3389, 295, 613, 51322, 51322, 659, 12, 17227, 2001, 33358, 13, 51415, 51415, 400, 309, 311, 12690, 1228, 257, 20678, 1219, 4471, 11, 597, 307, 914, 4274, 18356, 13, 51640, 51640], "temperature": 0.0, "avg_logprob": -0.1466382406290295, "compression_ratio": 1.7479338842975207, "no_speech_prob": 1.3630841749545652e-05}, {"id": 811, "seek": 319304, "start": 3203.92, "end": 3204.92, "text": " train our network.", "tokens": [50364, 264, 2372, 295, 1589, 19147, 767, 3542, 294, 1101, 33358, 13, 50640, 50640, 407, 322, 264, 2031, 12, 24633, 11, 321, 434, 5662, 264, 1230, 295, 4784, 325, 763, 300, 321, 434, 1228, 281, 1936, 50908, 50908, 3847, 527, 3209, 13, 50958, 50958, 407, 300, 311, 516, 490, 2319, 281, 1266, 11, 1360, 13, 51058, 51058, 400, 322, 264, 288, 12, 24633, 11, 321, 434, 1936, 13389, 264, 30621, 5003, 3389, 295, 613, 51322, 51322, 659, 12, 17227, 2001, 33358, 13, 51415, 51415, 400, 309, 311, 12690, 1228, 257, 20678, 1219, 4471, 11, 597, 307, 914, 4274, 18356, 13, 51640, 51640], "temperature": 0.0, "avg_logprob": -0.1466382406290295, "compression_ratio": 1.7479338842975207, "no_speech_prob": 1.3630841749545652e-05}, {"id": 812, "seek": 319304, "start": 3204.92, "end": 3206.92, "text": " So that's going from 100 to 10,000.", "tokens": [50364, 264, 2372, 295, 1589, 19147, 767, 3542, 294, 1101, 33358, 13, 50640, 50640, 407, 322, 264, 2031, 12, 24633, 11, 321, 434, 5662, 264, 1230, 295, 4784, 325, 763, 300, 321, 434, 1228, 281, 1936, 50908, 50908, 3847, 527, 3209, 13, 50958, 50958, 407, 300, 311, 516, 490, 2319, 281, 1266, 11, 1360, 13, 51058, 51058, 400, 322, 264, 288, 12, 24633, 11, 321, 434, 1936, 13389, 264, 30621, 5003, 3389, 295, 613, 51322, 51322, 659, 12, 17227, 2001, 33358, 13, 51415, 51415, 400, 309, 311, 12690, 1228, 257, 20678, 1219, 4471, 11, 597, 307, 914, 4274, 18356, 13, 51640, 51640], "temperature": 0.0, "avg_logprob": -0.1466382406290295, "compression_ratio": 1.7479338842975207, "no_speech_prob": 1.3630841749545652e-05}, {"id": 813, "seek": 319304, "start": 3206.92, "end": 3212.2, "text": " And on the y-axis, we're basically measuring the downstream transfer performance of these", "tokens": [50364, 264, 2372, 295, 1589, 19147, 767, 3542, 294, 1101, 33358, 13, 50640, 50640, 407, 322, 264, 2031, 12, 24633, 11, 321, 434, 5662, 264, 1230, 295, 4784, 325, 763, 300, 321, 434, 1228, 281, 1936, 50908, 50908, 3847, 527, 3209, 13, 50958, 50958, 407, 300, 311, 516, 490, 2319, 281, 1266, 11, 1360, 13, 51058, 51058, 400, 322, 264, 288, 12, 24633, 11, 321, 434, 1936, 13389, 264, 30621, 5003, 3389, 295, 613, 51322, 51322, 659, 12, 17227, 2001, 33358, 13, 51415, 51415, 400, 309, 311, 12690, 1228, 257, 20678, 1219, 4471, 11, 597, 307, 914, 4274, 18356, 13, 51640, 51640], "temperature": 0.0, "avg_logprob": -0.1466382406290295, "compression_ratio": 1.7479338842975207, "no_speech_prob": 1.3630841749545652e-05}, {"id": 814, "seek": 319304, "start": 3212.2, "end": 3214.06, "text": " pre-trained representations.", "tokens": [50364, 264, 2372, 295, 1589, 19147, 767, 3542, 294, 1101, 33358, 13, 50640, 50640, 407, 322, 264, 2031, 12, 24633, 11, 321, 434, 5662, 264, 1230, 295, 4784, 325, 763, 300, 321, 434, 1228, 281, 1936, 50908, 50908, 3847, 527, 3209, 13, 50958, 50958, 407, 300, 311, 516, 490, 2319, 281, 1266, 11, 1360, 13, 51058, 51058, 400, 322, 264, 288, 12, 24633, 11, 321, 434, 1936, 13389, 264, 30621, 5003, 3389, 295, 613, 51322, 51322, 659, 12, 17227, 2001, 33358, 13, 51415, 51415, 400, 309, 311, 12690, 1228, 257, 20678, 1219, 4471, 11, 597, 307, 914, 4274, 18356, 13, 51640, 51640], "temperature": 0.0, "avg_logprob": -0.1466382406290295, "compression_ratio": 1.7479338842975207, "no_speech_prob": 1.3630841749545652e-05}, {"id": 815, "seek": 319304, "start": 3214.06, "end": 3218.56, "text": " And it's measured using a metric called map, which is mean average precision.", "tokens": [50364, 264, 2372, 295, 1589, 19147, 767, 3542, 294, 1101, 33358, 13, 50640, 50640, 407, 322, 264, 2031, 12, 24633, 11, 321, 434, 5662, 264, 1230, 295, 4784, 325, 763, 300, 321, 434, 1228, 281, 1936, 50908, 50908, 3847, 527, 3209, 13, 50958, 50958, 407, 300, 311, 516, 490, 2319, 281, 1266, 11, 1360, 13, 51058, 51058, 400, 322, 264, 288, 12, 24633, 11, 321, 434, 1936, 13389, 264, 30621, 5003, 3389, 295, 613, 51322, 51322, 659, 12, 17227, 2001, 33358, 13, 51415, 51415, 400, 309, 311, 12690, 1228, 257, 20678, 1219, 4471, 11, 597, 307, 914, 4274, 18356, 13, 51640, 51640], "temperature": 0.0, "avg_logprob": -0.1466382406290295, "compression_ratio": 1.7479338842975207, "no_speech_prob": 1.3630841749545652e-05}, {"id": 816, "seek": 321856, "start": 3218.56, "end": 3225.12, "text": " So essentially, because this is a sort of multi-level classification problem, you're", "tokens": [50364, 407, 4476, 11, 570, 341, 307, 257, 1333, 295, 4825, 12, 12418, 21538, 1154, 11, 291, 434, 50692, 50692, 516, 281, 3481, 4274, 18356, 337, 1184, 295, 264, 819, 945, 5359, 13, 50874, 50874, 400, 550, 291, 434, 516, 281, 14722, 264, 914, 295, 300, 4274, 18356, 13, 51022, 51022, 407, 2946, 307, 1101, 294, 341, 1389, 13, 51162, 51162, 407, 321, 360, 300, 337, 732, 819, 6331, 1303, 11, 5202, 31890, 11, 597, 390, 7993, 1143, 294, 264, 51378, 51378, 361, 17156, 1607, 3035, 11, 293, 550, 5015, 31890, 12, 2803, 13, 51544, 51544, 400, 437, 291, 11441, 307, 337, 5202, 31890, 11, 5662, 264, 2372, 295, 4784, 325, 763, 307, 4420, 493, 281, 51829, 51829], "temperature": 0.0, "avg_logprob": -0.12680370266697988, "compression_ratio": 1.6928571428571428, "no_speech_prob": 3.8447869883384556e-06}, {"id": 817, "seek": 321856, "start": 3225.12, "end": 3228.7599999999998, "text": " going to measure average precision for each of the different 20 classes.", "tokens": [50364, 407, 4476, 11, 570, 341, 307, 257, 1333, 295, 4825, 12, 12418, 21538, 1154, 11, 291, 434, 50692, 50692, 516, 281, 3481, 4274, 18356, 337, 1184, 295, 264, 819, 945, 5359, 13, 50874, 50874, 400, 550, 291, 434, 516, 281, 14722, 264, 914, 295, 300, 4274, 18356, 13, 51022, 51022, 407, 2946, 307, 1101, 294, 341, 1389, 13, 51162, 51162, 407, 321, 360, 300, 337, 732, 819, 6331, 1303, 11, 5202, 31890, 11, 597, 390, 7993, 1143, 294, 264, 51378, 51378, 361, 17156, 1607, 3035, 11, 293, 550, 5015, 31890, 12, 2803, 13, 51544, 51544, 400, 437, 291, 11441, 307, 337, 5202, 31890, 11, 5662, 264, 2372, 295, 4784, 325, 763, 307, 4420, 493, 281, 51829, 51829], "temperature": 0.0, "avg_logprob": -0.12680370266697988, "compression_ratio": 1.6928571428571428, "no_speech_prob": 3.8447869883384556e-06}, {"id": 818, "seek": 321856, "start": 3228.7599999999998, "end": 3231.72, "text": " And then you're going to compute the mean of that average precision.", "tokens": [50364, 407, 4476, 11, 570, 341, 307, 257, 1333, 295, 4825, 12, 12418, 21538, 1154, 11, 291, 434, 50692, 50692, 516, 281, 3481, 4274, 18356, 337, 1184, 295, 264, 819, 945, 5359, 13, 50874, 50874, 400, 550, 291, 434, 516, 281, 14722, 264, 914, 295, 300, 4274, 18356, 13, 51022, 51022, 407, 2946, 307, 1101, 294, 341, 1389, 13, 51162, 51162, 407, 321, 360, 300, 337, 732, 819, 6331, 1303, 11, 5202, 31890, 11, 597, 390, 7993, 1143, 294, 264, 51378, 51378, 361, 17156, 1607, 3035, 11, 293, 550, 5015, 31890, 12, 2803, 13, 51544, 51544, 400, 437, 291, 11441, 307, 337, 5202, 31890, 11, 5662, 264, 2372, 295, 4784, 325, 763, 307, 4420, 493, 281, 51829, 51829], "temperature": 0.0, "avg_logprob": -0.12680370266697988, "compression_ratio": 1.6928571428571428, "no_speech_prob": 3.8447869883384556e-06}, {"id": 819, "seek": 321856, "start": 3231.72, "end": 3234.52, "text": " So higher is better in this case.", "tokens": [50364, 407, 4476, 11, 570, 341, 307, 257, 1333, 295, 4825, 12, 12418, 21538, 1154, 11, 291, 434, 50692, 50692, 516, 281, 3481, 4274, 18356, 337, 1184, 295, 264, 819, 945, 5359, 13, 50874, 50874, 400, 550, 291, 434, 516, 281, 14722, 264, 914, 295, 300, 4274, 18356, 13, 51022, 51022, 407, 2946, 307, 1101, 294, 341, 1389, 13, 51162, 51162, 407, 321, 360, 300, 337, 732, 819, 6331, 1303, 11, 5202, 31890, 11, 597, 390, 7993, 1143, 294, 264, 51378, 51378, 361, 17156, 1607, 3035, 11, 293, 550, 5015, 31890, 12, 2803, 13, 51544, 51544, 400, 437, 291, 11441, 307, 337, 5202, 31890, 11, 5662, 264, 2372, 295, 4784, 325, 763, 307, 4420, 493, 281, 51829, 51829], "temperature": 0.0, "avg_logprob": -0.12680370266697988, "compression_ratio": 1.6928571428571428, "no_speech_prob": 3.8447869883384556e-06}, {"id": 820, "seek": 321856, "start": 3234.52, "end": 3238.84, "text": " So we do that for two different architectures, AlexNet, which was originally used in the", "tokens": [50364, 407, 4476, 11, 570, 341, 307, 257, 1333, 295, 4825, 12, 12418, 21538, 1154, 11, 291, 434, 50692, 50692, 516, 281, 3481, 4274, 18356, 337, 1184, 295, 264, 819, 945, 5359, 13, 50874, 50874, 400, 550, 291, 434, 516, 281, 14722, 264, 914, 295, 300, 4274, 18356, 13, 51022, 51022, 407, 2946, 307, 1101, 294, 341, 1389, 13, 51162, 51162, 407, 321, 360, 300, 337, 732, 819, 6331, 1303, 11, 5202, 31890, 11, 597, 390, 7993, 1143, 294, 264, 51378, 51378, 361, 17156, 1607, 3035, 11, 293, 550, 5015, 31890, 12, 2803, 13, 51544, 51544, 400, 437, 291, 11441, 307, 337, 5202, 31890, 11, 5662, 264, 2372, 295, 4784, 325, 763, 307, 4420, 493, 281, 51829, 51829], "temperature": 0.0, "avg_logprob": -0.12680370266697988, "compression_ratio": 1.6928571428571428, "no_speech_prob": 3.8447869883384556e-06}, {"id": 821, "seek": 321856, "start": 3238.84, "end": 3242.16, "text": " jigsaw paper, and then ResNet-50.", "tokens": [50364, 407, 4476, 11, 570, 341, 307, 257, 1333, 295, 4825, 12, 12418, 21538, 1154, 11, 291, 434, 50692, 50692, 516, 281, 3481, 4274, 18356, 337, 1184, 295, 264, 819, 945, 5359, 13, 50874, 50874, 400, 550, 291, 434, 516, 281, 14722, 264, 914, 295, 300, 4274, 18356, 13, 51022, 51022, 407, 2946, 307, 1101, 294, 341, 1389, 13, 51162, 51162, 407, 321, 360, 300, 337, 732, 819, 6331, 1303, 11, 5202, 31890, 11, 597, 390, 7993, 1143, 294, 264, 51378, 51378, 361, 17156, 1607, 3035, 11, 293, 550, 5015, 31890, 12, 2803, 13, 51544, 51544, 400, 437, 291, 11441, 307, 337, 5202, 31890, 11, 5662, 264, 2372, 295, 4784, 325, 763, 307, 4420, 493, 281, 51829, 51829], "temperature": 0.0, "avg_logprob": -0.12680370266697988, "compression_ratio": 1.6928571428571428, "no_speech_prob": 3.8447869883384556e-06}, {"id": 822, "seek": 321856, "start": 3242.16, "end": 3247.86, "text": " And what you observe is for AlexNet, increasing the amount of permutations is useful up to", "tokens": [50364, 407, 4476, 11, 570, 341, 307, 257, 1333, 295, 4825, 12, 12418, 21538, 1154, 11, 291, 434, 50692, 50692, 516, 281, 3481, 4274, 18356, 337, 1184, 295, 264, 819, 945, 5359, 13, 50874, 50874, 400, 550, 291, 434, 516, 281, 14722, 264, 914, 295, 300, 4274, 18356, 13, 51022, 51022, 407, 2946, 307, 1101, 294, 341, 1389, 13, 51162, 51162, 407, 321, 360, 300, 337, 732, 819, 6331, 1303, 11, 5202, 31890, 11, 597, 390, 7993, 1143, 294, 264, 51378, 51378, 361, 17156, 1607, 3035, 11, 293, 550, 5015, 31890, 12, 2803, 13, 51544, 51544, 400, 437, 291, 11441, 307, 337, 5202, 31890, 11, 5662, 264, 2372, 295, 4784, 325, 763, 307, 4420, 493, 281, 51829, 51829], "temperature": 0.0, "avg_logprob": -0.12680370266697988, "compression_ratio": 1.6928571428571428, "no_speech_prob": 3.8447869883384556e-06}, {"id": 823, "seek": 324786, "start": 3247.86, "end": 3250.7200000000003, "text": " a certain point, but the gain is overall limited.", "tokens": [50364, 257, 1629, 935, 11, 457, 264, 6052, 307, 4787, 5567, 13, 50507, 50507, 13813, 337, 5015, 31890, 11, 498, 291, 3488, 264, 2372, 295, 4784, 325, 763, 11, 264, 10290, 3125, 50775, 50775, 2170, 1101, 293, 1101, 13, 50935, 50935, 400, 527, 17291, 390, 1936, 300, 264, 5015, 31890, 2316, 575, 1547, 6042, 300, 309, 393, 51153, 51153, 767, 5039, 257, 588, 2252, 4784, 11380, 1154, 13, 51306, 51306, 400, 562, 309, 39890, 257, 2252, 4784, 11380, 1154, 11, 309, 311, 1075, 281, 1466, 709, 1101, 33358, 51555, 51555, 300, 2674, 1125, 281, 819, 30621, 9608, 13, 51743, 51743], "temperature": 0.0, "avg_logprob": -0.13224236327822847, "compression_ratio": 1.7509727626459144, "no_speech_prob": 7.889051630627364e-06}, {"id": 824, "seek": 324786, "start": 3250.7200000000003, "end": 3256.08, "text": " Whereas for ResNet, if you increase the amount of permutations, the representation quality", "tokens": [50364, 257, 1629, 935, 11, 457, 264, 6052, 307, 4787, 5567, 13, 50507, 50507, 13813, 337, 5015, 31890, 11, 498, 291, 3488, 264, 2372, 295, 4784, 325, 763, 11, 264, 10290, 3125, 50775, 50775, 2170, 1101, 293, 1101, 13, 50935, 50935, 400, 527, 17291, 390, 1936, 300, 264, 5015, 31890, 2316, 575, 1547, 6042, 300, 309, 393, 51153, 51153, 767, 5039, 257, 588, 2252, 4784, 11380, 1154, 13, 51306, 51306, 400, 562, 309, 39890, 257, 2252, 4784, 11380, 1154, 11, 309, 311, 1075, 281, 1466, 709, 1101, 33358, 51555, 51555, 300, 2674, 1125, 281, 819, 30621, 9608, 13, 51743, 51743], "temperature": 0.0, "avg_logprob": -0.13224236327822847, "compression_ratio": 1.7509727626459144, "no_speech_prob": 7.889051630627364e-06}, {"id": 825, "seek": 324786, "start": 3256.08, "end": 3259.28, "text": " gets better and better.", "tokens": [50364, 257, 1629, 935, 11, 457, 264, 6052, 307, 4787, 5567, 13, 50507, 50507, 13813, 337, 5015, 31890, 11, 498, 291, 3488, 264, 2372, 295, 4784, 325, 763, 11, 264, 10290, 3125, 50775, 50775, 2170, 1101, 293, 1101, 13, 50935, 50935, 400, 527, 17291, 390, 1936, 300, 264, 5015, 31890, 2316, 575, 1547, 6042, 300, 309, 393, 51153, 51153, 767, 5039, 257, 588, 2252, 4784, 11380, 1154, 13, 51306, 51306, 400, 562, 309, 39890, 257, 2252, 4784, 11380, 1154, 11, 309, 311, 1075, 281, 1466, 709, 1101, 33358, 51555, 51555, 300, 2674, 1125, 281, 819, 30621, 9608, 13, 51743, 51743], "temperature": 0.0, "avg_logprob": -0.13224236327822847, "compression_ratio": 1.7509727626459144, "no_speech_prob": 7.889051630627364e-06}, {"id": 826, "seek": 324786, "start": 3259.28, "end": 3263.6400000000003, "text": " And our hypothesis was basically that the ResNet model has enough capacity that it can", "tokens": [50364, 257, 1629, 935, 11, 457, 264, 6052, 307, 4787, 5567, 13, 50507, 50507, 13813, 337, 5015, 31890, 11, 498, 291, 3488, 264, 2372, 295, 4784, 325, 763, 11, 264, 10290, 3125, 50775, 50775, 2170, 1101, 293, 1101, 13, 50935, 50935, 400, 527, 17291, 390, 1936, 300, 264, 5015, 31890, 2316, 575, 1547, 6042, 300, 309, 393, 51153, 51153, 767, 5039, 257, 588, 2252, 4784, 11380, 1154, 13, 51306, 51306, 400, 562, 309, 39890, 257, 2252, 4784, 11380, 1154, 11, 309, 311, 1075, 281, 1466, 709, 1101, 33358, 51555, 51555, 300, 2674, 1125, 281, 819, 30621, 9608, 13, 51743, 51743], "temperature": 0.0, "avg_logprob": -0.13224236327822847, "compression_ratio": 1.7509727626459144, "no_speech_prob": 7.889051630627364e-06}, {"id": 827, "seek": 324786, "start": 3263.6400000000003, "end": 3266.7000000000003, "text": " actually solve a very difficult permutation problem.", "tokens": [50364, 257, 1629, 935, 11, 457, 264, 6052, 307, 4787, 5567, 13, 50507, 50507, 13813, 337, 5015, 31890, 11, 498, 291, 3488, 264, 2372, 295, 4784, 325, 763, 11, 264, 10290, 3125, 50775, 50775, 2170, 1101, 293, 1101, 13, 50935, 50935, 400, 527, 17291, 390, 1936, 300, 264, 5015, 31890, 2316, 575, 1547, 6042, 300, 309, 393, 51153, 51153, 767, 5039, 257, 588, 2252, 4784, 11380, 1154, 13, 51306, 51306, 400, 562, 309, 39890, 257, 2252, 4784, 11380, 1154, 11, 309, 311, 1075, 281, 1466, 709, 1101, 33358, 51555, 51555, 300, 2674, 1125, 281, 819, 30621, 9608, 13, 51743, 51743], "temperature": 0.0, "avg_logprob": -0.13224236327822847, "compression_ratio": 1.7509727626459144, "no_speech_prob": 7.889051630627364e-06}, {"id": 828, "seek": 324786, "start": 3266.7000000000003, "end": 3271.6800000000003, "text": " And when it solves a difficult permutation problem, it's able to learn much better representations", "tokens": [50364, 257, 1629, 935, 11, 457, 264, 6052, 307, 4787, 5567, 13, 50507, 50507, 13813, 337, 5015, 31890, 11, 498, 291, 3488, 264, 2372, 295, 4784, 325, 763, 11, 264, 10290, 3125, 50775, 50775, 2170, 1101, 293, 1101, 13, 50935, 50935, 400, 527, 17291, 390, 1936, 300, 264, 5015, 31890, 2316, 575, 1547, 6042, 300, 309, 393, 51153, 51153, 767, 5039, 257, 588, 2252, 4784, 11380, 1154, 13, 51306, 51306, 400, 562, 309, 39890, 257, 2252, 4784, 11380, 1154, 11, 309, 311, 1075, 281, 1466, 709, 1101, 33358, 51555, 51555, 300, 2674, 1125, 281, 819, 30621, 9608, 13, 51743, 51743], "temperature": 0.0, "avg_logprob": -0.13224236327822847, "compression_ratio": 1.7509727626459144, "no_speech_prob": 7.889051630627364e-06}, {"id": 829, "seek": 324786, "start": 3271.6800000000003, "end": 3275.44, "text": " that generalize to different downstream tasks.", "tokens": [50364, 257, 1629, 935, 11, 457, 264, 6052, 307, 4787, 5567, 13, 50507, 50507, 13813, 337, 5015, 31890, 11, 498, 291, 3488, 264, 2372, 295, 4784, 325, 763, 11, 264, 10290, 3125, 50775, 50775, 2170, 1101, 293, 1101, 13, 50935, 50935, 400, 527, 17291, 390, 1936, 300, 264, 5015, 31890, 2316, 575, 1547, 6042, 300, 309, 393, 51153, 51153, 767, 5039, 257, 588, 2252, 4784, 11380, 1154, 13, 51306, 51306, 400, 562, 309, 39890, 257, 2252, 4784, 11380, 1154, 11, 309, 311, 1075, 281, 1466, 709, 1101, 33358, 51555, 51555, 300, 2674, 1125, 281, 819, 30621, 9608, 13, 51743, 51743], "temperature": 0.0, "avg_logprob": -0.13224236327822847, "compression_ratio": 1.7509727626459144, "no_speech_prob": 7.889051630627364e-06}, {"id": 830, "seek": 327544, "start": 3275.44, "end": 3282.96, "text": " So the next thing we did was to evaluate our method on the object detection task.", "tokens": [50364, 407, 264, 958, 551, 321, 630, 390, 281, 13059, 527, 3170, 322, 264, 2657, 17784, 5633, 13, 50740, 50740, 407, 2657, 17784, 307, 1936, 689, 291, 853, 281, 5876, 437, 6565, 366, 1974, 294, 50968, 50968, 364, 3256, 13, 51018, 51018, 509, 853, 281, 2642, 257, 2424, 926, 552, 13, 51110, 51110, 400, 291, 434, 12690, 1936, 2361, 322, 577, 665, 264, 2424, 307, 926, 264, 2657, 293, 1968, 51346, 51346, 291, 645, 1075, 281, 5876, 439, 264, 6565, 294, 364, 3256, 13, 51550, 51550, 400, 797, 11, 337, 341, 472, 11, 321, 764, 264, 912, 22785, 34, 1412, 992, 13, 51764, 51764], "temperature": 0.0, "avg_logprob": -0.12262451535179501, "compression_ratio": 1.7991266375545851, "no_speech_prob": 8.267543307738379e-06}, {"id": 831, "seek": 327544, "start": 3282.96, "end": 3287.52, "text": " So object detection is basically where you try to identify what objects are present in", "tokens": [50364, 407, 264, 958, 551, 321, 630, 390, 281, 13059, 527, 3170, 322, 264, 2657, 17784, 5633, 13, 50740, 50740, 407, 2657, 17784, 307, 1936, 689, 291, 853, 281, 5876, 437, 6565, 366, 1974, 294, 50968, 50968, 364, 3256, 13, 51018, 51018, 509, 853, 281, 2642, 257, 2424, 926, 552, 13, 51110, 51110, 400, 291, 434, 12690, 1936, 2361, 322, 577, 665, 264, 2424, 307, 926, 264, 2657, 293, 1968, 51346, 51346, 291, 645, 1075, 281, 5876, 439, 264, 6565, 294, 364, 3256, 13, 51550, 51550, 400, 797, 11, 337, 341, 472, 11, 321, 764, 264, 912, 22785, 34, 1412, 992, 13, 51764, 51764], "temperature": 0.0, "avg_logprob": -0.12262451535179501, "compression_ratio": 1.7991266375545851, "no_speech_prob": 8.267543307738379e-06}, {"id": 832, "seek": 327544, "start": 3287.52, "end": 3288.52, "text": " an image.", "tokens": [50364, 407, 264, 958, 551, 321, 630, 390, 281, 13059, 527, 3170, 322, 264, 2657, 17784, 5633, 13, 50740, 50740, 407, 2657, 17784, 307, 1936, 689, 291, 853, 281, 5876, 437, 6565, 366, 1974, 294, 50968, 50968, 364, 3256, 13, 51018, 51018, 509, 853, 281, 2642, 257, 2424, 926, 552, 13, 51110, 51110, 400, 291, 434, 12690, 1936, 2361, 322, 577, 665, 264, 2424, 307, 926, 264, 2657, 293, 1968, 51346, 51346, 291, 645, 1075, 281, 5876, 439, 264, 6565, 294, 364, 3256, 13, 51550, 51550, 400, 797, 11, 337, 341, 472, 11, 321, 764, 264, 912, 22785, 34, 1412, 992, 13, 51764, 51764], "temperature": 0.0, "avg_logprob": -0.12262451535179501, "compression_ratio": 1.7991266375545851, "no_speech_prob": 8.267543307738379e-06}, {"id": 833, "seek": 327544, "start": 3288.52, "end": 3290.36, "text": " You try to draw a box around them.", "tokens": [50364, 407, 264, 958, 551, 321, 630, 390, 281, 13059, 527, 3170, 322, 264, 2657, 17784, 5633, 13, 50740, 50740, 407, 2657, 17784, 307, 1936, 689, 291, 853, 281, 5876, 437, 6565, 366, 1974, 294, 50968, 50968, 364, 3256, 13, 51018, 51018, 509, 853, 281, 2642, 257, 2424, 926, 552, 13, 51110, 51110, 400, 291, 434, 12690, 1936, 2361, 322, 577, 665, 264, 2424, 307, 926, 264, 2657, 293, 1968, 51346, 51346, 291, 645, 1075, 281, 5876, 439, 264, 6565, 294, 364, 3256, 13, 51550, 51550, 400, 797, 11, 337, 341, 472, 11, 321, 764, 264, 912, 22785, 34, 1412, 992, 13, 51764, 51764], "temperature": 0.0, "avg_logprob": -0.12262451535179501, "compression_ratio": 1.7991266375545851, "no_speech_prob": 8.267543307738379e-06}, {"id": 834, "seek": 327544, "start": 3290.36, "end": 3295.08, "text": " And you're measured basically based on how good the box is around the object and whether", "tokens": [50364, 407, 264, 958, 551, 321, 630, 390, 281, 13059, 527, 3170, 322, 264, 2657, 17784, 5633, 13, 50740, 50740, 407, 2657, 17784, 307, 1936, 689, 291, 853, 281, 5876, 437, 6565, 366, 1974, 294, 50968, 50968, 364, 3256, 13, 51018, 51018, 509, 853, 281, 2642, 257, 2424, 926, 552, 13, 51110, 51110, 400, 291, 434, 12690, 1936, 2361, 322, 577, 665, 264, 2424, 307, 926, 264, 2657, 293, 1968, 51346, 51346, 291, 645, 1075, 281, 5876, 439, 264, 6565, 294, 364, 3256, 13, 51550, 51550, 400, 797, 11, 337, 341, 472, 11, 321, 764, 264, 912, 22785, 34, 1412, 992, 13, 51764, 51764], "temperature": 0.0, "avg_logprob": -0.12262451535179501, "compression_ratio": 1.7991266375545851, "no_speech_prob": 8.267543307738379e-06}, {"id": 835, "seek": 327544, "start": 3295.08, "end": 3299.16, "text": " you were able to identify all the objects in an image.", "tokens": [50364, 407, 264, 958, 551, 321, 630, 390, 281, 13059, 527, 3170, 322, 264, 2657, 17784, 5633, 13, 50740, 50740, 407, 2657, 17784, 307, 1936, 689, 291, 853, 281, 5876, 437, 6565, 366, 1974, 294, 50968, 50968, 364, 3256, 13, 51018, 51018, 509, 853, 281, 2642, 257, 2424, 926, 552, 13, 51110, 51110, 400, 291, 434, 12690, 1936, 2361, 322, 577, 665, 264, 2424, 307, 926, 264, 2657, 293, 1968, 51346, 51346, 291, 645, 1075, 281, 5876, 439, 264, 6565, 294, 364, 3256, 13, 51550, 51550, 400, 797, 11, 337, 341, 472, 11, 321, 764, 264, 912, 22785, 34, 1412, 992, 13, 51764, 51764], "temperature": 0.0, "avg_logprob": -0.12262451535179501, "compression_ratio": 1.7991266375545851, "no_speech_prob": 8.267543307738379e-06}, {"id": 836, "seek": 327544, "start": 3299.16, "end": 3303.44, "text": " And again, for this one, we use the same BOC data set.", "tokens": [50364, 407, 264, 958, 551, 321, 630, 390, 281, 13059, 527, 3170, 322, 264, 2657, 17784, 5633, 13, 50740, 50740, 407, 2657, 17784, 307, 1936, 689, 291, 853, 281, 5876, 437, 6565, 366, 1974, 294, 50968, 50968, 364, 3256, 13, 51018, 51018, 509, 853, 281, 2642, 257, 2424, 926, 552, 13, 51110, 51110, 400, 291, 434, 12690, 1936, 2361, 322, 577, 665, 264, 2424, 307, 926, 264, 2657, 293, 1968, 51346, 51346, 291, 645, 1075, 281, 5876, 439, 264, 6565, 294, 364, 3256, 13, 51550, 51550, 400, 797, 11, 337, 341, 472, 11, 321, 764, 264, 912, 22785, 34, 1412, 992, 13, 51764, 51764], "temperature": 0.0, "avg_logprob": -0.12262451535179501, "compression_ratio": 1.7991266375545851, "no_speech_prob": 8.267543307738379e-06}, {"id": 837, "seek": 330344, "start": 3303.44, "end": 3308.9, "text": " So this was the setting where we basically fine-tuned all the layers of a network because", "tokens": [50364, 407, 341, 390, 264, 3287, 689, 321, 1936, 2489, 12, 83, 43703, 439, 264, 7914, 295, 257, 3209, 570, 50637, 50637, 300, 311, 437, 311, 3832, 294, 17784, 13, 50762, 50762, 400, 437, 321, 13095, 390, 1936, 322, 732, 819, 37741, 295, 341, 22785, 34, 1412, 992, 11, 264, 51132, 51132, 361, 17156, 1607, 3170, 390, 767, 6457, 25323, 1951, 264, 10270, 295, 6713, 281, 1936, 3097, 51434, 51434, 257, 3256, 2533, 46533, 3170, 13, 51546, 51546, 407, 291, 362, 364, 3256, 2533, 46533, 3209, 13, 51664, 51664], "temperature": 0.0, "avg_logprob": -0.18197797139485677, "compression_ratio": 1.6710526315789473, "no_speech_prob": 4.565879407891771e-06}, {"id": 838, "seek": 330344, "start": 3308.9, "end": 3311.4, "text": " that's what's standard in detection.", "tokens": [50364, 407, 341, 390, 264, 3287, 689, 321, 1936, 2489, 12, 83, 43703, 439, 264, 7914, 295, 257, 3209, 570, 50637, 50637, 300, 311, 437, 311, 3832, 294, 17784, 13, 50762, 50762, 400, 437, 321, 13095, 390, 1936, 322, 732, 819, 37741, 295, 341, 22785, 34, 1412, 992, 11, 264, 51132, 51132, 361, 17156, 1607, 3170, 390, 767, 6457, 25323, 1951, 264, 10270, 295, 6713, 281, 1936, 3097, 51434, 51434, 257, 3256, 2533, 46533, 3170, 13, 51546, 51546, 407, 291, 362, 364, 3256, 2533, 46533, 3209, 13, 51664, 51664], "temperature": 0.0, "avg_logprob": -0.18197797139485677, "compression_ratio": 1.6710526315789473, "no_speech_prob": 4.565879407891771e-06}, {"id": 839, "seek": 330344, "start": 3311.4, "end": 3318.8, "text": " And what we observed was basically on two different splits of this BOC data set, the", "tokens": [50364, 407, 341, 390, 264, 3287, 689, 321, 1936, 2489, 12, 83, 43703, 439, 264, 7914, 295, 257, 3209, 570, 50637, 50637, 300, 311, 437, 311, 3832, 294, 17784, 13, 50762, 50762, 400, 437, 321, 13095, 390, 1936, 322, 732, 819, 37741, 295, 341, 22785, 34, 1412, 992, 11, 264, 51132, 51132, 361, 17156, 1607, 3170, 390, 767, 6457, 25323, 1951, 264, 10270, 295, 6713, 281, 1936, 3097, 51434, 51434, 257, 3256, 2533, 46533, 3170, 13, 51546, 51546, 407, 291, 362, 364, 3256, 2533, 46533, 3209, 13, 51664, 51664], "temperature": 0.0, "avg_logprob": -0.18197797139485677, "compression_ratio": 1.6710526315789473, "no_speech_prob": 4.565879407891771e-06}, {"id": 840, "seek": 330344, "start": 3318.8, "end": 3324.84, "text": " jigsaw method was actually fairly comparable within the margin of error to basically training", "tokens": [50364, 407, 341, 390, 264, 3287, 689, 321, 1936, 2489, 12, 83, 43703, 439, 264, 7914, 295, 257, 3209, 570, 50637, 50637, 300, 311, 437, 311, 3832, 294, 17784, 13, 50762, 50762, 400, 437, 321, 13095, 390, 1936, 322, 732, 819, 37741, 295, 341, 22785, 34, 1412, 992, 11, 264, 51132, 51132, 361, 17156, 1607, 3170, 390, 767, 6457, 25323, 1951, 264, 10270, 295, 6713, 281, 1936, 3097, 51434, 51434, 257, 3256, 2533, 46533, 3170, 13, 51546, 51546, 407, 291, 362, 364, 3256, 2533, 46533, 3209, 13, 51664, 51664], "temperature": 0.0, "avg_logprob": -0.18197797139485677, "compression_ratio": 1.6710526315789473, "no_speech_prob": 4.565879407891771e-06}, {"id": 841, "seek": 330344, "start": 3324.84, "end": 3327.08, "text": " a image net supervised method.", "tokens": [50364, 407, 341, 390, 264, 3287, 689, 321, 1936, 2489, 12, 83, 43703, 439, 264, 7914, 295, 257, 3209, 570, 50637, 50637, 300, 311, 437, 311, 3832, 294, 17784, 13, 50762, 50762, 400, 437, 321, 13095, 390, 1936, 322, 732, 819, 37741, 295, 341, 22785, 34, 1412, 992, 11, 264, 51132, 51132, 361, 17156, 1607, 3170, 390, 767, 6457, 25323, 1951, 264, 10270, 295, 6713, 281, 1936, 3097, 51434, 51434, 257, 3256, 2533, 46533, 3170, 13, 51546, 51546, 407, 291, 362, 364, 3256, 2533, 46533, 3209, 13, 51664, 51664], "temperature": 0.0, "avg_logprob": -0.18197797139485677, "compression_ratio": 1.6710526315789473, "no_speech_prob": 4.565879407891771e-06}, {"id": 842, "seek": 330344, "start": 3327.08, "end": 3329.44, "text": " So you have an image net supervised network.", "tokens": [50364, 407, 341, 390, 264, 3287, 689, 321, 1936, 2489, 12, 83, 43703, 439, 264, 7914, 295, 257, 3209, 570, 50637, 50637, 300, 311, 437, 311, 3832, 294, 17784, 13, 50762, 50762, 400, 437, 321, 13095, 390, 1936, 322, 732, 819, 37741, 295, 341, 22785, 34, 1412, 992, 11, 264, 51132, 51132, 361, 17156, 1607, 3170, 390, 767, 6457, 25323, 1951, 264, 10270, 295, 6713, 281, 1936, 3097, 51434, 51434, 257, 3256, 2533, 46533, 3170, 13, 51546, 51546, 407, 291, 362, 364, 3256, 2533, 46533, 3209, 13, 51664, 51664], "temperature": 0.0, "avg_logprob": -0.18197797139485677, "compression_ratio": 1.6710526315789473, "no_speech_prob": 4.565879407891771e-06}, {"id": 843, "seek": 332944, "start": 3329.44, "end": 3335.08, "text": " You fine-tune that on the task of detection and you get a mean average precision of 70.5", "tokens": [50364, 509, 2489, 12, 83, 2613, 300, 322, 264, 5633, 295, 17784, 293, 291, 483, 257, 914, 4274, 18356, 295, 5285, 13, 20, 50646, 50646, 420, 24733, 13, 17, 13, 50734, 50734, 400, 264, 361, 17156, 1607, 3170, 307, 1936, 1951, 264, 10270, 295, 6713, 295, 613, 7150, 11, 597, 50964, 50964, 294, 2564, 1333, 295, 3110, 300, 309, 767, 632, 512, 1333, 295, 1481, 47982, 4707, 293, 309, 51272, 51272, 390, 1075, 281, 2654, 1125, 6565, 534, 731, 13, 51558, 51558], "temperature": 0.0, "avg_logprob": -0.156517603311194, "compression_ratio": 1.5048076923076923, "no_speech_prob": 6.540323738590814e-06}, {"id": 844, "seek": 332944, "start": 3335.08, "end": 3336.84, "text": " or 76.2.", "tokens": [50364, 509, 2489, 12, 83, 2613, 300, 322, 264, 5633, 295, 17784, 293, 291, 483, 257, 914, 4274, 18356, 295, 5285, 13, 20, 50646, 50646, 420, 24733, 13, 17, 13, 50734, 50734, 400, 264, 361, 17156, 1607, 3170, 307, 1936, 1951, 264, 10270, 295, 6713, 295, 613, 7150, 11, 597, 50964, 50964, 294, 2564, 1333, 295, 3110, 300, 309, 767, 632, 512, 1333, 295, 1481, 47982, 4707, 293, 309, 51272, 51272, 390, 1075, 281, 2654, 1125, 6565, 534, 731, 13, 51558, 51558], "temperature": 0.0, "avg_logprob": -0.156517603311194, "compression_ratio": 1.5048076923076923, "no_speech_prob": 6.540323738590814e-06}, {"id": 845, "seek": 332944, "start": 3336.84, "end": 3341.44, "text": " And the jigsaw method is basically within the margin of error of these methods, which", "tokens": [50364, 509, 2489, 12, 83, 2613, 300, 322, 264, 5633, 295, 17784, 293, 291, 483, 257, 914, 4274, 18356, 295, 5285, 13, 20, 50646, 50646, 420, 24733, 13, 17, 13, 50734, 50734, 400, 264, 361, 17156, 1607, 3170, 307, 1936, 1951, 264, 10270, 295, 6713, 295, 613, 7150, 11, 597, 50964, 50964, 294, 2564, 1333, 295, 3110, 300, 309, 767, 632, 512, 1333, 295, 1481, 47982, 4707, 293, 309, 51272, 51272, 390, 1075, 281, 2654, 1125, 6565, 534, 731, 13, 51558, 51558], "temperature": 0.0, "avg_logprob": -0.156517603311194, "compression_ratio": 1.5048076923076923, "no_speech_prob": 6.540323738590814e-06}, {"id": 846, "seek": 332944, "start": 3341.44, "end": 3347.6, "text": " in itself sort of shows that it actually had some sort of nice semantic property and it", "tokens": [50364, 509, 2489, 12, 83, 2613, 300, 322, 264, 5633, 295, 17784, 293, 291, 483, 257, 914, 4274, 18356, 295, 5285, 13, 20, 50646, 50646, 420, 24733, 13, 17, 13, 50734, 50734, 400, 264, 361, 17156, 1607, 3170, 307, 1936, 1951, 264, 10270, 295, 6713, 295, 613, 7150, 11, 597, 50964, 50964, 294, 2564, 1333, 295, 3110, 300, 309, 767, 632, 512, 1333, 295, 1481, 47982, 4707, 293, 309, 51272, 51272, 390, 1075, 281, 2654, 1125, 6565, 534, 731, 13, 51558, 51558], "temperature": 0.0, "avg_logprob": -0.156517603311194, "compression_ratio": 1.5048076923076923, "no_speech_prob": 6.540323738590814e-06}, {"id": 847, "seek": 332944, "start": 3347.6, "end": 3353.32, "text": " was able to localize objects really well.", "tokens": [50364, 509, 2489, 12, 83, 2613, 300, 322, 264, 5633, 295, 17784, 293, 291, 483, 257, 914, 4274, 18356, 295, 5285, 13, 20, 50646, 50646, 420, 24733, 13, 17, 13, 50734, 50734, 400, 264, 361, 17156, 1607, 3170, 307, 1936, 1951, 264, 10270, 295, 6713, 295, 613, 7150, 11, 597, 50964, 50964, 294, 2564, 1333, 295, 3110, 300, 309, 767, 632, 512, 1333, 295, 1481, 47982, 4707, 293, 309, 51272, 51272, 390, 1075, 281, 2654, 1125, 6565, 534, 731, 13, 51558, 51558], "temperature": 0.0, "avg_logprob": -0.156517603311194, "compression_ratio": 1.5048076923076923, "no_speech_prob": 6.540323738590814e-06}, {"id": 848, "seek": 335332, "start": 3353.32, "end": 3361.04, "text": " And to put this sort of in context, for semantic feature learning in computer vision, especially,", "tokens": [50364, 400, 281, 829, 341, 1333, 295, 294, 4319, 11, 337, 47982, 4111, 2539, 294, 3820, 5201, 11, 2318, 11, 50750, 50750, 2657, 17784, 307, 1333, 295, 4888, 264, 18927, 1412, 992, 281, 360, 746, 534, 50982, 50982, 731, 322, 13, 51036, 51036, 400, 341, 1874, 11, 1936, 562, 321, 600, 1333, 295, 6572, 309, 11, 390, 264, 13699, 2878, 632, 51268, 51268, 1562, 808, 281, 46533, 659, 12, 17227, 1760, 294, 2115, 295, 17784, 13, 51732, 51732, 2188, 1168, 30, 51782, 51782], "temperature": 0.0, "avg_logprob": -0.24990372430710567, "compression_ratio": 1.59009009009009, "no_speech_prob": 6.240746188268531e-06}, {"id": 849, "seek": 335332, "start": 3361.04, "end": 3365.6800000000003, "text": " object detection is sort of considered the benchmark data set to do something really", "tokens": [50364, 400, 281, 829, 341, 1333, 295, 294, 4319, 11, 337, 47982, 4111, 2539, 294, 3820, 5201, 11, 2318, 11, 50750, 50750, 2657, 17784, 307, 1333, 295, 4888, 264, 18927, 1412, 992, 281, 360, 746, 534, 50982, 50982, 731, 322, 13, 51036, 51036, 400, 341, 1874, 11, 1936, 562, 321, 600, 1333, 295, 6572, 309, 11, 390, 264, 13699, 2878, 632, 51268, 51268, 1562, 808, 281, 46533, 659, 12, 17227, 1760, 294, 2115, 295, 17784, 13, 51732, 51732, 2188, 1168, 30, 51782, 51782], "temperature": 0.0, "avg_logprob": -0.24990372430710567, "compression_ratio": 1.59009009009009, "no_speech_prob": 6.240746188268531e-06}, {"id": 850, "seek": 335332, "start": 3365.6800000000003, "end": 3366.76, "text": " well on.", "tokens": [50364, 400, 281, 829, 341, 1333, 295, 294, 4319, 11, 337, 47982, 4111, 2539, 294, 3820, 5201, 11, 2318, 11, 50750, 50750, 2657, 17784, 307, 1333, 295, 4888, 264, 18927, 1412, 992, 281, 360, 746, 534, 50982, 50982, 731, 322, 13, 51036, 51036, 400, 341, 1874, 11, 1936, 562, 321, 600, 1333, 295, 6572, 309, 11, 390, 264, 13699, 2878, 632, 51268, 51268, 1562, 808, 281, 46533, 659, 12, 17227, 1760, 294, 2115, 295, 17784, 13, 51732, 51732, 2188, 1168, 30, 51782, 51782], "temperature": 0.0, "avg_logprob": -0.24990372430710567, "compression_ratio": 1.59009009009009, "no_speech_prob": 6.240746188268531e-06}, {"id": 851, "seek": 335332, "start": 3366.76, "end": 3371.4, "text": " And this result, basically when we've sort of published it, was the closest anyone had", "tokens": [50364, 400, 281, 829, 341, 1333, 295, 294, 4319, 11, 337, 47982, 4111, 2539, 294, 3820, 5201, 11, 2318, 11, 50750, 50750, 2657, 17784, 307, 1333, 295, 4888, 264, 18927, 1412, 992, 281, 360, 746, 534, 50982, 50982, 731, 322, 13, 51036, 51036, 400, 341, 1874, 11, 1936, 562, 321, 600, 1333, 295, 6572, 309, 11, 390, 264, 13699, 2878, 632, 51268, 51268, 1562, 808, 281, 46533, 659, 12, 17227, 1760, 294, 2115, 295, 17784, 13, 51732, 51732, 2188, 1168, 30, 51782, 51782], "temperature": 0.0, "avg_logprob": -0.24990372430710567, "compression_ratio": 1.59009009009009, "no_speech_prob": 6.240746188268531e-06}, {"id": 852, "seek": 335332, "start": 3371.4, "end": 3380.6800000000003, "text": " ever come to supervised pre-training in terms of detection.", "tokens": [50364, 400, 281, 829, 341, 1333, 295, 294, 4319, 11, 337, 47982, 4111, 2539, 294, 3820, 5201, 11, 2318, 11, 50750, 50750, 2657, 17784, 307, 1333, 295, 4888, 264, 18927, 1412, 992, 281, 360, 746, 534, 50982, 50982, 731, 322, 13, 51036, 51036, 400, 341, 1874, 11, 1936, 562, 321, 600, 1333, 295, 6572, 309, 11, 390, 264, 13699, 2878, 632, 51268, 51268, 1562, 808, 281, 46533, 659, 12, 17227, 1760, 294, 2115, 295, 17784, 13, 51732, 51732, 2188, 1168, 30, 51782, 51782], "temperature": 0.0, "avg_logprob": -0.24990372430710567, "compression_ratio": 1.59009009009009, "no_speech_prob": 6.240746188268531e-06}, {"id": 853, "seek": 335332, "start": 3380.6800000000003, "end": 3381.6800000000003, "text": " Some question?", "tokens": [50364, 400, 281, 829, 341, 1333, 295, 294, 4319, 11, 337, 47982, 4111, 2539, 294, 3820, 5201, 11, 2318, 11, 50750, 50750, 2657, 17784, 307, 1333, 295, 4888, 264, 18927, 1412, 992, 281, 360, 746, 534, 50982, 50982, 731, 322, 13, 51036, 51036, 400, 341, 1874, 11, 1936, 562, 321, 600, 1333, 295, 6572, 309, 11, 390, 264, 13699, 2878, 632, 51268, 51268, 1562, 808, 281, 46533, 659, 12, 17227, 1760, 294, 2115, 295, 17784, 13, 51732, 51732, 2188, 1168, 30, 51782, 51782], "temperature": 0.0, "avg_logprob": -0.24990372430710567, "compression_ratio": 1.59009009009009, "no_speech_prob": 6.240746188268531e-06}, {"id": 854, "seek": 338168, "start": 3381.68, "end": 3388.24, "text": " So is pre-text tasks similar to what we could try achieving with transfer learning?", "tokens": [50364, 407, 307, 659, 12, 25111, 9608, 2531, 281, 437, 321, 727, 853, 19626, 365, 5003, 2539, 30, 50692, 50692, 1119, 309, 411, 257, 25993, 295, 300, 420, 30, 50786, 50786, 1079, 13, 50836, 50836, 407, 11, 286, 914, 11, 264, 636, 291, 13059, 613, 659, 12, 25111, 9608, 307, 538, 5003, 2539, 13, 51002, 51002, 407, 291, 2042, 428, 3380, 659, 12, 25111, 5633, 293, 550, 291, 2489, 12, 83, 2613, 309, 322, 257, 1412, 992, 337, 51232, 51232, 257, 1729, 5633, 411, 17784, 13, 51306, 51306, 407, 264, 13344, 307, 1009, 5003, 2539, 13, 51752, 51752], "temperature": 0.0, "avg_logprob": -0.1618590114092586, "compression_ratio": 1.7393364928909953, "no_speech_prob": 1.241107293026289e-05}, {"id": 855, "seek": 338168, "start": 3388.24, "end": 3390.12, "text": " Is it like a subset of that or?", "tokens": [50364, 407, 307, 659, 12, 25111, 9608, 2531, 281, 437, 321, 727, 853, 19626, 365, 5003, 2539, 30, 50692, 50692, 1119, 309, 411, 257, 25993, 295, 300, 420, 30, 50786, 50786, 1079, 13, 50836, 50836, 407, 11, 286, 914, 11, 264, 636, 291, 13059, 613, 659, 12, 25111, 9608, 307, 538, 5003, 2539, 13, 51002, 51002, 407, 291, 2042, 428, 3380, 659, 12, 25111, 5633, 293, 550, 291, 2489, 12, 83, 2613, 309, 322, 257, 1412, 992, 337, 51232, 51232, 257, 1729, 5633, 411, 17784, 13, 51306, 51306, 407, 264, 13344, 307, 1009, 5003, 2539, 13, 51752, 51752], "temperature": 0.0, "avg_logprob": -0.1618590114092586, "compression_ratio": 1.7393364928909953, "no_speech_prob": 1.241107293026289e-05}, {"id": 856, "seek": 338168, "start": 3390.12, "end": 3391.12, "text": " Yes.", "tokens": [50364, 407, 307, 659, 12, 25111, 9608, 2531, 281, 437, 321, 727, 853, 19626, 365, 5003, 2539, 30, 50692, 50692, 1119, 309, 411, 257, 25993, 295, 300, 420, 30, 50786, 50786, 1079, 13, 50836, 50836, 407, 11, 286, 914, 11, 264, 636, 291, 13059, 613, 659, 12, 25111, 9608, 307, 538, 5003, 2539, 13, 51002, 51002, 407, 291, 2042, 428, 3380, 659, 12, 25111, 5633, 293, 550, 291, 2489, 12, 83, 2613, 309, 322, 257, 1412, 992, 337, 51232, 51232, 257, 1729, 5633, 411, 17784, 13, 51306, 51306, 407, 264, 13344, 307, 1009, 5003, 2539, 13, 51752, 51752], "temperature": 0.0, "avg_logprob": -0.1618590114092586, "compression_ratio": 1.7393364928909953, "no_speech_prob": 1.241107293026289e-05}, {"id": 857, "seek": 338168, "start": 3391.12, "end": 3394.44, "text": " So, I mean, the way you evaluate these pre-text tasks is by transfer learning.", "tokens": [50364, 407, 307, 659, 12, 25111, 9608, 2531, 281, 437, 321, 727, 853, 19626, 365, 5003, 2539, 30, 50692, 50692, 1119, 309, 411, 257, 25993, 295, 300, 420, 30, 50786, 50786, 1079, 13, 50836, 50836, 407, 11, 286, 914, 11, 264, 636, 291, 13059, 613, 659, 12, 25111, 9608, 307, 538, 5003, 2539, 13, 51002, 51002, 407, 291, 2042, 428, 3380, 659, 12, 25111, 5633, 293, 550, 291, 2489, 12, 83, 2613, 309, 322, 257, 1412, 992, 337, 51232, 51232, 257, 1729, 5633, 411, 17784, 13, 51306, 51306, 407, 264, 13344, 307, 1009, 5003, 2539, 13, 51752, 51752], "temperature": 0.0, "avg_logprob": -0.1618590114092586, "compression_ratio": 1.7393364928909953, "no_speech_prob": 1.241107293026289e-05}, {"id": 858, "seek": 338168, "start": 3394.44, "end": 3399.04, "text": " So you perform your original pre-text task and then you fine-tune it on a data set for", "tokens": [50364, 407, 307, 659, 12, 25111, 9608, 2531, 281, 437, 321, 727, 853, 19626, 365, 5003, 2539, 30, 50692, 50692, 1119, 309, 411, 257, 25993, 295, 300, 420, 30, 50786, 50786, 1079, 13, 50836, 50836, 407, 11, 286, 914, 11, 264, 636, 291, 13059, 613, 659, 12, 25111, 9608, 307, 538, 5003, 2539, 13, 51002, 51002, 407, 291, 2042, 428, 3380, 659, 12, 25111, 5633, 293, 550, 291, 2489, 12, 83, 2613, 309, 322, 257, 1412, 992, 337, 51232, 51232, 257, 1729, 5633, 411, 17784, 13, 51306, 51306, 407, 264, 13344, 307, 1009, 5003, 2539, 13, 51752, 51752], "temperature": 0.0, "avg_logprob": -0.1618590114092586, "compression_ratio": 1.7393364928909953, "no_speech_prob": 1.241107293026289e-05}, {"id": 859, "seek": 338168, "start": 3399.04, "end": 3400.52, "text": " a particular task like detection.", "tokens": [50364, 407, 307, 659, 12, 25111, 9608, 2531, 281, 437, 321, 727, 853, 19626, 365, 5003, 2539, 30, 50692, 50692, 1119, 309, 411, 257, 25993, 295, 300, 420, 30, 50786, 50786, 1079, 13, 50836, 50836, 407, 11, 286, 914, 11, 264, 636, 291, 13059, 613, 659, 12, 25111, 9608, 307, 538, 5003, 2539, 13, 51002, 51002, 407, 291, 2042, 428, 3380, 659, 12, 25111, 5633, 293, 550, 291, 2489, 12, 83, 2613, 309, 322, 257, 1412, 992, 337, 51232, 51232, 257, 1729, 5633, 411, 17784, 13, 51306, 51306, 407, 264, 13344, 307, 1009, 5003, 2539, 13, 51752, 51752], "temperature": 0.0, "avg_logprob": -0.1618590114092586, "compression_ratio": 1.7393364928909953, "no_speech_prob": 1.241107293026289e-05}, {"id": 860, "seek": 338168, "start": 3400.52, "end": 3409.44, "text": " So the evaluation is always transfer learning.", "tokens": [50364, 407, 307, 659, 12, 25111, 9608, 2531, 281, 437, 321, 727, 853, 19626, 365, 5003, 2539, 30, 50692, 50692, 1119, 309, 411, 257, 25993, 295, 300, 420, 30, 50786, 50786, 1079, 13, 50836, 50836, 407, 11, 286, 914, 11, 264, 636, 291, 13059, 613, 659, 12, 25111, 9608, 307, 538, 5003, 2539, 13, 51002, 51002, 407, 291, 2042, 428, 3380, 659, 12, 25111, 5633, 293, 550, 291, 2489, 12, 83, 2613, 309, 322, 257, 1412, 992, 337, 51232, 51232, 257, 1729, 5633, 411, 17784, 13, 51306, 51306, 407, 264, 13344, 307, 1009, 5003, 2539, 13, 51752, 51752], "temperature": 0.0, "avg_logprob": -0.1618590114092586, "compression_ratio": 1.7393364928909953, "no_speech_prob": 1.241107293026289e-05}, {"id": 861, "seek": 340944, "start": 3409.44, "end": 3413.52, "text": " So the next task we looked at was surface normal evaluation.", "tokens": [50364, 407, 264, 958, 5633, 321, 2956, 412, 390, 3753, 2710, 13344, 13, 50568, 50568, 407, 341, 307, 1936, 2212, 4846, 13, 50700, 50700, 509, 853, 281, 12539, 437, 366, 264, 805, 35, 7221, 295, 264, 11, 411, 1936, 412, 1184, 19261, 4914, 50988, 50988, 294, 264, 4846, 13, 51038, 51038, 407, 291, 853, 281, 6069, 437, 307, 264, 3753, 14764, 13, 51180, 51180, 407, 294, 805, 35, 11, 1936, 264, 1783, 11, 398, 11, 293, 1176, 18875, 412, 1184, 1729, 3753, 13, 51500, 51500, 407, 309, 311, 257, 1333, 295, 18011, 17630, 1154, 689, 291, 643, 281, 6269, 300, 1783, 11, 398, 11, 1176, 8062, 51714, 51714, 281, 1184, 4914, 294, 264, 4846, 13, 51842, 51842], "temperature": 0.0, "avg_logprob": -0.12355224156783799, "compression_ratio": 1.8097165991902835, "no_speech_prob": 1.6186848370125517e-05}, {"id": 862, "seek": 340944, "start": 3413.52, "end": 3416.16, "text": " So this is basically given input.", "tokens": [50364, 407, 264, 958, 5633, 321, 2956, 412, 390, 3753, 2710, 13344, 13, 50568, 50568, 407, 341, 307, 1936, 2212, 4846, 13, 50700, 50700, 509, 853, 281, 12539, 437, 366, 264, 805, 35, 7221, 295, 264, 11, 411, 1936, 412, 1184, 19261, 4914, 50988, 50988, 294, 264, 4846, 13, 51038, 51038, 407, 291, 853, 281, 6069, 437, 307, 264, 3753, 14764, 13, 51180, 51180, 407, 294, 805, 35, 11, 1936, 264, 1783, 11, 398, 11, 293, 1176, 18875, 412, 1184, 1729, 3753, 13, 51500, 51500, 407, 309, 311, 257, 1333, 295, 18011, 17630, 1154, 689, 291, 643, 281, 6269, 300, 1783, 11, 398, 11, 1176, 8062, 51714, 51714, 281, 1184, 4914, 294, 264, 4846, 13, 51842, 51842], "temperature": 0.0, "avg_logprob": -0.12355224156783799, "compression_ratio": 1.8097165991902835, "no_speech_prob": 1.6186848370125517e-05}, {"id": 863, "seek": 340944, "start": 3416.16, "end": 3421.92, "text": " You try to estimate what are the 3D properties of the, like basically at each pixel location", "tokens": [50364, 407, 264, 958, 5633, 321, 2956, 412, 390, 3753, 2710, 13344, 13, 50568, 50568, 407, 341, 307, 1936, 2212, 4846, 13, 50700, 50700, 509, 853, 281, 12539, 437, 366, 264, 805, 35, 7221, 295, 264, 11, 411, 1936, 412, 1184, 19261, 4914, 50988, 50988, 294, 264, 4846, 13, 51038, 51038, 407, 291, 853, 281, 6069, 437, 307, 264, 3753, 14764, 13, 51180, 51180, 407, 294, 805, 35, 11, 1936, 264, 1783, 11, 398, 11, 293, 1176, 18875, 412, 1184, 1729, 3753, 13, 51500, 51500, 407, 309, 311, 257, 1333, 295, 18011, 17630, 1154, 689, 291, 643, 281, 6269, 300, 1783, 11, 398, 11, 1176, 8062, 51714, 51714, 281, 1184, 4914, 294, 264, 4846, 13, 51842, 51842], "temperature": 0.0, "avg_logprob": -0.12355224156783799, "compression_ratio": 1.8097165991902835, "no_speech_prob": 1.6186848370125517e-05}, {"id": 864, "seek": 340944, "start": 3421.92, "end": 3422.92, "text": " in the input.", "tokens": [50364, 407, 264, 958, 5633, 321, 2956, 412, 390, 3753, 2710, 13344, 13, 50568, 50568, 407, 341, 307, 1936, 2212, 4846, 13, 50700, 50700, 509, 853, 281, 12539, 437, 366, 264, 805, 35, 7221, 295, 264, 11, 411, 1936, 412, 1184, 19261, 4914, 50988, 50988, 294, 264, 4846, 13, 51038, 51038, 407, 291, 853, 281, 6069, 437, 307, 264, 3753, 14764, 13, 51180, 51180, 407, 294, 805, 35, 11, 1936, 264, 1783, 11, 398, 11, 293, 1176, 18875, 412, 1184, 1729, 3753, 13, 51500, 51500, 407, 309, 311, 257, 1333, 295, 18011, 17630, 1154, 689, 291, 643, 281, 6269, 300, 1783, 11, 398, 11, 1176, 8062, 51714, 51714, 281, 1184, 4914, 294, 264, 4846, 13, 51842, 51842], "temperature": 0.0, "avg_logprob": -0.12355224156783799, "compression_ratio": 1.8097165991902835, "no_speech_prob": 1.6186848370125517e-05}, {"id": 865, "seek": 340944, "start": 3422.92, "end": 3425.76, "text": " So you try to predict what is the surface orientation.", "tokens": [50364, 407, 264, 958, 5633, 321, 2956, 412, 390, 3753, 2710, 13344, 13, 50568, 50568, 407, 341, 307, 1936, 2212, 4846, 13, 50700, 50700, 509, 853, 281, 12539, 437, 366, 264, 805, 35, 7221, 295, 264, 11, 411, 1936, 412, 1184, 19261, 4914, 50988, 50988, 294, 264, 4846, 13, 51038, 51038, 407, 291, 853, 281, 6069, 437, 307, 264, 3753, 14764, 13, 51180, 51180, 407, 294, 805, 35, 11, 1936, 264, 1783, 11, 398, 11, 293, 1176, 18875, 412, 1184, 1729, 3753, 13, 51500, 51500, 407, 309, 311, 257, 1333, 295, 18011, 17630, 1154, 689, 291, 643, 281, 6269, 300, 1783, 11, 398, 11, 1176, 8062, 51714, 51714, 281, 1184, 4914, 294, 264, 4846, 13, 51842, 51842], "temperature": 0.0, "avg_logprob": -0.12355224156783799, "compression_ratio": 1.8097165991902835, "no_speech_prob": 1.6186848370125517e-05}, {"id": 866, "seek": 340944, "start": 3425.76, "end": 3432.16, "text": " So in 3D, basically the X, Y, and Z vectors at each particular surface.", "tokens": [50364, 407, 264, 958, 5633, 321, 2956, 412, 390, 3753, 2710, 13344, 13, 50568, 50568, 407, 341, 307, 1936, 2212, 4846, 13, 50700, 50700, 509, 853, 281, 12539, 437, 366, 264, 805, 35, 7221, 295, 264, 11, 411, 1936, 412, 1184, 19261, 4914, 50988, 50988, 294, 264, 4846, 13, 51038, 51038, 407, 291, 853, 281, 6069, 437, 307, 264, 3753, 14764, 13, 51180, 51180, 407, 294, 805, 35, 11, 1936, 264, 1783, 11, 398, 11, 293, 1176, 18875, 412, 1184, 1729, 3753, 13, 51500, 51500, 407, 309, 311, 257, 1333, 295, 18011, 17630, 1154, 689, 291, 643, 281, 6269, 300, 1783, 11, 398, 11, 1176, 8062, 51714, 51714, 281, 1184, 4914, 294, 264, 4846, 13, 51842, 51842], "temperature": 0.0, "avg_logprob": -0.12355224156783799, "compression_ratio": 1.8097165991902835, "no_speech_prob": 1.6186848370125517e-05}, {"id": 867, "seek": 340944, "start": 3432.16, "end": 3436.44, "text": " So it's a sort of dense prediction problem where you need to assign that X, Y, Z vector", "tokens": [50364, 407, 264, 958, 5633, 321, 2956, 412, 390, 3753, 2710, 13344, 13, 50568, 50568, 407, 341, 307, 1936, 2212, 4846, 13, 50700, 50700, 509, 853, 281, 12539, 437, 366, 264, 805, 35, 7221, 295, 264, 11, 411, 1936, 412, 1184, 19261, 4914, 50988, 50988, 294, 264, 4846, 13, 51038, 51038, 407, 291, 853, 281, 6069, 437, 307, 264, 3753, 14764, 13, 51180, 51180, 407, 294, 805, 35, 11, 1936, 264, 1783, 11, 398, 11, 293, 1176, 18875, 412, 1184, 1729, 3753, 13, 51500, 51500, 407, 309, 311, 257, 1333, 295, 18011, 17630, 1154, 689, 291, 643, 281, 6269, 300, 1783, 11, 398, 11, 1176, 8062, 51714, 51714, 281, 1184, 4914, 294, 264, 4846, 13, 51842, 51842], "temperature": 0.0, "avg_logprob": -0.12355224156783799, "compression_ratio": 1.8097165991902835, "no_speech_prob": 1.6186848370125517e-05}, {"id": 868, "seek": 340944, "start": 3436.44, "end": 3439.0, "text": " to each location in the input.", "tokens": [50364, 407, 264, 958, 5633, 321, 2956, 412, 390, 3753, 2710, 13344, 13, 50568, 50568, 407, 341, 307, 1936, 2212, 4846, 13, 50700, 50700, 509, 853, 281, 12539, 437, 366, 264, 805, 35, 7221, 295, 264, 11, 411, 1936, 412, 1184, 19261, 4914, 50988, 50988, 294, 264, 4846, 13, 51038, 51038, 407, 291, 853, 281, 6069, 437, 307, 264, 3753, 14764, 13, 51180, 51180, 407, 294, 805, 35, 11, 1936, 264, 1783, 11, 398, 11, 293, 1176, 18875, 412, 1184, 1729, 3753, 13, 51500, 51500, 407, 309, 311, 257, 1333, 295, 18011, 17630, 1154, 689, 291, 643, 281, 6269, 300, 1783, 11, 398, 11, 1176, 8062, 51714, 51714, 281, 1184, 4914, 294, 264, 4846, 13, 51842, 51842], "temperature": 0.0, "avg_logprob": -0.12355224156783799, "compression_ratio": 1.8097165991902835, "no_speech_prob": 1.6186848370125517e-05}, {"id": 869, "seek": 343900, "start": 3439.0, "end": 3444.32, "text": " And for that, we use this nice data set created by NYU.", "tokens": [50364, 400, 337, 300, 11, 321, 764, 341, 1481, 1412, 992, 2942, 538, 42682, 13, 50630, 50630, 400, 321, 1936, 12690, 264, 17630, 7221, 295, 527, 3170, 293, 5347, 309, 281, 364, 3256, 50962, 50962, 2533, 46533, 3170, 13, 51060, 51060, 400, 370, 294, 341, 1389, 11, 321, 12690, 264, 26779, 6713, 293, 264, 9668, 3006, 21264, 13, 51328, 51328, 407, 264, 26779, 6713, 1936, 1355, 300, 3126, 307, 1101, 293, 9668, 3006, 1355, 2946, 51516, 51516, 307, 1101, 13, 51566, 51566, 407, 309, 3574, 484, 300, 264, 508, 17156, 1607, 659, 12, 17227, 1760, 5633, 390, 767, 534, 665, 294, 341, 1389, 13, 51850, 51850], "temperature": 0.0, "avg_logprob": -0.14803742025500147, "compression_ratio": 1.8612244897959183, "no_speech_prob": 6.048818249837495e-06}, {"id": 870, "seek": 343900, "start": 3444.32, "end": 3450.96, "text": " And we basically measured the prediction properties of our method and compared it to an image", "tokens": [50364, 400, 337, 300, 11, 321, 764, 341, 1481, 1412, 992, 2942, 538, 42682, 13, 50630, 50630, 400, 321, 1936, 12690, 264, 17630, 7221, 295, 527, 3170, 293, 5347, 309, 281, 364, 3256, 50962, 50962, 2533, 46533, 3170, 13, 51060, 51060, 400, 370, 294, 341, 1389, 11, 321, 12690, 264, 26779, 6713, 293, 264, 9668, 3006, 21264, 13, 51328, 51328, 407, 264, 26779, 6713, 1936, 1355, 300, 3126, 307, 1101, 293, 9668, 3006, 1355, 2946, 51516, 51516, 307, 1101, 13, 51566, 51566, 407, 309, 3574, 484, 300, 264, 508, 17156, 1607, 659, 12, 17227, 1760, 5633, 390, 767, 534, 665, 294, 341, 1389, 13, 51850, 51850], "temperature": 0.0, "avg_logprob": -0.14803742025500147, "compression_ratio": 1.8612244897959183, "no_speech_prob": 6.048818249837495e-06}, {"id": 871, "seek": 343900, "start": 3450.96, "end": 3452.92, "text": " net supervised method.", "tokens": [50364, 400, 337, 300, 11, 321, 764, 341, 1481, 1412, 992, 2942, 538, 42682, 13, 50630, 50630, 400, 321, 1936, 12690, 264, 17630, 7221, 295, 527, 3170, 293, 5347, 309, 281, 364, 3256, 50962, 50962, 2533, 46533, 3170, 13, 51060, 51060, 400, 370, 294, 341, 1389, 11, 321, 12690, 264, 26779, 6713, 293, 264, 9668, 3006, 21264, 13, 51328, 51328, 407, 264, 26779, 6713, 1936, 1355, 300, 3126, 307, 1101, 293, 9668, 3006, 1355, 2946, 51516, 51516, 307, 1101, 13, 51566, 51566, 407, 309, 3574, 484, 300, 264, 508, 17156, 1607, 659, 12, 17227, 1760, 5633, 390, 767, 534, 665, 294, 341, 1389, 13, 51850, 51850], "temperature": 0.0, "avg_logprob": -0.14803742025500147, "compression_ratio": 1.8612244897959183, "no_speech_prob": 6.048818249837495e-06}, {"id": 872, "seek": 343900, "start": 3452.92, "end": 3458.28, "text": " And so in this case, we measured the median error and the percentage correct predictions.", "tokens": [50364, 400, 337, 300, 11, 321, 764, 341, 1481, 1412, 992, 2942, 538, 42682, 13, 50630, 50630, 400, 321, 1936, 12690, 264, 17630, 7221, 295, 527, 3170, 293, 5347, 309, 281, 364, 3256, 50962, 50962, 2533, 46533, 3170, 13, 51060, 51060, 400, 370, 294, 341, 1389, 11, 321, 12690, 264, 26779, 6713, 293, 264, 9668, 3006, 21264, 13, 51328, 51328, 407, 264, 26779, 6713, 1936, 1355, 300, 3126, 307, 1101, 293, 9668, 3006, 1355, 2946, 51516, 51516, 307, 1101, 13, 51566, 51566, 407, 309, 3574, 484, 300, 264, 508, 17156, 1607, 659, 12, 17227, 1760, 5633, 390, 767, 534, 665, 294, 341, 1389, 13, 51850, 51850], "temperature": 0.0, "avg_logprob": -0.14803742025500147, "compression_ratio": 1.8612244897959183, "no_speech_prob": 6.048818249837495e-06}, {"id": 873, "seek": 343900, "start": 3458.28, "end": 3462.04, "text": " So the median error basically means that lower is better and percentage correct means higher", "tokens": [50364, 400, 337, 300, 11, 321, 764, 341, 1481, 1412, 992, 2942, 538, 42682, 13, 50630, 50630, 400, 321, 1936, 12690, 264, 17630, 7221, 295, 527, 3170, 293, 5347, 309, 281, 364, 3256, 50962, 50962, 2533, 46533, 3170, 13, 51060, 51060, 400, 370, 294, 341, 1389, 11, 321, 12690, 264, 26779, 6713, 293, 264, 9668, 3006, 21264, 13, 51328, 51328, 407, 264, 26779, 6713, 1936, 1355, 300, 3126, 307, 1101, 293, 9668, 3006, 1355, 2946, 51516, 51516, 307, 1101, 13, 51566, 51566, 407, 309, 3574, 484, 300, 264, 508, 17156, 1607, 659, 12, 17227, 1760, 5633, 390, 767, 534, 665, 294, 341, 1389, 13, 51850, 51850], "temperature": 0.0, "avg_logprob": -0.14803742025500147, "compression_ratio": 1.8612244897959183, "no_speech_prob": 6.048818249837495e-06}, {"id": 874, "seek": 343900, "start": 3462.04, "end": 3463.04, "text": " is better.", "tokens": [50364, 400, 337, 300, 11, 321, 764, 341, 1481, 1412, 992, 2942, 538, 42682, 13, 50630, 50630, 400, 321, 1936, 12690, 264, 17630, 7221, 295, 527, 3170, 293, 5347, 309, 281, 364, 3256, 50962, 50962, 2533, 46533, 3170, 13, 51060, 51060, 400, 370, 294, 341, 1389, 11, 321, 12690, 264, 26779, 6713, 293, 264, 9668, 3006, 21264, 13, 51328, 51328, 407, 264, 26779, 6713, 1936, 1355, 300, 3126, 307, 1101, 293, 9668, 3006, 1355, 2946, 51516, 51516, 307, 1101, 13, 51566, 51566, 407, 309, 3574, 484, 300, 264, 508, 17156, 1607, 659, 12, 17227, 1760, 5633, 390, 767, 534, 665, 294, 341, 1389, 13, 51850, 51850], "temperature": 0.0, "avg_logprob": -0.14803742025500147, "compression_ratio": 1.8612244897959183, "no_speech_prob": 6.048818249837495e-06}, {"id": 875, "seek": 343900, "start": 3463.04, "end": 3468.72, "text": " So it turned out that the Jigsaw pre-training task was actually really good in this case.", "tokens": [50364, 400, 337, 300, 11, 321, 764, 341, 1481, 1412, 992, 2942, 538, 42682, 13, 50630, 50630, 400, 321, 1936, 12690, 264, 17630, 7221, 295, 527, 3170, 293, 5347, 309, 281, 364, 3256, 50962, 50962, 2533, 46533, 3170, 13, 51060, 51060, 400, 370, 294, 341, 1389, 11, 321, 12690, 264, 26779, 6713, 293, 264, 9668, 3006, 21264, 13, 51328, 51328, 407, 264, 26779, 6713, 1936, 1355, 300, 3126, 307, 1101, 293, 9668, 3006, 1355, 2946, 51516, 51516, 307, 1101, 13, 51566, 51566, 407, 309, 3574, 484, 300, 264, 508, 17156, 1607, 659, 12, 17227, 1760, 5633, 390, 767, 534, 665, 294, 341, 1389, 13, 51850, 51850], "temperature": 0.0, "avg_logprob": -0.14803742025500147, "compression_ratio": 1.8612244897959183, "no_speech_prob": 6.048818249837495e-06}, {"id": 876, "seek": 346872, "start": 3468.72, "end": 3473.12, "text": " And it provided like significant improvements over image net pre-training.", "tokens": [50364, 400, 309, 5649, 411, 4776, 13797, 670, 3256, 2533, 659, 12, 17227, 1760, 13, 50584, 50584, 407, 309, 390, 1936, 2108, 512, 3866, 819, 6352, 11, 3866, 819, 37741, 13, 50794, 50794, 467, 390, 1075, 281, 534, 3612, 484, 26765, 264, 3256, 2533, 46533, 659, 12, 17227, 2001, 3170, 13, 51060, 51060, 407, 797, 11, 309, 1333, 295, 1709, 322, 281, 855, 300, 27479, 257, 659, 25111, 5633, 322, 3866, 819, 51332, 51332, 9608, 293, 3866, 819, 1412, 6352, 307, 534, 1021, 281, 1223, 437, 307, 534, 51560, 51560, 516, 322, 294, 428, 659, 25111, 5633, 13, 51669, 51669], "temperature": 0.0, "avg_logprob": -0.11025277694853225, "compression_ratio": 1.8755186721991701, "no_speech_prob": 5.014617727283621e-06}, {"id": 877, "seek": 346872, "start": 3473.12, "end": 3477.3199999999997, "text": " So it was basically across some multiple different sets, multiple different splits.", "tokens": [50364, 400, 309, 5649, 411, 4776, 13797, 670, 3256, 2533, 659, 12, 17227, 1760, 13, 50584, 50584, 407, 309, 390, 1936, 2108, 512, 3866, 819, 6352, 11, 3866, 819, 37741, 13, 50794, 50794, 467, 390, 1075, 281, 534, 3612, 484, 26765, 264, 3256, 2533, 46533, 659, 12, 17227, 2001, 3170, 13, 51060, 51060, 407, 797, 11, 309, 1333, 295, 1709, 322, 281, 855, 300, 27479, 257, 659, 25111, 5633, 322, 3866, 819, 51332, 51332, 9608, 293, 3866, 819, 1412, 6352, 307, 534, 1021, 281, 1223, 437, 307, 534, 51560, 51560, 516, 322, 294, 428, 659, 25111, 5633, 13, 51669, 51669], "temperature": 0.0, "avg_logprob": -0.11025277694853225, "compression_ratio": 1.8755186721991701, "no_speech_prob": 5.014617727283621e-06}, {"id": 878, "seek": 346872, "start": 3477.3199999999997, "end": 3482.64, "text": " It was able to really easily outperform the image net supervised pre-trained method.", "tokens": [50364, 400, 309, 5649, 411, 4776, 13797, 670, 3256, 2533, 659, 12, 17227, 1760, 13, 50584, 50584, 407, 309, 390, 1936, 2108, 512, 3866, 819, 6352, 11, 3866, 819, 37741, 13, 50794, 50794, 467, 390, 1075, 281, 534, 3612, 484, 26765, 264, 3256, 2533, 46533, 659, 12, 17227, 2001, 3170, 13, 51060, 51060, 407, 797, 11, 309, 1333, 295, 1709, 322, 281, 855, 300, 27479, 257, 659, 25111, 5633, 322, 3866, 819, 51332, 51332, 9608, 293, 3866, 819, 1412, 6352, 307, 534, 1021, 281, 1223, 437, 307, 534, 51560, 51560, 516, 322, 294, 428, 659, 25111, 5633, 13, 51669, 51669], "temperature": 0.0, "avg_logprob": -0.11025277694853225, "compression_ratio": 1.8755186721991701, "no_speech_prob": 5.014617727283621e-06}, {"id": 879, "seek": 346872, "start": 3482.64, "end": 3488.08, "text": " So again, it sort of goes on to show that evaluating a pretext task on multiple different", "tokens": [50364, 400, 309, 5649, 411, 4776, 13797, 670, 3256, 2533, 659, 12, 17227, 1760, 13, 50584, 50584, 407, 309, 390, 1936, 2108, 512, 3866, 819, 6352, 11, 3866, 819, 37741, 13, 50794, 50794, 467, 390, 1075, 281, 534, 3612, 484, 26765, 264, 3256, 2533, 46533, 659, 12, 17227, 2001, 3170, 13, 51060, 51060, 407, 797, 11, 309, 1333, 295, 1709, 322, 281, 855, 300, 27479, 257, 659, 25111, 5633, 322, 3866, 819, 51332, 51332, 9608, 293, 3866, 819, 1412, 6352, 307, 534, 1021, 281, 1223, 437, 307, 534, 51560, 51560, 516, 322, 294, 428, 659, 25111, 5633, 13, 51669, 51669], "temperature": 0.0, "avg_logprob": -0.11025277694853225, "compression_ratio": 1.8755186721991701, "no_speech_prob": 5.014617727283621e-06}, {"id": 880, "seek": 346872, "start": 3488.08, "end": 3492.64, "text": " tasks and multiple different data sets is really important to understand what is really", "tokens": [50364, 400, 309, 5649, 411, 4776, 13797, 670, 3256, 2533, 659, 12, 17227, 1760, 13, 50584, 50584, 407, 309, 390, 1936, 2108, 512, 3866, 819, 6352, 11, 3866, 819, 37741, 13, 50794, 50794, 467, 390, 1075, 281, 534, 3612, 484, 26765, 264, 3256, 2533, 46533, 659, 12, 17227, 2001, 3170, 13, 51060, 51060, 407, 797, 11, 309, 1333, 295, 1709, 322, 281, 855, 300, 27479, 257, 659, 25111, 5633, 322, 3866, 819, 51332, 51332, 9608, 293, 3866, 819, 1412, 6352, 307, 534, 1021, 281, 1223, 437, 307, 534, 51560, 51560, 516, 322, 294, 428, 659, 25111, 5633, 13, 51669, 51669], "temperature": 0.0, "avg_logprob": -0.11025277694853225, "compression_ratio": 1.8755186721991701, "no_speech_prob": 5.014617727283621e-06}, {"id": 881, "seek": 346872, "start": 3492.64, "end": 3494.8199999999997, "text": " going on in your pretext task.", "tokens": [50364, 400, 309, 5649, 411, 4776, 13797, 670, 3256, 2533, 659, 12, 17227, 1760, 13, 50584, 50584, 407, 309, 390, 1936, 2108, 512, 3866, 819, 6352, 11, 3866, 819, 37741, 13, 50794, 50794, 467, 390, 1075, 281, 534, 3612, 484, 26765, 264, 3256, 2533, 46533, 659, 12, 17227, 2001, 3170, 13, 51060, 51060, 407, 797, 11, 309, 1333, 295, 1709, 322, 281, 855, 300, 27479, 257, 659, 25111, 5633, 322, 3866, 819, 51332, 51332, 9608, 293, 3866, 819, 1412, 6352, 307, 534, 1021, 281, 1223, 437, 307, 534, 51560, 51560, 516, 322, 294, 428, 659, 25111, 5633, 13, 51669, 51669], "temperature": 0.0, "avg_logprob": -0.11025277694853225, "compression_ratio": 1.8755186721991701, "no_speech_prob": 5.014617727283621e-06}, {"id": 882, "seek": 349482, "start": 3494.82, "end": 3500.96, "text": " So somehow Jigsaw is really incorporating something about like geometry and something", "tokens": [50364, 407, 6063, 508, 17156, 1607, 307, 534, 33613, 746, 466, 411, 18426, 293, 746, 50671, 50671, 466, 411, 19261, 1496, 1589, 709, 1101, 813, 3256, 2533, 46533, 7150, 13, 51045, 51045, 407, 2721, 11, 321, 1352, 1333, 295, 264, 15847, 14835, 9430, 295, 341, 3170, 11, 411, 264, 508, 17156, 1607, 659, 12, 17227, 1760, 51309, 51309, 5633, 13, 51359, 51359, 407, 281, 360, 341, 11, 321, 25509, 322, 411, 264, 3287, 1219, 1326, 12, 18402, 2539, 13, 51577, 51577, 407, 294, 1326, 12, 18402, 2539, 11, 291, 362, 588, 1333, 295, 5567, 1230, 295, 3097, 5110, 11, 293, 51851, 51851], "temperature": 0.0, "avg_logprob": -0.12241295934880822, "compression_ratio": 1.7428571428571429, "no_speech_prob": 2.0261225017748075e-06}, {"id": 883, "seek": 349482, "start": 3500.96, "end": 3508.44, "text": " about like pixel level information much better than image net supervised methods.", "tokens": [50364, 407, 6063, 508, 17156, 1607, 307, 534, 33613, 746, 466, 411, 18426, 293, 746, 50671, 50671, 466, 411, 19261, 1496, 1589, 709, 1101, 813, 3256, 2533, 46533, 7150, 13, 51045, 51045, 407, 2721, 11, 321, 1352, 1333, 295, 264, 15847, 14835, 9430, 295, 341, 3170, 11, 411, 264, 508, 17156, 1607, 659, 12, 17227, 1760, 51309, 51309, 5633, 13, 51359, 51359, 407, 281, 360, 341, 11, 321, 25509, 322, 411, 264, 3287, 1219, 1326, 12, 18402, 2539, 13, 51577, 51577, 407, 294, 1326, 12, 18402, 2539, 11, 291, 362, 588, 1333, 295, 5567, 1230, 295, 3097, 5110, 11, 293, 51851, 51851], "temperature": 0.0, "avg_logprob": -0.12241295934880822, "compression_ratio": 1.7428571428571429, "no_speech_prob": 2.0261225017748075e-06}, {"id": 884, "seek": 349482, "start": 3508.44, "end": 3513.7200000000003, "text": " So finally, we found sort of the Achilles heel of this method, like the Jigsaw pre-training", "tokens": [50364, 407, 6063, 508, 17156, 1607, 307, 534, 33613, 746, 466, 411, 18426, 293, 746, 50671, 50671, 466, 411, 19261, 1496, 1589, 709, 1101, 813, 3256, 2533, 46533, 7150, 13, 51045, 51045, 407, 2721, 11, 321, 1352, 1333, 295, 264, 15847, 14835, 9430, 295, 341, 3170, 11, 411, 264, 508, 17156, 1607, 659, 12, 17227, 1760, 51309, 51309, 5633, 13, 51359, 51359, 407, 281, 360, 341, 11, 321, 25509, 322, 411, 264, 3287, 1219, 1326, 12, 18402, 2539, 13, 51577, 51577, 407, 294, 1326, 12, 18402, 2539, 11, 291, 362, 588, 1333, 295, 5567, 1230, 295, 3097, 5110, 11, 293, 51851, 51851], "temperature": 0.0, "avg_logprob": -0.12241295934880822, "compression_ratio": 1.7428571428571429, "no_speech_prob": 2.0261225017748075e-06}, {"id": 885, "seek": 349482, "start": 3513.7200000000003, "end": 3514.7200000000003, "text": " task.", "tokens": [50364, 407, 6063, 508, 17156, 1607, 307, 534, 33613, 746, 466, 411, 18426, 293, 746, 50671, 50671, 466, 411, 19261, 1496, 1589, 709, 1101, 813, 3256, 2533, 46533, 7150, 13, 51045, 51045, 407, 2721, 11, 321, 1352, 1333, 295, 264, 15847, 14835, 9430, 295, 341, 3170, 11, 411, 264, 508, 17156, 1607, 659, 12, 17227, 1760, 51309, 51309, 5633, 13, 51359, 51359, 407, 281, 360, 341, 11, 321, 25509, 322, 411, 264, 3287, 1219, 1326, 12, 18402, 2539, 13, 51577, 51577, 407, 294, 1326, 12, 18402, 2539, 11, 291, 362, 588, 1333, 295, 5567, 1230, 295, 3097, 5110, 11, 293, 51851, 51851], "temperature": 0.0, "avg_logprob": -0.12241295934880822, "compression_ratio": 1.7428571428571429, "no_speech_prob": 2.0261225017748075e-06}, {"id": 886, "seek": 349482, "start": 3514.7200000000003, "end": 3519.0800000000004, "text": " So to do this, we evaluated on like the setting called few-shot learning.", "tokens": [50364, 407, 6063, 508, 17156, 1607, 307, 534, 33613, 746, 466, 411, 18426, 293, 746, 50671, 50671, 466, 411, 19261, 1496, 1589, 709, 1101, 813, 3256, 2533, 46533, 7150, 13, 51045, 51045, 407, 2721, 11, 321, 1352, 1333, 295, 264, 15847, 14835, 9430, 295, 341, 3170, 11, 411, 264, 508, 17156, 1607, 659, 12, 17227, 1760, 51309, 51309, 5633, 13, 51359, 51359, 407, 281, 360, 341, 11, 321, 25509, 322, 411, 264, 3287, 1219, 1326, 12, 18402, 2539, 13, 51577, 51577, 407, 294, 1326, 12, 18402, 2539, 11, 291, 362, 588, 1333, 295, 5567, 1230, 295, 3097, 5110, 11, 293, 51851, 51851], "temperature": 0.0, "avg_logprob": -0.12241295934880822, "compression_ratio": 1.7428571428571429, "no_speech_prob": 2.0261225017748075e-06}, {"id": 887, "seek": 349482, "start": 3519.0800000000004, "end": 3524.56, "text": " So in few-shot learning, you have very sort of limited number of training examples, and", "tokens": [50364, 407, 6063, 508, 17156, 1607, 307, 534, 33613, 746, 466, 411, 18426, 293, 746, 50671, 50671, 466, 411, 19261, 1496, 1589, 709, 1101, 813, 3256, 2533, 46533, 7150, 13, 51045, 51045, 407, 2721, 11, 321, 1352, 1333, 295, 264, 15847, 14835, 9430, 295, 341, 3170, 11, 411, 264, 508, 17156, 1607, 659, 12, 17227, 1760, 51309, 51309, 5633, 13, 51359, 51359, 407, 281, 360, 341, 11, 321, 25509, 322, 411, 264, 3287, 1219, 1326, 12, 18402, 2539, 13, 51577, 51577, 407, 294, 1326, 12, 18402, 2539, 11, 291, 362, 588, 1333, 295, 5567, 1230, 295, 3097, 5110, 11, 293, 51851, 51851], "temperature": 0.0, "avg_logprob": -0.12241295934880822, "compression_ratio": 1.7428571428571429, "no_speech_prob": 2.0261225017748075e-06}, {"id": 888, "seek": 352456, "start": 3524.56, "end": 3529.88, "text": " you're training your classifier just on these very limited number of training examples.", "tokens": [50364, 291, 434, 3097, 428, 1508, 9902, 445, 322, 613, 588, 5567, 1230, 295, 3097, 5110, 13, 50630, 50630, 407, 322, 264, 2031, 12, 24633, 11, 286, 362, 264, 1230, 295, 3097, 5110, 300, 645, 1143, 281, 3847, 257, 3170, 13, 50911, 50911, 407, 300, 1709, 490, 584, 502, 281, 24124, 13, 51057, 51057, 400, 286, 478, 1333, 295, 4099, 291, 19490, 337, 411, 732, 819, 2698, 12, 48172, 24420, 7150, 13, 51300, 51300, 407, 508, 17156, 1607, 7150, 8895, 322, 732, 819, 1412, 6352, 11, 3256, 2533, 11, 597, 307, 322, 264, 1192, 11, 51522, 51522, 293, 257, 4974, 5015, 31890, 12, 2803, 13, 51676, 51676], "temperature": 0.0, "avg_logprob": -0.14823717541164821, "compression_ratio": 1.654320987654321, "no_speech_prob": 3.6687897591036744e-06}, {"id": 889, "seek": 352456, "start": 3529.88, "end": 3535.5, "text": " So on the x-axis, I have the number of training examples that were used to train a method.", "tokens": [50364, 291, 434, 3097, 428, 1508, 9902, 445, 322, 613, 588, 5567, 1230, 295, 3097, 5110, 13, 50630, 50630, 407, 322, 264, 2031, 12, 24633, 11, 286, 362, 264, 1230, 295, 3097, 5110, 300, 645, 1143, 281, 3847, 257, 3170, 13, 50911, 50911, 407, 300, 1709, 490, 584, 502, 281, 24124, 13, 51057, 51057, 400, 286, 478, 1333, 295, 4099, 291, 19490, 337, 411, 732, 819, 2698, 12, 48172, 24420, 7150, 13, 51300, 51300, 407, 508, 17156, 1607, 7150, 8895, 322, 732, 819, 1412, 6352, 11, 3256, 2533, 11, 597, 307, 322, 264, 1192, 11, 51522, 51522, 293, 257, 4974, 5015, 31890, 12, 2803, 13, 51676, 51676], "temperature": 0.0, "avg_logprob": -0.14823717541164821, "compression_ratio": 1.654320987654321, "no_speech_prob": 3.6687897591036744e-06}, {"id": 890, "seek": 352456, "start": 3535.5, "end": 3538.42, "text": " So that goes from say 1 to 96.", "tokens": [50364, 291, 434, 3097, 428, 1508, 9902, 445, 322, 613, 588, 5567, 1230, 295, 3097, 5110, 13, 50630, 50630, 407, 322, 264, 2031, 12, 24633, 11, 286, 362, 264, 1230, 295, 3097, 5110, 300, 645, 1143, 281, 3847, 257, 3170, 13, 50911, 50911, 407, 300, 1709, 490, 584, 502, 281, 24124, 13, 51057, 51057, 400, 286, 478, 1333, 295, 4099, 291, 19490, 337, 411, 732, 819, 2698, 12, 48172, 24420, 7150, 13, 51300, 51300, 407, 508, 17156, 1607, 7150, 8895, 322, 732, 819, 1412, 6352, 11, 3256, 2533, 11, 597, 307, 322, 264, 1192, 11, 51522, 51522, 293, 257, 4974, 5015, 31890, 12, 2803, 13, 51676, 51676], "temperature": 0.0, "avg_logprob": -0.14823717541164821, "compression_ratio": 1.654320987654321, "no_speech_prob": 3.6687897591036744e-06}, {"id": 891, "seek": 352456, "start": 3538.42, "end": 3543.2799999999997, "text": " And I'm sort of showing you curves for like two different self-supervised methods.", "tokens": [50364, 291, 434, 3097, 428, 1508, 9902, 445, 322, 613, 588, 5567, 1230, 295, 3097, 5110, 13, 50630, 50630, 407, 322, 264, 2031, 12, 24633, 11, 286, 362, 264, 1230, 295, 3097, 5110, 300, 645, 1143, 281, 3847, 257, 3170, 13, 50911, 50911, 407, 300, 1709, 490, 584, 502, 281, 24124, 13, 51057, 51057, 400, 286, 478, 1333, 295, 4099, 291, 19490, 337, 411, 732, 819, 2698, 12, 48172, 24420, 7150, 13, 51300, 51300, 407, 508, 17156, 1607, 7150, 8895, 322, 732, 819, 1412, 6352, 11, 3256, 2533, 11, 597, 307, 322, 264, 1192, 11, 51522, 51522, 293, 257, 4974, 5015, 31890, 12, 2803, 13, 51676, 51676], "temperature": 0.0, "avg_logprob": -0.14823717541164821, "compression_ratio": 1.654320987654321, "no_speech_prob": 3.6687897591036744e-06}, {"id": 892, "seek": 352456, "start": 3543.2799999999997, "end": 3547.72, "text": " So Jigsaw methods trained on two different data sets, image net, which is on the top,", "tokens": [50364, 291, 434, 3097, 428, 1508, 9902, 445, 322, 613, 588, 5567, 1230, 295, 3097, 5110, 13, 50630, 50630, 407, 322, 264, 2031, 12, 24633, 11, 286, 362, 264, 1230, 295, 3097, 5110, 300, 645, 1143, 281, 3847, 257, 3170, 13, 50911, 50911, 407, 300, 1709, 490, 584, 502, 281, 24124, 13, 51057, 51057, 400, 286, 478, 1333, 295, 4099, 291, 19490, 337, 411, 732, 819, 2698, 12, 48172, 24420, 7150, 13, 51300, 51300, 407, 508, 17156, 1607, 7150, 8895, 322, 732, 819, 1412, 6352, 11, 3256, 2533, 11, 597, 307, 322, 264, 1192, 11, 51522, 51522, 293, 257, 4974, 5015, 31890, 12, 2803, 13, 51676, 51676], "temperature": 0.0, "avg_logprob": -0.14823717541164821, "compression_ratio": 1.654320987654321, "no_speech_prob": 3.6687897591036744e-06}, {"id": 893, "seek": 352456, "start": 3547.72, "end": 3550.7999999999997, "text": " and a random ResNet-50.", "tokens": [50364, 291, 434, 3097, 428, 1508, 9902, 445, 322, 613, 588, 5567, 1230, 295, 3097, 5110, 13, 50630, 50630, 407, 322, 264, 2031, 12, 24633, 11, 286, 362, 264, 1230, 295, 3097, 5110, 300, 645, 1143, 281, 3847, 257, 3170, 13, 50911, 50911, 407, 300, 1709, 490, 584, 502, 281, 24124, 13, 51057, 51057, 400, 286, 478, 1333, 295, 4099, 291, 19490, 337, 411, 732, 819, 2698, 12, 48172, 24420, 7150, 13, 51300, 51300, 407, 508, 17156, 1607, 7150, 8895, 322, 732, 819, 1412, 6352, 11, 3256, 2533, 11, 597, 307, 322, 264, 1192, 11, 51522, 51522, 293, 257, 4974, 5015, 31890, 12, 2803, 13, 51676, 51676], "temperature": 0.0, "avg_logprob": -0.14823717541164821, "compression_ratio": 1.654320987654321, "no_speech_prob": 3.6687897591036744e-06}, {"id": 894, "seek": 355080, "start": 3550.8, "end": 3555.48, "text": " What you can observe is that there is a significant gap in performance between a self-supervised", "tokens": [50364, 708, 291, 393, 11441, 307, 300, 456, 307, 257, 4776, 7417, 294, 3389, 1296, 257, 2698, 12, 48172, 24420, 50598, 50598, 3170, 293, 257, 46533, 3170, 13, 50726, 50726, 400, 300, 7417, 1936, 445, 775, 406, 1643, 281, 5407, 382, 291, 3488, 264, 1230, 295, 21335, 50942, 50942, 5110, 11, 597, 935, 1333, 295, 3110, 300, 2698, 12, 48172, 24420, 33358, 11, 4878, 436, 815, 312, 665, 51226, 51226, 412, 9608, 411, 584, 10774, 35701, 420, 1729, 9608, 411, 3753, 2710, 35701, 11, 456, 51520, 51520, 307, 920, 257, 688, 295, 2649, 1296, 437, 1333, 295, 47982, 4171, 295, 264, 1412, 436, 7983, 11, 51775, 51775], "temperature": 0.0, "avg_logprob": -0.13098316722446018, "compression_ratio": 1.812274368231047, "no_speech_prob": 4.710796474682866e-06}, {"id": 895, "seek": 355080, "start": 3555.48, "end": 3558.04, "text": " method and a supervised method.", "tokens": [50364, 708, 291, 393, 11441, 307, 300, 456, 307, 257, 4776, 7417, 294, 3389, 1296, 257, 2698, 12, 48172, 24420, 50598, 50598, 3170, 293, 257, 46533, 3170, 13, 50726, 50726, 400, 300, 7417, 1936, 445, 775, 406, 1643, 281, 5407, 382, 291, 3488, 264, 1230, 295, 21335, 50942, 50942, 5110, 11, 597, 935, 1333, 295, 3110, 300, 2698, 12, 48172, 24420, 33358, 11, 4878, 436, 815, 312, 665, 51226, 51226, 412, 9608, 411, 584, 10774, 35701, 420, 1729, 9608, 411, 3753, 2710, 35701, 11, 456, 51520, 51520, 307, 920, 257, 688, 295, 2649, 1296, 437, 1333, 295, 47982, 4171, 295, 264, 1412, 436, 7983, 11, 51775, 51775], "temperature": 0.0, "avg_logprob": -0.13098316722446018, "compression_ratio": 1.812274368231047, "no_speech_prob": 4.710796474682866e-06}, {"id": 896, "seek": 355080, "start": 3558.04, "end": 3562.36, "text": " And that gap basically just does not seem to reduce as you increase the number of labeled", "tokens": [50364, 708, 291, 393, 11441, 307, 300, 456, 307, 257, 4776, 7417, 294, 3389, 1296, 257, 2698, 12, 48172, 24420, 50598, 50598, 3170, 293, 257, 46533, 3170, 13, 50726, 50726, 400, 300, 7417, 1936, 445, 775, 406, 1643, 281, 5407, 382, 291, 3488, 264, 1230, 295, 21335, 50942, 50942, 5110, 11, 597, 935, 1333, 295, 3110, 300, 2698, 12, 48172, 24420, 33358, 11, 4878, 436, 815, 312, 665, 51226, 51226, 412, 9608, 411, 584, 10774, 35701, 420, 1729, 9608, 411, 3753, 2710, 35701, 11, 456, 51520, 51520, 307, 920, 257, 688, 295, 2649, 1296, 437, 1333, 295, 47982, 4171, 295, 264, 1412, 436, 7983, 11, 51775, 51775], "temperature": 0.0, "avg_logprob": -0.13098316722446018, "compression_ratio": 1.812274368231047, "no_speech_prob": 4.710796474682866e-06}, {"id": 897, "seek": 355080, "start": 3562.36, "end": 3568.04, "text": " examples, which point sort of shows that self-supervised representations, although they may be good", "tokens": [50364, 708, 291, 393, 11441, 307, 300, 456, 307, 257, 4776, 7417, 294, 3389, 1296, 257, 2698, 12, 48172, 24420, 50598, 50598, 3170, 293, 257, 46533, 3170, 13, 50726, 50726, 400, 300, 7417, 1936, 445, 775, 406, 1643, 281, 5407, 382, 291, 3488, 264, 1230, 295, 21335, 50942, 50942, 5110, 11, 597, 935, 1333, 295, 3110, 300, 2698, 12, 48172, 24420, 33358, 11, 4878, 436, 815, 312, 665, 51226, 51226, 412, 9608, 411, 584, 10774, 35701, 420, 1729, 9608, 411, 3753, 2710, 35701, 11, 456, 51520, 51520, 307, 920, 257, 688, 295, 2649, 1296, 437, 1333, 295, 47982, 4171, 295, 264, 1412, 436, 7983, 11, 51775, 51775], "temperature": 0.0, "avg_logprob": -0.13098316722446018, "compression_ratio": 1.812274368231047, "no_speech_prob": 4.710796474682866e-06}, {"id": 898, "seek": 355080, "start": 3568.04, "end": 3573.92, "text": " at tasks like say pose estimation or particular tasks like surface normal estimation, there", "tokens": [50364, 708, 291, 393, 11441, 307, 300, 456, 307, 257, 4776, 7417, 294, 3389, 1296, 257, 2698, 12, 48172, 24420, 50598, 50598, 3170, 293, 257, 46533, 3170, 13, 50726, 50726, 400, 300, 7417, 1936, 445, 775, 406, 1643, 281, 5407, 382, 291, 3488, 264, 1230, 295, 21335, 50942, 50942, 5110, 11, 597, 935, 1333, 295, 3110, 300, 2698, 12, 48172, 24420, 33358, 11, 4878, 436, 815, 312, 665, 51226, 51226, 412, 9608, 411, 584, 10774, 35701, 420, 1729, 9608, 411, 3753, 2710, 35701, 11, 456, 51520, 51520, 307, 920, 257, 688, 295, 2649, 1296, 437, 1333, 295, 47982, 4171, 295, 264, 1412, 436, 7983, 11, 51775, 51775], "temperature": 0.0, "avg_logprob": -0.13098316722446018, "compression_ratio": 1.812274368231047, "no_speech_prob": 4.710796474682866e-06}, {"id": 899, "seek": 355080, "start": 3573.92, "end": 3579.02, "text": " is still a lot of difference between what sort of semantic aspect of the data they capture,", "tokens": [50364, 708, 291, 393, 11441, 307, 300, 456, 307, 257, 4776, 7417, 294, 3389, 1296, 257, 2698, 12, 48172, 24420, 50598, 50598, 3170, 293, 257, 46533, 3170, 13, 50726, 50726, 400, 300, 7417, 1936, 445, 775, 406, 1643, 281, 5407, 382, 291, 3488, 264, 1230, 295, 21335, 50942, 50942, 5110, 11, 597, 935, 1333, 295, 3110, 300, 2698, 12, 48172, 24420, 33358, 11, 4878, 436, 815, 312, 665, 51226, 51226, 412, 9608, 411, 584, 10774, 35701, 420, 1729, 9608, 411, 3753, 2710, 35701, 11, 456, 51520, 51520, 307, 920, 257, 688, 295, 2649, 1296, 437, 1333, 295, 47982, 4171, 295, 264, 1412, 436, 7983, 11, 51775, 51775], "temperature": 0.0, "avg_logprob": -0.13098316722446018, "compression_ratio": 1.812274368231047, "no_speech_prob": 4.710796474682866e-06}, {"id": 900, "seek": 357902, "start": 3579.02, "end": 3584.16, "text": " because this in the sort of few short learning task, if I give you one image, and if you're", "tokens": [50364, 570, 341, 294, 264, 1333, 295, 1326, 2099, 2539, 5633, 11, 498, 286, 976, 291, 472, 3256, 11, 293, 498, 291, 434, 50621, 50621, 1075, 281, 584, 746, 466, 309, 11, 428, 4111, 10290, 2203, 281, 312, 6457, 665, 281, 50819, 50819, 5039, 300, 5633, 13, 51069, 51069, 440, 661, 636, 321, 25509, 341, 3170, 390, 281, 1936, 574, 412, 437, 309, 27152, 412, 1184, 51309, 51309, 819, 4583, 13, 51377, 51377, 407, 321, 1936, 8895, 8213, 1508, 23463, 322, 819, 4583, 33358, 294, 257, 5015, 31890, 12, 2803, 13, 51800, 51800], "temperature": 0.0, "avg_logprob": -0.16621262976463805, "compression_ratio": 1.6307053941908713, "no_speech_prob": 7.64643118600361e-06}, {"id": 901, "seek": 357902, "start": 3584.16, "end": 3588.12, "text": " able to say something about it, your feature representation needs to be fairly good to", "tokens": [50364, 570, 341, 294, 264, 1333, 295, 1326, 2099, 2539, 5633, 11, 498, 286, 976, 291, 472, 3256, 11, 293, 498, 291, 434, 50621, 50621, 1075, 281, 584, 746, 466, 309, 11, 428, 4111, 10290, 2203, 281, 312, 6457, 665, 281, 50819, 50819, 5039, 300, 5633, 13, 51069, 51069, 440, 661, 636, 321, 25509, 341, 3170, 390, 281, 1936, 574, 412, 437, 309, 27152, 412, 1184, 51309, 51309, 819, 4583, 13, 51377, 51377, 407, 321, 1936, 8895, 8213, 1508, 23463, 322, 819, 4583, 33358, 294, 257, 5015, 31890, 12, 2803, 13, 51800, 51800], "temperature": 0.0, "avg_logprob": -0.16621262976463805, "compression_ratio": 1.6307053941908713, "no_speech_prob": 7.64643118600361e-06}, {"id": 902, "seek": 357902, "start": 3588.12, "end": 3593.12, "text": " solve that task.", "tokens": [50364, 570, 341, 294, 264, 1333, 295, 1326, 2099, 2539, 5633, 11, 498, 286, 976, 291, 472, 3256, 11, 293, 498, 291, 434, 50621, 50621, 1075, 281, 584, 746, 466, 309, 11, 428, 4111, 10290, 2203, 281, 312, 6457, 665, 281, 50819, 50819, 5039, 300, 5633, 13, 51069, 51069, 440, 661, 636, 321, 25509, 341, 3170, 390, 281, 1936, 574, 412, 437, 309, 27152, 412, 1184, 51309, 51309, 819, 4583, 13, 51377, 51377, 407, 321, 1936, 8895, 8213, 1508, 23463, 322, 819, 4583, 33358, 294, 257, 5015, 31890, 12, 2803, 13, 51800, 51800], "temperature": 0.0, "avg_logprob": -0.16621262976463805, "compression_ratio": 1.6307053941908713, "no_speech_prob": 7.64643118600361e-06}, {"id": 903, "seek": 357902, "start": 3593.12, "end": 3597.92, "text": " The other way we evaluated this method was to basically look at what it learns at each", "tokens": [50364, 570, 341, 294, 264, 1333, 295, 1326, 2099, 2539, 5633, 11, 498, 286, 976, 291, 472, 3256, 11, 293, 498, 291, 434, 50621, 50621, 1075, 281, 584, 746, 466, 309, 11, 428, 4111, 10290, 2203, 281, 312, 6457, 665, 281, 50819, 50819, 5039, 300, 5633, 13, 51069, 51069, 440, 661, 636, 321, 25509, 341, 3170, 390, 281, 1936, 574, 412, 437, 309, 27152, 412, 1184, 51309, 51309, 819, 4583, 13, 51377, 51377, 407, 321, 1936, 8895, 8213, 1508, 23463, 322, 819, 4583, 33358, 294, 257, 5015, 31890, 12, 2803, 13, 51800, 51800], "temperature": 0.0, "avg_logprob": -0.16621262976463805, "compression_ratio": 1.6307053941908713, "no_speech_prob": 7.64643118600361e-06}, {"id": 904, "seek": 357902, "start": 3597.92, "end": 3599.28, "text": " different layer.", "tokens": [50364, 570, 341, 294, 264, 1333, 295, 1326, 2099, 2539, 5633, 11, 498, 286, 976, 291, 472, 3256, 11, 293, 498, 291, 434, 50621, 50621, 1075, 281, 584, 746, 466, 309, 11, 428, 4111, 10290, 2203, 281, 312, 6457, 665, 281, 50819, 50819, 5039, 300, 5633, 13, 51069, 51069, 440, 661, 636, 321, 25509, 341, 3170, 390, 281, 1936, 574, 412, 437, 309, 27152, 412, 1184, 51309, 51309, 819, 4583, 13, 51377, 51377, 407, 321, 1936, 8895, 8213, 1508, 23463, 322, 819, 4583, 33358, 294, 257, 5015, 31890, 12, 2803, 13, 51800, 51800], "temperature": 0.0, "avg_logprob": -0.16621262976463805, "compression_ratio": 1.6307053941908713, "no_speech_prob": 7.64643118600361e-06}, {"id": 905, "seek": 357902, "start": 3599.28, "end": 3607.74, "text": " So we basically trained linear classifiers on different layer representations in a ResNet-50.", "tokens": [50364, 570, 341, 294, 264, 1333, 295, 1326, 2099, 2539, 5633, 11, 498, 286, 976, 291, 472, 3256, 11, 293, 498, 291, 434, 50621, 50621, 1075, 281, 584, 746, 466, 309, 11, 428, 4111, 10290, 2203, 281, 312, 6457, 665, 281, 50819, 50819, 5039, 300, 5633, 13, 51069, 51069, 440, 661, 636, 321, 25509, 341, 3170, 390, 281, 1936, 574, 412, 437, 309, 27152, 412, 1184, 51309, 51309, 819, 4583, 13, 51377, 51377, 407, 321, 1936, 8895, 8213, 1508, 23463, 322, 819, 4583, 33358, 294, 257, 5015, 31890, 12, 2803, 13, 51800, 51800], "temperature": 0.0, "avg_logprob": -0.16621262976463805, "compression_ratio": 1.6307053941908713, "no_speech_prob": 7.64643118600361e-06}, {"id": 906, "seek": 360774, "start": 3607.74, "end": 3612.64, "text": " So from the CON1, which is going to be the layer closest to the input to the output,", "tokens": [50364, 407, 490, 264, 16596, 16, 11, 597, 307, 516, 281, 312, 264, 4583, 13699, 281, 264, 4846, 281, 264, 5598, 11, 50609, 50609, 584, 295, 264, 5015, 17, 3461, 11, 264, 5015, 18, 3461, 11, 293, 264, 5015, 20, 3461, 13, 50793, 50793, 407, 5015, 20, 307, 1936, 264, 1333, 295, 6343, 1496, 10290, 300, 291, 603, 483, 484, 490, 257, 50999, 50999, 5015, 31890, 12, 2803, 13, 51077, 51077, 400, 934, 300, 10290, 307, 689, 291, 2042, 341, 2302, 361, 17156, 1607, 11, 411, 32884, 51261, 51261, 264, 4784, 11380, 5633, 13, 51373, 51373, 400, 370, 291, 574, 412, 11, 294, 341, 1389, 11, 264, 2031, 12, 24633, 8855, 264, 1333, 295, 689, 264, 4111, 307, 51626, 51626, 1348, 490, 11, 16596, 16, 420, 5015, 20, 13, 51757, 51757], "temperature": 0.0, "avg_logprob": -0.2033494891542377, "compression_ratio": 1.7593984962406015, "no_speech_prob": 6.854028924863087e-06}, {"id": 907, "seek": 360774, "start": 3612.64, "end": 3616.3199999999997, "text": " say of the Res2 block, the Res3 block, and the Res5 block.", "tokens": [50364, 407, 490, 264, 16596, 16, 11, 597, 307, 516, 281, 312, 264, 4583, 13699, 281, 264, 4846, 281, 264, 5598, 11, 50609, 50609, 584, 295, 264, 5015, 17, 3461, 11, 264, 5015, 18, 3461, 11, 293, 264, 5015, 20, 3461, 13, 50793, 50793, 407, 5015, 20, 307, 1936, 264, 1333, 295, 6343, 1496, 10290, 300, 291, 603, 483, 484, 490, 257, 50999, 50999, 5015, 31890, 12, 2803, 13, 51077, 51077, 400, 934, 300, 10290, 307, 689, 291, 2042, 341, 2302, 361, 17156, 1607, 11, 411, 32884, 51261, 51261, 264, 4784, 11380, 5633, 13, 51373, 51373, 400, 370, 291, 574, 412, 11, 294, 341, 1389, 11, 264, 2031, 12, 24633, 8855, 264, 1333, 295, 689, 264, 4111, 307, 51626, 51626, 1348, 490, 11, 16596, 16, 420, 5015, 20, 13, 51757, 51757], "temperature": 0.0, "avg_logprob": -0.2033494891542377, "compression_ratio": 1.7593984962406015, "no_speech_prob": 6.854028924863087e-06}, {"id": 908, "seek": 360774, "start": 3616.3199999999997, "end": 3620.4399999999996, "text": " So Res5 is basically the sort of highest level representation that you'll get out from a", "tokens": [50364, 407, 490, 264, 16596, 16, 11, 597, 307, 516, 281, 312, 264, 4583, 13699, 281, 264, 4846, 281, 264, 5598, 11, 50609, 50609, 584, 295, 264, 5015, 17, 3461, 11, 264, 5015, 18, 3461, 11, 293, 264, 5015, 20, 3461, 13, 50793, 50793, 407, 5015, 20, 307, 1936, 264, 1333, 295, 6343, 1496, 10290, 300, 291, 603, 483, 484, 490, 257, 50999, 50999, 5015, 31890, 12, 2803, 13, 51077, 51077, 400, 934, 300, 10290, 307, 689, 291, 2042, 341, 2302, 361, 17156, 1607, 11, 411, 32884, 51261, 51261, 264, 4784, 11380, 5633, 13, 51373, 51373, 400, 370, 291, 574, 412, 11, 294, 341, 1389, 11, 264, 2031, 12, 24633, 8855, 264, 1333, 295, 689, 264, 4111, 307, 51626, 51626, 1348, 490, 11, 16596, 16, 420, 5015, 20, 13, 51757, 51757], "temperature": 0.0, "avg_logprob": -0.2033494891542377, "compression_ratio": 1.7593984962406015, "no_speech_prob": 6.854028924863087e-06}, {"id": 909, "seek": 360774, "start": 3620.4399999999996, "end": 3622.0, "text": " ResNet-50.", "tokens": [50364, 407, 490, 264, 16596, 16, 11, 597, 307, 516, 281, 312, 264, 4583, 13699, 281, 264, 4846, 281, 264, 5598, 11, 50609, 50609, 584, 295, 264, 5015, 17, 3461, 11, 264, 5015, 18, 3461, 11, 293, 264, 5015, 20, 3461, 13, 50793, 50793, 407, 5015, 20, 307, 1936, 264, 1333, 295, 6343, 1496, 10290, 300, 291, 603, 483, 484, 490, 257, 50999, 50999, 5015, 31890, 12, 2803, 13, 51077, 51077, 400, 934, 300, 10290, 307, 689, 291, 2042, 341, 2302, 361, 17156, 1607, 11, 411, 32884, 51261, 51261, 264, 4784, 11380, 5633, 13, 51373, 51373, 400, 370, 291, 574, 412, 11, 294, 341, 1389, 11, 264, 2031, 12, 24633, 8855, 264, 1333, 295, 689, 264, 4111, 307, 51626, 51626, 1348, 490, 11, 16596, 16, 420, 5015, 20, 13, 51757, 51757], "temperature": 0.0, "avg_logprob": -0.2033494891542377, "compression_ratio": 1.7593984962406015, "no_speech_prob": 6.854028924863087e-06}, {"id": 910, "seek": 360774, "start": 3622.0, "end": 3625.68, "text": " And after that representation is where you perform this entire jigsaw, like predicting", "tokens": [50364, 407, 490, 264, 16596, 16, 11, 597, 307, 516, 281, 312, 264, 4583, 13699, 281, 264, 4846, 281, 264, 5598, 11, 50609, 50609, 584, 295, 264, 5015, 17, 3461, 11, 264, 5015, 18, 3461, 11, 293, 264, 5015, 20, 3461, 13, 50793, 50793, 407, 5015, 20, 307, 1936, 264, 1333, 295, 6343, 1496, 10290, 300, 291, 603, 483, 484, 490, 257, 50999, 50999, 5015, 31890, 12, 2803, 13, 51077, 51077, 400, 934, 300, 10290, 307, 689, 291, 2042, 341, 2302, 361, 17156, 1607, 11, 411, 32884, 51261, 51261, 264, 4784, 11380, 5633, 13, 51373, 51373, 400, 370, 291, 574, 412, 11, 294, 341, 1389, 11, 264, 2031, 12, 24633, 8855, 264, 1333, 295, 689, 264, 4111, 307, 51626, 51626, 1348, 490, 11, 16596, 16, 420, 5015, 20, 13, 51757, 51757], "temperature": 0.0, "avg_logprob": -0.2033494891542377, "compression_ratio": 1.7593984962406015, "no_speech_prob": 6.854028924863087e-06}, {"id": 911, "seek": 360774, "start": 3625.68, "end": 3627.9199999999996, "text": " the permutation task.", "tokens": [50364, 407, 490, 264, 16596, 16, 11, 597, 307, 516, 281, 312, 264, 4583, 13699, 281, 264, 4846, 281, 264, 5598, 11, 50609, 50609, 584, 295, 264, 5015, 17, 3461, 11, 264, 5015, 18, 3461, 11, 293, 264, 5015, 20, 3461, 13, 50793, 50793, 407, 5015, 20, 307, 1936, 264, 1333, 295, 6343, 1496, 10290, 300, 291, 603, 483, 484, 490, 257, 50999, 50999, 5015, 31890, 12, 2803, 13, 51077, 51077, 400, 934, 300, 10290, 307, 689, 291, 2042, 341, 2302, 361, 17156, 1607, 11, 411, 32884, 51261, 51261, 264, 4784, 11380, 5633, 13, 51373, 51373, 400, 370, 291, 574, 412, 11, 294, 341, 1389, 11, 264, 2031, 12, 24633, 8855, 264, 1333, 295, 689, 264, 4111, 307, 51626, 51626, 1348, 490, 11, 16596, 16, 420, 5015, 20, 13, 51757, 51757], "temperature": 0.0, "avg_logprob": -0.2033494891542377, "compression_ratio": 1.7593984962406015, "no_speech_prob": 6.854028924863087e-06}, {"id": 912, "seek": 360774, "start": 3627.9199999999996, "end": 3632.9799999999996, "text": " And so you look at, in this case, the x-axis represents the sort of where the feature is", "tokens": [50364, 407, 490, 264, 16596, 16, 11, 597, 307, 516, 281, 312, 264, 4583, 13699, 281, 264, 4846, 281, 264, 5598, 11, 50609, 50609, 584, 295, 264, 5015, 17, 3461, 11, 264, 5015, 18, 3461, 11, 293, 264, 5015, 20, 3461, 13, 50793, 50793, 407, 5015, 20, 307, 1936, 264, 1333, 295, 6343, 1496, 10290, 300, 291, 603, 483, 484, 490, 257, 50999, 50999, 5015, 31890, 12, 2803, 13, 51077, 51077, 400, 934, 300, 10290, 307, 689, 291, 2042, 341, 2302, 361, 17156, 1607, 11, 411, 32884, 51261, 51261, 264, 4784, 11380, 5633, 13, 51373, 51373, 400, 370, 291, 574, 412, 11, 294, 341, 1389, 11, 264, 2031, 12, 24633, 8855, 264, 1333, 295, 689, 264, 4111, 307, 51626, 51626, 1348, 490, 11, 16596, 16, 420, 5015, 20, 13, 51757, 51757], "temperature": 0.0, "avg_logprob": -0.2033494891542377, "compression_ratio": 1.7593984962406015, "no_speech_prob": 6.854028924863087e-06}, {"id": 913, "seek": 360774, "start": 3632.9799999999996, "end": 3635.6, "text": " coming from, CON1 or Res5.", "tokens": [50364, 407, 490, 264, 16596, 16, 11, 597, 307, 516, 281, 312, 264, 4583, 13699, 281, 264, 4846, 281, 264, 5598, 11, 50609, 50609, 584, 295, 264, 5015, 17, 3461, 11, 264, 5015, 18, 3461, 11, 293, 264, 5015, 20, 3461, 13, 50793, 50793, 407, 5015, 20, 307, 1936, 264, 1333, 295, 6343, 1496, 10290, 300, 291, 603, 483, 484, 490, 257, 50999, 50999, 5015, 31890, 12, 2803, 13, 51077, 51077, 400, 934, 300, 10290, 307, 689, 291, 2042, 341, 2302, 361, 17156, 1607, 11, 411, 32884, 51261, 51261, 264, 4784, 11380, 5633, 13, 51373, 51373, 400, 370, 291, 574, 412, 11, 294, 341, 1389, 11, 264, 2031, 12, 24633, 8855, 264, 1333, 295, 689, 264, 4111, 307, 51626, 51626, 1348, 490, 11, 16596, 16, 420, 5015, 20, 13, 51757, 51757], "temperature": 0.0, "avg_logprob": -0.2033494891542377, "compression_ratio": 1.7593984962406015, "no_speech_prob": 6.854028924863087e-06}, {"id": 914, "seek": 363560, "start": 3635.6, "end": 3640.88, "text": " And on the y-axis, we are looking at the, again, mean average precision of image classification", "tokens": [50364, 400, 322, 264, 288, 12, 24633, 11, 321, 366, 1237, 412, 264, 11, 797, 11, 914, 4274, 18356, 295, 3256, 21538, 50628, 50628, 322, 264, 42278, 13, 50724, 50724, 400, 1019, 77, 953, 1547, 11, 437, 291, 536, 307, 1936, 300, 264, 10290, 3125, 24771, 562, 50978, 50978, 291, 352, 490, 16596, 16, 281, 5015, 19, 13, 51088, 51088, 407, 309, 36129, 1333, 295, 8637, 294, 264, 914, 4274, 18356, 13, 51317, 51317, 583, 3030, 264, 917, 11, 456, 311, 257, 8199, 3270, 13, 51470, 51470, 407, 5015, 19, 281, 5015, 20, 307, 257, 8199, 3270, 294, 3389, 13, 51678, 51678, 1119, 300, 3462, 281, 264, 1186, 300, 309, 2121, 5660, 281, 264, 2685, 5633, 30, 51826, 51826], "temperature": 0.0, "avg_logprob": -0.15800674756368002, "compression_ratio": 1.654275092936803, "no_speech_prob": 1.3005103937757667e-05}, {"id": 915, "seek": 363560, "start": 3640.88, "end": 3642.7999999999997, "text": " on the OC.", "tokens": [50364, 400, 322, 264, 288, 12, 24633, 11, 321, 366, 1237, 412, 264, 11, 797, 11, 914, 4274, 18356, 295, 3256, 21538, 50628, 50628, 322, 264, 42278, 13, 50724, 50724, 400, 1019, 77, 953, 1547, 11, 437, 291, 536, 307, 1936, 300, 264, 10290, 3125, 24771, 562, 50978, 50978, 291, 352, 490, 16596, 16, 281, 5015, 19, 13, 51088, 51088, 407, 309, 36129, 1333, 295, 8637, 294, 264, 914, 4274, 18356, 13, 51317, 51317, 583, 3030, 264, 917, 11, 456, 311, 257, 8199, 3270, 13, 51470, 51470, 407, 5015, 19, 281, 5015, 20, 307, 257, 8199, 3270, 294, 3389, 13, 51678, 51678, 1119, 300, 3462, 281, 264, 1186, 300, 309, 2121, 5660, 281, 264, 2685, 5633, 30, 51826, 51826], "temperature": 0.0, "avg_logprob": -0.15800674756368002, "compression_ratio": 1.654275092936803, "no_speech_prob": 1.3005103937757667e-05}, {"id": 916, "seek": 363560, "start": 3642.7999999999997, "end": 3647.88, "text": " And funnily enough, what you see is basically that the representation quality improves when", "tokens": [50364, 400, 322, 264, 288, 12, 24633, 11, 321, 366, 1237, 412, 264, 11, 797, 11, 914, 4274, 18356, 295, 3256, 21538, 50628, 50628, 322, 264, 42278, 13, 50724, 50724, 400, 1019, 77, 953, 1547, 11, 437, 291, 536, 307, 1936, 300, 264, 10290, 3125, 24771, 562, 50978, 50978, 291, 352, 490, 16596, 16, 281, 5015, 19, 13, 51088, 51088, 407, 309, 36129, 1333, 295, 8637, 294, 264, 914, 4274, 18356, 13, 51317, 51317, 583, 3030, 264, 917, 11, 456, 311, 257, 8199, 3270, 13, 51470, 51470, 407, 5015, 19, 281, 5015, 20, 307, 257, 8199, 3270, 294, 3389, 13, 51678, 51678, 1119, 300, 3462, 281, 264, 1186, 300, 309, 2121, 5660, 281, 264, 2685, 5633, 30, 51826, 51826], "temperature": 0.0, "avg_logprob": -0.15800674756368002, "compression_ratio": 1.654275092936803, "no_speech_prob": 1.3005103937757667e-05}, {"id": 917, "seek": 363560, "start": 3647.88, "end": 3650.08, "text": " you go from CON1 to Res4.", "tokens": [50364, 400, 322, 264, 288, 12, 24633, 11, 321, 366, 1237, 412, 264, 11, 797, 11, 914, 4274, 18356, 295, 3256, 21538, 50628, 50628, 322, 264, 42278, 13, 50724, 50724, 400, 1019, 77, 953, 1547, 11, 437, 291, 536, 307, 1936, 300, 264, 10290, 3125, 24771, 562, 50978, 50978, 291, 352, 490, 16596, 16, 281, 5015, 19, 13, 51088, 51088, 407, 309, 36129, 1333, 295, 8637, 294, 264, 914, 4274, 18356, 13, 51317, 51317, 583, 3030, 264, 917, 11, 456, 311, 257, 8199, 3270, 13, 51470, 51470, 407, 5015, 19, 281, 5015, 20, 307, 257, 8199, 3270, 294, 3389, 13, 51678, 51678, 1119, 300, 3462, 281, 264, 1186, 300, 309, 2121, 5660, 281, 264, 2685, 5633, 30, 51826, 51826], "temperature": 0.0, "avg_logprob": -0.15800674756368002, "compression_ratio": 1.654275092936803, "no_speech_prob": 1.3005103937757667e-05}, {"id": 918, "seek": 363560, "start": 3650.08, "end": 3654.66, "text": " So it steadily sort of increases in the mean average precision.", "tokens": [50364, 400, 322, 264, 288, 12, 24633, 11, 321, 366, 1237, 412, 264, 11, 797, 11, 914, 4274, 18356, 295, 3256, 21538, 50628, 50628, 322, 264, 42278, 13, 50724, 50724, 400, 1019, 77, 953, 1547, 11, 437, 291, 536, 307, 1936, 300, 264, 10290, 3125, 24771, 562, 50978, 50978, 291, 352, 490, 16596, 16, 281, 5015, 19, 13, 51088, 51088, 407, 309, 36129, 1333, 295, 8637, 294, 264, 914, 4274, 18356, 13, 51317, 51317, 583, 3030, 264, 917, 11, 456, 311, 257, 8199, 3270, 13, 51470, 51470, 407, 5015, 19, 281, 5015, 20, 307, 257, 8199, 3270, 294, 3389, 13, 51678, 51678, 1119, 300, 3462, 281, 264, 1186, 300, 309, 2121, 5660, 281, 264, 2685, 5633, 30, 51826, 51826], "temperature": 0.0, "avg_logprob": -0.15800674756368002, "compression_ratio": 1.654275092936803, "no_speech_prob": 1.3005103937757667e-05}, {"id": 919, "seek": 363560, "start": 3654.66, "end": 3657.72, "text": " But towards the end, there's a sharp drop.", "tokens": [50364, 400, 322, 264, 288, 12, 24633, 11, 321, 366, 1237, 412, 264, 11, 797, 11, 914, 4274, 18356, 295, 3256, 21538, 50628, 50628, 322, 264, 42278, 13, 50724, 50724, 400, 1019, 77, 953, 1547, 11, 437, 291, 536, 307, 1936, 300, 264, 10290, 3125, 24771, 562, 50978, 50978, 291, 352, 490, 16596, 16, 281, 5015, 19, 13, 51088, 51088, 407, 309, 36129, 1333, 295, 8637, 294, 264, 914, 4274, 18356, 13, 51317, 51317, 583, 3030, 264, 917, 11, 456, 311, 257, 8199, 3270, 13, 51470, 51470, 407, 5015, 19, 281, 5015, 20, 307, 257, 8199, 3270, 294, 3389, 13, 51678, 51678, 1119, 300, 3462, 281, 264, 1186, 300, 309, 2121, 5660, 281, 264, 2685, 5633, 30, 51826, 51826], "temperature": 0.0, "avg_logprob": -0.15800674756368002, "compression_ratio": 1.654275092936803, "no_speech_prob": 1.3005103937757667e-05}, {"id": 920, "seek": 363560, "start": 3657.72, "end": 3661.88, "text": " So Res4 to Res5 is a sharp drop in performance.", "tokens": [50364, 400, 322, 264, 288, 12, 24633, 11, 321, 366, 1237, 412, 264, 11, 797, 11, 914, 4274, 18356, 295, 3256, 21538, 50628, 50628, 322, 264, 42278, 13, 50724, 50724, 400, 1019, 77, 953, 1547, 11, 437, 291, 536, 307, 1936, 300, 264, 10290, 3125, 24771, 562, 50978, 50978, 291, 352, 490, 16596, 16, 281, 5015, 19, 13, 51088, 51088, 407, 309, 36129, 1333, 295, 8637, 294, 264, 914, 4274, 18356, 13, 51317, 51317, 583, 3030, 264, 917, 11, 456, 311, 257, 8199, 3270, 13, 51470, 51470, 407, 5015, 19, 281, 5015, 20, 307, 257, 8199, 3270, 294, 3389, 13, 51678, 51678, 1119, 300, 3462, 281, 264, 1186, 300, 309, 2121, 5660, 281, 264, 2685, 5633, 30, 51826, 51826], "temperature": 0.0, "avg_logprob": -0.15800674756368002, "compression_ratio": 1.654275092936803, "no_speech_prob": 1.3005103937757667e-05}, {"id": 921, "seek": 363560, "start": 3661.88, "end": 3664.8399999999997, "text": " Is that due to the fact that it specializes to the specific task?", "tokens": [50364, 400, 322, 264, 288, 12, 24633, 11, 321, 366, 1237, 412, 264, 11, 797, 11, 914, 4274, 18356, 295, 3256, 21538, 50628, 50628, 322, 264, 42278, 13, 50724, 50724, 400, 1019, 77, 953, 1547, 11, 437, 291, 536, 307, 1936, 300, 264, 10290, 3125, 24771, 562, 50978, 50978, 291, 352, 490, 16596, 16, 281, 5015, 19, 13, 51088, 51088, 407, 309, 36129, 1333, 295, 8637, 294, 264, 914, 4274, 18356, 13, 51317, 51317, 583, 3030, 264, 917, 11, 456, 311, 257, 8199, 3270, 13, 51470, 51470, 407, 5015, 19, 281, 5015, 20, 307, 257, 8199, 3270, 294, 3389, 13, 51678, 51678, 1119, 300, 3462, 281, 264, 1186, 300, 309, 2121, 5660, 281, 264, 2685, 5633, 30, 51826, 51826], "temperature": 0.0, "avg_logprob": -0.15800674756368002, "compression_ratio": 1.654275092936803, "no_speech_prob": 1.3005103937757667e-05}, {"id": 922, "seek": 366484, "start": 3664.84, "end": 3666.38, "text": " Yes, exactly.", "tokens": [50364, 1079, 11, 2293, 13, 50441, 50441, 407, 341, 390, 588, 18788, 11, 570, 498, 291, 645, 281, 1333, 295, 7542, 341, 551, 337, 257, 46533, 50768, 50768, 3209, 11, 291, 11441, 300, 490, 16596, 16, 281, 5015, 20, 11, 264, 10290, 3125, 1009, 24771, 13, 51049, 51049, 400, 341, 307, 2074, 337, 1238, 709, 604, 665, 46533, 3209, 13, 51226, 51226, 13813, 337, 257, 688, 295, 264, 2698, 12, 48172, 24420, 9590, 11, 321, 1333, 295, 10477, 341, 5120, 337, 264, 51446, 51446, 12447, 3209, 11, 337, 2017, 2144, 11, 337, 4972, 2535, 13, 51638, 51638], "temperature": 0.0, "avg_logprob": -0.17837586694834184, "compression_ratio": 1.6762295081967213, "no_speech_prob": 7.411108981614234e-06}, {"id": 923, "seek": 366484, "start": 3666.38, "end": 3672.92, "text": " So this was very worrying, because if you were to sort of plot this thing for a supervised", "tokens": [50364, 1079, 11, 2293, 13, 50441, 50441, 407, 341, 390, 588, 18788, 11, 570, 498, 291, 645, 281, 1333, 295, 7542, 341, 551, 337, 257, 46533, 50768, 50768, 3209, 11, 291, 11441, 300, 490, 16596, 16, 281, 5015, 20, 11, 264, 10290, 3125, 1009, 24771, 13, 51049, 51049, 400, 341, 307, 2074, 337, 1238, 709, 604, 665, 46533, 3209, 13, 51226, 51226, 13813, 337, 257, 688, 295, 264, 2698, 12, 48172, 24420, 9590, 11, 321, 1333, 295, 10477, 341, 5120, 337, 264, 51446, 51446, 12447, 3209, 11, 337, 2017, 2144, 11, 337, 4972, 2535, 13, 51638, 51638], "temperature": 0.0, "avg_logprob": -0.17837586694834184, "compression_ratio": 1.6762295081967213, "no_speech_prob": 7.411108981614234e-06}, {"id": 924, "seek": 366484, "start": 3672.92, "end": 3678.54, "text": " network, you observe that from CON1 to Res5, the representation quality always improves.", "tokens": [50364, 1079, 11, 2293, 13, 50441, 50441, 407, 341, 390, 588, 18788, 11, 570, 498, 291, 645, 281, 1333, 295, 7542, 341, 551, 337, 257, 46533, 50768, 50768, 3209, 11, 291, 11441, 300, 490, 16596, 16, 281, 5015, 20, 11, 264, 10290, 3125, 1009, 24771, 13, 51049, 51049, 400, 341, 307, 2074, 337, 1238, 709, 604, 665, 46533, 3209, 13, 51226, 51226, 13813, 337, 257, 688, 295, 264, 2698, 12, 48172, 24420, 9590, 11, 321, 1333, 295, 10477, 341, 5120, 337, 264, 51446, 51446, 12447, 3209, 11, 337, 2017, 2144, 11, 337, 4972, 2535, 13, 51638, 51638], "temperature": 0.0, "avg_logprob": -0.17837586694834184, "compression_ratio": 1.6762295081967213, "no_speech_prob": 7.411108981614234e-06}, {"id": 925, "seek": 366484, "start": 3678.54, "end": 3682.08, "text": " And this is true for pretty much any good supervised network.", "tokens": [50364, 1079, 11, 2293, 13, 50441, 50441, 407, 341, 390, 588, 18788, 11, 570, 498, 291, 645, 281, 1333, 295, 7542, 341, 551, 337, 257, 46533, 50768, 50768, 3209, 11, 291, 11441, 300, 490, 16596, 16, 281, 5015, 20, 11, 264, 10290, 3125, 1009, 24771, 13, 51049, 51049, 400, 341, 307, 2074, 337, 1238, 709, 604, 665, 46533, 3209, 13, 51226, 51226, 13813, 337, 257, 688, 295, 264, 2698, 12, 48172, 24420, 9590, 11, 321, 1333, 295, 10477, 341, 5120, 337, 264, 51446, 51446, 12447, 3209, 11, 337, 2017, 2144, 11, 337, 4972, 2535, 13, 51638, 51638], "temperature": 0.0, "avg_logprob": -0.17837586694834184, "compression_ratio": 1.6762295081967213, "no_speech_prob": 7.411108981614234e-06}, {"id": 926, "seek": 366484, "start": 3682.08, "end": 3686.48, "text": " Whereas for a lot of the self-supervised networks, we sort of repeated this experiment for the", "tokens": [50364, 1079, 11, 2293, 13, 50441, 50441, 407, 341, 390, 588, 18788, 11, 570, 498, 291, 645, 281, 1333, 295, 7542, 341, 551, 337, 257, 46533, 50768, 50768, 3209, 11, 291, 11441, 300, 490, 16596, 16, 281, 5015, 20, 11, 264, 10290, 3125, 1009, 24771, 13, 51049, 51049, 400, 341, 307, 2074, 337, 1238, 709, 604, 665, 46533, 3209, 13, 51226, 51226, 13813, 337, 257, 688, 295, 264, 2698, 12, 48172, 24420, 9590, 11, 321, 1333, 295, 10477, 341, 5120, 337, 264, 51446, 51446, 12447, 3209, 11, 337, 2017, 2144, 11, 337, 4972, 2535, 13, 51638, 51638], "temperature": 0.0, "avg_logprob": -0.17837586694834184, "compression_ratio": 1.6762295081967213, "no_speech_prob": 7.411108981614234e-06}, {"id": 927, "seek": 366484, "start": 3686.48, "end": 3690.32, "text": " rotation network, for colorization, for relative position.", "tokens": [50364, 1079, 11, 2293, 13, 50441, 50441, 407, 341, 390, 588, 18788, 11, 570, 498, 291, 645, 281, 1333, 295, 7542, 341, 551, 337, 257, 46533, 50768, 50768, 3209, 11, 291, 11441, 300, 490, 16596, 16, 281, 5015, 20, 11, 264, 10290, 3125, 1009, 24771, 13, 51049, 51049, 400, 341, 307, 2074, 337, 1238, 709, 604, 665, 46533, 3209, 13, 51226, 51226, 13813, 337, 257, 688, 295, 264, 2698, 12, 48172, 24420, 9590, 11, 321, 1333, 295, 10477, 341, 5120, 337, 264, 51446, 51446, 12447, 3209, 11, 337, 2017, 2144, 11, 337, 4972, 2535, 13, 51638, 51638], "temperature": 0.0, "avg_logprob": -0.17837586694834184, "compression_ratio": 1.6762295081967213, "no_speech_prob": 7.411108981614234e-06}, {"id": 928, "seek": 369032, "start": 3690.32, "end": 3696.52, "text": " We would always observe this very sharp gap from Res4 to Res5.", "tokens": [50364, 492, 576, 1009, 11441, 341, 588, 8199, 7417, 490, 5015, 19, 281, 5015, 20, 13, 50674, 50674, 400, 370, 341, 1619, 300, 264, 917, 5633, 300, 321, 366, 12606, 11, 264, 659, 25111, 5633, 11, 307, 1391, 50946, 50946, 406, 588, 1481, 11, 570, 309, 311, 406, 588, 731, 17962, 281, 264, 30621, 47982, 9608, 300, 51298, 51298, 321, 534, 528, 281, 5039, 13, 51436, 51436, 3013, 1936, 5607, 385, 281, 264, 958, 644, 11, 597, 307, 281, 1223, 437, 307, 5361, 490, 51672, 51672], "temperature": 0.0, "avg_logprob": -0.08506135830934021, "compression_ratio": 1.5936073059360731, "no_speech_prob": 2.5215292680513812e-06}, {"id": 929, "seek": 369032, "start": 3696.52, "end": 3701.96, "text": " And so this says that the end task that we are solving, the pretext task, is probably", "tokens": [50364, 492, 576, 1009, 11441, 341, 588, 8199, 7417, 490, 5015, 19, 281, 5015, 20, 13, 50674, 50674, 400, 370, 341, 1619, 300, 264, 917, 5633, 300, 321, 366, 12606, 11, 264, 659, 25111, 5633, 11, 307, 1391, 50946, 50946, 406, 588, 1481, 11, 570, 309, 311, 406, 588, 731, 17962, 281, 264, 30621, 47982, 9608, 300, 51298, 51298, 321, 534, 528, 281, 5039, 13, 51436, 51436, 3013, 1936, 5607, 385, 281, 264, 958, 644, 11, 597, 307, 281, 1223, 437, 307, 5361, 490, 51672, 51672], "temperature": 0.0, "avg_logprob": -0.08506135830934021, "compression_ratio": 1.5936073059360731, "no_speech_prob": 2.5215292680513812e-06}, {"id": 930, "seek": 369032, "start": 3701.96, "end": 3709.0, "text": " not very nice, because it's not very well aligned to the downstream semantic tasks that", "tokens": [50364, 492, 576, 1009, 11441, 341, 588, 8199, 7417, 490, 5015, 19, 281, 5015, 20, 13, 50674, 50674, 400, 370, 341, 1619, 300, 264, 917, 5633, 300, 321, 366, 12606, 11, 264, 659, 25111, 5633, 11, 307, 1391, 50946, 50946, 406, 588, 1481, 11, 570, 309, 311, 406, 588, 731, 17962, 281, 264, 30621, 47982, 9608, 300, 51298, 51298, 321, 534, 528, 281, 5039, 13, 51436, 51436, 3013, 1936, 5607, 385, 281, 264, 958, 644, 11, 597, 307, 281, 1223, 437, 307, 5361, 490, 51672, 51672], "temperature": 0.0, "avg_logprob": -0.08506135830934021, "compression_ratio": 1.5936073059360731, "no_speech_prob": 2.5215292680513812e-06}, {"id": 931, "seek": 369032, "start": 3709.0, "end": 3711.76, "text": " we really want to solve.", "tokens": [50364, 492, 576, 1009, 11441, 341, 588, 8199, 7417, 490, 5015, 19, 281, 5015, 20, 13, 50674, 50674, 400, 370, 341, 1619, 300, 264, 917, 5633, 300, 321, 366, 12606, 11, 264, 659, 25111, 5633, 11, 307, 1391, 50946, 50946, 406, 588, 1481, 11, 570, 309, 311, 406, 588, 731, 17962, 281, 264, 30621, 47982, 9608, 300, 51298, 51298, 321, 534, 528, 281, 5039, 13, 51436, 51436, 3013, 1936, 5607, 385, 281, 264, 958, 644, 11, 597, 307, 281, 1223, 437, 307, 5361, 490, 51672, 51672], "temperature": 0.0, "avg_logprob": -0.08506135830934021, "compression_ratio": 1.5936073059360731, "no_speech_prob": 2.5215292680513812e-06}, {"id": 932, "seek": 369032, "start": 3711.76, "end": 3716.48, "text": " Which basically brings me to the next part, which is to understand what is missing from", "tokens": [50364, 492, 576, 1009, 11441, 341, 588, 8199, 7417, 490, 5015, 19, 281, 5015, 20, 13, 50674, 50674, 400, 370, 341, 1619, 300, 264, 917, 5633, 300, 321, 366, 12606, 11, 264, 659, 25111, 5633, 11, 307, 1391, 50946, 50946, 406, 588, 1481, 11, 570, 309, 311, 406, 588, 731, 17962, 281, 264, 30621, 47982, 9608, 300, 51298, 51298, 321, 534, 528, 281, 5039, 13, 51436, 51436, 3013, 1936, 5607, 385, 281, 264, 958, 644, 11, 597, 307, 281, 1223, 437, 307, 5361, 490, 51672, 51672], "temperature": 0.0, "avg_logprob": -0.08506135830934021, "compression_ratio": 1.5936073059360731, "no_speech_prob": 2.5215292680513812e-06}, {"id": 933, "seek": 371648, "start": 3716.48, "end": 3722.16, "text": " these pretext or these sort of proxy tasks.", "tokens": [50364, 613, 659, 25111, 420, 613, 1333, 295, 29690, 9608, 13, 50648, 50648, 407, 20928, 11, 659, 25111, 9608, 366, 1936, 746, 411, 32884, 12447, 420, 281, 6069, 11, 584, 11, 50980, 50980, 361, 17156, 1607, 24138, 13, 51030, 51030, 400, 309, 311, 588, 1333, 295, 11, 498, 291, 574, 412, 309, 294, 264, 3801, 3036, 295, 721, 11, 436, 434, 588, 51286, 51286, 8830, 13, 51336, 51336, 400, 264, 1186, 300, 436, 754, 589, 307, 1687, 8830, 13, 51523, 51523, 407, 337, 659, 25111, 9608, 11, 321, 362, 341, 659, 12, 17227, 1760, 1823, 11, 597, 307, 2698, 12, 48172, 24420, 13, 51792, 51792], "temperature": 0.0, "avg_logprob": -0.14843584456533757, "compression_ratio": 1.6812227074235808, "no_speech_prob": 7.1830440901976544e-06}, {"id": 934, "seek": 371648, "start": 3722.16, "end": 3728.8, "text": " So recap, pretext tasks are basically something like predicting rotation or to predict, say,", "tokens": [50364, 613, 659, 25111, 420, 613, 1333, 295, 29690, 9608, 13, 50648, 50648, 407, 20928, 11, 659, 25111, 9608, 366, 1936, 746, 411, 32884, 12447, 420, 281, 6069, 11, 584, 11, 50980, 50980, 361, 17156, 1607, 24138, 13, 51030, 51030, 400, 309, 311, 588, 1333, 295, 11, 498, 291, 574, 412, 309, 294, 264, 3801, 3036, 295, 721, 11, 436, 434, 588, 51286, 51286, 8830, 13, 51336, 51336, 400, 264, 1186, 300, 436, 754, 589, 307, 1687, 8830, 13, 51523, 51523, 407, 337, 659, 25111, 9608, 11, 321, 362, 341, 659, 12, 17227, 1760, 1823, 11, 597, 307, 2698, 12, 48172, 24420, 13, 51792, 51792], "temperature": 0.0, "avg_logprob": -0.14843584456533757, "compression_ratio": 1.6812227074235808, "no_speech_prob": 7.1830440901976544e-06}, {"id": 935, "seek": 371648, "start": 3728.8, "end": 3729.8, "text": " jigsaw puzzles.", "tokens": [50364, 613, 659, 25111, 420, 613, 1333, 295, 29690, 9608, 13, 50648, 50648, 407, 20928, 11, 659, 25111, 9608, 366, 1936, 746, 411, 32884, 12447, 420, 281, 6069, 11, 584, 11, 50980, 50980, 361, 17156, 1607, 24138, 13, 51030, 51030, 400, 309, 311, 588, 1333, 295, 11, 498, 291, 574, 412, 309, 294, 264, 3801, 3036, 295, 721, 11, 436, 434, 588, 51286, 51286, 8830, 13, 51336, 51336, 400, 264, 1186, 300, 436, 754, 589, 307, 1687, 8830, 13, 51523, 51523, 407, 337, 659, 25111, 9608, 11, 321, 362, 341, 659, 12, 17227, 1760, 1823, 11, 597, 307, 2698, 12, 48172, 24420, 13, 51792, 51792], "temperature": 0.0, "avg_logprob": -0.14843584456533757, "compression_ratio": 1.6812227074235808, "no_speech_prob": 7.1830440901976544e-06}, {"id": 936, "seek": 371648, "start": 3729.8, "end": 3734.92, "text": " And it's very sort of, if you look at it in the bigger picture of things, they're very", "tokens": [50364, 613, 659, 25111, 420, 613, 1333, 295, 29690, 9608, 13, 50648, 50648, 407, 20928, 11, 659, 25111, 9608, 366, 1936, 746, 411, 32884, 12447, 420, 281, 6069, 11, 584, 11, 50980, 50980, 361, 17156, 1607, 24138, 13, 51030, 51030, 400, 309, 311, 588, 1333, 295, 11, 498, 291, 574, 412, 309, 294, 264, 3801, 3036, 295, 721, 11, 436, 434, 588, 51286, 51286, 8830, 13, 51336, 51336, 400, 264, 1186, 300, 436, 754, 589, 307, 1687, 8830, 13, 51523, 51523, 407, 337, 659, 25111, 9608, 11, 321, 362, 341, 659, 12, 17227, 1760, 1823, 11, 597, 307, 2698, 12, 48172, 24420, 13, 51792, 51792], "temperature": 0.0, "avg_logprob": -0.14843584456533757, "compression_ratio": 1.6812227074235808, "no_speech_prob": 7.1830440901976544e-06}, {"id": 937, "seek": 371648, "start": 3734.92, "end": 3735.92, "text": " surprising.", "tokens": [50364, 613, 659, 25111, 420, 613, 1333, 295, 29690, 9608, 13, 50648, 50648, 407, 20928, 11, 659, 25111, 9608, 366, 1936, 746, 411, 32884, 12447, 420, 281, 6069, 11, 584, 11, 50980, 50980, 361, 17156, 1607, 24138, 13, 51030, 51030, 400, 309, 311, 588, 1333, 295, 11, 498, 291, 574, 412, 309, 294, 264, 3801, 3036, 295, 721, 11, 436, 434, 588, 51286, 51286, 8830, 13, 51336, 51336, 400, 264, 1186, 300, 436, 754, 589, 307, 1687, 8830, 13, 51523, 51523, 407, 337, 659, 25111, 9608, 11, 321, 362, 341, 659, 12, 17227, 1760, 1823, 11, 597, 307, 2698, 12, 48172, 24420, 13, 51792, 51792], "temperature": 0.0, "avg_logprob": -0.14843584456533757, "compression_ratio": 1.6812227074235808, "no_speech_prob": 7.1830440901976544e-06}, {"id": 938, "seek": 371648, "start": 3735.92, "end": 3739.66, "text": " And the fact that they even work is super surprising.", "tokens": [50364, 613, 659, 25111, 420, 613, 1333, 295, 29690, 9608, 13, 50648, 50648, 407, 20928, 11, 659, 25111, 9608, 366, 1936, 746, 411, 32884, 12447, 420, 281, 6069, 11, 584, 11, 50980, 50980, 361, 17156, 1607, 24138, 13, 51030, 51030, 400, 309, 311, 588, 1333, 295, 11, 498, 291, 574, 412, 309, 294, 264, 3801, 3036, 295, 721, 11, 436, 434, 588, 51286, 51286, 8830, 13, 51336, 51336, 400, 264, 1186, 300, 436, 754, 589, 307, 1687, 8830, 13, 51523, 51523, 407, 337, 659, 25111, 9608, 11, 321, 362, 341, 659, 12, 17227, 1760, 1823, 11, 597, 307, 2698, 12, 48172, 24420, 13, 51792, 51792], "temperature": 0.0, "avg_logprob": -0.14843584456533757, "compression_ratio": 1.6812227074235808, "no_speech_prob": 7.1830440901976544e-06}, {"id": 939, "seek": 371648, "start": 3739.66, "end": 3745.04, "text": " So for pretext tasks, we have this pre-training step, which is self-supervised.", "tokens": [50364, 613, 659, 25111, 420, 613, 1333, 295, 29690, 9608, 13, 50648, 50648, 407, 20928, 11, 659, 25111, 9608, 366, 1936, 746, 411, 32884, 12447, 420, 281, 6069, 11, 584, 11, 50980, 50980, 361, 17156, 1607, 24138, 13, 51030, 51030, 400, 309, 311, 588, 1333, 295, 11, 498, 291, 574, 412, 309, 294, 264, 3801, 3036, 295, 721, 11, 436, 434, 588, 51286, 51286, 8830, 13, 51336, 51336, 400, 264, 1186, 300, 436, 754, 589, 307, 1687, 8830, 13, 51523, 51523, 407, 337, 659, 25111, 9608, 11, 321, 362, 341, 659, 12, 17227, 1760, 1823, 11, 597, 307, 2698, 12, 48172, 24420, 13, 51792, 51792], "temperature": 0.0, "avg_logprob": -0.14843584456533757, "compression_ratio": 1.6812227074235808, "no_speech_prob": 7.1830440901976544e-06}, {"id": 940, "seek": 374504, "start": 3745.04, "end": 3749.7599999999998, "text": " And then we have our transfer tasks, which are image classification or detection.", "tokens": [50364, 400, 550, 321, 362, 527, 5003, 9608, 11, 597, 366, 3256, 21538, 420, 17784, 13, 50600, 50600, 400, 309, 311, 534, 257, 688, 295, 3172, 906, 1953, 293, 257, 688, 295, 1454, 300, 264, 659, 12, 17227, 1760, 5633, 50832, 50832, 293, 264, 5003, 5633, 366, 1687, 17962, 13, 50974, 50974, 400, 456, 307, 572, 4467, 11, 534, 13, 51068, 51068, 467, 311, 257, 688, 295, 445, 30049, 534, 11, 534, 1152, 300, 2035, 659, 25111, 5633, 321, 600, 808, 51268, 51268, 493, 365, 307, 534, 731, 17962, 365, 527, 5003, 5633, 13, 51403, 51403, 400, 12606, 300, 659, 25111, 5633, 486, 360, 534, 731, 294, 5003, 9608, 13, 51594, 51594, 407, 257, 688, 295, 2132, 1936, 1709, 666, 14685, 613, 659, 25111, 9608, 293, 18114, 552, 51830, 51830], "temperature": 0.0, "avg_logprob": -0.1192341797224438, "compression_ratio": 1.960431654676259, "no_speech_prob": 1.0952464435831644e-05}, {"id": 941, "seek": 374504, "start": 3749.7599999999998, "end": 3754.4, "text": " And it's really a lot of wishful thinking and a lot of hope that the pre-training task", "tokens": [50364, 400, 550, 321, 362, 527, 5003, 9608, 11, 597, 366, 3256, 21538, 420, 17784, 13, 50600, 50600, 400, 309, 311, 534, 257, 688, 295, 3172, 906, 1953, 293, 257, 688, 295, 1454, 300, 264, 659, 12, 17227, 1760, 5633, 50832, 50832, 293, 264, 5003, 5633, 366, 1687, 17962, 13, 50974, 50974, 400, 456, 307, 572, 4467, 11, 534, 13, 51068, 51068, 467, 311, 257, 688, 295, 445, 30049, 534, 11, 534, 1152, 300, 2035, 659, 25111, 5633, 321, 600, 808, 51268, 51268, 493, 365, 307, 534, 731, 17962, 365, 527, 5003, 5633, 13, 51403, 51403, 400, 12606, 300, 659, 25111, 5633, 486, 360, 534, 731, 294, 5003, 9608, 13, 51594, 51594, 407, 257, 688, 295, 2132, 1936, 1709, 666, 14685, 613, 659, 25111, 9608, 293, 18114, 552, 51830, 51830], "temperature": 0.0, "avg_logprob": -0.1192341797224438, "compression_ratio": 1.960431654676259, "no_speech_prob": 1.0952464435831644e-05}, {"id": 942, "seek": 374504, "start": 3754.4, "end": 3757.24, "text": " and the transfer task are super aligned.", "tokens": [50364, 400, 550, 321, 362, 527, 5003, 9608, 11, 597, 366, 3256, 21538, 420, 17784, 13, 50600, 50600, 400, 309, 311, 534, 257, 688, 295, 3172, 906, 1953, 293, 257, 688, 295, 1454, 300, 264, 659, 12, 17227, 1760, 5633, 50832, 50832, 293, 264, 5003, 5633, 366, 1687, 17962, 13, 50974, 50974, 400, 456, 307, 572, 4467, 11, 534, 13, 51068, 51068, 467, 311, 257, 688, 295, 445, 30049, 534, 11, 534, 1152, 300, 2035, 659, 25111, 5633, 321, 600, 808, 51268, 51268, 493, 365, 307, 534, 731, 17962, 365, 527, 5003, 5633, 13, 51403, 51403, 400, 12606, 300, 659, 25111, 5633, 486, 360, 534, 731, 294, 5003, 9608, 13, 51594, 51594, 407, 257, 688, 295, 2132, 1936, 1709, 666, 14685, 613, 659, 25111, 9608, 293, 18114, 552, 51830, 51830], "temperature": 0.0, "avg_logprob": -0.1192341797224438, "compression_ratio": 1.960431654676259, "no_speech_prob": 1.0952464435831644e-05}, {"id": 943, "seek": 374504, "start": 3757.24, "end": 3759.12, "text": " And there is no evidence, really.", "tokens": [50364, 400, 550, 321, 362, 527, 5003, 9608, 11, 597, 366, 3256, 21538, 420, 17784, 13, 50600, 50600, 400, 309, 311, 534, 257, 688, 295, 3172, 906, 1953, 293, 257, 688, 295, 1454, 300, 264, 659, 12, 17227, 1760, 5633, 50832, 50832, 293, 264, 5003, 5633, 366, 1687, 17962, 13, 50974, 50974, 400, 456, 307, 572, 4467, 11, 534, 13, 51068, 51068, 467, 311, 257, 688, 295, 445, 30049, 534, 11, 534, 1152, 300, 2035, 659, 25111, 5633, 321, 600, 808, 51268, 51268, 493, 365, 307, 534, 731, 17962, 365, 527, 5003, 5633, 13, 51403, 51403, 400, 12606, 300, 659, 25111, 5633, 486, 360, 534, 731, 294, 5003, 9608, 13, 51594, 51594, 407, 257, 688, 295, 2132, 1936, 1709, 666, 14685, 613, 659, 25111, 9608, 293, 18114, 552, 51830, 51830], "temperature": 0.0, "avg_logprob": -0.1192341797224438, "compression_ratio": 1.960431654676259, "no_speech_prob": 1.0952464435831644e-05}, {"id": 944, "seek": 374504, "start": 3759.12, "end": 3763.12, "text": " It's a lot of just wishing really, really hard that whatever pretext task we've come", "tokens": [50364, 400, 550, 321, 362, 527, 5003, 9608, 11, 597, 366, 3256, 21538, 420, 17784, 13, 50600, 50600, 400, 309, 311, 534, 257, 688, 295, 3172, 906, 1953, 293, 257, 688, 295, 1454, 300, 264, 659, 12, 17227, 1760, 5633, 50832, 50832, 293, 264, 5003, 5633, 366, 1687, 17962, 13, 50974, 50974, 400, 456, 307, 572, 4467, 11, 534, 13, 51068, 51068, 467, 311, 257, 688, 295, 445, 30049, 534, 11, 534, 1152, 300, 2035, 659, 25111, 5633, 321, 600, 808, 51268, 51268, 493, 365, 307, 534, 731, 17962, 365, 527, 5003, 5633, 13, 51403, 51403, 400, 12606, 300, 659, 25111, 5633, 486, 360, 534, 731, 294, 5003, 9608, 13, 51594, 51594, 407, 257, 688, 295, 2132, 1936, 1709, 666, 14685, 613, 659, 25111, 9608, 293, 18114, 552, 51830, 51830], "temperature": 0.0, "avg_logprob": -0.1192341797224438, "compression_ratio": 1.960431654676259, "no_speech_prob": 1.0952464435831644e-05}, {"id": 945, "seek": 374504, "start": 3763.12, "end": 3765.82, "text": " up with is really well aligned with our transfer task.", "tokens": [50364, 400, 550, 321, 362, 527, 5003, 9608, 11, 597, 366, 3256, 21538, 420, 17784, 13, 50600, 50600, 400, 309, 311, 534, 257, 688, 295, 3172, 906, 1953, 293, 257, 688, 295, 1454, 300, 264, 659, 12, 17227, 1760, 5633, 50832, 50832, 293, 264, 5003, 5633, 366, 1687, 17962, 13, 50974, 50974, 400, 456, 307, 572, 4467, 11, 534, 13, 51068, 51068, 467, 311, 257, 688, 295, 445, 30049, 534, 11, 534, 1152, 300, 2035, 659, 25111, 5633, 321, 600, 808, 51268, 51268, 493, 365, 307, 534, 731, 17962, 365, 527, 5003, 5633, 13, 51403, 51403, 400, 12606, 300, 659, 25111, 5633, 486, 360, 534, 731, 294, 5003, 9608, 13, 51594, 51594, 407, 257, 688, 295, 2132, 1936, 1709, 666, 14685, 613, 659, 25111, 9608, 293, 18114, 552, 51830, 51830], "temperature": 0.0, "avg_logprob": -0.1192341797224438, "compression_ratio": 1.960431654676259, "no_speech_prob": 1.0952464435831644e-05}, {"id": 946, "seek": 374504, "start": 3765.82, "end": 3769.64, "text": " And solving that pretext task will do really well in transfer tasks.", "tokens": [50364, 400, 550, 321, 362, 527, 5003, 9608, 11, 597, 366, 3256, 21538, 420, 17784, 13, 50600, 50600, 400, 309, 311, 534, 257, 688, 295, 3172, 906, 1953, 293, 257, 688, 295, 1454, 300, 264, 659, 12, 17227, 1760, 5633, 50832, 50832, 293, 264, 5003, 5633, 366, 1687, 17962, 13, 50974, 50974, 400, 456, 307, 572, 4467, 11, 534, 13, 51068, 51068, 467, 311, 257, 688, 295, 445, 30049, 534, 11, 534, 1152, 300, 2035, 659, 25111, 5633, 321, 600, 808, 51268, 51268, 493, 365, 307, 534, 731, 17962, 365, 527, 5003, 5633, 13, 51403, 51403, 400, 12606, 300, 659, 25111, 5633, 486, 360, 534, 731, 294, 5003, 9608, 13, 51594, 51594, 407, 257, 688, 295, 2132, 1936, 1709, 666, 14685, 613, 659, 25111, 9608, 293, 18114, 552, 51830, 51830], "temperature": 0.0, "avg_logprob": -0.1192341797224438, "compression_ratio": 1.960431654676259, "no_speech_prob": 1.0952464435831644e-05}, {"id": 947, "seek": 374504, "start": 3769.64, "end": 3774.36, "text": " So a lot of research basically goes into designing these pretext tasks and implementing them", "tokens": [50364, 400, 550, 321, 362, 527, 5003, 9608, 11, 597, 366, 3256, 21538, 420, 17784, 13, 50600, 50600, 400, 309, 311, 534, 257, 688, 295, 3172, 906, 1953, 293, 257, 688, 295, 1454, 300, 264, 659, 12, 17227, 1760, 5633, 50832, 50832, 293, 264, 5003, 5633, 366, 1687, 17962, 13, 50974, 50974, 400, 456, 307, 572, 4467, 11, 534, 13, 51068, 51068, 467, 311, 257, 688, 295, 445, 30049, 534, 11, 534, 1152, 300, 2035, 659, 25111, 5633, 321, 600, 808, 51268, 51268, 493, 365, 307, 534, 731, 17962, 365, 527, 5003, 5633, 13, 51403, 51403, 400, 12606, 300, 659, 25111, 5633, 486, 360, 534, 731, 294, 5003, 9608, 13, 51594, 51594, 407, 257, 688, 295, 2132, 1936, 1709, 666, 14685, 613, 659, 25111, 9608, 293, 18114, 552, 51830, 51830], "temperature": 0.0, "avg_logprob": -0.1192341797224438, "compression_ratio": 1.960431654676259, "no_speech_prob": 1.0952464435831644e-05}, {"id": 948, "seek": 377436, "start": 3774.36, "end": 3777.04, "text": " really well.", "tokens": [50364, 534, 731, 13, 50498, 50498, 583, 309, 311, 406, 1850, 983, 12606, 746, 411, 361, 17156, 1607, 24138, 820, 2924, 505, 1340, 466, 50776, 50776, 4361, 45298, 420, 11, 337, 1365, 11, 754, 264, 1389, 295, 11, 584, 11, 5336, 46533, 2539, 11, 689, 291, 434, 51062, 51062, 1382, 281, 6069, 50016, 490, 364, 3256, 11, 309, 311, 406, 1850, 983, 32884, 50016, 295, 51280, 51280, 364, 3256, 307, 767, 516, 281, 360, 746, 731, 337, 2539, 257, 665, 1508, 9902, 322, 5003, 51606, 51606, 9608, 13, 51694, 51694], "temperature": 0.0, "avg_logprob": -0.1515378218430739, "compression_ratio": 1.6741071428571428, "no_speech_prob": 5.173829322302481e-06}, {"id": 949, "seek": 377436, "start": 3777.04, "end": 3782.6, "text": " But it's not clear why solving something like jigsaw puzzles should teach us anything about", "tokens": [50364, 534, 731, 13, 50498, 50498, 583, 309, 311, 406, 1850, 983, 12606, 746, 411, 361, 17156, 1607, 24138, 820, 2924, 505, 1340, 466, 50776, 50776, 4361, 45298, 420, 11, 337, 1365, 11, 754, 264, 1389, 295, 11, 584, 11, 5336, 46533, 2539, 11, 689, 291, 434, 51062, 51062, 1382, 281, 6069, 50016, 490, 364, 3256, 11, 309, 311, 406, 1850, 983, 32884, 50016, 295, 51280, 51280, 364, 3256, 307, 767, 516, 281, 360, 746, 731, 337, 2539, 257, 665, 1508, 9902, 322, 5003, 51606, 51606, 9608, 13, 51694, 51694], "temperature": 0.0, "avg_logprob": -0.1515378218430739, "compression_ratio": 1.6741071428571428, "no_speech_prob": 5.173829322302481e-06}, {"id": 950, "seek": 377436, "start": 3782.6, "end": 3788.32, "text": " semantics or, for example, even the case of, say, weak supervised learning, where you're", "tokens": [50364, 534, 731, 13, 50498, 50498, 583, 309, 311, 406, 1850, 983, 12606, 746, 411, 361, 17156, 1607, 24138, 820, 2924, 505, 1340, 466, 50776, 50776, 4361, 45298, 420, 11, 337, 1365, 11, 754, 264, 1389, 295, 11, 584, 11, 5336, 46533, 2539, 11, 689, 291, 434, 51062, 51062, 1382, 281, 6069, 50016, 490, 364, 3256, 11, 309, 311, 406, 1850, 983, 32884, 50016, 295, 51280, 51280, 364, 3256, 307, 767, 516, 281, 360, 746, 731, 337, 2539, 257, 665, 1508, 9902, 322, 5003, 51606, 51606, 9608, 13, 51694, 51694], "temperature": 0.0, "avg_logprob": -0.1515378218430739, "compression_ratio": 1.6741071428571428, "no_speech_prob": 5.173829322302481e-06}, {"id": 951, "seek": 377436, "start": 3788.32, "end": 3792.6800000000003, "text": " trying to predict hashtags from an image, it's not clear why predicting hashtags of", "tokens": [50364, 534, 731, 13, 50498, 50498, 583, 309, 311, 406, 1850, 983, 12606, 746, 411, 361, 17156, 1607, 24138, 820, 2924, 505, 1340, 466, 50776, 50776, 4361, 45298, 420, 11, 337, 1365, 11, 754, 264, 1389, 295, 11, 584, 11, 5336, 46533, 2539, 11, 689, 291, 434, 51062, 51062, 1382, 281, 6069, 50016, 490, 364, 3256, 11, 309, 311, 406, 1850, 983, 32884, 50016, 295, 51280, 51280, 364, 3256, 307, 767, 516, 281, 360, 746, 731, 337, 2539, 257, 665, 1508, 9902, 322, 5003, 51606, 51606, 9608, 13, 51694, 51694], "temperature": 0.0, "avg_logprob": -0.1515378218430739, "compression_ratio": 1.6741071428571428, "no_speech_prob": 5.173829322302481e-06}, {"id": 952, "seek": 377436, "start": 3792.6800000000003, "end": 3799.2000000000003, "text": " an image is actually going to do something well for learning a good classifier on transfer", "tokens": [50364, 534, 731, 13, 50498, 50498, 583, 309, 311, 406, 1850, 983, 12606, 746, 411, 361, 17156, 1607, 24138, 820, 2924, 505, 1340, 466, 50776, 50776, 4361, 45298, 420, 11, 337, 1365, 11, 754, 264, 1389, 295, 11, 584, 11, 5336, 46533, 2539, 11, 689, 291, 434, 51062, 51062, 1382, 281, 6069, 50016, 490, 364, 3256, 11, 309, 311, 406, 1850, 983, 32884, 50016, 295, 51280, 51280, 364, 3256, 307, 767, 516, 281, 360, 746, 731, 337, 2539, 257, 665, 1508, 9902, 322, 5003, 51606, 51606, 9608, 13, 51694, 51694], "temperature": 0.0, "avg_logprob": -0.1515378218430739, "compression_ratio": 1.6741071428571428, "no_speech_prob": 5.173829322302481e-06}, {"id": 953, "seek": 377436, "start": 3799.2000000000003, "end": 3800.96, "text": " tasks.", "tokens": [50364, 534, 731, 13, 50498, 50498, 583, 309, 311, 406, 1850, 983, 12606, 746, 411, 361, 17156, 1607, 24138, 820, 2924, 505, 1340, 466, 50776, 50776, 4361, 45298, 420, 11, 337, 1365, 11, 754, 264, 1389, 295, 11, 584, 11, 5336, 46533, 2539, 11, 689, 291, 434, 51062, 51062, 1382, 281, 6069, 50016, 490, 364, 3256, 11, 309, 311, 406, 1850, 983, 32884, 50016, 295, 51280, 51280, 364, 3256, 307, 767, 516, 281, 360, 746, 731, 337, 2539, 257, 665, 1508, 9902, 322, 5003, 51606, 51606, 9608, 13, 51694, 51694], "temperature": 0.0, "avg_logprob": -0.1515378218430739, "compression_ratio": 1.6741071428571428, "no_speech_prob": 5.173829322302481e-06}, {"id": 954, "seek": 380096, "start": 3800.96, "end": 3806.56, "text": " So this question remains that, how do you design good pre-training tasks which are well", "tokens": [50364, 407, 341, 1168, 7023, 300, 11, 577, 360, 291, 1715, 665, 659, 12, 17227, 1760, 9608, 597, 366, 731, 50644, 50644, 17962, 365, 428, 5003, 9608, 30, 50807, 50807, 407, 341, 1454, 295, 2674, 2144, 307, 1936, 291, 393, 11, 293, 264, 636, 321, 393, 1333, 295, 13059, 51188, 51188, 341, 307, 1936, 538, 1237, 412, 264, 10290, 300, 1184, 4583, 13, 51366, 51366, 400, 498, 264, 1036, 1064, 321, 360, 406, 536, 33358, 300, 366, 731, 17962, 365, 264, 5003, 5633, 11, 51652, 51652], "temperature": 0.0, "avg_logprob": -0.1708806575029746, "compression_ratio": 1.7772511848341233, "no_speech_prob": 1.4738230674993247e-05}, {"id": 955, "seek": 380096, "start": 3806.56, "end": 3809.82, "text": " aligned with your transfer tasks?", "tokens": [50364, 407, 341, 1168, 7023, 300, 11, 577, 360, 291, 1715, 665, 659, 12, 17227, 1760, 9608, 597, 366, 731, 50644, 50644, 17962, 365, 428, 5003, 9608, 30, 50807, 50807, 407, 341, 1454, 295, 2674, 2144, 307, 1936, 291, 393, 11, 293, 264, 636, 321, 393, 1333, 295, 13059, 51188, 51188, 341, 307, 1936, 538, 1237, 412, 264, 10290, 300, 1184, 4583, 13, 51366, 51366, 400, 498, 264, 1036, 1064, 321, 360, 406, 536, 33358, 300, 366, 731, 17962, 365, 264, 5003, 5633, 11, 51652, 51652], "temperature": 0.0, "avg_logprob": -0.1708806575029746, "compression_ratio": 1.7772511848341233, "no_speech_prob": 1.4738230674993247e-05}, {"id": 956, "seek": 380096, "start": 3809.82, "end": 3817.44, "text": " So this hope of generalization is basically you can, and the way we can sort of evaluate", "tokens": [50364, 407, 341, 1168, 7023, 300, 11, 577, 360, 291, 1715, 665, 659, 12, 17227, 1760, 9608, 597, 366, 731, 50644, 50644, 17962, 365, 428, 5003, 9608, 30, 50807, 50807, 407, 341, 1454, 295, 2674, 2144, 307, 1936, 291, 393, 11, 293, 264, 636, 321, 393, 1333, 295, 13059, 51188, 51188, 341, 307, 1936, 538, 1237, 412, 264, 10290, 300, 1184, 4583, 13, 51366, 51366, 400, 498, 264, 1036, 1064, 321, 360, 406, 536, 33358, 300, 366, 731, 17962, 365, 264, 5003, 5633, 11, 51652, 51652], "temperature": 0.0, "avg_logprob": -0.1708806575029746, "compression_ratio": 1.7772511848341233, "no_speech_prob": 1.4738230674993247e-05}, {"id": 957, "seek": 380096, "start": 3817.44, "end": 3821.0, "text": " this is basically by looking at the representation that each layer.", "tokens": [50364, 407, 341, 1168, 7023, 300, 11, 577, 360, 291, 1715, 665, 659, 12, 17227, 1760, 9608, 597, 366, 731, 50644, 50644, 17962, 365, 428, 5003, 9608, 30, 50807, 50807, 407, 341, 1454, 295, 2674, 2144, 307, 1936, 291, 393, 11, 293, 264, 636, 321, 393, 1333, 295, 13059, 51188, 51188, 341, 307, 1936, 538, 1237, 412, 264, 10290, 300, 1184, 4583, 13, 51366, 51366, 400, 498, 264, 1036, 1064, 321, 360, 406, 536, 33358, 300, 366, 731, 17962, 365, 264, 5003, 5633, 11, 51652, 51652], "temperature": 0.0, "avg_logprob": -0.1708806575029746, "compression_ratio": 1.7772511848341233, "no_speech_prob": 1.4738230674993247e-05}, {"id": 958, "seek": 380096, "start": 3821.0, "end": 3826.7200000000003, "text": " And if the last year we do not see representations that are well aligned with the transfer task,", "tokens": [50364, 407, 341, 1168, 7023, 300, 11, 577, 360, 291, 1715, 665, 659, 12, 17227, 1760, 9608, 597, 366, 731, 50644, 50644, 17962, 365, 428, 5003, 9608, 30, 50807, 50807, 407, 341, 1454, 295, 2674, 2144, 307, 1936, 291, 393, 11, 293, 264, 636, 321, 393, 1333, 295, 13059, 51188, 51188, 341, 307, 1936, 538, 1237, 412, 264, 10290, 300, 1184, 4583, 13, 51366, 51366, 400, 498, 264, 1036, 1064, 321, 360, 406, 536, 33358, 300, 366, 731, 17962, 365, 264, 5003, 5633, 11, 51652, 51652], "temperature": 0.0, "avg_logprob": -0.1708806575029746, "compression_ratio": 1.7772511848341233, "no_speech_prob": 1.4738230674993247e-05}, {"id": 959, "seek": 382672, "start": 3826.72, "end": 3830.9599999999996, "text": " then that is a red flag and that's sort of telling us that maybe this pre-training task", "tokens": [50364, 550, 300, 307, 257, 2182, 7166, 293, 300, 311, 1333, 295, 3585, 505, 300, 1310, 341, 659, 12, 17227, 1760, 5633, 50576, 50576, 307, 406, 534, 264, 558, 5633, 281, 5039, 13, 50780, 50780, 407, 411, 286, 2835, 3071, 11, 341, 1936, 307, 264, 1333, 295, 5102, 300, 321, 483, 337, 361, 17156, 1607, 13, 51024, 51024, 400, 341, 3110, 505, 300, 1391, 264, 1036, 924, 366, 588, 709, 19813, 3030, 264, 361, 17156, 1607, 51280, 51280, 1154, 13, 51466, 51466, 407, 294, 2674, 11, 437, 321, 534, 528, 490, 659, 12, 17227, 2001, 4122, 307, 300, 436, 820, 2906, 577, 51776, 51776], "temperature": 0.0, "avg_logprob": -0.11974779764811198, "compression_ratio": 1.699588477366255, "no_speech_prob": 3.844802449748386e-06}, {"id": 960, "seek": 382672, "start": 3830.9599999999996, "end": 3835.04, "text": " is not really the right task to solve.", "tokens": [50364, 550, 300, 307, 257, 2182, 7166, 293, 300, 311, 1333, 295, 3585, 505, 300, 1310, 341, 659, 12, 17227, 1760, 5633, 50576, 50576, 307, 406, 534, 264, 558, 5633, 281, 5039, 13, 50780, 50780, 407, 411, 286, 2835, 3071, 11, 341, 1936, 307, 264, 1333, 295, 5102, 300, 321, 483, 337, 361, 17156, 1607, 13, 51024, 51024, 400, 341, 3110, 505, 300, 1391, 264, 1036, 924, 366, 588, 709, 19813, 3030, 264, 361, 17156, 1607, 51280, 51280, 1154, 13, 51466, 51466, 407, 294, 2674, 11, 437, 321, 534, 528, 490, 659, 12, 17227, 2001, 4122, 307, 300, 436, 820, 2906, 577, 51776, 51776], "temperature": 0.0, "avg_logprob": -0.11974779764811198, "compression_ratio": 1.699588477366255, "no_speech_prob": 3.844802449748386e-06}, {"id": 961, "seek": 382672, "start": 3835.04, "end": 3839.9199999999996, "text": " So like I mentioned earlier, this basically is the sort of pattern that we get for jigsaw.", "tokens": [50364, 550, 300, 307, 257, 2182, 7166, 293, 300, 311, 1333, 295, 3585, 505, 300, 1310, 341, 659, 12, 17227, 1760, 5633, 50576, 50576, 307, 406, 534, 264, 558, 5633, 281, 5039, 13, 50780, 50780, 407, 411, 286, 2835, 3071, 11, 341, 1936, 307, 264, 1333, 295, 5102, 300, 321, 483, 337, 361, 17156, 1607, 13, 51024, 51024, 400, 341, 3110, 505, 300, 1391, 264, 1036, 924, 366, 588, 709, 19813, 3030, 264, 361, 17156, 1607, 51280, 51280, 1154, 13, 51466, 51466, 407, 294, 2674, 11, 437, 321, 534, 528, 490, 659, 12, 17227, 2001, 4122, 307, 300, 436, 820, 2906, 577, 51776, 51776], "temperature": 0.0, "avg_logprob": -0.11974779764811198, "compression_ratio": 1.699588477366255, "no_speech_prob": 3.844802449748386e-06}, {"id": 962, "seek": 382672, "start": 3839.9199999999996, "end": 3845.04, "text": " And this shows us that probably the last years are very much specialized towards the jigsaw", "tokens": [50364, 550, 300, 307, 257, 2182, 7166, 293, 300, 311, 1333, 295, 3585, 505, 300, 1310, 341, 659, 12, 17227, 1760, 5633, 50576, 50576, 307, 406, 534, 264, 558, 5633, 281, 5039, 13, 50780, 50780, 407, 411, 286, 2835, 3071, 11, 341, 1936, 307, 264, 1333, 295, 5102, 300, 321, 483, 337, 361, 17156, 1607, 13, 51024, 51024, 400, 341, 3110, 505, 300, 1391, 264, 1036, 924, 366, 588, 709, 19813, 3030, 264, 361, 17156, 1607, 51280, 51280, 1154, 13, 51466, 51466, 407, 294, 2674, 11, 437, 321, 534, 528, 490, 659, 12, 17227, 2001, 4122, 307, 300, 436, 820, 2906, 577, 51776, 51776], "temperature": 0.0, "avg_logprob": -0.11974779764811198, "compression_ratio": 1.699588477366255, "no_speech_prob": 3.844802449748386e-06}, {"id": 963, "seek": 382672, "start": 3845.04, "end": 3848.7599999999998, "text": " problem.", "tokens": [50364, 550, 300, 307, 257, 2182, 7166, 293, 300, 311, 1333, 295, 3585, 505, 300, 1310, 341, 659, 12, 17227, 1760, 5633, 50576, 50576, 307, 406, 534, 264, 558, 5633, 281, 5039, 13, 50780, 50780, 407, 411, 286, 2835, 3071, 11, 341, 1936, 307, 264, 1333, 295, 5102, 300, 321, 483, 337, 361, 17156, 1607, 13, 51024, 51024, 400, 341, 3110, 505, 300, 1391, 264, 1036, 924, 366, 588, 709, 19813, 3030, 264, 361, 17156, 1607, 51280, 51280, 1154, 13, 51466, 51466, 407, 294, 2674, 11, 437, 321, 534, 528, 490, 659, 12, 17227, 2001, 4122, 307, 300, 436, 820, 2906, 577, 51776, 51776], "temperature": 0.0, "avg_logprob": -0.11974779764811198, "compression_ratio": 1.699588477366255, "no_speech_prob": 3.844802449748386e-06}, {"id": 964, "seek": 382672, "start": 3848.7599999999998, "end": 3854.9599999999996, "text": " So in general, what we really want from pre-trained features is that they should represent how", "tokens": [50364, 550, 300, 307, 257, 2182, 7166, 293, 300, 311, 1333, 295, 3585, 505, 300, 1310, 341, 659, 12, 17227, 1760, 5633, 50576, 50576, 307, 406, 534, 264, 558, 5633, 281, 5039, 13, 50780, 50780, 407, 411, 286, 2835, 3071, 11, 341, 1936, 307, 264, 1333, 295, 5102, 300, 321, 483, 337, 361, 17156, 1607, 13, 51024, 51024, 400, 341, 3110, 505, 300, 1391, 264, 1036, 924, 366, 588, 709, 19813, 3030, 264, 361, 17156, 1607, 51280, 51280, 1154, 13, 51466, 51466, 407, 294, 2674, 11, 437, 321, 534, 528, 490, 659, 12, 17227, 2001, 4122, 307, 300, 436, 820, 2906, 577, 51776, 51776], "temperature": 0.0, "avg_logprob": -0.11974779764811198, "compression_ratio": 1.699588477366255, "no_speech_prob": 3.844802449748386e-06}, {"id": 965, "seek": 385496, "start": 3854.96, "end": 3856.92, "text": " images are related to one another.", "tokens": [50364, 5267, 366, 4077, 281, 472, 1071, 13, 50462, 50462, 407, 4111, 10290, 820, 11, 293, 341, 1936, 1709, 646, 281, 584, 264, 23831, 5987, 50716, 50716, 5056, 14455, 300, 286, 632, 13, 50782, 50782, 814, 820, 534, 312, 1075, 281, 1594, 1214, 5267, 300, 366, 4361, 49505, 4077, 294, 512, 51034, 51034, 636, 13, 51084, 51084, 400, 264, 1150, 4707, 307, 1936, 257, 4707, 300, 575, 668, 264, 34889, 295, 14685, 5201, 51408, 51408, 4122, 13, 51458, 51458, 407, 754, 949, 584, 264, 2452, 2539, 4122, 366, 3743, 11, 264, 1011, 5611, 292, 4122, 645, 51664, 51664], "temperature": 0.0, "avg_logprob": -0.14008730108087714, "compression_ratio": 1.7710843373493976, "no_speech_prob": 1.0451130037836265e-05}, {"id": 966, "seek": 385496, "start": 3856.92, "end": 3862.0, "text": " So feature representation should, and this basically goes back to say the nearest neighbor", "tokens": [50364, 5267, 366, 4077, 281, 472, 1071, 13, 50462, 50462, 407, 4111, 10290, 820, 11, 293, 341, 1936, 1709, 646, 281, 584, 264, 23831, 5987, 50716, 50716, 5056, 14455, 300, 286, 632, 13, 50782, 50782, 814, 820, 534, 312, 1075, 281, 1594, 1214, 5267, 300, 366, 4361, 49505, 4077, 294, 512, 51034, 51034, 636, 13, 51084, 51084, 400, 264, 1150, 4707, 307, 1936, 257, 4707, 300, 575, 668, 264, 34889, 295, 14685, 5201, 51408, 51408, 4122, 13, 51458, 51458, 407, 754, 949, 584, 264, 2452, 2539, 4122, 366, 3743, 11, 264, 1011, 5611, 292, 4122, 645, 51664, 51664], "temperature": 0.0, "avg_logprob": -0.14008730108087714, "compression_ratio": 1.7710843373493976, "no_speech_prob": 1.0451130037836265e-05}, {"id": 967, "seek": 385496, "start": 3862.0, "end": 3863.32, "text": " visualizations that I had.", "tokens": [50364, 5267, 366, 4077, 281, 472, 1071, 13, 50462, 50462, 407, 4111, 10290, 820, 11, 293, 341, 1936, 1709, 646, 281, 584, 264, 23831, 5987, 50716, 50716, 5056, 14455, 300, 286, 632, 13, 50782, 50782, 814, 820, 534, 312, 1075, 281, 1594, 1214, 5267, 300, 366, 4361, 49505, 4077, 294, 512, 51034, 51034, 636, 13, 51084, 51084, 400, 264, 1150, 4707, 307, 1936, 257, 4707, 300, 575, 668, 264, 34889, 295, 14685, 5201, 51408, 51408, 4122, 13, 51458, 51458, 407, 754, 949, 584, 264, 2452, 2539, 4122, 366, 3743, 11, 264, 1011, 5611, 292, 4122, 645, 51664, 51664], "temperature": 0.0, "avg_logprob": -0.14008730108087714, "compression_ratio": 1.7710843373493976, "no_speech_prob": 1.0451130037836265e-05}, {"id": 968, "seek": 385496, "start": 3863.32, "end": 3868.36, "text": " They should really be able to group together images that are semantically related in some", "tokens": [50364, 5267, 366, 4077, 281, 472, 1071, 13, 50462, 50462, 407, 4111, 10290, 820, 11, 293, 341, 1936, 1709, 646, 281, 584, 264, 23831, 5987, 50716, 50716, 5056, 14455, 300, 286, 632, 13, 50782, 50782, 814, 820, 534, 312, 1075, 281, 1594, 1214, 5267, 300, 366, 4361, 49505, 4077, 294, 512, 51034, 51034, 636, 13, 51084, 51084, 400, 264, 1150, 4707, 307, 1936, 257, 4707, 300, 575, 668, 264, 34889, 295, 14685, 5201, 51408, 51408, 4122, 13, 51458, 51458, 407, 754, 949, 584, 264, 2452, 2539, 4122, 366, 3743, 11, 264, 1011, 5611, 292, 4122, 645, 51664, 51664], "temperature": 0.0, "avg_logprob": -0.14008730108087714, "compression_ratio": 1.7710843373493976, "no_speech_prob": 1.0451130037836265e-05}, {"id": 969, "seek": 385496, "start": 3868.36, "end": 3869.36, "text": " way.", "tokens": [50364, 5267, 366, 4077, 281, 472, 1071, 13, 50462, 50462, 407, 4111, 10290, 820, 11, 293, 341, 1936, 1709, 646, 281, 584, 264, 23831, 5987, 50716, 50716, 5056, 14455, 300, 286, 632, 13, 50782, 50782, 814, 820, 534, 312, 1075, 281, 1594, 1214, 5267, 300, 366, 4361, 49505, 4077, 294, 512, 51034, 51034, 636, 13, 51084, 51084, 400, 264, 1150, 4707, 307, 1936, 257, 4707, 300, 575, 668, 264, 34889, 295, 14685, 5201, 51408, 51408, 4122, 13, 51458, 51458, 407, 754, 949, 584, 264, 2452, 2539, 4122, 366, 3743, 11, 264, 1011, 5611, 292, 4122, 645, 51664, 51664], "temperature": 0.0, "avg_logprob": -0.14008730108087714, "compression_ratio": 1.7710843373493976, "no_speech_prob": 1.0451130037836265e-05}, {"id": 970, "seek": 385496, "start": 3869.36, "end": 3875.84, "text": " And the second property is basically a property that has been the backbone of designing vision", "tokens": [50364, 5267, 366, 4077, 281, 472, 1071, 13, 50462, 50462, 407, 4111, 10290, 820, 11, 293, 341, 1936, 1709, 646, 281, 584, 264, 23831, 5987, 50716, 50716, 5056, 14455, 300, 286, 632, 13, 50782, 50782, 814, 820, 534, 312, 1075, 281, 1594, 1214, 5267, 300, 366, 4361, 49505, 4077, 294, 512, 51034, 51034, 636, 13, 51084, 51084, 400, 264, 1150, 4707, 307, 1936, 257, 4707, 300, 575, 668, 264, 34889, 295, 14685, 5201, 51408, 51408, 4122, 13, 51458, 51458, 407, 754, 949, 584, 264, 2452, 2539, 4122, 366, 3743, 11, 264, 1011, 5611, 292, 4122, 645, 51664, 51664], "temperature": 0.0, "avg_logprob": -0.14008730108087714, "compression_ratio": 1.7710843373493976, "no_speech_prob": 1.0451130037836265e-05}, {"id": 971, "seek": 385496, "start": 3875.84, "end": 3876.84, "text": " features.", "tokens": [50364, 5267, 366, 4077, 281, 472, 1071, 13, 50462, 50462, 407, 4111, 10290, 820, 11, 293, 341, 1936, 1709, 646, 281, 584, 264, 23831, 5987, 50716, 50716, 5056, 14455, 300, 286, 632, 13, 50782, 50782, 814, 820, 534, 312, 1075, 281, 1594, 1214, 5267, 300, 366, 4361, 49505, 4077, 294, 512, 51034, 51034, 636, 13, 51084, 51084, 400, 264, 1150, 4707, 307, 1936, 257, 4707, 300, 575, 668, 264, 34889, 295, 14685, 5201, 51408, 51408, 4122, 13, 51458, 51458, 407, 754, 949, 584, 264, 2452, 2539, 4122, 366, 3743, 11, 264, 1011, 5611, 292, 4122, 645, 51664, 51664], "temperature": 0.0, "avg_logprob": -0.14008730108087714, "compression_ratio": 1.7710843373493976, "no_speech_prob": 1.0451130037836265e-05}, {"id": 972, "seek": 385496, "start": 3876.84, "end": 3880.96, "text": " So even before say the deep learning features are popular, the handcrafted features were", "tokens": [50364, 5267, 366, 4077, 281, 472, 1071, 13, 50462, 50462, 407, 4111, 10290, 820, 11, 293, 341, 1936, 1709, 646, 281, 584, 264, 23831, 5987, 50716, 50716, 5056, 14455, 300, 286, 632, 13, 50782, 50782, 814, 820, 534, 312, 1075, 281, 1594, 1214, 5267, 300, 366, 4361, 49505, 4077, 294, 512, 51034, 51034, 636, 13, 51084, 51084, 400, 264, 1150, 4707, 307, 1936, 257, 4707, 300, 575, 668, 264, 34889, 295, 14685, 5201, 51408, 51408, 4122, 13, 51458, 51458, 407, 754, 949, 584, 264, 2452, 2539, 4122, 366, 3743, 11, 264, 1011, 5611, 292, 4122, 645, 51664, 51664], "temperature": 0.0, "avg_logprob": -0.14008730108087714, "compression_ratio": 1.7710843373493976, "no_speech_prob": 1.0451130037836265e-05}, {"id": 973, "seek": 388096, "start": 3880.96, "end": 3885.52, "text": " always all about invariance, about sort of being invariant to things like lighting or", "tokens": [50364, 1009, 439, 466, 33270, 719, 11, 466, 1333, 295, 885, 33270, 394, 281, 721, 411, 9577, 420, 50592, 50592, 721, 411, 1900, 2017, 420, 1900, 4914, 13, 50752, 50752, 407, 613, 366, 264, 732, 7221, 300, 321, 534, 528, 294, 527, 659, 12, 17227, 2001, 4122, 13, 51046, 51046, 400, 456, 366, 1333, 295, 732, 2098, 295, 19626, 613, 721, 13, 51240, 51240, 1485, 307, 596, 48673, 293, 264, 661, 307, 8712, 488, 2539, 13, 51416, 51416, 400, 1293, 613, 7150, 362, 10768, 570, 436, 366, 534, 12606, 11, 436, 434, 1936, 51688, 51688], "temperature": 0.0, "avg_logprob": -0.12918253739674887, "compression_ratio": 1.7457627118644068, "no_speech_prob": 8.139488272718154e-06}, {"id": 974, "seek": 388096, "start": 3885.52, "end": 3888.7200000000003, "text": " things like exact color or exact location.", "tokens": [50364, 1009, 439, 466, 33270, 719, 11, 466, 1333, 295, 885, 33270, 394, 281, 721, 411, 9577, 420, 50592, 50592, 721, 411, 1900, 2017, 420, 1900, 4914, 13, 50752, 50752, 407, 613, 366, 264, 732, 7221, 300, 321, 534, 528, 294, 527, 659, 12, 17227, 2001, 4122, 13, 51046, 51046, 400, 456, 366, 1333, 295, 732, 2098, 295, 19626, 613, 721, 13, 51240, 51240, 1485, 307, 596, 48673, 293, 264, 661, 307, 8712, 488, 2539, 13, 51416, 51416, 400, 1293, 613, 7150, 362, 10768, 570, 436, 366, 534, 12606, 11, 436, 434, 1936, 51688, 51688], "temperature": 0.0, "avg_logprob": -0.12918253739674887, "compression_ratio": 1.7457627118644068, "no_speech_prob": 8.139488272718154e-06}, {"id": 975, "seek": 388096, "start": 3888.7200000000003, "end": 3894.6, "text": " So these are the two properties that we really want in our pre-trained features.", "tokens": [50364, 1009, 439, 466, 33270, 719, 11, 466, 1333, 295, 885, 33270, 394, 281, 721, 411, 9577, 420, 50592, 50592, 721, 411, 1900, 2017, 420, 1900, 4914, 13, 50752, 50752, 407, 613, 366, 264, 732, 7221, 300, 321, 534, 528, 294, 527, 659, 12, 17227, 2001, 4122, 13, 51046, 51046, 400, 456, 366, 1333, 295, 732, 2098, 295, 19626, 613, 721, 13, 51240, 51240, 1485, 307, 596, 48673, 293, 264, 661, 307, 8712, 488, 2539, 13, 51416, 51416, 400, 1293, 613, 7150, 362, 10768, 570, 436, 366, 534, 12606, 11, 436, 434, 1936, 51688, 51688], "temperature": 0.0, "avg_logprob": -0.12918253739674887, "compression_ratio": 1.7457627118644068, "no_speech_prob": 8.139488272718154e-06}, {"id": 976, "seek": 388096, "start": 3894.6, "end": 3898.48, "text": " And there are sort of two ways of achieving these things.", "tokens": [50364, 1009, 439, 466, 33270, 719, 11, 466, 1333, 295, 885, 33270, 394, 281, 721, 411, 9577, 420, 50592, 50592, 721, 411, 1900, 2017, 420, 1900, 4914, 13, 50752, 50752, 407, 613, 366, 264, 732, 7221, 300, 321, 534, 528, 294, 527, 659, 12, 17227, 2001, 4122, 13, 51046, 51046, 400, 456, 366, 1333, 295, 732, 2098, 295, 19626, 613, 721, 13, 51240, 51240, 1485, 307, 596, 48673, 293, 264, 661, 307, 8712, 488, 2539, 13, 51416, 51416, 400, 1293, 613, 7150, 362, 10768, 570, 436, 366, 534, 12606, 11, 436, 434, 1936, 51688, 51688], "temperature": 0.0, "avg_logprob": -0.12918253739674887, "compression_ratio": 1.7457627118644068, "no_speech_prob": 8.139488272718154e-06}, {"id": 977, "seek": 388096, "start": 3898.48, "end": 3902.0, "text": " One is clustering and the other is contrastive learning.", "tokens": [50364, 1009, 439, 466, 33270, 719, 11, 466, 1333, 295, 885, 33270, 394, 281, 721, 411, 9577, 420, 50592, 50592, 721, 411, 1900, 2017, 420, 1900, 4914, 13, 50752, 50752, 407, 613, 366, 264, 732, 7221, 300, 321, 534, 528, 294, 527, 659, 12, 17227, 2001, 4122, 13, 51046, 51046, 400, 456, 366, 1333, 295, 732, 2098, 295, 19626, 613, 721, 13, 51240, 51240, 1485, 307, 596, 48673, 293, 264, 661, 307, 8712, 488, 2539, 13, 51416, 51416, 400, 1293, 613, 7150, 362, 10768, 570, 436, 366, 534, 12606, 11, 436, 434, 1936, 51688, 51688], "temperature": 0.0, "avg_logprob": -0.12918253739674887, "compression_ratio": 1.7457627118644068, "no_speech_prob": 8.139488272718154e-06}, {"id": 978, "seek": 388096, "start": 3902.0, "end": 3907.44, "text": " And both these methods have promised because they are really solving, they're basically", "tokens": [50364, 1009, 439, 466, 33270, 719, 11, 466, 1333, 295, 885, 33270, 394, 281, 721, 411, 9577, 420, 50592, 50592, 721, 411, 1900, 2017, 420, 1900, 4914, 13, 50752, 50752, 407, 613, 366, 264, 732, 7221, 300, 321, 534, 528, 294, 527, 659, 12, 17227, 2001, 4122, 13, 51046, 51046, 400, 456, 366, 1333, 295, 732, 2098, 295, 19626, 613, 721, 13, 51240, 51240, 1485, 307, 596, 48673, 293, 264, 661, 307, 8712, 488, 2539, 13, 51416, 51416, 400, 1293, 613, 7150, 362, 10768, 570, 436, 366, 534, 12606, 11, 436, 434, 1936, 51688, 51688], "temperature": 0.0, "avg_logprob": -0.12918253739674887, "compression_ratio": 1.7457627118644068, "no_speech_prob": 8.139488272718154e-06}, {"id": 979, "seek": 390744, "start": 3907.44, "end": 3913.56, "text": " trying to get these properties when they're sort of trying to learn representations.", "tokens": [50364, 1382, 281, 483, 613, 7221, 562, 436, 434, 1333, 295, 1382, 281, 1466, 33358, 13, 50670, 50670, 400, 286, 1697, 300, 311, 983, 436, 600, 767, 586, 1409, 10205, 370, 709, 1101, 813, 50884, 50884, 2035, 659, 25111, 9608, 300, 645, 1011, 4761, 337, 370, 1400, 13, 51102, 51102, 407, 586, 286, 1333, 295, 1879, 322, 732, 5162, 1985, 300, 321, 362, 11, 597, 366, 11, 597, 2100, 666, 341, 51428, 51428, 13058, 295, 596, 48673, 293, 1048, 10652, 887, 13, 51576, 51576, 407, 472, 307, 1219, 13630, 3318, 11, 264, 661, 307, 1219, 3026, 75, 11, 293, 1293, 295, 552, 486, 312, 8212, 51766, 51766], "temperature": 0.0, "avg_logprob": -0.1499262915717231, "compression_ratio": 1.6830188679245284, "no_speech_prob": 7.411027581838425e-06}, {"id": 980, "seek": 390744, "start": 3913.56, "end": 3917.84, "text": " And I believe that's why they've actually now started performing so much better than", "tokens": [50364, 1382, 281, 483, 613, 7221, 562, 436, 434, 1333, 295, 1382, 281, 1466, 33358, 13, 50670, 50670, 400, 286, 1697, 300, 311, 983, 436, 600, 767, 586, 1409, 10205, 370, 709, 1101, 813, 50884, 50884, 2035, 659, 25111, 9608, 300, 645, 1011, 4761, 337, 370, 1400, 13, 51102, 51102, 407, 586, 286, 1333, 295, 1879, 322, 732, 5162, 1985, 300, 321, 362, 11, 597, 366, 11, 597, 2100, 666, 341, 51428, 51428, 13058, 295, 596, 48673, 293, 1048, 10652, 887, 13, 51576, 51576, 407, 472, 307, 1219, 13630, 3318, 11, 264, 661, 307, 1219, 3026, 75, 11, 293, 1293, 295, 552, 486, 312, 8212, 51766, 51766], "temperature": 0.0, "avg_logprob": -0.1499262915717231, "compression_ratio": 1.6830188679245284, "no_speech_prob": 7.411027581838425e-06}, {"id": 981, "seek": 390744, "start": 3917.84, "end": 3922.2000000000003, "text": " whatever pretext tasks that were hand designed for so far.", "tokens": [50364, 1382, 281, 483, 613, 7221, 562, 436, 434, 1333, 295, 1382, 281, 1466, 33358, 13, 50670, 50670, 400, 286, 1697, 300, 311, 983, 436, 600, 767, 586, 1409, 10205, 370, 709, 1101, 813, 50884, 50884, 2035, 659, 25111, 9608, 300, 645, 1011, 4761, 337, 370, 1400, 13, 51102, 51102, 407, 586, 286, 1333, 295, 1879, 322, 732, 5162, 1985, 300, 321, 362, 11, 597, 366, 11, 597, 2100, 666, 341, 51428, 51428, 13058, 295, 596, 48673, 293, 1048, 10652, 887, 13, 51576, 51576, 407, 472, 307, 1219, 13630, 3318, 11, 264, 661, 307, 1219, 3026, 75, 11, 293, 1293, 295, 552, 486, 312, 8212, 51766, 51766], "temperature": 0.0, "avg_logprob": -0.1499262915717231, "compression_ratio": 1.6830188679245284, "no_speech_prob": 7.411027581838425e-06}, {"id": 982, "seek": 390744, "start": 3922.2000000000003, "end": 3928.7200000000003, "text": " So now I sort of focus on two recent works that we have, which are, which fall into this", "tokens": [50364, 1382, 281, 483, 613, 7221, 562, 436, 434, 1333, 295, 1382, 281, 1466, 33358, 13, 50670, 50670, 400, 286, 1697, 300, 311, 983, 436, 600, 767, 586, 1409, 10205, 370, 709, 1101, 813, 50884, 50884, 2035, 659, 25111, 9608, 300, 645, 1011, 4761, 337, 370, 1400, 13, 51102, 51102, 407, 586, 286, 1333, 295, 1879, 322, 732, 5162, 1985, 300, 321, 362, 11, 597, 366, 11, 597, 2100, 666, 341, 51428, 51428, 13058, 295, 596, 48673, 293, 1048, 10652, 887, 13, 51576, 51576, 407, 472, 307, 1219, 13630, 3318, 11, 264, 661, 307, 1219, 3026, 75, 11, 293, 1293, 295, 552, 486, 312, 8212, 51766, 51766], "temperature": 0.0, "avg_logprob": -0.1499262915717231, "compression_ratio": 1.6830188679245284, "no_speech_prob": 7.411027581838425e-06}, {"id": 983, "seek": 390744, "start": 3928.7200000000003, "end": 3931.68, "text": " bucket of clustering and invariances.", "tokens": [50364, 1382, 281, 483, 613, 7221, 562, 436, 434, 1333, 295, 1382, 281, 1466, 33358, 13, 50670, 50670, 400, 286, 1697, 300, 311, 983, 436, 600, 767, 586, 1409, 10205, 370, 709, 1101, 813, 50884, 50884, 2035, 659, 25111, 9608, 300, 645, 1011, 4761, 337, 370, 1400, 13, 51102, 51102, 407, 586, 286, 1333, 295, 1879, 322, 732, 5162, 1985, 300, 321, 362, 11, 597, 366, 11, 597, 2100, 666, 341, 51428, 51428, 13058, 295, 596, 48673, 293, 1048, 10652, 887, 13, 51576, 51576, 407, 472, 307, 1219, 13630, 3318, 11, 264, 661, 307, 1219, 3026, 75, 11, 293, 1293, 295, 552, 486, 312, 8212, 51766, 51766], "temperature": 0.0, "avg_logprob": -0.1499262915717231, "compression_ratio": 1.6830188679245284, "no_speech_prob": 7.411027581838425e-06}, {"id": 984, "seek": 390744, "start": 3931.68, "end": 3935.48, "text": " So one is called cluster fit, the other is called Perl, and both of them will be presented", "tokens": [50364, 1382, 281, 483, 613, 7221, 562, 436, 434, 1333, 295, 1382, 281, 1466, 33358, 13, 50670, 50670, 400, 286, 1697, 300, 311, 983, 436, 600, 767, 586, 1409, 10205, 370, 709, 1101, 813, 50884, 50884, 2035, 659, 25111, 9608, 300, 645, 1011, 4761, 337, 370, 1400, 13, 51102, 51102, 407, 586, 286, 1333, 295, 1879, 322, 732, 5162, 1985, 300, 321, 362, 11, 597, 366, 11, 597, 2100, 666, 341, 51428, 51428, 13058, 295, 596, 48673, 293, 1048, 10652, 887, 13, 51576, 51576, 407, 472, 307, 1219, 13630, 3318, 11, 264, 661, 307, 1219, 3026, 75, 11, 293, 1293, 295, 552, 486, 312, 8212, 51766, 51766], "temperature": 0.0, "avg_logprob": -0.1499262915717231, "compression_ratio": 1.6830188679245284, "no_speech_prob": 7.411027581838425e-06}, {"id": 985, "seek": 393548, "start": 3935.48, "end": 3939.04, "text": " at CVPR this year.", "tokens": [50364, 412, 22995, 15958, 341, 1064, 13, 50542, 50542, 407, 264, 700, 589, 307, 13630, 3318, 13, 50686, 50686, 467, 311, 257, 3170, 597, 321, 519, 307, 588, 665, 281, 3470, 2674, 2144, 295, 5056, 33358, 13, 51033, 51033, 407, 596, 48673, 307, 1936, 257, 665, 636, 281, 1223, 437, 5267, 366, 41877, 1214, 11, 437, 5267, 51380, 51380, 352, 1214, 293, 437, 5267, 360, 406, 352, 1214, 13, 51548, 51548, 400, 309, 311, 1333, 295, 11, 538, 1936, 10205, 596, 48673, 322, 264, 4111, 1901, 11, 291, 393, 483, 51796, 51796], "temperature": 0.0, "avg_logprob": -0.12174027965914819, "compression_ratio": 1.6888888888888889, "no_speech_prob": 5.771752057626145e-06}, {"id": 986, "seek": 393548, "start": 3939.04, "end": 3941.92, "text": " So the first work is cluster fit.", "tokens": [50364, 412, 22995, 15958, 341, 1064, 13, 50542, 50542, 407, 264, 700, 589, 307, 13630, 3318, 13, 50686, 50686, 467, 311, 257, 3170, 597, 321, 519, 307, 588, 665, 281, 3470, 2674, 2144, 295, 5056, 33358, 13, 51033, 51033, 407, 596, 48673, 307, 1936, 257, 665, 636, 281, 1223, 437, 5267, 366, 41877, 1214, 11, 437, 5267, 51380, 51380, 352, 1214, 293, 437, 5267, 360, 406, 352, 1214, 13, 51548, 51548, 400, 309, 311, 1333, 295, 11, 538, 1936, 10205, 596, 48673, 322, 264, 4111, 1901, 11, 291, 393, 483, 51796, 51796], "temperature": 0.0, "avg_logprob": -0.12174027965914819, "compression_ratio": 1.6888888888888889, "no_speech_prob": 5.771752057626145e-06}, {"id": 987, "seek": 393548, "start": 3941.92, "end": 3948.86, "text": " It's a method which we think is very good to improve generalization of visual representations.", "tokens": [50364, 412, 22995, 15958, 341, 1064, 13, 50542, 50542, 407, 264, 700, 589, 307, 13630, 3318, 13, 50686, 50686, 467, 311, 257, 3170, 597, 321, 519, 307, 588, 665, 281, 3470, 2674, 2144, 295, 5056, 33358, 13, 51033, 51033, 407, 596, 48673, 307, 1936, 257, 665, 636, 281, 1223, 437, 5267, 366, 41877, 1214, 11, 437, 5267, 51380, 51380, 352, 1214, 293, 437, 5267, 360, 406, 352, 1214, 13, 51548, 51548, 400, 309, 311, 1333, 295, 11, 538, 1936, 10205, 596, 48673, 322, 264, 4111, 1901, 11, 291, 393, 483, 51796, 51796], "temperature": 0.0, "avg_logprob": -0.12174027965914819, "compression_ratio": 1.6888888888888889, "no_speech_prob": 5.771752057626145e-06}, {"id": 988, "seek": 393548, "start": 3948.86, "end": 3955.8, "text": " So clustering is basically a good way to understand what images are grouped together, what images", "tokens": [50364, 412, 22995, 15958, 341, 1064, 13, 50542, 50542, 407, 264, 700, 589, 307, 13630, 3318, 13, 50686, 50686, 467, 311, 257, 3170, 597, 321, 519, 307, 588, 665, 281, 3470, 2674, 2144, 295, 5056, 33358, 13, 51033, 51033, 407, 596, 48673, 307, 1936, 257, 665, 636, 281, 1223, 437, 5267, 366, 41877, 1214, 11, 437, 5267, 51380, 51380, 352, 1214, 293, 437, 5267, 360, 406, 352, 1214, 13, 51548, 51548, 400, 309, 311, 1333, 295, 11, 538, 1936, 10205, 596, 48673, 322, 264, 4111, 1901, 11, 291, 393, 483, 51796, 51796], "temperature": 0.0, "avg_logprob": -0.12174027965914819, "compression_ratio": 1.6888888888888889, "no_speech_prob": 5.771752057626145e-06}, {"id": 989, "seek": 393548, "start": 3955.8, "end": 3959.16, "text": " go together and what images do not go together.", "tokens": [50364, 412, 22995, 15958, 341, 1064, 13, 50542, 50542, 407, 264, 700, 589, 307, 13630, 3318, 13, 50686, 50686, 467, 311, 257, 3170, 597, 321, 519, 307, 588, 665, 281, 3470, 2674, 2144, 295, 5056, 33358, 13, 51033, 51033, 407, 596, 48673, 307, 1936, 257, 665, 636, 281, 1223, 437, 5267, 366, 41877, 1214, 11, 437, 5267, 51380, 51380, 352, 1214, 293, 437, 5267, 360, 406, 352, 1214, 13, 51548, 51548, 400, 309, 311, 1333, 295, 11, 538, 1936, 10205, 596, 48673, 322, 264, 4111, 1901, 11, 291, 393, 483, 51796, 51796], "temperature": 0.0, "avg_logprob": -0.12174027965914819, "compression_ratio": 1.6888888888888889, "no_speech_prob": 5.771752057626145e-06}, {"id": 990, "seek": 393548, "start": 3959.16, "end": 3964.12, "text": " And it's sort of, by basically performing clustering on the feature space, you can get", "tokens": [50364, 412, 22995, 15958, 341, 1064, 13, 50542, 50542, 407, 264, 700, 589, 307, 13630, 3318, 13, 50686, 50686, 467, 311, 257, 3170, 597, 321, 519, 307, 588, 665, 281, 3470, 2674, 2144, 295, 5056, 33358, 13, 51033, 51033, 407, 596, 48673, 307, 1936, 257, 665, 636, 281, 1223, 437, 5267, 366, 41877, 1214, 11, 437, 5267, 51380, 51380, 352, 1214, 293, 437, 5267, 360, 406, 352, 1214, 13, 51548, 51548, 400, 309, 311, 1333, 295, 11, 538, 1936, 10205, 596, 48673, 322, 264, 4111, 1901, 11, 291, 393, 483, 51796, 51796], "temperature": 0.0, "avg_logprob": -0.12174027965914819, "compression_ratio": 1.6888888888888889, "no_speech_prob": 5.771752057626145e-06}, {"id": 991, "seek": 396412, "start": 3964.12, "end": 3970.24, "text": " these nice buckets of images that are related and images that are not related.", "tokens": [50364, 613, 1481, 32191, 295, 5267, 300, 366, 4077, 293, 5267, 300, 366, 406, 4077, 13, 50670, 50670, 407, 264, 2135, 1558, 295, 341, 3035, 307, 4664, 2199, 13, 50836, 50836, 821, 366, 445, 732, 4439, 13, 50947, 50947, 1485, 307, 264, 13630, 1823, 11, 264, 661, 307, 264, 6069, 1823, 13, 51117, 51117, 407, 437, 321, 360, 307, 321, 747, 257, 659, 12, 17227, 2001, 3209, 293, 341, 393, 312, 604, 659, 12, 17227, 2001, 3209, 13, 51402, 51402, 467, 775, 406, 534, 362, 281, 312, 445, 257, 2698, 46533, 3209, 13, 51548, 51548, 467, 393, 2139, 312, 3256, 659, 12, 17227, 2001, 3209, 420, 257, 3209, 659, 12, 17227, 2001, 11, 584, 1228, 50016, 51794, 51794], "temperature": 0.0, "avg_logprob": -0.13843858542562532, "compression_ratio": 1.8987341772151898, "no_speech_prob": 7.888856089266483e-06}, {"id": 992, "seek": 396412, "start": 3970.24, "end": 3973.56, "text": " So the main idea of this paper is extremely simple.", "tokens": [50364, 613, 1481, 32191, 295, 5267, 300, 366, 4077, 293, 5267, 300, 366, 406, 4077, 13, 50670, 50670, 407, 264, 2135, 1558, 295, 341, 3035, 307, 4664, 2199, 13, 50836, 50836, 821, 366, 445, 732, 4439, 13, 50947, 50947, 1485, 307, 264, 13630, 1823, 11, 264, 661, 307, 264, 6069, 1823, 13, 51117, 51117, 407, 437, 321, 360, 307, 321, 747, 257, 659, 12, 17227, 2001, 3209, 293, 341, 393, 312, 604, 659, 12, 17227, 2001, 3209, 13, 51402, 51402, 467, 775, 406, 534, 362, 281, 312, 445, 257, 2698, 46533, 3209, 13, 51548, 51548, 467, 393, 2139, 312, 3256, 659, 12, 17227, 2001, 3209, 420, 257, 3209, 659, 12, 17227, 2001, 11, 584, 1228, 50016, 51794, 51794], "temperature": 0.0, "avg_logprob": -0.13843858542562532, "compression_ratio": 1.8987341772151898, "no_speech_prob": 7.888856089266483e-06}, {"id": 993, "seek": 396412, "start": 3973.56, "end": 3975.7799999999997, "text": " There are just two steps.", "tokens": [50364, 613, 1481, 32191, 295, 5267, 300, 366, 4077, 293, 5267, 300, 366, 406, 4077, 13, 50670, 50670, 407, 264, 2135, 1558, 295, 341, 3035, 307, 4664, 2199, 13, 50836, 50836, 821, 366, 445, 732, 4439, 13, 50947, 50947, 1485, 307, 264, 13630, 1823, 11, 264, 661, 307, 264, 6069, 1823, 13, 51117, 51117, 407, 437, 321, 360, 307, 321, 747, 257, 659, 12, 17227, 2001, 3209, 293, 341, 393, 312, 604, 659, 12, 17227, 2001, 3209, 13, 51402, 51402, 467, 775, 406, 534, 362, 281, 312, 445, 257, 2698, 46533, 3209, 13, 51548, 51548, 467, 393, 2139, 312, 3256, 659, 12, 17227, 2001, 3209, 420, 257, 3209, 659, 12, 17227, 2001, 11, 584, 1228, 50016, 51794, 51794], "temperature": 0.0, "avg_logprob": -0.13843858542562532, "compression_ratio": 1.8987341772151898, "no_speech_prob": 7.888856089266483e-06}, {"id": 994, "seek": 396412, "start": 3975.7799999999997, "end": 3979.18, "text": " One is the cluster step, the other is the predict step.", "tokens": [50364, 613, 1481, 32191, 295, 5267, 300, 366, 4077, 293, 5267, 300, 366, 406, 4077, 13, 50670, 50670, 407, 264, 2135, 1558, 295, 341, 3035, 307, 4664, 2199, 13, 50836, 50836, 821, 366, 445, 732, 4439, 13, 50947, 50947, 1485, 307, 264, 13630, 1823, 11, 264, 661, 307, 264, 6069, 1823, 13, 51117, 51117, 407, 437, 321, 360, 307, 321, 747, 257, 659, 12, 17227, 2001, 3209, 293, 341, 393, 312, 604, 659, 12, 17227, 2001, 3209, 13, 51402, 51402, 467, 775, 406, 534, 362, 281, 312, 445, 257, 2698, 46533, 3209, 13, 51548, 51548, 467, 393, 2139, 312, 3256, 659, 12, 17227, 2001, 3209, 420, 257, 3209, 659, 12, 17227, 2001, 11, 584, 1228, 50016, 51794, 51794], "temperature": 0.0, "avg_logprob": -0.13843858542562532, "compression_ratio": 1.8987341772151898, "no_speech_prob": 7.888856089266483e-06}, {"id": 995, "seek": 396412, "start": 3979.18, "end": 3984.88, "text": " So what we do is we take a pre-trained network and this can be any pre-trained network.", "tokens": [50364, 613, 1481, 32191, 295, 5267, 300, 366, 4077, 293, 5267, 300, 366, 406, 4077, 13, 50670, 50670, 407, 264, 2135, 1558, 295, 341, 3035, 307, 4664, 2199, 13, 50836, 50836, 821, 366, 445, 732, 4439, 13, 50947, 50947, 1485, 307, 264, 13630, 1823, 11, 264, 661, 307, 264, 6069, 1823, 13, 51117, 51117, 407, 437, 321, 360, 307, 321, 747, 257, 659, 12, 17227, 2001, 3209, 293, 341, 393, 312, 604, 659, 12, 17227, 2001, 3209, 13, 51402, 51402, 467, 775, 406, 534, 362, 281, 312, 445, 257, 2698, 46533, 3209, 13, 51548, 51548, 467, 393, 2139, 312, 3256, 659, 12, 17227, 2001, 3209, 420, 257, 3209, 659, 12, 17227, 2001, 11, 584, 1228, 50016, 51794, 51794], "temperature": 0.0, "avg_logprob": -0.13843858542562532, "compression_ratio": 1.8987341772151898, "no_speech_prob": 7.888856089266483e-06}, {"id": 996, "seek": 396412, "start": 3984.88, "end": 3987.7999999999997, "text": " It does not really have to be just a self supervised network.", "tokens": [50364, 613, 1481, 32191, 295, 5267, 300, 366, 4077, 293, 5267, 300, 366, 406, 4077, 13, 50670, 50670, 407, 264, 2135, 1558, 295, 341, 3035, 307, 4664, 2199, 13, 50836, 50836, 821, 366, 445, 732, 4439, 13, 50947, 50947, 1485, 307, 264, 13630, 1823, 11, 264, 661, 307, 264, 6069, 1823, 13, 51117, 51117, 407, 437, 321, 360, 307, 321, 747, 257, 659, 12, 17227, 2001, 3209, 293, 341, 393, 312, 604, 659, 12, 17227, 2001, 3209, 13, 51402, 51402, 467, 775, 406, 534, 362, 281, 312, 445, 257, 2698, 46533, 3209, 13, 51548, 51548, 467, 393, 2139, 312, 3256, 659, 12, 17227, 2001, 3209, 420, 257, 3209, 659, 12, 17227, 2001, 11, 584, 1228, 50016, 51794, 51794], "temperature": 0.0, "avg_logprob": -0.13843858542562532, "compression_ratio": 1.8987341772151898, "no_speech_prob": 7.888856089266483e-06}, {"id": 997, "seek": 396412, "start": 3987.7999999999997, "end": 3992.72, "text": " It can either be image pre-trained network or a network pre-trained, say using hashtags", "tokens": [50364, 613, 1481, 32191, 295, 5267, 300, 366, 4077, 293, 5267, 300, 366, 406, 4077, 13, 50670, 50670, 407, 264, 2135, 1558, 295, 341, 3035, 307, 4664, 2199, 13, 50836, 50836, 821, 366, 445, 732, 4439, 13, 50947, 50947, 1485, 307, 264, 13630, 1823, 11, 264, 661, 307, 264, 6069, 1823, 13, 51117, 51117, 407, 437, 321, 360, 307, 321, 747, 257, 659, 12, 17227, 2001, 3209, 293, 341, 393, 312, 604, 659, 12, 17227, 2001, 3209, 13, 51402, 51402, 467, 775, 406, 534, 362, 281, 312, 445, 257, 2698, 46533, 3209, 13, 51548, 51548, 467, 393, 2139, 312, 3256, 659, 12, 17227, 2001, 3209, 420, 257, 3209, 659, 12, 17227, 2001, 11, 584, 1228, 50016, 51794, 51794], "temperature": 0.0, "avg_logprob": -0.13843858542562532, "compression_ratio": 1.8987341772151898, "no_speech_prob": 7.888856089266483e-06}, {"id": 998, "seek": 399272, "start": 3992.72, "end": 3998.0, "text": " or a self supervised network like one trained to predict jigsaw permutations.", "tokens": [50364, 420, 257, 2698, 46533, 3209, 411, 472, 8895, 281, 6069, 361, 17156, 1607, 4784, 325, 763, 13, 50628, 50628, 400, 291, 747, 341, 659, 12, 17227, 2001, 3209, 293, 291, 8947, 257, 3840, 295, 4122, 490, 309, 322, 50866, 50866, 257, 992, 295, 5267, 13, 50962, 50962, 400, 295, 1164, 11, 613, 5267, 362, 572, 16949, 13, 51096, 51096, 509, 8947, 613, 4122, 293, 291, 2042, 350, 12, 1398, 599, 596, 48673, 13, 51284, 51284, 400, 437, 291, 586, 483, 307, 1936, 337, 1184, 7645, 11, 337, 1184, 3256, 11, 291, 458, 597, 13630, 51572, 51572, 309, 12953, 281, 293, 300, 3643, 1080, 7645, 13, 51736, 51736], "temperature": 0.0, "avg_logprob": -0.14403259207349306, "compression_ratio": 1.7669491525423728, "no_speech_prob": 4.092772996955318e-06}, {"id": 999, "seek": 399272, "start": 3998.0, "end": 4002.7599999999998, "text": " And you take this pre-trained network and you extract a bunch of features from it on", "tokens": [50364, 420, 257, 2698, 46533, 3209, 411, 472, 8895, 281, 6069, 361, 17156, 1607, 4784, 325, 763, 13, 50628, 50628, 400, 291, 747, 341, 659, 12, 17227, 2001, 3209, 293, 291, 8947, 257, 3840, 295, 4122, 490, 309, 322, 50866, 50866, 257, 992, 295, 5267, 13, 50962, 50962, 400, 295, 1164, 11, 613, 5267, 362, 572, 16949, 13, 51096, 51096, 509, 8947, 613, 4122, 293, 291, 2042, 350, 12, 1398, 599, 596, 48673, 13, 51284, 51284, 400, 437, 291, 586, 483, 307, 1936, 337, 1184, 7645, 11, 337, 1184, 3256, 11, 291, 458, 597, 13630, 51572, 51572, 309, 12953, 281, 293, 300, 3643, 1080, 7645, 13, 51736, 51736], "temperature": 0.0, "avg_logprob": -0.14403259207349306, "compression_ratio": 1.7669491525423728, "no_speech_prob": 4.092772996955318e-06}, {"id": 1000, "seek": 399272, "start": 4002.7599999999998, "end": 4004.68, "text": " a set of images.", "tokens": [50364, 420, 257, 2698, 46533, 3209, 411, 472, 8895, 281, 6069, 361, 17156, 1607, 4784, 325, 763, 13, 50628, 50628, 400, 291, 747, 341, 659, 12, 17227, 2001, 3209, 293, 291, 8947, 257, 3840, 295, 4122, 490, 309, 322, 50866, 50866, 257, 992, 295, 5267, 13, 50962, 50962, 400, 295, 1164, 11, 613, 5267, 362, 572, 16949, 13, 51096, 51096, 509, 8947, 613, 4122, 293, 291, 2042, 350, 12, 1398, 599, 596, 48673, 13, 51284, 51284, 400, 437, 291, 586, 483, 307, 1936, 337, 1184, 7645, 11, 337, 1184, 3256, 11, 291, 458, 597, 13630, 51572, 51572, 309, 12953, 281, 293, 300, 3643, 1080, 7645, 13, 51736, 51736], "temperature": 0.0, "avg_logprob": -0.14403259207349306, "compression_ratio": 1.7669491525423728, "no_speech_prob": 4.092772996955318e-06}, {"id": 1001, "seek": 399272, "start": 4004.68, "end": 4007.3599999999997, "text": " And of course, these images have no labels.", "tokens": [50364, 420, 257, 2698, 46533, 3209, 411, 472, 8895, 281, 6069, 361, 17156, 1607, 4784, 325, 763, 13, 50628, 50628, 400, 291, 747, 341, 659, 12, 17227, 2001, 3209, 293, 291, 8947, 257, 3840, 295, 4122, 490, 309, 322, 50866, 50866, 257, 992, 295, 5267, 13, 50962, 50962, 400, 295, 1164, 11, 613, 5267, 362, 572, 16949, 13, 51096, 51096, 509, 8947, 613, 4122, 293, 291, 2042, 350, 12, 1398, 599, 596, 48673, 13, 51284, 51284, 400, 437, 291, 586, 483, 307, 1936, 337, 1184, 7645, 11, 337, 1184, 3256, 11, 291, 458, 597, 13630, 51572, 51572, 309, 12953, 281, 293, 300, 3643, 1080, 7645, 13, 51736, 51736], "temperature": 0.0, "avg_logprob": -0.14403259207349306, "compression_ratio": 1.7669491525423728, "no_speech_prob": 4.092772996955318e-06}, {"id": 1002, "seek": 399272, "start": 4007.3599999999997, "end": 4011.12, "text": " You extract these features and you perform k-means clustering.", "tokens": [50364, 420, 257, 2698, 46533, 3209, 411, 472, 8895, 281, 6069, 361, 17156, 1607, 4784, 325, 763, 13, 50628, 50628, 400, 291, 747, 341, 659, 12, 17227, 2001, 3209, 293, 291, 8947, 257, 3840, 295, 4122, 490, 309, 322, 50866, 50866, 257, 992, 295, 5267, 13, 50962, 50962, 400, 295, 1164, 11, 613, 5267, 362, 572, 16949, 13, 51096, 51096, 509, 8947, 613, 4122, 293, 291, 2042, 350, 12, 1398, 599, 596, 48673, 13, 51284, 51284, 400, 437, 291, 586, 483, 307, 1936, 337, 1184, 7645, 11, 337, 1184, 3256, 11, 291, 458, 597, 13630, 51572, 51572, 309, 12953, 281, 293, 300, 3643, 1080, 7645, 13, 51736, 51736], "temperature": 0.0, "avg_logprob": -0.14403259207349306, "compression_ratio": 1.7669491525423728, "no_speech_prob": 4.092772996955318e-06}, {"id": 1003, "seek": 399272, "start": 4011.12, "end": 4016.8799999999997, "text": " And what you now get is basically for each label, for each image, you know which cluster", "tokens": [50364, 420, 257, 2698, 46533, 3209, 411, 472, 8895, 281, 6069, 361, 17156, 1607, 4784, 325, 763, 13, 50628, 50628, 400, 291, 747, 341, 659, 12, 17227, 2001, 3209, 293, 291, 8947, 257, 3840, 295, 4122, 490, 309, 322, 50866, 50866, 257, 992, 295, 5267, 13, 50962, 50962, 400, 295, 1164, 11, 613, 5267, 362, 572, 16949, 13, 51096, 51096, 509, 8947, 613, 4122, 293, 291, 2042, 350, 12, 1398, 599, 596, 48673, 13, 51284, 51284, 400, 437, 291, 586, 483, 307, 1936, 337, 1184, 7645, 11, 337, 1184, 3256, 11, 291, 458, 597, 13630, 51572, 51572, 309, 12953, 281, 293, 300, 3643, 1080, 7645, 13, 51736, 51736], "temperature": 0.0, "avg_logprob": -0.14403259207349306, "compression_ratio": 1.7669491525423728, "no_speech_prob": 4.092772996955318e-06}, {"id": 1004, "seek": 399272, "start": 4016.8799999999997, "end": 4020.16, "text": " it belongs to and that becomes its label.", "tokens": [50364, 420, 257, 2698, 46533, 3209, 411, 472, 8895, 281, 6069, 361, 17156, 1607, 4784, 325, 763, 13, 50628, 50628, 400, 291, 747, 341, 659, 12, 17227, 2001, 3209, 293, 291, 8947, 257, 3840, 295, 4122, 490, 309, 322, 50866, 50866, 257, 992, 295, 5267, 13, 50962, 50962, 400, 295, 1164, 11, 613, 5267, 362, 572, 16949, 13, 51096, 51096, 509, 8947, 613, 4122, 293, 291, 2042, 350, 12, 1398, 599, 596, 48673, 13, 51284, 51284, 400, 437, 291, 586, 483, 307, 1936, 337, 1184, 7645, 11, 337, 1184, 3256, 11, 291, 458, 597, 13630, 51572, 51572, 309, 12953, 281, 293, 300, 3643, 1080, 7645, 13, 51736, 51736], "temperature": 0.0, "avg_logprob": -0.14403259207349306, "compression_ratio": 1.7669491525423728, "no_speech_prob": 4.092772996955318e-06}, {"id": 1005, "seek": 402016, "start": 4020.16, "end": 4024.8399999999997, "text": " So in the second fit step, what you do is you train a network from scratch.", "tokens": [50364, 407, 294, 264, 1150, 3318, 1823, 11, 437, 291, 360, 307, 291, 3847, 257, 3209, 490, 8459, 13, 50598, 50598, 407, 411, 490, 4974, 9239, 293, 291, 3847, 341, 3209, 281, 6069, 445, 613, 35899, 16949, 13, 50930, 50930, 407, 436, 434, 35899, 570, 436, 645, 1936, 14879, 1228, 596, 48673, 13, 51116, 51116, 407, 436, 434, 406, 534, 1152, 16949, 597, 645, 2212, 538, 584, 257, 1952, 25339, 1639, 13, 51377, 51377, 400, 370, 586, 341, 1150, 3209, 307, 445, 8895, 281, 6069, 613, 13630, 22546, 13, 51616, 51616, 407, 309, 2516, 527, 3256, 293, 309, 9898, 281, 6069, 597, 472, 295, 264, 350, 23313, 300, 291, 658, 490, 51824, 51824], "temperature": 0.0, "avg_logprob": -0.13253657859668397, "compression_ratio": 1.8598484848484849, "no_speech_prob": 5.255267296888633e-06}, {"id": 1006, "seek": 402016, "start": 4024.8399999999997, "end": 4031.48, "text": " So like from random bits and you train this network to predict just these pseudo labels.", "tokens": [50364, 407, 294, 264, 1150, 3318, 1823, 11, 437, 291, 360, 307, 291, 3847, 257, 3209, 490, 8459, 13, 50598, 50598, 407, 411, 490, 4974, 9239, 293, 291, 3847, 341, 3209, 281, 6069, 445, 613, 35899, 16949, 13, 50930, 50930, 407, 436, 434, 35899, 570, 436, 645, 1936, 14879, 1228, 596, 48673, 13, 51116, 51116, 407, 436, 434, 406, 534, 1152, 16949, 597, 645, 2212, 538, 584, 257, 1952, 25339, 1639, 13, 51377, 51377, 400, 370, 586, 341, 1150, 3209, 307, 445, 8895, 281, 6069, 613, 13630, 22546, 13, 51616, 51616, 407, 309, 2516, 527, 3256, 293, 309, 9898, 281, 6069, 597, 472, 295, 264, 350, 23313, 300, 291, 658, 490, 51824, 51824], "temperature": 0.0, "avg_logprob": -0.13253657859668397, "compression_ratio": 1.8598484848484849, "no_speech_prob": 5.255267296888633e-06}, {"id": 1007, "seek": 402016, "start": 4031.48, "end": 4035.2, "text": " So they're pseudo because they were basically obtained using clustering.", "tokens": [50364, 407, 294, 264, 1150, 3318, 1823, 11, 437, 291, 360, 307, 291, 3847, 257, 3209, 490, 8459, 13, 50598, 50598, 407, 411, 490, 4974, 9239, 293, 291, 3847, 341, 3209, 281, 6069, 445, 613, 35899, 16949, 13, 50930, 50930, 407, 436, 434, 35899, 570, 436, 645, 1936, 14879, 1228, 596, 48673, 13, 51116, 51116, 407, 436, 434, 406, 534, 1152, 16949, 597, 645, 2212, 538, 584, 257, 1952, 25339, 1639, 13, 51377, 51377, 400, 370, 586, 341, 1150, 3209, 307, 445, 8895, 281, 6069, 613, 13630, 22546, 13, 51616, 51616, 407, 309, 2516, 527, 3256, 293, 309, 9898, 281, 6069, 597, 472, 295, 264, 350, 23313, 300, 291, 658, 490, 51824, 51824], "temperature": 0.0, "avg_logprob": -0.13253657859668397, "compression_ratio": 1.8598484848484849, "no_speech_prob": 5.255267296888633e-06}, {"id": 1008, "seek": 402016, "start": 4035.2, "end": 4040.42, "text": " So they're not really hard labels which were given by say a human annotator.", "tokens": [50364, 407, 294, 264, 1150, 3318, 1823, 11, 437, 291, 360, 307, 291, 3847, 257, 3209, 490, 8459, 13, 50598, 50598, 407, 411, 490, 4974, 9239, 293, 291, 3847, 341, 3209, 281, 6069, 445, 613, 35899, 16949, 13, 50930, 50930, 407, 436, 434, 35899, 570, 436, 645, 1936, 14879, 1228, 596, 48673, 13, 51116, 51116, 407, 436, 434, 406, 534, 1152, 16949, 597, 645, 2212, 538, 584, 257, 1952, 25339, 1639, 13, 51377, 51377, 400, 370, 586, 341, 1150, 3209, 307, 445, 8895, 281, 6069, 613, 13630, 22546, 13, 51616, 51616, 407, 309, 2516, 527, 3256, 293, 309, 9898, 281, 6069, 597, 472, 295, 264, 350, 23313, 300, 291, 658, 490, 51824, 51824], "temperature": 0.0, "avg_logprob": -0.13253657859668397, "compression_ratio": 1.8598484848484849, "no_speech_prob": 5.255267296888633e-06}, {"id": 1009, "seek": 402016, "start": 4040.42, "end": 4045.2, "text": " And so now this second network is just trained to predict these cluster assignments.", "tokens": [50364, 407, 294, 264, 1150, 3318, 1823, 11, 437, 291, 360, 307, 291, 3847, 257, 3209, 490, 8459, 13, 50598, 50598, 407, 411, 490, 4974, 9239, 293, 291, 3847, 341, 3209, 281, 6069, 445, 613, 35899, 16949, 13, 50930, 50930, 407, 436, 434, 35899, 570, 436, 645, 1936, 14879, 1228, 596, 48673, 13, 51116, 51116, 407, 436, 434, 406, 534, 1152, 16949, 597, 645, 2212, 538, 584, 257, 1952, 25339, 1639, 13, 51377, 51377, 400, 370, 586, 341, 1150, 3209, 307, 445, 8895, 281, 6069, 613, 13630, 22546, 13, 51616, 51616, 407, 309, 2516, 527, 3256, 293, 309, 9898, 281, 6069, 597, 472, 295, 264, 350, 23313, 300, 291, 658, 490, 51824, 51824], "temperature": 0.0, "avg_logprob": -0.13253657859668397, "compression_ratio": 1.8598484848484849, "no_speech_prob": 5.255267296888633e-06}, {"id": 1010, "seek": 402016, "start": 4045.2, "end": 4049.3599999999997, "text": " So it takes our image and it tries to predict which one of the k clusters that you got from", "tokens": [50364, 407, 294, 264, 1150, 3318, 1823, 11, 437, 291, 360, 307, 291, 3847, 257, 3209, 490, 8459, 13, 50598, 50598, 407, 411, 490, 4974, 9239, 293, 291, 3847, 341, 3209, 281, 6069, 445, 613, 35899, 16949, 13, 50930, 50930, 407, 436, 434, 35899, 570, 436, 645, 1936, 14879, 1228, 596, 48673, 13, 51116, 51116, 407, 436, 434, 406, 534, 1152, 16949, 597, 645, 2212, 538, 584, 257, 1952, 25339, 1639, 13, 51377, 51377, 400, 370, 586, 341, 1150, 3209, 307, 445, 8895, 281, 6069, 613, 13630, 22546, 13, 51616, 51616, 407, 309, 2516, 527, 3256, 293, 309, 9898, 281, 6069, 597, 472, 295, 264, 350, 23313, 300, 291, 658, 490, 51824, 51824], "temperature": 0.0, "avg_logprob": -0.13253657859668397, "compression_ratio": 1.8598484848484849, "no_speech_prob": 5.255267296888633e-06}, {"id": 1011, "seek": 404936, "start": 4049.36, "end": 4052.92, "text": " your k-means does this image belong to.", "tokens": [50364, 428, 350, 12, 1398, 599, 775, 341, 3256, 5784, 281, 13, 50542, 50542, 407, 257, 3832, 659, 12, 83, 7146, 293, 5003, 5633, 307, 281, 1936, 2042, 428, 659, 12, 17227, 1760, 13, 50806, 50806, 407, 300, 311, 264, 1192, 5386, 307, 281, 2042, 428, 659, 12, 17227, 1760, 322, 364, 10024, 411, 32884, 50016, 420, 51086, 51086, 32884, 19462, 9253, 13, 51194, 51194, 400, 550, 281, 13059, 341, 4111, 2361, 538, 2539, 383, 12, 43, 533, 289, 1705, 650, 13, 51460, 51460, 682, 264, 13630, 3318, 1002, 11, 321, 1936, 360, 406, 2557, 264, 659, 12, 17227, 1760, 13, 51666, 51666, 407, 291, 2042, 428, 659, 12, 17227, 1760, 382, 291, 645, 13, 51812, 51812], "temperature": 0.0, "avg_logprob": -0.1680541927531614, "compression_ratio": 1.7851239669421488, "no_speech_prob": 4.495075700106099e-06}, {"id": 1012, "seek": 404936, "start": 4052.92, "end": 4058.2000000000003, "text": " So a standard pre-train and transfer task is to basically perform your pre-training.", "tokens": [50364, 428, 350, 12, 1398, 599, 775, 341, 3256, 5784, 281, 13, 50542, 50542, 407, 257, 3832, 659, 12, 83, 7146, 293, 5003, 5633, 307, 281, 1936, 2042, 428, 659, 12, 17227, 1760, 13, 50806, 50806, 407, 300, 311, 264, 1192, 5386, 307, 281, 2042, 428, 659, 12, 17227, 1760, 322, 364, 10024, 411, 32884, 50016, 420, 51086, 51086, 32884, 19462, 9253, 13, 51194, 51194, 400, 550, 281, 13059, 341, 4111, 2361, 538, 2539, 383, 12, 43, 533, 289, 1705, 650, 13, 51460, 51460, 682, 264, 13630, 3318, 1002, 11, 321, 1936, 360, 406, 2557, 264, 659, 12, 17227, 1760, 13, 51666, 51666, 407, 291, 2042, 428, 659, 12, 17227, 1760, 382, 291, 645, 13, 51812, 51812], "temperature": 0.0, "avg_logprob": -0.1680541927531614, "compression_ratio": 1.7851239669421488, "no_speech_prob": 4.495075700106099e-06}, {"id": 1013, "seek": 404936, "start": 4058.2000000000003, "end": 4063.8, "text": " So that's the top row is to perform your pre-training on an objective like predicting hashtags or", "tokens": [50364, 428, 350, 12, 1398, 599, 775, 341, 3256, 5784, 281, 13, 50542, 50542, 407, 257, 3832, 659, 12, 83, 7146, 293, 5003, 5633, 307, 281, 1936, 2042, 428, 659, 12, 17227, 1760, 13, 50806, 50806, 407, 300, 311, 264, 1192, 5386, 307, 281, 2042, 428, 659, 12, 17227, 1760, 322, 364, 10024, 411, 32884, 50016, 420, 51086, 51086, 32884, 19462, 9253, 13, 51194, 51194, 400, 550, 281, 13059, 341, 4111, 2361, 538, 2539, 383, 12, 43, 533, 289, 1705, 650, 13, 51460, 51460, 682, 264, 13630, 3318, 1002, 11, 321, 1936, 360, 406, 2557, 264, 659, 12, 17227, 1760, 13, 51666, 51666, 407, 291, 2042, 428, 659, 12, 17227, 1760, 382, 291, 645, 13, 51812, 51812], "temperature": 0.0, "avg_logprob": -0.1680541927531614, "compression_ratio": 1.7851239669421488, "no_speech_prob": 4.495075700106099e-06}, {"id": 1014, "seek": 404936, "start": 4063.8, "end": 4065.96, "text": " predicting GPS locations.", "tokens": [50364, 428, 350, 12, 1398, 599, 775, 341, 3256, 5784, 281, 13, 50542, 50542, 407, 257, 3832, 659, 12, 83, 7146, 293, 5003, 5633, 307, 281, 1936, 2042, 428, 659, 12, 17227, 1760, 13, 50806, 50806, 407, 300, 311, 264, 1192, 5386, 307, 281, 2042, 428, 659, 12, 17227, 1760, 322, 364, 10024, 411, 32884, 50016, 420, 51086, 51086, 32884, 19462, 9253, 13, 51194, 51194, 400, 550, 281, 13059, 341, 4111, 2361, 538, 2539, 383, 12, 43, 533, 289, 1705, 650, 13, 51460, 51460, 682, 264, 13630, 3318, 1002, 11, 321, 1936, 360, 406, 2557, 264, 659, 12, 17227, 1760, 13, 51666, 51666, 407, 291, 2042, 428, 659, 12, 17227, 1760, 382, 291, 645, 13, 51812, 51812], "temperature": 0.0, "avg_logprob": -0.1680541927531614, "compression_ratio": 1.7851239669421488, "no_speech_prob": 4.495075700106099e-06}, {"id": 1015, "seek": 404936, "start": 4065.96, "end": 4071.28, "text": " And then to evaluate this feature based by learning C-Linear Probe.", "tokens": [50364, 428, 350, 12, 1398, 599, 775, 341, 3256, 5784, 281, 13, 50542, 50542, 407, 257, 3832, 659, 12, 83, 7146, 293, 5003, 5633, 307, 281, 1936, 2042, 428, 659, 12, 17227, 1760, 13, 50806, 50806, 407, 300, 311, 264, 1192, 5386, 307, 281, 2042, 428, 659, 12, 17227, 1760, 322, 364, 10024, 411, 32884, 50016, 420, 51086, 51086, 32884, 19462, 9253, 13, 51194, 51194, 400, 550, 281, 13059, 341, 4111, 2361, 538, 2539, 383, 12, 43, 533, 289, 1705, 650, 13, 51460, 51460, 682, 264, 13630, 3318, 1002, 11, 321, 1936, 360, 406, 2557, 264, 659, 12, 17227, 1760, 13, 51666, 51666, 407, 291, 2042, 428, 659, 12, 17227, 1760, 382, 291, 645, 13, 51812, 51812], "temperature": 0.0, "avg_logprob": -0.1680541927531614, "compression_ratio": 1.7851239669421488, "no_speech_prob": 4.495075700106099e-06}, {"id": 1016, "seek": 404936, "start": 4071.28, "end": 4075.4, "text": " In the cluster fit world, we basically do not touch the pre-training.", "tokens": [50364, 428, 350, 12, 1398, 599, 775, 341, 3256, 5784, 281, 13, 50542, 50542, 407, 257, 3832, 659, 12, 83, 7146, 293, 5003, 5633, 307, 281, 1936, 2042, 428, 659, 12, 17227, 1760, 13, 50806, 50806, 407, 300, 311, 264, 1192, 5386, 307, 281, 2042, 428, 659, 12, 17227, 1760, 322, 364, 10024, 411, 32884, 50016, 420, 51086, 51086, 32884, 19462, 9253, 13, 51194, 51194, 400, 550, 281, 13059, 341, 4111, 2361, 538, 2539, 383, 12, 43, 533, 289, 1705, 650, 13, 51460, 51460, 682, 264, 13630, 3318, 1002, 11, 321, 1936, 360, 406, 2557, 264, 659, 12, 17227, 1760, 13, 51666, 51666, 407, 291, 2042, 428, 659, 12, 17227, 1760, 382, 291, 645, 13, 51812, 51812], "temperature": 0.0, "avg_logprob": -0.1680541927531614, "compression_ratio": 1.7851239669421488, "no_speech_prob": 4.495075700106099e-06}, {"id": 1017, "seek": 404936, "start": 4075.4, "end": 4078.32, "text": " So you perform your pre-training as you were.", "tokens": [50364, 428, 350, 12, 1398, 599, 775, 341, 3256, 5784, 281, 13, 50542, 50542, 407, 257, 3832, 659, 12, 83, 7146, 293, 5003, 5633, 307, 281, 1936, 2042, 428, 659, 12, 17227, 1760, 13, 50806, 50806, 407, 300, 311, 264, 1192, 5386, 307, 281, 2042, 428, 659, 12, 17227, 1760, 322, 364, 10024, 411, 32884, 50016, 420, 51086, 51086, 32884, 19462, 9253, 13, 51194, 51194, 400, 550, 281, 13059, 341, 4111, 2361, 538, 2539, 383, 12, 43, 533, 289, 1705, 650, 13, 51460, 51460, 682, 264, 13630, 3318, 1002, 11, 321, 1936, 360, 406, 2557, 264, 659, 12, 17227, 1760, 13, 51666, 51666, 407, 291, 2042, 428, 659, 12, 17227, 1760, 382, 291, 645, 13, 51812, 51812], "temperature": 0.0, "avg_logprob": -0.1680541927531614, "compression_ratio": 1.7851239669421488, "no_speech_prob": 4.495075700106099e-06}, {"id": 1018, "seek": 407832, "start": 4078.32, "end": 4083.2400000000002, "text": " You just insert a step in between which is the cluster fit step where you take a data", "tokens": [50364, 509, 445, 8969, 257, 1823, 294, 1296, 597, 307, 264, 13630, 3318, 1823, 689, 291, 747, 257, 1412, 50610, 50610, 992, 413, 293, 291, 747, 428, 659, 12, 17227, 2001, 3209, 293, 291, 1466, 257, 777, 3209, 490, 8459, 322, 50844, 50844, 341, 1412, 13, 50896, 50896, 400, 2721, 11, 291, 1936, 764, 341, 3092, 3209, 337, 439, 428, 30621, 9608, 13, 51240, 51240, 407, 264, 1778, 321, 1697, 300, 341, 3170, 1985, 307, 570, 264, 596, 48673, 1823, 11, 562, 51632, 51632], "temperature": 0.0, "avg_logprob": -0.1569525213802562, "compression_ratio": 1.6666666666666667, "no_speech_prob": 7.411120350298006e-06}, {"id": 1019, "seek": 407832, "start": 4083.2400000000002, "end": 4087.92, "text": " set D and you take your pre-trained network and you learn a new network from scratch on", "tokens": [50364, 509, 445, 8969, 257, 1823, 294, 1296, 597, 307, 264, 13630, 3318, 1823, 689, 291, 747, 257, 1412, 50610, 50610, 992, 413, 293, 291, 747, 428, 659, 12, 17227, 2001, 3209, 293, 291, 1466, 257, 777, 3209, 490, 8459, 322, 50844, 50844, 341, 1412, 13, 50896, 50896, 400, 2721, 11, 291, 1936, 764, 341, 3092, 3209, 337, 439, 428, 30621, 9608, 13, 51240, 51240, 407, 264, 1778, 321, 1697, 300, 341, 3170, 1985, 307, 570, 264, 596, 48673, 1823, 11, 562, 51632, 51632], "temperature": 0.0, "avg_logprob": -0.1569525213802562, "compression_ratio": 1.6666666666666667, "no_speech_prob": 7.411120350298006e-06}, {"id": 1020, "seek": 407832, "start": 4087.92, "end": 4088.96, "text": " this data.", "tokens": [50364, 509, 445, 8969, 257, 1823, 294, 1296, 597, 307, 264, 13630, 3318, 1823, 689, 291, 747, 257, 1412, 50610, 50610, 992, 413, 293, 291, 747, 428, 659, 12, 17227, 2001, 3209, 293, 291, 1466, 257, 777, 3209, 490, 8459, 322, 50844, 50844, 341, 1412, 13, 50896, 50896, 400, 2721, 11, 291, 1936, 764, 341, 3092, 3209, 337, 439, 428, 30621, 9608, 13, 51240, 51240, 407, 264, 1778, 321, 1697, 300, 341, 3170, 1985, 307, 570, 264, 596, 48673, 1823, 11, 562, 51632, 51632], "temperature": 0.0, "avg_logprob": -0.1569525213802562, "compression_ratio": 1.6666666666666667, "no_speech_prob": 7.411120350298006e-06}, {"id": 1021, "seek": 407832, "start": 4088.96, "end": 4095.84, "text": " And finally, you basically use this green network for all your downstream tasks.", "tokens": [50364, 509, 445, 8969, 257, 1823, 294, 1296, 597, 307, 264, 13630, 3318, 1823, 689, 291, 747, 257, 1412, 50610, 50610, 992, 413, 293, 291, 747, 428, 659, 12, 17227, 2001, 3209, 293, 291, 1466, 257, 777, 3209, 490, 8459, 322, 50844, 50844, 341, 1412, 13, 50896, 50896, 400, 2721, 11, 291, 1936, 764, 341, 3092, 3209, 337, 439, 428, 30621, 9608, 13, 51240, 51240, 407, 264, 1778, 321, 1697, 300, 341, 3170, 1985, 307, 570, 264, 596, 48673, 1823, 11, 562, 51632, 51632], "temperature": 0.0, "avg_logprob": -0.1569525213802562, "compression_ratio": 1.6666666666666667, "no_speech_prob": 7.411120350298006e-06}, {"id": 1022, "seek": 407832, "start": 4095.84, "end": 4103.68, "text": " So the reason we believe that this method works is because the clustering step, when", "tokens": [50364, 509, 445, 8969, 257, 1823, 294, 1296, 597, 307, 264, 13630, 3318, 1823, 689, 291, 747, 257, 1412, 50610, 50610, 992, 413, 293, 291, 747, 428, 659, 12, 17227, 2001, 3209, 293, 291, 1466, 257, 777, 3209, 490, 8459, 322, 50844, 50844, 341, 1412, 13, 50896, 50896, 400, 2721, 11, 291, 1936, 764, 341, 3092, 3209, 337, 439, 428, 30621, 9608, 13, 51240, 51240, 407, 264, 1778, 321, 1697, 300, 341, 3170, 1985, 307, 570, 264, 596, 48673, 1823, 11, 562, 51632, 51632], "temperature": 0.0, "avg_logprob": -0.1569525213802562, "compression_ratio": 1.6666666666666667, "no_speech_prob": 7.411120350298006e-06}, {"id": 1023, "seek": 410368, "start": 4103.68, "end": 4109.240000000001, "text": " you're sort of clustering just these images, you're only capturing the essential information", "tokens": [50364, 291, 434, 1333, 295, 596, 48673, 445, 613, 5267, 11, 291, 434, 787, 23384, 264, 7115, 1589, 50642, 50642, 597, 307, 1936, 437, 5267, 352, 1214, 293, 437, 5267, 360, 406, 352, 1214, 13, 50864, 50864, 407, 291, 434, 10238, 1314, 439, 264, 661, 1589, 300, 307, 1974, 294, 264, 3380, 3209, 13, 51074, 51074, 509, 434, 445, 23384, 264, 1333, 295, 728, 12, 26624, 6159, 300, 645, 11828, 11, 300, 645, 51376, 51376, 37140, 538, 264, 5883, 3209, 13, 51618, 51618, 400, 281, 1333, 295, 1223, 341, 11, 321, 10332, 257, 6457, 2199, 5120, 13, 51786, 51786], "temperature": 0.0, "avg_logprob": -0.17576478958129882, "compression_ratio": 1.8653061224489795, "no_speech_prob": 1.3631008187076077e-05}, {"id": 1024, "seek": 410368, "start": 4109.240000000001, "end": 4113.68, "text": " which is basically what images go together and what images do not go together.", "tokens": [50364, 291, 434, 1333, 295, 596, 48673, 445, 613, 5267, 11, 291, 434, 787, 23384, 264, 7115, 1589, 50642, 50642, 597, 307, 1936, 437, 5267, 352, 1214, 293, 437, 5267, 360, 406, 352, 1214, 13, 50864, 50864, 407, 291, 434, 10238, 1314, 439, 264, 661, 1589, 300, 307, 1974, 294, 264, 3380, 3209, 13, 51074, 51074, 509, 434, 445, 23384, 264, 1333, 295, 728, 12, 26624, 6159, 300, 645, 11828, 11, 300, 645, 51376, 51376, 37140, 538, 264, 5883, 3209, 13, 51618, 51618, 400, 281, 1333, 295, 1223, 341, 11, 321, 10332, 257, 6457, 2199, 5120, 13, 51786, 51786], "temperature": 0.0, "avg_logprob": -0.17576478958129882, "compression_ratio": 1.8653061224489795, "no_speech_prob": 1.3631008187076077e-05}, {"id": 1025, "seek": 410368, "start": 4113.68, "end": 4117.88, "text": " So you're throwing away all the other information that is present in the original network.", "tokens": [50364, 291, 434, 1333, 295, 596, 48673, 445, 613, 5267, 11, 291, 434, 787, 23384, 264, 7115, 1589, 50642, 50642, 597, 307, 1936, 437, 5267, 352, 1214, 293, 437, 5267, 360, 406, 352, 1214, 13, 50864, 50864, 407, 291, 434, 10238, 1314, 439, 264, 661, 1589, 300, 307, 1974, 294, 264, 3380, 3209, 13, 51074, 51074, 509, 434, 445, 23384, 264, 1333, 295, 728, 12, 26624, 6159, 300, 645, 11828, 11, 300, 645, 51376, 51376, 37140, 538, 264, 5883, 3209, 13, 51618, 51618, 400, 281, 1333, 295, 1223, 341, 11, 321, 10332, 257, 6457, 2199, 5120, 13, 51786, 51786], "temperature": 0.0, "avg_logprob": -0.17576478958129882, "compression_ratio": 1.8653061224489795, "no_speech_prob": 1.3631008187076077e-05}, {"id": 1026, "seek": 410368, "start": 4117.88, "end": 4123.92, "text": " You're just capturing the sort of inter-image relationships that were captured, that were", "tokens": [50364, 291, 434, 1333, 295, 596, 48673, 445, 613, 5267, 11, 291, 434, 787, 23384, 264, 7115, 1589, 50642, 50642, 597, 307, 1936, 437, 5267, 352, 1214, 293, 437, 5267, 360, 406, 352, 1214, 13, 50864, 50864, 407, 291, 434, 10238, 1314, 439, 264, 661, 1589, 300, 307, 1974, 294, 264, 3380, 3209, 13, 51074, 51074, 509, 434, 445, 23384, 264, 1333, 295, 728, 12, 26624, 6159, 300, 645, 11828, 11, 300, 645, 51376, 51376, 37140, 538, 264, 5883, 3209, 13, 51618, 51618, 400, 281, 1333, 295, 1223, 341, 11, 321, 10332, 257, 6457, 2199, 5120, 13, 51786, 51786], "temperature": 0.0, "avg_logprob": -0.17576478958129882, "compression_ratio": 1.8653061224489795, "no_speech_prob": 1.3631008187076077e-05}, {"id": 1027, "seek": 410368, "start": 4123.92, "end": 4128.76, "text": " modeled by the initial network.", "tokens": [50364, 291, 434, 1333, 295, 596, 48673, 445, 613, 5267, 11, 291, 434, 787, 23384, 264, 7115, 1589, 50642, 50642, 597, 307, 1936, 437, 5267, 352, 1214, 293, 437, 5267, 360, 406, 352, 1214, 13, 50864, 50864, 407, 291, 434, 10238, 1314, 439, 264, 661, 1589, 300, 307, 1974, 294, 264, 3380, 3209, 13, 51074, 51074, 509, 434, 445, 23384, 264, 1333, 295, 728, 12, 26624, 6159, 300, 645, 11828, 11, 300, 645, 51376, 51376, 37140, 538, 264, 5883, 3209, 13, 51618, 51618, 400, 281, 1333, 295, 1223, 341, 11, 321, 10332, 257, 6457, 2199, 5120, 13, 51786, 51786], "temperature": 0.0, "avg_logprob": -0.17576478958129882, "compression_ratio": 1.8653061224489795, "no_speech_prob": 1.3631008187076077e-05}, {"id": 1028, "seek": 410368, "start": 4128.76, "end": 4132.12, "text": " And to sort of understand this, we performed a fairly simple experiment.", "tokens": [50364, 291, 434, 1333, 295, 596, 48673, 445, 613, 5267, 11, 291, 434, 787, 23384, 264, 7115, 1589, 50642, 50642, 597, 307, 1936, 437, 5267, 352, 1214, 293, 437, 5267, 360, 406, 352, 1214, 13, 50864, 50864, 407, 291, 434, 10238, 1314, 439, 264, 661, 1589, 300, 307, 1974, 294, 264, 3380, 3209, 13, 51074, 51074, 509, 434, 445, 23384, 264, 1333, 295, 728, 12, 26624, 6159, 300, 645, 11828, 11, 300, 645, 51376, 51376, 37140, 538, 264, 5883, 3209, 13, 51618, 51618, 400, 281, 1333, 295, 1223, 341, 11, 321, 10332, 257, 6457, 2199, 5120, 13, 51786, 51786], "temperature": 0.0, "avg_logprob": -0.17576478958129882, "compression_ratio": 1.8653061224489795, "no_speech_prob": 1.3631008187076077e-05}, {"id": 1029, "seek": 413212, "start": 4132.12, "end": 4136.4, "text": " We added label noise, so synthetic label noise to ImageNet.", "tokens": [50364, 492, 3869, 7645, 5658, 11, 370, 23420, 7645, 5658, 281, 29903, 31890, 13, 50578, 50578, 400, 321, 8895, 264, 3209, 1936, 322, 341, 24518, 29903, 31890, 13, 50750, 50750, 407, 445, 7929, 257, 3840, 295, 3256, 16949, 293, 3847, 257, 3209, 13, 51012, 51012, 400, 586, 291, 13059, 264, 4111, 10290, 490, 341, 3209, 322, 257, 30621, 5633, 11, 597, 51262, 51262, 307, 797, 29903, 31890, 11, 457, 309, 311, 257, 709, 4833, 3037, 295, 29903, 31890, 13, 51414, 51414, 407, 309, 311, 1722, 11, 1360, 12, 676, 21538, 13, 51632, 51632], "temperature": 0.0, "avg_logprob": -0.13594844493460148, "compression_ratio": 1.6327433628318584, "no_speech_prob": 3.555916237019119e-06}, {"id": 1030, "seek": 413212, "start": 4136.4, "end": 4139.84, "text": " And we trained the network basically on this noisy ImageNet.", "tokens": [50364, 492, 3869, 7645, 5658, 11, 370, 23420, 7645, 5658, 281, 29903, 31890, 13, 50578, 50578, 400, 321, 8895, 264, 3209, 1936, 322, 341, 24518, 29903, 31890, 13, 50750, 50750, 407, 445, 7929, 257, 3840, 295, 3256, 16949, 293, 3847, 257, 3209, 13, 51012, 51012, 400, 586, 291, 13059, 264, 4111, 10290, 490, 341, 3209, 322, 257, 30621, 5633, 11, 597, 51262, 51262, 307, 797, 29903, 31890, 11, 457, 309, 311, 257, 709, 4833, 3037, 295, 29903, 31890, 13, 51414, 51414, 407, 309, 311, 1722, 11, 1360, 12, 676, 21538, 13, 51632, 51632], "temperature": 0.0, "avg_logprob": -0.13594844493460148, "compression_ratio": 1.6327433628318584, "no_speech_prob": 3.555916237019119e-06}, {"id": 1031, "seek": 413212, "start": 4139.84, "end": 4145.08, "text": " So just flip a bunch of image labels and train a network.", "tokens": [50364, 492, 3869, 7645, 5658, 11, 370, 23420, 7645, 5658, 281, 29903, 31890, 13, 50578, 50578, 400, 321, 8895, 264, 3209, 1936, 322, 341, 24518, 29903, 31890, 13, 50750, 50750, 407, 445, 7929, 257, 3840, 295, 3256, 16949, 293, 3847, 257, 3209, 13, 51012, 51012, 400, 586, 291, 13059, 264, 4111, 10290, 490, 341, 3209, 322, 257, 30621, 5633, 11, 597, 51262, 51262, 307, 797, 29903, 31890, 11, 457, 309, 311, 257, 709, 4833, 3037, 295, 29903, 31890, 13, 51414, 51414, 407, 309, 311, 1722, 11, 1360, 12, 676, 21538, 13, 51632, 51632], "temperature": 0.0, "avg_logprob": -0.13594844493460148, "compression_ratio": 1.6327433628318584, "no_speech_prob": 3.555916237019119e-06}, {"id": 1032, "seek": 413212, "start": 4145.08, "end": 4150.08, "text": " And now you evaluate the feature representation from this network on a downstream task, which", "tokens": [50364, 492, 3869, 7645, 5658, 11, 370, 23420, 7645, 5658, 281, 29903, 31890, 13, 50578, 50578, 400, 321, 8895, 264, 3209, 1936, 322, 341, 24518, 29903, 31890, 13, 50750, 50750, 407, 445, 7929, 257, 3840, 295, 3256, 16949, 293, 3847, 257, 3209, 13, 51012, 51012, 400, 586, 291, 13059, 264, 4111, 10290, 490, 341, 3209, 322, 257, 30621, 5633, 11, 597, 51262, 51262, 307, 797, 29903, 31890, 11, 457, 309, 311, 257, 709, 4833, 3037, 295, 29903, 31890, 13, 51414, 51414, 407, 309, 311, 1722, 11, 1360, 12, 676, 21538, 13, 51632, 51632], "temperature": 0.0, "avg_logprob": -0.13594844493460148, "compression_ratio": 1.6327433628318584, "no_speech_prob": 3.555916237019119e-06}, {"id": 1033, "seek": 413212, "start": 4150.08, "end": 4153.12, "text": " is again ImageNet, but it's a much larger version of ImageNet.", "tokens": [50364, 492, 3869, 7645, 5658, 11, 370, 23420, 7645, 5658, 281, 29903, 31890, 13, 50578, 50578, 400, 321, 8895, 264, 3209, 1936, 322, 341, 24518, 29903, 31890, 13, 50750, 50750, 407, 445, 7929, 257, 3840, 295, 3256, 16949, 293, 3847, 257, 3209, 13, 51012, 51012, 400, 586, 291, 13059, 264, 4111, 10290, 490, 341, 3209, 322, 257, 30621, 5633, 11, 597, 51262, 51262, 307, 797, 29903, 31890, 11, 457, 309, 311, 257, 709, 4833, 3037, 295, 29903, 31890, 13, 51414, 51414, 407, 309, 311, 1722, 11, 1360, 12, 676, 21538, 13, 51632, 51632], "temperature": 0.0, "avg_logprob": -0.13594844493460148, "compression_ratio": 1.6327433628318584, "no_speech_prob": 3.555916237019119e-06}, {"id": 1034, "seek": 413212, "start": 4153.12, "end": 4157.48, "text": " So it's 9,000-way classification.", "tokens": [50364, 492, 3869, 7645, 5658, 11, 370, 23420, 7645, 5658, 281, 29903, 31890, 13, 50578, 50578, 400, 321, 8895, 264, 3209, 1936, 322, 341, 24518, 29903, 31890, 13, 50750, 50750, 407, 445, 7929, 257, 3840, 295, 3256, 16949, 293, 3847, 257, 3209, 13, 51012, 51012, 400, 586, 291, 13059, 264, 4111, 10290, 490, 341, 3209, 322, 257, 30621, 5633, 11, 597, 51262, 51262, 307, 797, 29903, 31890, 11, 457, 309, 311, 257, 709, 4833, 3037, 295, 29903, 31890, 13, 51414, 51414, 407, 309, 311, 1722, 11, 1360, 12, 676, 21538, 13, 51632, 51632], "temperature": 0.0, "avg_logprob": -0.13594844493460148, "compression_ratio": 1.6327433628318584, "no_speech_prob": 3.555916237019119e-06}, {"id": 1035, "seek": 415748, "start": 4157.48, "end": 4163.679999999999, "text": " So we basically on the x-axis have the amount of label noise added to the images.", "tokens": [50364, 407, 321, 1936, 322, 264, 2031, 12, 24633, 362, 264, 2372, 295, 7645, 5658, 3869, 281, 264, 5267, 13, 50674, 50674, 407, 300, 311, 516, 490, 1958, 4, 281, 9562, 6856, 50838, 50838, 400, 322, 264, 288, 12, 24633, 11, 321, 366, 1237, 412, 264, 5003, 3389, 322, 264, 4833, 29903, 31890, 11, 264, 29903, 31890, 51094, 51094, 1722, 11, 1360, 28872, 13, 51237, 51237, 407, 264, 7022, 1622, 307, 4099, 291, 264, 659, 12, 17227, 2001, 3209, 11, 597, 307, 1936, 382, 264, 2372, 51548, 51548, 295, 7645, 5658, 8637, 11, 264, 659, 12, 17227, 2001, 3209, 311, 3389, 322, 264, 30621, 5633, 51750, 51750, 24108, 13, 51800, 51800], "temperature": 0.0, "avg_logprob": -0.13380374227251327, "compression_ratio": 1.7887931034482758, "no_speech_prob": 4.710825578513322e-06}, {"id": 1036, "seek": 415748, "start": 4163.679999999999, "end": 4166.959999999999, "text": " So that's going from 0% to 75%.", "tokens": [50364, 407, 321, 1936, 322, 264, 2031, 12, 24633, 362, 264, 2372, 295, 7645, 5658, 3869, 281, 264, 5267, 13, 50674, 50674, 407, 300, 311, 516, 490, 1958, 4, 281, 9562, 6856, 50838, 50838, 400, 322, 264, 288, 12, 24633, 11, 321, 366, 1237, 412, 264, 5003, 3389, 322, 264, 4833, 29903, 31890, 11, 264, 29903, 31890, 51094, 51094, 1722, 11, 1360, 28872, 13, 51237, 51237, 407, 264, 7022, 1622, 307, 4099, 291, 264, 659, 12, 17227, 2001, 3209, 11, 597, 307, 1936, 382, 264, 2372, 51548, 51548, 295, 7645, 5658, 8637, 11, 264, 659, 12, 17227, 2001, 3209, 311, 3389, 322, 264, 30621, 5633, 51750, 51750, 24108, 13, 51800, 51800], "temperature": 0.0, "avg_logprob": -0.13380374227251327, "compression_ratio": 1.7887931034482758, "no_speech_prob": 4.710825578513322e-06}, {"id": 1037, "seek": 415748, "start": 4166.959999999999, "end": 4172.08, "text": " And on the y-axis, we are looking at the transfer performance on the larger ImageNet, the ImageNet", "tokens": [50364, 407, 321, 1936, 322, 264, 2031, 12, 24633, 362, 264, 2372, 295, 7645, 5658, 3869, 281, 264, 5267, 13, 50674, 50674, 407, 300, 311, 516, 490, 1958, 4, 281, 9562, 6856, 50838, 50838, 400, 322, 264, 288, 12, 24633, 11, 321, 366, 1237, 412, 264, 5003, 3389, 322, 264, 4833, 29903, 31890, 11, 264, 29903, 31890, 51094, 51094, 1722, 11, 1360, 28872, 13, 51237, 51237, 407, 264, 7022, 1622, 307, 4099, 291, 264, 659, 12, 17227, 2001, 3209, 11, 597, 307, 1936, 382, 264, 2372, 51548, 51548, 295, 7645, 5658, 8637, 11, 264, 659, 12, 17227, 2001, 3209, 311, 3389, 322, 264, 30621, 5633, 51750, 51750, 24108, 13, 51800, 51800], "temperature": 0.0, "avg_logprob": -0.13380374227251327, "compression_ratio": 1.7887931034482758, "no_speech_prob": 4.710825578513322e-06}, {"id": 1038, "seek": 415748, "start": 4172.08, "end": 4174.94, "text": " 9,000 dataset.", "tokens": [50364, 407, 321, 1936, 322, 264, 2031, 12, 24633, 362, 264, 2372, 295, 7645, 5658, 3869, 281, 264, 5267, 13, 50674, 50674, 407, 300, 311, 516, 490, 1958, 4, 281, 9562, 6856, 50838, 50838, 400, 322, 264, 288, 12, 24633, 11, 321, 366, 1237, 412, 264, 5003, 3389, 322, 264, 4833, 29903, 31890, 11, 264, 29903, 31890, 51094, 51094, 1722, 11, 1360, 28872, 13, 51237, 51237, 407, 264, 7022, 1622, 307, 4099, 291, 264, 659, 12, 17227, 2001, 3209, 11, 597, 307, 1936, 382, 264, 2372, 51548, 51548, 295, 7645, 5658, 8637, 11, 264, 659, 12, 17227, 2001, 3209, 311, 3389, 322, 264, 30621, 5633, 51750, 51750, 24108, 13, 51800, 51800], "temperature": 0.0, "avg_logprob": -0.13380374227251327, "compression_ratio": 1.7887931034482758, "no_speech_prob": 4.710825578513322e-06}, {"id": 1039, "seek": 415748, "start": 4174.94, "end": 4181.16, "text": " So the pink line is showing you the pre-trained network, which is basically as the amount", "tokens": [50364, 407, 321, 1936, 322, 264, 2031, 12, 24633, 362, 264, 2372, 295, 7645, 5658, 3869, 281, 264, 5267, 13, 50674, 50674, 407, 300, 311, 516, 490, 1958, 4, 281, 9562, 6856, 50838, 50838, 400, 322, 264, 288, 12, 24633, 11, 321, 366, 1237, 412, 264, 5003, 3389, 322, 264, 4833, 29903, 31890, 11, 264, 29903, 31890, 51094, 51094, 1722, 11, 1360, 28872, 13, 51237, 51237, 407, 264, 7022, 1622, 307, 4099, 291, 264, 659, 12, 17227, 2001, 3209, 11, 597, 307, 1936, 382, 264, 2372, 51548, 51548, 295, 7645, 5658, 8637, 11, 264, 659, 12, 17227, 2001, 3209, 311, 3389, 322, 264, 30621, 5633, 51750, 51750, 24108, 13, 51800, 51800], "temperature": 0.0, "avg_logprob": -0.13380374227251327, "compression_ratio": 1.7887931034482758, "no_speech_prob": 4.710825578513322e-06}, {"id": 1040, "seek": 415748, "start": 4181.16, "end": 4185.2, "text": " of label noise increases, the pre-trained network's performance on the downstream task", "tokens": [50364, 407, 321, 1936, 322, 264, 2031, 12, 24633, 362, 264, 2372, 295, 7645, 5658, 3869, 281, 264, 5267, 13, 50674, 50674, 407, 300, 311, 516, 490, 1958, 4, 281, 9562, 6856, 50838, 50838, 400, 322, 264, 288, 12, 24633, 11, 321, 366, 1237, 412, 264, 5003, 3389, 322, 264, 4833, 29903, 31890, 11, 264, 29903, 31890, 51094, 51094, 1722, 11, 1360, 28872, 13, 51237, 51237, 407, 264, 7022, 1622, 307, 4099, 291, 264, 659, 12, 17227, 2001, 3209, 11, 597, 307, 1936, 382, 264, 2372, 51548, 51548, 295, 7645, 5658, 8637, 11, 264, 659, 12, 17227, 2001, 3209, 311, 3389, 322, 264, 30621, 5633, 51750, 51750, 24108, 13, 51800, 51800], "temperature": 0.0, "avg_logprob": -0.13380374227251327, "compression_ratio": 1.7887931034482758, "no_speech_prob": 4.710825578513322e-06}, {"id": 1041, "seek": 415748, "start": 4185.2, "end": 4186.2, "text": " decreases.", "tokens": [50364, 407, 321, 1936, 322, 264, 2031, 12, 24633, 362, 264, 2372, 295, 7645, 5658, 3869, 281, 264, 5267, 13, 50674, 50674, 407, 300, 311, 516, 490, 1958, 4, 281, 9562, 6856, 50838, 50838, 400, 322, 264, 288, 12, 24633, 11, 321, 366, 1237, 412, 264, 5003, 3389, 322, 264, 4833, 29903, 31890, 11, 264, 29903, 31890, 51094, 51094, 1722, 11, 1360, 28872, 13, 51237, 51237, 407, 264, 7022, 1622, 307, 4099, 291, 264, 659, 12, 17227, 2001, 3209, 11, 597, 307, 1936, 382, 264, 2372, 51548, 51548, 295, 7645, 5658, 8637, 11, 264, 659, 12, 17227, 2001, 3209, 311, 3389, 322, 264, 30621, 5633, 51750, 51750, 24108, 13, 51800, 51800], "temperature": 0.0, "avg_logprob": -0.13380374227251327, "compression_ratio": 1.7887931034482758, "no_speech_prob": 4.710825578513322e-06}, {"id": 1042, "seek": 418620, "start": 4186.2, "end": 4191.5199999999995, "text": " And this is not surprising, because as your labels become less and less reliable, of course,", "tokens": [50364, 400, 341, 307, 406, 8830, 11, 570, 382, 428, 16949, 1813, 1570, 293, 1570, 12924, 11, 295, 1164, 11, 50630, 50630, 428, 10290, 3125, 307, 516, 281, 9753, 13, 50740, 50740, 407, 300, 1333, 295, 1709, 760, 588, 2661, 13, 50952, 50952, 682, 264, 1333, 295, 3344, 1622, 11, 321, 5120, 292, 365, 341, 6532, 1219, 2316, 42923, 399, 11, 51246, 51246, 689, 291, 747, 428, 5883, 3209, 293, 291, 764, 300, 281, 8460, 16949, 13, 51548, 51548, 407, 291, 574, 412, 264, 5598, 295, 300, 3209, 293, 291, 574, 412, 264, 1333, 295, 6687, 294, 51732, 51732, 264, 23930, 281, 8460, 16949, 337, 257, 1150, 3209, 13, 51860, 51860], "temperature": 0.0, "avg_logprob": -0.1987482990537371, "compression_ratio": 1.794007490636704, "no_speech_prob": 1.5935775081743486e-05}, {"id": 1043, "seek": 418620, "start": 4191.5199999999995, "end": 4193.72, "text": " your representation quality is going to suffer.", "tokens": [50364, 400, 341, 307, 406, 8830, 11, 570, 382, 428, 16949, 1813, 1570, 293, 1570, 12924, 11, 295, 1164, 11, 50630, 50630, 428, 10290, 3125, 307, 516, 281, 9753, 13, 50740, 50740, 407, 300, 1333, 295, 1709, 760, 588, 2661, 13, 50952, 50952, 682, 264, 1333, 295, 3344, 1622, 11, 321, 5120, 292, 365, 341, 6532, 1219, 2316, 42923, 399, 11, 51246, 51246, 689, 291, 747, 428, 5883, 3209, 293, 291, 764, 300, 281, 8460, 16949, 13, 51548, 51548, 407, 291, 574, 412, 264, 5598, 295, 300, 3209, 293, 291, 574, 412, 264, 1333, 295, 6687, 294, 51732, 51732, 264, 23930, 281, 8460, 16949, 337, 257, 1150, 3209, 13, 51860, 51860], "temperature": 0.0, "avg_logprob": -0.1987482990537371, "compression_ratio": 1.794007490636704, "no_speech_prob": 1.5935775081743486e-05}, {"id": 1044, "seek": 418620, "start": 4193.72, "end": 4197.96, "text": " So that sort of goes down very quickly.", "tokens": [50364, 400, 341, 307, 406, 8830, 11, 570, 382, 428, 16949, 1813, 1570, 293, 1570, 12924, 11, 295, 1164, 11, 50630, 50630, 428, 10290, 3125, 307, 516, 281, 9753, 13, 50740, 50740, 407, 300, 1333, 295, 1709, 760, 588, 2661, 13, 50952, 50952, 682, 264, 1333, 295, 3344, 1622, 11, 321, 5120, 292, 365, 341, 6532, 1219, 2316, 42923, 399, 11, 51246, 51246, 689, 291, 747, 428, 5883, 3209, 293, 291, 764, 300, 281, 8460, 16949, 13, 51548, 51548, 407, 291, 574, 412, 264, 5598, 295, 300, 3209, 293, 291, 574, 412, 264, 1333, 295, 6687, 294, 51732, 51732, 264, 23930, 281, 8460, 16949, 337, 257, 1150, 3209, 13, 51860, 51860], "temperature": 0.0, "avg_logprob": -0.1987482990537371, "compression_ratio": 1.794007490636704, "no_speech_prob": 1.5935775081743486e-05}, {"id": 1045, "seek": 418620, "start": 4197.96, "end": 4203.84, "text": " In the sort of blue line, we experimented with this technique called model distillation,", "tokens": [50364, 400, 341, 307, 406, 8830, 11, 570, 382, 428, 16949, 1813, 1570, 293, 1570, 12924, 11, 295, 1164, 11, 50630, 50630, 428, 10290, 3125, 307, 516, 281, 9753, 13, 50740, 50740, 407, 300, 1333, 295, 1709, 760, 588, 2661, 13, 50952, 50952, 682, 264, 1333, 295, 3344, 1622, 11, 321, 5120, 292, 365, 341, 6532, 1219, 2316, 42923, 399, 11, 51246, 51246, 689, 291, 747, 428, 5883, 3209, 293, 291, 764, 300, 281, 8460, 16949, 13, 51548, 51548, 407, 291, 574, 412, 264, 5598, 295, 300, 3209, 293, 291, 574, 412, 264, 1333, 295, 6687, 294, 51732, 51732, 264, 23930, 281, 8460, 16949, 337, 257, 1150, 3209, 13, 51860, 51860], "temperature": 0.0, "avg_logprob": -0.1987482990537371, "compression_ratio": 1.794007490636704, "no_speech_prob": 1.5935775081743486e-05}, {"id": 1046, "seek": 418620, "start": 4203.84, "end": 4209.88, "text": " where you take your initial network and you use that to generate labels.", "tokens": [50364, 400, 341, 307, 406, 8830, 11, 570, 382, 428, 16949, 1813, 1570, 293, 1570, 12924, 11, 295, 1164, 11, 50630, 50630, 428, 10290, 3125, 307, 516, 281, 9753, 13, 50740, 50740, 407, 300, 1333, 295, 1709, 760, 588, 2661, 13, 50952, 50952, 682, 264, 1333, 295, 3344, 1622, 11, 321, 5120, 292, 365, 341, 6532, 1219, 2316, 42923, 399, 11, 51246, 51246, 689, 291, 747, 428, 5883, 3209, 293, 291, 764, 300, 281, 8460, 16949, 13, 51548, 51548, 407, 291, 574, 412, 264, 5598, 295, 300, 3209, 293, 291, 574, 412, 264, 1333, 295, 6687, 294, 51732, 51732, 264, 23930, 281, 8460, 16949, 337, 257, 1150, 3209, 13, 51860, 51860], "temperature": 0.0, "avg_logprob": -0.1987482990537371, "compression_ratio": 1.794007490636704, "no_speech_prob": 1.5935775081743486e-05}, {"id": 1047, "seek": 418620, "start": 4209.88, "end": 4213.5599999999995, "text": " So you look at the output of that network and you look at the sort of confidence in", "tokens": [50364, 400, 341, 307, 406, 8830, 11, 570, 382, 428, 16949, 1813, 1570, 293, 1570, 12924, 11, 295, 1164, 11, 50630, 50630, 428, 10290, 3125, 307, 516, 281, 9753, 13, 50740, 50740, 407, 300, 1333, 295, 1709, 760, 588, 2661, 13, 50952, 50952, 682, 264, 1333, 295, 3344, 1622, 11, 321, 5120, 292, 365, 341, 6532, 1219, 2316, 42923, 399, 11, 51246, 51246, 689, 291, 747, 428, 5883, 3209, 293, 291, 764, 300, 281, 8460, 16949, 13, 51548, 51548, 407, 291, 574, 412, 264, 5598, 295, 300, 3209, 293, 291, 574, 412, 264, 1333, 295, 6687, 294, 51732, 51732, 264, 23930, 281, 8460, 16949, 337, 257, 1150, 3209, 13, 51860, 51860], "temperature": 0.0, "avg_logprob": -0.1987482990537371, "compression_ratio": 1.794007490636704, "no_speech_prob": 1.5935775081743486e-05}, {"id": 1048, "seek": 418620, "start": 4213.5599999999995, "end": 4216.12, "text": " the outputs to generate labels for a second network.", "tokens": [50364, 400, 341, 307, 406, 8830, 11, 570, 382, 428, 16949, 1813, 1570, 293, 1570, 12924, 11, 295, 1164, 11, 50630, 50630, 428, 10290, 3125, 307, 516, 281, 9753, 13, 50740, 50740, 407, 300, 1333, 295, 1709, 760, 588, 2661, 13, 50952, 50952, 682, 264, 1333, 295, 3344, 1622, 11, 321, 5120, 292, 365, 341, 6532, 1219, 2316, 42923, 399, 11, 51246, 51246, 689, 291, 747, 428, 5883, 3209, 293, 291, 764, 300, 281, 8460, 16949, 13, 51548, 51548, 407, 291, 574, 412, 264, 5598, 295, 300, 3209, 293, 291, 574, 412, 264, 1333, 295, 6687, 294, 51732, 51732, 264, 23930, 281, 8460, 16949, 337, 257, 1150, 3209, 13, 51860, 51860], "temperature": 0.0, "avg_logprob": -0.1987482990537371, "compression_ratio": 1.794007490636704, "no_speech_prob": 1.5935775081743486e-05}, {"id": 1049, "seek": 421612, "start": 4216.12, "end": 4217.96, "text": " And that's called model distillation.", "tokens": [50364, 400, 300, 311, 1219, 2316, 42923, 399, 13, 50456, 50456, 407, 2316, 42923, 399, 5101, 26213, 1101, 813, 264, 659, 12, 17227, 2001, 3209, 13, 50668, 50668, 400, 291, 393, 536, 300, 439, 2108, 13, 50750, 50750, 407, 382, 264, 2372, 295, 7645, 5658, 8637, 11, 264, 42923, 399, 2316, 767, 307, 709, 1101, 50975, 50975, 813, 264, 3380, 2316, 13, 51122, 51122, 400, 2721, 11, 3030, 264, 917, 11, 321, 362, 13630, 3318, 13, 51238, 51238, 407, 300, 311, 264, 3092, 1622, 13, 51308, 51308, 400, 291, 393, 536, 300, 264, 13630, 3318, 2316, 307, 14961, 1101, 813, 1936, 604, 51570, 51570, 295, 613, 7150, 11, 2139, 42923, 399, 420, 659, 12, 17227, 1760, 11, 293, 14961, 2709, 1101, 3542, 294, 51854, 51854], "temperature": 0.0, "avg_logprob": -0.10476371977064344, "compression_ratio": 1.9885496183206106, "no_speech_prob": 5.422106823971262e-06}, {"id": 1050, "seek": 421612, "start": 4217.96, "end": 4222.2, "text": " So model distillation generally performs better than the pre-trained network.", "tokens": [50364, 400, 300, 311, 1219, 2316, 42923, 399, 13, 50456, 50456, 407, 2316, 42923, 399, 5101, 26213, 1101, 813, 264, 659, 12, 17227, 2001, 3209, 13, 50668, 50668, 400, 291, 393, 536, 300, 439, 2108, 13, 50750, 50750, 407, 382, 264, 2372, 295, 7645, 5658, 8637, 11, 264, 42923, 399, 2316, 767, 307, 709, 1101, 50975, 50975, 813, 264, 3380, 2316, 13, 51122, 51122, 400, 2721, 11, 3030, 264, 917, 11, 321, 362, 13630, 3318, 13, 51238, 51238, 407, 300, 311, 264, 3092, 1622, 13, 51308, 51308, 400, 291, 393, 536, 300, 264, 13630, 3318, 2316, 307, 14961, 1101, 813, 1936, 604, 51570, 51570, 295, 613, 7150, 11, 2139, 42923, 399, 420, 659, 12, 17227, 1760, 11, 293, 14961, 2709, 1101, 3542, 294, 51854, 51854], "temperature": 0.0, "avg_logprob": -0.10476371977064344, "compression_ratio": 1.9885496183206106, "no_speech_prob": 5.422106823971262e-06}, {"id": 1051, "seek": 421612, "start": 4222.2, "end": 4223.84, "text": " And you can see that all across.", "tokens": [50364, 400, 300, 311, 1219, 2316, 42923, 399, 13, 50456, 50456, 407, 2316, 42923, 399, 5101, 26213, 1101, 813, 264, 659, 12, 17227, 2001, 3209, 13, 50668, 50668, 400, 291, 393, 536, 300, 439, 2108, 13, 50750, 50750, 407, 382, 264, 2372, 295, 7645, 5658, 8637, 11, 264, 42923, 399, 2316, 767, 307, 709, 1101, 50975, 50975, 813, 264, 3380, 2316, 13, 51122, 51122, 400, 2721, 11, 3030, 264, 917, 11, 321, 362, 13630, 3318, 13, 51238, 51238, 407, 300, 311, 264, 3092, 1622, 13, 51308, 51308, 400, 291, 393, 536, 300, 264, 13630, 3318, 2316, 307, 14961, 1101, 813, 1936, 604, 51570, 51570, 295, 613, 7150, 11, 2139, 42923, 399, 420, 659, 12, 17227, 1760, 11, 293, 14961, 2709, 1101, 3542, 294, 51854, 51854], "temperature": 0.0, "avg_logprob": -0.10476371977064344, "compression_ratio": 1.9885496183206106, "no_speech_prob": 5.422106823971262e-06}, {"id": 1052, "seek": 421612, "start": 4223.84, "end": 4228.34, "text": " So as the amount of label noise increases, the distillation model actually is much better", "tokens": [50364, 400, 300, 311, 1219, 2316, 42923, 399, 13, 50456, 50456, 407, 2316, 42923, 399, 5101, 26213, 1101, 813, 264, 659, 12, 17227, 2001, 3209, 13, 50668, 50668, 400, 291, 393, 536, 300, 439, 2108, 13, 50750, 50750, 407, 382, 264, 2372, 295, 7645, 5658, 8637, 11, 264, 42923, 399, 2316, 767, 307, 709, 1101, 50975, 50975, 813, 264, 3380, 2316, 13, 51122, 51122, 400, 2721, 11, 3030, 264, 917, 11, 321, 362, 13630, 3318, 13, 51238, 51238, 407, 300, 311, 264, 3092, 1622, 13, 51308, 51308, 400, 291, 393, 536, 300, 264, 13630, 3318, 2316, 307, 14961, 1101, 813, 1936, 604, 51570, 51570, 295, 613, 7150, 11, 2139, 42923, 399, 420, 659, 12, 17227, 1760, 11, 293, 14961, 2709, 1101, 3542, 294, 51854, 51854], "temperature": 0.0, "avg_logprob": -0.10476371977064344, "compression_ratio": 1.9885496183206106, "no_speech_prob": 5.422106823971262e-06}, {"id": 1053, "seek": 421612, "start": 4228.34, "end": 4231.28, "text": " than the original model.", "tokens": [50364, 400, 300, 311, 1219, 2316, 42923, 399, 13, 50456, 50456, 407, 2316, 42923, 399, 5101, 26213, 1101, 813, 264, 659, 12, 17227, 2001, 3209, 13, 50668, 50668, 400, 291, 393, 536, 300, 439, 2108, 13, 50750, 50750, 407, 382, 264, 2372, 295, 7645, 5658, 8637, 11, 264, 42923, 399, 2316, 767, 307, 709, 1101, 50975, 50975, 813, 264, 3380, 2316, 13, 51122, 51122, 400, 2721, 11, 3030, 264, 917, 11, 321, 362, 13630, 3318, 13, 51238, 51238, 407, 300, 311, 264, 3092, 1622, 13, 51308, 51308, 400, 291, 393, 536, 300, 264, 13630, 3318, 2316, 307, 14961, 1101, 813, 1936, 604, 51570, 51570, 295, 613, 7150, 11, 2139, 42923, 399, 420, 659, 12, 17227, 1760, 11, 293, 14961, 2709, 1101, 3542, 294, 51854, 51854], "temperature": 0.0, "avg_logprob": -0.10476371977064344, "compression_ratio": 1.9885496183206106, "no_speech_prob": 5.422106823971262e-06}, {"id": 1054, "seek": 421612, "start": 4231.28, "end": 4233.599999999999, "text": " And finally, towards the end, we have cluster fit.", "tokens": [50364, 400, 300, 311, 1219, 2316, 42923, 399, 13, 50456, 50456, 407, 2316, 42923, 399, 5101, 26213, 1101, 813, 264, 659, 12, 17227, 2001, 3209, 13, 50668, 50668, 400, 291, 393, 536, 300, 439, 2108, 13, 50750, 50750, 407, 382, 264, 2372, 295, 7645, 5658, 8637, 11, 264, 42923, 399, 2316, 767, 307, 709, 1101, 50975, 50975, 813, 264, 3380, 2316, 13, 51122, 51122, 400, 2721, 11, 3030, 264, 917, 11, 321, 362, 13630, 3318, 13, 51238, 51238, 407, 300, 311, 264, 3092, 1622, 13, 51308, 51308, 400, 291, 393, 536, 300, 264, 13630, 3318, 2316, 307, 14961, 1101, 813, 1936, 604, 51570, 51570, 295, 613, 7150, 11, 2139, 42923, 399, 420, 659, 12, 17227, 1760, 11, 293, 14961, 2709, 1101, 3542, 294, 51854, 51854], "temperature": 0.0, "avg_logprob": -0.10476371977064344, "compression_ratio": 1.9885496183206106, "no_speech_prob": 5.422106823971262e-06}, {"id": 1055, "seek": 421612, "start": 4233.599999999999, "end": 4235.0, "text": " So that's the green line.", "tokens": [50364, 400, 300, 311, 1219, 2316, 42923, 399, 13, 50456, 50456, 407, 2316, 42923, 399, 5101, 26213, 1101, 813, 264, 659, 12, 17227, 2001, 3209, 13, 50668, 50668, 400, 291, 393, 536, 300, 439, 2108, 13, 50750, 50750, 407, 382, 264, 2372, 295, 7645, 5658, 8637, 11, 264, 42923, 399, 2316, 767, 307, 709, 1101, 50975, 50975, 813, 264, 3380, 2316, 13, 51122, 51122, 400, 2721, 11, 3030, 264, 917, 11, 321, 362, 13630, 3318, 13, 51238, 51238, 407, 300, 311, 264, 3092, 1622, 13, 51308, 51308, 400, 291, 393, 536, 300, 264, 13630, 3318, 2316, 307, 14961, 1101, 813, 1936, 604, 51570, 51570, 295, 613, 7150, 11, 2139, 42923, 399, 420, 659, 12, 17227, 1760, 11, 293, 14961, 2709, 1101, 3542, 294, 51854, 51854], "temperature": 0.0, "avg_logprob": -0.10476371977064344, "compression_ratio": 1.9885496183206106, "no_speech_prob": 5.422106823971262e-06}, {"id": 1056, "seek": 421612, "start": 4235.0, "end": 4240.24, "text": " And you can see that the cluster fit model is consistently better than basically any", "tokens": [50364, 400, 300, 311, 1219, 2316, 42923, 399, 13, 50456, 50456, 407, 2316, 42923, 399, 5101, 26213, 1101, 813, 264, 659, 12, 17227, 2001, 3209, 13, 50668, 50668, 400, 291, 393, 536, 300, 439, 2108, 13, 50750, 50750, 407, 382, 264, 2372, 295, 7645, 5658, 8637, 11, 264, 42923, 399, 2316, 767, 307, 709, 1101, 50975, 50975, 813, 264, 3380, 2316, 13, 51122, 51122, 400, 2721, 11, 3030, 264, 917, 11, 321, 362, 13630, 3318, 13, 51238, 51238, 407, 300, 311, 264, 3092, 1622, 13, 51308, 51308, 400, 291, 393, 536, 300, 264, 13630, 3318, 2316, 307, 14961, 1101, 813, 1936, 604, 51570, 51570, 295, 613, 7150, 11, 2139, 42923, 399, 420, 659, 12, 17227, 1760, 11, 293, 14961, 2709, 1101, 3542, 294, 51854, 51854], "temperature": 0.0, "avg_logprob": -0.10476371977064344, "compression_ratio": 1.9885496183206106, "no_speech_prob": 5.422106823971262e-06}, {"id": 1057, "seek": 421612, "start": 4240.24, "end": 4245.92, "text": " of these methods, either distillation or pre-training, and consistently gives better results in", "tokens": [50364, 400, 300, 311, 1219, 2316, 42923, 399, 13, 50456, 50456, 407, 2316, 42923, 399, 5101, 26213, 1101, 813, 264, 659, 12, 17227, 2001, 3209, 13, 50668, 50668, 400, 291, 393, 536, 300, 439, 2108, 13, 50750, 50750, 407, 382, 264, 2372, 295, 7645, 5658, 8637, 11, 264, 42923, 399, 2316, 767, 307, 709, 1101, 50975, 50975, 813, 264, 3380, 2316, 13, 51122, 51122, 400, 2721, 11, 3030, 264, 917, 11, 321, 362, 13630, 3318, 13, 51238, 51238, 407, 300, 311, 264, 3092, 1622, 13, 51308, 51308, 400, 291, 393, 536, 300, 264, 13630, 3318, 2316, 307, 14961, 1101, 813, 1936, 604, 51570, 51570, 295, 613, 7150, 11, 2139, 42923, 399, 420, 659, 12, 17227, 1760, 11, 293, 14961, 2709, 1101, 3542, 294, 51854, 51854], "temperature": 0.0, "avg_logprob": -0.10476371977064344, "compression_ratio": 1.9885496183206106, "no_speech_prob": 5.422106823971262e-06}, {"id": 1058, "seek": 424592, "start": 4245.92, "end": 4250.56, "text": " including when you have zero label noise, which is basically when you have a pre-trained", "tokens": [50364, 3009, 562, 291, 362, 4018, 7645, 5658, 11, 597, 307, 1936, 562, 291, 362, 257, 659, 12, 17227, 2001, 50596, 50596, 3256, 2533, 3209, 13, 50942, 50942, 407, 321, 6456, 13, 50992, 50992, 14464, 11, 393, 291, 20945, 322, 264, 2649, 1296, 42923, 399, 293, 13630, 3318, 1564, 51218, 51218, 544, 30, 51268, 51268, 1079, 13, 51318, 51318, 407, 294, 42923, 399, 11, 286, 603, 352, 646, 281, 341, 3036, 13, 51478, 51478, 1079, 13, 51528, 51528, 407, 294, 42923, 399, 11, 437, 291, 576, 360, 307, 291, 576, 1936, 11, 370, 294, 341, 700, 1823, 11, 291, 51770, 51770], "temperature": 0.0, "avg_logprob": -0.1719671698177562, "compression_ratio": 1.6820276497695852, "no_speech_prob": 3.0241048079915345e-05}, {"id": 1059, "seek": 424592, "start": 4250.56, "end": 4257.4800000000005, "text": " image net network.", "tokens": [50364, 3009, 562, 291, 362, 4018, 7645, 5658, 11, 597, 307, 1936, 562, 291, 362, 257, 659, 12, 17227, 2001, 50596, 50596, 3256, 2533, 3209, 13, 50942, 50942, 407, 321, 6456, 13, 50992, 50992, 14464, 11, 393, 291, 20945, 322, 264, 2649, 1296, 42923, 399, 293, 13630, 3318, 1564, 51218, 51218, 544, 30, 51268, 51268, 1079, 13, 51318, 51318, 407, 294, 42923, 399, 11, 286, 603, 352, 646, 281, 341, 3036, 13, 51478, 51478, 1079, 13, 51528, 51528, 407, 294, 42923, 399, 11, 437, 291, 576, 360, 307, 291, 576, 1936, 11, 370, 294, 341, 700, 1823, 11, 291, 51770, 51770], "temperature": 0.0, "avg_logprob": -0.1719671698177562, "compression_ratio": 1.6820276497695852, "no_speech_prob": 3.0241048079915345e-05}, {"id": 1060, "seek": 424592, "start": 4257.4800000000005, "end": 4258.4800000000005, "text": " So we applied.", "tokens": [50364, 3009, 562, 291, 362, 4018, 7645, 5658, 11, 597, 307, 1936, 562, 291, 362, 257, 659, 12, 17227, 2001, 50596, 50596, 3256, 2533, 3209, 13, 50942, 50942, 407, 321, 6456, 13, 50992, 50992, 14464, 11, 393, 291, 20945, 322, 264, 2649, 1296, 42923, 399, 293, 13630, 3318, 1564, 51218, 51218, 544, 30, 51268, 51268, 1079, 13, 51318, 51318, 407, 294, 42923, 399, 11, 286, 603, 352, 646, 281, 341, 3036, 13, 51478, 51478, 1079, 13, 51528, 51528, 407, 294, 42923, 399, 11, 437, 291, 576, 360, 307, 291, 576, 1936, 11, 370, 294, 341, 700, 1823, 11, 291, 51770, 51770], "temperature": 0.0, "avg_logprob": -0.1719671698177562, "compression_ratio": 1.6820276497695852, "no_speech_prob": 3.0241048079915345e-05}, {"id": 1061, "seek": 424592, "start": 4258.4800000000005, "end": 4263.0, "text": " Question, can you elaborate on the difference between distillation and cluster fit once", "tokens": [50364, 3009, 562, 291, 362, 4018, 7645, 5658, 11, 597, 307, 1936, 562, 291, 362, 257, 659, 12, 17227, 2001, 50596, 50596, 3256, 2533, 3209, 13, 50942, 50942, 407, 321, 6456, 13, 50992, 50992, 14464, 11, 393, 291, 20945, 322, 264, 2649, 1296, 42923, 399, 293, 13630, 3318, 1564, 51218, 51218, 544, 30, 51268, 51268, 1079, 13, 51318, 51318, 407, 294, 42923, 399, 11, 286, 603, 352, 646, 281, 341, 3036, 13, 51478, 51478, 1079, 13, 51528, 51528, 407, 294, 42923, 399, 11, 437, 291, 576, 360, 307, 291, 576, 1936, 11, 370, 294, 341, 700, 1823, 11, 291, 51770, 51770], "temperature": 0.0, "avg_logprob": -0.1719671698177562, "compression_ratio": 1.6820276497695852, "no_speech_prob": 3.0241048079915345e-05}, {"id": 1062, "seek": 424592, "start": 4263.0, "end": 4264.0, "text": " more?", "tokens": [50364, 3009, 562, 291, 362, 4018, 7645, 5658, 11, 597, 307, 1936, 562, 291, 362, 257, 659, 12, 17227, 2001, 50596, 50596, 3256, 2533, 3209, 13, 50942, 50942, 407, 321, 6456, 13, 50992, 50992, 14464, 11, 393, 291, 20945, 322, 264, 2649, 1296, 42923, 399, 293, 13630, 3318, 1564, 51218, 51218, 544, 30, 51268, 51268, 1079, 13, 51318, 51318, 407, 294, 42923, 399, 11, 286, 603, 352, 646, 281, 341, 3036, 13, 51478, 51478, 1079, 13, 51528, 51528, 407, 294, 42923, 399, 11, 437, 291, 576, 360, 307, 291, 576, 1936, 11, 370, 294, 341, 700, 1823, 11, 291, 51770, 51770], "temperature": 0.0, "avg_logprob": -0.1719671698177562, "compression_ratio": 1.6820276497695852, "no_speech_prob": 3.0241048079915345e-05}, {"id": 1063, "seek": 424592, "start": 4264.0, "end": 4265.0, "text": " Yes.", "tokens": [50364, 3009, 562, 291, 362, 4018, 7645, 5658, 11, 597, 307, 1936, 562, 291, 362, 257, 659, 12, 17227, 2001, 50596, 50596, 3256, 2533, 3209, 13, 50942, 50942, 407, 321, 6456, 13, 50992, 50992, 14464, 11, 393, 291, 20945, 322, 264, 2649, 1296, 42923, 399, 293, 13630, 3318, 1564, 51218, 51218, 544, 30, 51268, 51268, 1079, 13, 51318, 51318, 407, 294, 42923, 399, 11, 286, 603, 352, 646, 281, 341, 3036, 13, 51478, 51478, 1079, 13, 51528, 51528, 407, 294, 42923, 399, 11, 437, 291, 576, 360, 307, 291, 576, 1936, 11, 370, 294, 341, 700, 1823, 11, 291, 51770, 51770], "temperature": 0.0, "avg_logprob": -0.1719671698177562, "compression_ratio": 1.6820276497695852, "no_speech_prob": 3.0241048079915345e-05}, {"id": 1064, "seek": 424592, "start": 4265.0, "end": 4268.2, "text": " So in distillation, I'll go back to this picture.", "tokens": [50364, 3009, 562, 291, 362, 4018, 7645, 5658, 11, 597, 307, 1936, 562, 291, 362, 257, 659, 12, 17227, 2001, 50596, 50596, 3256, 2533, 3209, 13, 50942, 50942, 407, 321, 6456, 13, 50992, 50992, 14464, 11, 393, 291, 20945, 322, 264, 2649, 1296, 42923, 399, 293, 13630, 3318, 1564, 51218, 51218, 544, 30, 51268, 51268, 1079, 13, 51318, 51318, 407, 294, 42923, 399, 11, 286, 603, 352, 646, 281, 341, 3036, 13, 51478, 51478, 1079, 13, 51528, 51528, 407, 294, 42923, 399, 11, 437, 291, 576, 360, 307, 291, 576, 1936, 11, 370, 294, 341, 700, 1823, 11, 291, 51770, 51770], "temperature": 0.0, "avg_logprob": -0.1719671698177562, "compression_ratio": 1.6820276497695852, "no_speech_prob": 3.0241048079915345e-05}, {"id": 1065, "seek": 424592, "start": 4268.2, "end": 4269.2, "text": " Yes.", "tokens": [50364, 3009, 562, 291, 362, 4018, 7645, 5658, 11, 597, 307, 1936, 562, 291, 362, 257, 659, 12, 17227, 2001, 50596, 50596, 3256, 2533, 3209, 13, 50942, 50942, 407, 321, 6456, 13, 50992, 50992, 14464, 11, 393, 291, 20945, 322, 264, 2649, 1296, 42923, 399, 293, 13630, 3318, 1564, 51218, 51218, 544, 30, 51268, 51268, 1079, 13, 51318, 51318, 407, 294, 42923, 399, 11, 286, 603, 352, 646, 281, 341, 3036, 13, 51478, 51478, 1079, 13, 51528, 51528, 407, 294, 42923, 399, 11, 437, 291, 576, 360, 307, 291, 576, 1936, 11, 370, 294, 341, 700, 1823, 11, 291, 51770, 51770], "temperature": 0.0, "avg_logprob": -0.1719671698177562, "compression_ratio": 1.6820276497695852, "no_speech_prob": 3.0241048079915345e-05}, {"id": 1066, "seek": 424592, "start": 4269.2, "end": 4274.04, "text": " So in distillation, what you would do is you would basically, so in this first step, you", "tokens": [50364, 3009, 562, 291, 362, 4018, 7645, 5658, 11, 597, 307, 1936, 562, 291, 362, 257, 659, 12, 17227, 2001, 50596, 50596, 3256, 2533, 3209, 13, 50942, 50942, 407, 321, 6456, 13, 50992, 50992, 14464, 11, 393, 291, 20945, 322, 264, 2649, 1296, 42923, 399, 293, 13630, 3318, 1564, 51218, 51218, 544, 30, 51268, 51268, 1079, 13, 51318, 51318, 407, 294, 42923, 399, 11, 286, 603, 352, 646, 281, 341, 3036, 13, 51478, 51478, 1079, 13, 51528, 51528, 407, 294, 42923, 399, 11, 437, 291, 576, 360, 307, 291, 576, 1936, 11, 370, 294, 341, 700, 1823, 11, 291, 51770, 51770], "temperature": 0.0, "avg_logprob": -0.1719671698177562, "compression_ratio": 1.6820276497695852, "no_speech_prob": 3.0241048079915345e-05}, {"id": 1067, "seek": 427404, "start": 4274.04, "end": 4279.72, "text": " would take the pre-trained network and you would use the labels this network is predicting.", "tokens": [50364, 576, 747, 264, 659, 12, 17227, 2001, 3209, 293, 291, 576, 764, 264, 16949, 341, 3209, 307, 32884, 13, 50648, 50648, 407, 584, 264, 3209, 1936, 6069, 82, 9714, 5359, 13, 50852, 50852, 407, 291, 1936, 764, 729, 16949, 294, 257, 23119, 6700, 281, 8460, 16949, 337, 428, 5267, 13, 51236, 51236, 407, 584, 264, 3209, 390, 8895, 281, 6069, 2319, 819, 3467, 295, 7197, 13, 51502, 51502, 407, 291, 747, 428, 5267, 293, 291, 483, 257, 7316, 670, 264, 2319, 819, 3467, 295, 7197, 293, 764, 51768, 51768], "temperature": 0.0, "avg_logprob": -0.11017042725950807, "compression_ratio": 1.9704433497536946, "no_speech_prob": 1.5688954590586945e-05}, {"id": 1068, "seek": 427404, "start": 4279.72, "end": 4283.8, "text": " So say the network basically predicts 1000 classes.", "tokens": [50364, 576, 747, 264, 659, 12, 17227, 2001, 3209, 293, 291, 576, 764, 264, 16949, 341, 3209, 307, 32884, 13, 50648, 50648, 407, 584, 264, 3209, 1936, 6069, 82, 9714, 5359, 13, 50852, 50852, 407, 291, 1936, 764, 729, 16949, 294, 257, 23119, 6700, 281, 8460, 16949, 337, 428, 5267, 13, 51236, 51236, 407, 584, 264, 3209, 390, 8895, 281, 6069, 2319, 819, 3467, 295, 7197, 13, 51502, 51502, 407, 291, 747, 428, 5267, 293, 291, 483, 257, 7316, 670, 264, 2319, 819, 3467, 295, 7197, 293, 764, 51768, 51768], "temperature": 0.0, "avg_logprob": -0.11017042725950807, "compression_ratio": 1.9704433497536946, "no_speech_prob": 1.5688954590586945e-05}, {"id": 1069, "seek": 427404, "start": 4283.8, "end": 4291.48, "text": " So you basically use those labels in a softer fashion to generate labels for your images.", "tokens": [50364, 576, 747, 264, 659, 12, 17227, 2001, 3209, 293, 291, 576, 764, 264, 16949, 341, 3209, 307, 32884, 13, 50648, 50648, 407, 584, 264, 3209, 1936, 6069, 82, 9714, 5359, 13, 50852, 50852, 407, 291, 1936, 764, 729, 16949, 294, 257, 23119, 6700, 281, 8460, 16949, 337, 428, 5267, 13, 51236, 51236, 407, 584, 264, 3209, 390, 8895, 281, 6069, 2319, 819, 3467, 295, 7197, 13, 51502, 51502, 407, 291, 747, 428, 5267, 293, 291, 483, 257, 7316, 670, 264, 2319, 819, 3467, 295, 7197, 293, 764, 51768, 51768], "temperature": 0.0, "avg_logprob": -0.11017042725950807, "compression_ratio": 1.9704433497536946, "no_speech_prob": 1.5688954590586945e-05}, {"id": 1070, "seek": 427404, "start": 4291.48, "end": 4296.8, "text": " So say the network was trained to predict 100 different types of dogs.", "tokens": [50364, 576, 747, 264, 659, 12, 17227, 2001, 3209, 293, 291, 576, 764, 264, 16949, 341, 3209, 307, 32884, 13, 50648, 50648, 407, 584, 264, 3209, 1936, 6069, 82, 9714, 5359, 13, 50852, 50852, 407, 291, 1936, 764, 729, 16949, 294, 257, 23119, 6700, 281, 8460, 16949, 337, 428, 5267, 13, 51236, 51236, 407, 584, 264, 3209, 390, 8895, 281, 6069, 2319, 819, 3467, 295, 7197, 13, 51502, 51502, 407, 291, 747, 428, 5267, 293, 291, 483, 257, 7316, 670, 264, 2319, 819, 3467, 295, 7197, 293, 764, 51768, 51768], "temperature": 0.0, "avg_logprob": -0.11017042725950807, "compression_ratio": 1.9704433497536946, "no_speech_prob": 1.5688954590586945e-05}, {"id": 1071, "seek": 427404, "start": 4296.8, "end": 4302.12, "text": " So you take your images and you get a distribution over the 100 different types of dogs and use", "tokens": [50364, 576, 747, 264, 659, 12, 17227, 2001, 3209, 293, 291, 576, 764, 264, 16949, 341, 3209, 307, 32884, 13, 50648, 50648, 407, 584, 264, 3209, 1936, 6069, 82, 9714, 5359, 13, 50852, 50852, 407, 291, 1936, 764, 729, 16949, 294, 257, 23119, 6700, 281, 8460, 16949, 337, 428, 5267, 13, 51236, 51236, 407, 584, 264, 3209, 390, 8895, 281, 6069, 2319, 819, 3467, 295, 7197, 13, 51502, 51502, 407, 291, 747, 428, 5267, 293, 291, 483, 257, 7316, 670, 264, 2319, 819, 3467, 295, 7197, 293, 764, 51768, 51768], "temperature": 0.0, "avg_logprob": -0.11017042725950807, "compression_ratio": 1.9704433497536946, "no_speech_prob": 1.5688954590586945e-05}, {"id": 1072, "seek": 430212, "start": 4302.12, "end": 4304.72, "text": " that distribution to train your second network.", "tokens": [50364, 300, 7316, 281, 3847, 428, 1150, 3209, 13, 50494, 50494, 13813, 294, 13630, 3318, 11, 291, 500, 380, 534, 1127, 466, 264, 7645, 1901, 420, 264, 1333, 295, 5598, 50808, 50808, 1901, 295, 264, 659, 12, 17227, 2001, 3209, 13, 50878, 50878, 509, 787, 574, 412, 264, 4122, 13, 50928, 50928, 509, 500, 380, 754, 574, 412, 264, 1036, 4498, 4582, 4583, 13, 51058, 51058, 509, 445, 574, 412, 264, 3894, 4122, 13, 51206, 51206, 5803, 309, 13, 51308, 51308, 2743, 11, 983, 576, 264, 23119, 7316, 854, 365, 3097, 30, 51484, 51484, 1743, 983, 576, 3097, 322, 341, 312, 4254, 30, 51628, 51628, 708, 311, 264, 24002, 2261, 42923, 399, 30, 51754, 51754], "temperature": 0.0, "avg_logprob": -0.25932724722500505, "compression_ratio": 1.814516129032258, "no_speech_prob": 5.255290034256177e-06}, {"id": 1073, "seek": 430212, "start": 4304.72, "end": 4311.0, "text": " Whereas in cluster fit, you don't really care about the label space or the sort of output", "tokens": [50364, 300, 7316, 281, 3847, 428, 1150, 3209, 13, 50494, 50494, 13813, 294, 13630, 3318, 11, 291, 500, 380, 534, 1127, 466, 264, 7645, 1901, 420, 264, 1333, 295, 5598, 50808, 50808, 1901, 295, 264, 659, 12, 17227, 2001, 3209, 13, 50878, 50878, 509, 787, 574, 412, 264, 4122, 13, 50928, 50928, 509, 500, 380, 754, 574, 412, 264, 1036, 4498, 4582, 4583, 13, 51058, 51058, 509, 445, 574, 412, 264, 3894, 4122, 13, 51206, 51206, 5803, 309, 13, 51308, 51308, 2743, 11, 983, 576, 264, 23119, 7316, 854, 365, 3097, 30, 51484, 51484, 1743, 983, 576, 3097, 322, 341, 312, 4254, 30, 51628, 51628, 708, 311, 264, 24002, 2261, 42923, 399, 30, 51754, 51754], "temperature": 0.0, "avg_logprob": -0.25932724722500505, "compression_ratio": 1.814516129032258, "no_speech_prob": 5.255290034256177e-06}, {"id": 1074, "seek": 430212, "start": 4311.0, "end": 4312.4, "text": " space of the pre-trained network.", "tokens": [50364, 300, 7316, 281, 3847, 428, 1150, 3209, 13, 50494, 50494, 13813, 294, 13630, 3318, 11, 291, 500, 380, 534, 1127, 466, 264, 7645, 1901, 420, 264, 1333, 295, 5598, 50808, 50808, 1901, 295, 264, 659, 12, 17227, 2001, 3209, 13, 50878, 50878, 509, 787, 574, 412, 264, 4122, 13, 50928, 50928, 509, 500, 380, 754, 574, 412, 264, 1036, 4498, 4582, 4583, 13, 51058, 51058, 509, 445, 574, 412, 264, 3894, 4122, 13, 51206, 51206, 5803, 309, 13, 51308, 51308, 2743, 11, 983, 576, 264, 23119, 7316, 854, 365, 3097, 30, 51484, 51484, 1743, 983, 576, 3097, 322, 341, 312, 4254, 30, 51628, 51628, 708, 311, 264, 24002, 2261, 42923, 399, 30, 51754, 51754], "temperature": 0.0, "avg_logprob": -0.25932724722500505, "compression_ratio": 1.814516129032258, "no_speech_prob": 5.255290034256177e-06}, {"id": 1075, "seek": 430212, "start": 4312.4, "end": 4313.4, "text": " You only look at the features.", "tokens": [50364, 300, 7316, 281, 3847, 428, 1150, 3209, 13, 50494, 50494, 13813, 294, 13630, 3318, 11, 291, 500, 380, 534, 1127, 466, 264, 7645, 1901, 420, 264, 1333, 295, 5598, 50808, 50808, 1901, 295, 264, 659, 12, 17227, 2001, 3209, 13, 50878, 50878, 509, 787, 574, 412, 264, 4122, 13, 50928, 50928, 509, 500, 380, 754, 574, 412, 264, 1036, 4498, 4582, 4583, 13, 51058, 51058, 509, 445, 574, 412, 264, 3894, 4122, 13, 51206, 51206, 5803, 309, 13, 51308, 51308, 2743, 11, 983, 576, 264, 23119, 7316, 854, 365, 3097, 30, 51484, 51484, 1743, 983, 576, 3097, 322, 341, 312, 4254, 30, 51628, 51628, 708, 311, 264, 24002, 2261, 42923, 399, 30, 51754, 51754], "temperature": 0.0, "avg_logprob": -0.25932724722500505, "compression_ratio": 1.814516129032258, "no_speech_prob": 5.255290034256177e-06}, {"id": 1076, "seek": 430212, "start": 4313.4, "end": 4316.0, "text": " You don't even look at the last fully connected layer.", "tokens": [50364, 300, 7316, 281, 3847, 428, 1150, 3209, 13, 50494, 50494, 13813, 294, 13630, 3318, 11, 291, 500, 380, 534, 1127, 466, 264, 7645, 1901, 420, 264, 1333, 295, 5598, 50808, 50808, 1901, 295, 264, 659, 12, 17227, 2001, 3209, 13, 50878, 50878, 509, 787, 574, 412, 264, 4122, 13, 50928, 50928, 509, 500, 380, 754, 574, 412, 264, 1036, 4498, 4582, 4583, 13, 51058, 51058, 509, 445, 574, 412, 264, 3894, 4122, 13, 51206, 51206, 5803, 309, 13, 51308, 51308, 2743, 11, 983, 576, 264, 23119, 7316, 854, 365, 3097, 30, 51484, 51484, 1743, 983, 576, 3097, 322, 341, 312, 4254, 30, 51628, 51628, 708, 311, 264, 24002, 2261, 42923, 399, 30, 51754, 51754], "temperature": 0.0, "avg_logprob": -0.25932724722500505, "compression_ratio": 1.814516129032258, "no_speech_prob": 5.255290034256177e-06}, {"id": 1077, "seek": 430212, "start": 4316.0, "end": 4318.96, "text": " You just look at the previous features.", "tokens": [50364, 300, 7316, 281, 3847, 428, 1150, 3209, 13, 50494, 50494, 13813, 294, 13630, 3318, 11, 291, 500, 380, 534, 1127, 466, 264, 7645, 1901, 420, 264, 1333, 295, 5598, 50808, 50808, 1901, 295, 264, 659, 12, 17227, 2001, 3209, 13, 50878, 50878, 509, 787, 574, 412, 264, 4122, 13, 50928, 50928, 509, 500, 380, 754, 574, 412, 264, 1036, 4498, 4582, 4583, 13, 51058, 51058, 509, 445, 574, 412, 264, 3894, 4122, 13, 51206, 51206, 5803, 309, 13, 51308, 51308, 2743, 11, 983, 576, 264, 23119, 7316, 854, 365, 3097, 30, 51484, 51484, 1743, 983, 576, 3097, 322, 341, 312, 4254, 30, 51628, 51628, 708, 311, 264, 24002, 2261, 42923, 399, 30, 51754, 51754], "temperature": 0.0, "avg_logprob": -0.25932724722500505, "compression_ratio": 1.814516129032258, "no_speech_prob": 5.255290034256177e-06}, {"id": 1078, "seek": 430212, "start": 4318.96, "end": 4321.0, "text": " Got it.", "tokens": [50364, 300, 7316, 281, 3847, 428, 1150, 3209, 13, 50494, 50494, 13813, 294, 13630, 3318, 11, 291, 500, 380, 534, 1127, 466, 264, 7645, 1901, 420, 264, 1333, 295, 5598, 50808, 50808, 1901, 295, 264, 659, 12, 17227, 2001, 3209, 13, 50878, 50878, 509, 787, 574, 412, 264, 4122, 13, 50928, 50928, 509, 500, 380, 754, 574, 412, 264, 1036, 4498, 4582, 4583, 13, 51058, 51058, 509, 445, 574, 412, 264, 3894, 4122, 13, 51206, 51206, 5803, 309, 13, 51308, 51308, 2743, 11, 983, 576, 264, 23119, 7316, 854, 365, 3097, 30, 51484, 51484, 1743, 983, 576, 3097, 322, 341, 312, 4254, 30, 51628, 51628, 708, 311, 264, 24002, 2261, 42923, 399, 30, 51754, 51754], "temperature": 0.0, "avg_logprob": -0.25932724722500505, "compression_ratio": 1.814516129032258, "no_speech_prob": 5.255290034256177e-06}, {"id": 1079, "seek": 430212, "start": 4321.0, "end": 4324.5199999999995, "text": " Also, why would the softer distribution help with training?", "tokens": [50364, 300, 7316, 281, 3847, 428, 1150, 3209, 13, 50494, 50494, 13813, 294, 13630, 3318, 11, 291, 500, 380, 534, 1127, 466, 264, 7645, 1901, 420, 264, 1333, 295, 5598, 50808, 50808, 1901, 295, 264, 659, 12, 17227, 2001, 3209, 13, 50878, 50878, 509, 787, 574, 412, 264, 4122, 13, 50928, 50928, 509, 500, 380, 754, 574, 412, 264, 1036, 4498, 4582, 4583, 13, 51058, 51058, 509, 445, 574, 412, 264, 3894, 4122, 13, 51206, 51206, 5803, 309, 13, 51308, 51308, 2743, 11, 983, 576, 264, 23119, 7316, 854, 365, 3097, 30, 51484, 51484, 1743, 983, 576, 3097, 322, 341, 312, 4254, 30, 51628, 51628, 708, 311, 264, 24002, 2261, 42923, 399, 30, 51754, 51754], "temperature": 0.0, "avg_logprob": -0.25932724722500505, "compression_ratio": 1.814516129032258, "no_speech_prob": 5.255290034256177e-06}, {"id": 1080, "seek": 430212, "start": 4324.5199999999995, "end": 4327.4, "text": " Like why would training on this be helped?", "tokens": [50364, 300, 7316, 281, 3847, 428, 1150, 3209, 13, 50494, 50494, 13813, 294, 13630, 3318, 11, 291, 500, 380, 534, 1127, 466, 264, 7645, 1901, 420, 264, 1333, 295, 5598, 50808, 50808, 1901, 295, 264, 659, 12, 17227, 2001, 3209, 13, 50878, 50878, 509, 787, 574, 412, 264, 4122, 13, 50928, 50928, 509, 500, 380, 754, 574, 412, 264, 1036, 4498, 4582, 4583, 13, 51058, 51058, 509, 445, 574, 412, 264, 3894, 4122, 13, 51206, 51206, 5803, 309, 13, 51308, 51308, 2743, 11, 983, 576, 264, 23119, 7316, 854, 365, 3097, 30, 51484, 51484, 1743, 983, 576, 3097, 322, 341, 312, 4254, 30, 51628, 51628, 708, 311, 264, 24002, 2261, 42923, 399, 30, 51754, 51754], "temperature": 0.0, "avg_logprob": -0.25932724722500505, "compression_ratio": 1.814516129032258, "no_speech_prob": 5.255290034256177e-06}, {"id": 1081, "seek": 430212, "start": 4327.4, "end": 4329.92, "text": " What's the intuition behind distillation?", "tokens": [50364, 300, 7316, 281, 3847, 428, 1150, 3209, 13, 50494, 50494, 13813, 294, 13630, 3318, 11, 291, 500, 380, 534, 1127, 466, 264, 7645, 1901, 420, 264, 1333, 295, 5598, 50808, 50808, 1901, 295, 264, 659, 12, 17227, 2001, 3209, 13, 50878, 50878, 509, 787, 574, 412, 264, 4122, 13, 50928, 50928, 509, 500, 380, 754, 574, 412, 264, 1036, 4498, 4582, 4583, 13, 51058, 51058, 509, 445, 574, 412, 264, 3894, 4122, 13, 51206, 51206, 5803, 309, 13, 51308, 51308, 2743, 11, 983, 576, 264, 23119, 7316, 854, 365, 3097, 30, 51484, 51484, 1743, 983, 576, 3097, 322, 341, 312, 4254, 30, 51628, 51628, 708, 311, 264, 24002, 2261, 42923, 399, 30, 51754, 51754], "temperature": 0.0, "avg_logprob": -0.25932724722500505, "compression_ratio": 1.814516129032258, "no_speech_prob": 5.255290034256177e-06}, {"id": 1082, "seek": 432992, "start": 4329.92, "end": 4334.86, "text": " So distillation's main intuition is basically that if your network was trained really well,", "tokens": [50364, 407, 42923, 399, 311, 2135, 24002, 307, 1936, 300, 498, 428, 3209, 390, 8895, 534, 731, 11, 50611, 50611, 370, 7297, 291, 632, 572, 7645, 5658, 11, 570, 257, 688, 295, 721, 366, 406, 534, 11, 257, 688, 295, 5267, 50996, 50996, 534, 500, 380, 5784, 294, 264, 912, 5359, 13, 51160, 51160, 407, 7297, 428, 1412, 992, 767, 632, 2331, 819, 3467, 295, 7197, 11, 457, 291, 632, 787, 51396, 51396, 2319, 295, 552, 21335, 13, 51486, 51486, 400, 370, 337, 257, 688, 295, 613, 5267, 11, 584, 291, 767, 632, 281, 6269, 11, 291, 632, 281, 1888, 1936, 51760, 51760], "temperature": 0.0, "avg_logprob": -0.1472932375394381, "compression_ratio": 1.75, "no_speech_prob": 6.962084626138676e-06}, {"id": 1083, "seek": 432992, "start": 4334.86, "end": 4342.56, "text": " so suppose you had no label noise, because a lot of things are not really, a lot of images", "tokens": [50364, 407, 42923, 399, 311, 2135, 24002, 307, 1936, 300, 498, 428, 3209, 390, 8895, 534, 731, 11, 50611, 50611, 370, 7297, 291, 632, 572, 7645, 5658, 11, 570, 257, 688, 295, 721, 366, 406, 534, 11, 257, 688, 295, 5267, 50996, 50996, 534, 500, 380, 5784, 294, 264, 912, 5359, 13, 51160, 51160, 407, 7297, 428, 1412, 992, 767, 632, 2331, 819, 3467, 295, 7197, 11, 457, 291, 632, 787, 51396, 51396, 2319, 295, 552, 21335, 13, 51486, 51486, 400, 370, 337, 257, 688, 295, 613, 5267, 11, 584, 291, 767, 632, 281, 6269, 11, 291, 632, 281, 1888, 1936, 51760, 51760], "temperature": 0.0, "avg_logprob": -0.1472932375394381, "compression_ratio": 1.75, "no_speech_prob": 6.962084626138676e-06}, {"id": 1084, "seek": 432992, "start": 4342.56, "end": 4345.84, "text": " really don't belong in the same classes.", "tokens": [50364, 407, 42923, 399, 311, 2135, 24002, 307, 1936, 300, 498, 428, 3209, 390, 8895, 534, 731, 11, 50611, 50611, 370, 7297, 291, 632, 572, 7645, 5658, 11, 570, 257, 688, 295, 721, 366, 406, 534, 11, 257, 688, 295, 5267, 50996, 50996, 534, 500, 380, 5784, 294, 264, 912, 5359, 13, 51160, 51160, 407, 7297, 428, 1412, 992, 767, 632, 2331, 819, 3467, 295, 7197, 11, 457, 291, 632, 787, 51396, 51396, 2319, 295, 552, 21335, 13, 51486, 51486, 400, 370, 337, 257, 688, 295, 613, 5267, 11, 584, 291, 767, 632, 281, 6269, 11, 291, 632, 281, 1888, 1936, 51760, 51760], "temperature": 0.0, "avg_logprob": -0.1472932375394381, "compression_ratio": 1.75, "no_speech_prob": 6.962084626138676e-06}, {"id": 1085, "seek": 432992, "start": 4345.84, "end": 4350.56, "text": " So suppose your data set actually had 200 different types of dogs, but you had only", "tokens": [50364, 407, 42923, 399, 311, 2135, 24002, 307, 1936, 300, 498, 428, 3209, 390, 8895, 534, 731, 11, 50611, 50611, 370, 7297, 291, 632, 572, 7645, 5658, 11, 570, 257, 688, 295, 721, 366, 406, 534, 11, 257, 688, 295, 5267, 50996, 50996, 534, 500, 380, 5784, 294, 264, 912, 5359, 13, 51160, 51160, 407, 7297, 428, 1412, 992, 767, 632, 2331, 819, 3467, 295, 7197, 11, 457, 291, 632, 787, 51396, 51396, 2319, 295, 552, 21335, 13, 51486, 51486, 400, 370, 337, 257, 688, 295, 613, 5267, 11, 584, 291, 767, 632, 281, 6269, 11, 291, 632, 281, 1888, 1936, 51760, 51760], "temperature": 0.0, "avg_logprob": -0.1472932375394381, "compression_ratio": 1.75, "no_speech_prob": 6.962084626138676e-06}, {"id": 1086, "seek": 432992, "start": 4350.56, "end": 4352.36, "text": " 100 of them labeled.", "tokens": [50364, 407, 42923, 399, 311, 2135, 24002, 307, 1936, 300, 498, 428, 3209, 390, 8895, 534, 731, 11, 50611, 50611, 370, 7297, 291, 632, 572, 7645, 5658, 11, 570, 257, 688, 295, 721, 366, 406, 534, 11, 257, 688, 295, 5267, 50996, 50996, 534, 500, 380, 5784, 294, 264, 912, 5359, 13, 51160, 51160, 407, 7297, 428, 1412, 992, 767, 632, 2331, 819, 3467, 295, 7197, 11, 457, 291, 632, 787, 51396, 51396, 2319, 295, 552, 21335, 13, 51486, 51486, 400, 370, 337, 257, 688, 295, 613, 5267, 11, 584, 291, 767, 632, 281, 6269, 11, 291, 632, 281, 1888, 1936, 51760, 51760], "temperature": 0.0, "avg_logprob": -0.1472932375394381, "compression_ratio": 1.75, "no_speech_prob": 6.962084626138676e-06}, {"id": 1087, "seek": 432992, "start": 4352.36, "end": 4357.84, "text": " And so for a lot of these images, say you actually had to assign, you had to pick basically", "tokens": [50364, 407, 42923, 399, 311, 2135, 24002, 307, 1936, 300, 498, 428, 3209, 390, 8895, 534, 731, 11, 50611, 50611, 370, 7297, 291, 632, 572, 7645, 5658, 11, 570, 257, 688, 295, 721, 366, 406, 534, 11, 257, 688, 295, 5267, 50996, 50996, 534, 500, 380, 5784, 294, 264, 912, 5359, 13, 51160, 51160, 407, 7297, 428, 1412, 992, 767, 632, 2331, 819, 3467, 295, 7197, 11, 457, 291, 632, 787, 51396, 51396, 2319, 295, 552, 21335, 13, 51486, 51486, 400, 370, 337, 257, 688, 295, 613, 5267, 11, 584, 291, 767, 632, 281, 6269, 11, 291, 632, 281, 1888, 1936, 51760, 51760], "temperature": 0.0, "avg_logprob": -0.1472932375394381, "compression_ratio": 1.75, "no_speech_prob": 6.962084626138676e-06}, {"id": 1088, "seek": 435784, "start": 4357.84, "end": 4363.16, "text": " which one of the dogs it was, a softer distribution is basically going to help you discover hidden", "tokens": [50364, 597, 472, 295, 264, 7197, 309, 390, 11, 257, 23119, 7316, 307, 1936, 516, 281, 854, 291, 4411, 7633, 50630, 50630, 10479, 13, 50680, 50680, 407, 309, 311, 1936, 1958, 13, 20, 733, 295, 341, 2010, 295, 3000, 293, 1958, 13, 20, 341, 733, 295, 3000, 13, 50998, 50998, 407, 1936, 1419, 613, 1333, 295, 23119, 16949, 3665, 291, 11985, 1333, 295, 264, 5883, 1508, 51334, 51334, 7316, 300, 291, 362, 13, 51434, 51434, 1033, 11, 1309, 291, 13, 51610, 51610], "temperature": 0.0, "avg_logprob": -0.24307804797069135, "compression_ratio": 1.6842105263157894, "no_speech_prob": 4.2227129597449675e-06}, {"id": 1089, "seek": 435784, "start": 4363.16, "end": 4364.16, "text": " categories.", "tokens": [50364, 597, 472, 295, 264, 7197, 309, 390, 11, 257, 23119, 7316, 307, 1936, 516, 281, 854, 291, 4411, 7633, 50630, 50630, 10479, 13, 50680, 50680, 407, 309, 311, 1936, 1958, 13, 20, 733, 295, 341, 2010, 295, 3000, 293, 1958, 13, 20, 341, 733, 295, 3000, 13, 50998, 50998, 407, 1936, 1419, 613, 1333, 295, 23119, 16949, 3665, 291, 11985, 1333, 295, 264, 5883, 1508, 51334, 51334, 7316, 300, 291, 362, 13, 51434, 51434, 1033, 11, 1309, 291, 13, 51610, 51610], "temperature": 0.0, "avg_logprob": -0.24307804797069135, "compression_ratio": 1.6842105263157894, "no_speech_prob": 4.2227129597449675e-06}, {"id": 1090, "seek": 435784, "start": 4364.16, "end": 4370.52, "text": " So it's basically 0.5 kind of this type of dog and 0.5 this kind of dog.", "tokens": [50364, 597, 472, 295, 264, 7197, 309, 390, 11, 257, 23119, 7316, 307, 1936, 516, 281, 854, 291, 4411, 7633, 50630, 50630, 10479, 13, 50680, 50680, 407, 309, 311, 1936, 1958, 13, 20, 733, 295, 341, 2010, 295, 3000, 293, 1958, 13, 20, 341, 733, 295, 3000, 13, 50998, 50998, 407, 1936, 1419, 613, 1333, 295, 23119, 16949, 3665, 291, 11985, 1333, 295, 264, 5883, 1508, 51334, 51334, 7316, 300, 291, 362, 13, 51434, 51434, 1033, 11, 1309, 291, 13, 51610, 51610], "temperature": 0.0, "avg_logprob": -0.24307804797069135, "compression_ratio": 1.6842105263157894, "no_speech_prob": 4.2227129597449675e-06}, {"id": 1091, "seek": 435784, "start": 4370.52, "end": 4377.24, "text": " So basically having these sort of softer labels helps you enhance sort of the initial class", "tokens": [50364, 597, 472, 295, 264, 7197, 309, 390, 11, 257, 23119, 7316, 307, 1936, 516, 281, 854, 291, 4411, 7633, 50630, 50630, 10479, 13, 50680, 50680, 407, 309, 311, 1936, 1958, 13, 20, 733, 295, 341, 2010, 295, 3000, 293, 1958, 13, 20, 341, 733, 295, 3000, 13, 50998, 50998, 407, 1936, 1419, 613, 1333, 295, 23119, 16949, 3665, 291, 11985, 1333, 295, 264, 5883, 1508, 51334, 51334, 7316, 300, 291, 362, 13, 51434, 51434, 1033, 11, 1309, 291, 13, 51610, 51610], "temperature": 0.0, "avg_logprob": -0.24307804797069135, "compression_ratio": 1.6842105263157894, "no_speech_prob": 4.2227129597449675e-06}, {"id": 1092, "seek": 435784, "start": 4377.24, "end": 4379.24, "text": " distribution that you have.", "tokens": [50364, 597, 472, 295, 264, 7197, 309, 390, 11, 257, 23119, 7316, 307, 1936, 516, 281, 854, 291, 4411, 7633, 50630, 50630, 10479, 13, 50680, 50680, 407, 309, 311, 1936, 1958, 13, 20, 733, 295, 341, 2010, 295, 3000, 293, 1958, 13, 20, 341, 733, 295, 3000, 13, 50998, 50998, 407, 1936, 1419, 613, 1333, 295, 23119, 16949, 3665, 291, 11985, 1333, 295, 264, 5883, 1508, 51334, 51334, 7316, 300, 291, 362, 13, 51434, 51434, 1033, 11, 1309, 291, 13, 51610, 51610], "temperature": 0.0, "avg_logprob": -0.24307804797069135, "compression_ratio": 1.6842105263157894, "no_speech_prob": 4.2227129597449675e-06}, {"id": 1093, "seek": 435784, "start": 4379.24, "end": 4382.76, "text": " Okay, thank you.", "tokens": [50364, 597, 472, 295, 264, 7197, 309, 390, 11, 257, 23119, 7316, 307, 1936, 516, 281, 854, 291, 4411, 7633, 50630, 50630, 10479, 13, 50680, 50680, 407, 309, 311, 1936, 1958, 13, 20, 733, 295, 341, 2010, 295, 3000, 293, 1958, 13, 20, 341, 733, 295, 3000, 13, 50998, 50998, 407, 1936, 1419, 613, 1333, 295, 23119, 16949, 3665, 291, 11985, 1333, 295, 264, 5883, 1508, 51334, 51334, 7316, 300, 291, 362, 13, 51434, 51434, 1033, 11, 1309, 291, 13, 51610, 51610], "temperature": 0.0, "avg_logprob": -0.24307804797069135, "compression_ratio": 1.6842105263157894, "no_speech_prob": 4.2227129597449675e-06}, {"id": 1094, "seek": 438276, "start": 4382.76, "end": 4393.96, "text": " So we applied this method to the self-supervised learning.", "tokens": [50364, 407, 321, 6456, 341, 3170, 281, 264, 2698, 12, 48172, 24420, 2539, 13, 50924, 50924, 407, 264, 361, 17156, 1607, 5633, 300, 286, 2825, 466, 3071, 11, 293, 321, 645, 1075, 281, 536, 8830, 11663, 51149, 51149, 295, 16823, 2108, 257, 3840, 295, 1412, 6352, 13, 51270, 51270, 407, 264, 361, 17156, 1607, 3170, 307, 294, 264, 1192, 5386, 11, 597, 11, 293, 294, 1184, 295, 264, 1333, 295, 13766, 11, 291, 434, 51566, 51566], "temperature": 0.0, "avg_logprob": -0.18341398858404778, "compression_ratio": 1.538888888888889, "no_speech_prob": 7.41105577617418e-06}, {"id": 1095, "seek": 438276, "start": 4393.96, "end": 4398.46, "text": " So the jigsaw task that I talked about earlier, and we were able to see surprising amounts", "tokens": [50364, 407, 321, 6456, 341, 3170, 281, 264, 2698, 12, 48172, 24420, 2539, 13, 50924, 50924, 407, 264, 361, 17156, 1607, 5633, 300, 286, 2825, 466, 3071, 11, 293, 321, 645, 1075, 281, 536, 8830, 11663, 51149, 51149, 295, 16823, 2108, 257, 3840, 295, 1412, 6352, 13, 51270, 51270, 407, 264, 361, 17156, 1607, 3170, 307, 294, 264, 1192, 5386, 11, 597, 11, 293, 294, 1184, 295, 264, 1333, 295, 13766, 11, 291, 434, 51566, 51566], "temperature": 0.0, "avg_logprob": -0.18341398858404778, "compression_ratio": 1.538888888888889, "no_speech_prob": 7.41105577617418e-06}, {"id": 1096, "seek": 438276, "start": 4398.46, "end": 4400.88, "text": " of gains across a bunch of data sets.", "tokens": [50364, 407, 321, 6456, 341, 3170, 281, 264, 2698, 12, 48172, 24420, 2539, 13, 50924, 50924, 407, 264, 361, 17156, 1607, 5633, 300, 286, 2825, 466, 3071, 11, 293, 321, 645, 1075, 281, 536, 8830, 11663, 51149, 51149, 295, 16823, 2108, 257, 3840, 295, 1412, 6352, 13, 51270, 51270, 407, 264, 361, 17156, 1607, 3170, 307, 294, 264, 1192, 5386, 11, 597, 11, 293, 294, 1184, 295, 264, 1333, 295, 13766, 11, 291, 434, 51566, 51566], "temperature": 0.0, "avg_logprob": -0.18341398858404778, "compression_ratio": 1.538888888888889, "no_speech_prob": 7.41105577617418e-06}, {"id": 1097, "seek": 438276, "start": 4400.88, "end": 4406.8, "text": " So the jigsaw method is in the top row, which, and in each of the sort of columns, you're", "tokens": [50364, 407, 321, 6456, 341, 3170, 281, 264, 2698, 12, 48172, 24420, 2539, 13, 50924, 50924, 407, 264, 361, 17156, 1607, 5633, 300, 286, 2825, 466, 3071, 11, 293, 321, 645, 1075, 281, 536, 8830, 11663, 51149, 51149, 295, 16823, 2108, 257, 3840, 295, 1412, 6352, 13, 51270, 51270, 407, 264, 361, 17156, 1607, 3170, 307, 294, 264, 1192, 5386, 11, 597, 11, 293, 294, 1184, 295, 264, 1333, 295, 13766, 11, 291, 434, 51566, 51566], "temperature": 0.0, "avg_logprob": -0.18341398858404778, "compression_ratio": 1.538888888888889, "no_speech_prob": 7.41105577617418e-06}, {"id": 1098, "seek": 440680, "start": 4406.8, "end": 4412.76, "text": " looking at the transfer performance of basically this jigsaw method on a bunch of different", "tokens": [50364, 1237, 412, 264, 5003, 3389, 295, 1936, 341, 361, 17156, 1607, 3170, 322, 257, 3840, 295, 819, 50662, 50662, 1412, 6352, 13, 50740, 50740, 759, 291, 3079, 13630, 3318, 281, 341, 361, 17156, 1607, 3170, 11, 291, 767, 393, 536, 16823, 2108, 439, 295, 613, 51032, 51032, 1412, 6352, 293, 436, 434, 6457, 8398, 13, 51196, 51196, 400, 321, 10332, 341, 1500, 322, 257, 3840, 295, 819, 659, 12, 17227, 1760, 7150, 411, 4297, 7129, 11, 370, 32884, 51446, 51446, 44796, 13, 51496, 51496, 400, 797, 11, 321, 727, 536, 6457, 1481, 16823, 2108, 613, 1451, 819, 1412, 6352, 13, 51812, 51812], "temperature": 0.0, "avg_logprob": -0.15135008555192214, "compression_ratio": 1.881578947368421, "no_speech_prob": 6.240813490876462e-06}, {"id": 1099, "seek": 440680, "start": 4412.76, "end": 4414.320000000001, "text": " data sets.", "tokens": [50364, 1237, 412, 264, 5003, 3389, 295, 1936, 341, 361, 17156, 1607, 3170, 322, 257, 3840, 295, 819, 50662, 50662, 1412, 6352, 13, 50740, 50740, 759, 291, 3079, 13630, 3318, 281, 341, 361, 17156, 1607, 3170, 11, 291, 767, 393, 536, 16823, 2108, 439, 295, 613, 51032, 51032, 1412, 6352, 293, 436, 434, 6457, 8398, 13, 51196, 51196, 400, 321, 10332, 341, 1500, 322, 257, 3840, 295, 819, 659, 12, 17227, 1760, 7150, 411, 4297, 7129, 11, 370, 32884, 51446, 51446, 44796, 13, 51496, 51496, 400, 797, 11, 321, 727, 536, 6457, 1481, 16823, 2108, 613, 1451, 819, 1412, 6352, 13, 51812, 51812], "temperature": 0.0, "avg_logprob": -0.15135008555192214, "compression_ratio": 1.881578947368421, "no_speech_prob": 6.240813490876462e-06}, {"id": 1100, "seek": 440680, "start": 4414.320000000001, "end": 4420.16, "text": " If you apply cluster fit to this jigsaw method, you actually can see gains across all of these", "tokens": [50364, 1237, 412, 264, 5003, 3389, 295, 1936, 341, 361, 17156, 1607, 3170, 322, 257, 3840, 295, 819, 50662, 50662, 1412, 6352, 13, 50740, 50740, 759, 291, 3079, 13630, 3318, 281, 341, 361, 17156, 1607, 3170, 11, 291, 767, 393, 536, 16823, 2108, 439, 295, 613, 51032, 51032, 1412, 6352, 293, 436, 434, 6457, 8398, 13, 51196, 51196, 400, 321, 10332, 341, 1500, 322, 257, 3840, 295, 819, 659, 12, 17227, 1760, 7150, 411, 4297, 7129, 11, 370, 32884, 51446, 51446, 44796, 13, 51496, 51496, 400, 797, 11, 321, 727, 536, 6457, 1481, 16823, 2108, 613, 1451, 819, 1412, 6352, 13, 51812, 51812], "temperature": 0.0, "avg_logprob": -0.15135008555192214, "compression_ratio": 1.881578947368421, "no_speech_prob": 6.240813490876462e-06}, {"id": 1101, "seek": 440680, "start": 4420.16, "end": 4423.4400000000005, "text": " data sets and they're fairly consistent.", "tokens": [50364, 1237, 412, 264, 5003, 3389, 295, 1936, 341, 361, 17156, 1607, 3170, 322, 257, 3840, 295, 819, 50662, 50662, 1412, 6352, 13, 50740, 50740, 759, 291, 3079, 13630, 3318, 281, 341, 361, 17156, 1607, 3170, 11, 291, 767, 393, 536, 16823, 2108, 439, 295, 613, 51032, 51032, 1412, 6352, 293, 436, 434, 6457, 8398, 13, 51196, 51196, 400, 321, 10332, 341, 1500, 322, 257, 3840, 295, 819, 659, 12, 17227, 1760, 7150, 411, 4297, 7129, 11, 370, 32884, 51446, 51446, 44796, 13, 51496, 51496, 400, 797, 11, 321, 727, 536, 6457, 1481, 16823, 2108, 613, 1451, 819, 1412, 6352, 13, 51812, 51812], "temperature": 0.0, "avg_logprob": -0.15135008555192214, "compression_ratio": 1.881578947368421, "no_speech_prob": 6.240813490876462e-06}, {"id": 1102, "seek": 440680, "start": 4423.4400000000005, "end": 4428.4400000000005, "text": " And we performed this test on a bunch of different pre-training methods like rotnet, so predicting", "tokens": [50364, 1237, 412, 264, 5003, 3389, 295, 1936, 341, 361, 17156, 1607, 3170, 322, 257, 3840, 295, 819, 50662, 50662, 1412, 6352, 13, 50740, 50740, 759, 291, 3079, 13630, 3318, 281, 341, 361, 17156, 1607, 3170, 11, 291, 767, 393, 536, 16823, 2108, 439, 295, 613, 51032, 51032, 1412, 6352, 293, 436, 434, 6457, 8398, 13, 51196, 51196, 400, 321, 10332, 341, 1500, 322, 257, 3840, 295, 819, 659, 12, 17227, 1760, 7150, 411, 4297, 7129, 11, 370, 32884, 51446, 51446, 44796, 13, 51496, 51496, 400, 797, 11, 321, 727, 536, 6457, 1481, 16823, 2108, 613, 1451, 819, 1412, 6352, 13, 51812, 51812], "temperature": 0.0, "avg_logprob": -0.15135008555192214, "compression_ratio": 1.881578947368421, "no_speech_prob": 6.240813490876462e-06}, {"id": 1103, "seek": 440680, "start": 4428.4400000000005, "end": 4429.4400000000005, "text": " rotations.", "tokens": [50364, 1237, 412, 264, 5003, 3389, 295, 1936, 341, 361, 17156, 1607, 3170, 322, 257, 3840, 295, 819, 50662, 50662, 1412, 6352, 13, 50740, 50740, 759, 291, 3079, 13630, 3318, 281, 341, 361, 17156, 1607, 3170, 11, 291, 767, 393, 536, 16823, 2108, 439, 295, 613, 51032, 51032, 1412, 6352, 293, 436, 434, 6457, 8398, 13, 51196, 51196, 400, 321, 10332, 341, 1500, 322, 257, 3840, 295, 819, 659, 12, 17227, 1760, 7150, 411, 4297, 7129, 11, 370, 32884, 51446, 51446, 44796, 13, 51496, 51496, 400, 797, 11, 321, 727, 536, 6457, 1481, 16823, 2108, 613, 1451, 819, 1412, 6352, 13, 51812, 51812], "temperature": 0.0, "avg_logprob": -0.15135008555192214, "compression_ratio": 1.881578947368421, "no_speech_prob": 6.240813490876462e-06}, {"id": 1104, "seek": 440680, "start": 4429.4400000000005, "end": 4435.76, "text": " And again, we could see fairly nice gains across these four different data sets.", "tokens": [50364, 1237, 412, 264, 5003, 3389, 295, 1936, 341, 361, 17156, 1607, 3170, 322, 257, 3840, 295, 819, 50662, 50662, 1412, 6352, 13, 50740, 50740, 759, 291, 3079, 13630, 3318, 281, 341, 361, 17156, 1607, 3170, 11, 291, 767, 393, 536, 16823, 2108, 439, 295, 613, 51032, 51032, 1412, 6352, 293, 436, 434, 6457, 8398, 13, 51196, 51196, 400, 321, 10332, 341, 1500, 322, 257, 3840, 295, 819, 659, 12, 17227, 1760, 7150, 411, 4297, 7129, 11, 370, 32884, 51446, 51446, 44796, 13, 51496, 51496, 400, 797, 11, 321, 727, 536, 6457, 1481, 16823, 2108, 613, 1451, 819, 1412, 6352, 13, 51812, 51812], "temperature": 0.0, "avg_logprob": -0.15135008555192214, "compression_ratio": 1.881578947368421, "no_speech_prob": 6.240813490876462e-06}, {"id": 1105, "seek": 443576, "start": 4435.76, "end": 4440.2, "text": " And surprisingly enough, cluster fit really works on any pre-trained network.", "tokens": [50364, 400, 17600, 1547, 11, 13630, 3318, 534, 1985, 322, 604, 659, 12, 17227, 2001, 3209, 13, 50586, 50586, 407, 309, 393, 312, 2139, 257, 4498, 46533, 3209, 420, 257, 12460, 46533, 3209, 13, 50814, 50814, 407, 584, 257, 3209, 300, 390, 8895, 281, 6069, 50016, 420, 257, 12460, 46533, 960, 3209, 51136, 51136, 420, 1936, 604, 2698, 12, 48172, 24420, 3209, 13, 51316, 51316, 400, 294, 1184, 295, 613, 3331, 11, 321, 393, 11441, 6457, 8398, 293, 2416, 16823, 562, 291, 51554, 51554, 3079, 13630, 3318, 13, 51604, 51604, 407, 309, 311, 767, 1075, 281, 3470, 264, 2674, 2144, 295, 881, 295, 613, 7150, 13, 51818, 51818], "temperature": 0.0, "avg_logprob": -0.11460392628241023, "compression_ratio": 1.873015873015873, "no_speech_prob": 2.1781481336802244e-05}, {"id": 1106, "seek": 443576, "start": 4440.2, "end": 4444.76, "text": " So it can be either a fully supervised network or a weekly supervised network.", "tokens": [50364, 400, 17600, 1547, 11, 13630, 3318, 534, 1985, 322, 604, 659, 12, 17227, 2001, 3209, 13, 50586, 50586, 407, 309, 393, 312, 2139, 257, 4498, 46533, 3209, 420, 257, 12460, 46533, 3209, 13, 50814, 50814, 407, 584, 257, 3209, 300, 390, 8895, 281, 6069, 50016, 420, 257, 12460, 46533, 960, 3209, 51136, 51136, 420, 1936, 604, 2698, 12, 48172, 24420, 3209, 13, 51316, 51316, 400, 294, 1184, 295, 613, 3331, 11, 321, 393, 11441, 6457, 8398, 293, 2416, 16823, 562, 291, 51554, 51554, 3079, 13630, 3318, 13, 51604, 51604, 407, 309, 311, 767, 1075, 281, 3470, 264, 2674, 2144, 295, 881, 295, 613, 7150, 13, 51818, 51818], "temperature": 0.0, "avg_logprob": -0.11460392628241023, "compression_ratio": 1.873015873015873, "no_speech_prob": 2.1781481336802244e-05}, {"id": 1107, "seek": 443576, "start": 4444.76, "end": 4451.2, "text": " So say a network that was trained to predict hashtags or a weekly supervised video network", "tokens": [50364, 400, 17600, 1547, 11, 13630, 3318, 534, 1985, 322, 604, 659, 12, 17227, 2001, 3209, 13, 50586, 50586, 407, 309, 393, 312, 2139, 257, 4498, 46533, 3209, 420, 257, 12460, 46533, 3209, 13, 50814, 50814, 407, 584, 257, 3209, 300, 390, 8895, 281, 6069, 50016, 420, 257, 12460, 46533, 960, 3209, 51136, 51136, 420, 1936, 604, 2698, 12, 48172, 24420, 3209, 13, 51316, 51316, 400, 294, 1184, 295, 613, 3331, 11, 321, 393, 11441, 6457, 8398, 293, 2416, 16823, 562, 291, 51554, 51554, 3079, 13630, 3318, 13, 51604, 51604, 407, 309, 311, 767, 1075, 281, 3470, 264, 2674, 2144, 295, 881, 295, 613, 7150, 13, 51818, 51818], "temperature": 0.0, "avg_logprob": -0.11460392628241023, "compression_ratio": 1.873015873015873, "no_speech_prob": 2.1781481336802244e-05}, {"id": 1108, "seek": 443576, "start": 4451.2, "end": 4454.8, "text": " or basically any self-supervised network.", "tokens": [50364, 400, 17600, 1547, 11, 13630, 3318, 534, 1985, 322, 604, 659, 12, 17227, 2001, 3209, 13, 50586, 50586, 407, 309, 393, 312, 2139, 257, 4498, 46533, 3209, 420, 257, 12460, 46533, 3209, 13, 50814, 50814, 407, 584, 257, 3209, 300, 390, 8895, 281, 6069, 50016, 420, 257, 12460, 46533, 960, 3209, 51136, 51136, 420, 1936, 604, 2698, 12, 48172, 24420, 3209, 13, 51316, 51316, 400, 294, 1184, 295, 613, 3331, 11, 321, 393, 11441, 6457, 8398, 293, 2416, 16823, 562, 291, 51554, 51554, 3079, 13630, 3318, 13, 51604, 51604, 407, 309, 311, 767, 1075, 281, 3470, 264, 2674, 2144, 295, 881, 295, 613, 7150, 13, 51818, 51818], "temperature": 0.0, "avg_logprob": -0.11460392628241023, "compression_ratio": 1.873015873015873, "no_speech_prob": 2.1781481336802244e-05}, {"id": 1109, "seek": 443576, "start": 4454.8, "end": 4459.56, "text": " And in each of these cases, we can observe fairly consistent and large gains when you", "tokens": [50364, 400, 17600, 1547, 11, 13630, 3318, 534, 1985, 322, 604, 659, 12, 17227, 2001, 3209, 13, 50586, 50586, 407, 309, 393, 312, 2139, 257, 4498, 46533, 3209, 420, 257, 12460, 46533, 3209, 13, 50814, 50814, 407, 584, 257, 3209, 300, 390, 8895, 281, 6069, 50016, 420, 257, 12460, 46533, 960, 3209, 51136, 51136, 420, 1936, 604, 2698, 12, 48172, 24420, 3209, 13, 51316, 51316, 400, 294, 1184, 295, 613, 3331, 11, 321, 393, 11441, 6457, 8398, 293, 2416, 16823, 562, 291, 51554, 51554, 3079, 13630, 3318, 13, 51604, 51604, 407, 309, 311, 767, 1075, 281, 3470, 264, 2674, 2144, 295, 881, 295, 613, 7150, 13, 51818, 51818], "temperature": 0.0, "avg_logprob": -0.11460392628241023, "compression_ratio": 1.873015873015873, "no_speech_prob": 2.1781481336802244e-05}, {"id": 1110, "seek": 443576, "start": 4459.56, "end": 4460.56, "text": " apply cluster fit.", "tokens": [50364, 400, 17600, 1547, 11, 13630, 3318, 534, 1985, 322, 604, 659, 12, 17227, 2001, 3209, 13, 50586, 50586, 407, 309, 393, 312, 2139, 257, 4498, 46533, 3209, 420, 257, 12460, 46533, 3209, 13, 50814, 50814, 407, 584, 257, 3209, 300, 390, 8895, 281, 6069, 50016, 420, 257, 12460, 46533, 960, 3209, 51136, 51136, 420, 1936, 604, 2698, 12, 48172, 24420, 3209, 13, 51316, 51316, 400, 294, 1184, 295, 613, 3331, 11, 321, 393, 11441, 6457, 8398, 293, 2416, 16823, 562, 291, 51554, 51554, 3079, 13630, 3318, 13, 51604, 51604, 407, 309, 311, 767, 1075, 281, 3470, 264, 2674, 2144, 295, 881, 295, 613, 7150, 13, 51818, 51818], "temperature": 0.0, "avg_logprob": -0.11460392628241023, "compression_ratio": 1.873015873015873, "no_speech_prob": 2.1781481336802244e-05}, {"id": 1111, "seek": 443576, "start": 4460.56, "end": 4464.84, "text": " So it's actually able to improve the generalization of most of these methods.", "tokens": [50364, 400, 17600, 1547, 11, 13630, 3318, 534, 1985, 322, 604, 659, 12, 17227, 2001, 3209, 13, 50586, 50586, 407, 309, 393, 312, 2139, 257, 4498, 46533, 3209, 420, 257, 12460, 46533, 3209, 13, 50814, 50814, 407, 584, 257, 3209, 300, 390, 8895, 281, 6069, 50016, 420, 257, 12460, 46533, 960, 3209, 51136, 51136, 420, 1936, 604, 2698, 12, 48172, 24420, 3209, 13, 51316, 51316, 400, 294, 1184, 295, 613, 3331, 11, 321, 393, 11441, 6457, 8398, 293, 2416, 16823, 562, 291, 51554, 51554, 3079, 13630, 3318, 13, 51604, 51604, 407, 309, 311, 767, 1075, 281, 3470, 264, 2674, 2144, 295, 881, 295, 613, 7150, 13, 51818, 51818], "temperature": 0.0, "avg_logprob": -0.11460392628241023, "compression_ratio": 1.873015873015873, "no_speech_prob": 2.1781481336802244e-05}, {"id": 1112, "seek": 446484, "start": 4464.84, "end": 4467.04, "text": " I think you're dragging your microphone around.", "tokens": [50364, 286, 519, 291, 434, 24385, 428, 10952, 926, 13, 50474, 50474, 467, 311, 588, 24518, 13, 50524, 50524, 1923, 30, 50574, 50574, 865, 13, 50624, 50624, 467, 311, 5541, 322, 452, 10732, 13, 50916, 50916, 407, 264, 1150, 551, 307, 1936, 613, 16823, 645, 1944, 1553, 2857, 1412, 11, 16949, 420, 51234, 51234, 2962, 294, 264, 9482, 13, 51304, 51304, 407, 294, 512, 636, 11, 291, 393, 519, 295, 341, 382, 885, 2698, 12, 48172, 24420, 2489, 15164, 1823, 13, 51608, 51608, 407, 291, 362, 428, 659, 12, 17227, 2001, 3209, 293, 550, 291, 1936, 2042, 341, 13630, 1823, 11, 597, 51812, 51812], "temperature": 0.0, "avg_logprob": -0.16231068202427457, "compression_ratio": 1.570281124497992, "no_speech_prob": 7.966416160343215e-05}, {"id": 1113, "seek": 446484, "start": 4467.04, "end": 4468.04, "text": " It's very noisy.", "tokens": [50364, 286, 519, 291, 434, 24385, 428, 10952, 926, 13, 50474, 50474, 467, 311, 588, 24518, 13, 50524, 50524, 1923, 30, 50574, 50574, 865, 13, 50624, 50624, 467, 311, 5541, 322, 452, 10732, 13, 50916, 50916, 407, 264, 1150, 551, 307, 1936, 613, 16823, 645, 1944, 1553, 2857, 1412, 11, 16949, 420, 51234, 51234, 2962, 294, 264, 9482, 13, 51304, 51304, 407, 294, 512, 636, 11, 291, 393, 519, 295, 341, 382, 885, 2698, 12, 48172, 24420, 2489, 15164, 1823, 13, 51608, 51608, 407, 291, 362, 428, 659, 12, 17227, 2001, 3209, 293, 550, 291, 1936, 2042, 341, 13630, 1823, 11, 597, 51812, 51812], "temperature": 0.0, "avg_logprob": -0.16231068202427457, "compression_ratio": 1.570281124497992, "no_speech_prob": 7.966416160343215e-05}, {"id": 1114, "seek": 446484, "start": 4468.04, "end": 4469.04, "text": " Me?", "tokens": [50364, 286, 519, 291, 434, 24385, 428, 10952, 926, 13, 50474, 50474, 467, 311, 588, 24518, 13, 50524, 50524, 1923, 30, 50574, 50574, 865, 13, 50624, 50624, 467, 311, 5541, 322, 452, 10732, 13, 50916, 50916, 407, 264, 1150, 551, 307, 1936, 613, 16823, 645, 1944, 1553, 2857, 1412, 11, 16949, 420, 51234, 51234, 2962, 294, 264, 9482, 13, 51304, 51304, 407, 294, 512, 636, 11, 291, 393, 519, 295, 341, 382, 885, 2698, 12, 48172, 24420, 2489, 15164, 1823, 13, 51608, 51608, 407, 291, 362, 428, 659, 12, 17227, 2001, 3209, 293, 550, 291, 1936, 2042, 341, 13630, 1823, 11, 597, 51812, 51812], "temperature": 0.0, "avg_logprob": -0.16231068202427457, "compression_ratio": 1.570281124497992, "no_speech_prob": 7.966416160343215e-05}, {"id": 1115, "seek": 446484, "start": 4469.04, "end": 4470.04, "text": " Yeah.", "tokens": [50364, 286, 519, 291, 434, 24385, 428, 10952, 926, 13, 50474, 50474, 467, 311, 588, 24518, 13, 50524, 50524, 1923, 30, 50574, 50574, 865, 13, 50624, 50624, 467, 311, 5541, 322, 452, 10732, 13, 50916, 50916, 407, 264, 1150, 551, 307, 1936, 613, 16823, 645, 1944, 1553, 2857, 1412, 11, 16949, 420, 51234, 51234, 2962, 294, 264, 9482, 13, 51304, 51304, 407, 294, 512, 636, 11, 291, 393, 519, 295, 341, 382, 885, 2698, 12, 48172, 24420, 2489, 15164, 1823, 13, 51608, 51608, 407, 291, 362, 428, 659, 12, 17227, 2001, 3209, 293, 550, 291, 1936, 2042, 341, 13630, 1823, 11, 597, 51812, 51812], "temperature": 0.0, "avg_logprob": -0.16231068202427457, "compression_ratio": 1.570281124497992, "no_speech_prob": 7.966416160343215e-05}, {"id": 1116, "seek": 446484, "start": 4470.04, "end": 4475.88, "text": " It's stuck on my laptop.", "tokens": [50364, 286, 519, 291, 434, 24385, 428, 10952, 926, 13, 50474, 50474, 467, 311, 588, 24518, 13, 50524, 50524, 1923, 30, 50574, 50574, 865, 13, 50624, 50624, 467, 311, 5541, 322, 452, 10732, 13, 50916, 50916, 407, 264, 1150, 551, 307, 1936, 613, 16823, 645, 1944, 1553, 2857, 1412, 11, 16949, 420, 51234, 51234, 2962, 294, 264, 9482, 13, 51304, 51304, 407, 294, 512, 636, 11, 291, 393, 519, 295, 341, 382, 885, 2698, 12, 48172, 24420, 2489, 15164, 1823, 13, 51608, 51608, 407, 291, 362, 428, 659, 12, 17227, 2001, 3209, 293, 550, 291, 1936, 2042, 341, 13630, 1823, 11, 597, 51812, 51812], "temperature": 0.0, "avg_logprob": -0.16231068202427457, "compression_ratio": 1.570281124497992, "no_speech_prob": 7.966416160343215e-05}, {"id": 1117, "seek": 446484, "start": 4475.88, "end": 4482.24, "text": " So the second thing is basically these gains were possible without extra data, labels or", "tokens": [50364, 286, 519, 291, 434, 24385, 428, 10952, 926, 13, 50474, 50474, 467, 311, 588, 24518, 13, 50524, 50524, 1923, 30, 50574, 50574, 865, 13, 50624, 50624, 467, 311, 5541, 322, 452, 10732, 13, 50916, 50916, 407, 264, 1150, 551, 307, 1936, 613, 16823, 645, 1944, 1553, 2857, 1412, 11, 16949, 420, 51234, 51234, 2962, 294, 264, 9482, 13, 51304, 51304, 407, 294, 512, 636, 11, 291, 393, 519, 295, 341, 382, 885, 2698, 12, 48172, 24420, 2489, 15164, 1823, 13, 51608, 51608, 407, 291, 362, 428, 659, 12, 17227, 2001, 3209, 293, 550, 291, 1936, 2042, 341, 13630, 1823, 11, 597, 51812, 51812], "temperature": 0.0, "avg_logprob": -0.16231068202427457, "compression_ratio": 1.570281124497992, "no_speech_prob": 7.966416160343215e-05}, {"id": 1118, "seek": 446484, "start": 4482.24, "end": 4483.64, "text": " changes in the architecture.", "tokens": [50364, 286, 519, 291, 434, 24385, 428, 10952, 926, 13, 50474, 50474, 467, 311, 588, 24518, 13, 50524, 50524, 1923, 30, 50574, 50574, 865, 13, 50624, 50624, 467, 311, 5541, 322, 452, 10732, 13, 50916, 50916, 407, 264, 1150, 551, 307, 1936, 613, 16823, 645, 1944, 1553, 2857, 1412, 11, 16949, 420, 51234, 51234, 2962, 294, 264, 9482, 13, 51304, 51304, 407, 294, 512, 636, 11, 291, 393, 519, 295, 341, 382, 885, 2698, 12, 48172, 24420, 2489, 15164, 1823, 13, 51608, 51608, 407, 291, 362, 428, 659, 12, 17227, 2001, 3209, 293, 550, 291, 1936, 2042, 341, 13630, 1823, 11, 597, 51812, 51812], "temperature": 0.0, "avg_logprob": -0.16231068202427457, "compression_ratio": 1.570281124497992, "no_speech_prob": 7.966416160343215e-05}, {"id": 1119, "seek": 446484, "start": 4483.64, "end": 4489.72, "text": " So in some way, you can think of this as being self-supervised fine tuning step.", "tokens": [50364, 286, 519, 291, 434, 24385, 428, 10952, 926, 13, 50474, 50474, 467, 311, 588, 24518, 13, 50524, 50524, 1923, 30, 50574, 50574, 865, 13, 50624, 50624, 467, 311, 5541, 322, 452, 10732, 13, 50916, 50916, 407, 264, 1150, 551, 307, 1936, 613, 16823, 645, 1944, 1553, 2857, 1412, 11, 16949, 420, 51234, 51234, 2962, 294, 264, 9482, 13, 51304, 51304, 407, 294, 512, 636, 11, 291, 393, 519, 295, 341, 382, 885, 2698, 12, 48172, 24420, 2489, 15164, 1823, 13, 51608, 51608, 407, 291, 362, 428, 659, 12, 17227, 2001, 3209, 293, 550, 291, 1936, 2042, 341, 13630, 1823, 11, 597, 51812, 51812], "temperature": 0.0, "avg_logprob": -0.16231068202427457, "compression_ratio": 1.570281124497992, "no_speech_prob": 7.966416160343215e-05}, {"id": 1120, "seek": 446484, "start": 4489.72, "end": 4493.8, "text": " So you have your pre-trained network and then you basically perform this cluster step, which", "tokens": [50364, 286, 519, 291, 434, 24385, 428, 10952, 926, 13, 50474, 50474, 467, 311, 588, 24518, 13, 50524, 50524, 1923, 30, 50574, 50574, 865, 13, 50624, 50624, 467, 311, 5541, 322, 452, 10732, 13, 50916, 50916, 407, 264, 1150, 551, 307, 1936, 613, 16823, 645, 1944, 1553, 2857, 1412, 11, 16949, 420, 51234, 51234, 2962, 294, 264, 9482, 13, 51304, 51304, 407, 294, 512, 636, 11, 291, 393, 519, 295, 341, 382, 885, 2698, 12, 48172, 24420, 2489, 15164, 1823, 13, 51608, 51608, 407, 291, 362, 428, 659, 12, 17227, 2001, 3209, 293, 550, 291, 1936, 2042, 341, 13630, 1823, 11, 597, 51812, 51812], "temperature": 0.0, "avg_logprob": -0.16231068202427457, "compression_ratio": 1.570281124497992, "no_speech_prob": 7.966416160343215e-05}, {"id": 1121, "seek": 449380, "start": 4493.8, "end": 4498.4400000000005, "text": " is cluster fit step, which is completely self-supervised or unsupervised.", "tokens": [50364, 307, 13630, 3318, 1823, 11, 597, 307, 2584, 2698, 12, 48172, 24420, 420, 2693, 12879, 24420, 13, 50596, 50596, 400, 550, 291, 393, 11441, 300, 264, 10290, 3125, 24771, 13, 50954, 50954, 286, 632, 257, 1168, 13, 51094, 51094, 682, 264, 4137, 300, 291, 4712, 264, 10444, 365, 508, 17156, 1607, 293, 538, 1228, 13630, 3318, 13, 51354, 51354, 407, 294, 341, 13630, 3318, 11, 307, 309, 4994, 551, 30, 51534, 51534, 467, 307, 406, 1228, 508, 17156, 1607, 412, 439, 13, 51668, 51668, 407, 309, 307, 6456, 322, 1192, 295, 264, 508, 17156, 1607, 3170, 13, 51790, 51790], "temperature": 0.0, "avg_logprob": -0.16166075149385056, "compression_ratio": 1.6851851851851851, "no_speech_prob": 1.2409769624355249e-05}, {"id": 1122, "seek": 449380, "start": 4498.4400000000005, "end": 4505.6, "text": " And then you can observe that the representation quality improves.", "tokens": [50364, 307, 13630, 3318, 1823, 11, 597, 307, 2584, 2698, 12, 48172, 24420, 420, 2693, 12879, 24420, 13, 50596, 50596, 400, 550, 291, 393, 11441, 300, 264, 10290, 3125, 24771, 13, 50954, 50954, 286, 632, 257, 1168, 13, 51094, 51094, 682, 264, 4137, 300, 291, 4712, 264, 10444, 365, 508, 17156, 1607, 293, 538, 1228, 13630, 3318, 13, 51354, 51354, 407, 294, 341, 13630, 3318, 11, 307, 309, 4994, 551, 30, 51534, 51534, 467, 307, 406, 1228, 508, 17156, 1607, 412, 439, 13, 51668, 51668, 407, 309, 307, 6456, 322, 1192, 295, 264, 508, 17156, 1607, 3170, 13, 51790, 51790], "temperature": 0.0, "avg_logprob": -0.16166075149385056, "compression_ratio": 1.6851851851851851, "no_speech_prob": 1.2409769624355249e-05}, {"id": 1123, "seek": 449380, "start": 4505.6, "end": 4508.400000000001, "text": " I had a question.", "tokens": [50364, 307, 13630, 3318, 1823, 11, 597, 307, 2584, 2698, 12, 48172, 24420, 420, 2693, 12879, 24420, 13, 50596, 50596, 400, 550, 291, 393, 11441, 300, 264, 10290, 3125, 24771, 13, 50954, 50954, 286, 632, 257, 1168, 13, 51094, 51094, 682, 264, 4137, 300, 291, 4712, 264, 10444, 365, 508, 17156, 1607, 293, 538, 1228, 13630, 3318, 13, 51354, 51354, 407, 294, 341, 13630, 3318, 11, 307, 309, 4994, 551, 30, 51534, 51534, 467, 307, 406, 1228, 508, 17156, 1607, 412, 439, 13, 51668, 51668, 407, 309, 307, 6456, 322, 1192, 295, 264, 508, 17156, 1607, 3170, 13, 51790, 51790], "temperature": 0.0, "avg_logprob": -0.16166075149385056, "compression_ratio": 1.6851851851851851, "no_speech_prob": 1.2409769624355249e-05}, {"id": 1124, "seek": 449380, "start": 4508.400000000001, "end": 4513.6, "text": " In the slide that you showed the improvement with Jigsaw and by using cluster fit.", "tokens": [50364, 307, 13630, 3318, 1823, 11, 597, 307, 2584, 2698, 12, 48172, 24420, 420, 2693, 12879, 24420, 13, 50596, 50596, 400, 550, 291, 393, 11441, 300, 264, 10290, 3125, 24771, 13, 50954, 50954, 286, 632, 257, 1168, 13, 51094, 51094, 682, 264, 4137, 300, 291, 4712, 264, 10444, 365, 508, 17156, 1607, 293, 538, 1228, 13630, 3318, 13, 51354, 51354, 407, 294, 341, 13630, 3318, 11, 307, 309, 4994, 551, 30, 51534, 51534, 467, 307, 406, 1228, 508, 17156, 1607, 412, 439, 13, 51668, 51668, 407, 309, 307, 6456, 322, 1192, 295, 264, 508, 17156, 1607, 3170, 13, 51790, 51790], "temperature": 0.0, "avg_logprob": -0.16166075149385056, "compression_ratio": 1.6851851851851851, "no_speech_prob": 1.2409769624355249e-05}, {"id": 1125, "seek": 449380, "start": 4513.6, "end": 4517.2, "text": " So in this cluster fit, is it separate thing?", "tokens": [50364, 307, 13630, 3318, 1823, 11, 597, 307, 2584, 2698, 12, 48172, 24420, 420, 2693, 12879, 24420, 13, 50596, 50596, 400, 550, 291, 393, 11441, 300, 264, 10290, 3125, 24771, 13, 50954, 50954, 286, 632, 257, 1168, 13, 51094, 51094, 682, 264, 4137, 300, 291, 4712, 264, 10444, 365, 508, 17156, 1607, 293, 538, 1228, 13630, 3318, 13, 51354, 51354, 407, 294, 341, 13630, 3318, 11, 307, 309, 4994, 551, 30, 51534, 51534, 467, 307, 406, 1228, 508, 17156, 1607, 412, 439, 13, 51668, 51668, 407, 309, 307, 6456, 322, 1192, 295, 264, 508, 17156, 1607, 3170, 13, 51790, 51790], "temperature": 0.0, "avg_logprob": -0.16166075149385056, "compression_ratio": 1.6851851851851851, "no_speech_prob": 1.2409769624355249e-05}, {"id": 1126, "seek": 449380, "start": 4517.2, "end": 4519.88, "text": " It is not using Jigsaw at all.", "tokens": [50364, 307, 13630, 3318, 1823, 11, 597, 307, 2584, 2698, 12, 48172, 24420, 420, 2693, 12879, 24420, 13, 50596, 50596, 400, 550, 291, 393, 11441, 300, 264, 10290, 3125, 24771, 13, 50954, 50954, 286, 632, 257, 1168, 13, 51094, 51094, 682, 264, 4137, 300, 291, 4712, 264, 10444, 365, 508, 17156, 1607, 293, 538, 1228, 13630, 3318, 13, 51354, 51354, 407, 294, 341, 13630, 3318, 11, 307, 309, 4994, 551, 30, 51534, 51534, 467, 307, 406, 1228, 508, 17156, 1607, 412, 439, 13, 51668, 51668, 407, 309, 307, 6456, 322, 1192, 295, 264, 508, 17156, 1607, 3170, 13, 51790, 51790], "temperature": 0.0, "avg_logprob": -0.16166075149385056, "compression_ratio": 1.6851851851851851, "no_speech_prob": 1.2409769624355249e-05}, {"id": 1127, "seek": 449380, "start": 4519.88, "end": 4522.320000000001, "text": " So it is applied on top of the Jigsaw method.", "tokens": [50364, 307, 13630, 3318, 1823, 11, 597, 307, 2584, 2698, 12, 48172, 24420, 420, 2693, 12879, 24420, 13, 50596, 50596, 400, 550, 291, 393, 11441, 300, 264, 10290, 3125, 24771, 13, 50954, 50954, 286, 632, 257, 1168, 13, 51094, 51094, 682, 264, 4137, 300, 291, 4712, 264, 10444, 365, 508, 17156, 1607, 293, 538, 1228, 13630, 3318, 13, 51354, 51354, 407, 294, 341, 13630, 3318, 11, 307, 309, 4994, 551, 30, 51534, 51534, 467, 307, 406, 1228, 508, 17156, 1607, 412, 439, 13, 51668, 51668, 407, 309, 307, 6456, 322, 1192, 295, 264, 508, 17156, 1607, 3170, 13, 51790, 51790], "temperature": 0.0, "avg_logprob": -0.16166075149385056, "compression_ratio": 1.6851851851851851, "no_speech_prob": 1.2409769624355249e-05}, {"id": 1128, "seek": 452232, "start": 4522.32, "end": 4526.28, "text": " So there was a pre-trained network from which you extract features.", "tokens": [50364, 407, 456, 390, 257, 659, 12, 17227, 2001, 3209, 490, 597, 291, 8947, 4122, 13, 50562, 50562, 407, 294, 341, 1389, 11, 300, 659, 12, 17227, 2001, 3209, 307, 264, 508, 17156, 1607, 659, 12, 17227, 2001, 3209, 13, 50786, 50786, 876, 11, 1392, 13, 50836, 50836, 583, 291, 747, 264, 508, 17156, 1607, 659, 12, 17227, 2001, 3209, 293, 550, 291, 1936, 2042, 13630, 3318, 51052, 51052, 322, 1192, 295, 309, 13, 51102, 51102, 1033, 13, 51152, 51152, 1044, 291, 13, 51202, 51202, 1396, 3257, 676, 11, 983, 13630, 3318, 307, 257, 665, 1558, 30, 51554, 51554, 286, 519, 264, 2135, 1333, 295, 24002, 307, 300, 562, 291, 584, 2042, 264, 508, 17156, 1607, 5633, 11, 264, 51758, 51758], "temperature": 0.0, "avg_logprob": -0.2275410011166432, "compression_ratio": 1.8401826484018264, "no_speech_prob": 1.5204688679659739e-05}, {"id": 1129, "seek": 452232, "start": 4526.28, "end": 4530.759999999999, "text": " So in this case, that pre-trained network is the Jigsaw pre-trained network.", "tokens": [50364, 407, 456, 390, 257, 659, 12, 17227, 2001, 3209, 490, 597, 291, 8947, 4122, 13, 50562, 50562, 407, 294, 341, 1389, 11, 300, 659, 12, 17227, 2001, 3209, 307, 264, 508, 17156, 1607, 659, 12, 17227, 2001, 3209, 13, 50786, 50786, 876, 11, 1392, 13, 50836, 50836, 583, 291, 747, 264, 508, 17156, 1607, 659, 12, 17227, 2001, 3209, 293, 550, 291, 1936, 2042, 13630, 3318, 51052, 51052, 322, 1192, 295, 309, 13, 51102, 51102, 1033, 13, 51152, 51152, 1044, 291, 13, 51202, 51202, 1396, 3257, 676, 11, 983, 13630, 3318, 307, 257, 665, 1558, 30, 51554, 51554, 286, 519, 264, 2135, 1333, 295, 24002, 307, 300, 562, 291, 584, 2042, 264, 508, 17156, 1607, 5633, 11, 264, 51758, 51758], "temperature": 0.0, "avg_logprob": -0.2275410011166432, "compression_ratio": 1.8401826484018264, "no_speech_prob": 1.5204688679659739e-05}, {"id": 1130, "seek": 452232, "start": 4530.759999999999, "end": 4531.759999999999, "text": " Oh, okay.", "tokens": [50364, 407, 456, 390, 257, 659, 12, 17227, 2001, 3209, 490, 597, 291, 8947, 4122, 13, 50562, 50562, 407, 294, 341, 1389, 11, 300, 659, 12, 17227, 2001, 3209, 307, 264, 508, 17156, 1607, 659, 12, 17227, 2001, 3209, 13, 50786, 50786, 876, 11, 1392, 13, 50836, 50836, 583, 291, 747, 264, 508, 17156, 1607, 659, 12, 17227, 2001, 3209, 293, 550, 291, 1936, 2042, 13630, 3318, 51052, 51052, 322, 1192, 295, 309, 13, 51102, 51102, 1033, 13, 51152, 51152, 1044, 291, 13, 51202, 51202, 1396, 3257, 676, 11, 983, 13630, 3318, 307, 257, 665, 1558, 30, 51554, 51554, 286, 519, 264, 2135, 1333, 295, 24002, 307, 300, 562, 291, 584, 2042, 264, 508, 17156, 1607, 5633, 11, 264, 51758, 51758], "temperature": 0.0, "avg_logprob": -0.2275410011166432, "compression_ratio": 1.8401826484018264, "no_speech_prob": 1.5204688679659739e-05}, {"id": 1131, "seek": 452232, "start": 4531.759999999999, "end": 4536.08, "text": " But you take the Jigsaw pre-trained network and then you basically perform cluster fit", "tokens": [50364, 407, 456, 390, 257, 659, 12, 17227, 2001, 3209, 490, 597, 291, 8947, 4122, 13, 50562, 50562, 407, 294, 341, 1389, 11, 300, 659, 12, 17227, 2001, 3209, 307, 264, 508, 17156, 1607, 659, 12, 17227, 2001, 3209, 13, 50786, 50786, 876, 11, 1392, 13, 50836, 50836, 583, 291, 747, 264, 508, 17156, 1607, 659, 12, 17227, 2001, 3209, 293, 550, 291, 1936, 2042, 13630, 3318, 51052, 51052, 322, 1192, 295, 309, 13, 51102, 51102, 1033, 13, 51152, 51152, 1044, 291, 13, 51202, 51202, 1396, 3257, 676, 11, 983, 13630, 3318, 307, 257, 665, 1558, 30, 51554, 51554, 286, 519, 264, 2135, 1333, 295, 24002, 307, 300, 562, 291, 584, 2042, 264, 508, 17156, 1607, 5633, 11, 264, 51758, 51758], "temperature": 0.0, "avg_logprob": -0.2275410011166432, "compression_ratio": 1.8401826484018264, "no_speech_prob": 1.5204688679659739e-05}, {"id": 1132, "seek": 452232, "start": 4536.08, "end": 4537.08, "text": " on top of it.", "tokens": [50364, 407, 456, 390, 257, 659, 12, 17227, 2001, 3209, 490, 597, 291, 8947, 4122, 13, 50562, 50562, 407, 294, 341, 1389, 11, 300, 659, 12, 17227, 2001, 3209, 307, 264, 508, 17156, 1607, 659, 12, 17227, 2001, 3209, 13, 50786, 50786, 876, 11, 1392, 13, 50836, 50836, 583, 291, 747, 264, 508, 17156, 1607, 659, 12, 17227, 2001, 3209, 293, 550, 291, 1936, 2042, 13630, 3318, 51052, 51052, 322, 1192, 295, 309, 13, 51102, 51102, 1033, 13, 51152, 51152, 1044, 291, 13, 51202, 51202, 1396, 3257, 676, 11, 983, 13630, 3318, 307, 257, 665, 1558, 30, 51554, 51554, 286, 519, 264, 2135, 1333, 295, 24002, 307, 300, 562, 291, 584, 2042, 264, 508, 17156, 1607, 5633, 11, 264, 51758, 51758], "temperature": 0.0, "avg_logprob": -0.2275410011166432, "compression_ratio": 1.8401826484018264, "no_speech_prob": 1.5204688679659739e-05}, {"id": 1133, "seek": 452232, "start": 4537.08, "end": 4538.08, "text": " Okay.", "tokens": [50364, 407, 456, 390, 257, 659, 12, 17227, 2001, 3209, 490, 597, 291, 8947, 4122, 13, 50562, 50562, 407, 294, 341, 1389, 11, 300, 659, 12, 17227, 2001, 3209, 307, 264, 508, 17156, 1607, 659, 12, 17227, 2001, 3209, 13, 50786, 50786, 876, 11, 1392, 13, 50836, 50836, 583, 291, 747, 264, 508, 17156, 1607, 659, 12, 17227, 2001, 3209, 293, 550, 291, 1936, 2042, 13630, 3318, 51052, 51052, 322, 1192, 295, 309, 13, 51102, 51102, 1033, 13, 51152, 51152, 1044, 291, 13, 51202, 51202, 1396, 3257, 676, 11, 983, 13630, 3318, 307, 257, 665, 1558, 30, 51554, 51554, 286, 519, 264, 2135, 1333, 295, 24002, 307, 300, 562, 291, 584, 2042, 264, 508, 17156, 1607, 5633, 11, 264, 51758, 51758], "temperature": 0.0, "avg_logprob": -0.2275410011166432, "compression_ratio": 1.8401826484018264, "no_speech_prob": 1.5204688679659739e-05}, {"id": 1134, "seek": 452232, "start": 4538.08, "end": 4539.08, "text": " Thank you.", "tokens": [50364, 407, 456, 390, 257, 659, 12, 17227, 2001, 3209, 490, 597, 291, 8947, 4122, 13, 50562, 50562, 407, 294, 341, 1389, 11, 300, 659, 12, 17227, 2001, 3209, 307, 264, 508, 17156, 1607, 659, 12, 17227, 2001, 3209, 13, 50786, 50786, 876, 11, 1392, 13, 50836, 50836, 583, 291, 747, 264, 508, 17156, 1607, 659, 12, 17227, 2001, 3209, 293, 550, 291, 1936, 2042, 13630, 3318, 51052, 51052, 322, 1192, 295, 309, 13, 51102, 51102, 1033, 13, 51152, 51152, 1044, 291, 13, 51202, 51202, 1396, 3257, 676, 11, 983, 13630, 3318, 307, 257, 665, 1558, 30, 51554, 51554, 286, 519, 264, 2135, 1333, 295, 24002, 307, 300, 562, 291, 584, 2042, 264, 508, 17156, 1607, 5633, 11, 264, 51758, 51758], "temperature": 0.0, "avg_logprob": -0.2275410011166432, "compression_ratio": 1.8401826484018264, "no_speech_prob": 1.5204688679659739e-05}, {"id": 1135, "seek": 452232, "start": 4539.08, "end": 4546.12, "text": " Then Lordway, why cluster fit is a good idea?", "tokens": [50364, 407, 456, 390, 257, 659, 12, 17227, 2001, 3209, 490, 597, 291, 8947, 4122, 13, 50562, 50562, 407, 294, 341, 1389, 11, 300, 659, 12, 17227, 2001, 3209, 307, 264, 508, 17156, 1607, 659, 12, 17227, 2001, 3209, 13, 50786, 50786, 876, 11, 1392, 13, 50836, 50836, 583, 291, 747, 264, 508, 17156, 1607, 659, 12, 17227, 2001, 3209, 293, 550, 291, 1936, 2042, 13630, 3318, 51052, 51052, 322, 1192, 295, 309, 13, 51102, 51102, 1033, 13, 51152, 51152, 1044, 291, 13, 51202, 51202, 1396, 3257, 676, 11, 983, 13630, 3318, 307, 257, 665, 1558, 30, 51554, 51554, 286, 519, 264, 2135, 1333, 295, 24002, 307, 300, 562, 291, 584, 2042, 264, 508, 17156, 1607, 5633, 11, 264, 51758, 51758], "temperature": 0.0, "avg_logprob": -0.2275410011166432, "compression_ratio": 1.8401826484018264, "no_speech_prob": 1.5204688679659739e-05}, {"id": 1136, "seek": 452232, "start": 4546.12, "end": 4550.2, "text": " I think the main sort of intuition is that when you say perform the Jigsaw task, the", "tokens": [50364, 407, 456, 390, 257, 659, 12, 17227, 2001, 3209, 490, 597, 291, 8947, 4122, 13, 50562, 50562, 407, 294, 341, 1389, 11, 300, 659, 12, 17227, 2001, 3209, 307, 264, 508, 17156, 1607, 659, 12, 17227, 2001, 3209, 13, 50786, 50786, 876, 11, 1392, 13, 50836, 50836, 583, 291, 747, 264, 508, 17156, 1607, 659, 12, 17227, 2001, 3209, 293, 550, 291, 1936, 2042, 13630, 3318, 51052, 51052, 322, 1192, 295, 309, 13, 51102, 51102, 1033, 13, 51152, 51152, 1044, 291, 13, 51202, 51202, 1396, 3257, 676, 11, 983, 13630, 3318, 307, 257, 665, 1558, 30, 51554, 51554, 286, 519, 264, 2135, 1333, 295, 24002, 307, 300, 562, 291, 584, 2042, 264, 508, 17156, 1607, 5633, 11, 264, 51758, 51758], "temperature": 0.0, "avg_logprob": -0.2275410011166432, "compression_ratio": 1.8401826484018264, "no_speech_prob": 1.5204688679659739e-05}, {"id": 1137, "seek": 455020, "start": 4550.2, "end": 4555.4, "text": " last layer becomes very much fine tuned for that particular Jigsaw task.", "tokens": [50364, 1036, 4583, 3643, 588, 709, 2489, 10870, 337, 300, 1729, 508, 17156, 1607, 5633, 13, 50624, 50624, 407, 321, 1866, 300, 14170, 352, 760, 13, 50726, 50726, 823, 11, 562, 291, 747, 729, 4122, 293, 291, 2042, 596, 48673, 322, 309, 11, 291, 393, 519, 295, 50940, 50940, 341, 382, 1936, 291, 434, 12245, 264, 2372, 295, 1589, 13, 51202, 51202, 759, 286, 3847, 264, 1150, 3209, 281, 3838, 1121, 735, 264, 4122, 295, 264, 700, 3209, 11, 51380, 51380, 286, 576, 1936, 483, 264, 912, 1900, 3209, 13, 51544, 51544, 583, 498, 286, 3847, 264, 1150, 3209, 787, 281, 6069, 437, 5267, 366, 41877, 1214, 294, 51760, 51760], "temperature": 0.0, "avg_logprob": -0.147933427277986, "compression_ratio": 1.701818181818182, "no_speech_prob": 1.1300000551273115e-05}, {"id": 1138, "seek": 455020, "start": 4555.4, "end": 4557.44, "text": " So we saw that accuracy go down.", "tokens": [50364, 1036, 4583, 3643, 588, 709, 2489, 10870, 337, 300, 1729, 508, 17156, 1607, 5633, 13, 50624, 50624, 407, 321, 1866, 300, 14170, 352, 760, 13, 50726, 50726, 823, 11, 562, 291, 747, 729, 4122, 293, 291, 2042, 596, 48673, 322, 309, 11, 291, 393, 519, 295, 50940, 50940, 341, 382, 1936, 291, 434, 12245, 264, 2372, 295, 1589, 13, 51202, 51202, 759, 286, 3847, 264, 1150, 3209, 281, 3838, 1121, 735, 264, 4122, 295, 264, 700, 3209, 11, 51380, 51380, 286, 576, 1936, 483, 264, 912, 1900, 3209, 13, 51544, 51544, 583, 498, 286, 3847, 264, 1150, 3209, 787, 281, 6069, 437, 5267, 366, 41877, 1214, 294, 51760, 51760], "temperature": 0.0, "avg_logprob": -0.147933427277986, "compression_ratio": 1.701818181818182, "no_speech_prob": 1.1300000551273115e-05}, {"id": 1139, "seek": 455020, "start": 4557.44, "end": 4561.72, "text": " Now, when you take those features and you perform clustering on it, you can think of", "tokens": [50364, 1036, 4583, 3643, 588, 709, 2489, 10870, 337, 300, 1729, 508, 17156, 1607, 5633, 13, 50624, 50624, 407, 321, 1866, 300, 14170, 352, 760, 13, 50726, 50726, 823, 11, 562, 291, 747, 729, 4122, 293, 291, 2042, 596, 48673, 322, 309, 11, 291, 393, 519, 295, 50940, 50940, 341, 382, 1936, 291, 434, 12245, 264, 2372, 295, 1589, 13, 51202, 51202, 759, 286, 3847, 264, 1150, 3209, 281, 3838, 1121, 735, 264, 4122, 295, 264, 700, 3209, 11, 51380, 51380, 286, 576, 1936, 483, 264, 912, 1900, 3209, 13, 51544, 51544, 583, 498, 286, 3847, 264, 1150, 3209, 787, 281, 6069, 437, 5267, 366, 41877, 1214, 294, 51760, 51760], "temperature": 0.0, "avg_logprob": -0.147933427277986, "compression_ratio": 1.701818181818182, "no_speech_prob": 1.1300000551273115e-05}, {"id": 1140, "seek": 455020, "start": 4561.72, "end": 4566.96, "text": " this as basically you're reducing the amount of information.", "tokens": [50364, 1036, 4583, 3643, 588, 709, 2489, 10870, 337, 300, 1729, 508, 17156, 1607, 5633, 13, 50624, 50624, 407, 321, 1866, 300, 14170, 352, 760, 13, 50726, 50726, 823, 11, 562, 291, 747, 729, 4122, 293, 291, 2042, 596, 48673, 322, 309, 11, 291, 393, 519, 295, 50940, 50940, 341, 382, 1936, 291, 434, 12245, 264, 2372, 295, 1589, 13, 51202, 51202, 759, 286, 3847, 264, 1150, 3209, 281, 3838, 1121, 735, 264, 4122, 295, 264, 700, 3209, 11, 51380, 51380, 286, 576, 1936, 483, 264, 912, 1900, 3209, 13, 51544, 51544, 583, 498, 286, 3847, 264, 1150, 3209, 787, 281, 6069, 437, 5267, 366, 41877, 1214, 294, 51760, 51760], "temperature": 0.0, "avg_logprob": -0.147933427277986, "compression_ratio": 1.701818181818182, "no_speech_prob": 1.1300000551273115e-05}, {"id": 1141, "seek": 455020, "start": 4566.96, "end": 4570.5199999999995, "text": " If I train the second network to directly regress the features of the first network,", "tokens": [50364, 1036, 4583, 3643, 588, 709, 2489, 10870, 337, 300, 1729, 508, 17156, 1607, 5633, 13, 50624, 50624, 407, 321, 1866, 300, 14170, 352, 760, 13, 50726, 50726, 823, 11, 562, 291, 747, 729, 4122, 293, 291, 2042, 596, 48673, 322, 309, 11, 291, 393, 519, 295, 50940, 50940, 341, 382, 1936, 291, 434, 12245, 264, 2372, 295, 1589, 13, 51202, 51202, 759, 286, 3847, 264, 1150, 3209, 281, 3838, 1121, 735, 264, 4122, 295, 264, 700, 3209, 11, 51380, 51380, 286, 576, 1936, 483, 264, 912, 1900, 3209, 13, 51544, 51544, 583, 498, 286, 3847, 264, 1150, 3209, 787, 281, 6069, 437, 5267, 366, 41877, 1214, 294, 51760, 51760], "temperature": 0.0, "avg_logprob": -0.147933427277986, "compression_ratio": 1.701818181818182, "no_speech_prob": 1.1300000551273115e-05}, {"id": 1142, "seek": 455020, "start": 4570.5199999999995, "end": 4573.8, "text": " I would basically get the same exact network.", "tokens": [50364, 1036, 4583, 3643, 588, 709, 2489, 10870, 337, 300, 1729, 508, 17156, 1607, 5633, 13, 50624, 50624, 407, 321, 1866, 300, 14170, 352, 760, 13, 50726, 50726, 823, 11, 562, 291, 747, 729, 4122, 293, 291, 2042, 596, 48673, 322, 309, 11, 291, 393, 519, 295, 50940, 50940, 341, 382, 1936, 291, 434, 12245, 264, 2372, 295, 1589, 13, 51202, 51202, 759, 286, 3847, 264, 1150, 3209, 281, 3838, 1121, 735, 264, 4122, 295, 264, 700, 3209, 11, 51380, 51380, 286, 576, 1936, 483, 264, 912, 1900, 3209, 13, 51544, 51544, 583, 498, 286, 3847, 264, 1150, 3209, 787, 281, 6069, 437, 5267, 366, 41877, 1214, 294, 51760, 51760], "temperature": 0.0, "avg_logprob": -0.147933427277986, "compression_ratio": 1.701818181818182, "no_speech_prob": 1.1300000551273115e-05}, {"id": 1143, "seek": 455020, "start": 4573.8, "end": 4578.12, "text": " But if I train the second network only to predict what images are grouped together in", "tokens": [50364, 1036, 4583, 3643, 588, 709, 2489, 10870, 337, 300, 1729, 508, 17156, 1607, 5633, 13, 50624, 50624, 407, 321, 1866, 300, 14170, 352, 760, 13, 50726, 50726, 823, 11, 562, 291, 747, 729, 4122, 293, 291, 2042, 596, 48673, 322, 309, 11, 291, 393, 519, 295, 50940, 50940, 341, 382, 1936, 291, 434, 12245, 264, 2372, 295, 1589, 13, 51202, 51202, 759, 286, 3847, 264, 1150, 3209, 281, 3838, 1121, 735, 264, 4122, 295, 264, 700, 3209, 11, 51380, 51380, 286, 576, 1936, 483, 264, 912, 1900, 3209, 13, 51544, 51544, 583, 498, 286, 3847, 264, 1150, 3209, 787, 281, 6069, 437, 5267, 366, 41877, 1214, 294, 51760, 51760], "temperature": 0.0, "avg_logprob": -0.147933427277986, "compression_ratio": 1.701818181818182, "no_speech_prob": 1.1300000551273115e-05}, {"id": 1144, "seek": 457812, "start": 4578.12, "end": 4582.64, "text": " the first one, I'm actually predicting lesser information.", "tokens": [50364, 264, 700, 472, 11, 286, 478, 767, 32884, 22043, 1589, 13, 50590, 50590, 400, 527, 1953, 307, 1936, 300, 596, 48673, 307, 512, 733, 295, 257, 5658, 17933, 6532, 13, 50801, 50801, 407, 309, 311, 534, 12720, 439, 264, 24617, 300, 366, 2685, 281, 508, 17156, 1607, 490, 300, 4111, 51090, 51090, 1901, 13, 51140, 51140, 400, 370, 264, 1150, 3209, 307, 767, 2539, 746, 4748, 544, 19577, 13, 51424, 51424, 663, 311, 1333, 295, 264, 1778, 337, 341, 5120, 382, 731, 13, 51536, 51536, 407, 294, 341, 1389, 11, 321, 1333, 295, 25790, 984, 29562, 300, 17291, 538, 767, 10711, 278, 2372, 51802, 51802, 295, 7645, 5658, 13, 51852, 51852], "temperature": 0.0, "avg_logprob": -0.09620304445249844, "compression_ratio": 1.7269503546099292, "no_speech_prob": 1.112513473344734e-05}, {"id": 1145, "seek": 457812, "start": 4582.64, "end": 4586.86, "text": " And our thinking is basically that clustering is some kind of a noise removal technique.", "tokens": [50364, 264, 700, 472, 11, 286, 478, 767, 32884, 22043, 1589, 13, 50590, 50590, 400, 527, 1953, 307, 1936, 300, 596, 48673, 307, 512, 733, 295, 257, 5658, 17933, 6532, 13, 50801, 50801, 407, 309, 311, 534, 12720, 439, 264, 24617, 300, 366, 2685, 281, 508, 17156, 1607, 490, 300, 4111, 51090, 51090, 1901, 13, 51140, 51140, 400, 370, 264, 1150, 3209, 307, 767, 2539, 746, 4748, 544, 19577, 13, 51424, 51424, 663, 311, 1333, 295, 264, 1778, 337, 341, 5120, 382, 731, 13, 51536, 51536, 407, 294, 341, 1389, 11, 321, 1333, 295, 25790, 984, 29562, 300, 17291, 538, 767, 10711, 278, 2372, 51802, 51802, 295, 7645, 5658, 13, 51852, 51852], "temperature": 0.0, "avg_logprob": -0.09620304445249844, "compression_ratio": 1.7269503546099292, "no_speech_prob": 1.112513473344734e-05}, {"id": 1146, "seek": 457812, "start": 4586.86, "end": 4592.64, "text": " So it's really removing all the artifacts that are specific to Jigsaw from that feature", "tokens": [50364, 264, 700, 472, 11, 286, 478, 767, 32884, 22043, 1589, 13, 50590, 50590, 400, 527, 1953, 307, 1936, 300, 596, 48673, 307, 512, 733, 295, 257, 5658, 17933, 6532, 13, 50801, 50801, 407, 309, 311, 534, 12720, 439, 264, 24617, 300, 366, 2685, 281, 508, 17156, 1607, 490, 300, 4111, 51090, 51090, 1901, 13, 51140, 51140, 400, 370, 264, 1150, 3209, 307, 767, 2539, 746, 4748, 544, 19577, 13, 51424, 51424, 663, 311, 1333, 295, 264, 1778, 337, 341, 5120, 382, 731, 13, 51536, 51536, 407, 294, 341, 1389, 11, 321, 1333, 295, 25790, 984, 29562, 300, 17291, 538, 767, 10711, 278, 2372, 51802, 51802, 295, 7645, 5658, 13, 51852, 51852], "temperature": 0.0, "avg_logprob": -0.09620304445249844, "compression_ratio": 1.7269503546099292, "no_speech_prob": 1.112513473344734e-05}, {"id": 1147, "seek": 457812, "start": 4592.64, "end": 4593.64, "text": " space.", "tokens": [50364, 264, 700, 472, 11, 286, 478, 767, 32884, 22043, 1589, 13, 50590, 50590, 400, 527, 1953, 307, 1936, 300, 596, 48673, 307, 512, 733, 295, 257, 5658, 17933, 6532, 13, 50801, 50801, 407, 309, 311, 534, 12720, 439, 264, 24617, 300, 366, 2685, 281, 508, 17156, 1607, 490, 300, 4111, 51090, 51090, 1901, 13, 51140, 51140, 400, 370, 264, 1150, 3209, 307, 767, 2539, 746, 4748, 544, 19577, 13, 51424, 51424, 663, 311, 1333, 295, 264, 1778, 337, 341, 5120, 382, 731, 13, 51536, 51536, 407, 294, 341, 1389, 11, 321, 1333, 295, 25790, 984, 29562, 300, 17291, 538, 767, 10711, 278, 2372, 51802, 51802, 295, 7645, 5658, 13, 51852, 51852], "temperature": 0.0, "avg_logprob": -0.09620304445249844, "compression_ratio": 1.7269503546099292, "no_speech_prob": 1.112513473344734e-05}, {"id": 1148, "seek": 457812, "start": 4593.64, "end": 4599.32, "text": " And so the second network is actually learning something slightly more generic.", "tokens": [50364, 264, 700, 472, 11, 286, 478, 767, 32884, 22043, 1589, 13, 50590, 50590, 400, 527, 1953, 307, 1936, 300, 596, 48673, 307, 512, 733, 295, 257, 5658, 17933, 6532, 13, 50801, 50801, 407, 309, 311, 534, 12720, 439, 264, 24617, 300, 366, 2685, 281, 508, 17156, 1607, 490, 300, 4111, 51090, 51090, 1901, 13, 51140, 51140, 400, 370, 264, 1150, 3209, 307, 767, 2539, 746, 4748, 544, 19577, 13, 51424, 51424, 663, 311, 1333, 295, 264, 1778, 337, 341, 5120, 382, 731, 13, 51536, 51536, 407, 294, 341, 1389, 11, 321, 1333, 295, 25790, 984, 29562, 300, 17291, 538, 767, 10711, 278, 2372, 51802, 51802, 295, 7645, 5658, 13, 51852, 51852], "temperature": 0.0, "avg_logprob": -0.09620304445249844, "compression_ratio": 1.7269503546099292, "no_speech_prob": 1.112513473344734e-05}, {"id": 1149, "seek": 457812, "start": 4599.32, "end": 4601.5599999999995, "text": " That's sort of the reason for this experiment as well.", "tokens": [50364, 264, 700, 472, 11, 286, 478, 767, 32884, 22043, 1589, 13, 50590, 50590, 400, 527, 1953, 307, 1936, 300, 596, 48673, 307, 512, 733, 295, 257, 5658, 17933, 6532, 13, 50801, 50801, 407, 309, 311, 534, 12720, 439, 264, 24617, 300, 366, 2685, 281, 508, 17156, 1607, 490, 300, 4111, 51090, 51090, 1901, 13, 51140, 51140, 400, 370, 264, 1150, 3209, 307, 767, 2539, 746, 4748, 544, 19577, 13, 51424, 51424, 663, 311, 1333, 295, 264, 1778, 337, 341, 5120, 382, 731, 13, 51536, 51536, 407, 294, 341, 1389, 11, 321, 1333, 295, 25790, 984, 29562, 300, 17291, 538, 767, 10711, 278, 2372, 51802, 51802, 295, 7645, 5658, 13, 51852, 51852], "temperature": 0.0, "avg_logprob": -0.09620304445249844, "compression_ratio": 1.7269503546099292, "no_speech_prob": 1.112513473344734e-05}, {"id": 1150, "seek": 457812, "start": 4601.5599999999995, "end": 4606.88, "text": " So in this case, we sort of empirically validate that hypothesis by actually injecting amount", "tokens": [50364, 264, 700, 472, 11, 286, 478, 767, 32884, 22043, 1589, 13, 50590, 50590, 400, 527, 1953, 307, 1936, 300, 596, 48673, 307, 512, 733, 295, 257, 5658, 17933, 6532, 13, 50801, 50801, 407, 309, 311, 534, 12720, 439, 264, 24617, 300, 366, 2685, 281, 508, 17156, 1607, 490, 300, 4111, 51090, 51090, 1901, 13, 51140, 51140, 400, 370, 264, 1150, 3209, 307, 767, 2539, 746, 4748, 544, 19577, 13, 51424, 51424, 663, 311, 1333, 295, 264, 1778, 337, 341, 5120, 382, 731, 13, 51536, 51536, 407, 294, 341, 1389, 11, 321, 1333, 295, 25790, 984, 29562, 300, 17291, 538, 767, 10711, 278, 2372, 51802, 51802, 295, 7645, 5658, 13, 51852, 51852], "temperature": 0.0, "avg_logprob": -0.09620304445249844, "compression_ratio": 1.7269503546099292, "no_speech_prob": 1.112513473344734e-05}, {"id": 1151, "seek": 457812, "start": 4606.88, "end": 4607.88, "text": " of label noise.", "tokens": [50364, 264, 700, 472, 11, 286, 478, 767, 32884, 22043, 1589, 13, 50590, 50590, 400, 527, 1953, 307, 1936, 300, 596, 48673, 307, 512, 733, 295, 257, 5658, 17933, 6532, 13, 50801, 50801, 407, 309, 311, 534, 12720, 439, 264, 24617, 300, 366, 2685, 281, 508, 17156, 1607, 490, 300, 4111, 51090, 51090, 1901, 13, 51140, 51140, 400, 370, 264, 1150, 3209, 307, 767, 2539, 746, 4748, 544, 19577, 13, 51424, 51424, 663, 311, 1333, 295, 264, 1778, 337, 341, 5120, 382, 731, 13, 51536, 51536, 407, 294, 341, 1389, 11, 321, 1333, 295, 25790, 984, 29562, 300, 17291, 538, 767, 10711, 278, 2372, 51802, 51802, 295, 7645, 5658, 13, 51852, 51852], "temperature": 0.0, "avg_logprob": -0.09620304445249844, "compression_ratio": 1.7269503546099292, "no_speech_prob": 1.112513473344734e-05}, {"id": 1152, "seek": 460788, "start": 4607.88, "end": 4611.64, "text": " So the last layer basically is going to get more and more noisy.", "tokens": [50364, 407, 264, 1036, 4583, 1936, 307, 516, 281, 483, 544, 293, 544, 24518, 13, 50552, 50552, 400, 562, 291, 360, 13630, 3318, 322, 1192, 295, 341, 11, 291, 767, 797, 536, 10444, 13, 50716, 50716, 407, 300, 311, 1333, 295, 527, 24071, 295, 341, 17291, 13, 50926, 50926, 286, 632, 1071, 1168, 13, 51074, 51074, 407, 630, 291, 3481, 264, 3389, 295, 13630, 3318, 322, 2657, 17784, 30, 51264, 51264, 2589, 309, 2042, 382, 731, 420, 390, 309, 445, 869, 294, 21538, 30, 51468, 51468, 407, 309, 10332, 731, 294, 17784, 382, 731, 13, 51582, 51582, 407, 309, 767, 26213, 731, 13, 51852, 51852], "temperature": 0.0, "avg_logprob": -0.17792138513529077, "compression_ratio": 1.7327935222672064, "no_speech_prob": 2.0145233065704815e-05}, {"id": 1153, "seek": 460788, "start": 4611.64, "end": 4614.92, "text": " And when you do cluster fit on top of this, you actually again see improvement.", "tokens": [50364, 407, 264, 1036, 4583, 1936, 307, 516, 281, 483, 544, 293, 544, 24518, 13, 50552, 50552, 400, 562, 291, 360, 13630, 3318, 322, 1192, 295, 341, 11, 291, 767, 797, 536, 10444, 13, 50716, 50716, 407, 300, 311, 1333, 295, 527, 24071, 295, 341, 17291, 13, 50926, 50926, 286, 632, 1071, 1168, 13, 51074, 51074, 407, 630, 291, 3481, 264, 3389, 295, 13630, 3318, 322, 2657, 17784, 30, 51264, 51264, 2589, 309, 2042, 382, 731, 420, 390, 309, 445, 869, 294, 21538, 30, 51468, 51468, 407, 309, 10332, 731, 294, 17784, 382, 731, 13, 51582, 51582, 407, 309, 767, 26213, 731, 13, 51852, 51852], "temperature": 0.0, "avg_logprob": -0.17792138513529077, "compression_ratio": 1.7327935222672064, "no_speech_prob": 2.0145233065704815e-05}, {"id": 1154, "seek": 460788, "start": 4614.92, "end": 4619.12, "text": " So that's sort of our validation of this hypothesis.", "tokens": [50364, 407, 264, 1036, 4583, 1936, 307, 516, 281, 483, 544, 293, 544, 24518, 13, 50552, 50552, 400, 562, 291, 360, 13630, 3318, 322, 1192, 295, 341, 11, 291, 767, 797, 536, 10444, 13, 50716, 50716, 407, 300, 311, 1333, 295, 527, 24071, 295, 341, 17291, 13, 50926, 50926, 286, 632, 1071, 1168, 13, 51074, 51074, 407, 630, 291, 3481, 264, 3389, 295, 13630, 3318, 322, 2657, 17784, 30, 51264, 51264, 2589, 309, 2042, 382, 731, 420, 390, 309, 445, 869, 294, 21538, 30, 51468, 51468, 407, 309, 10332, 731, 294, 17784, 382, 731, 13, 51582, 51582, 407, 309, 767, 26213, 731, 13, 51852, 51852], "temperature": 0.0, "avg_logprob": -0.17792138513529077, "compression_ratio": 1.7327935222672064, "no_speech_prob": 2.0145233065704815e-05}, {"id": 1155, "seek": 460788, "start": 4619.12, "end": 4622.08, "text": " I had another question.", "tokens": [50364, 407, 264, 1036, 4583, 1936, 307, 516, 281, 483, 544, 293, 544, 24518, 13, 50552, 50552, 400, 562, 291, 360, 13630, 3318, 322, 1192, 295, 341, 11, 291, 767, 797, 536, 10444, 13, 50716, 50716, 407, 300, 311, 1333, 295, 527, 24071, 295, 341, 17291, 13, 50926, 50926, 286, 632, 1071, 1168, 13, 51074, 51074, 407, 630, 291, 3481, 264, 3389, 295, 13630, 3318, 322, 2657, 17784, 30, 51264, 51264, 2589, 309, 2042, 382, 731, 420, 390, 309, 445, 869, 294, 21538, 30, 51468, 51468, 407, 309, 10332, 731, 294, 17784, 382, 731, 13, 51582, 51582, 407, 309, 767, 26213, 731, 13, 51852, 51852], "temperature": 0.0, "avg_logprob": -0.17792138513529077, "compression_ratio": 1.7327935222672064, "no_speech_prob": 2.0145233065704815e-05}, {"id": 1156, "seek": 460788, "start": 4622.08, "end": 4625.88, "text": " So did you measure the performance of cluster fit on object detection?", "tokens": [50364, 407, 264, 1036, 4583, 1936, 307, 516, 281, 483, 544, 293, 544, 24518, 13, 50552, 50552, 400, 562, 291, 360, 13630, 3318, 322, 1192, 295, 341, 11, 291, 767, 797, 536, 10444, 13, 50716, 50716, 407, 300, 311, 1333, 295, 527, 24071, 295, 341, 17291, 13, 50926, 50926, 286, 632, 1071, 1168, 13, 51074, 51074, 407, 630, 291, 3481, 264, 3389, 295, 13630, 3318, 322, 2657, 17784, 30, 51264, 51264, 2589, 309, 2042, 382, 731, 420, 390, 309, 445, 869, 294, 21538, 30, 51468, 51468, 407, 309, 10332, 731, 294, 17784, 382, 731, 13, 51582, 51582, 407, 309, 767, 26213, 731, 13, 51852, 51852], "temperature": 0.0, "avg_logprob": -0.17792138513529077, "compression_ratio": 1.7327935222672064, "no_speech_prob": 2.0145233065704815e-05}, {"id": 1157, "seek": 460788, "start": 4625.88, "end": 4629.96, "text": " Did it perform as well or was it just great in classification?", "tokens": [50364, 407, 264, 1036, 4583, 1936, 307, 516, 281, 483, 544, 293, 544, 24518, 13, 50552, 50552, 400, 562, 291, 360, 13630, 3318, 322, 1192, 295, 341, 11, 291, 767, 797, 536, 10444, 13, 50716, 50716, 407, 300, 311, 1333, 295, 527, 24071, 295, 341, 17291, 13, 50926, 50926, 286, 632, 1071, 1168, 13, 51074, 51074, 407, 630, 291, 3481, 264, 3389, 295, 13630, 3318, 322, 2657, 17784, 30, 51264, 51264, 2589, 309, 2042, 382, 731, 420, 390, 309, 445, 869, 294, 21538, 30, 51468, 51468, 407, 309, 10332, 731, 294, 17784, 382, 731, 13, 51582, 51582, 407, 309, 767, 26213, 731, 13, 51852, 51852], "temperature": 0.0, "avg_logprob": -0.17792138513529077, "compression_ratio": 1.7327935222672064, "no_speech_prob": 2.0145233065704815e-05}, {"id": 1158, "seek": 460788, "start": 4629.96, "end": 4632.24, "text": " So it performed well in detection as well.", "tokens": [50364, 407, 264, 1036, 4583, 1936, 307, 516, 281, 483, 544, 293, 544, 24518, 13, 50552, 50552, 400, 562, 291, 360, 13630, 3318, 322, 1192, 295, 341, 11, 291, 767, 797, 536, 10444, 13, 50716, 50716, 407, 300, 311, 1333, 295, 527, 24071, 295, 341, 17291, 13, 50926, 50926, 286, 632, 1071, 1168, 13, 51074, 51074, 407, 630, 291, 3481, 264, 3389, 295, 13630, 3318, 322, 2657, 17784, 30, 51264, 51264, 2589, 309, 2042, 382, 731, 420, 390, 309, 445, 869, 294, 21538, 30, 51468, 51468, 407, 309, 10332, 731, 294, 17784, 382, 731, 13, 51582, 51582, 407, 309, 767, 26213, 731, 13, 51852, 51852], "temperature": 0.0, "avg_logprob": -0.17792138513529077, "compression_ratio": 1.7327935222672064, "no_speech_prob": 2.0145233065704815e-05}, {"id": 1159, "seek": 460788, "start": 4632.24, "end": 4637.64, "text": " So it actually performs well.", "tokens": [50364, 407, 264, 1036, 4583, 1936, 307, 516, 281, 483, 544, 293, 544, 24518, 13, 50552, 50552, 400, 562, 291, 360, 13630, 3318, 322, 1192, 295, 341, 11, 291, 767, 797, 536, 10444, 13, 50716, 50716, 407, 300, 311, 1333, 295, 527, 24071, 295, 341, 17291, 13, 50926, 50926, 286, 632, 1071, 1168, 13, 51074, 51074, 407, 630, 291, 3481, 264, 3389, 295, 13630, 3318, 322, 2657, 17784, 30, 51264, 51264, 2589, 309, 2042, 382, 731, 420, 390, 309, 445, 869, 294, 21538, 30, 51468, 51468, 407, 309, 10332, 731, 294, 17784, 382, 731, 13, 51582, 51582, 407, 309, 767, 26213, 731, 13, 51852, 51852], "temperature": 0.0, "avg_logprob": -0.17792138513529077, "compression_ratio": 1.7327935222672064, "no_speech_prob": 2.0145233065704815e-05}, {"id": 1160, "seek": 463764, "start": 4637.64, "end": 4643.84, "text": " So there were initial experiments on detection where it actually does perform well.", "tokens": [50364, 407, 456, 645, 5883, 12050, 322, 17784, 689, 309, 767, 775, 2042, 731, 13, 50674, 50674, 492, 630, 406, 534, 2944, 257, 688, 322, 264, 17784, 4171, 295, 309, 294, 341, 1729, 3035, 13, 50896, 50896, 492, 645, 1333, 295, 544, 3102, 294, 19817, 3337, 420, 411, 8213, 21538, 733, 295, 12050, 13, 51204, 51204, 1033, 11, 570, 286, 390, 1953, 498, 321, 366, 1455, 613, 35899, 16949, 11, 321, 366, 1936, 1455, 51488, 51488, 309, 11299, 281, 21538, 5633, 2602, 295, 257, 17784, 5633, 13, 51774, 51774], "temperature": 0.0, "avg_logprob": -0.22747063106960722, "compression_ratio": 1.7447698744769875, "no_speech_prob": 1.952434286067728e-05}, {"id": 1161, "seek": 463764, "start": 4643.84, "end": 4648.280000000001, "text": " We did not really push a lot on the detection aspect of it in this particular paper.", "tokens": [50364, 407, 456, 645, 5883, 12050, 322, 17784, 689, 309, 767, 775, 2042, 731, 13, 50674, 50674, 492, 630, 406, 534, 2944, 257, 688, 322, 264, 17784, 4171, 295, 309, 294, 341, 1729, 3035, 13, 50896, 50896, 492, 645, 1333, 295, 544, 3102, 294, 19817, 3337, 420, 411, 8213, 21538, 733, 295, 12050, 13, 51204, 51204, 1033, 11, 570, 286, 390, 1953, 498, 321, 366, 1455, 613, 35899, 16949, 11, 321, 366, 1936, 1455, 51488, 51488, 309, 11299, 281, 21538, 5633, 2602, 295, 257, 17784, 5633, 13, 51774, 51774], "temperature": 0.0, "avg_logprob": -0.22747063106960722, "compression_ratio": 1.7447698744769875, "no_speech_prob": 1.952434286067728e-05}, {"id": 1162, "seek": 463764, "start": 4648.280000000001, "end": 4654.4400000000005, "text": " We were sort of more interested in retrieval or like linear classification kind of experiments.", "tokens": [50364, 407, 456, 645, 5883, 12050, 322, 17784, 689, 309, 767, 775, 2042, 731, 13, 50674, 50674, 492, 630, 406, 534, 2944, 257, 688, 322, 264, 17784, 4171, 295, 309, 294, 341, 1729, 3035, 13, 50896, 50896, 492, 645, 1333, 295, 544, 3102, 294, 19817, 3337, 420, 411, 8213, 21538, 733, 295, 12050, 13, 51204, 51204, 1033, 11, 570, 286, 390, 1953, 498, 321, 366, 1455, 613, 35899, 16949, 11, 321, 366, 1936, 1455, 51488, 51488, 309, 11299, 281, 21538, 5633, 2602, 295, 257, 17784, 5633, 13, 51774, 51774], "temperature": 0.0, "avg_logprob": -0.22747063106960722, "compression_ratio": 1.7447698744769875, "no_speech_prob": 1.952434286067728e-05}, {"id": 1163, "seek": 463764, "start": 4654.4400000000005, "end": 4660.12, "text": " Okay, because I was thinking if we are making these pseudo labels, we are basically making", "tokens": [50364, 407, 456, 645, 5883, 12050, 322, 17784, 689, 309, 767, 775, 2042, 731, 13, 50674, 50674, 492, 630, 406, 534, 2944, 257, 688, 322, 264, 17784, 4171, 295, 309, 294, 341, 1729, 3035, 13, 50896, 50896, 492, 645, 1333, 295, 544, 3102, 294, 19817, 3337, 420, 411, 8213, 21538, 733, 295, 12050, 13, 51204, 51204, 1033, 11, 570, 286, 390, 1953, 498, 321, 366, 1455, 613, 35899, 16949, 11, 321, 366, 1936, 1455, 51488, 51488, 309, 11299, 281, 21538, 5633, 2602, 295, 257, 17784, 5633, 13, 51774, 51774], "temperature": 0.0, "avg_logprob": -0.22747063106960722, "compression_ratio": 1.7447698744769875, "no_speech_prob": 1.952434286067728e-05}, {"id": 1164, "seek": 463764, "start": 4660.12, "end": 4665.84, "text": " it unable to classification task instead of a detection task.", "tokens": [50364, 407, 456, 645, 5883, 12050, 322, 17784, 689, 309, 767, 775, 2042, 731, 13, 50674, 50674, 492, 630, 406, 534, 2944, 257, 688, 322, 264, 17784, 4171, 295, 309, 294, 341, 1729, 3035, 13, 50896, 50896, 492, 645, 1333, 295, 544, 3102, 294, 19817, 3337, 420, 411, 8213, 21538, 733, 295, 12050, 13, 51204, 51204, 1033, 11, 570, 286, 390, 1953, 498, 321, 366, 1455, 613, 35899, 16949, 11, 321, 366, 1936, 1455, 51488, 51488, 309, 11299, 281, 21538, 5633, 2602, 295, 257, 17784, 5633, 13, 51774, 51774], "temperature": 0.0, "avg_logprob": -0.22747063106960722, "compression_ratio": 1.7447698744769875, "no_speech_prob": 1.952434286067728e-05}, {"id": 1165, "seek": 466584, "start": 4665.84, "end": 4669.6, "text": " Maybe we could lose some of those features that Jigsaw got.", "tokens": [50364, 2704, 321, 727, 3624, 512, 295, 729, 4122, 300, 508, 17156, 1607, 658, 13, 50552, 50552, 1779, 11, 300, 307, 1944, 13, 50724, 50724, 1711, 1935, 264, 5883, 12050, 300, 286, 632, 1190, 630, 406, 1643, 281, 3402, 341, 13, 50962, 50962, 821, 390, 10444, 294, 17784, 13, 51028, 51028, 467, 390, 6696, 13, 51096, 51096, 583, 17784, 13797, 4787, 411, 264, 7417, 294, 3389, 307, 1217, 370, 1359, 300, 51304, 51304, 264, 13797, 366, 767, 5101, 588, 1359, 294, 2674, 13, 51512, 51512, 1033, 11, 1309, 291, 13, 51678, 51678], "temperature": 0.0, "avg_logprob": -0.2528409445157615, "compression_ratio": 1.6379310344827587, "no_speech_prob": 1.834064460126683e-05}, {"id": 1166, "seek": 466584, "start": 4669.6, "end": 4673.04, "text": " Right, that is possible.", "tokens": [50364, 2704, 321, 727, 3624, 512, 295, 729, 4122, 300, 508, 17156, 1607, 658, 13, 50552, 50552, 1779, 11, 300, 307, 1944, 13, 50724, 50724, 1711, 1935, 264, 5883, 12050, 300, 286, 632, 1190, 630, 406, 1643, 281, 3402, 341, 13, 50962, 50962, 821, 390, 10444, 294, 17784, 13, 51028, 51028, 467, 390, 6696, 13, 51096, 51096, 583, 17784, 13797, 4787, 411, 264, 7417, 294, 3389, 307, 1217, 370, 1359, 300, 51304, 51304, 264, 13797, 366, 767, 5101, 588, 1359, 294, 2674, 13, 51512, 51512, 1033, 11, 1309, 291, 13, 51678, 51678], "temperature": 0.0, "avg_logprob": -0.2528409445157615, "compression_ratio": 1.6379310344827587, "no_speech_prob": 1.834064460126683e-05}, {"id": 1167, "seek": 466584, "start": 4673.04, "end": 4677.8, "text": " At least the initial experiments that I had run did not seem to suggest this.", "tokens": [50364, 2704, 321, 727, 3624, 512, 295, 729, 4122, 300, 508, 17156, 1607, 658, 13, 50552, 50552, 1779, 11, 300, 307, 1944, 13, 50724, 50724, 1711, 1935, 264, 5883, 12050, 300, 286, 632, 1190, 630, 406, 1643, 281, 3402, 341, 13, 50962, 50962, 821, 390, 10444, 294, 17784, 13, 51028, 51028, 467, 390, 6696, 13, 51096, 51096, 583, 17784, 13797, 4787, 411, 264, 7417, 294, 3389, 307, 1217, 370, 1359, 300, 51304, 51304, 264, 13797, 366, 767, 5101, 588, 1359, 294, 2674, 13, 51512, 51512, 1033, 11, 1309, 291, 13, 51678, 51678], "temperature": 0.0, "avg_logprob": -0.2528409445157615, "compression_ratio": 1.6379310344827587, "no_speech_prob": 1.834064460126683e-05}, {"id": 1168, "seek": 466584, "start": 4677.8, "end": 4679.12, "text": " There was improvement in detection.", "tokens": [50364, 2704, 321, 727, 3624, 512, 295, 729, 4122, 300, 508, 17156, 1607, 658, 13, 50552, 50552, 1779, 11, 300, 307, 1944, 13, 50724, 50724, 1711, 1935, 264, 5883, 12050, 300, 286, 632, 1190, 630, 406, 1643, 281, 3402, 341, 13, 50962, 50962, 821, 390, 10444, 294, 17784, 13, 51028, 51028, 467, 390, 6696, 13, 51096, 51096, 583, 17784, 13797, 4787, 411, 264, 7417, 294, 3389, 307, 1217, 370, 1359, 300, 51304, 51304, 264, 13797, 366, 767, 5101, 588, 1359, 294, 2674, 13, 51512, 51512, 1033, 11, 1309, 291, 13, 51678, 51678], "temperature": 0.0, "avg_logprob": -0.2528409445157615, "compression_ratio": 1.6379310344827587, "no_speech_prob": 1.834064460126683e-05}, {"id": 1169, "seek": 466584, "start": 4679.12, "end": 4680.4800000000005, "text": " It was minor.", "tokens": [50364, 2704, 321, 727, 3624, 512, 295, 729, 4122, 300, 508, 17156, 1607, 658, 13, 50552, 50552, 1779, 11, 300, 307, 1944, 13, 50724, 50724, 1711, 1935, 264, 5883, 12050, 300, 286, 632, 1190, 630, 406, 1643, 281, 3402, 341, 13, 50962, 50962, 821, 390, 10444, 294, 17784, 13, 51028, 51028, 467, 390, 6696, 13, 51096, 51096, 583, 17784, 13797, 4787, 411, 264, 7417, 294, 3389, 307, 1217, 370, 1359, 300, 51304, 51304, 264, 13797, 366, 767, 5101, 588, 1359, 294, 2674, 13, 51512, 51512, 1033, 11, 1309, 291, 13, 51678, 51678], "temperature": 0.0, "avg_logprob": -0.2528409445157615, "compression_ratio": 1.6379310344827587, "no_speech_prob": 1.834064460126683e-05}, {"id": 1170, "seek": 466584, "start": 4680.4800000000005, "end": 4684.64, "text": " But detection improvements overall like the gap in performance is already so small that", "tokens": [50364, 2704, 321, 727, 3624, 512, 295, 729, 4122, 300, 508, 17156, 1607, 658, 13, 50552, 50552, 1779, 11, 300, 307, 1944, 13, 50724, 50724, 1711, 1935, 264, 5883, 12050, 300, 286, 632, 1190, 630, 406, 1643, 281, 3402, 341, 13, 50962, 50962, 821, 390, 10444, 294, 17784, 13, 51028, 51028, 467, 390, 6696, 13, 51096, 51096, 583, 17784, 13797, 4787, 411, 264, 7417, 294, 3389, 307, 1217, 370, 1359, 300, 51304, 51304, 264, 13797, 366, 767, 5101, 588, 1359, 294, 2674, 13, 51512, 51512, 1033, 11, 1309, 291, 13, 51678, 51678], "temperature": 0.0, "avg_logprob": -0.2528409445157615, "compression_ratio": 1.6379310344827587, "no_speech_prob": 1.834064460126683e-05}, {"id": 1171, "seek": 466584, "start": 4684.64, "end": 4688.8, "text": " the improvements are actually generally very small in general.", "tokens": [50364, 2704, 321, 727, 3624, 512, 295, 729, 4122, 300, 508, 17156, 1607, 658, 13, 50552, 50552, 1779, 11, 300, 307, 1944, 13, 50724, 50724, 1711, 1935, 264, 5883, 12050, 300, 286, 632, 1190, 630, 406, 1643, 281, 3402, 341, 13, 50962, 50962, 821, 390, 10444, 294, 17784, 13, 51028, 51028, 467, 390, 6696, 13, 51096, 51096, 583, 17784, 13797, 4787, 411, 264, 7417, 294, 3389, 307, 1217, 370, 1359, 300, 51304, 51304, 264, 13797, 366, 767, 5101, 588, 1359, 294, 2674, 13, 51512, 51512, 1033, 11, 1309, 291, 13, 51678, 51678], "temperature": 0.0, "avg_logprob": -0.2528409445157615, "compression_ratio": 1.6379310344827587, "no_speech_prob": 1.834064460126683e-05}, {"id": 1172, "seek": 466584, "start": 4688.8, "end": 4692.12, "text": " Okay, thank you.", "tokens": [50364, 2704, 321, 727, 3624, 512, 295, 729, 4122, 300, 508, 17156, 1607, 658, 13, 50552, 50552, 1779, 11, 300, 307, 1944, 13, 50724, 50724, 1711, 1935, 264, 5883, 12050, 300, 286, 632, 1190, 630, 406, 1643, 281, 3402, 341, 13, 50962, 50962, 821, 390, 10444, 294, 17784, 13, 51028, 51028, 467, 390, 6696, 13, 51096, 51096, 583, 17784, 13797, 4787, 411, 264, 7417, 294, 3389, 307, 1217, 370, 1359, 300, 51304, 51304, 264, 13797, 366, 767, 5101, 588, 1359, 294, 2674, 13, 51512, 51512, 1033, 11, 1309, 291, 13, 51678, 51678], "temperature": 0.0, "avg_logprob": -0.2528409445157615, "compression_ratio": 1.6379310344827587, "no_speech_prob": 1.834064460126683e-05}, {"id": 1173, "seek": 469212, "start": 4692.12, "end": 4696.5599999999995, "text": " I had a doubt in the same cluster fit algorithm.", "tokens": [50364, 286, 632, 257, 6385, 294, 264, 912, 13630, 3318, 9284, 13, 50586, 50586, 407, 486, 264, 2572, 4583, 295, 13630, 3318, 9284, 406, 483, 797, 49851, 394, 281, 264, 16949, 300, 50942, 50942, 645, 1143, 337, 3097, 309, 322, 300, 5633, 30, 51110, 51110, 467, 3643, 1570, 49851, 394, 13, 51170, 51170, 407, 437, 321, 1352, 390, 498, 291, 645, 281, 1333, 295, 264, 3035, 575, 341, 7542, 11, 286, 500, 380, 362, 309, 294, 51388, 51388, 264, 9788, 11, 7015, 11, 264, 3035, 575, 264, 7542, 689, 1392, 11, 341, 1729, 7542, 689, 51762, 51762], "temperature": 0.0, "avg_logprob": -0.1821787503300881, "compression_ratio": 1.7534246575342465, "no_speech_prob": 3.8822603528387845e-05}, {"id": 1174, "seek": 469212, "start": 4696.5599999999995, "end": 4703.68, "text": " So will the final layer of cluster fit algorithm not get again covariant to the labels that", "tokens": [50364, 286, 632, 257, 6385, 294, 264, 912, 13630, 3318, 9284, 13, 50586, 50586, 407, 486, 264, 2572, 4583, 295, 13630, 3318, 9284, 406, 483, 797, 49851, 394, 281, 264, 16949, 300, 50942, 50942, 645, 1143, 337, 3097, 309, 322, 300, 5633, 30, 51110, 51110, 467, 3643, 1570, 49851, 394, 13, 51170, 51170, 407, 437, 321, 1352, 390, 498, 291, 645, 281, 1333, 295, 264, 3035, 575, 341, 7542, 11, 286, 500, 380, 362, 309, 294, 51388, 51388, 264, 9788, 11, 7015, 11, 264, 3035, 575, 264, 7542, 689, 1392, 11, 341, 1729, 7542, 689, 51762, 51762], "temperature": 0.0, "avg_logprob": -0.1821787503300881, "compression_ratio": 1.7534246575342465, "no_speech_prob": 3.8822603528387845e-05}, {"id": 1175, "seek": 469212, "start": 4703.68, "end": 4707.04, "text": " were used for training it on that task?", "tokens": [50364, 286, 632, 257, 6385, 294, 264, 912, 13630, 3318, 9284, 13, 50586, 50586, 407, 486, 264, 2572, 4583, 295, 13630, 3318, 9284, 406, 483, 797, 49851, 394, 281, 264, 16949, 300, 50942, 50942, 645, 1143, 337, 3097, 309, 322, 300, 5633, 30, 51110, 51110, 467, 3643, 1570, 49851, 394, 13, 51170, 51170, 407, 437, 321, 1352, 390, 498, 291, 645, 281, 1333, 295, 264, 3035, 575, 341, 7542, 11, 286, 500, 380, 362, 309, 294, 51388, 51388, 264, 9788, 11, 7015, 11, 264, 3035, 575, 264, 7542, 689, 1392, 11, 341, 1729, 7542, 689, 51762, 51762], "temperature": 0.0, "avg_logprob": -0.1821787503300881, "compression_ratio": 1.7534246575342465, "no_speech_prob": 3.8822603528387845e-05}, {"id": 1176, "seek": 469212, "start": 4707.04, "end": 4708.24, "text": " It becomes less covariant.", "tokens": [50364, 286, 632, 257, 6385, 294, 264, 912, 13630, 3318, 9284, 13, 50586, 50586, 407, 486, 264, 2572, 4583, 295, 13630, 3318, 9284, 406, 483, 797, 49851, 394, 281, 264, 16949, 300, 50942, 50942, 645, 1143, 337, 3097, 309, 322, 300, 5633, 30, 51110, 51110, 467, 3643, 1570, 49851, 394, 13, 51170, 51170, 407, 437, 321, 1352, 390, 498, 291, 645, 281, 1333, 295, 264, 3035, 575, 341, 7542, 11, 286, 500, 380, 362, 309, 294, 51388, 51388, 264, 9788, 11, 7015, 11, 264, 3035, 575, 264, 7542, 689, 1392, 11, 341, 1729, 7542, 689, 51762, 51762], "temperature": 0.0, "avg_logprob": -0.1821787503300881, "compression_ratio": 1.7534246575342465, "no_speech_prob": 3.8822603528387845e-05}, {"id": 1177, "seek": 469212, "start": 4708.24, "end": 4712.599999999999, "text": " So what we found was if you were to sort of the paper has this plot, I don't have it in", "tokens": [50364, 286, 632, 257, 6385, 294, 264, 912, 13630, 3318, 9284, 13, 50586, 50586, 407, 486, 264, 2572, 4583, 295, 13630, 3318, 9284, 406, 483, 797, 49851, 394, 281, 264, 16949, 300, 50942, 50942, 645, 1143, 337, 3097, 309, 322, 300, 5633, 30, 51110, 51110, 467, 3643, 1570, 49851, 394, 13, 51170, 51170, 407, 437, 321, 1352, 390, 498, 291, 645, 281, 1333, 295, 264, 3035, 575, 341, 7542, 11, 286, 500, 380, 362, 309, 294, 51388, 51388, 264, 9788, 11, 7015, 11, 264, 3035, 575, 264, 7542, 689, 1392, 11, 341, 1729, 7542, 689, 51762, 51762], "temperature": 0.0, "avg_logprob": -0.1821787503300881, "compression_ratio": 1.7534246575342465, "no_speech_prob": 3.8822603528387845e-05}, {"id": 1178, "seek": 469212, "start": 4712.599999999999, "end": 4720.08, "text": " the slides, unfortunately, the paper has the plot where okay, this particular plot where", "tokens": [50364, 286, 632, 257, 6385, 294, 264, 912, 13630, 3318, 9284, 13, 50586, 50586, 407, 486, 264, 2572, 4583, 295, 13630, 3318, 9284, 406, 483, 797, 49851, 394, 281, 264, 16949, 300, 50942, 50942, 645, 1143, 337, 3097, 309, 322, 300, 5633, 30, 51110, 51110, 467, 3643, 1570, 49851, 394, 13, 51170, 51170, 407, 437, 321, 1352, 390, 498, 291, 645, 281, 1333, 295, 264, 3035, 575, 341, 7542, 11, 286, 500, 380, 362, 309, 294, 51388, 51388, 264, 9788, 11, 7015, 11, 264, 3035, 575, 264, 7542, 689, 1392, 11, 341, 1729, 7542, 689, 51762, 51762], "temperature": 0.0, "avg_logprob": -0.1821787503300881, "compression_ratio": 1.7534246575342465, "no_speech_prob": 3.8822603528387845e-05}, {"id": 1179, "seek": 472008, "start": 4720.08, "end": 4723.44, "text": " we were looking at con one to res five, cluster fit is much better.", "tokens": [50364, 321, 645, 1237, 412, 416, 472, 281, 725, 1732, 11, 13630, 3318, 307, 709, 1101, 13, 50532, 50532, 407, 264, 725, 1732, 281, 725, 1451, 7417, 337, 13630, 3318, 307, 709, 4356, 813, 309, 307, 337, 508, 17156, 1607, 50764, 50764, 420, 6922, 7129, 13, 50814, 50814, 583, 390, 309, 1101, 813, 725, 1451, 420, 390, 309, 4748, 5324, 30, 51058, 51058, 407, 309, 390, 322, 322, 15216, 34, 21538, 11, 309, 390, 1101, 13, 51262, 51262, 583, 337, 584, 661, 9608, 411, 3256, 2533, 11, 309, 390, 4748, 5324, 13, 51436, 51436, 407, 309, 630, 406, 2584, 3191, 264, 1154, 13, 51556, 51556, 1033, 11, 1309, 291, 13, 51714, 51714, 3013, 390, 1333, 295, 264, 12335, 337, 3026, 75, 13, 51828, 51828], "temperature": 0.0, "avg_logprob": -0.2905789489746094, "compression_ratio": 1.777327935222672, "no_speech_prob": 5.306403181748465e-05}, {"id": 1180, "seek": 472008, "start": 4723.44, "end": 4728.08, "text": " So the res five to res four gap for cluster fit is much smaller than it is for Jigsaw", "tokens": [50364, 321, 645, 1237, 412, 416, 472, 281, 725, 1732, 11, 13630, 3318, 307, 709, 1101, 13, 50532, 50532, 407, 264, 725, 1732, 281, 725, 1451, 7417, 337, 13630, 3318, 307, 709, 4356, 813, 309, 307, 337, 508, 17156, 1607, 50764, 50764, 420, 6922, 7129, 13, 50814, 50814, 583, 390, 309, 1101, 813, 725, 1451, 420, 390, 309, 4748, 5324, 30, 51058, 51058, 407, 309, 390, 322, 322, 15216, 34, 21538, 11, 309, 390, 1101, 13, 51262, 51262, 583, 337, 584, 661, 9608, 411, 3256, 2533, 11, 309, 390, 4748, 5324, 13, 51436, 51436, 407, 309, 630, 406, 2584, 3191, 264, 1154, 13, 51556, 51556, 1033, 11, 1309, 291, 13, 51714, 51714, 3013, 390, 1333, 295, 264, 12335, 337, 3026, 75, 13, 51828, 51828], "temperature": 0.0, "avg_logprob": -0.2905789489746094, "compression_ratio": 1.777327935222672, "no_speech_prob": 5.306403181748465e-05}, {"id": 1181, "seek": 472008, "start": 4728.08, "end": 4729.08, "text": " or Rocknet.", "tokens": [50364, 321, 645, 1237, 412, 416, 472, 281, 725, 1732, 11, 13630, 3318, 307, 709, 1101, 13, 50532, 50532, 407, 264, 725, 1732, 281, 725, 1451, 7417, 337, 13630, 3318, 307, 709, 4356, 813, 309, 307, 337, 508, 17156, 1607, 50764, 50764, 420, 6922, 7129, 13, 50814, 50814, 583, 390, 309, 1101, 813, 725, 1451, 420, 390, 309, 4748, 5324, 30, 51058, 51058, 407, 309, 390, 322, 322, 15216, 34, 21538, 11, 309, 390, 1101, 13, 51262, 51262, 583, 337, 584, 661, 9608, 411, 3256, 2533, 11, 309, 390, 4748, 5324, 13, 51436, 51436, 407, 309, 630, 406, 2584, 3191, 264, 1154, 13, 51556, 51556, 1033, 11, 1309, 291, 13, 51714, 51714, 3013, 390, 1333, 295, 264, 12335, 337, 3026, 75, 13, 51828, 51828], "temperature": 0.0, "avg_logprob": -0.2905789489746094, "compression_ratio": 1.777327935222672, "no_speech_prob": 5.306403181748465e-05}, {"id": 1182, "seek": 472008, "start": 4729.08, "end": 4733.96, "text": " But was it better than res four or was it slightly worse?", "tokens": [50364, 321, 645, 1237, 412, 416, 472, 281, 725, 1732, 11, 13630, 3318, 307, 709, 1101, 13, 50532, 50532, 407, 264, 725, 1732, 281, 725, 1451, 7417, 337, 13630, 3318, 307, 709, 4356, 813, 309, 307, 337, 508, 17156, 1607, 50764, 50764, 420, 6922, 7129, 13, 50814, 50814, 583, 390, 309, 1101, 813, 725, 1451, 420, 390, 309, 4748, 5324, 30, 51058, 51058, 407, 309, 390, 322, 322, 15216, 34, 21538, 11, 309, 390, 1101, 13, 51262, 51262, 583, 337, 584, 661, 9608, 411, 3256, 2533, 11, 309, 390, 4748, 5324, 13, 51436, 51436, 407, 309, 630, 406, 2584, 3191, 264, 1154, 13, 51556, 51556, 1033, 11, 1309, 291, 13, 51714, 51714, 3013, 390, 1333, 295, 264, 12335, 337, 3026, 75, 13, 51828, 51828], "temperature": 0.0, "avg_logprob": -0.2905789489746094, "compression_ratio": 1.777327935222672, "no_speech_prob": 5.306403181748465e-05}, {"id": 1183, "seek": 472008, "start": 4733.96, "end": 4738.04, "text": " So it was on on VOC classification, it was better.", "tokens": [50364, 321, 645, 1237, 412, 416, 472, 281, 725, 1732, 11, 13630, 3318, 307, 709, 1101, 13, 50532, 50532, 407, 264, 725, 1732, 281, 725, 1451, 7417, 337, 13630, 3318, 307, 709, 4356, 813, 309, 307, 337, 508, 17156, 1607, 50764, 50764, 420, 6922, 7129, 13, 50814, 50814, 583, 390, 309, 1101, 813, 725, 1451, 420, 390, 309, 4748, 5324, 30, 51058, 51058, 407, 309, 390, 322, 322, 15216, 34, 21538, 11, 309, 390, 1101, 13, 51262, 51262, 583, 337, 584, 661, 9608, 411, 3256, 2533, 11, 309, 390, 4748, 5324, 13, 51436, 51436, 407, 309, 630, 406, 2584, 3191, 264, 1154, 13, 51556, 51556, 1033, 11, 1309, 291, 13, 51714, 51714, 3013, 390, 1333, 295, 264, 12335, 337, 3026, 75, 13, 51828, 51828], "temperature": 0.0, "avg_logprob": -0.2905789489746094, "compression_ratio": 1.777327935222672, "no_speech_prob": 5.306403181748465e-05}, {"id": 1184, "seek": 472008, "start": 4738.04, "end": 4741.5199999999995, "text": " But for say other tasks like image net, it was slightly worse.", "tokens": [50364, 321, 645, 1237, 412, 416, 472, 281, 725, 1732, 11, 13630, 3318, 307, 709, 1101, 13, 50532, 50532, 407, 264, 725, 1732, 281, 725, 1451, 7417, 337, 13630, 3318, 307, 709, 4356, 813, 309, 307, 337, 508, 17156, 1607, 50764, 50764, 420, 6922, 7129, 13, 50814, 50814, 583, 390, 309, 1101, 813, 725, 1451, 420, 390, 309, 4748, 5324, 30, 51058, 51058, 407, 309, 390, 322, 322, 15216, 34, 21538, 11, 309, 390, 1101, 13, 51262, 51262, 583, 337, 584, 661, 9608, 411, 3256, 2533, 11, 309, 390, 4748, 5324, 13, 51436, 51436, 407, 309, 630, 406, 2584, 3191, 264, 1154, 13, 51556, 51556, 1033, 11, 1309, 291, 13, 51714, 51714, 3013, 390, 1333, 295, 264, 12335, 337, 3026, 75, 13, 51828, 51828], "temperature": 0.0, "avg_logprob": -0.2905789489746094, "compression_ratio": 1.777327935222672, "no_speech_prob": 5.306403181748465e-05}, {"id": 1185, "seek": 472008, "start": 4741.5199999999995, "end": 4743.92, "text": " So it did not completely fix the problem.", "tokens": [50364, 321, 645, 1237, 412, 416, 472, 281, 725, 1732, 11, 13630, 3318, 307, 709, 1101, 13, 50532, 50532, 407, 264, 725, 1732, 281, 725, 1451, 7417, 337, 13630, 3318, 307, 709, 4356, 813, 309, 307, 337, 508, 17156, 1607, 50764, 50764, 420, 6922, 7129, 13, 50814, 50814, 583, 390, 309, 1101, 813, 725, 1451, 420, 390, 309, 4748, 5324, 30, 51058, 51058, 407, 309, 390, 322, 322, 15216, 34, 21538, 11, 309, 390, 1101, 13, 51262, 51262, 583, 337, 584, 661, 9608, 411, 3256, 2533, 11, 309, 390, 4748, 5324, 13, 51436, 51436, 407, 309, 630, 406, 2584, 3191, 264, 1154, 13, 51556, 51556, 1033, 11, 1309, 291, 13, 51714, 51714, 3013, 390, 1333, 295, 264, 12335, 337, 3026, 75, 13, 51828, 51828], "temperature": 0.0, "avg_logprob": -0.2905789489746094, "compression_ratio": 1.777327935222672, "no_speech_prob": 5.306403181748465e-05}, {"id": 1186, "seek": 472008, "start": 4743.92, "end": 4747.08, "text": " Okay, thank you.", "tokens": [50364, 321, 645, 1237, 412, 416, 472, 281, 725, 1732, 11, 13630, 3318, 307, 709, 1101, 13, 50532, 50532, 407, 264, 725, 1732, 281, 725, 1451, 7417, 337, 13630, 3318, 307, 709, 4356, 813, 309, 307, 337, 508, 17156, 1607, 50764, 50764, 420, 6922, 7129, 13, 50814, 50814, 583, 390, 309, 1101, 813, 725, 1451, 420, 390, 309, 4748, 5324, 30, 51058, 51058, 407, 309, 390, 322, 322, 15216, 34, 21538, 11, 309, 390, 1101, 13, 51262, 51262, 583, 337, 584, 661, 9608, 411, 3256, 2533, 11, 309, 390, 4748, 5324, 13, 51436, 51436, 407, 309, 630, 406, 2584, 3191, 264, 1154, 13, 51556, 51556, 1033, 11, 1309, 291, 13, 51714, 51714, 3013, 390, 1333, 295, 264, 12335, 337, 3026, 75, 13, 51828, 51828], "temperature": 0.0, "avg_logprob": -0.2905789489746094, "compression_ratio": 1.777327935222672, "no_speech_prob": 5.306403181748465e-05}, {"id": 1187, "seek": 472008, "start": 4747.08, "end": 4749.36, "text": " Which was sort of the motivation for Perl.", "tokens": [50364, 321, 645, 1237, 412, 416, 472, 281, 725, 1732, 11, 13630, 3318, 307, 709, 1101, 13, 50532, 50532, 407, 264, 725, 1732, 281, 725, 1451, 7417, 337, 13630, 3318, 307, 709, 4356, 813, 309, 307, 337, 508, 17156, 1607, 50764, 50764, 420, 6922, 7129, 13, 50814, 50814, 583, 390, 309, 1101, 813, 725, 1451, 420, 390, 309, 4748, 5324, 30, 51058, 51058, 407, 309, 390, 322, 322, 15216, 34, 21538, 11, 309, 390, 1101, 13, 51262, 51262, 583, 337, 584, 661, 9608, 411, 3256, 2533, 11, 309, 390, 4748, 5324, 13, 51436, 51436, 407, 309, 630, 406, 2584, 3191, 264, 1154, 13, 51556, 51556, 1033, 11, 1309, 291, 13, 51714, 51714, 3013, 390, 1333, 295, 264, 12335, 337, 3026, 75, 13, 51828, 51828], "temperature": 0.0, "avg_logprob": -0.2905789489746094, "compression_ratio": 1.777327935222672, "no_speech_prob": 5.306403181748465e-05}, {"id": 1188, "seek": 474936, "start": 4749.36, "end": 4752.599999999999, "text": " So basically, I'll not talk about Perl.", "tokens": [50364, 407, 1936, 11, 286, 603, 406, 751, 466, 3026, 75, 13, 50526, 50526, 407, 3026, 75, 390, 1333, 295, 4232, 490, 264, 17291, 797, 11, 300, 291, 643, 281, 312, 33270, 394, 281, 613, 50782, 50782, 659, 25111, 9608, 13, 50884, 50884, 407, 949, 286, 483, 666, 264, 4365, 295, 3026, 75, 11, 286, 486, 751, 534, 257, 707, 857, 466, 294, 2674, 51212, 51212, 8712, 488, 2539, 13, 51316, 51316, 1012, 867, 2077, 360, 286, 362, 11, 538, 264, 636, 30, 51434, 51434, 2119, 2077, 544, 420, 1570, 13, 51528, 51528, 1033, 11, 370, 869, 13, 51662, 51662], "temperature": 0.0, "avg_logprob": -0.2225423000826694, "compression_ratio": 1.5, "no_speech_prob": 3.1688578019384295e-05}, {"id": 1189, "seek": 474936, "start": 4752.599999999999, "end": 4757.719999999999, "text": " So Perl was sort of born from the hypothesis again, that you need to be invariant to these", "tokens": [50364, 407, 1936, 11, 286, 603, 406, 751, 466, 3026, 75, 13, 50526, 50526, 407, 3026, 75, 390, 1333, 295, 4232, 490, 264, 17291, 797, 11, 300, 291, 643, 281, 312, 33270, 394, 281, 613, 50782, 50782, 659, 25111, 9608, 13, 50884, 50884, 407, 949, 286, 483, 666, 264, 4365, 295, 3026, 75, 11, 286, 486, 751, 534, 257, 707, 857, 466, 294, 2674, 51212, 51212, 8712, 488, 2539, 13, 51316, 51316, 1012, 867, 2077, 360, 286, 362, 11, 538, 264, 636, 30, 51434, 51434, 2119, 2077, 544, 420, 1570, 13, 51528, 51528, 1033, 11, 370, 869, 13, 51662, 51662], "temperature": 0.0, "avg_logprob": -0.2225423000826694, "compression_ratio": 1.5, "no_speech_prob": 3.1688578019384295e-05}, {"id": 1190, "seek": 474936, "start": 4757.719999999999, "end": 4759.759999999999, "text": " pretext tasks.", "tokens": [50364, 407, 1936, 11, 286, 603, 406, 751, 466, 3026, 75, 13, 50526, 50526, 407, 3026, 75, 390, 1333, 295, 4232, 490, 264, 17291, 797, 11, 300, 291, 643, 281, 312, 33270, 394, 281, 613, 50782, 50782, 659, 25111, 9608, 13, 50884, 50884, 407, 949, 286, 483, 666, 264, 4365, 295, 3026, 75, 11, 286, 486, 751, 534, 257, 707, 857, 466, 294, 2674, 51212, 51212, 8712, 488, 2539, 13, 51316, 51316, 1012, 867, 2077, 360, 286, 362, 11, 538, 264, 636, 30, 51434, 51434, 2119, 2077, 544, 420, 1570, 13, 51528, 51528, 1033, 11, 370, 869, 13, 51662, 51662], "temperature": 0.0, "avg_logprob": -0.2225423000826694, "compression_ratio": 1.5, "no_speech_prob": 3.1688578019384295e-05}, {"id": 1191, "seek": 474936, "start": 4759.759999999999, "end": 4766.32, "text": " So before I get into the details of Perl, I will talk really a little bit about in general", "tokens": [50364, 407, 1936, 11, 286, 603, 406, 751, 466, 3026, 75, 13, 50526, 50526, 407, 3026, 75, 390, 1333, 295, 4232, 490, 264, 17291, 797, 11, 300, 291, 643, 281, 312, 33270, 394, 281, 613, 50782, 50782, 659, 25111, 9608, 13, 50884, 50884, 407, 949, 286, 483, 666, 264, 4365, 295, 3026, 75, 11, 286, 486, 751, 534, 257, 707, 857, 466, 294, 2674, 51212, 51212, 8712, 488, 2539, 13, 51316, 51316, 1012, 867, 2077, 360, 286, 362, 11, 538, 264, 636, 30, 51434, 51434, 2119, 2077, 544, 420, 1570, 13, 51528, 51528, 1033, 11, 370, 869, 13, 51662, 51662], "temperature": 0.0, "avg_logprob": -0.2225423000826694, "compression_ratio": 1.5, "no_speech_prob": 3.1688578019384295e-05}, {"id": 1192, "seek": 474936, "start": 4766.32, "end": 4768.4, "text": " contrastive learning.", "tokens": [50364, 407, 1936, 11, 286, 603, 406, 751, 466, 3026, 75, 13, 50526, 50526, 407, 3026, 75, 390, 1333, 295, 4232, 490, 264, 17291, 797, 11, 300, 291, 643, 281, 312, 33270, 394, 281, 613, 50782, 50782, 659, 25111, 9608, 13, 50884, 50884, 407, 949, 286, 483, 666, 264, 4365, 295, 3026, 75, 11, 286, 486, 751, 534, 257, 707, 857, 466, 294, 2674, 51212, 51212, 8712, 488, 2539, 13, 51316, 51316, 1012, 867, 2077, 360, 286, 362, 11, 538, 264, 636, 30, 51434, 51434, 2119, 2077, 544, 420, 1570, 13, 51528, 51528, 1033, 11, 370, 869, 13, 51662, 51662], "temperature": 0.0, "avg_logprob": -0.2225423000826694, "compression_ratio": 1.5, "no_speech_prob": 3.1688578019384295e-05}, {"id": 1193, "seek": 474936, "start": 4768.4, "end": 4770.759999999999, "text": " How many minutes do I have, by the way?", "tokens": [50364, 407, 1936, 11, 286, 603, 406, 751, 466, 3026, 75, 13, 50526, 50526, 407, 3026, 75, 390, 1333, 295, 4232, 490, 264, 17291, 797, 11, 300, 291, 643, 281, 312, 33270, 394, 281, 613, 50782, 50782, 659, 25111, 9608, 13, 50884, 50884, 407, 949, 286, 483, 666, 264, 4365, 295, 3026, 75, 11, 286, 486, 751, 534, 257, 707, 857, 466, 294, 2674, 51212, 51212, 8712, 488, 2539, 13, 51316, 51316, 1012, 867, 2077, 360, 286, 362, 11, 538, 264, 636, 30, 51434, 51434, 2119, 2077, 544, 420, 1570, 13, 51528, 51528, 1033, 11, 370, 869, 13, 51662, 51662], "temperature": 0.0, "avg_logprob": -0.2225423000826694, "compression_ratio": 1.5, "no_speech_prob": 3.1688578019384295e-05}, {"id": 1194, "seek": 474936, "start": 4770.759999999999, "end": 4772.639999999999, "text": " 15 minutes more or less.", "tokens": [50364, 407, 1936, 11, 286, 603, 406, 751, 466, 3026, 75, 13, 50526, 50526, 407, 3026, 75, 390, 1333, 295, 4232, 490, 264, 17291, 797, 11, 300, 291, 643, 281, 312, 33270, 394, 281, 613, 50782, 50782, 659, 25111, 9608, 13, 50884, 50884, 407, 949, 286, 483, 666, 264, 4365, 295, 3026, 75, 11, 286, 486, 751, 534, 257, 707, 857, 466, 294, 2674, 51212, 51212, 8712, 488, 2539, 13, 51316, 51316, 1012, 867, 2077, 360, 286, 362, 11, 538, 264, 636, 30, 51434, 51434, 2119, 2077, 544, 420, 1570, 13, 51528, 51528, 1033, 11, 370, 869, 13, 51662, 51662], "temperature": 0.0, "avg_logprob": -0.2225423000826694, "compression_ratio": 1.5, "no_speech_prob": 3.1688578019384295e-05}, {"id": 1195, "seek": 474936, "start": 4772.639999999999, "end": 4775.32, "text": " Okay, so great.", "tokens": [50364, 407, 1936, 11, 286, 603, 406, 751, 466, 3026, 75, 13, 50526, 50526, 407, 3026, 75, 390, 1333, 295, 4232, 490, 264, 17291, 797, 11, 300, 291, 643, 281, 312, 33270, 394, 281, 613, 50782, 50782, 659, 25111, 9608, 13, 50884, 50884, 407, 949, 286, 483, 666, 264, 4365, 295, 3026, 75, 11, 286, 486, 751, 534, 257, 707, 857, 466, 294, 2674, 51212, 51212, 8712, 488, 2539, 13, 51316, 51316, 1012, 867, 2077, 360, 286, 362, 11, 538, 264, 636, 30, 51434, 51434, 2119, 2077, 544, 420, 1570, 13, 51528, 51528, 1033, 11, 370, 869, 13, 51662, 51662], "temperature": 0.0, "avg_logprob": -0.2225423000826694, "compression_ratio": 1.5, "no_speech_prob": 3.1688578019384295e-05}, {"id": 1196, "seek": 477532, "start": 4775.32, "end": 4782.24, "text": " So contrastive learning is basically a sort of general framework that tries to learn a", "tokens": [50364, 407, 8712, 488, 2539, 307, 1936, 257, 1333, 295, 2674, 8388, 300, 9898, 281, 1466, 257, 50710, 50710, 4111, 1901, 300, 393, 10432, 1214, 420, 1333, 295, 829, 1214, 2793, 300, 366, 4077, 51008, 51008, 293, 2944, 4936, 2793, 300, 366, 406, 4077, 13, 51146, 51146, 407, 294, 341, 1389, 11, 3811, 411, 264, 3344, 9002, 366, 264, 4077, 2793, 11, 264, 22897, 366, 4077, 51386, 51386, 293, 264, 9656, 366, 264, 4077, 2793, 13, 51522, 51522, 509, 603, 8947, 4122, 337, 1184, 295, 613, 1412, 2793, 807, 257, 5507, 3209, 11, 597, 51818, 51818], "temperature": 0.0, "avg_logprob": -0.12393707590004832, "compression_ratio": 1.858974358974359, "no_speech_prob": 1.7777059838408604e-05}, {"id": 1197, "seek": 477532, "start": 4782.24, "end": 4788.2, "text": " feature space that can combine together or sort of put together points that are related", "tokens": [50364, 407, 8712, 488, 2539, 307, 1936, 257, 1333, 295, 2674, 8388, 300, 9898, 281, 1466, 257, 50710, 50710, 4111, 1901, 300, 393, 10432, 1214, 420, 1333, 295, 829, 1214, 2793, 300, 366, 4077, 51008, 51008, 293, 2944, 4936, 2793, 300, 366, 406, 4077, 13, 51146, 51146, 407, 294, 341, 1389, 11, 3811, 411, 264, 3344, 9002, 366, 264, 4077, 2793, 11, 264, 22897, 366, 4077, 51386, 51386, 293, 264, 9656, 366, 264, 4077, 2793, 13, 51522, 51522, 509, 603, 8947, 4122, 337, 1184, 295, 613, 1412, 2793, 807, 257, 5507, 3209, 11, 597, 51818, 51818], "temperature": 0.0, "avg_logprob": -0.12393707590004832, "compression_ratio": 1.858974358974359, "no_speech_prob": 1.7777059838408604e-05}, {"id": 1198, "seek": 477532, "start": 4788.2, "end": 4790.96, "text": " and push apart points that are not related.", "tokens": [50364, 407, 8712, 488, 2539, 307, 1936, 257, 1333, 295, 2674, 8388, 300, 9898, 281, 1466, 257, 50710, 50710, 4111, 1901, 300, 393, 10432, 1214, 420, 1333, 295, 829, 1214, 2793, 300, 366, 4077, 51008, 51008, 293, 2944, 4936, 2793, 300, 366, 406, 4077, 13, 51146, 51146, 407, 294, 341, 1389, 11, 3811, 411, 264, 3344, 9002, 366, 264, 4077, 2793, 11, 264, 22897, 366, 4077, 51386, 51386, 293, 264, 9656, 366, 264, 4077, 2793, 13, 51522, 51522, 509, 603, 8947, 4122, 337, 1184, 295, 613, 1412, 2793, 807, 257, 5507, 3209, 11, 597, 51818, 51818], "temperature": 0.0, "avg_logprob": -0.12393707590004832, "compression_ratio": 1.858974358974359, "no_speech_prob": 1.7777059838408604e-05}, {"id": 1199, "seek": 477532, "start": 4790.96, "end": 4795.759999999999, "text": " So in this case, imagine like the blue boxes are the related points, the greens are related", "tokens": [50364, 407, 8712, 488, 2539, 307, 1936, 257, 1333, 295, 2674, 8388, 300, 9898, 281, 1466, 257, 50710, 50710, 4111, 1901, 300, 393, 10432, 1214, 420, 1333, 295, 829, 1214, 2793, 300, 366, 4077, 51008, 51008, 293, 2944, 4936, 2793, 300, 366, 406, 4077, 13, 51146, 51146, 407, 294, 341, 1389, 11, 3811, 411, 264, 3344, 9002, 366, 264, 4077, 2793, 11, 264, 22897, 366, 4077, 51386, 51386, 293, 264, 9656, 366, 264, 4077, 2793, 13, 51522, 51522, 509, 603, 8947, 4122, 337, 1184, 295, 613, 1412, 2793, 807, 257, 5507, 3209, 11, 597, 51818, 51818], "temperature": 0.0, "avg_logprob": -0.12393707590004832, "compression_ratio": 1.858974358974359, "no_speech_prob": 1.7777059838408604e-05}, {"id": 1200, "seek": 477532, "start": 4795.759999999999, "end": 4798.48, "text": " and the purple are the related points.", "tokens": [50364, 407, 8712, 488, 2539, 307, 1936, 257, 1333, 295, 2674, 8388, 300, 9898, 281, 1466, 257, 50710, 50710, 4111, 1901, 300, 393, 10432, 1214, 420, 1333, 295, 829, 1214, 2793, 300, 366, 4077, 51008, 51008, 293, 2944, 4936, 2793, 300, 366, 406, 4077, 13, 51146, 51146, 407, 294, 341, 1389, 11, 3811, 411, 264, 3344, 9002, 366, 264, 4077, 2793, 11, 264, 22897, 366, 4077, 51386, 51386, 293, 264, 9656, 366, 264, 4077, 2793, 13, 51522, 51522, 509, 603, 8947, 4122, 337, 1184, 295, 613, 1412, 2793, 807, 257, 5507, 3209, 11, 597, 51818, 51818], "temperature": 0.0, "avg_logprob": -0.12393707590004832, "compression_ratio": 1.858974358974359, "no_speech_prob": 1.7777059838408604e-05}, {"id": 1201, "seek": 477532, "start": 4798.48, "end": 4804.4, "text": " You'll extract features for each of these data points through a shared network, which", "tokens": [50364, 407, 8712, 488, 2539, 307, 1936, 257, 1333, 295, 2674, 8388, 300, 9898, 281, 1466, 257, 50710, 50710, 4111, 1901, 300, 393, 10432, 1214, 420, 1333, 295, 829, 1214, 2793, 300, 366, 4077, 51008, 51008, 293, 2944, 4936, 2793, 300, 366, 406, 4077, 13, 51146, 51146, 407, 294, 341, 1389, 11, 3811, 411, 264, 3344, 9002, 366, 264, 4077, 2793, 11, 264, 22897, 366, 4077, 51386, 51386, 293, 264, 9656, 366, 264, 4077, 2793, 13, 51522, 51522, 509, 603, 8947, 4122, 337, 1184, 295, 613, 1412, 2793, 807, 257, 5507, 3209, 11, 597, 51818, 51818], "temperature": 0.0, "avg_logprob": -0.12393707590004832, "compression_ratio": 1.858974358974359, "no_speech_prob": 1.7777059838408604e-05}, {"id": 1202, "seek": 480440, "start": 4804.4, "end": 4806.28, "text": " is called a Sianese network.", "tokens": [50364, 307, 1219, 257, 318, 952, 1130, 3209, 13, 50458, 50458, 509, 603, 483, 257, 3840, 295, 3256, 4122, 337, 1184, 295, 613, 1412, 2793, 13, 50728, 50728, 400, 550, 291, 603, 3079, 257, 4470, 2445, 11, 597, 307, 257, 8712, 488, 4470, 2445, 11, 597, 307, 516, 51000, 51000, 281, 853, 281, 1333, 295, 17522, 264, 4560, 1296, 264, 3344, 2793, 382, 8851, 281, 584, 264, 4560, 51356, 51356, 1296, 264, 3344, 935, 293, 264, 3092, 935, 13, 51498, 51498, 1610, 264, 4560, 1936, 1296, 264, 3344, 935, 820, 312, 1570, 813, 264, 4560, 1296, 51730, 51730], "temperature": 0.0, "avg_logprob": -0.1580246241405757, "compression_ratio": 1.9577464788732395, "no_speech_prob": 2.5865159841487184e-05}, {"id": 1203, "seek": 480440, "start": 4806.28, "end": 4811.679999999999, "text": " You'll get a bunch of image features for each of these data points.", "tokens": [50364, 307, 1219, 257, 318, 952, 1130, 3209, 13, 50458, 50458, 509, 603, 483, 257, 3840, 295, 3256, 4122, 337, 1184, 295, 613, 1412, 2793, 13, 50728, 50728, 400, 550, 291, 603, 3079, 257, 4470, 2445, 11, 597, 307, 257, 8712, 488, 4470, 2445, 11, 597, 307, 516, 51000, 51000, 281, 853, 281, 1333, 295, 17522, 264, 4560, 1296, 264, 3344, 2793, 382, 8851, 281, 584, 264, 4560, 51356, 51356, 1296, 264, 3344, 935, 293, 264, 3092, 935, 13, 51498, 51498, 1610, 264, 4560, 1936, 1296, 264, 3344, 935, 820, 312, 1570, 813, 264, 4560, 1296, 51730, 51730], "temperature": 0.0, "avg_logprob": -0.1580246241405757, "compression_ratio": 1.9577464788732395, "no_speech_prob": 2.5865159841487184e-05}, {"id": 1204, "seek": 480440, "start": 4811.679999999999, "end": 4817.12, "text": " And then you'll apply a loss function, which is a contrastive loss function, which is going", "tokens": [50364, 307, 1219, 257, 318, 952, 1130, 3209, 13, 50458, 50458, 509, 603, 483, 257, 3840, 295, 3256, 4122, 337, 1184, 295, 613, 1412, 2793, 13, 50728, 50728, 400, 550, 291, 603, 3079, 257, 4470, 2445, 11, 597, 307, 257, 8712, 488, 4470, 2445, 11, 597, 307, 516, 51000, 51000, 281, 853, 281, 1333, 295, 17522, 264, 4560, 1296, 264, 3344, 2793, 382, 8851, 281, 584, 264, 4560, 51356, 51356, 1296, 264, 3344, 935, 293, 264, 3092, 935, 13, 51498, 51498, 1610, 264, 4560, 1936, 1296, 264, 3344, 935, 820, 312, 1570, 813, 264, 4560, 1296, 51730, 51730], "temperature": 0.0, "avg_logprob": -0.1580246241405757, "compression_ratio": 1.9577464788732395, "no_speech_prob": 2.5865159841487184e-05}, {"id": 1205, "seek": 480440, "start": 4817.12, "end": 4824.24, "text": " to try to sort of minimize the distance between the blue points as opposed to say the distance", "tokens": [50364, 307, 1219, 257, 318, 952, 1130, 3209, 13, 50458, 50458, 509, 603, 483, 257, 3840, 295, 3256, 4122, 337, 1184, 295, 613, 1412, 2793, 13, 50728, 50728, 400, 550, 291, 603, 3079, 257, 4470, 2445, 11, 597, 307, 257, 8712, 488, 4470, 2445, 11, 597, 307, 516, 51000, 51000, 281, 853, 281, 1333, 295, 17522, 264, 4560, 1296, 264, 3344, 2793, 382, 8851, 281, 584, 264, 4560, 51356, 51356, 1296, 264, 3344, 935, 293, 264, 3092, 935, 13, 51498, 51498, 1610, 264, 4560, 1936, 1296, 264, 3344, 935, 820, 312, 1570, 813, 264, 4560, 1296, 51730, 51730], "temperature": 0.0, "avg_logprob": -0.1580246241405757, "compression_ratio": 1.9577464788732395, "no_speech_prob": 2.5865159841487184e-05}, {"id": 1206, "seek": 480440, "start": 4824.24, "end": 4827.08, "text": " between the blue point and the green point.", "tokens": [50364, 307, 1219, 257, 318, 952, 1130, 3209, 13, 50458, 50458, 509, 603, 483, 257, 3840, 295, 3256, 4122, 337, 1184, 295, 613, 1412, 2793, 13, 50728, 50728, 400, 550, 291, 603, 3079, 257, 4470, 2445, 11, 597, 307, 257, 8712, 488, 4470, 2445, 11, 597, 307, 516, 51000, 51000, 281, 853, 281, 1333, 295, 17522, 264, 4560, 1296, 264, 3344, 2793, 382, 8851, 281, 584, 264, 4560, 51356, 51356, 1296, 264, 3344, 935, 293, 264, 3092, 935, 13, 51498, 51498, 1610, 264, 4560, 1936, 1296, 264, 3344, 935, 820, 312, 1570, 813, 264, 4560, 1296, 51730, 51730], "temperature": 0.0, "avg_logprob": -0.1580246241405757, "compression_ratio": 1.9577464788732395, "no_speech_prob": 2.5865159841487184e-05}, {"id": 1207, "seek": 480440, "start": 4827.08, "end": 4831.719999999999, "text": " Or the distance basically between the blue point should be less than the distance between", "tokens": [50364, 307, 1219, 257, 318, 952, 1130, 3209, 13, 50458, 50458, 509, 603, 483, 257, 3840, 295, 3256, 4122, 337, 1184, 295, 613, 1412, 2793, 13, 50728, 50728, 400, 550, 291, 603, 3079, 257, 4470, 2445, 11, 597, 307, 257, 8712, 488, 4470, 2445, 11, 597, 307, 516, 51000, 51000, 281, 853, 281, 1333, 295, 17522, 264, 4560, 1296, 264, 3344, 2793, 382, 8851, 281, 584, 264, 4560, 51356, 51356, 1296, 264, 3344, 935, 293, 264, 3092, 935, 13, 51498, 51498, 1610, 264, 4560, 1936, 1296, 264, 3344, 935, 820, 312, 1570, 813, 264, 4560, 1296, 51730, 51730], "temperature": 0.0, "avg_logprob": -0.1580246241405757, "compression_ratio": 1.9577464788732395, "no_speech_prob": 2.5865159841487184e-05}, {"id": 1208, "seek": 483172, "start": 4831.72, "end": 4836.320000000001, "text": " the blue point and the green point or the blue point and the purple point.", "tokens": [50364, 264, 3344, 935, 293, 264, 3092, 935, 420, 264, 3344, 935, 293, 264, 9656, 935, 13, 50594, 50594, 407, 12240, 29432, 490, 264, 4077, 10938, 820, 312, 709, 4966, 813, 12240, 29432, 490, 264, 38967, 50858, 50858, 10938, 13, 50908, 50908, 407, 300, 311, 1333, 295, 264, 2674, 1558, 295, 8712, 488, 2539, 13, 51072, 51072, 400, 295, 1164, 11, 4956, 390, 472, 295, 264, 700, 561, 281, 1333, 295, 17421, 341, 3170, 294, 702, 3071, 51292, 51292, 3035, 365, 497, 4427, 389, 1720, 304, 11, 597, 307, 1219, 2491, 13, 16406, 13, 51487, 51487, 400, 370, 8712, 488, 2539, 575, 586, 1027, 257, 725, 44607, 294, 2698, 12, 48172, 24420, 2539, 13, 51684, 51684], "temperature": 0.0, "avg_logprob": -0.15552991883367553, "compression_ratio": 1.8196078431372549, "no_speech_prob": 4.029313458886463e-06}, {"id": 1209, "seek": 483172, "start": 4836.320000000001, "end": 4841.6, "text": " So embeddings from the related samples should be much closer than embeddings from the unrelated", "tokens": [50364, 264, 3344, 935, 293, 264, 3092, 935, 420, 264, 3344, 935, 293, 264, 9656, 935, 13, 50594, 50594, 407, 12240, 29432, 490, 264, 4077, 10938, 820, 312, 709, 4966, 813, 12240, 29432, 490, 264, 38967, 50858, 50858, 10938, 13, 50908, 50908, 407, 300, 311, 1333, 295, 264, 2674, 1558, 295, 8712, 488, 2539, 13, 51072, 51072, 400, 295, 1164, 11, 4956, 390, 472, 295, 264, 700, 561, 281, 1333, 295, 17421, 341, 3170, 294, 702, 3071, 51292, 51292, 3035, 365, 497, 4427, 389, 1720, 304, 11, 597, 307, 1219, 2491, 13, 16406, 13, 51487, 51487, 400, 370, 8712, 488, 2539, 575, 586, 1027, 257, 725, 44607, 294, 2698, 12, 48172, 24420, 2539, 13, 51684, 51684], "temperature": 0.0, "avg_logprob": -0.15552991883367553, "compression_ratio": 1.8196078431372549, "no_speech_prob": 4.029313458886463e-06}, {"id": 1210, "seek": 483172, "start": 4841.6, "end": 4842.6, "text": " samples.", "tokens": [50364, 264, 3344, 935, 293, 264, 3092, 935, 420, 264, 3344, 935, 293, 264, 9656, 935, 13, 50594, 50594, 407, 12240, 29432, 490, 264, 4077, 10938, 820, 312, 709, 4966, 813, 12240, 29432, 490, 264, 38967, 50858, 50858, 10938, 13, 50908, 50908, 407, 300, 311, 1333, 295, 264, 2674, 1558, 295, 8712, 488, 2539, 13, 51072, 51072, 400, 295, 1164, 11, 4956, 390, 472, 295, 264, 700, 561, 281, 1333, 295, 17421, 341, 3170, 294, 702, 3071, 51292, 51292, 3035, 365, 497, 4427, 389, 1720, 304, 11, 597, 307, 1219, 2491, 13, 16406, 13, 51487, 51487, 400, 370, 8712, 488, 2539, 575, 586, 1027, 257, 725, 44607, 294, 2698, 12, 48172, 24420, 2539, 13, 51684, 51684], "temperature": 0.0, "avg_logprob": -0.15552991883367553, "compression_ratio": 1.8196078431372549, "no_speech_prob": 4.029313458886463e-06}, {"id": 1211, "seek": 483172, "start": 4842.6, "end": 4845.88, "text": " So that's sort of the general idea of contrastive learning.", "tokens": [50364, 264, 3344, 935, 293, 264, 3092, 935, 420, 264, 3344, 935, 293, 264, 9656, 935, 13, 50594, 50594, 407, 12240, 29432, 490, 264, 4077, 10938, 820, 312, 709, 4966, 813, 12240, 29432, 490, 264, 38967, 50858, 50858, 10938, 13, 50908, 50908, 407, 300, 311, 1333, 295, 264, 2674, 1558, 295, 8712, 488, 2539, 13, 51072, 51072, 400, 295, 1164, 11, 4956, 390, 472, 295, 264, 700, 561, 281, 1333, 295, 17421, 341, 3170, 294, 702, 3071, 51292, 51292, 3035, 365, 497, 4427, 389, 1720, 304, 11, 597, 307, 1219, 2491, 13, 16406, 13, 51487, 51487, 400, 370, 8712, 488, 2539, 575, 586, 1027, 257, 725, 44607, 294, 2698, 12, 48172, 24420, 2539, 13, 51684, 51684], "temperature": 0.0, "avg_logprob": -0.15552991883367553, "compression_ratio": 1.8196078431372549, "no_speech_prob": 4.029313458886463e-06}, {"id": 1212, "seek": 483172, "start": 4845.88, "end": 4850.280000000001, "text": " And of course, Jan was one of the first people to sort of propose this method in his earlier", "tokens": [50364, 264, 3344, 935, 293, 264, 3092, 935, 420, 264, 3344, 935, 293, 264, 9656, 935, 13, 50594, 50594, 407, 12240, 29432, 490, 264, 4077, 10938, 820, 312, 709, 4966, 813, 12240, 29432, 490, 264, 38967, 50858, 50858, 10938, 13, 50908, 50908, 407, 300, 311, 1333, 295, 264, 2674, 1558, 295, 8712, 488, 2539, 13, 51072, 51072, 400, 295, 1164, 11, 4956, 390, 472, 295, 264, 700, 561, 281, 1333, 295, 17421, 341, 3170, 294, 702, 3071, 51292, 51292, 3035, 365, 497, 4427, 389, 1720, 304, 11, 597, 307, 1219, 2491, 13, 16406, 13, 51487, 51487, 400, 370, 8712, 488, 2539, 575, 586, 1027, 257, 725, 44607, 294, 2698, 12, 48172, 24420, 2539, 13, 51684, 51684], "temperature": 0.0, "avg_logprob": -0.15552991883367553, "compression_ratio": 1.8196078431372549, "no_speech_prob": 4.029313458886463e-06}, {"id": 1213, "seek": 483172, "start": 4850.280000000001, "end": 4854.18, "text": " paper with Raya Hatsal, which is called Dr. Lim.", "tokens": [50364, 264, 3344, 935, 293, 264, 3092, 935, 420, 264, 3344, 935, 293, 264, 9656, 935, 13, 50594, 50594, 407, 12240, 29432, 490, 264, 4077, 10938, 820, 312, 709, 4966, 813, 12240, 29432, 490, 264, 38967, 50858, 50858, 10938, 13, 50908, 50908, 407, 300, 311, 1333, 295, 264, 2674, 1558, 295, 8712, 488, 2539, 13, 51072, 51072, 400, 295, 1164, 11, 4956, 390, 472, 295, 264, 700, 561, 281, 1333, 295, 17421, 341, 3170, 294, 702, 3071, 51292, 51292, 3035, 365, 497, 4427, 389, 1720, 304, 11, 597, 307, 1219, 2491, 13, 16406, 13, 51487, 51487, 400, 370, 8712, 488, 2539, 575, 586, 1027, 257, 725, 44607, 294, 2698, 12, 48172, 24420, 2539, 13, 51684, 51684], "temperature": 0.0, "avg_logprob": -0.15552991883367553, "compression_ratio": 1.8196078431372549, "no_speech_prob": 4.029313458886463e-06}, {"id": 1214, "seek": 483172, "start": 4854.18, "end": 4858.12, "text": " And so contrastive learning has now made a resurgence in self-supervised learning.", "tokens": [50364, 264, 3344, 935, 293, 264, 3092, 935, 420, 264, 3344, 935, 293, 264, 9656, 935, 13, 50594, 50594, 407, 12240, 29432, 490, 264, 4077, 10938, 820, 312, 709, 4966, 813, 12240, 29432, 490, 264, 38967, 50858, 50858, 10938, 13, 50908, 50908, 407, 300, 311, 1333, 295, 264, 2674, 1558, 295, 8712, 488, 2539, 13, 51072, 51072, 400, 295, 1164, 11, 4956, 390, 472, 295, 264, 700, 561, 281, 1333, 295, 17421, 341, 3170, 294, 702, 3071, 51292, 51292, 3035, 365, 497, 4427, 389, 1720, 304, 11, 597, 307, 1219, 2491, 13, 16406, 13, 51487, 51487, 400, 370, 8712, 488, 2539, 575, 586, 1027, 257, 725, 44607, 294, 2698, 12, 48172, 24420, 2539, 13, 51684, 51684], "temperature": 0.0, "avg_logprob": -0.15552991883367553, "compression_ratio": 1.8196078431372549, "no_speech_prob": 4.029313458886463e-06}, {"id": 1215, "seek": 485812, "start": 4858.12, "end": 4862.88, "text": " Pretty much a lot of the self-supervised state of the art methods are really based on contrastive", "tokens": [50364, 10693, 709, 257, 688, 295, 264, 2698, 12, 48172, 24420, 1785, 295, 264, 1523, 7150, 366, 534, 2361, 322, 8712, 488, 50602, 50602, 2539, 13, 50756, 50756, 400, 264, 2135, 1168, 307, 11, 577, 360, 291, 6964, 437, 307, 4077, 293, 38967, 30, 51002, 51002, 407, 294, 264, 1389, 295, 46533, 2539, 11, 300, 311, 6457, 1850, 13, 51166, 51166, 1057, 295, 264, 3000, 5267, 366, 4077, 5267, 13, 51292, 51292, 400, 604, 3256, 300, 307, 406, 257, 3000, 3256, 307, 1936, 364, 38967, 3256, 13, 51516, 51516, 583, 309, 311, 406, 370, 1850, 577, 281, 6964, 264, 4077, 293, 38967, 1287, 294, 341, 1389, 295, 2698, 12, 48172, 24420, 51792, 51792], "temperature": 0.0, "avg_logprob": -0.1297435760498047, "compression_ratio": 1.895397489539749, "no_speech_prob": 2.5464982172707096e-05}, {"id": 1216, "seek": 485812, "start": 4862.88, "end": 4865.96, "text": " learning.", "tokens": [50364, 10693, 709, 257, 688, 295, 264, 2698, 12, 48172, 24420, 1785, 295, 264, 1523, 7150, 366, 534, 2361, 322, 8712, 488, 50602, 50602, 2539, 13, 50756, 50756, 400, 264, 2135, 1168, 307, 11, 577, 360, 291, 6964, 437, 307, 4077, 293, 38967, 30, 51002, 51002, 407, 294, 264, 1389, 295, 46533, 2539, 11, 300, 311, 6457, 1850, 13, 51166, 51166, 1057, 295, 264, 3000, 5267, 366, 4077, 5267, 13, 51292, 51292, 400, 604, 3256, 300, 307, 406, 257, 3000, 3256, 307, 1936, 364, 38967, 3256, 13, 51516, 51516, 583, 309, 311, 406, 370, 1850, 577, 281, 6964, 264, 4077, 293, 38967, 1287, 294, 341, 1389, 295, 2698, 12, 48172, 24420, 51792, 51792], "temperature": 0.0, "avg_logprob": -0.1297435760498047, "compression_ratio": 1.895397489539749, "no_speech_prob": 2.5464982172707096e-05}, {"id": 1217, "seek": 485812, "start": 4865.96, "end": 4870.88, "text": " And the main question is, how do you define what is related and unrelated?", "tokens": [50364, 10693, 709, 257, 688, 295, 264, 2698, 12, 48172, 24420, 1785, 295, 264, 1523, 7150, 366, 534, 2361, 322, 8712, 488, 50602, 50602, 2539, 13, 50756, 50756, 400, 264, 2135, 1168, 307, 11, 577, 360, 291, 6964, 437, 307, 4077, 293, 38967, 30, 51002, 51002, 407, 294, 264, 1389, 295, 46533, 2539, 11, 300, 311, 6457, 1850, 13, 51166, 51166, 1057, 295, 264, 3000, 5267, 366, 4077, 5267, 13, 51292, 51292, 400, 604, 3256, 300, 307, 406, 257, 3000, 3256, 307, 1936, 364, 38967, 3256, 13, 51516, 51516, 583, 309, 311, 406, 370, 1850, 577, 281, 6964, 264, 4077, 293, 38967, 1287, 294, 341, 1389, 295, 2698, 12, 48172, 24420, 51792, 51792], "temperature": 0.0, "avg_logprob": -0.1297435760498047, "compression_ratio": 1.895397489539749, "no_speech_prob": 2.5464982172707096e-05}, {"id": 1218, "seek": 485812, "start": 4870.88, "end": 4874.16, "text": " So in the case of supervised learning, that's fairly clear.", "tokens": [50364, 10693, 709, 257, 688, 295, 264, 2698, 12, 48172, 24420, 1785, 295, 264, 1523, 7150, 366, 534, 2361, 322, 8712, 488, 50602, 50602, 2539, 13, 50756, 50756, 400, 264, 2135, 1168, 307, 11, 577, 360, 291, 6964, 437, 307, 4077, 293, 38967, 30, 51002, 51002, 407, 294, 264, 1389, 295, 46533, 2539, 11, 300, 311, 6457, 1850, 13, 51166, 51166, 1057, 295, 264, 3000, 5267, 366, 4077, 5267, 13, 51292, 51292, 400, 604, 3256, 300, 307, 406, 257, 3000, 3256, 307, 1936, 364, 38967, 3256, 13, 51516, 51516, 583, 309, 311, 406, 370, 1850, 577, 281, 6964, 264, 4077, 293, 38967, 1287, 294, 341, 1389, 295, 2698, 12, 48172, 24420, 51792, 51792], "temperature": 0.0, "avg_logprob": -0.1297435760498047, "compression_ratio": 1.895397489539749, "no_speech_prob": 2.5464982172707096e-05}, {"id": 1219, "seek": 485812, "start": 4874.16, "end": 4876.68, "text": " All of the dog images are related images.", "tokens": [50364, 10693, 709, 257, 688, 295, 264, 2698, 12, 48172, 24420, 1785, 295, 264, 1523, 7150, 366, 534, 2361, 322, 8712, 488, 50602, 50602, 2539, 13, 50756, 50756, 400, 264, 2135, 1168, 307, 11, 577, 360, 291, 6964, 437, 307, 4077, 293, 38967, 30, 51002, 51002, 407, 294, 264, 1389, 295, 46533, 2539, 11, 300, 311, 6457, 1850, 13, 51166, 51166, 1057, 295, 264, 3000, 5267, 366, 4077, 5267, 13, 51292, 51292, 400, 604, 3256, 300, 307, 406, 257, 3000, 3256, 307, 1936, 364, 38967, 3256, 13, 51516, 51516, 583, 309, 311, 406, 370, 1850, 577, 281, 6964, 264, 4077, 293, 38967, 1287, 294, 341, 1389, 295, 2698, 12, 48172, 24420, 51792, 51792], "temperature": 0.0, "avg_logprob": -0.1297435760498047, "compression_ratio": 1.895397489539749, "no_speech_prob": 2.5464982172707096e-05}, {"id": 1220, "seek": 485812, "start": 4876.68, "end": 4881.16, "text": " And any image that is not a dog image is basically an unrelated image.", "tokens": [50364, 10693, 709, 257, 688, 295, 264, 2698, 12, 48172, 24420, 1785, 295, 264, 1523, 7150, 366, 534, 2361, 322, 8712, 488, 50602, 50602, 2539, 13, 50756, 50756, 400, 264, 2135, 1168, 307, 11, 577, 360, 291, 6964, 437, 307, 4077, 293, 38967, 30, 51002, 51002, 407, 294, 264, 1389, 295, 46533, 2539, 11, 300, 311, 6457, 1850, 13, 51166, 51166, 1057, 295, 264, 3000, 5267, 366, 4077, 5267, 13, 51292, 51292, 400, 604, 3256, 300, 307, 406, 257, 3000, 3256, 307, 1936, 364, 38967, 3256, 13, 51516, 51516, 583, 309, 311, 406, 370, 1850, 577, 281, 6964, 264, 4077, 293, 38967, 1287, 294, 341, 1389, 295, 2698, 12, 48172, 24420, 51792, 51792], "temperature": 0.0, "avg_logprob": -0.1297435760498047, "compression_ratio": 1.895397489539749, "no_speech_prob": 2.5464982172707096e-05}, {"id": 1221, "seek": 485812, "start": 4881.16, "end": 4886.68, "text": " But it's not so clear how to define the related and unrelatedness in this case of self-supervised", "tokens": [50364, 10693, 709, 257, 688, 295, 264, 2698, 12, 48172, 24420, 1785, 295, 264, 1523, 7150, 366, 534, 2361, 322, 8712, 488, 50602, 50602, 2539, 13, 50756, 50756, 400, 264, 2135, 1168, 307, 11, 577, 360, 291, 6964, 437, 307, 4077, 293, 38967, 30, 51002, 51002, 407, 294, 264, 1389, 295, 46533, 2539, 11, 300, 311, 6457, 1850, 13, 51166, 51166, 1057, 295, 264, 3000, 5267, 366, 4077, 5267, 13, 51292, 51292, 400, 604, 3256, 300, 307, 406, 257, 3000, 3256, 307, 1936, 364, 38967, 3256, 13, 51516, 51516, 583, 309, 311, 406, 370, 1850, 577, 281, 6964, 264, 4077, 293, 38967, 1287, 294, 341, 1389, 295, 2698, 12, 48172, 24420, 51792, 51792], "temperature": 0.0, "avg_logprob": -0.1297435760498047, "compression_ratio": 1.895397489539749, "no_speech_prob": 2.5464982172707096e-05}, {"id": 1222, "seek": 488668, "start": 4886.68, "end": 4888.76, "text": " learning.", "tokens": [50364, 2539, 13, 50468, 50468, 440, 661, 1333, 295, 2135, 2649, 490, 746, 411, 257, 659, 25111, 5633, 307, 300, 8712, 488, 2539, 50756, 50756, 534, 4112, 466, 264, 2302, 420, 257, 688, 295, 1412, 412, 1564, 13, 51028, 51028, 407, 281, 352, 646, 281, 452, 3894, 4137, 11, 498, 291, 574, 412, 264, 4470, 2445, 11, 309, 1009, 11626, 51314, 51314, 3866, 5267, 13, 51392, 51392, 467, 11626, 11, 294, 264, 700, 5386, 11, 309, 11626, 1936, 264, 3344, 5267, 293, 264, 3092, 5267, 13, 51686, 51686], "temperature": 0.0, "avg_logprob": -0.15773220276564695, "compression_ratio": 1.6529680365296804, "no_speech_prob": 1.2606597920239437e-05}, {"id": 1223, "seek": 488668, "start": 4888.76, "end": 4894.52, "text": " The other sort of main difference from something like a pretext task is that contrastive learning", "tokens": [50364, 2539, 13, 50468, 50468, 440, 661, 1333, 295, 2135, 2649, 490, 746, 411, 257, 659, 25111, 5633, 307, 300, 8712, 488, 2539, 50756, 50756, 534, 4112, 466, 264, 2302, 420, 257, 688, 295, 1412, 412, 1564, 13, 51028, 51028, 407, 281, 352, 646, 281, 452, 3894, 4137, 11, 498, 291, 574, 412, 264, 4470, 2445, 11, 309, 1009, 11626, 51314, 51314, 3866, 5267, 13, 51392, 51392, 467, 11626, 11, 294, 264, 700, 5386, 11, 309, 11626, 1936, 264, 3344, 5267, 293, 264, 3092, 5267, 13, 51686, 51686], "temperature": 0.0, "avg_logprob": -0.15773220276564695, "compression_ratio": 1.6529680365296804, "no_speech_prob": 1.2606597920239437e-05}, {"id": 1224, "seek": 488668, "start": 4894.52, "end": 4899.96, "text": " really reasons about the entire or a lot of data at once.", "tokens": [50364, 2539, 13, 50468, 50468, 440, 661, 1333, 295, 2135, 2649, 490, 746, 411, 257, 659, 25111, 5633, 307, 300, 8712, 488, 2539, 50756, 50756, 534, 4112, 466, 264, 2302, 420, 257, 688, 295, 1412, 412, 1564, 13, 51028, 51028, 407, 281, 352, 646, 281, 452, 3894, 4137, 11, 498, 291, 574, 412, 264, 4470, 2445, 11, 309, 1009, 11626, 51314, 51314, 3866, 5267, 13, 51392, 51392, 467, 11626, 11, 294, 264, 700, 5386, 11, 309, 11626, 1936, 264, 3344, 5267, 293, 264, 3092, 5267, 13, 51686, 51686], "temperature": 0.0, "avg_logprob": -0.15773220276564695, "compression_ratio": 1.6529680365296804, "no_speech_prob": 1.2606597920239437e-05}, {"id": 1225, "seek": 488668, "start": 4899.96, "end": 4905.68, "text": " So to go back to my previous slide, if you look at the loss function, it always involves", "tokens": [50364, 2539, 13, 50468, 50468, 440, 661, 1333, 295, 2135, 2649, 490, 746, 411, 257, 659, 25111, 5633, 307, 300, 8712, 488, 2539, 50756, 50756, 534, 4112, 466, 264, 2302, 420, 257, 688, 295, 1412, 412, 1564, 13, 51028, 51028, 407, 281, 352, 646, 281, 452, 3894, 4137, 11, 498, 291, 574, 412, 264, 4470, 2445, 11, 309, 1009, 11626, 51314, 51314, 3866, 5267, 13, 51392, 51392, 467, 11626, 11, 294, 264, 700, 5386, 11, 309, 11626, 1936, 264, 3344, 5267, 293, 264, 3092, 5267, 13, 51686, 51686], "temperature": 0.0, "avg_logprob": -0.15773220276564695, "compression_ratio": 1.6529680365296804, "no_speech_prob": 1.2606597920239437e-05}, {"id": 1226, "seek": 488668, "start": 4905.68, "end": 4907.240000000001, "text": " multiple images.", "tokens": [50364, 2539, 13, 50468, 50468, 440, 661, 1333, 295, 2135, 2649, 490, 746, 411, 257, 659, 25111, 5633, 307, 300, 8712, 488, 2539, 50756, 50756, 534, 4112, 466, 264, 2302, 420, 257, 688, 295, 1412, 412, 1564, 13, 51028, 51028, 407, 281, 352, 646, 281, 452, 3894, 4137, 11, 498, 291, 574, 412, 264, 4470, 2445, 11, 309, 1009, 11626, 51314, 51314, 3866, 5267, 13, 51392, 51392, 467, 11626, 11, 294, 264, 700, 5386, 11, 309, 11626, 1936, 264, 3344, 5267, 293, 264, 3092, 5267, 13, 51686, 51686], "temperature": 0.0, "avg_logprob": -0.15773220276564695, "compression_ratio": 1.6529680365296804, "no_speech_prob": 1.2606597920239437e-05}, {"id": 1227, "seek": 488668, "start": 4907.240000000001, "end": 4913.12, "text": " It involves, in the first row, it involves basically the blue images and the green images.", "tokens": [50364, 2539, 13, 50468, 50468, 440, 661, 1333, 295, 2135, 2649, 490, 746, 411, 257, 659, 25111, 5633, 307, 300, 8712, 488, 2539, 50756, 50756, 534, 4112, 466, 264, 2302, 420, 257, 688, 295, 1412, 412, 1564, 13, 51028, 51028, 407, 281, 352, 646, 281, 452, 3894, 4137, 11, 498, 291, 574, 412, 264, 4470, 2445, 11, 309, 1009, 11626, 51314, 51314, 3866, 5267, 13, 51392, 51392, 467, 11626, 11, 294, 264, 700, 5386, 11, 309, 11626, 1936, 264, 3344, 5267, 293, 264, 3092, 5267, 13, 51686, 51686], "temperature": 0.0, "avg_logprob": -0.15773220276564695, "compression_ratio": 1.6529680365296804, "no_speech_prob": 1.2606597920239437e-05}, {"id": 1228, "seek": 491312, "start": 4913.12, "end": 4916.84, "text": " In the second row, it involves the blue images and the purple images.", "tokens": [50364, 682, 264, 1150, 5386, 11, 309, 11626, 264, 3344, 5267, 293, 264, 9656, 5267, 13, 50550, 50550, 13813, 498, 291, 574, 412, 257, 5633, 411, 11, 584, 11, 361, 17156, 1607, 420, 257, 5633, 411, 12447, 11, 291, 434, 1009, 21577, 50832, 50832, 466, 257, 2167, 3256, 21761, 13, 50990, 50990, 407, 300, 311, 1333, 295, 1071, 2649, 365, 8712, 488, 2539, 13, 51170, 51170, 4839, 4148, 488, 2539, 1009, 4112, 466, 3866, 1412, 2793, 412, 1564, 13, 51470, 51470, 407, 586, 1348, 281, 264, 1168, 11, 577, 360, 291, 6964, 4077, 420, 38967, 5267, 30, 51758, 51758], "temperature": 0.0, "avg_logprob": -0.13507547378540039, "compression_ratio": 1.6979591836734693, "no_speech_prob": 5.4221054597292095e-06}, {"id": 1229, "seek": 491312, "start": 4916.84, "end": 4922.48, "text": " Whereas if you look at a task like, say, jigsaw or a task like rotation, you're always reasoning", "tokens": [50364, 682, 264, 1150, 5386, 11, 309, 11626, 264, 3344, 5267, 293, 264, 9656, 5267, 13, 50550, 50550, 13813, 498, 291, 574, 412, 257, 5633, 411, 11, 584, 11, 361, 17156, 1607, 420, 257, 5633, 411, 12447, 11, 291, 434, 1009, 21577, 50832, 50832, 466, 257, 2167, 3256, 21761, 13, 50990, 50990, 407, 300, 311, 1333, 295, 1071, 2649, 365, 8712, 488, 2539, 13, 51170, 51170, 4839, 4148, 488, 2539, 1009, 4112, 466, 3866, 1412, 2793, 412, 1564, 13, 51470, 51470, 407, 586, 1348, 281, 264, 1168, 11, 577, 360, 291, 6964, 4077, 420, 38967, 5267, 30, 51758, 51758], "temperature": 0.0, "avg_logprob": -0.13507547378540039, "compression_ratio": 1.6979591836734693, "no_speech_prob": 5.4221054597292095e-06}, {"id": 1230, "seek": 491312, "start": 4922.48, "end": 4925.64, "text": " about a single image independently.", "tokens": [50364, 682, 264, 1150, 5386, 11, 309, 11626, 264, 3344, 5267, 293, 264, 9656, 5267, 13, 50550, 50550, 13813, 498, 291, 574, 412, 257, 5633, 411, 11, 584, 11, 361, 17156, 1607, 420, 257, 5633, 411, 12447, 11, 291, 434, 1009, 21577, 50832, 50832, 466, 257, 2167, 3256, 21761, 13, 50990, 50990, 407, 300, 311, 1333, 295, 1071, 2649, 365, 8712, 488, 2539, 13, 51170, 51170, 4839, 4148, 488, 2539, 1009, 4112, 466, 3866, 1412, 2793, 412, 1564, 13, 51470, 51470, 407, 586, 1348, 281, 264, 1168, 11, 577, 360, 291, 6964, 4077, 420, 38967, 5267, 30, 51758, 51758], "temperature": 0.0, "avg_logprob": -0.13507547378540039, "compression_ratio": 1.6979591836734693, "no_speech_prob": 5.4221054597292095e-06}, {"id": 1231, "seek": 491312, "start": 4925.64, "end": 4929.24, "text": " So that's sort of another difference with contrastive learning.", "tokens": [50364, 682, 264, 1150, 5386, 11, 309, 11626, 264, 3344, 5267, 293, 264, 9656, 5267, 13, 50550, 50550, 13813, 498, 291, 574, 412, 257, 5633, 411, 11, 584, 11, 361, 17156, 1607, 420, 257, 5633, 411, 12447, 11, 291, 434, 1009, 21577, 50832, 50832, 466, 257, 2167, 3256, 21761, 13, 50990, 50990, 407, 300, 311, 1333, 295, 1071, 2649, 365, 8712, 488, 2539, 13, 51170, 51170, 4839, 4148, 488, 2539, 1009, 4112, 466, 3866, 1412, 2793, 412, 1564, 13, 51470, 51470, 407, 586, 1348, 281, 264, 1168, 11, 577, 360, 291, 6964, 4077, 420, 38967, 5267, 30, 51758, 51758], "temperature": 0.0, "avg_logprob": -0.13507547378540039, "compression_ratio": 1.6979591836734693, "no_speech_prob": 5.4221054597292095e-06}, {"id": 1232, "seek": 491312, "start": 4929.24, "end": 4935.24, "text": " Contrastive learning always reasons about multiple data points at once.", "tokens": [50364, 682, 264, 1150, 5386, 11, 309, 11626, 264, 3344, 5267, 293, 264, 9656, 5267, 13, 50550, 50550, 13813, 498, 291, 574, 412, 257, 5633, 411, 11, 584, 11, 361, 17156, 1607, 420, 257, 5633, 411, 12447, 11, 291, 434, 1009, 21577, 50832, 50832, 466, 257, 2167, 3256, 21761, 13, 50990, 50990, 407, 300, 311, 1333, 295, 1071, 2649, 365, 8712, 488, 2539, 13, 51170, 51170, 4839, 4148, 488, 2539, 1009, 4112, 466, 3866, 1412, 2793, 412, 1564, 13, 51470, 51470, 407, 586, 1348, 281, 264, 1168, 11, 577, 360, 291, 6964, 4077, 420, 38967, 5267, 30, 51758, 51758], "temperature": 0.0, "avg_logprob": -0.13507547378540039, "compression_ratio": 1.6979591836734693, "no_speech_prob": 5.4221054597292095e-06}, {"id": 1233, "seek": 491312, "start": 4935.24, "end": 4941.0, "text": " So now coming to the question, how do you define related or unrelated images?", "tokens": [50364, 682, 264, 1150, 5386, 11, 309, 11626, 264, 3344, 5267, 293, 264, 9656, 5267, 13, 50550, 50550, 13813, 498, 291, 574, 412, 257, 5633, 411, 11, 584, 11, 361, 17156, 1607, 420, 257, 5633, 411, 12447, 11, 291, 434, 1009, 21577, 50832, 50832, 466, 257, 2167, 3256, 21761, 13, 50990, 50990, 407, 300, 311, 1333, 295, 1071, 2649, 365, 8712, 488, 2539, 13, 51170, 51170, 4839, 4148, 488, 2539, 1009, 4112, 466, 3866, 1412, 2793, 412, 1564, 13, 51470, 51470, 407, 586, 1348, 281, 264, 1168, 11, 577, 360, 291, 6964, 4077, 420, 38967, 5267, 30, 51758, 51758], "temperature": 0.0, "avg_logprob": -0.13507547378540039, "compression_ratio": 1.6979591836734693, "no_speech_prob": 5.4221054597292095e-06}, {"id": 1234, "seek": 494100, "start": 4941.0, "end": 4944.96, "text": " You can actually use similar techniques to what I was talking about earlier.", "tokens": [50364, 509, 393, 767, 764, 2531, 7512, 281, 437, 286, 390, 1417, 466, 3071, 13, 50562, 50562, 509, 393, 764, 12083, 295, 257, 960, 13, 50669, 50669, 407, 291, 393, 764, 264, 1333, 295, 42881, 3687, 295, 1412, 13, 50880, 50880, 407, 281, 1333, 295, 1223, 300, 12083, 300, 366, 11184, 294, 257, 960, 366, 4077, 293, 12083, 11, 51186, 51186, 584, 11, 490, 257, 819, 960, 11, 597, 366, 3052, 1314, 294, 565, 11, 366, 38967, 13, 51447, 51447, 400, 300, 1333, 295, 575, 8693, 264, 5143, 295, 257, 688, 295, 2698, 12, 48172, 24420, 2539, 7150, 294, 51648, 51648, 341, 1859, 13, 51700, 51700], "temperature": 0.0, "avg_logprob": -0.1303838123785001, "compression_ratio": 1.7366255144032923, "no_speech_prob": 1.2411108400556259e-05}, {"id": 1235, "seek": 494100, "start": 4944.96, "end": 4947.1, "text": " You can use frames of a video.", "tokens": [50364, 509, 393, 767, 764, 2531, 7512, 281, 437, 286, 390, 1417, 466, 3071, 13, 50562, 50562, 509, 393, 764, 12083, 295, 257, 960, 13, 50669, 50669, 407, 291, 393, 764, 264, 1333, 295, 42881, 3687, 295, 1412, 13, 50880, 50880, 407, 281, 1333, 295, 1223, 300, 12083, 300, 366, 11184, 294, 257, 960, 366, 4077, 293, 12083, 11, 51186, 51186, 584, 11, 490, 257, 819, 960, 11, 597, 366, 3052, 1314, 294, 565, 11, 366, 38967, 13, 51447, 51447, 400, 300, 1333, 295, 575, 8693, 264, 5143, 295, 257, 688, 295, 2698, 12, 48172, 24420, 2539, 7150, 294, 51648, 51648, 341, 1859, 13, 51700, 51700], "temperature": 0.0, "avg_logprob": -0.1303838123785001, "compression_ratio": 1.7366255144032923, "no_speech_prob": 1.2411108400556259e-05}, {"id": 1236, "seek": 494100, "start": 4947.1, "end": 4951.32, "text": " So you can use the sort of sequential nature of data.", "tokens": [50364, 509, 393, 767, 764, 2531, 7512, 281, 437, 286, 390, 1417, 466, 3071, 13, 50562, 50562, 509, 393, 764, 12083, 295, 257, 960, 13, 50669, 50669, 407, 291, 393, 764, 264, 1333, 295, 42881, 3687, 295, 1412, 13, 50880, 50880, 407, 281, 1333, 295, 1223, 300, 12083, 300, 366, 11184, 294, 257, 960, 366, 4077, 293, 12083, 11, 51186, 51186, 584, 11, 490, 257, 819, 960, 11, 597, 366, 3052, 1314, 294, 565, 11, 366, 38967, 13, 51447, 51447, 400, 300, 1333, 295, 575, 8693, 264, 5143, 295, 257, 688, 295, 2698, 12, 48172, 24420, 2539, 7150, 294, 51648, 51648, 341, 1859, 13, 51700, 51700], "temperature": 0.0, "avg_logprob": -0.1303838123785001, "compression_ratio": 1.7366255144032923, "no_speech_prob": 1.2411108400556259e-05}, {"id": 1237, "seek": 494100, "start": 4951.32, "end": 4957.44, "text": " So to sort of understand that frames that are nearby in a video are related and frames,", "tokens": [50364, 509, 393, 767, 764, 2531, 7512, 281, 437, 286, 390, 1417, 466, 3071, 13, 50562, 50562, 509, 393, 764, 12083, 295, 257, 960, 13, 50669, 50669, 407, 291, 393, 764, 264, 1333, 295, 42881, 3687, 295, 1412, 13, 50880, 50880, 407, 281, 1333, 295, 1223, 300, 12083, 300, 366, 11184, 294, 257, 960, 366, 4077, 293, 12083, 11, 51186, 51186, 584, 11, 490, 257, 819, 960, 11, 597, 366, 3052, 1314, 294, 565, 11, 366, 38967, 13, 51447, 51447, 400, 300, 1333, 295, 575, 8693, 264, 5143, 295, 257, 688, 295, 2698, 12, 48172, 24420, 2539, 7150, 294, 51648, 51648, 341, 1859, 13, 51700, 51700], "temperature": 0.0, "avg_logprob": -0.1303838123785001, "compression_ratio": 1.7366255144032923, "no_speech_prob": 1.2411108400556259e-05}, {"id": 1238, "seek": 494100, "start": 4957.44, "end": 4962.66, "text": " say, from a different video, which are further away in time, are unrelated.", "tokens": [50364, 509, 393, 767, 764, 2531, 7512, 281, 437, 286, 390, 1417, 466, 3071, 13, 50562, 50562, 509, 393, 764, 12083, 295, 257, 960, 13, 50669, 50669, 407, 291, 393, 764, 264, 1333, 295, 42881, 3687, 295, 1412, 13, 50880, 50880, 407, 281, 1333, 295, 1223, 300, 12083, 300, 366, 11184, 294, 257, 960, 366, 4077, 293, 12083, 11, 51186, 51186, 584, 11, 490, 257, 819, 960, 11, 597, 366, 3052, 1314, 294, 565, 11, 366, 38967, 13, 51447, 51447, 400, 300, 1333, 295, 575, 8693, 264, 5143, 295, 257, 688, 295, 2698, 12, 48172, 24420, 2539, 7150, 294, 51648, 51648, 341, 1859, 13, 51700, 51700], "temperature": 0.0, "avg_logprob": -0.1303838123785001, "compression_ratio": 1.7366255144032923, "no_speech_prob": 1.2411108400556259e-05}, {"id": 1239, "seek": 494100, "start": 4962.66, "end": 4966.68, "text": " And that sort of has formed the basis of a lot of self-supervised learning methods in", "tokens": [50364, 509, 393, 767, 764, 2531, 7512, 281, 437, 286, 390, 1417, 466, 3071, 13, 50562, 50562, 509, 393, 764, 12083, 295, 257, 960, 13, 50669, 50669, 407, 291, 393, 764, 264, 1333, 295, 42881, 3687, 295, 1412, 13, 50880, 50880, 407, 281, 1333, 295, 1223, 300, 12083, 300, 366, 11184, 294, 257, 960, 366, 4077, 293, 12083, 11, 51186, 51186, 584, 11, 490, 257, 819, 960, 11, 597, 366, 3052, 1314, 294, 565, 11, 366, 38967, 13, 51447, 51447, 400, 300, 1333, 295, 575, 8693, 264, 5143, 295, 257, 688, 295, 2698, 12, 48172, 24420, 2539, 7150, 294, 51648, 51648, 341, 1859, 13, 51700, 51700], "temperature": 0.0, "avg_logprob": -0.1303838123785001, "compression_ratio": 1.7366255144032923, "no_speech_prob": 1.2411108400556259e-05}, {"id": 1240, "seek": 494100, "start": 4966.68, "end": 4967.72, "text": " this area.", "tokens": [50364, 509, 393, 767, 764, 2531, 7512, 281, 437, 286, 390, 1417, 466, 3071, 13, 50562, 50562, 509, 393, 764, 12083, 295, 257, 960, 13, 50669, 50669, 407, 291, 393, 764, 264, 1333, 295, 42881, 3687, 295, 1412, 13, 50880, 50880, 407, 281, 1333, 295, 1223, 300, 12083, 300, 366, 11184, 294, 257, 960, 366, 4077, 293, 12083, 11, 51186, 51186, 584, 11, 490, 257, 819, 960, 11, 597, 366, 3052, 1314, 294, 565, 11, 366, 38967, 13, 51447, 51447, 400, 300, 1333, 295, 575, 8693, 264, 5143, 295, 257, 688, 295, 2698, 12, 48172, 24420, 2539, 7150, 294, 51648, 51648, 341, 1859, 13, 51700, 51700], "temperature": 0.0, "avg_logprob": -0.1303838123785001, "compression_ratio": 1.7366255144032923, "no_speech_prob": 1.2411108400556259e-05}, {"id": 1241, "seek": 496772, "start": 4967.72, "end": 4972.5, "text": " So if you know of this popular method called CPC, which is contrastive predictive coding,", "tokens": [50364, 407, 498, 291, 458, 295, 341, 3743, 3170, 1219, 383, 12986, 11, 597, 307, 8712, 488, 35521, 17720, 11, 50603, 50603, 300, 534, 30910, 322, 264, 42881, 3687, 295, 257, 6358, 13, 50794, 50794, 400, 309, 1936, 1619, 300, 10938, 300, 366, 1998, 538, 294, 264, 565, 1901, 366, 4077, 293, 51106, 51106, 10938, 300, 366, 3052, 4936, 294, 264, 565, 1901, 366, 38967, 13, 51312, 51312, 400, 456, 311, 257, 6457, 2416, 2372, 295, 589, 1936, 12382, 1748, 341, 13, 51592, 51592, 467, 393, 2139, 312, 294, 264, 6218, 9274, 13, 51722, 51722, 467, 393, 2139, 312, 294, 960, 13, 51799, 51799], "temperature": 0.0, "avg_logprob": -0.10003694806780133, "compression_ratio": 1.763265306122449, "no_speech_prob": 1.2218390111229382e-05}, {"id": 1242, "seek": 496772, "start": 4972.5, "end": 4976.320000000001, "text": " that really relies on the sequential nature of a signal.", "tokens": [50364, 407, 498, 291, 458, 295, 341, 3743, 3170, 1219, 383, 12986, 11, 597, 307, 8712, 488, 35521, 17720, 11, 50603, 50603, 300, 534, 30910, 322, 264, 42881, 3687, 295, 257, 6358, 13, 50794, 50794, 400, 309, 1936, 1619, 300, 10938, 300, 366, 1998, 538, 294, 264, 565, 1901, 366, 4077, 293, 51106, 51106, 10938, 300, 366, 3052, 4936, 294, 264, 565, 1901, 366, 38967, 13, 51312, 51312, 400, 456, 311, 257, 6457, 2416, 2372, 295, 589, 1936, 12382, 1748, 341, 13, 51592, 51592, 467, 393, 2139, 312, 294, 264, 6218, 9274, 13, 51722, 51722, 467, 393, 2139, 312, 294, 960, 13, 51799, 51799], "temperature": 0.0, "avg_logprob": -0.10003694806780133, "compression_ratio": 1.763265306122449, "no_speech_prob": 1.2218390111229382e-05}, {"id": 1243, "seek": 496772, "start": 4976.320000000001, "end": 4982.56, "text": " And it basically says that samples that are close by in the time space are related and", "tokens": [50364, 407, 498, 291, 458, 295, 341, 3743, 3170, 1219, 383, 12986, 11, 597, 307, 8712, 488, 35521, 17720, 11, 50603, 50603, 300, 534, 30910, 322, 264, 42881, 3687, 295, 257, 6358, 13, 50794, 50794, 400, 309, 1936, 1619, 300, 10938, 300, 366, 1998, 538, 294, 264, 565, 1901, 366, 4077, 293, 51106, 51106, 10938, 300, 366, 3052, 4936, 294, 264, 565, 1901, 366, 38967, 13, 51312, 51312, 400, 456, 311, 257, 6457, 2416, 2372, 295, 589, 1936, 12382, 1748, 341, 13, 51592, 51592, 467, 393, 2139, 312, 294, 264, 6218, 9274, 13, 51722, 51722, 467, 393, 2139, 312, 294, 960, 13, 51799, 51799], "temperature": 0.0, "avg_logprob": -0.10003694806780133, "compression_ratio": 1.763265306122449, "no_speech_prob": 1.2218390111229382e-05}, {"id": 1244, "seek": 496772, "start": 4982.56, "end": 4986.68, "text": " samples that are further apart in the time space are unrelated.", "tokens": [50364, 407, 498, 291, 458, 295, 341, 3743, 3170, 1219, 383, 12986, 11, 597, 307, 8712, 488, 35521, 17720, 11, 50603, 50603, 300, 534, 30910, 322, 264, 42881, 3687, 295, 257, 6358, 13, 50794, 50794, 400, 309, 1936, 1619, 300, 10938, 300, 366, 1998, 538, 294, 264, 565, 1901, 366, 4077, 293, 51106, 51106, 10938, 300, 366, 3052, 4936, 294, 264, 565, 1901, 366, 38967, 13, 51312, 51312, 400, 456, 311, 257, 6457, 2416, 2372, 295, 589, 1936, 12382, 1748, 341, 13, 51592, 51592, 467, 393, 2139, 312, 294, 264, 6218, 9274, 13, 51722, 51722, 467, 393, 2139, 312, 294, 960, 13, 51799, 51799], "temperature": 0.0, "avg_logprob": -0.10003694806780133, "compression_ratio": 1.763265306122449, "no_speech_prob": 1.2218390111229382e-05}, {"id": 1245, "seek": 496772, "start": 4986.68, "end": 4992.280000000001, "text": " And there's a fairly large amount of work basically exploiting this.", "tokens": [50364, 407, 498, 291, 458, 295, 341, 3743, 3170, 1219, 383, 12986, 11, 597, 307, 8712, 488, 35521, 17720, 11, 50603, 50603, 300, 534, 30910, 322, 264, 42881, 3687, 295, 257, 6358, 13, 50794, 50794, 400, 309, 1936, 1619, 300, 10938, 300, 366, 1998, 538, 294, 264, 565, 1901, 366, 4077, 293, 51106, 51106, 10938, 300, 366, 3052, 4936, 294, 264, 565, 1901, 366, 38967, 13, 51312, 51312, 400, 456, 311, 257, 6457, 2416, 2372, 295, 589, 1936, 12382, 1748, 341, 13, 51592, 51592, 467, 393, 2139, 312, 294, 264, 6218, 9274, 13, 51722, 51722, 467, 393, 2139, 312, 294, 960, 13, 51799, 51799], "temperature": 0.0, "avg_logprob": -0.10003694806780133, "compression_ratio": 1.763265306122449, "no_speech_prob": 1.2218390111229382e-05}, {"id": 1246, "seek": 496772, "start": 4992.280000000001, "end": 4994.88, "text": " It can either be in the speech domain.", "tokens": [50364, 407, 498, 291, 458, 295, 341, 3743, 3170, 1219, 383, 12986, 11, 597, 307, 8712, 488, 35521, 17720, 11, 50603, 50603, 300, 534, 30910, 322, 264, 42881, 3687, 295, 257, 6358, 13, 50794, 50794, 400, 309, 1936, 1619, 300, 10938, 300, 366, 1998, 538, 294, 264, 565, 1901, 366, 4077, 293, 51106, 51106, 10938, 300, 366, 3052, 4936, 294, 264, 565, 1901, 366, 38967, 13, 51312, 51312, 400, 456, 311, 257, 6457, 2416, 2372, 295, 589, 1936, 12382, 1748, 341, 13, 51592, 51592, 467, 393, 2139, 312, 294, 264, 6218, 9274, 13, 51722, 51722, 467, 393, 2139, 312, 294, 960, 13, 51799, 51799], "temperature": 0.0, "avg_logprob": -0.10003694806780133, "compression_ratio": 1.763265306122449, "no_speech_prob": 1.2218390111229382e-05}, {"id": 1247, "seek": 496772, "start": 4994.88, "end": 4996.42, "text": " It can either be in video.", "tokens": [50364, 407, 498, 291, 458, 295, 341, 3743, 3170, 1219, 383, 12986, 11, 597, 307, 8712, 488, 35521, 17720, 11, 50603, 50603, 300, 534, 30910, 322, 264, 42881, 3687, 295, 257, 6358, 13, 50794, 50794, 400, 309, 1936, 1619, 300, 10938, 300, 366, 1998, 538, 294, 264, 565, 1901, 366, 4077, 293, 51106, 51106, 10938, 300, 366, 3052, 4936, 294, 264, 565, 1901, 366, 38967, 13, 51312, 51312, 400, 456, 311, 257, 6457, 2416, 2372, 295, 589, 1936, 12382, 1748, 341, 13, 51592, 51592, 467, 393, 2139, 312, 294, 264, 6218, 9274, 13, 51722, 51722, 467, 393, 2139, 312, 294, 960, 13, 51799, 51799], "temperature": 0.0, "avg_logprob": -0.10003694806780133, "compression_ratio": 1.763265306122449, "no_speech_prob": 1.2218390111229382e-05}, {"id": 1248, "seek": 499642, "start": 4996.42, "end": 5001.7, "text": " It can be in text, or it can be in regular images.", "tokens": [50364, 467, 393, 312, 294, 2487, 11, 420, 309, 393, 312, 294, 3890, 5267, 13, 50628, 50628, 400, 3938, 11, 321, 600, 611, 668, 1364, 322, 960, 293, 6278, 13, 50757, 50757, 407, 1936, 1566, 300, 257, 960, 293, 1080, 11760, 6278, 366, 4077, 10938, 11, 293, 257, 960, 293, 51089, 51089, 6278, 490, 257, 819, 3256, 960, 366, 1936, 38967, 10938, 13, 51420, 51420, 400, 512, 295, 264, 2440, 589, 294, 1333, 295, 2698, 12, 48172, 24420, 2539, 611, 764, 341, 8712, 488, 2539, 51823, 51823], "temperature": 0.0, "avg_logprob": -0.17236723683097147, "compression_ratio": 1.7630331753554502, "no_speech_prob": 4.289263870305149e-06}, {"id": 1249, "seek": 499642, "start": 5001.7, "end": 5004.28, "text": " And recently, we've also been working on video and audio.", "tokens": [50364, 467, 393, 312, 294, 2487, 11, 420, 309, 393, 312, 294, 3890, 5267, 13, 50628, 50628, 400, 3938, 11, 321, 600, 611, 668, 1364, 322, 960, 293, 6278, 13, 50757, 50757, 407, 1936, 1566, 300, 257, 960, 293, 1080, 11760, 6278, 366, 4077, 10938, 11, 293, 257, 960, 293, 51089, 51089, 6278, 490, 257, 819, 3256, 960, 366, 1936, 38967, 10938, 13, 51420, 51420, 400, 512, 295, 264, 2440, 589, 294, 1333, 295, 2698, 12, 48172, 24420, 2539, 611, 764, 341, 8712, 488, 2539, 51823, 51823], "temperature": 0.0, "avg_logprob": -0.17236723683097147, "compression_ratio": 1.7630331753554502, "no_speech_prob": 4.289263870305149e-06}, {"id": 1250, "seek": 499642, "start": 5004.28, "end": 5010.92, "text": " So basically saying that a video and its corresponding audio are related samples, and a video and", "tokens": [50364, 467, 393, 312, 294, 2487, 11, 420, 309, 393, 312, 294, 3890, 5267, 13, 50628, 50628, 400, 3938, 11, 321, 600, 611, 668, 1364, 322, 960, 293, 6278, 13, 50757, 50757, 407, 1936, 1566, 300, 257, 960, 293, 1080, 11760, 6278, 366, 4077, 10938, 11, 293, 257, 960, 293, 51089, 51089, 6278, 490, 257, 819, 3256, 960, 366, 1936, 38967, 10938, 13, 51420, 51420, 400, 512, 295, 264, 2440, 589, 294, 1333, 295, 2698, 12, 48172, 24420, 2539, 611, 764, 341, 8712, 488, 2539, 51823, 51823], "temperature": 0.0, "avg_logprob": -0.17236723683097147, "compression_ratio": 1.7630331753554502, "no_speech_prob": 4.289263870305149e-06}, {"id": 1251, "seek": 499642, "start": 5010.92, "end": 5017.54, "text": " audio from a different image video are basically unrelated samples.", "tokens": [50364, 467, 393, 312, 294, 2487, 11, 420, 309, 393, 312, 294, 3890, 5267, 13, 50628, 50628, 400, 3938, 11, 321, 600, 611, 668, 1364, 322, 960, 293, 6278, 13, 50757, 50757, 407, 1936, 1566, 300, 257, 960, 293, 1080, 11760, 6278, 366, 4077, 10938, 11, 293, 257, 960, 293, 51089, 51089, 6278, 490, 257, 819, 3256, 960, 366, 1936, 38967, 10938, 13, 51420, 51420, 400, 512, 295, 264, 2440, 589, 294, 1333, 295, 2698, 12, 48172, 24420, 2539, 611, 764, 341, 8712, 488, 2539, 51823, 51823], "temperature": 0.0, "avg_logprob": -0.17236723683097147, "compression_ratio": 1.7630331753554502, "no_speech_prob": 4.289263870305149e-06}, {"id": 1252, "seek": 499642, "start": 5017.54, "end": 5025.6, "text": " And some of the early work in sort of self-supervised learning also use this contrastive learning", "tokens": [50364, 467, 393, 312, 294, 2487, 11, 420, 309, 393, 312, 294, 3890, 5267, 13, 50628, 50628, 400, 3938, 11, 321, 600, 611, 668, 1364, 322, 960, 293, 6278, 13, 50757, 50757, 407, 1936, 1566, 300, 257, 960, 293, 1080, 11760, 6278, 366, 4077, 10938, 11, 293, 257, 960, 293, 51089, 51089, 6278, 490, 257, 819, 3256, 960, 366, 1936, 38967, 10938, 13, 51420, 51420, 400, 512, 295, 264, 2440, 589, 294, 1333, 295, 2698, 12, 48172, 24420, 2539, 611, 764, 341, 8712, 488, 2539, 51823, 51823], "temperature": 0.0, "avg_logprob": -0.17236723683097147, "compression_ratio": 1.7630331753554502, "no_speech_prob": 4.289263870305149e-06}, {"id": 1253, "seek": 502560, "start": 5025.6, "end": 5026.6, "text": " method.", "tokens": [50364, 3170, 13, 50414, 50414, 400, 264, 636, 436, 7642, 4077, 10938, 390, 6457, 1880, 13, 50576, 50576, 407, 291, 1190, 364, 2657, 37516, 670, 257, 960, 11, 293, 300, 1333, 295, 2709, 291, 257, 2684, 9972, 13, 51004, 51004, 400, 437, 291, 584, 307, 300, 604, 9972, 300, 390, 31703, 538, 452, 37516, 307, 4077, 281, 452, 3380, 51288, 51288, 9972, 11, 9735, 604, 9972, 490, 257, 819, 960, 307, 257, 406, 4077, 9972, 13, 51552, 51552, 400, 370, 300, 1936, 2709, 291, 613, 3840, 295, 4077, 293, 38967, 10938, 13, 51780, 51780], "temperature": 0.0, "avg_logprob": -0.1264477579217208, "compression_ratio": 1.8099547511312217, "no_speech_prob": 7.527859906986123e-06}, {"id": 1254, "seek": 502560, "start": 5026.6, "end": 5029.84, "text": " And the way they defined related samples was fairly interesting.", "tokens": [50364, 3170, 13, 50414, 50414, 400, 264, 636, 436, 7642, 4077, 10938, 390, 6457, 1880, 13, 50576, 50576, 407, 291, 1190, 364, 2657, 37516, 670, 257, 960, 11, 293, 300, 1333, 295, 2709, 291, 257, 2684, 9972, 13, 51004, 51004, 400, 437, 291, 584, 307, 300, 604, 9972, 300, 390, 31703, 538, 452, 37516, 307, 4077, 281, 452, 3380, 51288, 51288, 9972, 11, 9735, 604, 9972, 490, 257, 819, 960, 307, 257, 406, 4077, 9972, 13, 51552, 51552, 400, 370, 300, 1936, 2709, 291, 613, 3840, 295, 4077, 293, 38967, 10938, 13, 51780, 51780], "temperature": 0.0, "avg_logprob": -0.1264477579217208, "compression_ratio": 1.8099547511312217, "no_speech_prob": 7.527859906986123e-06}, {"id": 1255, "seek": 502560, "start": 5029.84, "end": 5038.400000000001, "text": " So you run an object tracker over a video, and that sort of gives you a moving patch.", "tokens": [50364, 3170, 13, 50414, 50414, 400, 264, 636, 436, 7642, 4077, 10938, 390, 6457, 1880, 13, 50576, 50576, 407, 291, 1190, 364, 2657, 37516, 670, 257, 960, 11, 293, 300, 1333, 295, 2709, 291, 257, 2684, 9972, 13, 51004, 51004, 400, 437, 291, 584, 307, 300, 604, 9972, 300, 390, 31703, 538, 452, 37516, 307, 4077, 281, 452, 3380, 51288, 51288, 9972, 11, 9735, 604, 9972, 490, 257, 819, 960, 307, 257, 406, 4077, 9972, 13, 51552, 51552, 400, 370, 300, 1936, 2709, 291, 613, 3840, 295, 4077, 293, 38967, 10938, 13, 51780, 51780], "temperature": 0.0, "avg_logprob": -0.1264477579217208, "compression_ratio": 1.8099547511312217, "no_speech_prob": 7.527859906986123e-06}, {"id": 1256, "seek": 502560, "start": 5038.400000000001, "end": 5044.08, "text": " And what you say is that any patch that was tracked by my tracker is related to my original", "tokens": [50364, 3170, 13, 50414, 50414, 400, 264, 636, 436, 7642, 4077, 10938, 390, 6457, 1880, 13, 50576, 50576, 407, 291, 1190, 364, 2657, 37516, 670, 257, 960, 11, 293, 300, 1333, 295, 2709, 291, 257, 2684, 9972, 13, 51004, 51004, 400, 437, 291, 584, 307, 300, 604, 9972, 300, 390, 31703, 538, 452, 37516, 307, 4077, 281, 452, 3380, 51288, 51288, 9972, 11, 9735, 604, 9972, 490, 257, 819, 960, 307, 257, 406, 4077, 9972, 13, 51552, 51552, 400, 370, 300, 1936, 2709, 291, 613, 3840, 295, 4077, 293, 38967, 10938, 13, 51780, 51780], "temperature": 0.0, "avg_logprob": -0.1264477579217208, "compression_ratio": 1.8099547511312217, "no_speech_prob": 7.527859906986123e-06}, {"id": 1257, "seek": 502560, "start": 5044.08, "end": 5049.360000000001, "text": " patch, whereas any patch from a different video is a not related patch.", "tokens": [50364, 3170, 13, 50414, 50414, 400, 264, 636, 436, 7642, 4077, 10938, 390, 6457, 1880, 13, 50576, 50576, 407, 291, 1190, 364, 2657, 37516, 670, 257, 960, 11, 293, 300, 1333, 295, 2709, 291, 257, 2684, 9972, 13, 51004, 51004, 400, 437, 291, 584, 307, 300, 604, 9972, 300, 390, 31703, 538, 452, 37516, 307, 4077, 281, 452, 3380, 51288, 51288, 9972, 11, 9735, 604, 9972, 490, 257, 819, 960, 307, 257, 406, 4077, 9972, 13, 51552, 51552, 400, 370, 300, 1936, 2709, 291, 613, 3840, 295, 4077, 293, 38967, 10938, 13, 51780, 51780], "temperature": 0.0, "avg_logprob": -0.1264477579217208, "compression_ratio": 1.8099547511312217, "no_speech_prob": 7.527859906986123e-06}, {"id": 1258, "seek": 502560, "start": 5049.360000000001, "end": 5053.92, "text": " And so that basically gives you these bunch of related and unrelated samples.", "tokens": [50364, 3170, 13, 50414, 50414, 400, 264, 636, 436, 7642, 4077, 10938, 390, 6457, 1880, 13, 50576, 50576, 407, 291, 1190, 364, 2657, 37516, 670, 257, 960, 11, 293, 300, 1333, 295, 2709, 291, 257, 2684, 9972, 13, 51004, 51004, 400, 437, 291, 584, 307, 300, 604, 9972, 300, 390, 31703, 538, 452, 37516, 307, 4077, 281, 452, 3380, 51288, 51288, 9972, 11, 9735, 604, 9972, 490, 257, 819, 960, 307, 257, 406, 4077, 9972, 13, 51552, 51552, 400, 370, 300, 1936, 2709, 291, 613, 3840, 295, 4077, 293, 38967, 10938, 13, 51780, 51780], "temperature": 0.0, "avg_logprob": -0.1264477579217208, "compression_ratio": 1.8099547511312217, "no_speech_prob": 7.527859906986123e-06}, {"id": 1259, "seek": 505392, "start": 5053.92, "end": 5060.8, "text": " So if you look at, in this case, figure C, where you have this distance notation, what", "tokens": [50364, 407, 498, 291, 574, 412, 11, 294, 341, 1389, 11, 2573, 383, 11, 689, 291, 362, 341, 4560, 24657, 11, 437, 50708, 50708, 341, 3209, 9898, 281, 1466, 307, 1936, 300, 26531, 300, 366, 1348, 490, 264, 912, 960, 50928, 50928, 366, 4077, 11, 293, 26531, 300, 366, 1348, 490, 819, 2145, 366, 406, 4077, 13, 51184, 51184, 400, 370, 294, 512, 636, 11, 309, 6772, 27152, 466, 819, 26059, 295, 364, 2657, 13, 51474, 51474, 407, 257, 6586, 19174, 490, 819, 17480, 14708, 420, 819, 26059, 295, 257, 3000, 11, 293, 309, 9898, 51842, 51842], "temperature": 0.0, "avg_logprob": -0.12430409022739955, "compression_ratio": 1.844155844155844, "no_speech_prob": 2.9943964818812674e-06}, {"id": 1260, "seek": 505392, "start": 5060.8, "end": 5065.2, "text": " this network tries to learn is basically that patches that are coming from the same video", "tokens": [50364, 407, 498, 291, 574, 412, 11, 294, 341, 1389, 11, 2573, 383, 11, 689, 291, 362, 341, 4560, 24657, 11, 437, 50708, 50708, 341, 3209, 9898, 281, 1466, 307, 1936, 300, 26531, 300, 366, 1348, 490, 264, 912, 960, 50928, 50928, 366, 4077, 11, 293, 26531, 300, 366, 1348, 490, 819, 2145, 366, 406, 4077, 13, 51184, 51184, 400, 370, 294, 512, 636, 11, 309, 6772, 27152, 466, 819, 26059, 295, 364, 2657, 13, 51474, 51474, 407, 257, 6586, 19174, 490, 819, 17480, 14708, 420, 819, 26059, 295, 257, 3000, 11, 293, 309, 9898, 51842, 51842], "temperature": 0.0, "avg_logprob": -0.12430409022739955, "compression_ratio": 1.844155844155844, "no_speech_prob": 2.9943964818812674e-06}, {"id": 1261, "seek": 505392, "start": 5065.2, "end": 5070.32, "text": " are related, and patches that are coming from different videos are not related.", "tokens": [50364, 407, 498, 291, 574, 412, 11, 294, 341, 1389, 11, 2573, 383, 11, 689, 291, 362, 341, 4560, 24657, 11, 437, 50708, 50708, 341, 3209, 9898, 281, 1466, 307, 1936, 300, 26531, 300, 366, 1348, 490, 264, 912, 960, 50928, 50928, 366, 4077, 11, 293, 26531, 300, 366, 1348, 490, 819, 2145, 366, 406, 4077, 13, 51184, 51184, 400, 370, 294, 512, 636, 11, 309, 6772, 27152, 466, 819, 26059, 295, 364, 2657, 13, 51474, 51474, 407, 257, 6586, 19174, 490, 819, 17480, 14708, 420, 819, 26059, 295, 257, 3000, 11, 293, 309, 9898, 51842, 51842], "temperature": 0.0, "avg_logprob": -0.12430409022739955, "compression_ratio": 1.844155844155844, "no_speech_prob": 2.9943964818812674e-06}, {"id": 1262, "seek": 505392, "start": 5070.32, "end": 5076.12, "text": " And so in some way, it automatically learns about different poses of an object.", "tokens": [50364, 407, 498, 291, 574, 412, 11, 294, 341, 1389, 11, 2573, 383, 11, 689, 291, 362, 341, 4560, 24657, 11, 437, 50708, 50708, 341, 3209, 9898, 281, 1466, 307, 1936, 300, 26531, 300, 366, 1348, 490, 264, 912, 960, 50928, 50928, 366, 4077, 11, 293, 26531, 300, 366, 1348, 490, 819, 2145, 366, 406, 4077, 13, 51184, 51184, 400, 370, 294, 512, 636, 11, 309, 6772, 27152, 466, 819, 26059, 295, 364, 2657, 13, 51474, 51474, 407, 257, 6586, 19174, 490, 819, 17480, 14708, 420, 819, 26059, 295, 257, 3000, 11, 293, 309, 9898, 51842, 51842], "temperature": 0.0, "avg_logprob": -0.12430409022739955, "compression_ratio": 1.844155844155844, "no_speech_prob": 2.9943964818812674e-06}, {"id": 1263, "seek": 505392, "start": 5076.12, "end": 5083.4800000000005, "text": " So a cycle viewed from different viewing angles or different poses of a dog, and it tries", "tokens": [50364, 407, 498, 291, 574, 412, 11, 294, 341, 1389, 11, 2573, 383, 11, 689, 291, 362, 341, 4560, 24657, 11, 437, 50708, 50708, 341, 3209, 9898, 281, 1466, 307, 1936, 300, 26531, 300, 366, 1348, 490, 264, 912, 960, 50928, 50928, 366, 4077, 11, 293, 26531, 300, 366, 1348, 490, 819, 2145, 366, 406, 4077, 13, 51184, 51184, 400, 370, 294, 512, 636, 11, 309, 6772, 27152, 466, 819, 26059, 295, 364, 2657, 13, 51474, 51474, 407, 257, 6586, 19174, 490, 819, 17480, 14708, 420, 819, 26059, 295, 257, 3000, 11, 293, 309, 9898, 51842, 51842], "temperature": 0.0, "avg_logprob": -0.12430409022739955, "compression_ratio": 1.844155844155844, "no_speech_prob": 2.9943964818812674e-06}, {"id": 1264, "seek": 508348, "start": 5083.48, "end": 5088.919999999999, "text": " to sort of group them together.", "tokens": [50364, 281, 1333, 295, 1594, 552, 1214, 13, 50636, 50636, 682, 2674, 11, 498, 291, 445, 751, 466, 5267, 11, 257, 688, 295, 589, 307, 1096, 322, 1237, 412, 11184, 50988, 50988, 3256, 26531, 5717, 17275, 26531, 13, 51100, 51100, 407, 881, 295, 264, 1333, 295, 383, 12986, 3037, 472, 293, 383, 12986, 3037, 732, 7150, 366, 534, 1333, 295, 51390, 51390, 12382, 1748, 341, 4707, 295, 5267, 13, 51514, 51514, 407, 437, 291, 360, 307, 291, 362, 3256, 26531, 300, 366, 1998, 538, 11, 291, 818, 552, 382, 35127, 11, 51772, 51772], "temperature": 0.0, "avg_logprob": -0.13824380712306245, "compression_ratio": 1.6743119266055047, "no_speech_prob": 5.7718739299161825e-06}, {"id": 1265, "seek": 508348, "start": 5088.919999999999, "end": 5095.959999999999, "text": " In general, if you just talk about images, a lot of work is done on looking at nearby", "tokens": [50364, 281, 1333, 295, 1594, 552, 1214, 13, 50636, 50636, 682, 2674, 11, 498, 291, 445, 751, 466, 5267, 11, 257, 688, 295, 589, 307, 1096, 322, 1237, 412, 11184, 50988, 50988, 3256, 26531, 5717, 17275, 26531, 13, 51100, 51100, 407, 881, 295, 264, 1333, 295, 383, 12986, 3037, 472, 293, 383, 12986, 3037, 732, 7150, 366, 534, 1333, 295, 51390, 51390, 12382, 1748, 341, 4707, 295, 5267, 13, 51514, 51514, 407, 437, 291, 360, 307, 291, 362, 3256, 26531, 300, 366, 1998, 538, 11, 291, 818, 552, 382, 35127, 11, 51772, 51772], "temperature": 0.0, "avg_logprob": -0.13824380712306245, "compression_ratio": 1.6743119266055047, "no_speech_prob": 5.7718739299161825e-06}, {"id": 1266, "seek": 508348, "start": 5095.959999999999, "end": 5098.2, "text": " image patches versus distant patches.", "tokens": [50364, 281, 1333, 295, 1594, 552, 1214, 13, 50636, 50636, 682, 2674, 11, 498, 291, 445, 751, 466, 5267, 11, 257, 688, 295, 589, 307, 1096, 322, 1237, 412, 11184, 50988, 50988, 3256, 26531, 5717, 17275, 26531, 13, 51100, 51100, 407, 881, 295, 264, 1333, 295, 383, 12986, 3037, 472, 293, 383, 12986, 3037, 732, 7150, 366, 534, 1333, 295, 51390, 51390, 12382, 1748, 341, 4707, 295, 5267, 13, 51514, 51514, 407, 437, 291, 360, 307, 291, 362, 3256, 26531, 300, 366, 1998, 538, 11, 291, 818, 552, 382, 35127, 11, 51772, 51772], "temperature": 0.0, "avg_logprob": -0.13824380712306245, "compression_ratio": 1.6743119266055047, "no_speech_prob": 5.7718739299161825e-06}, {"id": 1267, "seek": 508348, "start": 5098.2, "end": 5104.0, "text": " So most of the sort of CPC version one and CPC version two methods are really sort of", "tokens": [50364, 281, 1333, 295, 1594, 552, 1214, 13, 50636, 50636, 682, 2674, 11, 498, 291, 445, 751, 466, 5267, 11, 257, 688, 295, 589, 307, 1096, 322, 1237, 412, 11184, 50988, 50988, 3256, 26531, 5717, 17275, 26531, 13, 51100, 51100, 407, 881, 295, 264, 1333, 295, 383, 12986, 3037, 472, 293, 383, 12986, 3037, 732, 7150, 366, 534, 1333, 295, 51390, 51390, 12382, 1748, 341, 4707, 295, 5267, 13, 51514, 51514, 407, 437, 291, 360, 307, 291, 362, 3256, 26531, 300, 366, 1998, 538, 11, 291, 818, 552, 382, 35127, 11, 51772, 51772], "temperature": 0.0, "avg_logprob": -0.13824380712306245, "compression_ratio": 1.6743119266055047, "no_speech_prob": 5.7718739299161825e-06}, {"id": 1268, "seek": 508348, "start": 5104.0, "end": 5106.48, "text": " exploiting this property of images.", "tokens": [50364, 281, 1333, 295, 1594, 552, 1214, 13, 50636, 50636, 682, 2674, 11, 498, 291, 445, 751, 466, 5267, 11, 257, 688, 295, 589, 307, 1096, 322, 1237, 412, 11184, 50988, 50988, 3256, 26531, 5717, 17275, 26531, 13, 51100, 51100, 407, 881, 295, 264, 1333, 295, 383, 12986, 3037, 472, 293, 383, 12986, 3037, 732, 7150, 366, 534, 1333, 295, 51390, 51390, 12382, 1748, 341, 4707, 295, 5267, 13, 51514, 51514, 407, 437, 291, 360, 307, 291, 362, 3256, 26531, 300, 366, 1998, 538, 11, 291, 818, 552, 382, 35127, 11, 51772, 51772], "temperature": 0.0, "avg_logprob": -0.13824380712306245, "compression_ratio": 1.6743119266055047, "no_speech_prob": 5.7718739299161825e-06}, {"id": 1269, "seek": 508348, "start": 5106.48, "end": 5111.639999999999, "text": " So what you do is you have image patches that are close by, you call them as positives,", "tokens": [50364, 281, 1333, 295, 1594, 552, 1214, 13, 50636, 50636, 682, 2674, 11, 498, 291, 445, 751, 466, 5267, 11, 257, 688, 295, 589, 307, 1096, 322, 1237, 412, 11184, 50988, 50988, 3256, 26531, 5717, 17275, 26531, 13, 51100, 51100, 407, 881, 295, 264, 1333, 295, 383, 12986, 3037, 472, 293, 383, 12986, 3037, 732, 7150, 366, 534, 1333, 295, 51390, 51390, 12382, 1748, 341, 4707, 295, 5267, 13, 51514, 51514, 407, 437, 291, 360, 307, 291, 362, 3256, 26531, 300, 366, 1998, 538, 11, 291, 818, 552, 382, 35127, 11, 51772, 51772], "temperature": 0.0, "avg_logprob": -0.13824380712306245, "compression_ratio": 1.6743119266055047, "no_speech_prob": 5.7718739299161825e-06}, {"id": 1270, "seek": 511164, "start": 5111.64, "end": 5117.68, "text": " and image patches that are further apart, like far, farther away in the image are considered", "tokens": [50364, 293, 3256, 26531, 300, 366, 3052, 4936, 11, 411, 1400, 11, 20344, 1314, 294, 264, 3256, 366, 4888, 50666, 50666, 382, 40019, 13, 50716, 50716, 400, 550, 291, 1936, 445, 17522, 257, 8712, 488, 4470, 1228, 341, 1333, 295, 7123, 295, 35127, 50956, 50956, 293, 40019, 13, 51142, 51142, 440, 544, 1333, 295, 3743, 420, 411, 2042, 394, 636, 295, 884, 341, 307, 281, 574, 412, 26531, 1348, 51462, 51462, 490, 364, 3256, 293, 8712, 552, 365, 26531, 1348, 490, 257, 819, 3256, 13, 51670, 51670], "temperature": 0.0, "avg_logprob": -0.1371396238153631, "compression_ratio": 1.7432432432432432, "no_speech_prob": 8.530235390935559e-06}, {"id": 1271, "seek": 511164, "start": 5117.68, "end": 5118.68, "text": " as negatives.", "tokens": [50364, 293, 3256, 26531, 300, 366, 3052, 4936, 11, 411, 1400, 11, 20344, 1314, 294, 264, 3256, 366, 4888, 50666, 50666, 382, 40019, 13, 50716, 50716, 400, 550, 291, 1936, 445, 17522, 257, 8712, 488, 4470, 1228, 341, 1333, 295, 7123, 295, 35127, 50956, 50956, 293, 40019, 13, 51142, 51142, 440, 544, 1333, 295, 3743, 420, 411, 2042, 394, 636, 295, 884, 341, 307, 281, 574, 412, 26531, 1348, 51462, 51462, 490, 364, 3256, 293, 8712, 552, 365, 26531, 1348, 490, 257, 819, 3256, 13, 51670, 51670], "temperature": 0.0, "avg_logprob": -0.1371396238153631, "compression_ratio": 1.7432432432432432, "no_speech_prob": 8.530235390935559e-06}, {"id": 1272, "seek": 511164, "start": 5118.68, "end": 5123.4800000000005, "text": " And then you basically just minimize a contrastive loss using this sort of definition of positives", "tokens": [50364, 293, 3256, 26531, 300, 366, 3052, 4936, 11, 411, 1400, 11, 20344, 1314, 294, 264, 3256, 366, 4888, 50666, 50666, 382, 40019, 13, 50716, 50716, 400, 550, 291, 1936, 445, 17522, 257, 8712, 488, 4470, 1228, 341, 1333, 295, 7123, 295, 35127, 50956, 50956, 293, 40019, 13, 51142, 51142, 440, 544, 1333, 295, 3743, 420, 411, 2042, 394, 636, 295, 884, 341, 307, 281, 574, 412, 26531, 1348, 51462, 51462, 490, 364, 3256, 293, 8712, 552, 365, 26531, 1348, 490, 257, 819, 3256, 13, 51670, 51670], "temperature": 0.0, "avg_logprob": -0.1371396238153631, "compression_ratio": 1.7432432432432432, "no_speech_prob": 8.530235390935559e-06}, {"id": 1273, "seek": 511164, "start": 5123.4800000000005, "end": 5127.200000000001, "text": " and negatives.", "tokens": [50364, 293, 3256, 26531, 300, 366, 3052, 4936, 11, 411, 1400, 11, 20344, 1314, 294, 264, 3256, 366, 4888, 50666, 50666, 382, 40019, 13, 50716, 50716, 400, 550, 291, 1936, 445, 17522, 257, 8712, 488, 4470, 1228, 341, 1333, 295, 7123, 295, 35127, 50956, 50956, 293, 40019, 13, 51142, 51142, 440, 544, 1333, 295, 3743, 420, 411, 2042, 394, 636, 295, 884, 341, 307, 281, 574, 412, 26531, 1348, 51462, 51462, 490, 364, 3256, 293, 8712, 552, 365, 26531, 1348, 490, 257, 819, 3256, 13, 51670, 51670], "temperature": 0.0, "avg_logprob": -0.1371396238153631, "compression_ratio": 1.7432432432432432, "no_speech_prob": 8.530235390935559e-06}, {"id": 1274, "seek": 511164, "start": 5127.200000000001, "end": 5133.6, "text": " The more sort of popular or like performant way of doing this is to look at patches coming", "tokens": [50364, 293, 3256, 26531, 300, 366, 3052, 4936, 11, 411, 1400, 11, 20344, 1314, 294, 264, 3256, 366, 4888, 50666, 50666, 382, 40019, 13, 50716, 50716, 400, 550, 291, 1936, 445, 17522, 257, 8712, 488, 4470, 1228, 341, 1333, 295, 7123, 295, 35127, 50956, 50956, 293, 40019, 13, 51142, 51142, 440, 544, 1333, 295, 3743, 420, 411, 2042, 394, 636, 295, 884, 341, 307, 281, 574, 412, 26531, 1348, 51462, 51462, 490, 364, 3256, 293, 8712, 552, 365, 26531, 1348, 490, 257, 819, 3256, 13, 51670, 51670], "temperature": 0.0, "avg_logprob": -0.1371396238153631, "compression_ratio": 1.7432432432432432, "no_speech_prob": 8.530235390935559e-06}, {"id": 1275, "seek": 511164, "start": 5133.6, "end": 5137.76, "text": " from an image and contrast them with patches coming from a different image.", "tokens": [50364, 293, 3256, 26531, 300, 366, 3052, 4936, 11, 411, 1400, 11, 20344, 1314, 294, 264, 3256, 366, 4888, 50666, 50666, 382, 40019, 13, 50716, 50716, 400, 550, 291, 1936, 445, 17522, 257, 8712, 488, 4470, 1228, 341, 1333, 295, 7123, 295, 35127, 50956, 50956, 293, 40019, 13, 51142, 51142, 440, 544, 1333, 295, 3743, 420, 411, 2042, 394, 636, 295, 884, 341, 307, 281, 574, 412, 26531, 1348, 51462, 51462, 490, 364, 3256, 293, 8712, 552, 365, 26531, 1348, 490, 257, 819, 3256, 13, 51670, 51670], "temperature": 0.0, "avg_logprob": -0.1371396238153631, "compression_ratio": 1.7432432432432432, "no_speech_prob": 8.530235390935559e-06}, {"id": 1276, "seek": 513776, "start": 5137.76, "end": 5144.0, "text": " So this sort of forms the basis of a lot of popular methods, like instance discrimination,", "tokens": [50364, 407, 341, 1333, 295, 6422, 264, 5143, 295, 257, 688, 295, 3743, 7150, 11, 411, 5197, 15973, 11, 50676, 50676, 3335, 21141, 11, 3026, 75, 11, 318, 6683, 34, 5797, 13, 50802, 50802, 440, 1558, 307, 1936, 437, 311, 4898, 294, 264, 3256, 13, 50974, 50974, 1407, 1333, 295, 483, 666, 544, 2607, 11, 437, 613, 7150, 360, 307, 436, 8947, 732, 2584, 51244, 51244, 4974, 26531, 490, 364, 3256, 13, 51321, 51321, 407, 613, 26531, 393, 312, 33535, 11, 436, 393, 767, 312, 16212, 1951, 472, 1071, 11, 51546, 51546, 420, 436, 393, 312, 2584, 1400, 4936, 11, 293, 550, 3079, 512, 1333, 295, 1412, 14501, 19631, 13, 51827, 51827], "temperature": 0.0, "avg_logprob": -0.21835222497450568, "compression_ratio": 1.6879699248120301, "no_speech_prob": 7.182932677096687e-06}, {"id": 1277, "seek": 513776, "start": 5144.0, "end": 5146.52, "text": " MoCo, Perl, SEMClear.", "tokens": [50364, 407, 341, 1333, 295, 6422, 264, 5143, 295, 257, 688, 295, 3743, 7150, 11, 411, 5197, 15973, 11, 50676, 50676, 3335, 21141, 11, 3026, 75, 11, 318, 6683, 34, 5797, 13, 50802, 50802, 440, 1558, 307, 1936, 437, 311, 4898, 294, 264, 3256, 13, 50974, 50974, 1407, 1333, 295, 483, 666, 544, 2607, 11, 437, 613, 7150, 360, 307, 436, 8947, 732, 2584, 51244, 51244, 4974, 26531, 490, 364, 3256, 13, 51321, 51321, 407, 613, 26531, 393, 312, 33535, 11, 436, 393, 767, 312, 16212, 1951, 472, 1071, 11, 51546, 51546, 420, 436, 393, 312, 2584, 1400, 4936, 11, 293, 550, 3079, 512, 1333, 295, 1412, 14501, 19631, 13, 51827, 51827], "temperature": 0.0, "avg_logprob": -0.21835222497450568, "compression_ratio": 1.6879699248120301, "no_speech_prob": 7.182932677096687e-06}, {"id": 1278, "seek": 513776, "start": 5146.52, "end": 5149.96, "text": " The idea is basically what's shown in the image.", "tokens": [50364, 407, 341, 1333, 295, 6422, 264, 5143, 295, 257, 688, 295, 3743, 7150, 11, 411, 5197, 15973, 11, 50676, 50676, 3335, 21141, 11, 3026, 75, 11, 318, 6683, 34, 5797, 13, 50802, 50802, 440, 1558, 307, 1936, 437, 311, 4898, 294, 264, 3256, 13, 50974, 50974, 1407, 1333, 295, 483, 666, 544, 2607, 11, 437, 613, 7150, 360, 307, 436, 8947, 732, 2584, 51244, 51244, 4974, 26531, 490, 364, 3256, 13, 51321, 51321, 407, 613, 26531, 393, 312, 33535, 11, 436, 393, 767, 312, 16212, 1951, 472, 1071, 11, 51546, 51546, 420, 436, 393, 312, 2584, 1400, 4936, 11, 293, 550, 3079, 512, 1333, 295, 1412, 14501, 19631, 13, 51827, 51827], "temperature": 0.0, "avg_logprob": -0.21835222497450568, "compression_ratio": 1.6879699248120301, "no_speech_prob": 7.182932677096687e-06}, {"id": 1279, "seek": 513776, "start": 5149.96, "end": 5155.360000000001, "text": " To sort of get into more detail, what these methods do is they extract two completely", "tokens": [50364, 407, 341, 1333, 295, 6422, 264, 5143, 295, 257, 688, 295, 3743, 7150, 11, 411, 5197, 15973, 11, 50676, 50676, 3335, 21141, 11, 3026, 75, 11, 318, 6683, 34, 5797, 13, 50802, 50802, 440, 1558, 307, 1936, 437, 311, 4898, 294, 264, 3256, 13, 50974, 50974, 1407, 1333, 295, 483, 666, 544, 2607, 11, 437, 613, 7150, 360, 307, 436, 8947, 732, 2584, 51244, 51244, 4974, 26531, 490, 364, 3256, 13, 51321, 51321, 407, 613, 26531, 393, 312, 33535, 11, 436, 393, 767, 312, 16212, 1951, 472, 1071, 11, 51546, 51546, 420, 436, 393, 312, 2584, 1400, 4936, 11, 293, 550, 3079, 512, 1333, 295, 1412, 14501, 19631, 13, 51827, 51827], "temperature": 0.0, "avg_logprob": -0.21835222497450568, "compression_ratio": 1.6879699248120301, "no_speech_prob": 7.182932677096687e-06}, {"id": 1280, "seek": 513776, "start": 5155.360000000001, "end": 5156.900000000001, "text": " random patches from an image.", "tokens": [50364, 407, 341, 1333, 295, 6422, 264, 5143, 295, 257, 688, 295, 3743, 7150, 11, 411, 5197, 15973, 11, 50676, 50676, 3335, 21141, 11, 3026, 75, 11, 318, 6683, 34, 5797, 13, 50802, 50802, 440, 1558, 307, 1936, 437, 311, 4898, 294, 264, 3256, 13, 50974, 50974, 1407, 1333, 295, 483, 666, 544, 2607, 11, 437, 613, 7150, 360, 307, 436, 8947, 732, 2584, 51244, 51244, 4974, 26531, 490, 364, 3256, 13, 51321, 51321, 407, 613, 26531, 393, 312, 33535, 11, 436, 393, 767, 312, 16212, 1951, 472, 1071, 11, 51546, 51546, 420, 436, 393, 312, 2584, 1400, 4936, 11, 293, 550, 3079, 512, 1333, 295, 1412, 14501, 19631, 13, 51827, 51827], "temperature": 0.0, "avg_logprob": -0.21835222497450568, "compression_ratio": 1.6879699248120301, "no_speech_prob": 7.182932677096687e-06}, {"id": 1281, "seek": 513776, "start": 5156.900000000001, "end": 5161.400000000001, "text": " So these patches can be overlapping, they can actually be contained within one another,", "tokens": [50364, 407, 341, 1333, 295, 6422, 264, 5143, 295, 257, 688, 295, 3743, 7150, 11, 411, 5197, 15973, 11, 50676, 50676, 3335, 21141, 11, 3026, 75, 11, 318, 6683, 34, 5797, 13, 50802, 50802, 440, 1558, 307, 1936, 437, 311, 4898, 294, 264, 3256, 13, 50974, 50974, 1407, 1333, 295, 483, 666, 544, 2607, 11, 437, 613, 7150, 360, 307, 436, 8947, 732, 2584, 51244, 51244, 4974, 26531, 490, 364, 3256, 13, 51321, 51321, 407, 613, 26531, 393, 312, 33535, 11, 436, 393, 767, 312, 16212, 1951, 472, 1071, 11, 51546, 51546, 420, 436, 393, 312, 2584, 1400, 4936, 11, 293, 550, 3079, 512, 1333, 295, 1412, 14501, 19631, 13, 51827, 51827], "temperature": 0.0, "avg_logprob": -0.21835222497450568, "compression_ratio": 1.6879699248120301, "no_speech_prob": 7.182932677096687e-06}, {"id": 1282, "seek": 513776, "start": 5161.400000000001, "end": 5167.02, "text": " or they can be completely far apart, and then apply some sort of data augmentation.", "tokens": [50364, 407, 341, 1333, 295, 6422, 264, 5143, 295, 257, 688, 295, 3743, 7150, 11, 411, 5197, 15973, 11, 50676, 50676, 3335, 21141, 11, 3026, 75, 11, 318, 6683, 34, 5797, 13, 50802, 50802, 440, 1558, 307, 1936, 437, 311, 4898, 294, 264, 3256, 13, 50974, 50974, 1407, 1333, 295, 483, 666, 544, 2607, 11, 437, 613, 7150, 360, 307, 436, 8947, 732, 2584, 51244, 51244, 4974, 26531, 490, 364, 3256, 13, 51321, 51321, 407, 613, 26531, 393, 312, 33535, 11, 436, 393, 767, 312, 16212, 1951, 472, 1071, 11, 51546, 51546, 420, 436, 393, 312, 2584, 1400, 4936, 11, 293, 550, 3079, 512, 1333, 295, 1412, 14501, 19631, 13, 51827, 51827], "temperature": 0.0, "avg_logprob": -0.21835222497450568, "compression_ratio": 1.6879699248120301, "no_speech_prob": 7.182932677096687e-06}, {"id": 1283, "seek": 516702, "start": 5167.02, "end": 5172.040000000001, "text": " So in this case, say a color jittering or removing the color or so on.", "tokens": [50364, 407, 294, 341, 1389, 11, 584, 257, 2017, 361, 3904, 278, 420, 12720, 264, 2017, 420, 370, 322, 13, 50615, 50615, 400, 550, 291, 6964, 613, 732, 26531, 281, 312, 428, 1333, 295, 3353, 5110, 13, 50841, 50841, 509, 8947, 1071, 9972, 490, 257, 819, 3256, 11, 293, 341, 307, 797, 257, 4974, 9972, 11, 293, 51067, 51067, 300, 1936, 3643, 428, 3671, 13, 51205, 51205, 400, 257, 688, 295, 613, 7150, 486, 8947, 257, 688, 295, 3671, 26531, 11, 293, 550, 436, 486, 51481, 51481, 1936, 2042, 8712, 488, 2539, 13, 51611, 51611, 407, 291, 366, 23968, 281, 3353, 10938, 11, 457, 291, 362, 257, 688, 295, 3671, 10938, 300, 291, 434, 51811, 51811], "temperature": 0.0, "avg_logprob": -0.13022599668584317, "compression_ratio": 1.8631178707224334, "no_speech_prob": 1.0952864613500424e-05}, {"id": 1284, "seek": 516702, "start": 5172.040000000001, "end": 5176.56, "text": " And then you define these two patches to be your sort of positive examples.", "tokens": [50364, 407, 294, 341, 1389, 11, 584, 257, 2017, 361, 3904, 278, 420, 12720, 264, 2017, 420, 370, 322, 13, 50615, 50615, 400, 550, 291, 6964, 613, 732, 26531, 281, 312, 428, 1333, 295, 3353, 5110, 13, 50841, 50841, 509, 8947, 1071, 9972, 490, 257, 819, 3256, 11, 293, 341, 307, 797, 257, 4974, 9972, 11, 293, 51067, 51067, 300, 1936, 3643, 428, 3671, 13, 51205, 51205, 400, 257, 688, 295, 613, 7150, 486, 8947, 257, 688, 295, 3671, 26531, 11, 293, 550, 436, 486, 51481, 51481, 1936, 2042, 8712, 488, 2539, 13, 51611, 51611, 407, 291, 366, 23968, 281, 3353, 10938, 11, 457, 291, 362, 257, 688, 295, 3671, 10938, 300, 291, 434, 51811, 51811], "temperature": 0.0, "avg_logprob": -0.13022599668584317, "compression_ratio": 1.8631178707224334, "no_speech_prob": 1.0952864613500424e-05}, {"id": 1285, "seek": 516702, "start": 5176.56, "end": 5181.080000000001, "text": " You extract another patch from a different image, and this is again a random patch, and", "tokens": [50364, 407, 294, 341, 1389, 11, 584, 257, 2017, 361, 3904, 278, 420, 12720, 264, 2017, 420, 370, 322, 13, 50615, 50615, 400, 550, 291, 6964, 613, 732, 26531, 281, 312, 428, 1333, 295, 3353, 5110, 13, 50841, 50841, 509, 8947, 1071, 9972, 490, 257, 819, 3256, 11, 293, 341, 307, 797, 257, 4974, 9972, 11, 293, 51067, 51067, 300, 1936, 3643, 428, 3671, 13, 51205, 51205, 400, 257, 688, 295, 613, 7150, 486, 8947, 257, 688, 295, 3671, 26531, 11, 293, 550, 436, 486, 51481, 51481, 1936, 2042, 8712, 488, 2539, 13, 51611, 51611, 407, 291, 366, 23968, 281, 3353, 10938, 11, 457, 291, 362, 257, 688, 295, 3671, 10938, 300, 291, 434, 51811, 51811], "temperature": 0.0, "avg_logprob": -0.13022599668584317, "compression_ratio": 1.8631178707224334, "no_speech_prob": 1.0952864613500424e-05}, {"id": 1286, "seek": 516702, "start": 5181.080000000001, "end": 5183.84, "text": " that basically becomes your negative.", "tokens": [50364, 407, 294, 341, 1389, 11, 584, 257, 2017, 361, 3904, 278, 420, 12720, 264, 2017, 420, 370, 322, 13, 50615, 50615, 400, 550, 291, 6964, 613, 732, 26531, 281, 312, 428, 1333, 295, 3353, 5110, 13, 50841, 50841, 509, 8947, 1071, 9972, 490, 257, 819, 3256, 11, 293, 341, 307, 797, 257, 4974, 9972, 11, 293, 51067, 51067, 300, 1936, 3643, 428, 3671, 13, 51205, 51205, 400, 257, 688, 295, 613, 7150, 486, 8947, 257, 688, 295, 3671, 26531, 11, 293, 550, 436, 486, 51481, 51481, 1936, 2042, 8712, 488, 2539, 13, 51611, 51611, 407, 291, 366, 23968, 281, 3353, 10938, 11, 457, 291, 362, 257, 688, 295, 3671, 10938, 300, 291, 434, 51811, 51811], "temperature": 0.0, "avg_logprob": -0.13022599668584317, "compression_ratio": 1.8631178707224334, "no_speech_prob": 1.0952864613500424e-05}, {"id": 1287, "seek": 516702, "start": 5183.84, "end": 5189.360000000001, "text": " And a lot of these methods will extract a lot of negative patches, and then they will", "tokens": [50364, 407, 294, 341, 1389, 11, 584, 257, 2017, 361, 3904, 278, 420, 12720, 264, 2017, 420, 370, 322, 13, 50615, 50615, 400, 550, 291, 6964, 613, 732, 26531, 281, 312, 428, 1333, 295, 3353, 5110, 13, 50841, 50841, 509, 8947, 1071, 9972, 490, 257, 819, 3256, 11, 293, 341, 307, 797, 257, 4974, 9972, 11, 293, 51067, 51067, 300, 1936, 3643, 428, 3671, 13, 51205, 51205, 400, 257, 688, 295, 613, 7150, 486, 8947, 257, 688, 295, 3671, 26531, 11, 293, 550, 436, 486, 51481, 51481, 1936, 2042, 8712, 488, 2539, 13, 51611, 51611, 407, 291, 366, 23968, 281, 3353, 10938, 11, 457, 291, 362, 257, 688, 295, 3671, 10938, 300, 291, 434, 51811, 51811], "temperature": 0.0, "avg_logprob": -0.13022599668584317, "compression_ratio": 1.8631178707224334, "no_speech_prob": 1.0952864613500424e-05}, {"id": 1288, "seek": 516702, "start": 5189.360000000001, "end": 5191.96, "text": " basically perform contrastive learning.", "tokens": [50364, 407, 294, 341, 1389, 11, 584, 257, 2017, 361, 3904, 278, 420, 12720, 264, 2017, 420, 370, 322, 13, 50615, 50615, 400, 550, 291, 6964, 613, 732, 26531, 281, 312, 428, 1333, 295, 3353, 5110, 13, 50841, 50841, 509, 8947, 1071, 9972, 490, 257, 819, 3256, 11, 293, 341, 307, 797, 257, 4974, 9972, 11, 293, 51067, 51067, 300, 1936, 3643, 428, 3671, 13, 51205, 51205, 400, 257, 688, 295, 613, 7150, 486, 8947, 257, 688, 295, 3671, 26531, 11, 293, 550, 436, 486, 51481, 51481, 1936, 2042, 8712, 488, 2539, 13, 51611, 51611, 407, 291, 366, 23968, 281, 3353, 10938, 11, 457, 291, 362, 257, 688, 295, 3671, 10938, 300, 291, 434, 51811, 51811], "temperature": 0.0, "avg_logprob": -0.13022599668584317, "compression_ratio": 1.8631178707224334, "no_speech_prob": 1.0952864613500424e-05}, {"id": 1289, "seek": 516702, "start": 5191.96, "end": 5195.96, "text": " So you are relating to positive samples, but you have a lot of negative samples that you're", "tokens": [50364, 407, 294, 341, 1389, 11, 584, 257, 2017, 361, 3904, 278, 420, 12720, 264, 2017, 420, 370, 322, 13, 50615, 50615, 400, 550, 291, 6964, 613, 732, 26531, 281, 312, 428, 1333, 295, 3353, 5110, 13, 50841, 50841, 509, 8947, 1071, 9972, 490, 257, 819, 3256, 11, 293, 341, 307, 797, 257, 4974, 9972, 11, 293, 51067, 51067, 300, 1936, 3643, 428, 3671, 13, 51205, 51205, 400, 257, 688, 295, 613, 7150, 486, 8947, 257, 688, 295, 3671, 26531, 11, 293, 550, 436, 486, 51481, 51481, 1936, 2042, 8712, 488, 2539, 13, 51611, 51611, 407, 291, 366, 23968, 281, 3353, 10938, 11, 457, 291, 362, 257, 688, 295, 3671, 10938, 300, 291, 434, 51811, 51811], "temperature": 0.0, "avg_logprob": -0.13022599668584317, "compression_ratio": 1.8631178707224334, "no_speech_prob": 1.0952864613500424e-05}, {"id": 1290, "seek": 519596, "start": 5195.96, "end": 5200.64, "text": " contrasting this against.", "tokens": [50364, 8712, 278, 341, 1970, 13, 50598, 50598, 407, 586, 2684, 281, 3026, 75, 257, 707, 857, 11, 718, 311, 1333, 295, 853, 281, 1223, 437, 264, 2135, 2649, 50940, 50940, 295, 659, 25111, 9608, 307, 293, 577, 8712, 488, 2539, 307, 1333, 295, 588, 819, 490, 659, 25111, 9608, 13, 51210, 51210, 407, 264, 472, 551, 286, 1217, 2835, 390, 659, 25111, 9608, 1009, 1778, 466, 257, 2167, 3256, 412, 51442, 51442, 1564, 13, 51492, 51492, 407, 264, 1558, 307, 300, 2212, 364, 3256, 11, 291, 3079, 257, 4088, 281, 300, 3256, 13, 51720, 51720], "temperature": 0.0, "avg_logprob": -0.1197773648291519, "compression_ratio": 1.71875, "no_speech_prob": 4.710846496891463e-06}, {"id": 1291, "seek": 519596, "start": 5200.64, "end": 5207.4800000000005, "text": " So now moving to Perl a little bit, let's sort of try to understand what the main difference", "tokens": [50364, 8712, 278, 341, 1970, 13, 50598, 50598, 407, 586, 2684, 281, 3026, 75, 257, 707, 857, 11, 718, 311, 1333, 295, 853, 281, 1223, 437, 264, 2135, 2649, 50940, 50940, 295, 659, 25111, 9608, 307, 293, 577, 8712, 488, 2539, 307, 1333, 295, 588, 819, 490, 659, 25111, 9608, 13, 51210, 51210, 407, 264, 472, 551, 286, 1217, 2835, 390, 659, 25111, 9608, 1009, 1778, 466, 257, 2167, 3256, 412, 51442, 51442, 1564, 13, 51492, 51492, 407, 264, 1558, 307, 300, 2212, 364, 3256, 11, 291, 3079, 257, 4088, 281, 300, 3256, 13, 51720, 51720], "temperature": 0.0, "avg_logprob": -0.1197773648291519, "compression_ratio": 1.71875, "no_speech_prob": 4.710846496891463e-06}, {"id": 1292, "seek": 519596, "start": 5207.4800000000005, "end": 5212.88, "text": " of pretext tasks is and how contrastive learning is sort of very different from pretext tasks.", "tokens": [50364, 8712, 278, 341, 1970, 13, 50598, 50598, 407, 586, 2684, 281, 3026, 75, 257, 707, 857, 11, 718, 311, 1333, 295, 853, 281, 1223, 437, 264, 2135, 2649, 50940, 50940, 295, 659, 25111, 9608, 307, 293, 577, 8712, 488, 2539, 307, 1333, 295, 588, 819, 490, 659, 25111, 9608, 13, 51210, 51210, 407, 264, 472, 551, 286, 1217, 2835, 390, 659, 25111, 9608, 1009, 1778, 466, 257, 2167, 3256, 412, 51442, 51442, 1564, 13, 51492, 51492, 407, 264, 1558, 307, 300, 2212, 364, 3256, 11, 291, 3079, 257, 4088, 281, 300, 3256, 13, 51720, 51720], "temperature": 0.0, "avg_logprob": -0.1197773648291519, "compression_ratio": 1.71875, "no_speech_prob": 4.710846496891463e-06}, {"id": 1293, "seek": 519596, "start": 5212.88, "end": 5217.52, "text": " So the one thing I already mentioned was pretext tasks always reason about a single image at", "tokens": [50364, 8712, 278, 341, 1970, 13, 50598, 50598, 407, 586, 2684, 281, 3026, 75, 257, 707, 857, 11, 718, 311, 1333, 295, 853, 281, 1223, 437, 264, 2135, 2649, 50940, 50940, 295, 659, 25111, 9608, 307, 293, 577, 8712, 488, 2539, 307, 1333, 295, 588, 819, 490, 659, 25111, 9608, 13, 51210, 51210, 407, 264, 472, 551, 286, 1217, 2835, 390, 659, 25111, 9608, 1009, 1778, 466, 257, 2167, 3256, 412, 51442, 51442, 1564, 13, 51492, 51492, 407, 264, 1558, 307, 300, 2212, 364, 3256, 11, 291, 3079, 257, 4088, 281, 300, 3256, 13, 51720, 51720], "temperature": 0.0, "avg_logprob": -0.1197773648291519, "compression_ratio": 1.71875, "no_speech_prob": 4.710846496891463e-06}, {"id": 1294, "seek": 519596, "start": 5217.52, "end": 5218.52, "text": " once.", "tokens": [50364, 8712, 278, 341, 1970, 13, 50598, 50598, 407, 586, 2684, 281, 3026, 75, 257, 707, 857, 11, 718, 311, 1333, 295, 853, 281, 1223, 437, 264, 2135, 2649, 50940, 50940, 295, 659, 25111, 9608, 307, 293, 577, 8712, 488, 2539, 307, 1333, 295, 588, 819, 490, 659, 25111, 9608, 13, 51210, 51210, 407, 264, 472, 551, 286, 1217, 2835, 390, 659, 25111, 9608, 1009, 1778, 466, 257, 2167, 3256, 412, 51442, 51442, 1564, 13, 51492, 51492, 407, 264, 1558, 307, 300, 2212, 364, 3256, 11, 291, 3079, 257, 4088, 281, 300, 3256, 13, 51720, 51720], "temperature": 0.0, "avg_logprob": -0.1197773648291519, "compression_ratio": 1.71875, "no_speech_prob": 4.710846496891463e-06}, {"id": 1295, "seek": 519596, "start": 5218.52, "end": 5223.08, "text": " So the idea is that given an image, you apply a transform to that image.", "tokens": [50364, 8712, 278, 341, 1970, 13, 50598, 50598, 407, 586, 2684, 281, 3026, 75, 257, 707, 857, 11, 718, 311, 1333, 295, 853, 281, 1223, 437, 264, 2135, 2649, 50940, 50940, 295, 659, 25111, 9608, 307, 293, 577, 8712, 488, 2539, 307, 1333, 295, 588, 819, 490, 659, 25111, 9608, 13, 51210, 51210, 407, 264, 472, 551, 286, 1217, 2835, 390, 659, 25111, 9608, 1009, 1778, 466, 257, 2167, 3256, 412, 51442, 51442, 1564, 13, 51492, 51492, 407, 264, 1558, 307, 300, 2212, 364, 3256, 11, 291, 3079, 257, 4088, 281, 300, 3256, 13, 51720, 51720], "temperature": 0.0, "avg_logprob": -0.1197773648291519, "compression_ratio": 1.71875, "no_speech_prob": 4.710846496891463e-06}, {"id": 1296, "seek": 522308, "start": 5223.08, "end": 5230.76, "text": " So in this case, say a jigsaw transform, and then you basically input this transformed", "tokens": [50364, 407, 294, 341, 1389, 11, 584, 257, 361, 17156, 1607, 4088, 11, 293, 550, 291, 1936, 4846, 341, 16894, 50748, 50748, 3256, 666, 257, 416, 2533, 11, 293, 291, 853, 281, 6069, 264, 4707, 295, 264, 4088, 300, 291, 6456, 13, 50960, 50960, 407, 264, 4784, 11380, 300, 291, 6456, 420, 264, 12447, 300, 291, 6456, 420, 264, 733, 295, 2017, 51208, 51208, 300, 291, 7261, 293, 370, 322, 13, 51316, 51316, 407, 264, 659, 25111, 9608, 1009, 1778, 466, 257, 2167, 3256, 13, 51534, 51534, 400, 264, 1150, 551, 307, 300, 264, 5633, 300, 291, 434, 10205, 294, 341, 1389, 534, 575, 51786, 51786], "temperature": 0.0, "avg_logprob": -0.10882923090569327, "compression_ratio": 1.9004329004329004, "no_speech_prob": 3.844907951133791e-06}, {"id": 1297, "seek": 522308, "start": 5230.76, "end": 5235.0, "text": " image into a con net, and you try to predict the property of the transform that you applied.", "tokens": [50364, 407, 294, 341, 1389, 11, 584, 257, 361, 17156, 1607, 4088, 11, 293, 550, 291, 1936, 4846, 341, 16894, 50748, 50748, 3256, 666, 257, 416, 2533, 11, 293, 291, 853, 281, 6069, 264, 4707, 295, 264, 4088, 300, 291, 6456, 13, 50960, 50960, 407, 264, 4784, 11380, 300, 291, 6456, 420, 264, 12447, 300, 291, 6456, 420, 264, 733, 295, 2017, 51208, 51208, 300, 291, 7261, 293, 370, 322, 13, 51316, 51316, 407, 264, 659, 25111, 9608, 1009, 1778, 466, 257, 2167, 3256, 13, 51534, 51534, 400, 264, 1150, 551, 307, 300, 264, 5633, 300, 291, 434, 10205, 294, 341, 1389, 534, 575, 51786, 51786], "temperature": 0.0, "avg_logprob": -0.10882923090569327, "compression_ratio": 1.9004329004329004, "no_speech_prob": 3.844907951133791e-06}, {"id": 1298, "seek": 522308, "start": 5235.0, "end": 5239.96, "text": " So the permutation that you applied or the rotation that you applied or the kind of color", "tokens": [50364, 407, 294, 341, 1389, 11, 584, 257, 361, 17156, 1607, 4088, 11, 293, 550, 291, 1936, 4846, 341, 16894, 50748, 50748, 3256, 666, 257, 416, 2533, 11, 293, 291, 853, 281, 6069, 264, 4707, 295, 264, 4088, 300, 291, 6456, 13, 50960, 50960, 407, 264, 4784, 11380, 300, 291, 6456, 420, 264, 12447, 300, 291, 6456, 420, 264, 733, 295, 2017, 51208, 51208, 300, 291, 7261, 293, 370, 322, 13, 51316, 51316, 407, 264, 659, 25111, 9608, 1009, 1778, 466, 257, 2167, 3256, 13, 51534, 51534, 400, 264, 1150, 551, 307, 300, 264, 5633, 300, 291, 434, 10205, 294, 341, 1389, 534, 575, 51786, 51786], "temperature": 0.0, "avg_logprob": -0.10882923090569327, "compression_ratio": 1.9004329004329004, "no_speech_prob": 3.844907951133791e-06}, {"id": 1299, "seek": 522308, "start": 5239.96, "end": 5242.12, "text": " that you removed and so on.", "tokens": [50364, 407, 294, 341, 1389, 11, 584, 257, 361, 17156, 1607, 4088, 11, 293, 550, 291, 1936, 4846, 341, 16894, 50748, 50748, 3256, 666, 257, 416, 2533, 11, 293, 291, 853, 281, 6069, 264, 4707, 295, 264, 4088, 300, 291, 6456, 13, 50960, 50960, 407, 264, 4784, 11380, 300, 291, 6456, 420, 264, 12447, 300, 291, 6456, 420, 264, 733, 295, 2017, 51208, 51208, 300, 291, 7261, 293, 370, 322, 13, 51316, 51316, 407, 264, 659, 25111, 9608, 1009, 1778, 466, 257, 2167, 3256, 13, 51534, 51534, 400, 264, 1150, 551, 307, 300, 264, 5633, 300, 291, 434, 10205, 294, 341, 1389, 534, 575, 51786, 51786], "temperature": 0.0, "avg_logprob": -0.10882923090569327, "compression_ratio": 1.9004329004329004, "no_speech_prob": 3.844907951133791e-06}, {"id": 1300, "seek": 522308, "start": 5242.12, "end": 5246.48, "text": " So the pretext tasks always reason about a single image.", "tokens": [50364, 407, 294, 341, 1389, 11, 584, 257, 361, 17156, 1607, 4088, 11, 293, 550, 291, 1936, 4846, 341, 16894, 50748, 50748, 3256, 666, 257, 416, 2533, 11, 293, 291, 853, 281, 6069, 264, 4707, 295, 264, 4088, 300, 291, 6456, 13, 50960, 50960, 407, 264, 4784, 11380, 300, 291, 6456, 420, 264, 12447, 300, 291, 6456, 420, 264, 733, 295, 2017, 51208, 51208, 300, 291, 7261, 293, 370, 322, 13, 51316, 51316, 407, 264, 659, 25111, 9608, 1009, 1778, 466, 257, 2167, 3256, 13, 51534, 51534, 400, 264, 1150, 551, 307, 300, 264, 5633, 300, 291, 434, 10205, 294, 341, 1389, 534, 575, 51786, 51786], "temperature": 0.0, "avg_logprob": -0.10882923090569327, "compression_ratio": 1.9004329004329004, "no_speech_prob": 3.844907951133791e-06}, {"id": 1301, "seek": 522308, "start": 5246.48, "end": 5251.5199999999995, "text": " And the second thing is that the task that you're performing in this case really has", "tokens": [50364, 407, 294, 341, 1389, 11, 584, 257, 361, 17156, 1607, 4088, 11, 293, 550, 291, 1936, 4846, 341, 16894, 50748, 50748, 3256, 666, 257, 416, 2533, 11, 293, 291, 853, 281, 6069, 264, 4707, 295, 264, 4088, 300, 291, 6456, 13, 50960, 50960, 407, 264, 4784, 11380, 300, 291, 6456, 420, 264, 12447, 300, 291, 6456, 420, 264, 733, 295, 2017, 51208, 51208, 300, 291, 7261, 293, 370, 322, 13, 51316, 51316, 407, 264, 659, 25111, 9608, 1009, 1778, 466, 257, 2167, 3256, 13, 51534, 51534, 400, 264, 1150, 551, 307, 300, 264, 5633, 300, 291, 434, 10205, 294, 341, 1389, 534, 575, 51786, 51786], "temperature": 0.0, "avg_logprob": -0.10882923090569327, "compression_ratio": 1.9004329004329004, "no_speech_prob": 3.844907951133791e-06}, {"id": 1302, "seek": 525152, "start": 5251.52, "end": 5254.68, "text": " to capture some property of the transform.", "tokens": [50364, 281, 7983, 512, 4707, 295, 264, 4088, 13, 50522, 50522, 407, 309, 534, 2203, 281, 7983, 264, 1900, 4784, 11380, 300, 291, 6456, 420, 264, 733, 295, 12447, 300, 50764, 50764, 291, 6456, 11, 597, 1355, 300, 264, 1036, 1064, 33358, 366, 767, 516, 281, 10559, 51046, 51046, 420, 1333, 295, 10559, 257, 688, 382, 264, 4088, 2962, 13, 51282, 51282, 400, 300, 307, 538, 1715, 570, 291, 434, 534, 1382, 281, 5039, 300, 659, 25111, 5633, 13, 51548, 51548, 583, 7015, 11, 437, 341, 1355, 307, 300, 264, 1036, 1064, 33358, 7983, 257, 588, 51805, 51805], "temperature": 0.0, "avg_logprob": -0.13346377286044034, "compression_ratio": 1.8888888888888888, "no_speech_prob": 7.296269814105472e-06}, {"id": 1303, "seek": 525152, "start": 5254.68, "end": 5259.52, "text": " So it really needs to capture the exact permutation that you applied or the kind of rotation that", "tokens": [50364, 281, 7983, 512, 4707, 295, 264, 4088, 13, 50522, 50522, 407, 309, 534, 2203, 281, 7983, 264, 1900, 4784, 11380, 300, 291, 6456, 420, 264, 733, 295, 12447, 300, 50764, 50764, 291, 6456, 11, 597, 1355, 300, 264, 1036, 1064, 33358, 366, 767, 516, 281, 10559, 51046, 51046, 420, 1333, 295, 10559, 257, 688, 382, 264, 4088, 2962, 13, 51282, 51282, 400, 300, 307, 538, 1715, 570, 291, 434, 534, 1382, 281, 5039, 300, 659, 25111, 5633, 13, 51548, 51548, 583, 7015, 11, 437, 341, 1355, 307, 300, 264, 1036, 1064, 33358, 7983, 257, 588, 51805, 51805], "temperature": 0.0, "avg_logprob": -0.13346377286044034, "compression_ratio": 1.8888888888888888, "no_speech_prob": 7.296269814105472e-06}, {"id": 1304, "seek": 525152, "start": 5259.52, "end": 5265.160000000001, "text": " you applied, which means that the last year representations are actually going to vary", "tokens": [50364, 281, 7983, 512, 4707, 295, 264, 4088, 13, 50522, 50522, 407, 309, 534, 2203, 281, 7983, 264, 1900, 4784, 11380, 300, 291, 6456, 420, 264, 733, 295, 12447, 300, 50764, 50764, 291, 6456, 11, 597, 1355, 300, 264, 1036, 1064, 33358, 366, 767, 516, 281, 10559, 51046, 51046, 420, 1333, 295, 10559, 257, 688, 382, 264, 4088, 2962, 13, 51282, 51282, 400, 300, 307, 538, 1715, 570, 291, 434, 534, 1382, 281, 5039, 300, 659, 25111, 5633, 13, 51548, 51548, 583, 7015, 11, 437, 341, 1355, 307, 300, 264, 1036, 1064, 33358, 7983, 257, 588, 51805, 51805], "temperature": 0.0, "avg_logprob": -0.13346377286044034, "compression_ratio": 1.8888888888888888, "no_speech_prob": 7.296269814105472e-06}, {"id": 1305, "seek": 525152, "start": 5265.160000000001, "end": 5269.88, "text": " or sort of vary a lot as the transform changes.", "tokens": [50364, 281, 7983, 512, 4707, 295, 264, 4088, 13, 50522, 50522, 407, 309, 534, 2203, 281, 7983, 264, 1900, 4784, 11380, 300, 291, 6456, 420, 264, 733, 295, 12447, 300, 50764, 50764, 291, 6456, 11, 597, 1355, 300, 264, 1036, 1064, 33358, 366, 767, 516, 281, 10559, 51046, 51046, 420, 1333, 295, 10559, 257, 688, 382, 264, 4088, 2962, 13, 51282, 51282, 400, 300, 307, 538, 1715, 570, 291, 434, 534, 1382, 281, 5039, 300, 659, 25111, 5633, 13, 51548, 51548, 583, 7015, 11, 437, 341, 1355, 307, 300, 264, 1036, 1064, 33358, 7983, 257, 588, 51805, 51805], "temperature": 0.0, "avg_logprob": -0.13346377286044034, "compression_ratio": 1.8888888888888888, "no_speech_prob": 7.296269814105472e-06}, {"id": 1306, "seek": 525152, "start": 5269.88, "end": 5275.200000000001, "text": " And that is by design because you're really trying to solve that pretext task.", "tokens": [50364, 281, 7983, 512, 4707, 295, 264, 4088, 13, 50522, 50522, 407, 309, 534, 2203, 281, 7983, 264, 1900, 4784, 11380, 300, 291, 6456, 420, 264, 733, 295, 12447, 300, 50764, 50764, 291, 6456, 11, 597, 1355, 300, 264, 1036, 1064, 33358, 366, 767, 516, 281, 10559, 51046, 51046, 420, 1333, 295, 10559, 257, 688, 382, 264, 4088, 2962, 13, 51282, 51282, 400, 300, 307, 538, 1715, 570, 291, 434, 534, 1382, 281, 5039, 300, 659, 25111, 5633, 13, 51548, 51548, 583, 7015, 11, 437, 341, 1355, 307, 300, 264, 1036, 1064, 33358, 7983, 257, 588, 51805, 51805], "temperature": 0.0, "avg_logprob": -0.13346377286044034, "compression_ratio": 1.8888888888888888, "no_speech_prob": 7.296269814105472e-06}, {"id": 1307, "seek": 525152, "start": 5275.200000000001, "end": 5280.34, "text": " But unfortunately, what this means is that the last year representations capture a very", "tokens": [50364, 281, 7983, 512, 4707, 295, 264, 4088, 13, 50522, 50522, 407, 309, 534, 2203, 281, 7983, 264, 1900, 4784, 11380, 300, 291, 6456, 420, 264, 733, 295, 12447, 300, 50764, 50764, 291, 6456, 11, 597, 1355, 300, 264, 1036, 1064, 33358, 366, 767, 516, 281, 10559, 51046, 51046, 420, 1333, 295, 10559, 257, 688, 382, 264, 4088, 2962, 13, 51282, 51282, 400, 300, 307, 538, 1715, 570, 291, 434, 534, 1382, 281, 5039, 300, 659, 25111, 5633, 13, 51548, 51548, 583, 7015, 11, 437, 341, 1355, 307, 300, 264, 1036, 1064, 33358, 7983, 257, 588, 51805, 51805], "temperature": 0.0, "avg_logprob": -0.13346377286044034, "compression_ratio": 1.8888888888888888, "no_speech_prob": 7.296269814105472e-06}, {"id": 1308, "seek": 528034, "start": 5280.34, "end": 5282.04, "text": " low level property of the signal.", "tokens": [50364, 2295, 1496, 4707, 295, 264, 6358, 13, 50449, 50449, 407, 436, 7983, 721, 411, 12447, 420, 370, 322, 13, 50621, 50621, 13813, 437, 307, 1333, 295, 4761, 420, 437, 307, 5176, 295, 613, 33358, 307, 300, 50909, 50909, 436, 366, 1333, 295, 33270, 394, 281, 613, 721, 13, 51017, 51017, 509, 820, 312, 1075, 281, 5521, 257, 3857, 572, 1871, 1968, 264, 3857, 307, 27405, 420, 1968, 264, 51197, 51197, 3857, 307, 14075, 3030, 538, 4289, 5310, 13, 51349, 51349, 13813, 562, 291, 434, 12606, 300, 1729, 659, 25111, 5633, 11, 291, 434, 40288, 264, 1900, 6182, 51575, 51575, 551, 13, 51625, 51625, 509, 434, 1566, 300, 286, 820, 312, 1075, 281, 5521, 1968, 341, 3036, 307, 27405, 420, 1968, 51773, 51773], "temperature": 0.0, "avg_logprob": -0.17154229071832472, "compression_ratio": 1.9304029304029304, "no_speech_prob": 5.594259164354298e-06}, {"id": 1309, "seek": 528034, "start": 5282.04, "end": 5285.4800000000005, "text": " So they capture things like rotation or so on.", "tokens": [50364, 2295, 1496, 4707, 295, 264, 6358, 13, 50449, 50449, 407, 436, 7983, 721, 411, 12447, 420, 370, 322, 13, 50621, 50621, 13813, 437, 307, 1333, 295, 4761, 420, 437, 307, 5176, 295, 613, 33358, 307, 300, 50909, 50909, 436, 366, 1333, 295, 33270, 394, 281, 613, 721, 13, 51017, 51017, 509, 820, 312, 1075, 281, 5521, 257, 3857, 572, 1871, 1968, 264, 3857, 307, 27405, 420, 1968, 264, 51197, 51197, 3857, 307, 14075, 3030, 538, 4289, 5310, 13, 51349, 51349, 13813, 562, 291, 434, 12606, 300, 1729, 659, 25111, 5633, 11, 291, 434, 40288, 264, 1900, 6182, 51575, 51575, 551, 13, 51625, 51625, 509, 434, 1566, 300, 286, 820, 312, 1075, 281, 5521, 1968, 341, 3036, 307, 27405, 420, 1968, 51773, 51773], "temperature": 0.0, "avg_logprob": -0.17154229071832472, "compression_ratio": 1.9304029304029304, "no_speech_prob": 5.594259164354298e-06}, {"id": 1310, "seek": 528034, "start": 5285.4800000000005, "end": 5291.24, "text": " Whereas what is sort of designed or what is expected of these representations is that", "tokens": [50364, 2295, 1496, 4707, 295, 264, 6358, 13, 50449, 50449, 407, 436, 7983, 721, 411, 12447, 420, 370, 322, 13, 50621, 50621, 13813, 437, 307, 1333, 295, 4761, 420, 437, 307, 5176, 295, 613, 33358, 307, 300, 50909, 50909, 436, 366, 1333, 295, 33270, 394, 281, 613, 721, 13, 51017, 51017, 509, 820, 312, 1075, 281, 5521, 257, 3857, 572, 1871, 1968, 264, 3857, 307, 27405, 420, 1968, 264, 51197, 51197, 3857, 307, 14075, 3030, 538, 4289, 5310, 13, 51349, 51349, 13813, 562, 291, 434, 12606, 300, 1729, 659, 25111, 5633, 11, 291, 434, 40288, 264, 1900, 6182, 51575, 51575, 551, 13, 51625, 51625, 509, 434, 1566, 300, 286, 820, 312, 1075, 281, 5521, 1968, 341, 3036, 307, 27405, 420, 1968, 51773, 51773], "temperature": 0.0, "avg_logprob": -0.17154229071832472, "compression_ratio": 1.9304029304029304, "no_speech_prob": 5.594259164354298e-06}, {"id": 1311, "seek": 528034, "start": 5291.24, "end": 5293.400000000001, "text": " they are sort of invariant to these things.", "tokens": [50364, 2295, 1496, 4707, 295, 264, 6358, 13, 50449, 50449, 407, 436, 7983, 721, 411, 12447, 420, 370, 322, 13, 50621, 50621, 13813, 437, 307, 1333, 295, 4761, 420, 437, 307, 5176, 295, 613, 33358, 307, 300, 50909, 50909, 436, 366, 1333, 295, 33270, 394, 281, 613, 721, 13, 51017, 51017, 509, 820, 312, 1075, 281, 5521, 257, 3857, 572, 1871, 1968, 264, 3857, 307, 27405, 420, 1968, 264, 51197, 51197, 3857, 307, 14075, 3030, 538, 4289, 5310, 13, 51349, 51349, 13813, 562, 291, 434, 12606, 300, 1729, 659, 25111, 5633, 11, 291, 434, 40288, 264, 1900, 6182, 51575, 51575, 551, 13, 51625, 51625, 509, 434, 1566, 300, 286, 820, 312, 1075, 281, 5521, 1968, 341, 3036, 307, 27405, 420, 1968, 51773, 51773], "temperature": 0.0, "avg_logprob": -0.17154229071832472, "compression_ratio": 1.9304029304029304, "no_speech_prob": 5.594259164354298e-06}, {"id": 1312, "seek": 528034, "start": 5293.400000000001, "end": 5297.0, "text": " You should be able to recognize a cat no matter whether the cat is upright or whether the", "tokens": [50364, 2295, 1496, 4707, 295, 264, 6358, 13, 50449, 50449, 407, 436, 7983, 721, 411, 12447, 420, 370, 322, 13, 50621, 50621, 13813, 437, 307, 1333, 295, 4761, 420, 437, 307, 5176, 295, 613, 33358, 307, 300, 50909, 50909, 436, 366, 1333, 295, 33270, 394, 281, 613, 721, 13, 51017, 51017, 509, 820, 312, 1075, 281, 5521, 257, 3857, 572, 1871, 1968, 264, 3857, 307, 27405, 420, 1968, 264, 51197, 51197, 3857, 307, 14075, 3030, 538, 4289, 5310, 13, 51349, 51349, 13813, 562, 291, 434, 12606, 300, 1729, 659, 25111, 5633, 11, 291, 434, 40288, 264, 1900, 6182, 51575, 51575, 551, 13, 51625, 51625, 509, 434, 1566, 300, 286, 820, 312, 1075, 281, 5521, 1968, 341, 3036, 307, 27405, 420, 1968, 51773, 51773], "temperature": 0.0, "avg_logprob": -0.17154229071832472, "compression_ratio": 1.9304029304029304, "no_speech_prob": 5.594259164354298e-06}, {"id": 1313, "seek": 528034, "start": 5297.0, "end": 5300.04, "text": " cat is bent towards by 90 degrees.", "tokens": [50364, 2295, 1496, 4707, 295, 264, 6358, 13, 50449, 50449, 407, 436, 7983, 721, 411, 12447, 420, 370, 322, 13, 50621, 50621, 13813, 437, 307, 1333, 295, 4761, 420, 437, 307, 5176, 295, 613, 33358, 307, 300, 50909, 50909, 436, 366, 1333, 295, 33270, 394, 281, 613, 721, 13, 51017, 51017, 509, 820, 312, 1075, 281, 5521, 257, 3857, 572, 1871, 1968, 264, 3857, 307, 27405, 420, 1968, 264, 51197, 51197, 3857, 307, 14075, 3030, 538, 4289, 5310, 13, 51349, 51349, 13813, 562, 291, 434, 12606, 300, 1729, 659, 25111, 5633, 11, 291, 434, 40288, 264, 1900, 6182, 51575, 51575, 551, 13, 51625, 51625, 509, 434, 1566, 300, 286, 820, 312, 1075, 281, 5521, 1968, 341, 3036, 307, 27405, 420, 1968, 51773, 51773], "temperature": 0.0, "avg_logprob": -0.17154229071832472, "compression_ratio": 1.9304029304029304, "no_speech_prob": 5.594259164354298e-06}, {"id": 1314, "seek": 528034, "start": 5300.04, "end": 5304.56, "text": " Whereas when you're solving that particular pretext task, you're imposing the exact opposite", "tokens": [50364, 2295, 1496, 4707, 295, 264, 6358, 13, 50449, 50449, 407, 436, 7983, 721, 411, 12447, 420, 370, 322, 13, 50621, 50621, 13813, 437, 307, 1333, 295, 4761, 420, 437, 307, 5176, 295, 613, 33358, 307, 300, 50909, 50909, 436, 366, 1333, 295, 33270, 394, 281, 613, 721, 13, 51017, 51017, 509, 820, 312, 1075, 281, 5521, 257, 3857, 572, 1871, 1968, 264, 3857, 307, 27405, 420, 1968, 264, 51197, 51197, 3857, 307, 14075, 3030, 538, 4289, 5310, 13, 51349, 51349, 13813, 562, 291, 434, 12606, 300, 1729, 659, 25111, 5633, 11, 291, 434, 40288, 264, 1900, 6182, 51575, 51575, 551, 13, 51625, 51625, 509, 434, 1566, 300, 286, 820, 312, 1075, 281, 5521, 1968, 341, 3036, 307, 27405, 420, 1968, 51773, 51773], "temperature": 0.0, "avg_logprob": -0.17154229071832472, "compression_ratio": 1.9304029304029304, "no_speech_prob": 5.594259164354298e-06}, {"id": 1315, "seek": 528034, "start": 5304.56, "end": 5305.56, "text": " thing.", "tokens": [50364, 2295, 1496, 4707, 295, 264, 6358, 13, 50449, 50449, 407, 436, 7983, 721, 411, 12447, 420, 370, 322, 13, 50621, 50621, 13813, 437, 307, 1333, 295, 4761, 420, 437, 307, 5176, 295, 613, 33358, 307, 300, 50909, 50909, 436, 366, 1333, 295, 33270, 394, 281, 613, 721, 13, 51017, 51017, 509, 820, 312, 1075, 281, 5521, 257, 3857, 572, 1871, 1968, 264, 3857, 307, 27405, 420, 1968, 264, 51197, 51197, 3857, 307, 14075, 3030, 538, 4289, 5310, 13, 51349, 51349, 13813, 562, 291, 434, 12606, 300, 1729, 659, 25111, 5633, 11, 291, 434, 40288, 264, 1900, 6182, 51575, 51575, 551, 13, 51625, 51625, 509, 434, 1566, 300, 286, 820, 312, 1075, 281, 5521, 1968, 341, 3036, 307, 27405, 420, 1968, 51773, 51773], "temperature": 0.0, "avg_logprob": -0.17154229071832472, "compression_ratio": 1.9304029304029304, "no_speech_prob": 5.594259164354298e-06}, {"id": 1316, "seek": 528034, "start": 5305.56, "end": 5308.52, "text": " You're saying that I should be able to recognize whether this picture is upright or whether", "tokens": [50364, 2295, 1496, 4707, 295, 264, 6358, 13, 50449, 50449, 407, 436, 7983, 721, 411, 12447, 420, 370, 322, 13, 50621, 50621, 13813, 437, 307, 1333, 295, 4761, 420, 437, 307, 5176, 295, 613, 33358, 307, 300, 50909, 50909, 436, 366, 1333, 295, 33270, 394, 281, 613, 721, 13, 51017, 51017, 509, 820, 312, 1075, 281, 5521, 257, 3857, 572, 1871, 1968, 264, 3857, 307, 27405, 420, 1968, 264, 51197, 51197, 3857, 307, 14075, 3030, 538, 4289, 5310, 13, 51349, 51349, 13813, 562, 291, 434, 12606, 300, 1729, 659, 25111, 5633, 11, 291, 434, 40288, 264, 1900, 6182, 51575, 51575, 551, 13, 51625, 51625, 509, 434, 1566, 300, 286, 820, 312, 1075, 281, 5521, 1968, 341, 3036, 307, 27405, 420, 1968, 51773, 51773], "temperature": 0.0, "avg_logprob": -0.17154229071832472, "compression_ratio": 1.9304029304029304, "no_speech_prob": 5.594259164354298e-06}, {"id": 1317, "seek": 530852, "start": 5308.52, "end": 5314.320000000001, "text": " this picture is basically tilted sideways.", "tokens": [50364, 341, 3036, 307, 1936, 43229, 26092, 13, 50654, 50654, 407, 456, 366, 867, 22847, 294, 597, 291, 534, 528, 613, 2295, 1496, 33358, 50890, 50890, 281, 312, 49851, 394, 13, 51034, 51034, 400, 257, 688, 295, 309, 534, 575, 281, 360, 322, 264, 5633, 300, 291, 434, 10205, 13, 51216, 51216, 400, 1596, 257, 1326, 9608, 294, 805, 35, 534, 528, 281, 312, 35521, 13, 51422, 51422, 407, 291, 528, 281, 1333, 295, 6069, 437, 2799, 35592, 291, 362, 562, 291, 434, 1237, 412, 51652, 51652, 732, 6809, 295, 264, 912, 2657, 420, 370, 322, 13, 51760, 51760], "temperature": 0.0, "avg_logprob": -0.10825530052185059, "compression_ratio": 1.6751054852320675, "no_speech_prob": 4.029381670989096e-06}, {"id": 1318, "seek": 530852, "start": 5314.320000000001, "end": 5319.040000000001, "text": " So there are many exceptions in which you really want these low level representations", "tokens": [50364, 341, 3036, 307, 1936, 43229, 26092, 13, 50654, 50654, 407, 456, 366, 867, 22847, 294, 597, 291, 534, 528, 613, 2295, 1496, 33358, 50890, 50890, 281, 312, 49851, 394, 13, 51034, 51034, 400, 257, 688, 295, 309, 534, 575, 281, 360, 322, 264, 5633, 300, 291, 434, 10205, 13, 51216, 51216, 400, 1596, 257, 1326, 9608, 294, 805, 35, 534, 528, 281, 312, 35521, 13, 51422, 51422, 407, 291, 528, 281, 1333, 295, 6069, 437, 2799, 35592, 291, 362, 562, 291, 434, 1237, 412, 51652, 51652, 732, 6809, 295, 264, 912, 2657, 420, 370, 322, 13, 51760, 51760], "temperature": 0.0, "avg_logprob": -0.10825530052185059, "compression_ratio": 1.6751054852320675, "no_speech_prob": 4.029381670989096e-06}, {"id": 1319, "seek": 530852, "start": 5319.040000000001, "end": 5321.92, "text": " to be covariant.", "tokens": [50364, 341, 3036, 307, 1936, 43229, 26092, 13, 50654, 50654, 407, 456, 366, 867, 22847, 294, 597, 291, 534, 528, 613, 2295, 1496, 33358, 50890, 50890, 281, 312, 49851, 394, 13, 51034, 51034, 400, 257, 688, 295, 309, 534, 575, 281, 360, 322, 264, 5633, 300, 291, 434, 10205, 13, 51216, 51216, 400, 1596, 257, 1326, 9608, 294, 805, 35, 534, 528, 281, 312, 35521, 13, 51422, 51422, 407, 291, 528, 281, 1333, 295, 6069, 437, 2799, 35592, 291, 362, 562, 291, 434, 1237, 412, 51652, 51652, 732, 6809, 295, 264, 912, 2657, 420, 370, 322, 13, 51760, 51760], "temperature": 0.0, "avg_logprob": -0.10825530052185059, "compression_ratio": 1.6751054852320675, "no_speech_prob": 4.029381670989096e-06}, {"id": 1320, "seek": 530852, "start": 5321.92, "end": 5325.56, "text": " And a lot of it really has to do on the task that you're performing.", "tokens": [50364, 341, 3036, 307, 1936, 43229, 26092, 13, 50654, 50654, 407, 456, 366, 867, 22847, 294, 597, 291, 534, 528, 613, 2295, 1496, 33358, 50890, 50890, 281, 312, 49851, 394, 13, 51034, 51034, 400, 257, 688, 295, 309, 534, 575, 281, 360, 322, 264, 5633, 300, 291, 434, 10205, 13, 51216, 51216, 400, 1596, 257, 1326, 9608, 294, 805, 35, 534, 528, 281, 312, 35521, 13, 51422, 51422, 407, 291, 528, 281, 1333, 295, 6069, 437, 2799, 35592, 291, 362, 562, 291, 434, 1237, 412, 51652, 51652, 732, 6809, 295, 264, 912, 2657, 420, 370, 322, 13, 51760, 51760], "temperature": 0.0, "avg_logprob": -0.10825530052185059, "compression_ratio": 1.6751054852320675, "no_speech_prob": 4.029381670989096e-06}, {"id": 1321, "seek": 530852, "start": 5325.56, "end": 5329.68, "text": " And quite a few tasks in 3D really want to be predictive.", "tokens": [50364, 341, 3036, 307, 1936, 43229, 26092, 13, 50654, 50654, 407, 456, 366, 867, 22847, 294, 597, 291, 534, 528, 613, 2295, 1496, 33358, 50890, 50890, 281, 312, 49851, 394, 13, 51034, 51034, 400, 257, 688, 295, 309, 534, 575, 281, 360, 322, 264, 5633, 300, 291, 434, 10205, 13, 51216, 51216, 400, 1596, 257, 1326, 9608, 294, 805, 35, 534, 528, 281, 312, 35521, 13, 51422, 51422, 407, 291, 528, 281, 1333, 295, 6069, 437, 2799, 35592, 291, 362, 562, 291, 434, 1237, 412, 51652, 51652, 732, 6809, 295, 264, 912, 2657, 420, 370, 322, 13, 51760, 51760], "temperature": 0.0, "avg_logprob": -0.10825530052185059, "compression_ratio": 1.6751054852320675, "no_speech_prob": 4.029381670989096e-06}, {"id": 1322, "seek": 530852, "start": 5329.68, "end": 5334.280000000001, "text": " So you want to sort of predict what camera transforms you have when you're looking at", "tokens": [50364, 341, 3036, 307, 1936, 43229, 26092, 13, 50654, 50654, 407, 456, 366, 867, 22847, 294, 597, 291, 534, 528, 613, 2295, 1496, 33358, 50890, 50890, 281, 312, 49851, 394, 13, 51034, 51034, 400, 257, 688, 295, 309, 534, 575, 281, 360, 322, 264, 5633, 300, 291, 434, 10205, 13, 51216, 51216, 400, 1596, 257, 1326, 9608, 294, 805, 35, 534, 528, 281, 312, 35521, 13, 51422, 51422, 407, 291, 528, 281, 1333, 295, 6069, 437, 2799, 35592, 291, 362, 562, 291, 434, 1237, 412, 51652, 51652, 732, 6809, 295, 264, 912, 2657, 420, 370, 322, 13, 51760, 51760], "temperature": 0.0, "avg_logprob": -0.10825530052185059, "compression_ratio": 1.6751054852320675, "no_speech_prob": 4.029381670989096e-06}, {"id": 1323, "seek": 530852, "start": 5334.280000000001, "end": 5336.4400000000005, "text": " two views of the same object or so on.", "tokens": [50364, 341, 3036, 307, 1936, 43229, 26092, 13, 50654, 50654, 407, 456, 366, 867, 22847, 294, 597, 291, 534, 528, 613, 2295, 1496, 33358, 50890, 50890, 281, 312, 49851, 394, 13, 51034, 51034, 400, 257, 688, 295, 309, 534, 575, 281, 360, 322, 264, 5633, 300, 291, 434, 10205, 13, 51216, 51216, 400, 1596, 257, 1326, 9608, 294, 805, 35, 534, 528, 281, 312, 35521, 13, 51422, 51422, 407, 291, 528, 281, 1333, 295, 6069, 437, 2799, 35592, 291, 362, 562, 291, 434, 1237, 412, 51652, 51652, 732, 6809, 295, 264, 912, 2657, 420, 370, 322, 13, 51760, 51760], "temperature": 0.0, "avg_logprob": -0.10825530052185059, "compression_ratio": 1.6751054852320675, "no_speech_prob": 4.029381670989096e-06}, {"id": 1324, "seek": 533644, "start": 5336.44, "end": 5341.16, "text": " But unless you have that kind of a specific application for a lot of semantic tasks, you", "tokens": [50364, 583, 5969, 291, 362, 300, 733, 295, 257, 2685, 3861, 337, 257, 688, 295, 47982, 9608, 11, 291, 50600, 50600, 534, 528, 281, 312, 33270, 394, 281, 264, 4088, 300, 366, 1143, 382, 4846, 13, 50914, 50914, 407, 33270, 1719, 362, 1333, 295, 668, 264, 589, 45079, 337, 4111, 2539, 13, 51168, 51168, 407, 746, 411, 318, 12775, 11, 597, 307, 257, 6457, 3743, 1011, 5611, 292, 4111, 11, 264, 286, 294, 318, 12775, 534, 7382, 51540, 51540, 337, 33270, 394, 13, 51643, 51643, 400, 46533, 9590, 11, 337, 1365, 11, 46533, 5202, 36170, 420, 46533, 5015, 426, 1385, 11, 436, 434, 51854, 51854], "temperature": 0.0, "avg_logprob": -0.1745218240989829, "compression_ratio": 1.6784313725490196, "no_speech_prob": 9.97264123725472e-06}, {"id": 1325, "seek": 533644, "start": 5341.16, "end": 5347.44, "text": " really want to be invariant to the transform that are used as input.", "tokens": [50364, 583, 5969, 291, 362, 300, 733, 295, 257, 2685, 3861, 337, 257, 688, 295, 47982, 9608, 11, 291, 50600, 50600, 534, 528, 281, 312, 33270, 394, 281, 264, 4088, 300, 366, 1143, 382, 4846, 13, 50914, 50914, 407, 33270, 1719, 362, 1333, 295, 668, 264, 589, 45079, 337, 4111, 2539, 13, 51168, 51168, 407, 746, 411, 318, 12775, 11, 597, 307, 257, 6457, 3743, 1011, 5611, 292, 4111, 11, 264, 286, 294, 318, 12775, 534, 7382, 51540, 51540, 337, 33270, 394, 13, 51643, 51643, 400, 46533, 9590, 11, 337, 1365, 11, 46533, 5202, 36170, 420, 46533, 5015, 426, 1385, 11, 436, 434, 51854, 51854], "temperature": 0.0, "avg_logprob": -0.1745218240989829, "compression_ratio": 1.6784313725490196, "no_speech_prob": 9.97264123725472e-06}, {"id": 1326, "seek": 533644, "start": 5347.44, "end": 5352.5199999999995, "text": " So invariants have sort of been the workhorse for feature learning.", "tokens": [50364, 583, 5969, 291, 362, 300, 733, 295, 257, 2685, 3861, 337, 257, 688, 295, 47982, 9608, 11, 291, 50600, 50600, 534, 528, 281, 312, 33270, 394, 281, 264, 4088, 300, 366, 1143, 382, 4846, 13, 50914, 50914, 407, 33270, 1719, 362, 1333, 295, 668, 264, 589, 45079, 337, 4111, 2539, 13, 51168, 51168, 407, 746, 411, 318, 12775, 11, 597, 307, 257, 6457, 3743, 1011, 5611, 292, 4111, 11, 264, 286, 294, 318, 12775, 534, 7382, 51540, 51540, 337, 33270, 394, 13, 51643, 51643, 400, 46533, 9590, 11, 337, 1365, 11, 46533, 5202, 36170, 420, 46533, 5015, 426, 1385, 11, 436, 434, 51854, 51854], "temperature": 0.0, "avg_logprob": -0.1745218240989829, "compression_ratio": 1.6784313725490196, "no_speech_prob": 9.97264123725472e-06}, {"id": 1327, "seek": 533644, "start": 5352.5199999999995, "end": 5359.96, "text": " So something like SIF, which is a fairly popular handcrafted feature, the I in SIF really stands", "tokens": [50364, 583, 5969, 291, 362, 300, 733, 295, 257, 2685, 3861, 337, 257, 688, 295, 47982, 9608, 11, 291, 50600, 50600, 534, 528, 281, 312, 33270, 394, 281, 264, 4088, 300, 366, 1143, 382, 4846, 13, 50914, 50914, 407, 33270, 1719, 362, 1333, 295, 668, 264, 589, 45079, 337, 4111, 2539, 13, 51168, 51168, 407, 746, 411, 318, 12775, 11, 597, 307, 257, 6457, 3743, 1011, 5611, 292, 4111, 11, 264, 286, 294, 318, 12775, 534, 7382, 51540, 51540, 337, 33270, 394, 13, 51643, 51643, 400, 46533, 9590, 11, 337, 1365, 11, 46533, 5202, 36170, 420, 46533, 5015, 426, 1385, 11, 436, 434, 51854, 51854], "temperature": 0.0, "avg_logprob": -0.1745218240989829, "compression_ratio": 1.6784313725490196, "no_speech_prob": 9.97264123725472e-06}, {"id": 1328, "seek": 533644, "start": 5359.96, "end": 5362.0199999999995, "text": " for invariant.", "tokens": [50364, 583, 5969, 291, 362, 300, 733, 295, 257, 2685, 3861, 337, 257, 688, 295, 47982, 9608, 11, 291, 50600, 50600, 534, 528, 281, 312, 33270, 394, 281, 264, 4088, 300, 366, 1143, 382, 4846, 13, 50914, 50914, 407, 33270, 1719, 362, 1333, 295, 668, 264, 589, 45079, 337, 4111, 2539, 13, 51168, 51168, 407, 746, 411, 318, 12775, 11, 597, 307, 257, 6457, 3743, 1011, 5611, 292, 4111, 11, 264, 286, 294, 318, 12775, 534, 7382, 51540, 51540, 337, 33270, 394, 13, 51643, 51643, 400, 46533, 9590, 11, 337, 1365, 11, 46533, 5202, 36170, 420, 46533, 5015, 426, 1385, 11, 436, 434, 51854, 51854], "temperature": 0.0, "avg_logprob": -0.1745218240989829, "compression_ratio": 1.6784313725490196, "no_speech_prob": 9.97264123725472e-06}, {"id": 1329, "seek": 533644, "start": 5362.0199999999995, "end": 5366.24, "text": " And supervised networks, for example, supervised Alex nets or supervised Res Nets, they're", "tokens": [50364, 583, 5969, 291, 362, 300, 733, 295, 257, 2685, 3861, 337, 257, 688, 295, 47982, 9608, 11, 291, 50600, 50600, 534, 528, 281, 312, 33270, 394, 281, 264, 4088, 300, 366, 1143, 382, 4846, 13, 50914, 50914, 407, 33270, 1719, 362, 1333, 295, 668, 264, 589, 45079, 337, 4111, 2539, 13, 51168, 51168, 407, 746, 411, 318, 12775, 11, 597, 307, 257, 6457, 3743, 1011, 5611, 292, 4111, 11, 264, 286, 294, 318, 12775, 534, 7382, 51540, 51540, 337, 33270, 394, 13, 51643, 51643, 400, 46533, 9590, 11, 337, 1365, 11, 46533, 5202, 36170, 420, 46533, 5015, 426, 1385, 11, 436, 434, 51854, 51854], "temperature": 0.0, "avg_logprob": -0.1745218240989829, "compression_ratio": 1.6784313725490196, "no_speech_prob": 9.97264123725472e-06}, {"id": 1330, "seek": 536624, "start": 5366.24, "end": 5368.639999999999, "text": " trained to be invariant data augmentation.", "tokens": [50364, 8895, 281, 312, 33270, 394, 1412, 14501, 19631, 13, 50484, 50484, 509, 528, 341, 3209, 281, 33872, 819, 16829, 420, 819, 44796, 295, 341, 3256, 50756, 50756, 382, 257, 4230, 11, 2831, 813, 1029, 309, 281, 6069, 437, 2293, 390, 264, 9887, 6456, 281, 51016, 51016, 264, 4846, 13, 51110, 51110, 407, 341, 307, 437, 7547, 3026, 75, 13, 51250, 51250, 407, 3026, 75, 7382, 337, 659, 25111, 33270, 394, 10290, 2539, 11, 689, 264, 1558, 307, 300, 291, 528, 51524, 51524, 264, 10290, 281, 312, 33270, 394, 420, 7983, 382, 707, 1589, 382, 1944, 295, 264, 4846, 51826, 51826], "temperature": 0.0, "avg_logprob": -0.1295304391898361, "compression_ratio": 1.8583333333333334, "no_speech_prob": 1.3006404515181202e-05}, {"id": 1331, "seek": 536624, "start": 5368.639999999999, "end": 5374.08, "text": " You want this network to classify different crops or different rotations of this image", "tokens": [50364, 8895, 281, 312, 33270, 394, 1412, 14501, 19631, 13, 50484, 50484, 509, 528, 341, 3209, 281, 33872, 819, 16829, 420, 819, 44796, 295, 341, 3256, 50756, 50756, 382, 257, 4230, 11, 2831, 813, 1029, 309, 281, 6069, 437, 2293, 390, 264, 9887, 6456, 281, 51016, 51016, 264, 4846, 13, 51110, 51110, 407, 341, 307, 437, 7547, 3026, 75, 13, 51250, 51250, 407, 3026, 75, 7382, 337, 659, 25111, 33270, 394, 10290, 2539, 11, 689, 264, 1558, 307, 300, 291, 528, 51524, 51524, 264, 10290, 281, 312, 33270, 394, 420, 7983, 382, 707, 1589, 382, 1944, 295, 264, 4846, 51826, 51826], "temperature": 0.0, "avg_logprob": -0.1295304391898361, "compression_ratio": 1.8583333333333334, "no_speech_prob": 1.3006404515181202e-05}, {"id": 1332, "seek": 536624, "start": 5374.08, "end": 5379.28, "text": " as a tree, rather than ask it to predict what exactly was the transformation applied to", "tokens": [50364, 8895, 281, 312, 33270, 394, 1412, 14501, 19631, 13, 50484, 50484, 509, 528, 341, 3209, 281, 33872, 819, 16829, 420, 819, 44796, 295, 341, 3256, 50756, 50756, 382, 257, 4230, 11, 2831, 813, 1029, 309, 281, 6069, 437, 2293, 390, 264, 9887, 6456, 281, 51016, 51016, 264, 4846, 13, 51110, 51110, 407, 341, 307, 437, 7547, 3026, 75, 13, 51250, 51250, 407, 3026, 75, 7382, 337, 659, 25111, 33270, 394, 10290, 2539, 11, 689, 264, 1558, 307, 300, 291, 528, 51524, 51524, 264, 10290, 281, 312, 33270, 394, 420, 7983, 382, 707, 1589, 382, 1944, 295, 264, 4846, 51826, 51826], "temperature": 0.0, "avg_logprob": -0.1295304391898361, "compression_ratio": 1.8583333333333334, "no_speech_prob": 1.3006404515181202e-05}, {"id": 1333, "seek": 536624, "start": 5379.28, "end": 5381.16, "text": " the input.", "tokens": [50364, 8895, 281, 312, 33270, 394, 1412, 14501, 19631, 13, 50484, 50484, 509, 528, 341, 3209, 281, 33872, 819, 16829, 420, 819, 44796, 295, 341, 3256, 50756, 50756, 382, 257, 4230, 11, 2831, 813, 1029, 309, 281, 6069, 437, 2293, 390, 264, 9887, 6456, 281, 51016, 51016, 264, 4846, 13, 51110, 51110, 407, 341, 307, 437, 7547, 3026, 75, 13, 51250, 51250, 407, 3026, 75, 7382, 337, 659, 25111, 33270, 394, 10290, 2539, 11, 689, 264, 1558, 307, 300, 291, 528, 51524, 51524, 264, 10290, 281, 312, 33270, 394, 420, 7983, 382, 707, 1589, 382, 1944, 295, 264, 4846, 51826, 51826], "temperature": 0.0, "avg_logprob": -0.1295304391898361, "compression_ratio": 1.8583333333333334, "no_speech_prob": 1.3006404515181202e-05}, {"id": 1334, "seek": 536624, "start": 5381.16, "end": 5383.96, "text": " So this is what inspired Perl.", "tokens": [50364, 8895, 281, 312, 33270, 394, 1412, 14501, 19631, 13, 50484, 50484, 509, 528, 341, 3209, 281, 33872, 819, 16829, 420, 819, 44796, 295, 341, 3256, 50756, 50756, 382, 257, 4230, 11, 2831, 813, 1029, 309, 281, 6069, 437, 2293, 390, 264, 9887, 6456, 281, 51016, 51016, 264, 4846, 13, 51110, 51110, 407, 341, 307, 437, 7547, 3026, 75, 13, 51250, 51250, 407, 3026, 75, 7382, 337, 659, 25111, 33270, 394, 10290, 2539, 11, 689, 264, 1558, 307, 300, 291, 528, 51524, 51524, 264, 10290, 281, 312, 33270, 394, 420, 7983, 382, 707, 1589, 382, 1944, 295, 264, 4846, 51826, 51826], "temperature": 0.0, "avg_logprob": -0.1295304391898361, "compression_ratio": 1.8583333333333334, "no_speech_prob": 1.3006404515181202e-05}, {"id": 1335, "seek": 536624, "start": 5383.96, "end": 5389.44, "text": " So Perl stands for pretext invariant representation learning, where the idea is that you want", "tokens": [50364, 8895, 281, 312, 33270, 394, 1412, 14501, 19631, 13, 50484, 50484, 509, 528, 341, 3209, 281, 33872, 819, 16829, 420, 819, 44796, 295, 341, 3256, 50756, 50756, 382, 257, 4230, 11, 2831, 813, 1029, 309, 281, 6069, 437, 2293, 390, 264, 9887, 6456, 281, 51016, 51016, 264, 4846, 13, 51110, 51110, 407, 341, 307, 437, 7547, 3026, 75, 13, 51250, 51250, 407, 3026, 75, 7382, 337, 659, 25111, 33270, 394, 10290, 2539, 11, 689, 264, 1558, 307, 300, 291, 528, 51524, 51524, 264, 10290, 281, 312, 33270, 394, 420, 7983, 382, 707, 1589, 382, 1944, 295, 264, 4846, 51826, 51826], "temperature": 0.0, "avg_logprob": -0.1295304391898361, "compression_ratio": 1.8583333333333334, "no_speech_prob": 1.3006404515181202e-05}, {"id": 1336, "seek": 536624, "start": 5389.44, "end": 5395.48, "text": " the representation to be invariant or capture as little information as possible of the input", "tokens": [50364, 8895, 281, 312, 33270, 394, 1412, 14501, 19631, 13, 50484, 50484, 509, 528, 341, 3209, 281, 33872, 819, 16829, 420, 819, 44796, 295, 341, 3256, 50756, 50756, 382, 257, 4230, 11, 2831, 813, 1029, 309, 281, 6069, 437, 2293, 390, 264, 9887, 6456, 281, 51016, 51016, 264, 4846, 13, 51110, 51110, 407, 341, 307, 437, 7547, 3026, 75, 13, 51250, 51250, 407, 3026, 75, 7382, 337, 659, 25111, 33270, 394, 10290, 2539, 11, 689, 264, 1558, 307, 300, 291, 528, 51524, 51524, 264, 10290, 281, 312, 33270, 394, 420, 7983, 382, 707, 1589, 382, 1944, 295, 264, 4846, 51826, 51826], "temperature": 0.0, "avg_logprob": -0.1295304391898361, "compression_ratio": 1.8583333333333334, "no_speech_prob": 1.3006404515181202e-05}, {"id": 1337, "seek": 539548, "start": 5395.48, "end": 5397.24, "text": " transform.", "tokens": [50364, 4088, 13, 50452, 50452, 407, 291, 362, 264, 3256, 11, 291, 362, 264, 4088, 3037, 295, 264, 3256, 11, 291, 3154, 2128, 1293, 50700, 50700, 295, 613, 5267, 807, 257, 2701, 11, 291, 483, 257, 10290, 11, 293, 550, 291, 1936, 5373, 50986, 50986, 613, 33358, 281, 312, 2531, 13, 51119, 51119, 407, 294, 2115, 295, 264, 24657, 286, 390, 1417, 466, 3071, 11, 291, 1936, 584, 300, 264, 51412, 51412, 3256, 286, 293, 604, 659, 25111, 16894, 3037, 295, 341, 3256, 286, 366, 4077, 10938, 11, 293, 604, 51734, 51734], "temperature": 0.0, "avg_logprob": -0.17238518499558972, "compression_ratio": 1.9707317073170731, "no_speech_prob": 3.4465333555999678e-06}, {"id": 1338, "seek": 539548, "start": 5397.24, "end": 5402.2, "text": " So you have the image, you have the transform version of the image, you feed forward both", "tokens": [50364, 4088, 13, 50452, 50452, 407, 291, 362, 264, 3256, 11, 291, 362, 264, 4088, 3037, 295, 264, 3256, 11, 291, 3154, 2128, 1293, 50700, 50700, 295, 613, 5267, 807, 257, 2701, 11, 291, 483, 257, 10290, 11, 293, 550, 291, 1936, 5373, 50986, 50986, 613, 33358, 281, 312, 2531, 13, 51119, 51119, 407, 294, 2115, 295, 264, 24657, 286, 390, 1417, 466, 3071, 11, 291, 1936, 584, 300, 264, 51412, 51412, 3256, 286, 293, 604, 659, 25111, 16894, 3037, 295, 341, 3256, 286, 366, 4077, 10938, 11, 293, 604, 51734, 51734], "temperature": 0.0, "avg_logprob": -0.17238518499558972, "compression_ratio": 1.9707317073170731, "no_speech_prob": 3.4465333555999678e-06}, {"id": 1339, "seek": 539548, "start": 5402.2, "end": 5407.919999999999, "text": " of these images through a content, you get a representation, and then you basically encourage", "tokens": [50364, 4088, 13, 50452, 50452, 407, 291, 362, 264, 3256, 11, 291, 362, 264, 4088, 3037, 295, 264, 3256, 11, 291, 3154, 2128, 1293, 50700, 50700, 295, 613, 5267, 807, 257, 2701, 11, 291, 483, 257, 10290, 11, 293, 550, 291, 1936, 5373, 50986, 50986, 613, 33358, 281, 312, 2531, 13, 51119, 51119, 407, 294, 2115, 295, 264, 24657, 286, 390, 1417, 466, 3071, 11, 291, 1936, 584, 300, 264, 51412, 51412, 3256, 286, 293, 604, 659, 25111, 16894, 3037, 295, 341, 3256, 286, 366, 4077, 10938, 11, 293, 604, 51734, 51734], "temperature": 0.0, "avg_logprob": -0.17238518499558972, "compression_ratio": 1.9707317073170731, "no_speech_prob": 3.4465333555999678e-06}, {"id": 1340, "seek": 539548, "start": 5407.919999999999, "end": 5410.58, "text": " these representations to be similar.", "tokens": [50364, 4088, 13, 50452, 50452, 407, 291, 362, 264, 3256, 11, 291, 362, 264, 4088, 3037, 295, 264, 3256, 11, 291, 3154, 2128, 1293, 50700, 50700, 295, 613, 5267, 807, 257, 2701, 11, 291, 483, 257, 10290, 11, 293, 550, 291, 1936, 5373, 50986, 50986, 613, 33358, 281, 312, 2531, 13, 51119, 51119, 407, 294, 2115, 295, 264, 24657, 286, 390, 1417, 466, 3071, 11, 291, 1936, 584, 300, 264, 51412, 51412, 3256, 286, 293, 604, 659, 25111, 16894, 3037, 295, 341, 3256, 286, 366, 4077, 10938, 11, 293, 604, 51734, 51734], "temperature": 0.0, "avg_logprob": -0.17238518499558972, "compression_ratio": 1.9707317073170731, "no_speech_prob": 3.4465333555999678e-06}, {"id": 1341, "seek": 539548, "start": 5410.58, "end": 5416.44, "text": " So in terms of the notation I was talking about earlier, you basically say that the", "tokens": [50364, 4088, 13, 50452, 50452, 407, 291, 362, 264, 3256, 11, 291, 362, 264, 4088, 3037, 295, 264, 3256, 11, 291, 3154, 2128, 1293, 50700, 50700, 295, 613, 5267, 807, 257, 2701, 11, 291, 483, 257, 10290, 11, 293, 550, 291, 1936, 5373, 50986, 50986, 613, 33358, 281, 312, 2531, 13, 51119, 51119, 407, 294, 2115, 295, 264, 24657, 286, 390, 1417, 466, 3071, 11, 291, 1936, 584, 300, 264, 51412, 51412, 3256, 286, 293, 604, 659, 25111, 16894, 3037, 295, 341, 3256, 286, 366, 4077, 10938, 11, 293, 604, 51734, 51734], "temperature": 0.0, "avg_logprob": -0.17238518499558972, "compression_ratio": 1.9707317073170731, "no_speech_prob": 3.4465333555999678e-06}, {"id": 1342, "seek": 539548, "start": 5416.44, "end": 5422.879999999999, "text": " image I and any pretext transformed version of this image I are related samples, and any", "tokens": [50364, 4088, 13, 50452, 50452, 407, 291, 362, 264, 3256, 11, 291, 362, 264, 4088, 3037, 295, 264, 3256, 11, 291, 3154, 2128, 1293, 50700, 50700, 295, 613, 5267, 807, 257, 2701, 11, 291, 483, 257, 10290, 11, 293, 550, 291, 1936, 5373, 50986, 50986, 613, 33358, 281, 312, 2531, 13, 51119, 51119, 407, 294, 2115, 295, 264, 24657, 286, 390, 1417, 466, 3071, 11, 291, 1936, 584, 300, 264, 51412, 51412, 3256, 286, 293, 604, 659, 25111, 16894, 3037, 295, 341, 3256, 286, 366, 4077, 10938, 11, 293, 604, 51734, 51734], "temperature": 0.0, "avg_logprob": -0.17238518499558972, "compression_ratio": 1.9707317073170731, "no_speech_prob": 3.4465333555999678e-06}, {"id": 1343, "seek": 542288, "start": 5422.88, "end": 5426.68, "text": " other image is an unrelated sample.", "tokens": [50364, 661, 3256, 307, 364, 38967, 6889, 13, 50554, 50554, 407, 294, 341, 636, 11, 562, 291, 3847, 341, 3209, 11, 341, 10290, 4696, 8306, 588, 50838, 50838, 707, 1589, 466, 341, 4088, 314, 13, 51066, 51066, 400, 2086, 11, 291, 3847, 309, 1228, 8712, 488, 2539, 13, 51164, 51164, 407, 8712, 488, 2539, 644, 307, 281, 1936, 11, 291, 362, 584, 4111, 1932, 1348, 490, 264, 3380, 51490, 51490, 3256, 286, 11, 293, 291, 362, 264, 4111, 9467, 1348, 490, 264, 4088, 3037, 13, 51766, 51766], "temperature": 0.0, "avg_logprob": -0.1791687228462913, "compression_ratio": 1.7990654205607477, "no_speech_prob": 6.643272627115948e-06}, {"id": 1344, "seek": 542288, "start": 5426.68, "end": 5432.36, "text": " So in this way, when you train this network, this representation hopefully contains very", "tokens": [50364, 661, 3256, 307, 364, 38967, 6889, 13, 50554, 50554, 407, 294, 341, 636, 11, 562, 291, 3847, 341, 3209, 11, 341, 10290, 4696, 8306, 588, 50838, 50838, 707, 1589, 466, 341, 4088, 314, 13, 51066, 51066, 400, 2086, 11, 291, 3847, 309, 1228, 8712, 488, 2539, 13, 51164, 51164, 407, 8712, 488, 2539, 644, 307, 281, 1936, 11, 291, 362, 584, 4111, 1932, 1348, 490, 264, 3380, 51490, 51490, 3256, 286, 11, 293, 291, 362, 264, 4111, 9467, 1348, 490, 264, 4088, 3037, 13, 51766, 51766], "temperature": 0.0, "avg_logprob": -0.1791687228462913, "compression_ratio": 1.7990654205607477, "no_speech_prob": 6.643272627115948e-06}, {"id": 1345, "seek": 542288, "start": 5432.36, "end": 5436.92, "text": " little information about this transform T.", "tokens": [50364, 661, 3256, 307, 364, 38967, 6889, 13, 50554, 50554, 407, 294, 341, 636, 11, 562, 291, 3847, 341, 3209, 11, 341, 10290, 4696, 8306, 588, 50838, 50838, 707, 1589, 466, 341, 4088, 314, 13, 51066, 51066, 400, 2086, 11, 291, 3847, 309, 1228, 8712, 488, 2539, 13, 51164, 51164, 407, 8712, 488, 2539, 644, 307, 281, 1936, 11, 291, 362, 584, 4111, 1932, 1348, 490, 264, 3380, 51490, 51490, 3256, 286, 11, 293, 291, 362, 264, 4111, 9467, 1348, 490, 264, 4088, 3037, 13, 51766, 51766], "temperature": 0.0, "avg_logprob": -0.1791687228462913, "compression_ratio": 1.7990654205607477, "no_speech_prob": 6.643272627115948e-06}, {"id": 1346, "seek": 542288, "start": 5436.92, "end": 5438.88, "text": " And yes, you train it using contrastive learning.", "tokens": [50364, 661, 3256, 307, 364, 38967, 6889, 13, 50554, 50554, 407, 294, 341, 636, 11, 562, 291, 3847, 341, 3209, 11, 341, 10290, 4696, 8306, 588, 50838, 50838, 707, 1589, 466, 341, 4088, 314, 13, 51066, 51066, 400, 2086, 11, 291, 3847, 309, 1228, 8712, 488, 2539, 13, 51164, 51164, 407, 8712, 488, 2539, 644, 307, 281, 1936, 11, 291, 362, 584, 4111, 1932, 1348, 490, 264, 3380, 51490, 51490, 3256, 286, 11, 293, 291, 362, 264, 4111, 9467, 1348, 490, 264, 4088, 3037, 13, 51766, 51766], "temperature": 0.0, "avg_logprob": -0.1791687228462913, "compression_ratio": 1.7990654205607477, "no_speech_prob": 6.643272627115948e-06}, {"id": 1347, "seek": 542288, "start": 5438.88, "end": 5445.400000000001, "text": " So contrastive learning part is to basically, you have say feature vi coming from the original", "tokens": [50364, 661, 3256, 307, 364, 38967, 6889, 13, 50554, 50554, 407, 294, 341, 636, 11, 562, 291, 3847, 341, 3209, 11, 341, 10290, 4696, 8306, 588, 50838, 50838, 707, 1589, 466, 341, 4088, 314, 13, 51066, 51066, 400, 2086, 11, 291, 3847, 309, 1228, 8712, 488, 2539, 13, 51164, 51164, 407, 8712, 488, 2539, 644, 307, 281, 1936, 11, 291, 362, 584, 4111, 1932, 1348, 490, 264, 3380, 51490, 51490, 3256, 286, 11, 293, 291, 362, 264, 4111, 9467, 1348, 490, 264, 4088, 3037, 13, 51766, 51766], "temperature": 0.0, "avg_logprob": -0.1791687228462913, "compression_ratio": 1.7990654205607477, "no_speech_prob": 6.643272627115948e-06}, {"id": 1348, "seek": 542288, "start": 5445.400000000001, "end": 5450.92, "text": " image I, and you have the feature vit coming from the transform version.", "tokens": [50364, 661, 3256, 307, 364, 38967, 6889, 13, 50554, 50554, 407, 294, 341, 636, 11, 562, 291, 3847, 341, 3209, 11, 341, 10290, 4696, 8306, 588, 50838, 50838, 707, 1589, 466, 341, 4088, 314, 13, 51066, 51066, 400, 2086, 11, 291, 3847, 309, 1228, 8712, 488, 2539, 13, 51164, 51164, 407, 8712, 488, 2539, 644, 307, 281, 1936, 11, 291, 362, 584, 4111, 1932, 1348, 490, 264, 3380, 51490, 51490, 3256, 286, 11, 293, 291, 362, 264, 4111, 9467, 1348, 490, 264, 4088, 3037, 13, 51766, 51766], "temperature": 0.0, "avg_logprob": -0.1791687228462913, "compression_ratio": 1.7990654205607477, "no_speech_prob": 6.643272627115948e-06}, {"id": 1349, "seek": 545092, "start": 5450.92, "end": 5454.4400000000005, "text": " And you want both of these representations to be the same.", "tokens": [50364, 400, 291, 528, 1293, 295, 613, 33358, 281, 312, 264, 912, 13, 50540, 50540, 400, 294, 264, 3035, 11, 321, 2956, 412, 732, 819, 1785, 295, 264, 1523, 659, 25111, 35592, 13, 50770, 50770, 407, 300, 307, 264, 361, 17156, 1607, 293, 264, 12447, 3170, 300, 286, 2825, 466, 3071, 13, 50978, 50978, 400, 321, 611, 24016, 21267, 295, 613, 35592, 13, 51098, 51098, 407, 3079, 1293, 361, 17156, 1607, 293, 12447, 412, 264, 912, 565, 13, 51268, 51268, 407, 294, 512, 636, 11, 341, 307, 411, 4825, 12, 83, 3863, 2539, 11, 457, 291, 434, 406, 534, 1382, 281, 6069, 1293, 51500, 51500, 361, 17156, 1607, 293, 12447, 11, 291, 434, 1382, 281, 312, 33270, 394, 281, 1293, 361, 17156, 1607, 293, 12447, 13, 51798, 51798], "temperature": 0.0, "avg_logprob": -0.10718485366466433, "compression_ratio": 1.868421052631579, "no_speech_prob": 1.4738163372385316e-05}, {"id": 1350, "seek": 545092, "start": 5454.4400000000005, "end": 5459.04, "text": " And in the paper, we looked at two different state of the art pretext transforms.", "tokens": [50364, 400, 291, 528, 1293, 295, 613, 33358, 281, 312, 264, 912, 13, 50540, 50540, 400, 294, 264, 3035, 11, 321, 2956, 412, 732, 819, 1785, 295, 264, 1523, 659, 25111, 35592, 13, 50770, 50770, 407, 300, 307, 264, 361, 17156, 1607, 293, 264, 12447, 3170, 300, 286, 2825, 466, 3071, 13, 50978, 50978, 400, 321, 611, 24016, 21267, 295, 613, 35592, 13, 51098, 51098, 407, 3079, 1293, 361, 17156, 1607, 293, 12447, 412, 264, 912, 565, 13, 51268, 51268, 407, 294, 512, 636, 11, 341, 307, 411, 4825, 12, 83, 3863, 2539, 11, 457, 291, 434, 406, 534, 1382, 281, 6069, 1293, 51500, 51500, 361, 17156, 1607, 293, 12447, 11, 291, 434, 1382, 281, 312, 33270, 394, 281, 1293, 361, 17156, 1607, 293, 12447, 13, 51798, 51798], "temperature": 0.0, "avg_logprob": -0.10718485366466433, "compression_ratio": 1.868421052631579, "no_speech_prob": 1.4738163372385316e-05}, {"id": 1351, "seek": 545092, "start": 5459.04, "end": 5463.2, "text": " So that is the jigsaw and the rotation method that I talked about earlier.", "tokens": [50364, 400, 291, 528, 1293, 295, 613, 33358, 281, 312, 264, 912, 13, 50540, 50540, 400, 294, 264, 3035, 11, 321, 2956, 412, 732, 819, 1785, 295, 264, 1523, 659, 25111, 35592, 13, 50770, 50770, 407, 300, 307, 264, 361, 17156, 1607, 293, 264, 12447, 3170, 300, 286, 2825, 466, 3071, 13, 50978, 50978, 400, 321, 611, 24016, 21267, 295, 613, 35592, 13, 51098, 51098, 407, 3079, 1293, 361, 17156, 1607, 293, 12447, 412, 264, 912, 565, 13, 51268, 51268, 407, 294, 512, 636, 11, 341, 307, 411, 4825, 12, 83, 3863, 2539, 11, 457, 291, 434, 406, 534, 1382, 281, 6069, 1293, 51500, 51500, 361, 17156, 1607, 293, 12447, 11, 291, 434, 1382, 281, 312, 33270, 394, 281, 1293, 361, 17156, 1607, 293, 12447, 13, 51798, 51798], "temperature": 0.0, "avg_logprob": -0.10718485366466433, "compression_ratio": 1.868421052631579, "no_speech_prob": 1.4738163372385316e-05}, {"id": 1352, "seek": 545092, "start": 5463.2, "end": 5465.6, "text": " And we also explored combinations of these transforms.", "tokens": [50364, 400, 291, 528, 1293, 295, 613, 33358, 281, 312, 264, 912, 13, 50540, 50540, 400, 294, 264, 3035, 11, 321, 2956, 412, 732, 819, 1785, 295, 264, 1523, 659, 25111, 35592, 13, 50770, 50770, 407, 300, 307, 264, 361, 17156, 1607, 293, 264, 12447, 3170, 300, 286, 2825, 466, 3071, 13, 50978, 50978, 400, 321, 611, 24016, 21267, 295, 613, 35592, 13, 51098, 51098, 407, 3079, 1293, 361, 17156, 1607, 293, 12447, 412, 264, 912, 565, 13, 51268, 51268, 407, 294, 512, 636, 11, 341, 307, 411, 4825, 12, 83, 3863, 2539, 11, 457, 291, 434, 406, 534, 1382, 281, 6069, 1293, 51500, 51500, 361, 17156, 1607, 293, 12447, 11, 291, 434, 1382, 281, 312, 33270, 394, 281, 1293, 361, 17156, 1607, 293, 12447, 13, 51798, 51798], "temperature": 0.0, "avg_logprob": -0.10718485366466433, "compression_ratio": 1.868421052631579, "no_speech_prob": 1.4738163372385316e-05}, {"id": 1353, "seek": 545092, "start": 5465.6, "end": 5469.0, "text": " So apply both jigsaw and rotation at the same time.", "tokens": [50364, 400, 291, 528, 1293, 295, 613, 33358, 281, 312, 264, 912, 13, 50540, 50540, 400, 294, 264, 3035, 11, 321, 2956, 412, 732, 819, 1785, 295, 264, 1523, 659, 25111, 35592, 13, 50770, 50770, 407, 300, 307, 264, 361, 17156, 1607, 293, 264, 12447, 3170, 300, 286, 2825, 466, 3071, 13, 50978, 50978, 400, 321, 611, 24016, 21267, 295, 613, 35592, 13, 51098, 51098, 407, 3079, 1293, 361, 17156, 1607, 293, 12447, 412, 264, 912, 565, 13, 51268, 51268, 407, 294, 512, 636, 11, 341, 307, 411, 4825, 12, 83, 3863, 2539, 11, 457, 291, 434, 406, 534, 1382, 281, 6069, 1293, 51500, 51500, 361, 17156, 1607, 293, 12447, 11, 291, 434, 1382, 281, 312, 33270, 394, 281, 1293, 361, 17156, 1607, 293, 12447, 13, 51798, 51798], "temperature": 0.0, "avg_logprob": -0.10718485366466433, "compression_ratio": 1.868421052631579, "no_speech_prob": 1.4738163372385316e-05}, {"id": 1354, "seek": 545092, "start": 5469.0, "end": 5473.64, "text": " So in some way, this is like multi-task learning, but you're not really trying to predict both", "tokens": [50364, 400, 291, 528, 1293, 295, 613, 33358, 281, 312, 264, 912, 13, 50540, 50540, 400, 294, 264, 3035, 11, 321, 2956, 412, 732, 819, 1785, 295, 264, 1523, 659, 25111, 35592, 13, 50770, 50770, 407, 300, 307, 264, 361, 17156, 1607, 293, 264, 12447, 3170, 300, 286, 2825, 466, 3071, 13, 50978, 50978, 400, 321, 611, 24016, 21267, 295, 613, 35592, 13, 51098, 51098, 407, 3079, 1293, 361, 17156, 1607, 293, 12447, 412, 264, 912, 565, 13, 51268, 51268, 407, 294, 512, 636, 11, 341, 307, 411, 4825, 12, 83, 3863, 2539, 11, 457, 291, 434, 406, 534, 1382, 281, 6069, 1293, 51500, 51500, 361, 17156, 1607, 293, 12447, 11, 291, 434, 1382, 281, 312, 33270, 394, 281, 1293, 361, 17156, 1607, 293, 12447, 13, 51798, 51798], "temperature": 0.0, "avg_logprob": -0.10718485366466433, "compression_ratio": 1.868421052631579, "no_speech_prob": 1.4738163372385316e-05}, {"id": 1355, "seek": 545092, "start": 5473.64, "end": 5479.6, "text": " jigsaw and rotation, you're trying to be invariant to both jigsaw and rotation.", "tokens": [50364, 400, 291, 528, 1293, 295, 613, 33358, 281, 312, 264, 912, 13, 50540, 50540, 400, 294, 264, 3035, 11, 321, 2956, 412, 732, 819, 1785, 295, 264, 1523, 659, 25111, 35592, 13, 50770, 50770, 407, 300, 307, 264, 361, 17156, 1607, 293, 264, 12447, 3170, 300, 286, 2825, 466, 3071, 13, 50978, 50978, 400, 321, 611, 24016, 21267, 295, 613, 35592, 13, 51098, 51098, 407, 3079, 1293, 361, 17156, 1607, 293, 12447, 412, 264, 912, 565, 13, 51268, 51268, 407, 294, 512, 636, 11, 341, 307, 411, 4825, 12, 83, 3863, 2539, 11, 457, 291, 434, 406, 534, 1382, 281, 6069, 1293, 51500, 51500, 361, 17156, 1607, 293, 12447, 11, 291, 434, 1382, 281, 312, 33270, 394, 281, 1293, 361, 17156, 1607, 293, 12447, 13, 51798, 51798], "temperature": 0.0, "avg_logprob": -0.10718485366466433, "compression_ratio": 1.868421052631579, "no_speech_prob": 1.4738163372385316e-05}, {"id": 1356, "seek": 547960, "start": 5479.6, "end": 5486.64, "text": " So the key thing that has sort of made contrastive learning work well in the past, like sort", "tokens": [50364, 407, 264, 2141, 551, 300, 575, 1333, 295, 1027, 8712, 488, 2539, 589, 731, 294, 264, 1791, 11, 411, 1333, 50716, 50716, 295, 4406, 15257, 11, 307, 534, 1228, 257, 2416, 1230, 295, 40019, 13, 50998, 50998, 400, 472, 295, 264, 665, 1333, 295, 10577, 300, 7268, 341, 390, 341, 5197, 15973, 3035, 51290, 51290, 490, 6096, 11, 597, 7268, 341, 3410, 295, 257, 4675, 3765, 13, 51578, 51578, 400, 341, 575, 17786, 11, 286, 576, 584, 11, 881, 295, 264, 1333, 295, 5162, 7150, 11, 597, 366, 1785, 51778, 51778], "temperature": 0.0, "avg_logprob": -0.14014798851423366, "compression_ratio": 1.6680497925311204, "no_speech_prob": 1.5445119061041623e-05}, {"id": 1357, "seek": 547960, "start": 5486.64, "end": 5492.280000000001, "text": " of successful attempts, is really using a large number of negatives.", "tokens": [50364, 407, 264, 2141, 551, 300, 575, 1333, 295, 1027, 8712, 488, 2539, 589, 731, 294, 264, 1791, 11, 411, 1333, 50716, 50716, 295, 4406, 15257, 11, 307, 534, 1228, 257, 2416, 1230, 295, 40019, 13, 50998, 50998, 400, 472, 295, 264, 665, 1333, 295, 10577, 300, 7268, 341, 390, 341, 5197, 15973, 3035, 51290, 51290, 490, 6096, 11, 597, 7268, 341, 3410, 295, 257, 4675, 3765, 13, 51578, 51578, 400, 341, 575, 17786, 11, 286, 576, 584, 11, 881, 295, 264, 1333, 295, 5162, 7150, 11, 597, 366, 1785, 51778, 51778], "temperature": 0.0, "avg_logprob": -0.14014798851423366, "compression_ratio": 1.6680497925311204, "no_speech_prob": 1.5445119061041623e-05}, {"id": 1358, "seek": 547960, "start": 5492.280000000001, "end": 5498.120000000001, "text": " And one of the good sort of papers that introduced this was this instance discrimination paper", "tokens": [50364, 407, 264, 2141, 551, 300, 575, 1333, 295, 1027, 8712, 488, 2539, 589, 731, 294, 264, 1791, 11, 411, 1333, 50716, 50716, 295, 4406, 15257, 11, 307, 534, 1228, 257, 2416, 1230, 295, 40019, 13, 50998, 50998, 400, 472, 295, 264, 665, 1333, 295, 10577, 300, 7268, 341, 390, 341, 5197, 15973, 3035, 51290, 51290, 490, 6096, 11, 597, 7268, 341, 3410, 295, 257, 4675, 3765, 13, 51578, 51578, 400, 341, 575, 17786, 11, 286, 576, 584, 11, 881, 295, 264, 1333, 295, 5162, 7150, 11, 597, 366, 1785, 51778, 51778], "temperature": 0.0, "avg_logprob": -0.14014798851423366, "compression_ratio": 1.6680497925311204, "no_speech_prob": 1.5445119061041623e-05}, {"id": 1359, "seek": 547960, "start": 5498.120000000001, "end": 5503.88, "text": " from 2018, which introduced this concept of a memory bank.", "tokens": [50364, 407, 264, 2141, 551, 300, 575, 1333, 295, 1027, 8712, 488, 2539, 589, 731, 294, 264, 1791, 11, 411, 1333, 50716, 50716, 295, 4406, 15257, 11, 307, 534, 1228, 257, 2416, 1230, 295, 40019, 13, 50998, 50998, 400, 472, 295, 264, 665, 1333, 295, 10577, 300, 7268, 341, 390, 341, 5197, 15973, 3035, 51290, 51290, 490, 6096, 11, 597, 7268, 341, 3410, 295, 257, 4675, 3765, 13, 51578, 51578, 400, 341, 575, 17786, 11, 286, 576, 584, 11, 881, 295, 264, 1333, 295, 5162, 7150, 11, 597, 366, 1785, 51778, 51778], "temperature": 0.0, "avg_logprob": -0.14014798851423366, "compression_ratio": 1.6680497925311204, "no_speech_prob": 1.5445119061041623e-05}, {"id": 1360, "seek": 547960, "start": 5503.88, "end": 5507.88, "text": " And this has powered, I would say, most of the sort of recent methods, which are state", "tokens": [50364, 407, 264, 2141, 551, 300, 575, 1333, 295, 1027, 8712, 488, 2539, 589, 731, 294, 264, 1791, 11, 411, 1333, 50716, 50716, 295, 4406, 15257, 11, 307, 534, 1228, 257, 2416, 1230, 295, 40019, 13, 50998, 50998, 400, 472, 295, 264, 665, 1333, 295, 10577, 300, 7268, 341, 390, 341, 5197, 15973, 3035, 51290, 51290, 490, 6096, 11, 597, 7268, 341, 3410, 295, 257, 4675, 3765, 13, 51578, 51578, 400, 341, 575, 17786, 11, 286, 576, 584, 11, 881, 295, 264, 1333, 295, 5162, 7150, 11, 597, 366, 1785, 51778, 51778], "temperature": 0.0, "avg_logprob": -0.14014798851423366, "compression_ratio": 1.6680497925311204, "no_speech_prob": 1.5445119061041623e-05}, {"id": 1361, "seek": 550788, "start": 5507.88, "end": 5510.4800000000005, "text": " of the art, including MoCo, Perl.", "tokens": [50364, 295, 264, 1523, 11, 3009, 3335, 21141, 11, 3026, 75, 13, 50494, 50494, 400, 436, 434, 439, 1333, 295, 3094, 293, 1333, 295, 28822, 322, 341, 1558, 295, 257, 4675, 3765, 13, 50652, 50652, 1664, 286, 1029, 291, 281, 39456, 428, 16278, 490, 264, 3820, 30, 50804, 50804, 1436, 309, 311, 588, 24518, 13, 50877, 50877, 1436, 264, 10952, 307, 6183, 490, 264, 16278, 13, 51018, 51018, 400, 300, 311, 668, 588, 485, 51168, 51168, 1119, 309, 1101, 586, 30, 51344, 51344, 2704, 13, 51394, 51394, 286, 500, 380, 458, 13, 51444, 51444, 961, 311, 853, 13, 51494, 51494, 1033, 11, 718, 311, 853, 13, 51544, 51544], "temperature": 0.0, "avg_logprob": -0.2883797916797323, "compression_ratio": 1.5934579439252337, "no_speech_prob": 3.320880568935536e-05}, {"id": 1362, "seek": 550788, "start": 5510.4800000000005, "end": 5513.64, "text": " And they're all sort of built and sort of hinge on this idea of a memory bank.", "tokens": [50364, 295, 264, 1523, 11, 3009, 3335, 21141, 11, 3026, 75, 13, 50494, 50494, 400, 436, 434, 439, 1333, 295, 3094, 293, 1333, 295, 28822, 322, 341, 1558, 295, 257, 4675, 3765, 13, 50652, 50652, 1664, 286, 1029, 291, 281, 39456, 428, 16278, 490, 264, 3820, 30, 50804, 50804, 1436, 309, 311, 588, 24518, 13, 50877, 50877, 1436, 264, 10952, 307, 6183, 490, 264, 16278, 13, 51018, 51018, 400, 300, 311, 668, 588, 485, 51168, 51168, 1119, 309, 1101, 586, 30, 51344, 51344, 2704, 13, 51394, 51394, 286, 500, 380, 458, 13, 51444, 51444, 961, 311, 853, 13, 51494, 51494, 1033, 11, 718, 311, 853, 13, 51544, 51544], "temperature": 0.0, "avg_logprob": -0.2883797916797323, "compression_ratio": 1.5934579439252337, "no_speech_prob": 3.320880568935536e-05}, {"id": 1363, "seek": 550788, "start": 5513.64, "end": 5516.68, "text": " Can I ask you to unplug your headphones from the computer?", "tokens": [50364, 295, 264, 1523, 11, 3009, 3335, 21141, 11, 3026, 75, 13, 50494, 50494, 400, 436, 434, 439, 1333, 295, 3094, 293, 1333, 295, 28822, 322, 341, 1558, 295, 257, 4675, 3765, 13, 50652, 50652, 1664, 286, 1029, 291, 281, 39456, 428, 16278, 490, 264, 3820, 30, 50804, 50804, 1436, 309, 311, 588, 24518, 13, 50877, 50877, 1436, 264, 10952, 307, 6183, 490, 264, 16278, 13, 51018, 51018, 400, 300, 311, 668, 588, 485, 51168, 51168, 1119, 309, 1101, 586, 30, 51344, 51344, 2704, 13, 51394, 51394, 286, 500, 380, 458, 13, 51444, 51444, 961, 311, 853, 13, 51494, 51494, 1033, 11, 718, 311, 853, 13, 51544, 51544], "temperature": 0.0, "avg_logprob": -0.2883797916797323, "compression_ratio": 1.5934579439252337, "no_speech_prob": 3.320880568935536e-05}, {"id": 1364, "seek": 550788, "start": 5516.68, "end": 5518.14, "text": " Because it's very noisy.", "tokens": [50364, 295, 264, 1523, 11, 3009, 3335, 21141, 11, 3026, 75, 13, 50494, 50494, 400, 436, 434, 439, 1333, 295, 3094, 293, 1333, 295, 28822, 322, 341, 1558, 295, 257, 4675, 3765, 13, 50652, 50652, 1664, 286, 1029, 291, 281, 39456, 428, 16278, 490, 264, 3820, 30, 50804, 50804, 1436, 309, 311, 588, 24518, 13, 50877, 50877, 1436, 264, 10952, 307, 6183, 490, 264, 16278, 13, 51018, 51018, 400, 300, 311, 668, 588, 485, 51168, 51168, 1119, 309, 1101, 586, 30, 51344, 51344, 2704, 13, 51394, 51394, 286, 500, 380, 458, 13, 51444, 51444, 961, 311, 853, 13, 51494, 51494, 1033, 11, 718, 311, 853, 13, 51544, 51544], "temperature": 0.0, "avg_logprob": -0.2883797916797323, "compression_ratio": 1.5934579439252337, "no_speech_prob": 3.320880568935536e-05}, {"id": 1365, "seek": 550788, "start": 5518.14, "end": 5520.96, "text": " Because the microphone is picked from the headphones.", "tokens": [50364, 295, 264, 1523, 11, 3009, 3335, 21141, 11, 3026, 75, 13, 50494, 50494, 400, 436, 434, 439, 1333, 295, 3094, 293, 1333, 295, 28822, 322, 341, 1558, 295, 257, 4675, 3765, 13, 50652, 50652, 1664, 286, 1029, 291, 281, 39456, 428, 16278, 490, 264, 3820, 30, 50804, 50804, 1436, 309, 311, 588, 24518, 13, 50877, 50877, 1436, 264, 10952, 307, 6183, 490, 264, 16278, 13, 51018, 51018, 400, 300, 311, 668, 588, 485, 51168, 51168, 1119, 309, 1101, 586, 30, 51344, 51344, 2704, 13, 51394, 51394, 286, 500, 380, 458, 13, 51444, 51444, 961, 311, 853, 13, 51494, 51494, 1033, 11, 718, 311, 853, 13, 51544, 51544], "temperature": 0.0, "avg_logprob": -0.2883797916797323, "compression_ratio": 1.5934579439252337, "no_speech_prob": 3.320880568935536e-05}, {"id": 1366, "seek": 550788, "start": 5520.96, "end": 5523.96, "text": " And that's been very...", "tokens": [50364, 295, 264, 1523, 11, 3009, 3335, 21141, 11, 3026, 75, 13, 50494, 50494, 400, 436, 434, 439, 1333, 295, 3094, 293, 1333, 295, 28822, 322, 341, 1558, 295, 257, 4675, 3765, 13, 50652, 50652, 1664, 286, 1029, 291, 281, 39456, 428, 16278, 490, 264, 3820, 30, 50804, 50804, 1436, 309, 311, 588, 24518, 13, 50877, 50877, 1436, 264, 10952, 307, 6183, 490, 264, 16278, 13, 51018, 51018, 400, 300, 311, 668, 588, 485, 51168, 51168, 1119, 309, 1101, 586, 30, 51344, 51344, 2704, 13, 51394, 51394, 286, 500, 380, 458, 13, 51444, 51444, 961, 311, 853, 13, 51494, 51494, 1033, 11, 718, 311, 853, 13, 51544, 51544], "temperature": 0.0, "avg_logprob": -0.2883797916797323, "compression_ratio": 1.5934579439252337, "no_speech_prob": 3.320880568935536e-05}, {"id": 1367, "seek": 550788, "start": 5523.96, "end": 5527.4800000000005, "text": " Is it better now?", "tokens": [50364, 295, 264, 1523, 11, 3009, 3335, 21141, 11, 3026, 75, 13, 50494, 50494, 400, 436, 434, 439, 1333, 295, 3094, 293, 1333, 295, 28822, 322, 341, 1558, 295, 257, 4675, 3765, 13, 50652, 50652, 1664, 286, 1029, 291, 281, 39456, 428, 16278, 490, 264, 3820, 30, 50804, 50804, 1436, 309, 311, 588, 24518, 13, 50877, 50877, 1436, 264, 10952, 307, 6183, 490, 264, 16278, 13, 51018, 51018, 400, 300, 311, 668, 588, 485, 51168, 51168, 1119, 309, 1101, 586, 30, 51344, 51344, 2704, 13, 51394, 51394, 286, 500, 380, 458, 13, 51444, 51444, 961, 311, 853, 13, 51494, 51494, 1033, 11, 718, 311, 853, 13, 51544, 51544], "temperature": 0.0, "avg_logprob": -0.2883797916797323, "compression_ratio": 1.5934579439252337, "no_speech_prob": 3.320880568935536e-05}, {"id": 1368, "seek": 550788, "start": 5527.4800000000005, "end": 5528.4800000000005, "text": " Maybe.", "tokens": [50364, 295, 264, 1523, 11, 3009, 3335, 21141, 11, 3026, 75, 13, 50494, 50494, 400, 436, 434, 439, 1333, 295, 3094, 293, 1333, 295, 28822, 322, 341, 1558, 295, 257, 4675, 3765, 13, 50652, 50652, 1664, 286, 1029, 291, 281, 39456, 428, 16278, 490, 264, 3820, 30, 50804, 50804, 1436, 309, 311, 588, 24518, 13, 50877, 50877, 1436, 264, 10952, 307, 6183, 490, 264, 16278, 13, 51018, 51018, 400, 300, 311, 668, 588, 485, 51168, 51168, 1119, 309, 1101, 586, 30, 51344, 51344, 2704, 13, 51394, 51394, 286, 500, 380, 458, 13, 51444, 51444, 961, 311, 853, 13, 51494, 51494, 1033, 11, 718, 311, 853, 13, 51544, 51544], "temperature": 0.0, "avg_logprob": -0.2883797916797323, "compression_ratio": 1.5934579439252337, "no_speech_prob": 3.320880568935536e-05}, {"id": 1369, "seek": 550788, "start": 5528.4800000000005, "end": 5529.4800000000005, "text": " I don't know.", "tokens": [50364, 295, 264, 1523, 11, 3009, 3335, 21141, 11, 3026, 75, 13, 50494, 50494, 400, 436, 434, 439, 1333, 295, 3094, 293, 1333, 295, 28822, 322, 341, 1558, 295, 257, 4675, 3765, 13, 50652, 50652, 1664, 286, 1029, 291, 281, 39456, 428, 16278, 490, 264, 3820, 30, 50804, 50804, 1436, 309, 311, 588, 24518, 13, 50877, 50877, 1436, 264, 10952, 307, 6183, 490, 264, 16278, 13, 51018, 51018, 400, 300, 311, 668, 588, 485, 51168, 51168, 1119, 309, 1101, 586, 30, 51344, 51344, 2704, 13, 51394, 51394, 286, 500, 380, 458, 13, 51444, 51444, 961, 311, 853, 13, 51494, 51494, 1033, 11, 718, 311, 853, 13, 51544, 51544], "temperature": 0.0, "avg_logprob": -0.2883797916797323, "compression_ratio": 1.5934579439252337, "no_speech_prob": 3.320880568935536e-05}, {"id": 1370, "seek": 550788, "start": 5529.4800000000005, "end": 5530.4800000000005, "text": " Let's try.", "tokens": [50364, 295, 264, 1523, 11, 3009, 3335, 21141, 11, 3026, 75, 13, 50494, 50494, 400, 436, 434, 439, 1333, 295, 3094, 293, 1333, 295, 28822, 322, 341, 1558, 295, 257, 4675, 3765, 13, 50652, 50652, 1664, 286, 1029, 291, 281, 39456, 428, 16278, 490, 264, 3820, 30, 50804, 50804, 1436, 309, 311, 588, 24518, 13, 50877, 50877, 1436, 264, 10952, 307, 6183, 490, 264, 16278, 13, 51018, 51018, 400, 300, 311, 668, 588, 485, 51168, 51168, 1119, 309, 1101, 586, 30, 51344, 51344, 2704, 13, 51394, 51394, 286, 500, 380, 458, 13, 51444, 51444, 961, 311, 853, 13, 51494, 51494, 1033, 11, 718, 311, 853, 13, 51544, 51544], "temperature": 0.0, "avg_logprob": -0.2883797916797323, "compression_ratio": 1.5934579439252337, "no_speech_prob": 3.320880568935536e-05}, {"id": 1371, "seek": 550788, "start": 5530.4800000000005, "end": 5531.4800000000005, "text": " Okay, let's try.", "tokens": [50364, 295, 264, 1523, 11, 3009, 3335, 21141, 11, 3026, 75, 13, 50494, 50494, 400, 436, 434, 439, 1333, 295, 3094, 293, 1333, 295, 28822, 322, 341, 1558, 295, 257, 4675, 3765, 13, 50652, 50652, 1664, 286, 1029, 291, 281, 39456, 428, 16278, 490, 264, 3820, 30, 50804, 50804, 1436, 309, 311, 588, 24518, 13, 50877, 50877, 1436, 264, 10952, 307, 6183, 490, 264, 16278, 13, 51018, 51018, 400, 300, 311, 668, 588, 485, 51168, 51168, 1119, 309, 1101, 586, 30, 51344, 51344, 2704, 13, 51394, 51394, 286, 500, 380, 458, 13, 51444, 51444, 961, 311, 853, 13, 51494, 51494, 1033, 11, 718, 311, 853, 13, 51544, 51544], "temperature": 0.0, "avg_logprob": -0.2883797916797323, "compression_ratio": 1.5934579439252337, "no_speech_prob": 3.320880568935536e-05}, {"id": 1372, "seek": 553148, "start": 5531.48, "end": 5538.5199999999995, "text": " So the memory bank is a sort of nice way to get a large number of negatives without really", "tokens": [50364, 407, 264, 4675, 3765, 307, 257, 1333, 295, 1481, 636, 281, 483, 257, 2416, 1230, 295, 40019, 1553, 534, 50716, 50716, 5662, 264, 1333, 295, 14722, 11695, 13, 50872, 50872, 407, 437, 291, 360, 307, 291, 3531, 257, 4111, 8062, 680, 3256, 294, 1333, 295, 4675, 13, 51185, 51185, 400, 550, 291, 764, 300, 4111, 8062, 294, 428, 8712, 488, 2539, 13, 51358, 51358, 407, 1392, 11, 718, 311, 1333, 295, 700, 751, 466, 577, 291, 576, 360, 341, 2302, 3026, 75, 8657, 1553, 51705, 51705, 1228, 257, 4675, 3765, 13, 51775, 51775], "temperature": 0.0, "avg_logprob": -0.10973876150030838, "compression_ratio": 1.6916299559471366, "no_speech_prob": 5.203498290029529e-07}, {"id": 1373, "seek": 553148, "start": 5538.5199999999995, "end": 5541.639999999999, "text": " increasing the sort of compute requirement.", "tokens": [50364, 407, 264, 4675, 3765, 307, 257, 1333, 295, 1481, 636, 281, 483, 257, 2416, 1230, 295, 40019, 1553, 534, 50716, 50716, 5662, 264, 1333, 295, 14722, 11695, 13, 50872, 50872, 407, 437, 291, 360, 307, 291, 3531, 257, 4111, 8062, 680, 3256, 294, 1333, 295, 4675, 13, 51185, 51185, 400, 550, 291, 764, 300, 4111, 8062, 294, 428, 8712, 488, 2539, 13, 51358, 51358, 407, 1392, 11, 718, 311, 1333, 295, 700, 751, 466, 577, 291, 576, 360, 341, 2302, 3026, 75, 8657, 1553, 51705, 51705, 1228, 257, 4675, 3765, 13, 51775, 51775], "temperature": 0.0, "avg_logprob": -0.10973876150030838, "compression_ratio": 1.6916299559471366, "no_speech_prob": 5.203498290029529e-07}, {"id": 1374, "seek": 553148, "start": 5541.639999999999, "end": 5547.9, "text": " So what you do is you store a feature vector per image in sort of memory.", "tokens": [50364, 407, 264, 4675, 3765, 307, 257, 1333, 295, 1481, 636, 281, 483, 257, 2416, 1230, 295, 40019, 1553, 534, 50716, 50716, 5662, 264, 1333, 295, 14722, 11695, 13, 50872, 50872, 407, 437, 291, 360, 307, 291, 3531, 257, 4111, 8062, 680, 3256, 294, 1333, 295, 4675, 13, 51185, 51185, 400, 550, 291, 764, 300, 4111, 8062, 294, 428, 8712, 488, 2539, 13, 51358, 51358, 407, 1392, 11, 718, 311, 1333, 295, 700, 751, 466, 577, 291, 576, 360, 341, 2302, 3026, 75, 8657, 1553, 51705, 51705, 1228, 257, 4675, 3765, 13, 51775, 51775], "temperature": 0.0, "avg_logprob": -0.10973876150030838, "compression_ratio": 1.6916299559471366, "no_speech_prob": 5.203498290029529e-07}, {"id": 1375, "seek": 553148, "start": 5547.9, "end": 5551.36, "text": " And then you use that feature vector in your contrastive learning.", "tokens": [50364, 407, 264, 4675, 3765, 307, 257, 1333, 295, 1481, 636, 281, 483, 257, 2416, 1230, 295, 40019, 1553, 534, 50716, 50716, 5662, 264, 1333, 295, 14722, 11695, 13, 50872, 50872, 407, 437, 291, 360, 307, 291, 3531, 257, 4111, 8062, 680, 3256, 294, 1333, 295, 4675, 13, 51185, 51185, 400, 550, 291, 764, 300, 4111, 8062, 294, 428, 8712, 488, 2539, 13, 51358, 51358, 407, 1392, 11, 718, 311, 1333, 295, 700, 751, 466, 577, 291, 576, 360, 341, 2302, 3026, 75, 8657, 1553, 51705, 51705, 1228, 257, 4675, 3765, 13, 51775, 51775], "temperature": 0.0, "avg_logprob": -0.10973876150030838, "compression_ratio": 1.6916299559471366, "no_speech_prob": 5.203498290029529e-07}, {"id": 1376, "seek": 553148, "start": 5551.36, "end": 5558.299999999999, "text": " So okay, let's sort of first talk about how you would do this entire Perl setup without", "tokens": [50364, 407, 264, 4675, 3765, 307, 257, 1333, 295, 1481, 636, 281, 483, 257, 2416, 1230, 295, 40019, 1553, 534, 50716, 50716, 5662, 264, 1333, 295, 14722, 11695, 13, 50872, 50872, 407, 437, 291, 360, 307, 291, 3531, 257, 4111, 8062, 680, 3256, 294, 1333, 295, 4675, 13, 51185, 51185, 400, 550, 291, 764, 300, 4111, 8062, 294, 428, 8712, 488, 2539, 13, 51358, 51358, 407, 1392, 11, 718, 311, 1333, 295, 700, 751, 466, 577, 291, 576, 360, 341, 2302, 3026, 75, 8657, 1553, 51705, 51705, 1228, 257, 4675, 3765, 13, 51775, 51775], "temperature": 0.0, "avg_logprob": -0.10973876150030838, "compression_ratio": 1.6916299559471366, "no_speech_prob": 5.203498290029529e-07}, {"id": 1377, "seek": 553148, "start": 5558.299999999999, "end": 5559.7, "text": " using a memory bank.", "tokens": [50364, 407, 264, 4675, 3765, 307, 257, 1333, 295, 1481, 636, 281, 483, 257, 2416, 1230, 295, 40019, 1553, 534, 50716, 50716, 5662, 264, 1333, 295, 14722, 11695, 13, 50872, 50872, 407, 437, 291, 360, 307, 291, 3531, 257, 4111, 8062, 680, 3256, 294, 1333, 295, 4675, 13, 51185, 51185, 400, 550, 291, 764, 300, 4111, 8062, 294, 428, 8712, 488, 2539, 13, 51358, 51358, 407, 1392, 11, 718, 311, 1333, 295, 700, 751, 466, 577, 291, 576, 360, 341, 2302, 3026, 75, 8657, 1553, 51705, 51705, 1228, 257, 4675, 3765, 13, 51775, 51775], "temperature": 0.0, "avg_logprob": -0.10973876150030838, "compression_ratio": 1.6916299559471366, "no_speech_prob": 5.203498290029529e-07}, {"id": 1378, "seek": 555970, "start": 5559.7, "end": 5566.42, "text": " So you have an image i, you have an image it, you feed forward both of these images,", "tokens": [50364, 407, 291, 362, 364, 3256, 741, 11, 291, 362, 364, 3256, 309, 11, 291, 3154, 2128, 1293, 295, 613, 5267, 11, 50700, 50700, 291, 483, 257, 4111, 8062, 283, 295, 1932, 490, 264, 3380, 3256, 741, 11, 291, 483, 257, 4111, 290, 295, 9467, 51033, 51033, 490, 264, 16894, 9606, 11, 264, 26531, 294, 341, 1389, 13, 51271, 51271, 400, 437, 291, 528, 307, 264, 4122, 283, 293, 290, 281, 312, 2531, 13, 51440, 51440, 400, 291, 528, 4122, 490, 604, 661, 3256, 11, 370, 364, 38967, 3256, 11, 281, 1936, 312, 7802, 332, 2202, 13, 51775, 51775], "temperature": 0.0, "avg_logprob": -0.1514668083190918, "compression_ratio": 1.881188118811881, "no_speech_prob": 8.186244713215274e-07}, {"id": 1379, "seek": 555970, "start": 5566.42, "end": 5573.08, "text": " you get a feature vector f of vi from the original image i, you get a feature g of vit", "tokens": [50364, 407, 291, 362, 364, 3256, 741, 11, 291, 362, 364, 3256, 309, 11, 291, 3154, 2128, 1293, 295, 613, 5267, 11, 50700, 50700, 291, 483, 257, 4111, 8062, 283, 295, 1932, 490, 264, 3380, 3256, 741, 11, 291, 483, 257, 4111, 290, 295, 9467, 51033, 51033, 490, 264, 16894, 9606, 11, 264, 26531, 294, 341, 1389, 13, 51271, 51271, 400, 437, 291, 528, 307, 264, 4122, 283, 293, 290, 281, 312, 2531, 13, 51440, 51440, 400, 291, 528, 4122, 490, 604, 661, 3256, 11, 370, 364, 38967, 3256, 11, 281, 1936, 312, 7802, 332, 2202, 13, 51775, 51775], "temperature": 0.0, "avg_logprob": -0.1514668083190918, "compression_ratio": 1.881188118811881, "no_speech_prob": 8.186244713215274e-07}, {"id": 1380, "seek": 555970, "start": 5573.08, "end": 5577.84, "text": " from the transformed versions, the patches in this case.", "tokens": [50364, 407, 291, 362, 364, 3256, 741, 11, 291, 362, 364, 3256, 309, 11, 291, 3154, 2128, 1293, 295, 613, 5267, 11, 50700, 50700, 291, 483, 257, 4111, 8062, 283, 295, 1932, 490, 264, 3380, 3256, 741, 11, 291, 483, 257, 4111, 290, 295, 9467, 51033, 51033, 490, 264, 16894, 9606, 11, 264, 26531, 294, 341, 1389, 13, 51271, 51271, 400, 437, 291, 528, 307, 264, 4122, 283, 293, 290, 281, 312, 2531, 13, 51440, 51440, 400, 291, 528, 4122, 490, 604, 661, 3256, 11, 370, 364, 38967, 3256, 11, 281, 1936, 312, 7802, 332, 2202, 13, 51775, 51775], "temperature": 0.0, "avg_logprob": -0.1514668083190918, "compression_ratio": 1.881188118811881, "no_speech_prob": 8.186244713215274e-07}, {"id": 1381, "seek": 555970, "start": 5577.84, "end": 5581.22, "text": " And what you want is the features f and g to be similar.", "tokens": [50364, 407, 291, 362, 364, 3256, 741, 11, 291, 362, 364, 3256, 309, 11, 291, 3154, 2128, 1293, 295, 613, 5267, 11, 50700, 50700, 291, 483, 257, 4111, 8062, 283, 295, 1932, 490, 264, 3380, 3256, 741, 11, 291, 483, 257, 4111, 290, 295, 9467, 51033, 51033, 490, 264, 16894, 9606, 11, 264, 26531, 294, 341, 1389, 13, 51271, 51271, 400, 437, 291, 528, 307, 264, 4122, 283, 293, 290, 281, 312, 2531, 13, 51440, 51440, 400, 291, 528, 4122, 490, 604, 661, 3256, 11, 370, 364, 38967, 3256, 11, 281, 1936, 312, 7802, 332, 2202, 13, 51775, 51775], "temperature": 0.0, "avg_logprob": -0.1514668083190918, "compression_ratio": 1.881188118811881, "no_speech_prob": 8.186244713215274e-07}, {"id": 1382, "seek": 555970, "start": 5581.22, "end": 5587.92, "text": " And you want features from any other image, so an unrelated image, to basically be dissimilar.", "tokens": [50364, 407, 291, 362, 364, 3256, 741, 11, 291, 362, 364, 3256, 309, 11, 291, 3154, 2128, 1293, 295, 613, 5267, 11, 50700, 50700, 291, 483, 257, 4111, 8062, 283, 295, 1932, 490, 264, 3380, 3256, 741, 11, 291, 483, 257, 4111, 290, 295, 9467, 51033, 51033, 490, 264, 16894, 9606, 11, 264, 26531, 294, 341, 1389, 13, 51271, 51271, 400, 437, 291, 528, 307, 264, 4122, 283, 293, 290, 281, 312, 2531, 13, 51440, 51440, 400, 291, 528, 4122, 490, 604, 661, 3256, 11, 370, 364, 38967, 3256, 11, 281, 1936, 312, 7802, 332, 2202, 13, 51775, 51775], "temperature": 0.0, "avg_logprob": -0.1514668083190918, "compression_ratio": 1.881188118811881, "no_speech_prob": 8.186244713215274e-07}, {"id": 1383, "seek": 558792, "start": 5587.92, "end": 5595.36, "text": " So in this case, what we now can do is rather than if we want a lot of negatives, we would", "tokens": [50364, 407, 294, 341, 1389, 11, 437, 321, 586, 393, 360, 307, 2831, 813, 498, 321, 528, 257, 688, 295, 40019, 11, 321, 576, 50736, 50736, 534, 528, 257, 688, 295, 613, 3671, 5267, 281, 312, 3154, 2128, 412, 264, 912, 565, 11, 597, 50940, 50940, 534, 1355, 300, 291, 643, 257, 588, 2416, 15245, 2744, 281, 312, 1075, 281, 360, 341, 13, 51128, 51128, 400, 295, 1164, 11, 257, 2416, 15245, 2744, 1355, 307, 406, 534, 1333, 295, 665, 11, 307, 406, 1944, 322, 51428, 51428, 584, 257, 5567, 2372, 295, 18407, 4675, 13, 51568, 51568, 407, 264, 636, 281, 1333, 295, 360, 300, 307, 281, 764, 746, 1219, 257, 4675, 3765, 13, 51754, 51754], "temperature": 0.0, "avg_logprob": -0.11174743195884249, "compression_ratio": 1.7588932806324111, "no_speech_prob": 1.39253484121582e-06}, {"id": 1384, "seek": 558792, "start": 5595.36, "end": 5599.4400000000005, "text": " really want a lot of these negative images to be feed forward at the same time, which", "tokens": [50364, 407, 294, 341, 1389, 11, 437, 321, 586, 393, 360, 307, 2831, 813, 498, 321, 528, 257, 688, 295, 40019, 11, 321, 576, 50736, 50736, 534, 528, 257, 688, 295, 613, 3671, 5267, 281, 312, 3154, 2128, 412, 264, 912, 565, 11, 597, 50940, 50940, 534, 1355, 300, 291, 643, 257, 588, 2416, 15245, 2744, 281, 312, 1075, 281, 360, 341, 13, 51128, 51128, 400, 295, 1164, 11, 257, 2416, 15245, 2744, 1355, 307, 406, 534, 1333, 295, 665, 11, 307, 406, 1944, 322, 51428, 51428, 584, 257, 5567, 2372, 295, 18407, 4675, 13, 51568, 51568, 407, 264, 636, 281, 1333, 295, 360, 300, 307, 281, 764, 746, 1219, 257, 4675, 3765, 13, 51754, 51754], "temperature": 0.0, "avg_logprob": -0.11174743195884249, "compression_ratio": 1.7588932806324111, "no_speech_prob": 1.39253484121582e-06}, {"id": 1385, "seek": 558792, "start": 5599.4400000000005, "end": 5603.2, "text": " really means that you need a very large batch size to be able to do this.", "tokens": [50364, 407, 294, 341, 1389, 11, 437, 321, 586, 393, 360, 307, 2831, 813, 498, 321, 528, 257, 688, 295, 40019, 11, 321, 576, 50736, 50736, 534, 528, 257, 688, 295, 613, 3671, 5267, 281, 312, 3154, 2128, 412, 264, 912, 565, 11, 597, 50940, 50940, 534, 1355, 300, 291, 643, 257, 588, 2416, 15245, 2744, 281, 312, 1075, 281, 360, 341, 13, 51128, 51128, 400, 295, 1164, 11, 257, 2416, 15245, 2744, 1355, 307, 406, 534, 1333, 295, 665, 11, 307, 406, 1944, 322, 51428, 51428, 584, 257, 5567, 2372, 295, 18407, 4675, 13, 51568, 51568, 407, 264, 636, 281, 1333, 295, 360, 300, 307, 281, 764, 746, 1219, 257, 4675, 3765, 13, 51754, 51754], "temperature": 0.0, "avg_logprob": -0.11174743195884249, "compression_ratio": 1.7588932806324111, "no_speech_prob": 1.39253484121582e-06}, {"id": 1386, "seek": 558792, "start": 5603.2, "end": 5609.2, "text": " And of course, a large batch size means is not really sort of good, is not possible on", "tokens": [50364, 407, 294, 341, 1389, 11, 437, 321, 586, 393, 360, 307, 2831, 813, 498, 321, 528, 257, 688, 295, 40019, 11, 321, 576, 50736, 50736, 534, 528, 257, 688, 295, 613, 3671, 5267, 281, 312, 3154, 2128, 412, 264, 912, 565, 11, 597, 50940, 50940, 534, 1355, 300, 291, 643, 257, 588, 2416, 15245, 2744, 281, 312, 1075, 281, 360, 341, 13, 51128, 51128, 400, 295, 1164, 11, 257, 2416, 15245, 2744, 1355, 307, 406, 534, 1333, 295, 665, 11, 307, 406, 1944, 322, 51428, 51428, 584, 257, 5567, 2372, 295, 18407, 4675, 13, 51568, 51568, 407, 264, 636, 281, 1333, 295, 360, 300, 307, 281, 764, 746, 1219, 257, 4675, 3765, 13, 51754, 51754], "temperature": 0.0, "avg_logprob": -0.11174743195884249, "compression_ratio": 1.7588932806324111, "no_speech_prob": 1.39253484121582e-06}, {"id": 1387, "seek": 558792, "start": 5609.2, "end": 5612.0, "text": " say a limited amount of GPU memory.", "tokens": [50364, 407, 294, 341, 1389, 11, 437, 321, 586, 393, 360, 307, 2831, 813, 498, 321, 528, 257, 688, 295, 40019, 11, 321, 576, 50736, 50736, 534, 528, 257, 688, 295, 613, 3671, 5267, 281, 312, 3154, 2128, 412, 264, 912, 565, 11, 597, 50940, 50940, 534, 1355, 300, 291, 643, 257, 588, 2416, 15245, 2744, 281, 312, 1075, 281, 360, 341, 13, 51128, 51128, 400, 295, 1164, 11, 257, 2416, 15245, 2744, 1355, 307, 406, 534, 1333, 295, 665, 11, 307, 406, 1944, 322, 51428, 51428, 584, 257, 5567, 2372, 295, 18407, 4675, 13, 51568, 51568, 407, 264, 636, 281, 1333, 295, 360, 300, 307, 281, 764, 746, 1219, 257, 4675, 3765, 13, 51754, 51754], "temperature": 0.0, "avg_logprob": -0.11174743195884249, "compression_ratio": 1.7588932806324111, "no_speech_prob": 1.39253484121582e-06}, {"id": 1388, "seek": 558792, "start": 5612.0, "end": 5615.72, "text": " So the way to sort of do that is to use something called a memory bank.", "tokens": [50364, 407, 294, 341, 1389, 11, 437, 321, 586, 393, 360, 307, 2831, 813, 498, 321, 528, 257, 688, 295, 40019, 11, 321, 576, 50736, 50736, 534, 528, 257, 688, 295, 613, 3671, 5267, 281, 312, 3154, 2128, 412, 264, 912, 565, 11, 597, 50940, 50940, 534, 1355, 300, 291, 643, 257, 588, 2416, 15245, 2744, 281, 312, 1075, 281, 360, 341, 13, 51128, 51128, 400, 295, 1164, 11, 257, 2416, 15245, 2744, 1355, 307, 406, 534, 1333, 295, 665, 11, 307, 406, 1944, 322, 51428, 51428, 584, 257, 5567, 2372, 295, 18407, 4675, 13, 51568, 51568, 407, 264, 636, 281, 1333, 295, 360, 300, 307, 281, 764, 746, 1219, 257, 4675, 3765, 13, 51754, 51754], "temperature": 0.0, "avg_logprob": -0.11174743195884249, "compression_ratio": 1.7588932806324111, "no_speech_prob": 1.39253484121582e-06}, {"id": 1389, "seek": 561572, "start": 5615.72, "end": 5620.72, "text": " So what this memory bank does is that it stores a feature vector for each of the images in", "tokens": [50364, 407, 437, 341, 4675, 3765, 775, 307, 300, 309, 9512, 257, 4111, 8062, 337, 1184, 295, 264, 5267, 294, 50614, 50614, 428, 1412, 992, 13, 50686, 50686, 400, 562, 291, 434, 884, 8712, 488, 2539, 11, 2831, 813, 1228, 4111, 18875, 11, 584, 490, 50900, 50900, 257, 819, 3671, 3256, 11, 1333, 295, 257, 819, 3256, 294, 428, 15245, 11, 291, 393, 445, 30254, 51160, 51160, 613, 4122, 490, 257, 4675, 13, 51294, 51294, 509, 393, 445, 30254, 4122, 295, 604, 661, 517, 7191, 3904, 292, 3256, 490, 264, 4675, 11, 293, 291, 51494, 51494, 393, 445, 15802, 300, 281, 2042, 8712, 488, 2539, 13, 51678, 51678, 407, 294, 3026, 75, 11, 321, 6666, 264, 10024, 666, 732, 3166, 13, 51848, 51848], "temperature": 0.0, "avg_logprob": -0.16796842698127992, "compression_ratio": 1.8892988929889298, "no_speech_prob": 1.9033477656194009e-06}, {"id": 1390, "seek": 561572, "start": 5620.72, "end": 5622.16, "text": " your data set.", "tokens": [50364, 407, 437, 341, 4675, 3765, 775, 307, 300, 309, 9512, 257, 4111, 8062, 337, 1184, 295, 264, 5267, 294, 50614, 50614, 428, 1412, 992, 13, 50686, 50686, 400, 562, 291, 434, 884, 8712, 488, 2539, 11, 2831, 813, 1228, 4111, 18875, 11, 584, 490, 50900, 50900, 257, 819, 3671, 3256, 11, 1333, 295, 257, 819, 3256, 294, 428, 15245, 11, 291, 393, 445, 30254, 51160, 51160, 613, 4122, 490, 257, 4675, 13, 51294, 51294, 509, 393, 445, 30254, 4122, 295, 604, 661, 517, 7191, 3904, 292, 3256, 490, 264, 4675, 11, 293, 291, 51494, 51494, 393, 445, 15802, 300, 281, 2042, 8712, 488, 2539, 13, 51678, 51678, 407, 294, 3026, 75, 11, 321, 6666, 264, 10024, 666, 732, 3166, 13, 51848, 51848], "temperature": 0.0, "avg_logprob": -0.16796842698127992, "compression_ratio": 1.8892988929889298, "no_speech_prob": 1.9033477656194009e-06}, {"id": 1391, "seek": 561572, "start": 5622.16, "end": 5626.4400000000005, "text": " And when you're doing contrastive learning, rather than using feature vectors, say from", "tokens": [50364, 407, 437, 341, 4675, 3765, 775, 307, 300, 309, 9512, 257, 4111, 8062, 337, 1184, 295, 264, 5267, 294, 50614, 50614, 428, 1412, 992, 13, 50686, 50686, 400, 562, 291, 434, 884, 8712, 488, 2539, 11, 2831, 813, 1228, 4111, 18875, 11, 584, 490, 50900, 50900, 257, 819, 3671, 3256, 11, 1333, 295, 257, 819, 3256, 294, 428, 15245, 11, 291, 393, 445, 30254, 51160, 51160, 613, 4122, 490, 257, 4675, 13, 51294, 51294, 509, 393, 445, 30254, 4122, 295, 604, 661, 517, 7191, 3904, 292, 3256, 490, 264, 4675, 11, 293, 291, 51494, 51494, 393, 445, 15802, 300, 281, 2042, 8712, 488, 2539, 13, 51678, 51678, 407, 294, 3026, 75, 11, 321, 6666, 264, 10024, 666, 732, 3166, 13, 51848, 51848], "temperature": 0.0, "avg_logprob": -0.16796842698127992, "compression_ratio": 1.8892988929889298, "no_speech_prob": 1.9033477656194009e-06}, {"id": 1392, "seek": 561572, "start": 5626.4400000000005, "end": 5631.64, "text": " a different negative image, sort of a different image in your batch, you can just retrieve", "tokens": [50364, 407, 437, 341, 4675, 3765, 775, 307, 300, 309, 9512, 257, 4111, 8062, 337, 1184, 295, 264, 5267, 294, 50614, 50614, 428, 1412, 992, 13, 50686, 50686, 400, 562, 291, 434, 884, 8712, 488, 2539, 11, 2831, 813, 1228, 4111, 18875, 11, 584, 490, 50900, 50900, 257, 819, 3671, 3256, 11, 1333, 295, 257, 819, 3256, 294, 428, 15245, 11, 291, 393, 445, 30254, 51160, 51160, 613, 4122, 490, 257, 4675, 13, 51294, 51294, 509, 393, 445, 30254, 4122, 295, 604, 661, 517, 7191, 3904, 292, 3256, 490, 264, 4675, 11, 293, 291, 51494, 51494, 393, 445, 15802, 300, 281, 2042, 8712, 488, 2539, 13, 51678, 51678, 407, 294, 3026, 75, 11, 321, 6666, 264, 10024, 666, 732, 3166, 13, 51848, 51848], "temperature": 0.0, "avg_logprob": -0.16796842698127992, "compression_ratio": 1.8892988929889298, "no_speech_prob": 1.9033477656194009e-06}, {"id": 1393, "seek": 561572, "start": 5631.64, "end": 5634.320000000001, "text": " these features from a memory.", "tokens": [50364, 407, 437, 341, 4675, 3765, 775, 307, 300, 309, 9512, 257, 4111, 8062, 337, 1184, 295, 264, 5267, 294, 50614, 50614, 428, 1412, 992, 13, 50686, 50686, 400, 562, 291, 434, 884, 8712, 488, 2539, 11, 2831, 813, 1228, 4111, 18875, 11, 584, 490, 50900, 50900, 257, 819, 3671, 3256, 11, 1333, 295, 257, 819, 3256, 294, 428, 15245, 11, 291, 393, 445, 30254, 51160, 51160, 613, 4122, 490, 257, 4675, 13, 51294, 51294, 509, 393, 445, 30254, 4122, 295, 604, 661, 517, 7191, 3904, 292, 3256, 490, 264, 4675, 11, 293, 291, 51494, 51494, 393, 445, 15802, 300, 281, 2042, 8712, 488, 2539, 13, 51678, 51678, 407, 294, 3026, 75, 11, 321, 6666, 264, 10024, 666, 732, 3166, 13, 51848, 51848], "temperature": 0.0, "avg_logprob": -0.16796842698127992, "compression_ratio": 1.8892988929889298, "no_speech_prob": 1.9033477656194009e-06}, {"id": 1394, "seek": 561572, "start": 5634.320000000001, "end": 5638.320000000001, "text": " You can just retrieve features of any other unglittered image from the memory, and you", "tokens": [50364, 407, 437, 341, 4675, 3765, 775, 307, 300, 309, 9512, 257, 4111, 8062, 337, 1184, 295, 264, 5267, 294, 50614, 50614, 428, 1412, 992, 13, 50686, 50686, 400, 562, 291, 434, 884, 8712, 488, 2539, 11, 2831, 813, 1228, 4111, 18875, 11, 584, 490, 50900, 50900, 257, 819, 3671, 3256, 11, 1333, 295, 257, 819, 3256, 294, 428, 15245, 11, 291, 393, 445, 30254, 51160, 51160, 613, 4122, 490, 257, 4675, 13, 51294, 51294, 509, 393, 445, 30254, 4122, 295, 604, 661, 517, 7191, 3904, 292, 3256, 490, 264, 4675, 11, 293, 291, 51494, 51494, 393, 445, 15802, 300, 281, 2042, 8712, 488, 2539, 13, 51678, 51678, 407, 294, 3026, 75, 11, 321, 6666, 264, 10024, 666, 732, 3166, 13, 51848, 51848], "temperature": 0.0, "avg_logprob": -0.16796842698127992, "compression_ratio": 1.8892988929889298, "no_speech_prob": 1.9033477656194009e-06}, {"id": 1395, "seek": 561572, "start": 5638.320000000001, "end": 5642.0, "text": " can just substitute that to perform contrastive learning.", "tokens": [50364, 407, 437, 341, 4675, 3765, 775, 307, 300, 309, 9512, 257, 4111, 8062, 337, 1184, 295, 264, 5267, 294, 50614, 50614, 428, 1412, 992, 13, 50686, 50686, 400, 562, 291, 434, 884, 8712, 488, 2539, 11, 2831, 813, 1228, 4111, 18875, 11, 584, 490, 50900, 50900, 257, 819, 3671, 3256, 11, 1333, 295, 257, 819, 3256, 294, 428, 15245, 11, 291, 393, 445, 30254, 51160, 51160, 613, 4122, 490, 257, 4675, 13, 51294, 51294, 509, 393, 445, 30254, 4122, 295, 604, 661, 517, 7191, 3904, 292, 3256, 490, 264, 4675, 11, 293, 291, 51494, 51494, 393, 445, 15802, 300, 281, 2042, 8712, 488, 2539, 13, 51678, 51678, 407, 294, 3026, 75, 11, 321, 6666, 264, 10024, 666, 732, 3166, 13, 51848, 51848], "temperature": 0.0, "avg_logprob": -0.16796842698127992, "compression_ratio": 1.8892988929889298, "no_speech_prob": 1.9033477656194009e-06}, {"id": 1396, "seek": 561572, "start": 5642.0, "end": 5645.400000000001, "text": " So in Perl, we divided the objective into two parts.", "tokens": [50364, 407, 437, 341, 4675, 3765, 775, 307, 300, 309, 9512, 257, 4111, 8062, 337, 1184, 295, 264, 5267, 294, 50614, 50614, 428, 1412, 992, 13, 50686, 50686, 400, 562, 291, 434, 884, 8712, 488, 2539, 11, 2831, 813, 1228, 4111, 18875, 11, 584, 490, 50900, 50900, 257, 819, 3671, 3256, 11, 1333, 295, 257, 819, 3256, 294, 428, 15245, 11, 291, 393, 445, 30254, 51160, 51160, 613, 4122, 490, 257, 4675, 13, 51294, 51294, 509, 393, 445, 30254, 4122, 295, 604, 661, 517, 7191, 3904, 292, 3256, 490, 264, 4675, 11, 293, 291, 51494, 51494, 393, 445, 15802, 300, 281, 2042, 8712, 488, 2539, 13, 51678, 51678, 407, 294, 3026, 75, 11, 321, 6666, 264, 10024, 666, 732, 3166, 13, 51848, 51848], "temperature": 0.0, "avg_logprob": -0.16796842698127992, "compression_ratio": 1.8892988929889298, "no_speech_prob": 1.9033477656194009e-06}, {"id": 1397, "seek": 564540, "start": 5645.4, "end": 5651.639999999999, "text": " There was a contrastive term to bring the feature vector from the transformed image,", "tokens": [50364, 821, 390, 257, 8712, 488, 1433, 281, 1565, 264, 4111, 8062, 490, 264, 16894, 3256, 11, 50676, 50676, 370, 290, 295, 1932, 11, 2531, 281, 264, 10290, 300, 321, 362, 294, 264, 4675, 11, 370, 275, 295, 741, 13, 51008, 51008, 400, 14138, 11, 321, 362, 257, 1150, 8712, 488, 1433, 300, 9898, 281, 1565, 264, 4111, 283, 295, 51232, 51232, 1932, 1998, 281, 264, 4111, 10290, 300, 321, 362, 294, 4675, 13, 51434, 51434, 407, 4476, 11, 290, 307, 885, 7373, 1998, 281, 2752, 11, 293, 283, 307, 885, 7373, 1998, 281, 2752, 13, 51757, 51757], "temperature": 0.0, "avg_logprob": -0.10885161582869712, "compression_ratio": 2.0412371134020617, "no_speech_prob": 6.747904535586713e-06}, {"id": 1398, "seek": 564540, "start": 5651.639999999999, "end": 5658.28, "text": " so g of vi, similar to the representation that we have in the memory, so m of i.", "tokens": [50364, 821, 390, 257, 8712, 488, 1433, 281, 1565, 264, 4111, 8062, 490, 264, 16894, 3256, 11, 50676, 50676, 370, 290, 295, 1932, 11, 2531, 281, 264, 10290, 300, 321, 362, 294, 264, 4675, 11, 370, 275, 295, 741, 13, 51008, 51008, 400, 14138, 11, 321, 362, 257, 1150, 8712, 488, 1433, 300, 9898, 281, 1565, 264, 4111, 283, 295, 51232, 51232, 1932, 1998, 281, 264, 4111, 10290, 300, 321, 362, 294, 4675, 13, 51434, 51434, 407, 4476, 11, 290, 307, 885, 7373, 1998, 281, 2752, 11, 293, 283, 307, 885, 7373, 1998, 281, 2752, 13, 51757, 51757], "temperature": 0.0, "avg_logprob": -0.10885161582869712, "compression_ratio": 2.0412371134020617, "no_speech_prob": 6.747904535586713e-06}, {"id": 1399, "seek": 564540, "start": 5658.28, "end": 5662.759999999999, "text": " And similarly, we have a second contrastive term that tries to bring the feature f of", "tokens": [50364, 821, 390, 257, 8712, 488, 1433, 281, 1565, 264, 4111, 8062, 490, 264, 16894, 3256, 11, 50676, 50676, 370, 290, 295, 1932, 11, 2531, 281, 264, 10290, 300, 321, 362, 294, 264, 4675, 11, 370, 275, 295, 741, 13, 51008, 51008, 400, 14138, 11, 321, 362, 257, 1150, 8712, 488, 1433, 300, 9898, 281, 1565, 264, 4111, 283, 295, 51232, 51232, 1932, 1998, 281, 264, 4111, 10290, 300, 321, 362, 294, 4675, 13, 51434, 51434, 407, 4476, 11, 290, 307, 885, 7373, 1998, 281, 2752, 11, 293, 283, 307, 885, 7373, 1998, 281, 2752, 13, 51757, 51757], "temperature": 0.0, "avg_logprob": -0.10885161582869712, "compression_ratio": 2.0412371134020617, "no_speech_prob": 6.747904535586713e-06}, {"id": 1400, "seek": 564540, "start": 5662.759999999999, "end": 5666.799999999999, "text": " vi close to the feature representation that we have in memory.", "tokens": [50364, 821, 390, 257, 8712, 488, 1433, 281, 1565, 264, 4111, 8062, 490, 264, 16894, 3256, 11, 50676, 50676, 370, 290, 295, 1932, 11, 2531, 281, 264, 10290, 300, 321, 362, 294, 264, 4675, 11, 370, 275, 295, 741, 13, 51008, 51008, 400, 14138, 11, 321, 362, 257, 1150, 8712, 488, 1433, 300, 9898, 281, 1565, 264, 4111, 283, 295, 51232, 51232, 1932, 1998, 281, 264, 4111, 10290, 300, 321, 362, 294, 4675, 13, 51434, 51434, 407, 4476, 11, 290, 307, 885, 7373, 1998, 281, 2752, 11, 293, 283, 307, 885, 7373, 1998, 281, 2752, 13, 51757, 51757], "temperature": 0.0, "avg_logprob": -0.10885161582869712, "compression_ratio": 2.0412371134020617, "no_speech_prob": 6.747904535586713e-06}, {"id": 1401, "seek": 564540, "start": 5666.799999999999, "end": 5673.259999999999, "text": " So essentially, g is being pulled close to mi, and f is being pulled close to mi.", "tokens": [50364, 821, 390, 257, 8712, 488, 1433, 281, 1565, 264, 4111, 8062, 490, 264, 16894, 3256, 11, 50676, 50676, 370, 290, 295, 1932, 11, 2531, 281, 264, 10290, 300, 321, 362, 294, 264, 4675, 11, 370, 275, 295, 741, 13, 51008, 51008, 400, 14138, 11, 321, 362, 257, 1150, 8712, 488, 1433, 300, 9898, 281, 1565, 264, 4111, 283, 295, 51232, 51232, 1932, 1998, 281, 264, 4111, 10290, 300, 321, 362, 294, 4675, 13, 51434, 51434, 407, 4476, 11, 290, 307, 885, 7373, 1998, 281, 2752, 11, 293, 283, 307, 885, 7373, 1998, 281, 2752, 13, 51757, 51757], "temperature": 0.0, "avg_logprob": -0.10885161582869712, "compression_ratio": 2.0412371134020617, "no_speech_prob": 6.747904535586713e-06}, {"id": 1402, "seek": 567326, "start": 5673.26, "end": 5677.6, "text": " So by transitivity, f and g are being pulled close to one another.", "tokens": [50364, 407, 538, 17976, 4253, 11, 283, 293, 290, 366, 885, 7373, 1998, 281, 472, 1071, 13, 50581, 50581, 400, 264, 1778, 337, 29279, 341, 484, 390, 309, 1333, 295, 48384, 3097, 11, 293, 321, 645, 50813, 50813, 1075, 281, 3847, 1553, 884, 341, 11, 1936, 264, 3097, 576, 406, 534, 41881, 13, 51113, 51113, 400, 370, 538, 29279, 341, 484, 666, 732, 6422, 11, 2831, 813, 884, 2047, 8712, 488, 2539, 51373, 51373, 1296, 283, 293, 290, 11, 321, 645, 1075, 281, 31870, 3097, 293, 767, 483, 309, 1364, 13, 51698, 51698], "temperature": 0.0, "avg_logprob": -0.10187098320494307, "compression_ratio": 1.7982456140350878, "no_speech_prob": 1.653672711654508e-06}, {"id": 1403, "seek": 567326, "start": 5677.6, "end": 5682.24, "text": " And the reason for separating this out was it sort of stabilized training, and we were", "tokens": [50364, 407, 538, 17976, 4253, 11, 283, 293, 290, 366, 885, 7373, 1998, 281, 472, 1071, 13, 50581, 50581, 400, 264, 1778, 337, 29279, 341, 484, 390, 309, 1333, 295, 48384, 3097, 11, 293, 321, 645, 50813, 50813, 1075, 281, 3847, 1553, 884, 341, 11, 1936, 264, 3097, 576, 406, 534, 41881, 13, 51113, 51113, 400, 370, 538, 29279, 341, 484, 666, 732, 6422, 11, 2831, 813, 884, 2047, 8712, 488, 2539, 51373, 51373, 1296, 283, 293, 290, 11, 321, 645, 1075, 281, 31870, 3097, 293, 767, 483, 309, 1364, 13, 51698, 51698], "temperature": 0.0, "avg_logprob": -0.10187098320494307, "compression_ratio": 1.7982456140350878, "no_speech_prob": 1.653672711654508e-06}, {"id": 1404, "seek": 567326, "start": 5682.24, "end": 5688.24, "text": " able to train without doing this, basically the training would not really converge.", "tokens": [50364, 407, 538, 17976, 4253, 11, 283, 293, 290, 366, 885, 7373, 1998, 281, 472, 1071, 13, 50581, 50581, 400, 264, 1778, 337, 29279, 341, 484, 390, 309, 1333, 295, 48384, 3097, 11, 293, 321, 645, 50813, 50813, 1075, 281, 3847, 1553, 884, 341, 11, 1936, 264, 3097, 576, 406, 534, 41881, 13, 51113, 51113, 400, 370, 538, 29279, 341, 484, 666, 732, 6422, 11, 2831, 813, 884, 2047, 8712, 488, 2539, 51373, 51373, 1296, 283, 293, 290, 11, 321, 645, 1075, 281, 31870, 3097, 293, 767, 483, 309, 1364, 13, 51698, 51698], "temperature": 0.0, "avg_logprob": -0.10187098320494307, "compression_ratio": 1.7982456140350878, "no_speech_prob": 1.653672711654508e-06}, {"id": 1405, "seek": 567326, "start": 5688.24, "end": 5693.4400000000005, "text": " And so by separating this out into two forms, rather than doing direct contrastive learning", "tokens": [50364, 407, 538, 17976, 4253, 11, 283, 293, 290, 366, 885, 7373, 1998, 281, 472, 1071, 13, 50581, 50581, 400, 264, 1778, 337, 29279, 341, 484, 390, 309, 1333, 295, 48384, 3097, 11, 293, 321, 645, 50813, 50813, 1075, 281, 3847, 1553, 884, 341, 11, 1936, 264, 3097, 576, 406, 534, 41881, 13, 51113, 51113, 400, 370, 538, 29279, 341, 484, 666, 732, 6422, 11, 2831, 813, 884, 2047, 8712, 488, 2539, 51373, 51373, 1296, 283, 293, 290, 11, 321, 645, 1075, 281, 31870, 3097, 293, 767, 483, 309, 1364, 13, 51698, 51698], "temperature": 0.0, "avg_logprob": -0.10187098320494307, "compression_ratio": 1.7982456140350878, "no_speech_prob": 1.653672711654508e-06}, {"id": 1406, "seek": 567326, "start": 5693.4400000000005, "end": 5699.9400000000005, "text": " between f and g, we were able to stabilize training and actually get it working.", "tokens": [50364, 407, 538, 17976, 4253, 11, 283, 293, 290, 366, 885, 7373, 1998, 281, 472, 1071, 13, 50581, 50581, 400, 264, 1778, 337, 29279, 341, 484, 390, 309, 1333, 295, 48384, 3097, 11, 293, 321, 645, 50813, 50813, 1075, 281, 3847, 1553, 884, 341, 11, 1936, 264, 3097, 576, 406, 534, 41881, 13, 51113, 51113, 400, 370, 538, 29279, 341, 484, 666, 732, 6422, 11, 2831, 813, 884, 2047, 8712, 488, 2539, 51373, 51373, 1296, 283, 293, 290, 11, 321, 645, 1075, 281, 31870, 3097, 293, 767, 483, 309, 1364, 13, 51698, 51698], "temperature": 0.0, "avg_logprob": -0.10187098320494307, "compression_ratio": 1.7982456140350878, "no_speech_prob": 1.653672711654508e-06}, {"id": 1407, "seek": 569994, "start": 5699.94, "end": 5707.12, "text": " So the way to evaluate this is basically by standard sort of pre-training evaluation setup,", "tokens": [50364, 407, 264, 636, 281, 13059, 341, 307, 1936, 538, 3832, 1333, 295, 659, 12, 17227, 1760, 13344, 8657, 11, 50723, 50723, 370, 5003, 2539, 11, 689, 321, 393, 659, 12, 83, 7146, 322, 5267, 1553, 16949, 13, 50942, 50942, 407, 264, 3832, 321, 366, 884, 341, 307, 281, 747, 29903, 31890, 11, 3507, 1314, 264, 16949, 11, 293, 11865, 51161, 51161, 309, 307, 2693, 12879, 24420, 11, 293, 550, 13059, 1228, 11, 584, 11, 1577, 2489, 15164, 420, 3097, 257, 8213, 51475, 51475, 1508, 9902, 13, 51547, 51547, 440, 1150, 551, 321, 630, 390, 611, 1500, 3026, 75, 293, 1080, 13956, 1287, 281, 3256, 37870, 51817, 51817], "temperature": 0.0, "avg_logprob": -0.12723582381502205, "compression_ratio": 1.7341269841269842, "no_speech_prob": 1.8161829302698607e-06}, {"id": 1408, "seek": 569994, "start": 5707.12, "end": 5711.5, "text": " so transfer learning, where we can pre-train on images without labels.", "tokens": [50364, 407, 264, 636, 281, 13059, 341, 307, 1936, 538, 3832, 1333, 295, 659, 12, 17227, 1760, 13344, 8657, 11, 50723, 50723, 370, 5003, 2539, 11, 689, 321, 393, 659, 12, 83, 7146, 322, 5267, 1553, 16949, 13, 50942, 50942, 407, 264, 3832, 321, 366, 884, 341, 307, 281, 747, 29903, 31890, 11, 3507, 1314, 264, 16949, 11, 293, 11865, 51161, 51161, 309, 307, 2693, 12879, 24420, 11, 293, 550, 13059, 1228, 11, 584, 11, 1577, 2489, 15164, 420, 3097, 257, 8213, 51475, 51475, 1508, 9902, 13, 51547, 51547, 440, 1150, 551, 321, 630, 390, 611, 1500, 3026, 75, 293, 1080, 13956, 1287, 281, 3256, 37870, 51817, 51817], "temperature": 0.0, "avg_logprob": -0.12723582381502205, "compression_ratio": 1.7341269841269842, "no_speech_prob": 1.8161829302698607e-06}, {"id": 1409, "seek": 569994, "start": 5711.5, "end": 5715.879999999999, "text": " So the standard we are doing this is to take ImageNet, throw away the labels, and pretend", "tokens": [50364, 407, 264, 636, 281, 13059, 341, 307, 1936, 538, 3832, 1333, 295, 659, 12, 17227, 1760, 13344, 8657, 11, 50723, 50723, 370, 5003, 2539, 11, 689, 321, 393, 659, 12, 83, 7146, 322, 5267, 1553, 16949, 13, 50942, 50942, 407, 264, 3832, 321, 366, 884, 341, 307, 281, 747, 29903, 31890, 11, 3507, 1314, 264, 16949, 11, 293, 11865, 51161, 51161, 309, 307, 2693, 12879, 24420, 11, 293, 550, 13059, 1228, 11, 584, 11, 1577, 2489, 15164, 420, 3097, 257, 8213, 51475, 51475, 1508, 9902, 13, 51547, 51547, 440, 1150, 551, 321, 630, 390, 611, 1500, 3026, 75, 293, 1080, 13956, 1287, 281, 3256, 37870, 51817, 51817], "temperature": 0.0, "avg_logprob": -0.12723582381502205, "compression_ratio": 1.7341269841269842, "no_speech_prob": 1.8161829302698607e-06}, {"id": 1410, "seek": 569994, "start": 5715.879999999999, "end": 5722.16, "text": " it is unsupervised, and then evaluate using, say, full fine tuning or training a linear", "tokens": [50364, 407, 264, 636, 281, 13059, 341, 307, 1936, 538, 3832, 1333, 295, 659, 12, 17227, 1760, 13344, 8657, 11, 50723, 50723, 370, 5003, 2539, 11, 689, 321, 393, 659, 12, 83, 7146, 322, 5267, 1553, 16949, 13, 50942, 50942, 407, 264, 3832, 321, 366, 884, 341, 307, 281, 747, 29903, 31890, 11, 3507, 1314, 264, 16949, 11, 293, 11865, 51161, 51161, 309, 307, 2693, 12879, 24420, 11, 293, 550, 13059, 1228, 11, 584, 11, 1577, 2489, 15164, 420, 3097, 257, 8213, 51475, 51475, 1508, 9902, 13, 51547, 51547, 440, 1150, 551, 321, 630, 390, 611, 1500, 3026, 75, 293, 1080, 13956, 1287, 281, 3256, 37870, 51817, 51817], "temperature": 0.0, "avg_logprob": -0.12723582381502205, "compression_ratio": 1.7341269841269842, "no_speech_prob": 1.8161829302698607e-06}, {"id": 1411, "seek": 569994, "start": 5722.16, "end": 5723.599999999999, "text": " classifier.", "tokens": [50364, 407, 264, 636, 281, 13059, 341, 307, 1936, 538, 3832, 1333, 295, 659, 12, 17227, 1760, 13344, 8657, 11, 50723, 50723, 370, 5003, 2539, 11, 689, 321, 393, 659, 12, 83, 7146, 322, 5267, 1553, 16949, 13, 50942, 50942, 407, 264, 3832, 321, 366, 884, 341, 307, 281, 747, 29903, 31890, 11, 3507, 1314, 264, 16949, 11, 293, 11865, 51161, 51161, 309, 307, 2693, 12879, 24420, 11, 293, 550, 13059, 1228, 11, 584, 11, 1577, 2489, 15164, 420, 3097, 257, 8213, 51475, 51475, 1508, 9902, 13, 51547, 51547, 440, 1150, 551, 321, 630, 390, 611, 1500, 3026, 75, 293, 1080, 13956, 1287, 281, 3256, 37870, 51817, 51817], "temperature": 0.0, "avg_logprob": -0.12723582381502205, "compression_ratio": 1.7341269841269842, "no_speech_prob": 1.8161829302698607e-06}, {"id": 1412, "seek": 569994, "start": 5723.599999999999, "end": 5729.0, "text": " The second thing we did was also test Perl and its robustness to image distributions", "tokens": [50364, 407, 264, 636, 281, 13059, 341, 307, 1936, 538, 3832, 1333, 295, 659, 12, 17227, 1760, 13344, 8657, 11, 50723, 50723, 370, 5003, 2539, 11, 689, 321, 393, 659, 12, 83, 7146, 322, 5267, 1553, 16949, 13, 50942, 50942, 407, 264, 3832, 321, 366, 884, 341, 307, 281, 747, 29903, 31890, 11, 3507, 1314, 264, 16949, 11, 293, 11865, 51161, 51161, 309, 307, 2693, 12879, 24420, 11, 293, 550, 13059, 1228, 11, 584, 11, 1577, 2489, 15164, 420, 3097, 257, 8213, 51475, 51475, 1508, 9902, 13, 51547, 51547, 440, 1150, 551, 321, 630, 390, 611, 1500, 3026, 75, 293, 1080, 13956, 1287, 281, 3256, 37870, 51817, 51817], "temperature": 0.0, "avg_logprob": -0.12723582381502205, "compression_ratio": 1.7341269841269842, "no_speech_prob": 1.8161829302698607e-06}, {"id": 1413, "seek": 572900, "start": 5729.0, "end": 5731.28, "text": " by training it on in-the-wild images.", "tokens": [50364, 538, 3097, 309, 322, 294, 12, 3322, 12, 86, 793, 5267, 13, 50478, 50478, 407, 321, 445, 1890, 472, 8213, 3256, 16979, 490, 3235, 618, 81, 13, 50634, 50634, 407, 341, 307, 264, 398, 37, 11717, 28872, 13, 50746, 50746, 400, 550, 321, 1936, 659, 12, 17227, 2001, 322, 613, 5267, 293, 550, 10332, 5003, 2539, 51024, 51024, 322, 819, 42856, 13, 51244, 51244, 286, 632, 257, 1168, 466, 264, 3026, 75, 3170, 11, 466, 264, 4675, 3765, 13, 51524, 51524], "temperature": 0.0, "avg_logprob": -0.22835765976503672, "compression_ratio": 1.5, "no_speech_prob": 2.726430693655857e-06}, {"id": 1414, "seek": 572900, "start": 5731.28, "end": 5734.4, "text": " So we just took one linear image randomly from Flickr.", "tokens": [50364, 538, 3097, 309, 322, 294, 12, 3322, 12, 86, 793, 5267, 13, 50478, 50478, 407, 321, 445, 1890, 472, 8213, 3256, 16979, 490, 3235, 618, 81, 13, 50634, 50634, 407, 341, 307, 264, 398, 37, 11717, 28872, 13, 50746, 50746, 400, 550, 321, 1936, 659, 12, 17227, 2001, 322, 613, 5267, 293, 550, 10332, 5003, 2539, 51024, 51024, 322, 819, 42856, 13, 51244, 51244, 286, 632, 257, 1168, 466, 264, 3026, 75, 3170, 11, 466, 264, 4675, 3765, 13, 51524, 51524], "temperature": 0.0, "avg_logprob": -0.22835765976503672, "compression_ratio": 1.5, "no_speech_prob": 2.726430693655857e-06}, {"id": 1415, "seek": 572900, "start": 5734.4, "end": 5736.64, "text": " So this is the YFCC dataset.", "tokens": [50364, 538, 3097, 309, 322, 294, 12, 3322, 12, 86, 793, 5267, 13, 50478, 50478, 407, 321, 445, 1890, 472, 8213, 3256, 16979, 490, 3235, 618, 81, 13, 50634, 50634, 407, 341, 307, 264, 398, 37, 11717, 28872, 13, 50746, 50746, 400, 550, 321, 1936, 659, 12, 17227, 2001, 322, 613, 5267, 293, 550, 10332, 5003, 2539, 51024, 51024, 322, 819, 42856, 13, 51244, 51244, 286, 632, 257, 1168, 466, 264, 3026, 75, 3170, 11, 466, 264, 4675, 3765, 13, 51524, 51524], "temperature": 0.0, "avg_logprob": -0.22835765976503672, "compression_ratio": 1.5, "no_speech_prob": 2.726430693655857e-06}, {"id": 1416, "seek": 572900, "start": 5736.64, "end": 5742.2, "text": " And then we basically pre-trained on these images and then performed transfer learning", "tokens": [50364, 538, 3097, 309, 322, 294, 12, 3322, 12, 86, 793, 5267, 13, 50478, 50478, 407, 321, 445, 1890, 472, 8213, 3256, 16979, 490, 3235, 618, 81, 13, 50634, 50634, 407, 341, 307, 264, 398, 37, 11717, 28872, 13, 50746, 50746, 400, 550, 321, 1936, 659, 12, 17227, 2001, 322, 613, 5267, 293, 550, 10332, 5003, 2539, 51024, 51024, 322, 819, 42856, 13, 51244, 51244, 286, 632, 257, 1168, 466, 264, 3026, 75, 3170, 11, 466, 264, 4675, 3765, 13, 51524, 51524], "temperature": 0.0, "avg_logprob": -0.22835765976503672, "compression_ratio": 1.5, "no_speech_prob": 2.726430693655857e-06}, {"id": 1417, "seek": 572900, "start": 5742.2, "end": 5746.6, "text": " on different datasets.", "tokens": [50364, 538, 3097, 309, 322, 294, 12, 3322, 12, 86, 793, 5267, 13, 50478, 50478, 407, 321, 445, 1890, 472, 8213, 3256, 16979, 490, 3235, 618, 81, 13, 50634, 50634, 407, 341, 307, 264, 398, 37, 11717, 28872, 13, 50746, 50746, 400, 550, 321, 1936, 659, 12, 17227, 2001, 322, 613, 5267, 293, 550, 10332, 5003, 2539, 51024, 51024, 322, 819, 42856, 13, 51244, 51244, 286, 632, 257, 1168, 466, 264, 3026, 75, 3170, 11, 466, 264, 4675, 3765, 13, 51524, 51524], "temperature": 0.0, "avg_logprob": -0.22835765976503672, "compression_ratio": 1.5, "no_speech_prob": 2.726430693655857e-06}, {"id": 1418, "seek": 572900, "start": 5746.6, "end": 5752.2, "text": " I had a question about the Perl method, about the memory bank.", "tokens": [50364, 538, 3097, 309, 322, 294, 12, 3322, 12, 86, 793, 5267, 13, 50478, 50478, 407, 321, 445, 1890, 472, 8213, 3256, 16979, 490, 3235, 618, 81, 13, 50634, 50634, 407, 341, 307, 264, 398, 37, 11717, 28872, 13, 50746, 50746, 400, 550, 321, 1936, 659, 12, 17227, 2001, 322, 613, 5267, 293, 550, 10332, 5003, 2539, 51024, 51024, 322, 819, 42856, 13, 51244, 51244, 286, 632, 257, 1168, 466, 264, 3026, 75, 3170, 11, 466, 264, 4675, 3765, 13, 51524, 51524], "temperature": 0.0, "avg_logprob": -0.22835765976503672, "compression_ratio": 1.5, "no_speech_prob": 2.726430693655857e-06}, {"id": 1419, "seek": 575220, "start": 5752.2, "end": 5759.96, "text": " Wouldn't those feature representations stored in the memory bank be out of date?", "tokens": [50364, 26291, 380, 729, 4111, 33358, 12187, 294, 264, 4675, 3765, 312, 484, 295, 4002, 30, 50752, 50752, 865, 11, 370, 436, 360, 352, 257, 707, 857, 484, 295, 4002, 11, 457, 294, 3124, 11, 309, 534, 775, 406, 652, 300, 51050, 51050, 709, 295, 257, 2649, 13, 51152, 51152, 407, 456, 311, 257, 1729, 636, 295, 25113, 552, 1228, 485, 51348, 51348, 407, 275, 295, 741, 307, 257, 2684, 4274, 295, 264, 10290, 283, 11, 293, 300, 2684, 4274, 11, 4878, 309, 311, 51668, 51668], "temperature": 0.0, "avg_logprob": -0.24751419856630522, "compression_ratio": 1.6208530805687205, "no_speech_prob": 2.5464554710197262e-05}, {"id": 1420, "seek": 575220, "start": 5759.96, "end": 5765.92, "text": " Yeah, so they do go a little bit out of date, but in practice, it really does not make that", "tokens": [50364, 26291, 380, 729, 4111, 33358, 12187, 294, 264, 4675, 3765, 312, 484, 295, 4002, 30, 50752, 50752, 865, 11, 370, 436, 360, 352, 257, 707, 857, 484, 295, 4002, 11, 457, 294, 3124, 11, 309, 534, 775, 406, 652, 300, 51050, 51050, 709, 295, 257, 2649, 13, 51152, 51152, 407, 456, 311, 257, 1729, 636, 295, 25113, 552, 1228, 485, 51348, 51348, 407, 275, 295, 741, 307, 257, 2684, 4274, 295, 264, 10290, 283, 11, 293, 300, 2684, 4274, 11, 4878, 309, 311, 51668, 51668], "temperature": 0.0, "avg_logprob": -0.24751419856630522, "compression_ratio": 1.6208530805687205, "no_speech_prob": 2.5464554710197262e-05}, {"id": 1421, "seek": 575220, "start": 5765.92, "end": 5767.96, "text": " much of a difference.", "tokens": [50364, 26291, 380, 729, 4111, 33358, 12187, 294, 264, 4675, 3765, 312, 484, 295, 4002, 30, 50752, 50752, 865, 11, 370, 436, 360, 352, 257, 707, 857, 484, 295, 4002, 11, 457, 294, 3124, 11, 309, 534, 775, 406, 652, 300, 51050, 51050, 709, 295, 257, 2649, 13, 51152, 51152, 407, 456, 311, 257, 1729, 636, 295, 25113, 552, 1228, 485, 51348, 51348, 407, 275, 295, 741, 307, 257, 2684, 4274, 295, 264, 10290, 283, 11, 293, 300, 2684, 4274, 11, 4878, 309, 311, 51668, 51668], "temperature": 0.0, "avg_logprob": -0.24751419856630522, "compression_ratio": 1.6208530805687205, "no_speech_prob": 2.5464554710197262e-05}, {"id": 1422, "seek": 575220, "start": 5767.96, "end": 5771.88, "text": " So there's a particular way of updating them using...", "tokens": [50364, 26291, 380, 729, 4111, 33358, 12187, 294, 264, 4675, 3765, 312, 484, 295, 4002, 30, 50752, 50752, 865, 11, 370, 436, 360, 352, 257, 707, 857, 484, 295, 4002, 11, 457, 294, 3124, 11, 309, 534, 775, 406, 652, 300, 51050, 51050, 709, 295, 257, 2649, 13, 51152, 51152, 407, 456, 311, 257, 1729, 636, 295, 25113, 552, 1228, 485, 51348, 51348, 407, 275, 295, 741, 307, 257, 2684, 4274, 295, 264, 10290, 283, 11, 293, 300, 2684, 4274, 11, 4878, 309, 311, 51668, 51668], "temperature": 0.0, "avg_logprob": -0.24751419856630522, "compression_ratio": 1.6208530805687205, "no_speech_prob": 2.5464554710197262e-05}, {"id": 1423, "seek": 575220, "start": 5771.88, "end": 5778.28, "text": " So m of i is a moving average of the representation f, and that moving average, although it's", "tokens": [50364, 26291, 380, 729, 4111, 33358, 12187, 294, 264, 4675, 3765, 312, 484, 295, 4002, 30, 50752, 50752, 865, 11, 370, 436, 360, 352, 257, 707, 857, 484, 295, 4002, 11, 457, 294, 3124, 11, 309, 534, 775, 406, 652, 300, 51050, 51050, 709, 295, 257, 2649, 13, 51152, 51152, 407, 456, 311, 257, 1729, 636, 295, 25113, 552, 1228, 485, 51348, 51348, 407, 275, 295, 741, 307, 257, 2684, 4274, 295, 264, 10290, 283, 11, 293, 300, 2684, 4274, 11, 4878, 309, 311, 51668, 51668], "temperature": 0.0, "avg_logprob": -0.24751419856630522, "compression_ratio": 1.6208530805687205, "no_speech_prob": 2.5464554710197262e-05}, {"id": 1424, "seek": 577828, "start": 5778.28, "end": 5785.8, "text": " stale, it actually does not matter a lot in practice, you can still continue to use them.", "tokens": [50364, 342, 1220, 11, 309, 767, 775, 406, 1871, 257, 688, 294, 3124, 11, 291, 393, 920, 2354, 281, 764, 552, 13, 50740, 50740, 407, 11926, 411, 286, 3938, 1401, 264, 3035, 3998, 34, 5797, 11, 597, 1143, 257, 2603, 15245, 2744, 11, 411, 51018, 51018, 1649, 11, 1360, 420, 746, 13, 51092, 51092, 407, 1228, 264, 4675, 3765, 3109, 293, 1242, 613, 1649, 11, 1360, 5110, 294, 472, 4470, 2445, 11, 51458, 51458, 307, 300, 1944, 30, 51508, 51508, 1079, 11, 370, 264, 1333, 295, 3998, 34, 5797, 636, 295, 884, 309, 534, 7029, 257, 2416, 15245, 2744, 570, 51838, 51838], "temperature": 0.0, "avg_logprob": -0.21554017298429914, "compression_ratio": 1.5742971887550201, "no_speech_prob": 1.0952850061585195e-05}, {"id": 1425, "seek": 577828, "start": 5785.8, "end": 5791.36, "text": " So assuming like I recently read the paper SimClear, which used a huge batch size, like", "tokens": [50364, 342, 1220, 11, 309, 767, 775, 406, 1871, 257, 688, 294, 3124, 11, 291, 393, 920, 2354, 281, 764, 552, 13, 50740, 50740, 407, 11926, 411, 286, 3938, 1401, 264, 3035, 3998, 34, 5797, 11, 597, 1143, 257, 2603, 15245, 2744, 11, 411, 51018, 51018, 1649, 11, 1360, 420, 746, 13, 51092, 51092, 407, 1228, 264, 4675, 3765, 3109, 293, 1242, 613, 1649, 11, 1360, 5110, 294, 472, 4470, 2445, 11, 51458, 51458, 307, 300, 1944, 30, 51508, 51508, 1079, 11, 370, 264, 1333, 295, 3998, 34, 5797, 636, 295, 884, 309, 534, 7029, 257, 2416, 15245, 2744, 570, 51838, 51838], "temperature": 0.0, "avg_logprob": -0.21554017298429914, "compression_ratio": 1.5742971887550201, "no_speech_prob": 1.0952850061585195e-05}, {"id": 1426, "seek": 577828, "start": 5791.36, "end": 5792.84, "text": " 8,000 or something.", "tokens": [50364, 342, 1220, 11, 309, 767, 775, 406, 1871, 257, 688, 294, 3124, 11, 291, 393, 920, 2354, 281, 764, 552, 13, 50740, 50740, 407, 11926, 411, 286, 3938, 1401, 264, 3035, 3998, 34, 5797, 11, 597, 1143, 257, 2603, 15245, 2744, 11, 411, 51018, 51018, 1649, 11, 1360, 420, 746, 13, 51092, 51092, 407, 1228, 264, 4675, 3765, 3109, 293, 1242, 613, 1649, 11, 1360, 5110, 294, 472, 4470, 2445, 11, 51458, 51458, 307, 300, 1944, 30, 51508, 51508, 1079, 11, 370, 264, 1333, 295, 3998, 34, 5797, 636, 295, 884, 309, 534, 7029, 257, 2416, 15245, 2744, 570, 51838, 51838], "temperature": 0.0, "avg_logprob": -0.21554017298429914, "compression_ratio": 1.5742971887550201, "no_speech_prob": 1.0952850061585195e-05}, {"id": 1427, "seek": 577828, "start": 5792.84, "end": 5800.16, "text": " So using the memory bank approach and getting these 8,000 examples in one loss function,", "tokens": [50364, 342, 1220, 11, 309, 767, 775, 406, 1871, 257, 688, 294, 3124, 11, 291, 393, 920, 2354, 281, 764, 552, 13, 50740, 50740, 407, 11926, 411, 286, 3938, 1401, 264, 3035, 3998, 34, 5797, 11, 597, 1143, 257, 2603, 15245, 2744, 11, 411, 51018, 51018, 1649, 11, 1360, 420, 746, 13, 51092, 51092, 407, 1228, 264, 4675, 3765, 3109, 293, 1242, 613, 1649, 11, 1360, 5110, 294, 472, 4470, 2445, 11, 51458, 51458, 307, 300, 1944, 30, 51508, 51508, 1079, 11, 370, 264, 1333, 295, 3998, 34, 5797, 636, 295, 884, 309, 534, 7029, 257, 2416, 15245, 2744, 570, 51838, 51838], "temperature": 0.0, "avg_logprob": -0.21554017298429914, "compression_ratio": 1.5742971887550201, "no_speech_prob": 1.0952850061585195e-05}, {"id": 1428, "seek": 577828, "start": 5800.16, "end": 5801.16, "text": " is that possible?", "tokens": [50364, 342, 1220, 11, 309, 767, 775, 406, 1871, 257, 688, 294, 3124, 11, 291, 393, 920, 2354, 281, 764, 552, 13, 50740, 50740, 407, 11926, 411, 286, 3938, 1401, 264, 3035, 3998, 34, 5797, 11, 597, 1143, 257, 2603, 15245, 2744, 11, 411, 51018, 51018, 1649, 11, 1360, 420, 746, 13, 51092, 51092, 407, 1228, 264, 4675, 3765, 3109, 293, 1242, 613, 1649, 11, 1360, 5110, 294, 472, 4470, 2445, 11, 51458, 51458, 307, 300, 1944, 30, 51508, 51508, 1079, 11, 370, 264, 1333, 295, 3998, 34, 5797, 636, 295, 884, 309, 534, 7029, 257, 2416, 15245, 2744, 570, 51838, 51838], "temperature": 0.0, "avg_logprob": -0.21554017298429914, "compression_ratio": 1.5742971887550201, "no_speech_prob": 1.0952850061585195e-05}, {"id": 1429, "seek": 577828, "start": 5801.16, "end": 5807.759999999999, "text": " Yes, so the sort of SimClear way of doing it really requires a large batch size because", "tokens": [50364, 342, 1220, 11, 309, 767, 775, 406, 1871, 257, 688, 294, 3124, 11, 291, 393, 920, 2354, 281, 764, 552, 13, 50740, 50740, 407, 11926, 411, 286, 3938, 1401, 264, 3035, 3998, 34, 5797, 11, 597, 1143, 257, 2603, 15245, 2744, 11, 411, 51018, 51018, 1649, 11, 1360, 420, 746, 13, 51092, 51092, 407, 1228, 264, 4675, 3765, 3109, 293, 1242, 613, 1649, 11, 1360, 5110, 294, 472, 4470, 2445, 11, 51458, 51458, 307, 300, 1944, 30, 51508, 51508, 1079, 11, 370, 264, 1333, 295, 3998, 34, 5797, 636, 295, 884, 309, 534, 7029, 257, 2416, 15245, 2744, 570, 51838, 51838], "temperature": 0.0, "avg_logprob": -0.21554017298429914, "compression_ratio": 1.5742971887550201, "no_speech_prob": 1.0952850061585195e-05}, {"id": 1430, "seek": 580776, "start": 5807.76, "end": 5810.96, "text": " you're getting negatives from different images in the same batch.", "tokens": [50364, 291, 434, 1242, 40019, 490, 819, 5267, 294, 264, 912, 15245, 13, 50524, 50524, 13813, 498, 291, 764, 746, 411, 264, 4675, 3765, 11, 291, 534, 360, 406, 643, 257, 2416, 15245, 50710, 50710, 2744, 13, 50760, 50760, 407, 291, 393, 3847, 341, 365, 411, 8858, 5267, 294, 257, 15245, 570, 439, 264, 40019, 366, 534, 50986, 50986, 1348, 490, 264, 4675, 3765, 11, 597, 775, 406, 534, 3651, 291, 281, 360, 3866, 3154, 30126, 13, 51266, 51266, 1033, 11, 1309, 291, 13, 51436, 51436, 759, 291, 434, 1228, 4675, 3765, 11, 550, 291, 393, 380, 646, 48256, 807, 264, 3671, 1365, 13, 51661, 51661, 407, 307, 300, 406, 257, 1154, 30, 51844, 51844], "temperature": 0.0, "avg_logprob": -0.21043368043570682, "compression_ratio": 1.7752808988764044, "no_speech_prob": 6.854049388493877e-06}, {"id": 1431, "seek": 580776, "start": 5810.96, "end": 5814.68, "text": " Whereas if you use something like the memory bank, you really do not need a large batch", "tokens": [50364, 291, 434, 1242, 40019, 490, 819, 5267, 294, 264, 912, 15245, 13, 50524, 50524, 13813, 498, 291, 764, 746, 411, 264, 4675, 3765, 11, 291, 534, 360, 406, 643, 257, 2416, 15245, 50710, 50710, 2744, 13, 50760, 50760, 407, 291, 393, 3847, 341, 365, 411, 8858, 5267, 294, 257, 15245, 570, 439, 264, 40019, 366, 534, 50986, 50986, 1348, 490, 264, 4675, 3765, 11, 597, 775, 406, 534, 3651, 291, 281, 360, 3866, 3154, 30126, 13, 51266, 51266, 1033, 11, 1309, 291, 13, 51436, 51436, 759, 291, 434, 1228, 4675, 3765, 11, 550, 291, 393, 380, 646, 48256, 807, 264, 3671, 1365, 13, 51661, 51661, 407, 307, 300, 406, 257, 1154, 30, 51844, 51844], "temperature": 0.0, "avg_logprob": -0.21043368043570682, "compression_ratio": 1.7752808988764044, "no_speech_prob": 6.854049388493877e-06}, {"id": 1432, "seek": 580776, "start": 5814.68, "end": 5815.68, "text": " size.", "tokens": [50364, 291, 434, 1242, 40019, 490, 819, 5267, 294, 264, 912, 15245, 13, 50524, 50524, 13813, 498, 291, 764, 746, 411, 264, 4675, 3765, 11, 291, 534, 360, 406, 643, 257, 2416, 15245, 50710, 50710, 2744, 13, 50760, 50760, 407, 291, 393, 3847, 341, 365, 411, 8858, 5267, 294, 257, 15245, 570, 439, 264, 40019, 366, 534, 50986, 50986, 1348, 490, 264, 4675, 3765, 11, 597, 775, 406, 534, 3651, 291, 281, 360, 3866, 3154, 30126, 13, 51266, 51266, 1033, 11, 1309, 291, 13, 51436, 51436, 759, 291, 434, 1228, 4675, 3765, 11, 550, 291, 393, 380, 646, 48256, 807, 264, 3671, 1365, 13, 51661, 51661, 407, 307, 300, 406, 257, 1154, 30, 51844, 51844], "temperature": 0.0, "avg_logprob": -0.21043368043570682, "compression_ratio": 1.7752808988764044, "no_speech_prob": 6.854049388493877e-06}, {"id": 1433, "seek": 580776, "start": 5815.68, "end": 5820.2, "text": " So you can train this with like 32 images in a batch because all the negatives are really", "tokens": [50364, 291, 434, 1242, 40019, 490, 819, 5267, 294, 264, 912, 15245, 13, 50524, 50524, 13813, 498, 291, 764, 746, 411, 264, 4675, 3765, 11, 291, 534, 360, 406, 643, 257, 2416, 15245, 50710, 50710, 2744, 13, 50760, 50760, 407, 291, 393, 3847, 341, 365, 411, 8858, 5267, 294, 257, 15245, 570, 439, 264, 40019, 366, 534, 50986, 50986, 1348, 490, 264, 4675, 3765, 11, 597, 775, 406, 534, 3651, 291, 281, 360, 3866, 3154, 30126, 13, 51266, 51266, 1033, 11, 1309, 291, 13, 51436, 51436, 759, 291, 434, 1228, 4675, 3765, 11, 550, 291, 393, 380, 646, 48256, 807, 264, 3671, 1365, 13, 51661, 51661, 407, 307, 300, 406, 257, 1154, 30, 51844, 51844], "temperature": 0.0, "avg_logprob": -0.21043368043570682, "compression_ratio": 1.7752808988764044, "no_speech_prob": 6.854049388493877e-06}, {"id": 1434, "seek": 580776, "start": 5820.2, "end": 5825.8, "text": " coming from the memory bank, which does not really require you to do multiple feed forwards.", "tokens": [50364, 291, 434, 1242, 40019, 490, 819, 5267, 294, 264, 912, 15245, 13, 50524, 50524, 13813, 498, 291, 764, 746, 411, 264, 4675, 3765, 11, 291, 534, 360, 406, 643, 257, 2416, 15245, 50710, 50710, 2744, 13, 50760, 50760, 407, 291, 393, 3847, 341, 365, 411, 8858, 5267, 294, 257, 15245, 570, 439, 264, 40019, 366, 534, 50986, 50986, 1348, 490, 264, 4675, 3765, 11, 597, 775, 406, 534, 3651, 291, 281, 360, 3866, 3154, 30126, 13, 51266, 51266, 1033, 11, 1309, 291, 13, 51436, 51436, 759, 291, 434, 1228, 4675, 3765, 11, 550, 291, 393, 380, 646, 48256, 807, 264, 3671, 1365, 13, 51661, 51661, 407, 307, 300, 406, 257, 1154, 30, 51844, 51844], "temperature": 0.0, "avg_logprob": -0.21043368043570682, "compression_ratio": 1.7752808988764044, "no_speech_prob": 6.854049388493877e-06}, {"id": 1435, "seek": 580776, "start": 5825.8, "end": 5829.2, "text": " Okay, thank you.", "tokens": [50364, 291, 434, 1242, 40019, 490, 819, 5267, 294, 264, 912, 15245, 13, 50524, 50524, 13813, 498, 291, 764, 746, 411, 264, 4675, 3765, 11, 291, 534, 360, 406, 643, 257, 2416, 15245, 50710, 50710, 2744, 13, 50760, 50760, 407, 291, 393, 3847, 341, 365, 411, 8858, 5267, 294, 257, 15245, 570, 439, 264, 40019, 366, 534, 50986, 50986, 1348, 490, 264, 4675, 3765, 11, 597, 775, 406, 534, 3651, 291, 281, 360, 3866, 3154, 30126, 13, 51266, 51266, 1033, 11, 1309, 291, 13, 51436, 51436, 759, 291, 434, 1228, 4675, 3765, 11, 550, 291, 393, 380, 646, 48256, 807, 264, 3671, 1365, 13, 51661, 51661, 407, 307, 300, 406, 257, 1154, 30, 51844, 51844], "temperature": 0.0, "avg_logprob": -0.21043368043570682, "compression_ratio": 1.7752808988764044, "no_speech_prob": 6.854049388493877e-06}, {"id": 1436, "seek": 580776, "start": 5829.2, "end": 5833.7, "text": " If you're using memory bank, then you can't back propagate through the negative example.", "tokens": [50364, 291, 434, 1242, 40019, 490, 819, 5267, 294, 264, 912, 15245, 13, 50524, 50524, 13813, 498, 291, 764, 746, 411, 264, 4675, 3765, 11, 291, 534, 360, 406, 643, 257, 2416, 15245, 50710, 50710, 2744, 13, 50760, 50760, 407, 291, 393, 3847, 341, 365, 411, 8858, 5267, 294, 257, 15245, 570, 439, 264, 40019, 366, 534, 50986, 50986, 1348, 490, 264, 4675, 3765, 11, 597, 775, 406, 534, 3651, 291, 281, 360, 3866, 3154, 30126, 13, 51266, 51266, 1033, 11, 1309, 291, 13, 51436, 51436, 759, 291, 434, 1228, 4675, 3765, 11, 550, 291, 393, 380, 646, 48256, 807, 264, 3671, 1365, 13, 51661, 51661, 407, 307, 300, 406, 257, 1154, 30, 51844, 51844], "temperature": 0.0, "avg_logprob": -0.21043368043570682, "compression_ratio": 1.7752808988764044, "no_speech_prob": 6.854049388493877e-06}, {"id": 1437, "seek": 580776, "start": 5833.7, "end": 5837.360000000001, "text": " So is that not a problem?", "tokens": [50364, 291, 434, 1242, 40019, 490, 819, 5267, 294, 264, 912, 15245, 13, 50524, 50524, 13813, 498, 291, 764, 746, 411, 264, 4675, 3765, 11, 291, 534, 360, 406, 643, 257, 2416, 15245, 50710, 50710, 2744, 13, 50760, 50760, 407, 291, 393, 3847, 341, 365, 411, 8858, 5267, 294, 257, 15245, 570, 439, 264, 40019, 366, 534, 50986, 50986, 1348, 490, 264, 4675, 3765, 11, 597, 775, 406, 534, 3651, 291, 281, 360, 3866, 3154, 30126, 13, 51266, 51266, 1033, 11, 1309, 291, 13, 51436, 51436, 759, 291, 434, 1228, 4675, 3765, 11, 550, 291, 393, 380, 646, 48256, 807, 264, 3671, 1365, 13, 51661, 51661, 407, 307, 300, 406, 257, 1154, 30, 51844, 51844], "temperature": 0.0, "avg_logprob": -0.21043368043570682, "compression_ratio": 1.7752808988764044, "no_speech_prob": 6.854049388493877e-06}, {"id": 1438, "seek": 583736, "start": 5837.36, "end": 5841.099999999999, "text": " I mean, it does not create that much of a problem really.", "tokens": [50364, 286, 914, 11, 309, 775, 406, 1884, 300, 709, 295, 257, 1154, 534, 13, 50551, 50551, 407, 300, 390, 472, 551, 286, 390, 5804, 466, 382, 731, 13, 50724, 50724, 407, 294, 264, 5883, 9606, 11, 321, 630, 853, 746, 597, 390, 411, 1228, 257, 4833, 15245, 2744, 13, 50980, 50980, 583, 562, 321, 16858, 281, 746, 411, 264, 4675, 3765, 11, 309, 630, 406, 534, 5407, 3389, 11, 51254, 51254, 588, 11, 588, 707, 11, 588, 709, 294, 264, 11004, 294, 3389, 13, 51482, 51482, 1033, 11, 604, 24002, 983, 300, 311, 264, 1389, 30, 51704, 51704], "temperature": 0.0, "avg_logprob": -0.21149641036987304, "compression_ratio": 1.6851063829787234, "no_speech_prob": 1.892365798994433e-05}, {"id": 1439, "seek": 583736, "start": 5841.099999999999, "end": 5844.5599999999995, "text": " So that was one thing I was worried about as well.", "tokens": [50364, 286, 914, 11, 309, 775, 406, 1884, 300, 709, 295, 257, 1154, 534, 13, 50551, 50551, 407, 300, 390, 472, 551, 286, 390, 5804, 466, 382, 731, 13, 50724, 50724, 407, 294, 264, 5883, 9606, 11, 321, 630, 853, 746, 597, 390, 411, 1228, 257, 4833, 15245, 2744, 13, 50980, 50980, 583, 562, 321, 16858, 281, 746, 411, 264, 4675, 3765, 11, 309, 630, 406, 534, 5407, 3389, 11, 51254, 51254, 588, 11, 588, 707, 11, 588, 709, 294, 264, 11004, 294, 3389, 13, 51482, 51482, 1033, 11, 604, 24002, 983, 300, 311, 264, 1389, 30, 51704, 51704], "temperature": 0.0, "avg_logprob": -0.21149641036987304, "compression_ratio": 1.6851063829787234, "no_speech_prob": 1.892365798994433e-05}, {"id": 1440, "seek": 583736, "start": 5844.5599999999995, "end": 5849.679999999999, "text": " So in the initial versions, we did try something which was like using a larger batch size.", "tokens": [50364, 286, 914, 11, 309, 775, 406, 1884, 300, 709, 295, 257, 1154, 534, 13, 50551, 50551, 407, 300, 390, 472, 551, 286, 390, 5804, 466, 382, 731, 13, 50724, 50724, 407, 294, 264, 5883, 9606, 11, 321, 630, 853, 746, 597, 390, 411, 1228, 257, 4833, 15245, 2744, 13, 50980, 50980, 583, 562, 321, 16858, 281, 746, 411, 264, 4675, 3765, 11, 309, 630, 406, 534, 5407, 3389, 11, 51254, 51254, 588, 11, 588, 707, 11, 588, 709, 294, 264, 11004, 294, 3389, 13, 51482, 51482, 1033, 11, 604, 24002, 983, 300, 311, 264, 1389, 30, 51704, 51704], "temperature": 0.0, "avg_logprob": -0.21149641036987304, "compression_ratio": 1.6851063829787234, "no_speech_prob": 1.892365798994433e-05}, {"id": 1441, "seek": 583736, "start": 5849.679999999999, "end": 5855.16, "text": " But when we switched to something like the memory bank, it did not really reduce performance,", "tokens": [50364, 286, 914, 11, 309, 775, 406, 1884, 300, 709, 295, 257, 1154, 534, 13, 50551, 50551, 407, 300, 390, 472, 551, 286, 390, 5804, 466, 382, 731, 13, 50724, 50724, 407, 294, 264, 5883, 9606, 11, 321, 630, 853, 746, 597, 390, 411, 1228, 257, 4833, 15245, 2744, 13, 50980, 50980, 583, 562, 321, 16858, 281, 746, 411, 264, 4675, 3765, 11, 309, 630, 406, 534, 5407, 3389, 11, 51254, 51254, 588, 11, 588, 707, 11, 588, 709, 294, 264, 11004, 294, 3389, 13, 51482, 51482, 1033, 11, 604, 24002, 983, 300, 311, 264, 1389, 30, 51704, 51704], "temperature": 0.0, "avg_logprob": -0.21149641036987304, "compression_ratio": 1.6851063829787234, "no_speech_prob": 1.892365798994433e-05}, {"id": 1442, "seek": 583736, "start": 5855.16, "end": 5859.719999999999, "text": " very, very little, very much in the reduction in performance.", "tokens": [50364, 286, 914, 11, 309, 775, 406, 1884, 300, 709, 295, 257, 1154, 534, 13, 50551, 50551, 407, 300, 390, 472, 551, 286, 390, 5804, 466, 382, 731, 13, 50724, 50724, 407, 294, 264, 5883, 9606, 11, 321, 630, 853, 746, 597, 390, 411, 1228, 257, 4833, 15245, 2744, 13, 50980, 50980, 583, 562, 321, 16858, 281, 746, 411, 264, 4675, 3765, 11, 309, 630, 406, 534, 5407, 3389, 11, 51254, 51254, 588, 11, 588, 707, 11, 588, 709, 294, 264, 11004, 294, 3389, 13, 51482, 51482, 1033, 11, 604, 24002, 983, 300, 311, 264, 1389, 30, 51704, 51704], "temperature": 0.0, "avg_logprob": -0.21149641036987304, "compression_ratio": 1.6851063829787234, "no_speech_prob": 1.892365798994433e-05}, {"id": 1443, "seek": 583736, "start": 5859.719999999999, "end": 5864.16, "text": " Okay, any intuition why that's the case?", "tokens": [50364, 286, 914, 11, 309, 775, 406, 1884, 300, 709, 295, 257, 1154, 534, 13, 50551, 50551, 407, 300, 390, 472, 551, 286, 390, 5804, 466, 382, 731, 13, 50724, 50724, 407, 294, 264, 5883, 9606, 11, 321, 630, 853, 746, 597, 390, 411, 1228, 257, 4833, 15245, 2744, 13, 50980, 50980, 583, 562, 321, 16858, 281, 746, 411, 264, 4675, 3765, 11, 309, 630, 406, 534, 5407, 3389, 11, 51254, 51254, 588, 11, 588, 707, 11, 588, 709, 294, 264, 11004, 294, 3389, 13, 51482, 51482, 1033, 11, 604, 24002, 983, 300, 311, 264, 1389, 30, 51704, 51704], "temperature": 0.0, "avg_logprob": -0.21149641036987304, "compression_ratio": 1.6851063829787234, "no_speech_prob": 1.892365798994433e-05}, {"id": 1444, "seek": 586416, "start": 5864.16, "end": 5868.639999999999, "text": " I think overall contrastive learning is fairly slow to converge.", "tokens": [50364, 286, 519, 4787, 8712, 488, 2539, 307, 6457, 2964, 281, 41881, 13, 50588, 50588, 407, 439, 411, 439, 7150, 293, 1850, 293, 411, 264, 6792, 3037, 295, 705, 1291, 293, 370, 322, 13, 50862, 50862, 1057, 295, 552, 3847, 337, 588, 2416, 1230, 295, 30992, 28346, 4033, 13, 51018, 51018, 407, 264, 1230, 295, 646, 79, 7424, 300, 291, 434, 1242, 420, 264, 1230, 295, 4675, 420, 13075, 9205, 51260, 51260, 300, 291, 434, 884, 366, 588, 2416, 294, 2674, 13, 51365, 51365, 407, 264, 1186, 300, 291, 1713, 484, 322, 472, 295, 552, 294, 341, 1729, 1389, 1391, 775, 406, 51546, 51546, 362, 300, 2808, 295, 364, 1802, 13, 51646, 51646, 1033, 11, 3231, 13, 51762, 51762, 5264, 1732, 2077, 13, 51812, 51812], "temperature": 0.0, "avg_logprob": -0.24784112355065724, "compression_ratio": 1.7598566308243728, "no_speech_prob": 2.6680707378545776e-05}, {"id": 1445, "seek": 586416, "start": 5868.639999999999, "end": 5874.12, "text": " So all like all methods and clear and like the latest version of moco and so on.", "tokens": [50364, 286, 519, 4787, 8712, 488, 2539, 307, 6457, 2964, 281, 41881, 13, 50588, 50588, 407, 439, 411, 439, 7150, 293, 1850, 293, 411, 264, 6792, 3037, 295, 705, 1291, 293, 370, 322, 13, 50862, 50862, 1057, 295, 552, 3847, 337, 588, 2416, 1230, 295, 30992, 28346, 4033, 13, 51018, 51018, 407, 264, 1230, 295, 646, 79, 7424, 300, 291, 434, 1242, 420, 264, 1230, 295, 4675, 420, 13075, 9205, 51260, 51260, 300, 291, 434, 884, 366, 588, 2416, 294, 2674, 13, 51365, 51365, 407, 264, 1186, 300, 291, 1713, 484, 322, 472, 295, 552, 294, 341, 1729, 1389, 1391, 775, 406, 51546, 51546, 362, 300, 2808, 295, 364, 1802, 13, 51646, 51646, 1033, 11, 3231, 13, 51762, 51762, 5264, 1732, 2077, 13, 51812, 51812], "temperature": 0.0, "avg_logprob": -0.24784112355065724, "compression_ratio": 1.7598566308243728, "no_speech_prob": 2.6680707378545776e-05}, {"id": 1446, "seek": 586416, "start": 5874.12, "end": 5877.24, "text": " All of them train for very large number of epochs anyway.", "tokens": [50364, 286, 519, 4787, 8712, 488, 2539, 307, 6457, 2964, 281, 41881, 13, 50588, 50588, 407, 439, 411, 439, 7150, 293, 1850, 293, 411, 264, 6792, 3037, 295, 705, 1291, 293, 370, 322, 13, 50862, 50862, 1057, 295, 552, 3847, 337, 588, 2416, 1230, 295, 30992, 28346, 4033, 13, 51018, 51018, 407, 264, 1230, 295, 646, 79, 7424, 300, 291, 434, 1242, 420, 264, 1230, 295, 4675, 420, 13075, 9205, 51260, 51260, 300, 291, 434, 884, 366, 588, 2416, 294, 2674, 13, 51365, 51365, 407, 264, 1186, 300, 291, 1713, 484, 322, 472, 295, 552, 294, 341, 1729, 1389, 1391, 775, 406, 51546, 51546, 362, 300, 2808, 295, 364, 1802, 13, 51646, 51646, 1033, 11, 3231, 13, 51762, 51762, 5264, 1732, 2077, 13, 51812, 51812], "temperature": 0.0, "avg_logprob": -0.24784112355065724, "compression_ratio": 1.7598566308243728, "no_speech_prob": 2.6680707378545776e-05}, {"id": 1447, "seek": 586416, "start": 5877.24, "end": 5882.08, "text": " So the number of backpacks that you're getting or the number of memory or parameter updates", "tokens": [50364, 286, 519, 4787, 8712, 488, 2539, 307, 6457, 2964, 281, 41881, 13, 50588, 50588, 407, 439, 411, 439, 7150, 293, 1850, 293, 411, 264, 6792, 3037, 295, 705, 1291, 293, 370, 322, 13, 50862, 50862, 1057, 295, 552, 3847, 337, 588, 2416, 1230, 295, 30992, 28346, 4033, 13, 51018, 51018, 407, 264, 1230, 295, 646, 79, 7424, 300, 291, 434, 1242, 420, 264, 1230, 295, 4675, 420, 13075, 9205, 51260, 51260, 300, 291, 434, 884, 366, 588, 2416, 294, 2674, 13, 51365, 51365, 407, 264, 1186, 300, 291, 1713, 484, 322, 472, 295, 552, 294, 341, 1729, 1389, 1391, 775, 406, 51546, 51546, 362, 300, 2808, 295, 364, 1802, 13, 51646, 51646, 1033, 11, 3231, 13, 51762, 51762, 5264, 1732, 2077, 13, 51812, 51812], "temperature": 0.0, "avg_logprob": -0.24784112355065724, "compression_ratio": 1.7598566308243728, "no_speech_prob": 2.6680707378545776e-05}, {"id": 1448, "seek": 586416, "start": 5882.08, "end": 5884.18, "text": " that you're doing are very large in general.", "tokens": [50364, 286, 519, 4787, 8712, 488, 2539, 307, 6457, 2964, 281, 41881, 13, 50588, 50588, 407, 439, 411, 439, 7150, 293, 1850, 293, 411, 264, 6792, 3037, 295, 705, 1291, 293, 370, 322, 13, 50862, 50862, 1057, 295, 552, 3847, 337, 588, 2416, 1230, 295, 30992, 28346, 4033, 13, 51018, 51018, 407, 264, 1230, 295, 646, 79, 7424, 300, 291, 434, 1242, 420, 264, 1230, 295, 4675, 420, 13075, 9205, 51260, 51260, 300, 291, 434, 884, 366, 588, 2416, 294, 2674, 13, 51365, 51365, 407, 264, 1186, 300, 291, 1713, 484, 322, 472, 295, 552, 294, 341, 1729, 1389, 1391, 775, 406, 51546, 51546, 362, 300, 2808, 295, 364, 1802, 13, 51646, 51646, 1033, 11, 3231, 13, 51762, 51762, 5264, 1732, 2077, 13, 51812, 51812], "temperature": 0.0, "avg_logprob": -0.24784112355065724, "compression_ratio": 1.7598566308243728, "no_speech_prob": 2.6680707378545776e-05}, {"id": 1449, "seek": 586416, "start": 5884.18, "end": 5887.8, "text": " So the fact that you miss out on one of them in this particular case probably does not", "tokens": [50364, 286, 519, 4787, 8712, 488, 2539, 307, 6457, 2964, 281, 41881, 13, 50588, 50588, 407, 439, 411, 439, 7150, 293, 1850, 293, 411, 264, 6792, 3037, 295, 705, 1291, 293, 370, 322, 13, 50862, 50862, 1057, 295, 552, 3847, 337, 588, 2416, 1230, 295, 30992, 28346, 4033, 13, 51018, 51018, 407, 264, 1230, 295, 646, 79, 7424, 300, 291, 434, 1242, 420, 264, 1230, 295, 4675, 420, 13075, 9205, 51260, 51260, 300, 291, 434, 884, 366, 588, 2416, 294, 2674, 13, 51365, 51365, 407, 264, 1186, 300, 291, 1713, 484, 322, 472, 295, 552, 294, 341, 1729, 1389, 1391, 775, 406, 51546, 51546, 362, 300, 2808, 295, 364, 1802, 13, 51646, 51646, 1033, 11, 3231, 13, 51762, 51762, 5264, 1732, 2077, 13, 51812, 51812], "temperature": 0.0, "avg_logprob": -0.24784112355065724, "compression_ratio": 1.7598566308243728, "no_speech_prob": 2.6680707378545776e-05}, {"id": 1450, "seek": 586416, "start": 5887.8, "end": 5889.8, "text": " have that middle of an effect.", "tokens": [50364, 286, 519, 4787, 8712, 488, 2539, 307, 6457, 2964, 281, 41881, 13, 50588, 50588, 407, 439, 411, 439, 7150, 293, 1850, 293, 411, 264, 6792, 3037, 295, 705, 1291, 293, 370, 322, 13, 50862, 50862, 1057, 295, 552, 3847, 337, 588, 2416, 1230, 295, 30992, 28346, 4033, 13, 51018, 51018, 407, 264, 1230, 295, 646, 79, 7424, 300, 291, 434, 1242, 420, 264, 1230, 295, 4675, 420, 13075, 9205, 51260, 51260, 300, 291, 434, 884, 366, 588, 2416, 294, 2674, 13, 51365, 51365, 407, 264, 1186, 300, 291, 1713, 484, 322, 472, 295, 552, 294, 341, 1729, 1389, 1391, 775, 406, 51546, 51546, 362, 300, 2808, 295, 364, 1802, 13, 51646, 51646, 1033, 11, 3231, 13, 51762, 51762, 5264, 1732, 2077, 13, 51812, 51812], "temperature": 0.0, "avg_logprob": -0.24784112355065724, "compression_ratio": 1.7598566308243728, "no_speech_prob": 2.6680707378545776e-05}, {"id": 1451, "seek": 586416, "start": 5889.8, "end": 5892.12, "text": " Okay, thanks.", "tokens": [50364, 286, 519, 4787, 8712, 488, 2539, 307, 6457, 2964, 281, 41881, 13, 50588, 50588, 407, 439, 411, 439, 7150, 293, 1850, 293, 411, 264, 6792, 3037, 295, 705, 1291, 293, 370, 322, 13, 50862, 50862, 1057, 295, 552, 3847, 337, 588, 2416, 1230, 295, 30992, 28346, 4033, 13, 51018, 51018, 407, 264, 1230, 295, 646, 79, 7424, 300, 291, 434, 1242, 420, 264, 1230, 295, 4675, 420, 13075, 9205, 51260, 51260, 300, 291, 434, 884, 366, 588, 2416, 294, 2674, 13, 51365, 51365, 407, 264, 1186, 300, 291, 1713, 484, 322, 472, 295, 552, 294, 341, 1729, 1389, 1391, 775, 406, 51546, 51546, 362, 300, 2808, 295, 364, 1802, 13, 51646, 51646, 1033, 11, 3231, 13, 51762, 51762, 5264, 1732, 2077, 13, 51812, 51812], "temperature": 0.0, "avg_logprob": -0.24784112355065724, "compression_ratio": 1.7598566308243728, "no_speech_prob": 2.6680707378545776e-05}, {"id": 1452, "seek": 586416, "start": 5892.12, "end": 5893.12, "text": " Last five minutes.", "tokens": [50364, 286, 519, 4787, 8712, 488, 2539, 307, 6457, 2964, 281, 41881, 13, 50588, 50588, 407, 439, 411, 439, 7150, 293, 1850, 293, 411, 264, 6792, 3037, 295, 705, 1291, 293, 370, 322, 13, 50862, 50862, 1057, 295, 552, 3847, 337, 588, 2416, 1230, 295, 30992, 28346, 4033, 13, 51018, 51018, 407, 264, 1230, 295, 646, 79, 7424, 300, 291, 434, 1242, 420, 264, 1230, 295, 4675, 420, 13075, 9205, 51260, 51260, 300, 291, 434, 884, 366, 588, 2416, 294, 2674, 13, 51365, 51365, 407, 264, 1186, 300, 291, 1713, 484, 322, 472, 295, 552, 294, 341, 1729, 1389, 1391, 775, 406, 51546, 51546, 362, 300, 2808, 295, 364, 1802, 13, 51646, 51646, 1033, 11, 3231, 13, 51762, 51762, 5264, 1732, 2077, 13, 51812, 51812], "temperature": 0.0, "avg_logprob": -0.24784112355065724, "compression_ratio": 1.7598566308243728, "no_speech_prob": 2.6680707378545776e-05}, {"id": 1453, "seek": 589312, "start": 5893.12, "end": 5894.12, "text": " Cool.", "tokens": [50364, 8561, 13, 50414, 50414, 12627, 456, 13, 50528, 50528, 407, 1338, 11, 321, 1936, 13059, 3026, 75, 322, 257, 3840, 295, 819, 9608, 13, 50723, 50723, 407, 264, 700, 551, 390, 2657, 17784, 13, 50860, 50860, 3764, 11, 1333, 295, 3832, 5633, 294, 5201, 13, 51090, 51090, 400, 294, 341, 1389, 11, 3026, 75, 390, 1075, 281, 484, 26765, 3256, 2533, 46533, 3097, 322, 17784, 51312, 51312, 337, 1293, 264, 15216, 34, 1958, 22, 293, 1614, 1804, 2272, 1412, 6352, 13, 51536, 51536, 400, 309, 484, 26765, 82, 322, 264, 1333, 295, 881, 1056, 299, 391, 13344, 46691, 11, 597, 307, 5372, 439, 11, 597, 51798, 51798], "temperature": 0.0, "avg_logprob": -0.24499655207362744, "compression_ratio": 1.6081632653061224, "no_speech_prob": 6.747914994775783e-06}, {"id": 1454, "seek": 589312, "start": 5894.12, "end": 5896.4, "text": " Almost there.", "tokens": [50364, 8561, 13, 50414, 50414, 12627, 456, 13, 50528, 50528, 407, 1338, 11, 321, 1936, 13059, 3026, 75, 322, 257, 3840, 295, 819, 9608, 13, 50723, 50723, 407, 264, 700, 551, 390, 2657, 17784, 13, 50860, 50860, 3764, 11, 1333, 295, 3832, 5633, 294, 5201, 13, 51090, 51090, 400, 294, 341, 1389, 11, 3026, 75, 390, 1075, 281, 484, 26765, 3256, 2533, 46533, 3097, 322, 17784, 51312, 51312, 337, 1293, 264, 15216, 34, 1958, 22, 293, 1614, 1804, 2272, 1412, 6352, 13, 51536, 51536, 400, 309, 484, 26765, 82, 322, 264, 1333, 295, 881, 1056, 299, 391, 13344, 46691, 11, 597, 307, 5372, 439, 11, 597, 51798, 51798], "temperature": 0.0, "avg_logprob": -0.24499655207362744, "compression_ratio": 1.6081632653061224, "no_speech_prob": 6.747914994775783e-06}, {"id": 1455, "seek": 589312, "start": 5896.4, "end": 5900.3, "text": " So yeah, we basically evaluate Perl on a bunch of different tasks.", "tokens": [50364, 8561, 13, 50414, 50414, 12627, 456, 13, 50528, 50528, 407, 1338, 11, 321, 1936, 13059, 3026, 75, 322, 257, 3840, 295, 819, 9608, 13, 50723, 50723, 407, 264, 700, 551, 390, 2657, 17784, 13, 50860, 50860, 3764, 11, 1333, 295, 3832, 5633, 294, 5201, 13, 51090, 51090, 400, 294, 341, 1389, 11, 3026, 75, 390, 1075, 281, 484, 26765, 3256, 2533, 46533, 3097, 322, 17784, 51312, 51312, 337, 1293, 264, 15216, 34, 1958, 22, 293, 1614, 1804, 2272, 1412, 6352, 13, 51536, 51536, 400, 309, 484, 26765, 82, 322, 264, 1333, 295, 881, 1056, 299, 391, 13344, 46691, 11, 597, 307, 5372, 439, 11, 597, 51798, 51798], "temperature": 0.0, "avg_logprob": -0.24499655207362744, "compression_ratio": 1.6081632653061224, "no_speech_prob": 6.747914994775783e-06}, {"id": 1456, "seek": 589312, "start": 5900.3, "end": 5903.04, "text": " So the first thing was object detection.", "tokens": [50364, 8561, 13, 50414, 50414, 12627, 456, 13, 50528, 50528, 407, 1338, 11, 321, 1936, 13059, 3026, 75, 322, 257, 3840, 295, 819, 9608, 13, 50723, 50723, 407, 264, 700, 551, 390, 2657, 17784, 13, 50860, 50860, 3764, 11, 1333, 295, 3832, 5633, 294, 5201, 13, 51090, 51090, 400, 294, 341, 1389, 11, 3026, 75, 390, 1075, 281, 484, 26765, 3256, 2533, 46533, 3097, 322, 17784, 51312, 51312, 337, 1293, 264, 15216, 34, 1958, 22, 293, 1614, 1804, 2272, 1412, 6352, 13, 51536, 51536, 400, 309, 484, 26765, 82, 322, 264, 1333, 295, 881, 1056, 299, 391, 13344, 46691, 11, 597, 307, 5372, 439, 11, 597, 51798, 51798], "temperature": 0.0, "avg_logprob": -0.24499655207362744, "compression_ratio": 1.6081632653061224, "no_speech_prob": 6.747914994775783e-06}, {"id": 1457, "seek": 589312, "start": 5903.04, "end": 5907.64, "text": " Again, sort of standard task in vision.", "tokens": [50364, 8561, 13, 50414, 50414, 12627, 456, 13, 50528, 50528, 407, 1338, 11, 321, 1936, 13059, 3026, 75, 322, 257, 3840, 295, 819, 9608, 13, 50723, 50723, 407, 264, 700, 551, 390, 2657, 17784, 13, 50860, 50860, 3764, 11, 1333, 295, 3832, 5633, 294, 5201, 13, 51090, 51090, 400, 294, 341, 1389, 11, 3026, 75, 390, 1075, 281, 484, 26765, 3256, 2533, 46533, 3097, 322, 17784, 51312, 51312, 337, 1293, 264, 15216, 34, 1958, 22, 293, 1614, 1804, 2272, 1412, 6352, 13, 51536, 51536, 400, 309, 484, 26765, 82, 322, 264, 1333, 295, 881, 1056, 299, 391, 13344, 46691, 11, 597, 307, 5372, 439, 11, 597, 51798, 51798], "temperature": 0.0, "avg_logprob": -0.24499655207362744, "compression_ratio": 1.6081632653061224, "no_speech_prob": 6.747914994775783e-06}, {"id": 1458, "seek": 589312, "start": 5907.64, "end": 5912.08, "text": " And in this case, Perl was able to outperform image net supervised training on detection", "tokens": [50364, 8561, 13, 50414, 50414, 12627, 456, 13, 50528, 50528, 407, 1338, 11, 321, 1936, 13059, 3026, 75, 322, 257, 3840, 295, 819, 9608, 13, 50723, 50723, 407, 264, 700, 551, 390, 2657, 17784, 13, 50860, 50860, 3764, 11, 1333, 295, 3832, 5633, 294, 5201, 13, 51090, 51090, 400, 294, 341, 1389, 11, 3026, 75, 390, 1075, 281, 484, 26765, 3256, 2533, 46533, 3097, 322, 17784, 51312, 51312, 337, 1293, 264, 15216, 34, 1958, 22, 293, 1614, 1804, 2272, 1412, 6352, 13, 51536, 51536, 400, 309, 484, 26765, 82, 322, 264, 1333, 295, 881, 1056, 299, 391, 13344, 46691, 11, 597, 307, 5372, 439, 11, 597, 51798, 51798], "temperature": 0.0, "avg_logprob": -0.24499655207362744, "compression_ratio": 1.6081632653061224, "no_speech_prob": 6.747914994775783e-06}, {"id": 1459, "seek": 589312, "start": 5912.08, "end": 5916.5599999999995, "text": " for both the VOC 07 and 7 plus 12 data sets.", "tokens": [50364, 8561, 13, 50414, 50414, 12627, 456, 13, 50528, 50528, 407, 1338, 11, 321, 1936, 13059, 3026, 75, 322, 257, 3840, 295, 819, 9608, 13, 50723, 50723, 407, 264, 700, 551, 390, 2657, 17784, 13, 50860, 50860, 3764, 11, 1333, 295, 3832, 5633, 294, 5201, 13, 51090, 51090, 400, 294, 341, 1389, 11, 3026, 75, 390, 1075, 281, 484, 26765, 3256, 2533, 46533, 3097, 322, 17784, 51312, 51312, 337, 1293, 264, 15216, 34, 1958, 22, 293, 1614, 1804, 2272, 1412, 6352, 13, 51536, 51536, 400, 309, 484, 26765, 82, 322, 264, 1333, 295, 881, 1056, 299, 391, 13344, 46691, 11, 597, 307, 5372, 439, 11, 597, 51798, 51798], "temperature": 0.0, "avg_logprob": -0.24499655207362744, "compression_ratio": 1.6081632653061224, "no_speech_prob": 6.747914994775783e-06}, {"id": 1460, "seek": 589312, "start": 5916.5599999999995, "end": 5921.8, "text": " And it outperforms on the sort of most stricter evaluation criterion, which is AP all, which", "tokens": [50364, 8561, 13, 50414, 50414, 12627, 456, 13, 50528, 50528, 407, 1338, 11, 321, 1936, 13059, 3026, 75, 322, 257, 3840, 295, 819, 9608, 13, 50723, 50723, 407, 264, 700, 551, 390, 2657, 17784, 13, 50860, 50860, 3764, 11, 1333, 295, 3832, 5633, 294, 5201, 13, 51090, 51090, 400, 294, 341, 1389, 11, 3026, 75, 390, 1075, 281, 484, 26765, 3256, 2533, 46533, 3097, 322, 17784, 51312, 51312, 337, 1293, 264, 15216, 34, 1958, 22, 293, 1614, 1804, 2272, 1412, 6352, 13, 51536, 51536, 400, 309, 484, 26765, 82, 322, 264, 1333, 295, 881, 1056, 299, 391, 13344, 46691, 11, 597, 307, 5372, 439, 11, 597, 51798, 51798], "temperature": 0.0, "avg_logprob": -0.24499655207362744, "compression_ratio": 1.6081632653061224, "no_speech_prob": 6.747914994775783e-06}, {"id": 1461, "seek": 592180, "start": 5921.8, "end": 5927.2, "text": " is now introduced by Coco, which was already sort of a positive sign that it was able to", "tokens": [50364, 307, 586, 7268, 538, 29787, 11, 597, 390, 1217, 1333, 295, 257, 3353, 1465, 300, 309, 390, 1075, 281, 50634, 50634, 360, 341, 13, 50724, 50724, 440, 1150, 551, 321, 2956, 412, 390, 1936, 27479, 3026, 75, 322, 12909, 46533, 2539, 13, 50966, 50966, 400, 1564, 797, 11, 3026, 75, 390, 10205, 6457, 731, 13, 51076, 51076, 467, 390, 767, 1101, 813, 584, 264, 659, 25111, 5633, 295, 361, 17156, 1607, 13, 51302, 51302, 407, 264, 787, 2649, 1296, 264, 1192, 5386, 293, 264, 2767, 5386, 307, 264, 1186, 300, 3026, 75, 307, 51526, 51526, 364, 33270, 394, 3037, 11, 9735, 361, 17156, 1607, 307, 257, 49851, 394, 3037, 13, 51822, 51822], "temperature": 0.0, "avg_logprob": -0.15565233063279538, "compression_ratio": 1.678030303030303, "no_speech_prob": 1.136548348767974e-06}, {"id": 1462, "seek": 592180, "start": 5927.2, "end": 5929.0, "text": " do this.", "tokens": [50364, 307, 586, 7268, 538, 29787, 11, 597, 390, 1217, 1333, 295, 257, 3353, 1465, 300, 309, 390, 1075, 281, 50634, 50634, 360, 341, 13, 50724, 50724, 440, 1150, 551, 321, 2956, 412, 390, 1936, 27479, 3026, 75, 322, 12909, 46533, 2539, 13, 50966, 50966, 400, 1564, 797, 11, 3026, 75, 390, 10205, 6457, 731, 13, 51076, 51076, 467, 390, 767, 1101, 813, 584, 264, 659, 25111, 5633, 295, 361, 17156, 1607, 13, 51302, 51302, 407, 264, 787, 2649, 1296, 264, 1192, 5386, 293, 264, 2767, 5386, 307, 264, 1186, 300, 3026, 75, 307, 51526, 51526, 364, 33270, 394, 3037, 11, 9735, 361, 17156, 1607, 307, 257, 49851, 394, 3037, 13, 51822, 51822], "temperature": 0.0, "avg_logprob": -0.15565233063279538, "compression_ratio": 1.678030303030303, "no_speech_prob": 1.136548348767974e-06}, {"id": 1463, "seek": 592180, "start": 5929.0, "end": 5933.84, "text": " The second thing we looked at was basically evaluating Perl on semi supervised learning.", "tokens": [50364, 307, 586, 7268, 538, 29787, 11, 597, 390, 1217, 1333, 295, 257, 3353, 1465, 300, 309, 390, 1075, 281, 50634, 50634, 360, 341, 13, 50724, 50724, 440, 1150, 551, 321, 2956, 412, 390, 1936, 27479, 3026, 75, 322, 12909, 46533, 2539, 13, 50966, 50966, 400, 1564, 797, 11, 3026, 75, 390, 10205, 6457, 731, 13, 51076, 51076, 467, 390, 767, 1101, 813, 584, 264, 659, 25111, 5633, 295, 361, 17156, 1607, 13, 51302, 51302, 407, 264, 787, 2649, 1296, 264, 1192, 5386, 293, 264, 2767, 5386, 307, 264, 1186, 300, 3026, 75, 307, 51526, 51526, 364, 33270, 394, 3037, 11, 9735, 361, 17156, 1607, 307, 257, 49851, 394, 3037, 13, 51822, 51822], "temperature": 0.0, "avg_logprob": -0.15565233063279538, "compression_ratio": 1.678030303030303, "no_speech_prob": 1.136548348767974e-06}, {"id": 1464, "seek": 592180, "start": 5933.84, "end": 5936.04, "text": " And once again, Perl was performing fairly well.", "tokens": [50364, 307, 586, 7268, 538, 29787, 11, 597, 390, 1217, 1333, 295, 257, 3353, 1465, 300, 309, 390, 1075, 281, 50634, 50634, 360, 341, 13, 50724, 50724, 440, 1150, 551, 321, 2956, 412, 390, 1936, 27479, 3026, 75, 322, 12909, 46533, 2539, 13, 50966, 50966, 400, 1564, 797, 11, 3026, 75, 390, 10205, 6457, 731, 13, 51076, 51076, 467, 390, 767, 1101, 813, 584, 264, 659, 25111, 5633, 295, 361, 17156, 1607, 13, 51302, 51302, 407, 264, 787, 2649, 1296, 264, 1192, 5386, 293, 264, 2767, 5386, 307, 264, 1186, 300, 3026, 75, 307, 51526, 51526, 364, 33270, 394, 3037, 11, 9735, 361, 17156, 1607, 307, 257, 49851, 394, 3037, 13, 51822, 51822], "temperature": 0.0, "avg_logprob": -0.15565233063279538, "compression_ratio": 1.678030303030303, "no_speech_prob": 1.136548348767974e-06}, {"id": 1465, "seek": 592180, "start": 5936.04, "end": 5940.56, "text": " It was actually better than say the pretext task of jigsaw.", "tokens": [50364, 307, 586, 7268, 538, 29787, 11, 597, 390, 1217, 1333, 295, 257, 3353, 1465, 300, 309, 390, 1075, 281, 50634, 50634, 360, 341, 13, 50724, 50724, 440, 1150, 551, 321, 2956, 412, 390, 1936, 27479, 3026, 75, 322, 12909, 46533, 2539, 13, 50966, 50966, 400, 1564, 797, 11, 3026, 75, 390, 10205, 6457, 731, 13, 51076, 51076, 467, 390, 767, 1101, 813, 584, 264, 659, 25111, 5633, 295, 361, 17156, 1607, 13, 51302, 51302, 407, 264, 787, 2649, 1296, 264, 1192, 5386, 293, 264, 2767, 5386, 307, 264, 1186, 300, 3026, 75, 307, 51526, 51526, 364, 33270, 394, 3037, 11, 9735, 361, 17156, 1607, 307, 257, 49851, 394, 3037, 13, 51822, 51822], "temperature": 0.0, "avg_logprob": -0.15565233063279538, "compression_ratio": 1.678030303030303, "no_speech_prob": 1.136548348767974e-06}, {"id": 1466, "seek": 592180, "start": 5940.56, "end": 5945.04, "text": " So the only difference between the top row and the bottom row is the fact that Perl is", "tokens": [50364, 307, 586, 7268, 538, 29787, 11, 597, 390, 1217, 1333, 295, 257, 3353, 1465, 300, 309, 390, 1075, 281, 50634, 50634, 360, 341, 13, 50724, 50724, 440, 1150, 551, 321, 2956, 412, 390, 1936, 27479, 3026, 75, 322, 12909, 46533, 2539, 13, 50966, 50966, 400, 1564, 797, 11, 3026, 75, 390, 10205, 6457, 731, 13, 51076, 51076, 467, 390, 767, 1101, 813, 584, 264, 659, 25111, 5633, 295, 361, 17156, 1607, 13, 51302, 51302, 407, 264, 787, 2649, 1296, 264, 1192, 5386, 293, 264, 2767, 5386, 307, 264, 1186, 300, 3026, 75, 307, 51526, 51526, 364, 33270, 394, 3037, 11, 9735, 361, 17156, 1607, 307, 257, 49851, 394, 3037, 13, 51822, 51822], "temperature": 0.0, "avg_logprob": -0.15565233063279538, "compression_ratio": 1.678030303030303, "no_speech_prob": 1.136548348767974e-06}, {"id": 1467, "seek": 592180, "start": 5945.04, "end": 5950.96, "text": " an invariant version, whereas jigsaw is a covariant version.", "tokens": [50364, 307, 586, 7268, 538, 29787, 11, 597, 390, 1217, 1333, 295, 257, 3353, 1465, 300, 309, 390, 1075, 281, 50634, 50634, 360, 341, 13, 50724, 50724, 440, 1150, 551, 321, 2956, 412, 390, 1936, 27479, 3026, 75, 322, 12909, 46533, 2539, 13, 50966, 50966, 400, 1564, 797, 11, 3026, 75, 390, 10205, 6457, 731, 13, 51076, 51076, 467, 390, 767, 1101, 813, 584, 264, 659, 25111, 5633, 295, 361, 17156, 1607, 13, 51302, 51302, 407, 264, 787, 2649, 1296, 264, 1192, 5386, 293, 264, 2767, 5386, 307, 264, 1186, 300, 3026, 75, 307, 51526, 51526, 364, 33270, 394, 3037, 11, 9735, 361, 17156, 1607, 307, 257, 49851, 394, 3037, 13, 51822, 51822], "temperature": 0.0, "avg_logprob": -0.15565233063279538, "compression_ratio": 1.678030303030303, "no_speech_prob": 1.136548348767974e-06}, {"id": 1468, "seek": 595096, "start": 5950.96, "end": 5954.88, "text": " And in terms of linear classification, when Perl came out, it was basically at par with", "tokens": [50364, 400, 294, 2115, 295, 8213, 21538, 11, 562, 3026, 75, 1361, 484, 11, 309, 390, 1936, 412, 971, 365, 50560, 50560, 383, 12986, 311, 6792, 3037, 293, 390, 10205, 6457, 731, 322, 257, 3840, 295, 819, 13075, 6257, 50872, 50872, 293, 257, 3840, 295, 819, 6331, 1303, 13, 50988, 50988, 400, 295, 1164, 11, 586, 291, 393, 362, 6457, 665, 3389, 538, 7150, 411, 3998, 34, 5797, 13, 51187, 51187, 407, 300, 1230, 337, 3998, 34, 5797, 11760, 576, 1936, 312, 466, 28267, 420, 5285, 5347, 51466, 51466, 281, 3026, 75, 311, 25082, 12, 742, 1230, 13, 51730, 51730], "temperature": 0.0, "avg_logprob": -0.18030283710744122, "compression_ratio": 1.6108949416342413, "no_speech_prob": 1.3496882047547842e-06}, {"id": 1469, "seek": 595096, "start": 5954.88, "end": 5961.12, "text": " CPC's latest version and was performing fairly well on a bunch of different parameter settings", "tokens": [50364, 400, 294, 2115, 295, 8213, 21538, 11, 562, 3026, 75, 1361, 484, 11, 309, 390, 1936, 412, 971, 365, 50560, 50560, 383, 12986, 311, 6792, 3037, 293, 390, 10205, 6457, 731, 322, 257, 3840, 295, 819, 13075, 6257, 50872, 50872, 293, 257, 3840, 295, 819, 6331, 1303, 13, 50988, 50988, 400, 295, 1164, 11, 586, 291, 393, 362, 6457, 665, 3389, 538, 7150, 411, 3998, 34, 5797, 13, 51187, 51187, 407, 300, 1230, 337, 3998, 34, 5797, 11760, 576, 1936, 312, 466, 28267, 420, 5285, 5347, 51466, 51466, 281, 3026, 75, 311, 25082, 12, 742, 1230, 13, 51730, 51730], "temperature": 0.0, "avg_logprob": -0.18030283710744122, "compression_ratio": 1.6108949416342413, "no_speech_prob": 1.3496882047547842e-06}, {"id": 1470, "seek": 595096, "start": 5961.12, "end": 5963.44, "text": " and a bunch of different architectures.", "tokens": [50364, 400, 294, 2115, 295, 8213, 21538, 11, 562, 3026, 75, 1361, 484, 11, 309, 390, 1936, 412, 971, 365, 50560, 50560, 383, 12986, 311, 6792, 3037, 293, 390, 10205, 6457, 731, 322, 257, 3840, 295, 819, 13075, 6257, 50872, 50872, 293, 257, 3840, 295, 819, 6331, 1303, 13, 50988, 50988, 400, 295, 1164, 11, 586, 291, 393, 362, 6457, 665, 3389, 538, 7150, 411, 3998, 34, 5797, 13, 51187, 51187, 407, 300, 1230, 337, 3998, 34, 5797, 11760, 576, 1936, 312, 466, 28267, 420, 5285, 5347, 51466, 51466, 281, 3026, 75, 311, 25082, 12, 742, 1230, 13, 51730, 51730], "temperature": 0.0, "avg_logprob": -0.18030283710744122, "compression_ratio": 1.6108949416342413, "no_speech_prob": 1.3496882047547842e-06}, {"id": 1471, "seek": 595096, "start": 5963.44, "end": 5967.42, "text": " And of course, now you can have fairly good performance by methods like SimClear.", "tokens": [50364, 400, 294, 2115, 295, 8213, 21538, 11, 562, 3026, 75, 1361, 484, 11, 309, 390, 1936, 412, 971, 365, 50560, 50560, 383, 12986, 311, 6792, 3037, 293, 390, 10205, 6457, 731, 322, 257, 3840, 295, 819, 13075, 6257, 50872, 50872, 293, 257, 3840, 295, 819, 6331, 1303, 13, 50988, 50988, 400, 295, 1164, 11, 586, 291, 393, 362, 6457, 665, 3389, 538, 7150, 411, 3998, 34, 5797, 13, 51187, 51187, 407, 300, 1230, 337, 3998, 34, 5797, 11760, 576, 1936, 312, 466, 28267, 420, 5285, 5347, 51466, 51466, 281, 3026, 75, 311, 25082, 12, 742, 1230, 13, 51730, 51730], "temperature": 0.0, "avg_logprob": -0.18030283710744122, "compression_ratio": 1.6108949416342413, "no_speech_prob": 1.3496882047547842e-06}, {"id": 1472, "seek": 595096, "start": 5967.42, "end": 5973.0, "text": " So that number for SimClear corresponding would basically be about 69 or 70 compared", "tokens": [50364, 400, 294, 2115, 295, 8213, 21538, 11, 562, 3026, 75, 1361, 484, 11, 309, 390, 1936, 412, 971, 365, 50560, 50560, 383, 12986, 311, 6792, 3037, 293, 390, 10205, 6457, 731, 322, 257, 3840, 295, 819, 13075, 6257, 50872, 50872, 293, 257, 3840, 295, 819, 6331, 1303, 13, 50988, 50988, 400, 295, 1164, 11, 586, 291, 393, 362, 6457, 665, 3389, 538, 7150, 411, 3998, 34, 5797, 13, 51187, 51187, 407, 300, 1230, 337, 3998, 34, 5797, 11760, 576, 1936, 312, 466, 28267, 420, 5285, 5347, 51466, 51466, 281, 3026, 75, 311, 25082, 12, 742, 1230, 13, 51730, 51730], "temperature": 0.0, "avg_logprob": -0.18030283710744122, "compression_ratio": 1.6108949416342413, "no_speech_prob": 1.3496882047547842e-06}, {"id": 1473, "seek": 595096, "start": 5973.0, "end": 5978.28, "text": " to Perl's 63-ish number.", "tokens": [50364, 400, 294, 2115, 295, 8213, 21538, 11, 562, 3026, 75, 1361, 484, 11, 309, 390, 1936, 412, 971, 365, 50560, 50560, 383, 12986, 311, 6792, 3037, 293, 390, 10205, 6457, 731, 322, 257, 3840, 295, 819, 13075, 6257, 50872, 50872, 293, 257, 3840, 295, 819, 6331, 1303, 13, 50988, 50988, 400, 295, 1164, 11, 586, 291, 393, 362, 6457, 665, 3389, 538, 7150, 411, 3998, 34, 5797, 13, 51187, 51187, 407, 300, 1230, 337, 3998, 34, 5797, 11760, 576, 1936, 312, 466, 28267, 420, 5285, 5347, 51466, 51466, 281, 3026, 75, 311, 25082, 12, 742, 1230, 13, 51730, 51730], "temperature": 0.0, "avg_logprob": -0.18030283710744122, "compression_ratio": 1.6108949416342413, "no_speech_prob": 1.3496882047547842e-06}, {"id": 1474, "seek": 597828, "start": 5978.28, "end": 5983.599999999999, "text": " The other thing we looked at was basically how Perl sort of generalizes across data distributions.", "tokens": [50364, 440, 661, 551, 321, 2956, 412, 390, 1936, 577, 3026, 75, 1333, 295, 2674, 5660, 2108, 1412, 37870, 13, 50630, 50630, 407, 337, 341, 11, 321, 2956, 412, 445, 22774, 260, 5267, 490, 264, 398, 37, 11717, 28872, 13, 50902, 50902, 400, 3026, 75, 390, 1075, 281, 1333, 295, 484, 26765, 7150, 300, 645, 8895, 1228, 2319, 1413, 544, 1412, 13, 51136, 51136, 407, 264, 361, 17156, 1607, 5386, 294, 264, 1150, 11, 411, 264, 361, 17156, 1607, 5386, 11, 597, 307, 264, 1150, 5386, 11, 390, 8895, 51400, 51400, 322, 2319, 2459, 5267, 11, 9735, 3026, 75, 390, 445, 8895, 322, 502, 2459, 5267, 13, 51648, 51648], "temperature": 0.0, "avg_logprob": -0.1344025265086781, "compression_ratio": 1.7634854771784232, "no_speech_prob": 1.6536716884729685e-06}, {"id": 1475, "seek": 597828, "start": 5983.599999999999, "end": 5989.04, "text": " So for this, we looked at just flicker images from the YFCC dataset.", "tokens": [50364, 440, 661, 551, 321, 2956, 412, 390, 1936, 577, 3026, 75, 1333, 295, 2674, 5660, 2108, 1412, 37870, 13, 50630, 50630, 407, 337, 341, 11, 321, 2956, 412, 445, 22774, 260, 5267, 490, 264, 398, 37, 11717, 28872, 13, 50902, 50902, 400, 3026, 75, 390, 1075, 281, 1333, 295, 484, 26765, 7150, 300, 645, 8895, 1228, 2319, 1413, 544, 1412, 13, 51136, 51136, 407, 264, 361, 17156, 1607, 5386, 294, 264, 1150, 11, 411, 264, 361, 17156, 1607, 5386, 11, 597, 307, 264, 1150, 5386, 11, 390, 8895, 51400, 51400, 322, 2319, 2459, 5267, 11, 9735, 3026, 75, 390, 445, 8895, 322, 502, 2459, 5267, 13, 51648, 51648], "temperature": 0.0, "avg_logprob": -0.1344025265086781, "compression_ratio": 1.7634854771784232, "no_speech_prob": 1.6536716884729685e-06}, {"id": 1476, "seek": 597828, "start": 5989.04, "end": 5993.719999999999, "text": " And Perl was able to sort of outperform methods that were trained using 100 times more data.", "tokens": [50364, 440, 661, 551, 321, 2956, 412, 390, 1936, 577, 3026, 75, 1333, 295, 2674, 5660, 2108, 1412, 37870, 13, 50630, 50630, 407, 337, 341, 11, 321, 2956, 412, 445, 22774, 260, 5267, 490, 264, 398, 37, 11717, 28872, 13, 50902, 50902, 400, 3026, 75, 390, 1075, 281, 1333, 295, 484, 26765, 7150, 300, 645, 8895, 1228, 2319, 1413, 544, 1412, 13, 51136, 51136, 407, 264, 361, 17156, 1607, 5386, 294, 264, 1150, 11, 411, 264, 361, 17156, 1607, 5386, 11, 597, 307, 264, 1150, 5386, 11, 390, 8895, 51400, 51400, 322, 2319, 2459, 5267, 11, 9735, 3026, 75, 390, 445, 8895, 322, 502, 2459, 5267, 13, 51648, 51648], "temperature": 0.0, "avg_logprob": -0.1344025265086781, "compression_ratio": 1.7634854771784232, "no_speech_prob": 1.6536716884729685e-06}, {"id": 1477, "seek": 597828, "start": 5993.719999999999, "end": 5999.0, "text": " So the jigsaw row in the second, like the jigsaw row, which is the second row, was trained", "tokens": [50364, 440, 661, 551, 321, 2956, 412, 390, 1936, 577, 3026, 75, 1333, 295, 2674, 5660, 2108, 1412, 37870, 13, 50630, 50630, 407, 337, 341, 11, 321, 2956, 412, 445, 22774, 260, 5267, 490, 264, 398, 37, 11717, 28872, 13, 50902, 50902, 400, 3026, 75, 390, 1075, 281, 1333, 295, 484, 26765, 7150, 300, 645, 8895, 1228, 2319, 1413, 544, 1412, 13, 51136, 51136, 407, 264, 361, 17156, 1607, 5386, 294, 264, 1150, 11, 411, 264, 361, 17156, 1607, 5386, 11, 597, 307, 264, 1150, 5386, 11, 390, 8895, 51400, 51400, 322, 2319, 2459, 5267, 11, 9735, 3026, 75, 390, 445, 8895, 322, 502, 2459, 5267, 13, 51648, 51648], "temperature": 0.0, "avg_logprob": -0.1344025265086781, "compression_ratio": 1.7634854771784232, "no_speech_prob": 1.6536716884729685e-06}, {"id": 1478, "seek": 597828, "start": 5999.0, "end": 6003.96, "text": " on 100 million images, whereas Perl was just trained on 1 million images.", "tokens": [50364, 440, 661, 551, 321, 2956, 412, 390, 1936, 577, 3026, 75, 1333, 295, 2674, 5660, 2108, 1412, 37870, 13, 50630, 50630, 407, 337, 341, 11, 321, 2956, 412, 445, 22774, 260, 5267, 490, 264, 398, 37, 11717, 28872, 13, 50902, 50902, 400, 3026, 75, 390, 1075, 281, 1333, 295, 484, 26765, 7150, 300, 645, 8895, 1228, 2319, 1413, 544, 1412, 13, 51136, 51136, 407, 264, 361, 17156, 1607, 5386, 294, 264, 1150, 11, 411, 264, 361, 17156, 1607, 5386, 11, 597, 307, 264, 1150, 5386, 11, 390, 8895, 51400, 51400, 322, 2319, 2459, 5267, 11, 9735, 3026, 75, 390, 445, 8895, 322, 502, 2459, 5267, 13, 51648, 51648], "temperature": 0.0, "avg_logprob": -0.1344025265086781, "compression_ratio": 1.7634854771784232, "no_speech_prob": 1.6536716884729685e-06}, {"id": 1479, "seek": 600396, "start": 6003.96, "end": 6009.44, "text": " And despite that, it's actually able to sort of outperform the jigsaw method fairly easily.", "tokens": [50364, 400, 7228, 300, 11, 309, 311, 767, 1075, 281, 1333, 295, 484, 26765, 264, 361, 17156, 1607, 3170, 6457, 3612, 13, 50638, 50638, 639, 797, 3110, 291, 264, 1347, 295, 12102, 33270, 1719, 666, 428, 10290, 2831, 813, 32884, 50982, 50982, 659, 25111, 9608, 13, 51162, 51162, 400, 2721, 11, 264, 1333, 295, 551, 286, 1409, 484, 365, 11, 597, 307, 300, 1968, 341, 551, 307, 51368, 51368, 767, 47982, 13, 51418, 51418, 407, 498, 291, 574, 412, 819, 7914, 295, 33358, 11, 370, 2656, 16, 281, 5015, 20, 11, 361, 17156, 1607, 1936, 3110, 257, 51716, 51716], "temperature": 0.0, "avg_logprob": -0.1604265594482422, "compression_ratio": 1.610236220472441, "no_speech_prob": 2.090423549816478e-06}, {"id": 1480, "seek": 600396, "start": 6009.44, "end": 6016.32, "text": " This again shows you the power of baking invariants into your representation rather than predicting", "tokens": [50364, 400, 7228, 300, 11, 309, 311, 767, 1075, 281, 1333, 295, 484, 26765, 264, 361, 17156, 1607, 3170, 6457, 3612, 13, 50638, 50638, 639, 797, 3110, 291, 264, 1347, 295, 12102, 33270, 1719, 666, 428, 10290, 2831, 813, 32884, 50982, 50982, 659, 25111, 9608, 13, 51162, 51162, 400, 2721, 11, 264, 1333, 295, 551, 286, 1409, 484, 365, 11, 597, 307, 300, 1968, 341, 551, 307, 51368, 51368, 767, 47982, 13, 51418, 51418, 407, 498, 291, 574, 412, 819, 7914, 295, 33358, 11, 370, 2656, 16, 281, 5015, 20, 11, 361, 17156, 1607, 1936, 3110, 257, 51716, 51716], "temperature": 0.0, "avg_logprob": -0.1604265594482422, "compression_ratio": 1.610236220472441, "no_speech_prob": 2.090423549816478e-06}, {"id": 1481, "seek": 600396, "start": 6016.32, "end": 6019.92, "text": " pretext tasks.", "tokens": [50364, 400, 7228, 300, 11, 309, 311, 767, 1075, 281, 1333, 295, 484, 26765, 264, 361, 17156, 1607, 3170, 6457, 3612, 13, 50638, 50638, 639, 797, 3110, 291, 264, 1347, 295, 12102, 33270, 1719, 666, 428, 10290, 2831, 813, 32884, 50982, 50982, 659, 25111, 9608, 13, 51162, 51162, 400, 2721, 11, 264, 1333, 295, 551, 286, 1409, 484, 365, 11, 597, 307, 300, 1968, 341, 551, 307, 51368, 51368, 767, 47982, 13, 51418, 51418, 407, 498, 291, 574, 412, 819, 7914, 295, 33358, 11, 370, 2656, 16, 281, 5015, 20, 11, 361, 17156, 1607, 1936, 3110, 257, 51716, 51716], "temperature": 0.0, "avg_logprob": -0.1604265594482422, "compression_ratio": 1.610236220472441, "no_speech_prob": 2.090423549816478e-06}, {"id": 1482, "seek": 600396, "start": 6019.92, "end": 6024.04, "text": " And finally, the sort of thing I started out with, which is that whether this thing is", "tokens": [50364, 400, 7228, 300, 11, 309, 311, 767, 1075, 281, 1333, 295, 484, 26765, 264, 361, 17156, 1607, 3170, 6457, 3612, 13, 50638, 50638, 639, 797, 3110, 291, 264, 1347, 295, 12102, 33270, 1719, 666, 428, 10290, 2831, 813, 32884, 50982, 50982, 659, 25111, 9608, 13, 51162, 51162, 400, 2721, 11, 264, 1333, 295, 551, 286, 1409, 484, 365, 11, 597, 307, 300, 1968, 341, 551, 307, 51368, 51368, 767, 47982, 13, 51418, 51418, 407, 498, 291, 574, 412, 819, 7914, 295, 33358, 11, 370, 2656, 16, 281, 5015, 20, 11, 361, 17156, 1607, 1936, 3110, 257, 51716, 51716], "temperature": 0.0, "avg_logprob": -0.1604265594482422, "compression_ratio": 1.610236220472441, "no_speech_prob": 2.090423549816478e-06}, {"id": 1483, "seek": 600396, "start": 6024.04, "end": 6025.04, "text": " actually semantic.", "tokens": [50364, 400, 7228, 300, 11, 309, 311, 767, 1075, 281, 1333, 295, 484, 26765, 264, 361, 17156, 1607, 3170, 6457, 3612, 13, 50638, 50638, 639, 797, 3110, 291, 264, 1347, 295, 12102, 33270, 1719, 666, 428, 10290, 2831, 813, 32884, 50982, 50982, 659, 25111, 9608, 13, 51162, 51162, 400, 2721, 11, 264, 1333, 295, 551, 286, 1409, 484, 365, 11, 597, 307, 300, 1968, 341, 551, 307, 51368, 51368, 767, 47982, 13, 51418, 51418, 407, 498, 291, 574, 412, 819, 7914, 295, 33358, 11, 370, 2656, 16, 281, 5015, 20, 11, 361, 17156, 1607, 1936, 3110, 257, 51716, 51716], "temperature": 0.0, "avg_logprob": -0.1604265594482422, "compression_ratio": 1.610236220472441, "no_speech_prob": 2.090423549816478e-06}, {"id": 1484, "seek": 600396, "start": 6025.04, "end": 6031.0, "text": " So if you look at different layers of representations, so Con1 to Res5, jigsaw basically shows a", "tokens": [50364, 400, 7228, 300, 11, 309, 311, 767, 1075, 281, 1333, 295, 484, 26765, 264, 361, 17156, 1607, 3170, 6457, 3612, 13, 50638, 50638, 639, 797, 3110, 291, 264, 1347, 295, 12102, 33270, 1719, 666, 428, 10290, 2831, 813, 32884, 50982, 50982, 659, 25111, 9608, 13, 51162, 51162, 400, 2721, 11, 264, 1333, 295, 551, 286, 1409, 484, 365, 11, 597, 307, 300, 1968, 341, 551, 307, 51368, 51368, 767, 47982, 13, 51418, 51418, 407, 498, 291, 574, 412, 819, 7914, 295, 33358, 11, 370, 2656, 16, 281, 5015, 20, 11, 361, 17156, 1607, 1936, 3110, 257, 51716, 51716], "temperature": 0.0, "avg_logprob": -0.1604265594482422, "compression_ratio": 1.610236220472441, "no_speech_prob": 2.090423549816478e-06}, {"id": 1485, "seek": 603100, "start": 6031.0, "end": 6036.36, "text": " drop in performance from Res4 to Res5, whereas for Perl, you see a sort of nicely increasing", "tokens": [50364, 3270, 294, 3389, 490, 5015, 19, 281, 5015, 20, 11, 9735, 337, 3026, 75, 11, 291, 536, 257, 1333, 295, 9594, 5662, 50632, 50632, 4295, 11, 9735, 5015, 19, 293, 5015, 20, 483, 12980, 544, 293, 544, 47982, 13, 50998, 50998, 682, 2115, 295, 1154, 14024, 11, 3026, 75, 390, 588, 665, 412, 13175, 300, 570, 291, 434, 1128, 51208, 51208, 32884, 264, 1230, 295, 4784, 325, 763, 13, 51308, 51308, 509, 434, 445, 1228, 552, 412, 4846, 382, 1333, 295, 1412, 14501, 19631, 13, 51492, 51492, 407, 3026, 75, 393, 1333, 295, 4373, 588, 731, 281, 439, 264, 13898, 11, 1360, 1944, 4784, 325, 763, 294, 264, 4949, 51770, 51770], "temperature": 0.0, "avg_logprob": -0.14072727102093993, "compression_ratio": 1.683206106870229, "no_speech_prob": 5.507505647983635e-06}, {"id": 1486, "seek": 603100, "start": 6036.36, "end": 6043.68, "text": " graph, whereas Res4 and Res5 get increasingly more and more semantic.", "tokens": [50364, 3270, 294, 3389, 490, 5015, 19, 281, 5015, 20, 11, 9735, 337, 3026, 75, 11, 291, 536, 257, 1333, 295, 9594, 5662, 50632, 50632, 4295, 11, 9735, 5015, 19, 293, 5015, 20, 483, 12980, 544, 293, 544, 47982, 13, 50998, 50998, 682, 2115, 295, 1154, 14024, 11, 3026, 75, 390, 588, 665, 412, 13175, 300, 570, 291, 434, 1128, 51208, 51208, 32884, 264, 1230, 295, 4784, 325, 763, 13, 51308, 51308, 509, 434, 445, 1228, 552, 412, 4846, 382, 1333, 295, 1412, 14501, 19631, 13, 51492, 51492, 407, 3026, 75, 393, 1333, 295, 4373, 588, 731, 281, 439, 264, 13898, 11, 1360, 1944, 4784, 325, 763, 294, 264, 4949, 51770, 51770], "temperature": 0.0, "avg_logprob": -0.14072727102093993, "compression_ratio": 1.683206106870229, "no_speech_prob": 5.507505647983635e-06}, {"id": 1487, "seek": 603100, "start": 6043.68, "end": 6047.88, "text": " In terms of problem complexity, Perl was very good at handling that because you're never", "tokens": [50364, 3270, 294, 3389, 490, 5015, 19, 281, 5015, 20, 11, 9735, 337, 3026, 75, 11, 291, 536, 257, 1333, 295, 9594, 5662, 50632, 50632, 4295, 11, 9735, 5015, 19, 293, 5015, 20, 483, 12980, 544, 293, 544, 47982, 13, 50998, 50998, 682, 2115, 295, 1154, 14024, 11, 3026, 75, 390, 588, 665, 412, 13175, 300, 570, 291, 434, 1128, 51208, 51208, 32884, 264, 1230, 295, 4784, 325, 763, 13, 51308, 51308, 509, 434, 445, 1228, 552, 412, 4846, 382, 1333, 295, 1412, 14501, 19631, 13, 51492, 51492, 407, 3026, 75, 393, 1333, 295, 4373, 588, 731, 281, 439, 264, 13898, 11, 1360, 1944, 4784, 325, 763, 294, 264, 4949, 51770, 51770], "temperature": 0.0, "avg_logprob": -0.14072727102093993, "compression_ratio": 1.683206106870229, "no_speech_prob": 5.507505647983635e-06}, {"id": 1488, "seek": 603100, "start": 6047.88, "end": 6049.88, "text": " predicting the number of permutations.", "tokens": [50364, 3270, 294, 3389, 490, 5015, 19, 281, 5015, 20, 11, 9735, 337, 3026, 75, 11, 291, 536, 257, 1333, 295, 9594, 5662, 50632, 50632, 4295, 11, 9735, 5015, 19, 293, 5015, 20, 483, 12980, 544, 293, 544, 47982, 13, 50998, 50998, 682, 2115, 295, 1154, 14024, 11, 3026, 75, 390, 588, 665, 412, 13175, 300, 570, 291, 434, 1128, 51208, 51208, 32884, 264, 1230, 295, 4784, 325, 763, 13, 51308, 51308, 509, 434, 445, 1228, 552, 412, 4846, 382, 1333, 295, 1412, 14501, 19631, 13, 51492, 51492, 407, 3026, 75, 393, 1333, 295, 4373, 588, 731, 281, 439, 264, 13898, 11, 1360, 1944, 4784, 325, 763, 294, 264, 4949, 51770, 51770], "temperature": 0.0, "avg_logprob": -0.14072727102093993, "compression_ratio": 1.683206106870229, "no_speech_prob": 5.507505647983635e-06}, {"id": 1489, "seek": 603100, "start": 6049.88, "end": 6053.56, "text": " You're just using them at input as sort of data augmentation.", "tokens": [50364, 3270, 294, 3389, 490, 5015, 19, 281, 5015, 20, 11, 9735, 337, 3026, 75, 11, 291, 536, 257, 1333, 295, 9594, 5662, 50632, 50632, 4295, 11, 9735, 5015, 19, 293, 5015, 20, 483, 12980, 544, 293, 544, 47982, 13, 50998, 50998, 682, 2115, 295, 1154, 14024, 11, 3026, 75, 390, 588, 665, 412, 13175, 300, 570, 291, 434, 1128, 51208, 51208, 32884, 264, 1230, 295, 4784, 325, 763, 13, 51308, 51308, 509, 434, 445, 1228, 552, 412, 4846, 382, 1333, 295, 1412, 14501, 19631, 13, 51492, 51492, 407, 3026, 75, 393, 1333, 295, 4373, 588, 731, 281, 439, 264, 13898, 11, 1360, 1944, 4784, 325, 763, 294, 264, 4949, 51770, 51770], "temperature": 0.0, "avg_logprob": -0.14072727102093993, "compression_ratio": 1.683206106870229, "no_speech_prob": 5.507505647983635e-06}, {"id": 1490, "seek": 603100, "start": 6053.56, "end": 6059.12, "text": " So Perl can sort of scale very well to all the 360,000 possible permutations in the nine", "tokens": [50364, 3270, 294, 3389, 490, 5015, 19, 281, 5015, 20, 11, 9735, 337, 3026, 75, 11, 291, 536, 257, 1333, 295, 9594, 5662, 50632, 50632, 4295, 11, 9735, 5015, 19, 293, 5015, 20, 483, 12980, 544, 293, 544, 47982, 13, 50998, 50998, 682, 2115, 295, 1154, 14024, 11, 3026, 75, 390, 588, 665, 412, 13175, 300, 570, 291, 434, 1128, 51208, 51208, 32884, 264, 1230, 295, 4784, 325, 763, 13, 51308, 51308, 509, 434, 445, 1228, 552, 412, 4846, 382, 1333, 295, 1412, 14501, 19631, 13, 51492, 51492, 407, 3026, 75, 393, 1333, 295, 4373, 588, 731, 281, 439, 264, 13898, 11, 1360, 1944, 4784, 325, 763, 294, 264, 4949, 51770, 51770], "temperature": 0.0, "avg_logprob": -0.14072727102093993, "compression_ratio": 1.683206106870229, "no_speech_prob": 5.507505647983635e-06}, {"id": 1491, "seek": 605912, "start": 6059.12, "end": 6063.48, "text": " patches, whereas for jigsaw, because you're predicting that, you're very limited by the", "tokens": [50364, 26531, 11, 9735, 337, 361, 17156, 1607, 11, 570, 291, 434, 32884, 300, 11, 291, 434, 588, 5567, 538, 264, 50582, 50582, 2744, 295, 428, 5598, 1901, 13, 50806, 50806, 400, 264, 3035, 611, 3110, 300, 321, 393, 10101, 3026, 75, 281, 406, 445, 411, 11, 309, 311, 406, 5567, 281, 51024, 51024, 361, 17156, 1607, 11, 291, 393, 360, 300, 322, 12447, 13, 51136, 51136, 509, 393, 294, 1186, 360, 309, 322, 257, 6562, 295, 361, 17156, 1607, 293, 12447, 11, 293, 291, 393, 483, 544, 51310, 51310, 293, 544, 16823, 562, 291, 1936, 722, 884, 341, 13, 51592, 51592], "temperature": 0.0, "avg_logprob": -0.16067499327428134, "compression_ratio": 1.6923076923076923, "no_speech_prob": 2.29589500122529e-06}, {"id": 1492, "seek": 605912, "start": 6063.48, "end": 6067.96, "text": " size of your output space.", "tokens": [50364, 26531, 11, 9735, 337, 361, 17156, 1607, 11, 570, 291, 434, 32884, 300, 11, 291, 434, 588, 5567, 538, 264, 50582, 50582, 2744, 295, 428, 5598, 1901, 13, 50806, 50806, 400, 264, 3035, 611, 3110, 300, 321, 393, 10101, 3026, 75, 281, 406, 445, 411, 11, 309, 311, 406, 5567, 281, 51024, 51024, 361, 17156, 1607, 11, 291, 393, 360, 300, 322, 12447, 13, 51136, 51136, 509, 393, 294, 1186, 360, 309, 322, 257, 6562, 295, 361, 17156, 1607, 293, 12447, 11, 293, 291, 393, 483, 544, 51310, 51310, 293, 544, 16823, 562, 291, 1936, 722, 884, 341, 13, 51592, 51592], "temperature": 0.0, "avg_logprob": -0.16067499327428134, "compression_ratio": 1.6923076923076923, "no_speech_prob": 2.29589500122529e-06}, {"id": 1493, "seek": 605912, "start": 6067.96, "end": 6072.32, "text": " And the paper also shows that we can extend Perl to not just like, it's not limited to", "tokens": [50364, 26531, 11, 9735, 337, 361, 17156, 1607, 11, 570, 291, 434, 32884, 300, 11, 291, 434, 588, 5567, 538, 264, 50582, 50582, 2744, 295, 428, 5598, 1901, 13, 50806, 50806, 400, 264, 3035, 611, 3110, 300, 321, 393, 10101, 3026, 75, 281, 406, 445, 411, 11, 309, 311, 406, 5567, 281, 51024, 51024, 361, 17156, 1607, 11, 291, 393, 360, 300, 322, 12447, 13, 51136, 51136, 509, 393, 294, 1186, 360, 309, 322, 257, 6562, 295, 361, 17156, 1607, 293, 12447, 11, 293, 291, 393, 483, 544, 51310, 51310, 293, 544, 16823, 562, 291, 1936, 722, 884, 341, 13, 51592, 51592], "temperature": 0.0, "avg_logprob": -0.16067499327428134, "compression_ratio": 1.6923076923076923, "no_speech_prob": 2.29589500122529e-06}, {"id": 1494, "seek": 605912, "start": 6072.32, "end": 6074.5599999999995, "text": " jigsaw, you can do that on rotation.", "tokens": [50364, 26531, 11, 9735, 337, 361, 17156, 1607, 11, 570, 291, 434, 32884, 300, 11, 291, 434, 588, 5567, 538, 264, 50582, 50582, 2744, 295, 428, 5598, 1901, 13, 50806, 50806, 400, 264, 3035, 611, 3110, 300, 321, 393, 10101, 3026, 75, 281, 406, 445, 411, 11, 309, 311, 406, 5567, 281, 51024, 51024, 361, 17156, 1607, 11, 291, 393, 360, 300, 322, 12447, 13, 51136, 51136, 509, 393, 294, 1186, 360, 309, 322, 257, 6562, 295, 361, 17156, 1607, 293, 12447, 11, 293, 291, 393, 483, 544, 51310, 51310, 293, 544, 16823, 562, 291, 1936, 722, 884, 341, 13, 51592, 51592], "temperature": 0.0, "avg_logprob": -0.16067499327428134, "compression_ratio": 1.6923076923076923, "no_speech_prob": 2.29589500122529e-06}, {"id": 1495, "seek": 605912, "start": 6074.5599999999995, "end": 6078.04, "text": " You can in fact do it on a combination of jigsaw and rotation, and you can get more", "tokens": [50364, 26531, 11, 9735, 337, 361, 17156, 1607, 11, 570, 291, 434, 32884, 300, 11, 291, 434, 588, 5567, 538, 264, 50582, 50582, 2744, 295, 428, 5598, 1901, 13, 50806, 50806, 400, 264, 3035, 611, 3110, 300, 321, 393, 10101, 3026, 75, 281, 406, 445, 411, 11, 309, 311, 406, 5567, 281, 51024, 51024, 361, 17156, 1607, 11, 291, 393, 360, 300, 322, 12447, 13, 51136, 51136, 509, 393, 294, 1186, 360, 309, 322, 257, 6562, 295, 361, 17156, 1607, 293, 12447, 11, 293, 291, 393, 483, 544, 51310, 51310, 293, 544, 16823, 562, 291, 1936, 722, 884, 341, 13, 51592, 51592], "temperature": 0.0, "avg_logprob": -0.16067499327428134, "compression_ratio": 1.6923076923076923, "no_speech_prob": 2.29589500122529e-06}, {"id": 1496, "seek": 605912, "start": 6078.04, "end": 6083.68, "text": " and more gains when you basically start doing this.", "tokens": [50364, 26531, 11, 9735, 337, 361, 17156, 1607, 11, 570, 291, 434, 32884, 300, 11, 291, 434, 588, 5567, 538, 264, 50582, 50582, 2744, 295, 428, 5598, 1901, 13, 50806, 50806, 400, 264, 3035, 611, 3110, 300, 321, 393, 10101, 3026, 75, 281, 406, 445, 411, 11, 309, 311, 406, 5567, 281, 51024, 51024, 361, 17156, 1607, 11, 291, 393, 360, 300, 322, 12447, 13, 51136, 51136, 509, 393, 294, 1186, 360, 309, 322, 257, 6562, 295, 361, 17156, 1607, 293, 12447, 11, 293, 291, 393, 483, 544, 51310, 51310, 293, 544, 16823, 562, 291, 1936, 722, 884, 341, 13, 51592, 51592], "temperature": 0.0, "avg_logprob": -0.16067499327428134, "compression_ratio": 1.6923076923076923, "no_speech_prob": 2.29589500122529e-06}, {"id": 1497, "seek": 608368, "start": 6083.68, "end": 6089.16, "text": " So basically, if you look at these methods, starting from pretext tasks to clustering", "tokens": [50364, 407, 1936, 11, 498, 291, 574, 412, 613, 7150, 11, 2891, 490, 659, 25111, 9608, 281, 596, 48673, 50638, 50638, 281, 3026, 75, 11, 382, 291, 352, 490, 264, 1411, 281, 264, 558, 11, 291, 1936, 483, 544, 293, 544, 33270, 719, 13, 50912, 50912, 400, 294, 512, 636, 11, 291, 611, 536, 364, 3488, 294, 3389, 11, 597, 1333, 295, 13409, 300, 51139, 51139, 12102, 294, 544, 293, 544, 33270, 719, 281, 428, 7150, 307, 767, 516, 281, 312, 544, 4961, 51312, 51312, 294, 264, 938, 1433, 13, 51448, 51448, 821, 366, 512, 2099, 49886, 11, 597, 307, 1936, 300, 321, 534, 360, 406, 1223, 437, 366, 51662, 51662, 264, 992, 295, 1412, 35592, 300, 1871, 13, 51773, 51773], "temperature": 0.0, "avg_logprob": -0.12343577087902632, "compression_ratio": 1.7978339350180506, "no_speech_prob": 1.7603135802346515e-06}, {"id": 1498, "seek": 608368, "start": 6089.16, "end": 6094.64, "text": " to Perl, as you go from the left to the right, you basically get more and more invariance.", "tokens": [50364, 407, 1936, 11, 498, 291, 574, 412, 613, 7150, 11, 2891, 490, 659, 25111, 9608, 281, 596, 48673, 50638, 50638, 281, 3026, 75, 11, 382, 291, 352, 490, 264, 1411, 281, 264, 558, 11, 291, 1936, 483, 544, 293, 544, 33270, 719, 13, 50912, 50912, 400, 294, 512, 636, 11, 291, 611, 536, 364, 3488, 294, 3389, 11, 597, 1333, 295, 13409, 300, 51139, 51139, 12102, 294, 544, 293, 544, 33270, 719, 281, 428, 7150, 307, 767, 516, 281, 312, 544, 4961, 51312, 51312, 294, 264, 938, 1433, 13, 51448, 51448, 821, 366, 512, 2099, 49886, 11, 597, 307, 1936, 300, 321, 534, 360, 406, 1223, 437, 366, 51662, 51662, 264, 992, 295, 1412, 35592, 300, 1871, 13, 51773, 51773], "temperature": 0.0, "avg_logprob": -0.12343577087902632, "compression_ratio": 1.7978339350180506, "no_speech_prob": 1.7603135802346515e-06}, {"id": 1499, "seek": 608368, "start": 6094.64, "end": 6099.18, "text": " And in some way, you also see an increase in performance, which sort of suggests that", "tokens": [50364, 407, 1936, 11, 498, 291, 574, 412, 613, 7150, 11, 2891, 490, 659, 25111, 9608, 281, 596, 48673, 50638, 50638, 281, 3026, 75, 11, 382, 291, 352, 490, 264, 1411, 281, 264, 558, 11, 291, 1936, 483, 544, 293, 544, 33270, 719, 13, 50912, 50912, 400, 294, 512, 636, 11, 291, 611, 536, 364, 3488, 294, 3389, 11, 597, 1333, 295, 13409, 300, 51139, 51139, 12102, 294, 544, 293, 544, 33270, 719, 281, 428, 7150, 307, 767, 516, 281, 312, 544, 4961, 51312, 51312, 294, 264, 938, 1433, 13, 51448, 51448, 821, 366, 512, 2099, 49886, 11, 597, 307, 1936, 300, 321, 534, 360, 406, 1223, 437, 366, 51662, 51662, 264, 992, 295, 1412, 35592, 300, 1871, 13, 51773, 51773], "temperature": 0.0, "avg_logprob": -0.12343577087902632, "compression_ratio": 1.7978339350180506, "no_speech_prob": 1.7603135802346515e-06}, {"id": 1500, "seek": 608368, "start": 6099.18, "end": 6102.64, "text": " baking in more and more invariance to your methods is actually going to be more helpful", "tokens": [50364, 407, 1936, 11, 498, 291, 574, 412, 613, 7150, 11, 2891, 490, 659, 25111, 9608, 281, 596, 48673, 50638, 50638, 281, 3026, 75, 11, 382, 291, 352, 490, 264, 1411, 281, 264, 558, 11, 291, 1936, 483, 544, 293, 544, 33270, 719, 13, 50912, 50912, 400, 294, 512, 636, 11, 291, 611, 536, 364, 3488, 294, 3389, 11, 597, 1333, 295, 13409, 300, 51139, 51139, 12102, 294, 544, 293, 544, 33270, 719, 281, 428, 7150, 307, 767, 516, 281, 312, 544, 4961, 51312, 51312, 294, 264, 938, 1433, 13, 51448, 51448, 821, 366, 512, 2099, 49886, 11, 597, 307, 1936, 300, 321, 534, 360, 406, 1223, 437, 366, 51662, 51662, 264, 992, 295, 1412, 35592, 300, 1871, 13, 51773, 51773], "temperature": 0.0, "avg_logprob": -0.12343577087902632, "compression_ratio": 1.7978339350180506, "no_speech_prob": 1.7603135802346515e-06}, {"id": 1501, "seek": 608368, "start": 6102.64, "end": 6105.360000000001, "text": " in the long term.", "tokens": [50364, 407, 1936, 11, 498, 291, 574, 412, 613, 7150, 11, 2891, 490, 659, 25111, 9608, 281, 596, 48673, 50638, 50638, 281, 3026, 75, 11, 382, 291, 352, 490, 264, 1411, 281, 264, 558, 11, 291, 1936, 483, 544, 293, 544, 33270, 719, 13, 50912, 50912, 400, 294, 512, 636, 11, 291, 611, 536, 364, 3488, 294, 3389, 11, 597, 1333, 295, 13409, 300, 51139, 51139, 12102, 294, 544, 293, 544, 33270, 719, 281, 428, 7150, 307, 767, 516, 281, 312, 544, 4961, 51312, 51312, 294, 264, 938, 1433, 13, 51448, 51448, 821, 366, 512, 2099, 49886, 11, 597, 307, 1936, 300, 321, 534, 360, 406, 1223, 437, 366, 51662, 51662, 264, 992, 295, 1412, 35592, 300, 1871, 13, 51773, 51773], "temperature": 0.0, "avg_logprob": -0.12343577087902632, "compression_ratio": 1.7978339350180506, "no_speech_prob": 1.7603135802346515e-06}, {"id": 1502, "seek": 608368, "start": 6105.360000000001, "end": 6109.64, "text": " There are some shortcomings, which is basically that we really do not understand what are", "tokens": [50364, 407, 1936, 11, 498, 291, 574, 412, 613, 7150, 11, 2891, 490, 659, 25111, 9608, 281, 596, 48673, 50638, 50638, 281, 3026, 75, 11, 382, 291, 352, 490, 264, 1411, 281, 264, 558, 11, 291, 1936, 483, 544, 293, 544, 33270, 719, 13, 50912, 50912, 400, 294, 512, 636, 11, 291, 611, 536, 364, 3488, 294, 3389, 11, 597, 1333, 295, 13409, 300, 51139, 51139, 12102, 294, 544, 293, 544, 33270, 719, 281, 428, 7150, 307, 767, 516, 281, 312, 544, 4961, 51312, 51312, 294, 264, 938, 1433, 13, 51448, 51448, 821, 366, 512, 2099, 49886, 11, 597, 307, 1936, 300, 321, 534, 360, 406, 1223, 437, 366, 51662, 51662, 264, 992, 295, 1412, 35592, 300, 1871, 13, 51773, 51773], "temperature": 0.0, "avg_logprob": -0.12343577087902632, "compression_ratio": 1.7978339350180506, "no_speech_prob": 1.7603135802346515e-06}, {"id": 1503, "seek": 608368, "start": 6109.64, "end": 6111.860000000001, "text": " the set of data transforms that matter.", "tokens": [50364, 407, 1936, 11, 498, 291, 574, 412, 613, 7150, 11, 2891, 490, 659, 25111, 9608, 281, 596, 48673, 50638, 50638, 281, 3026, 75, 11, 382, 291, 352, 490, 264, 1411, 281, 264, 558, 11, 291, 1936, 483, 544, 293, 544, 33270, 719, 13, 50912, 50912, 400, 294, 512, 636, 11, 291, 611, 536, 364, 3488, 294, 3389, 11, 597, 1333, 295, 13409, 300, 51139, 51139, 12102, 294, 544, 293, 544, 33270, 719, 281, 428, 7150, 307, 767, 516, 281, 312, 544, 4961, 51312, 51312, 294, 264, 938, 1433, 13, 51448, 51448, 821, 366, 512, 2099, 49886, 11, 597, 307, 1936, 300, 321, 534, 360, 406, 1223, 437, 366, 51662, 51662, 264, 992, 295, 1412, 35592, 300, 1871, 13, 51773, 51773], "temperature": 0.0, "avg_logprob": -0.12343577087902632, "compression_ratio": 1.7978339350180506, "no_speech_prob": 1.7603135802346515e-06}, {"id": 1504, "seek": 611186, "start": 6111.86, "end": 6117.08, "text": " So jigsaw works really well, but it's not very clear why this is happening.", "tokens": [50364, 407, 361, 17156, 1607, 1985, 534, 731, 11, 457, 309, 311, 406, 588, 1850, 983, 341, 307, 2737, 13, 50625, 50625, 407, 512, 1333, 295, 2027, 589, 11, 420, 498, 291, 528, 281, 3496, 428, 13798, 17796, 1953, 466, 50843, 50843, 746, 307, 534, 3701, 437, 33270, 2676, 534, 1871, 562, 291, 434, 1382, 281, 5039, 51121, 51121, 257, 46533, 5633, 13, 51191, 51191, 708, 33270, 719, 534, 1871, 337, 746, 411, 257, 4447, 13, 51437, 51437, 400, 300, 311, 309, 13, 51487, 51487, 407, 1936, 6069, 544, 293, 544, 1589, 293, 853, 281, 312, 382, 33270, 394, 382, 1944, 13, 51695, 51695, 1044, 291, 13, 51745, 51745], "temperature": 0.0, "avg_logprob": -0.19907684326171876, "compression_ratio": 1.702290076335878, "no_speech_prob": 8.267496014013886e-06}, {"id": 1505, "seek": 611186, "start": 6117.08, "end": 6121.44, "text": " So some sort of future work, or if you want to spend your spare cycles thinking about", "tokens": [50364, 407, 361, 17156, 1607, 1985, 534, 731, 11, 457, 309, 311, 406, 588, 1850, 983, 341, 307, 2737, 13, 50625, 50625, 407, 512, 1333, 295, 2027, 589, 11, 420, 498, 291, 528, 281, 3496, 428, 13798, 17796, 1953, 466, 50843, 50843, 746, 307, 534, 3701, 437, 33270, 2676, 534, 1871, 562, 291, 434, 1382, 281, 5039, 51121, 51121, 257, 46533, 5633, 13, 51191, 51191, 708, 33270, 719, 534, 1871, 337, 746, 411, 257, 4447, 13, 51437, 51437, 400, 300, 311, 309, 13, 51487, 51487, 407, 1936, 6069, 544, 293, 544, 1589, 293, 853, 281, 312, 382, 33270, 394, 382, 1944, 13, 51695, 51695, 1044, 291, 13, 51745, 51745], "temperature": 0.0, "avg_logprob": -0.19907684326171876, "compression_ratio": 1.702290076335878, "no_speech_prob": 8.267496014013886e-06}, {"id": 1506, "seek": 611186, "start": 6121.44, "end": 6127.0, "text": " something is really understanding what invariances really matter when you're trying to solve", "tokens": [50364, 407, 361, 17156, 1607, 1985, 534, 731, 11, 457, 309, 311, 406, 588, 1850, 983, 341, 307, 2737, 13, 50625, 50625, 407, 512, 1333, 295, 2027, 589, 11, 420, 498, 291, 528, 281, 3496, 428, 13798, 17796, 1953, 466, 50843, 50843, 746, 307, 534, 3701, 437, 33270, 2676, 534, 1871, 562, 291, 434, 1382, 281, 5039, 51121, 51121, 257, 46533, 5633, 13, 51191, 51191, 708, 33270, 719, 534, 1871, 337, 746, 411, 257, 4447, 13, 51437, 51437, 400, 300, 311, 309, 13, 51487, 51487, 407, 1936, 6069, 544, 293, 544, 1589, 293, 853, 281, 312, 382, 33270, 394, 382, 1944, 13, 51695, 51695, 1044, 291, 13, 51745, 51745], "temperature": 0.0, "avg_logprob": -0.19907684326171876, "compression_ratio": 1.702290076335878, "no_speech_prob": 8.267496014013886e-06}, {"id": 1507, "seek": 611186, "start": 6127.0, "end": 6128.4, "text": " a supervised task.", "tokens": [50364, 407, 361, 17156, 1607, 1985, 534, 731, 11, 457, 309, 311, 406, 588, 1850, 983, 341, 307, 2737, 13, 50625, 50625, 407, 512, 1333, 295, 2027, 589, 11, 420, 498, 291, 528, 281, 3496, 428, 13798, 17796, 1953, 466, 50843, 50843, 746, 307, 534, 3701, 437, 33270, 2676, 534, 1871, 562, 291, 434, 1382, 281, 5039, 51121, 51121, 257, 46533, 5633, 13, 51191, 51191, 708, 33270, 719, 534, 1871, 337, 746, 411, 257, 4447, 13, 51437, 51437, 400, 300, 311, 309, 13, 51487, 51487, 407, 1936, 6069, 544, 293, 544, 1589, 293, 853, 281, 312, 382, 33270, 394, 382, 1944, 13, 51695, 51695, 1044, 291, 13, 51745, 51745], "temperature": 0.0, "avg_logprob": -0.19907684326171876, "compression_ratio": 1.702290076335878, "no_speech_prob": 8.267496014013886e-06}, {"id": 1508, "seek": 611186, "start": 6128.4, "end": 6133.32, "text": " What invariance really matter for something like a mission.", "tokens": [50364, 407, 361, 17156, 1607, 1985, 534, 731, 11, 457, 309, 311, 406, 588, 1850, 983, 341, 307, 2737, 13, 50625, 50625, 407, 512, 1333, 295, 2027, 589, 11, 420, 498, 291, 528, 281, 3496, 428, 13798, 17796, 1953, 466, 50843, 50843, 746, 307, 534, 3701, 437, 33270, 2676, 534, 1871, 562, 291, 434, 1382, 281, 5039, 51121, 51121, 257, 46533, 5633, 13, 51191, 51191, 708, 33270, 719, 534, 1871, 337, 746, 411, 257, 4447, 13, 51437, 51437, 400, 300, 311, 309, 13, 51487, 51487, 407, 1936, 6069, 544, 293, 544, 1589, 293, 853, 281, 312, 382, 33270, 394, 382, 1944, 13, 51695, 51695, 1044, 291, 13, 51745, 51745], "temperature": 0.0, "avg_logprob": -0.19907684326171876, "compression_ratio": 1.702290076335878, "no_speech_prob": 8.267496014013886e-06}, {"id": 1509, "seek": 611186, "start": 6133.32, "end": 6134.32, "text": " And that's it.", "tokens": [50364, 407, 361, 17156, 1607, 1985, 534, 731, 11, 457, 309, 311, 406, 588, 1850, 983, 341, 307, 2737, 13, 50625, 50625, 407, 512, 1333, 295, 2027, 589, 11, 420, 498, 291, 528, 281, 3496, 428, 13798, 17796, 1953, 466, 50843, 50843, 746, 307, 534, 3701, 437, 33270, 2676, 534, 1871, 562, 291, 434, 1382, 281, 5039, 51121, 51121, 257, 46533, 5633, 13, 51191, 51191, 708, 33270, 719, 534, 1871, 337, 746, 411, 257, 4447, 13, 51437, 51437, 400, 300, 311, 309, 13, 51487, 51487, 407, 1936, 6069, 544, 293, 544, 1589, 293, 853, 281, 312, 382, 33270, 394, 382, 1944, 13, 51695, 51695, 1044, 291, 13, 51745, 51745], "temperature": 0.0, "avg_logprob": -0.19907684326171876, "compression_ratio": 1.702290076335878, "no_speech_prob": 8.267496014013886e-06}, {"id": 1510, "seek": 611186, "start": 6134.32, "end": 6138.48, "text": " So basically predict more and more information and try to be as invariant as possible.", "tokens": [50364, 407, 361, 17156, 1607, 1985, 534, 731, 11, 457, 309, 311, 406, 588, 1850, 983, 341, 307, 2737, 13, 50625, 50625, 407, 512, 1333, 295, 2027, 589, 11, 420, 498, 291, 528, 281, 3496, 428, 13798, 17796, 1953, 466, 50843, 50843, 746, 307, 534, 3701, 437, 33270, 2676, 534, 1871, 562, 291, 434, 1382, 281, 5039, 51121, 51121, 257, 46533, 5633, 13, 51191, 51191, 708, 33270, 719, 534, 1871, 337, 746, 411, 257, 4447, 13, 51437, 51437, 400, 300, 311, 309, 13, 51487, 51487, 407, 1936, 6069, 544, 293, 544, 1589, 293, 853, 281, 312, 382, 33270, 394, 382, 1944, 13, 51695, 51695, 1044, 291, 13, 51745, 51745], "temperature": 0.0, "avg_logprob": -0.19907684326171876, "compression_ratio": 1.702290076335878, "no_speech_prob": 8.267496014013886e-06}, {"id": 1511, "seek": 611186, "start": 6138.48, "end": 6139.48, "text": " Thank you.", "tokens": [50364, 407, 361, 17156, 1607, 1985, 534, 731, 11, 457, 309, 311, 406, 588, 1850, 983, 341, 307, 2737, 13, 50625, 50625, 407, 512, 1333, 295, 2027, 589, 11, 420, 498, 291, 528, 281, 3496, 428, 13798, 17796, 1953, 466, 50843, 50843, 746, 307, 534, 3701, 437, 33270, 2676, 534, 1871, 562, 291, 434, 1382, 281, 5039, 51121, 51121, 257, 46533, 5633, 13, 51191, 51191, 708, 33270, 719, 534, 1871, 337, 746, 411, 257, 4447, 13, 51437, 51437, 400, 300, 311, 309, 13, 51487, 51487, 407, 1936, 6069, 544, 293, 544, 1589, 293, 853, 281, 312, 382, 33270, 394, 382, 1944, 13, 51695, 51695, 1044, 291, 13, 51745, 51745], "temperature": 0.0, "avg_logprob": -0.19907684326171876, "compression_ratio": 1.702290076335878, "no_speech_prob": 8.267496014013886e-06}, {"id": 1512, "seek": 613948, "start": 6139.48, "end": 6142.839999999999, "text": " Hey, so I had a question.", "tokens": [50364, 1911, 11, 370, 286, 632, 257, 1168, 13, 50532, 50532, 1079, 11, 613, 8712, 488, 9590, 11, 436, 393, 380, 764, 264, 15245, 2026, 4583, 11, 558, 30, 50764, 50764, 1436, 550, 1589, 576, 1320, 490, 472, 6889, 281, 264, 661, 13, 50930, 50930, 400, 550, 264, 3209, 1062, 1466, 257, 588, 26703, 636, 295, 29279, 264, 40019, 490, 264, 3353, 13, 51300, 51300, 407, 309, 411, 337, 1365, 11, 321, 534, 630, 406, 11441, 300, 14029, 412, 439, 13, 51558, 51558, 407, 321, 630, 406, 534, 362, 281, 360, 604, 2121, 11733, 365, 15245, 13, 51702, 51702], "temperature": 0.0, "avg_logprob": -0.2207956886291504, "compression_ratio": 1.6224899598393574, "no_speech_prob": 0.0001231309724971652}, {"id": 1513, "seek": 613948, "start": 6142.839999999999, "end": 6147.48, "text": " Yes, these contrastive networks, they can't use the batch norm layer, right?", "tokens": [50364, 1911, 11, 370, 286, 632, 257, 1168, 13, 50532, 50532, 1079, 11, 613, 8712, 488, 9590, 11, 436, 393, 380, 764, 264, 15245, 2026, 4583, 11, 558, 30, 50764, 50764, 1436, 550, 1589, 576, 1320, 490, 472, 6889, 281, 264, 661, 13, 50930, 50930, 400, 550, 264, 3209, 1062, 1466, 257, 588, 26703, 636, 295, 29279, 264, 40019, 490, 264, 3353, 13, 51300, 51300, 407, 309, 411, 337, 1365, 11, 321, 534, 630, 406, 11441, 300, 14029, 412, 439, 13, 51558, 51558, 407, 321, 630, 406, 534, 362, 281, 360, 604, 2121, 11733, 365, 15245, 13, 51702, 51702], "temperature": 0.0, "avg_logprob": -0.2207956886291504, "compression_ratio": 1.6224899598393574, "no_speech_prob": 0.0001231309724971652}, {"id": 1514, "seek": 613948, "start": 6147.48, "end": 6150.799999999999, "text": " Because then information would pass from one sample to the other.", "tokens": [50364, 1911, 11, 370, 286, 632, 257, 1168, 13, 50532, 50532, 1079, 11, 613, 8712, 488, 9590, 11, 436, 393, 380, 764, 264, 15245, 2026, 4583, 11, 558, 30, 50764, 50764, 1436, 550, 1589, 576, 1320, 490, 472, 6889, 281, 264, 661, 13, 50930, 50930, 400, 550, 264, 3209, 1062, 1466, 257, 588, 26703, 636, 295, 29279, 264, 40019, 490, 264, 3353, 13, 51300, 51300, 407, 309, 411, 337, 1365, 11, 321, 534, 630, 406, 11441, 300, 14029, 412, 439, 13, 51558, 51558, 407, 321, 630, 406, 534, 362, 281, 360, 604, 2121, 11733, 365, 15245, 13, 51702, 51702], "temperature": 0.0, "avg_logprob": -0.2207956886291504, "compression_ratio": 1.6224899598393574, "no_speech_prob": 0.0001231309724971652}, {"id": 1515, "seek": 613948, "start": 6150.799999999999, "end": 6158.2, "text": " And then the network might learn a very trivial way of separating the negatives from the positive.", "tokens": [50364, 1911, 11, 370, 286, 632, 257, 1168, 13, 50532, 50532, 1079, 11, 613, 8712, 488, 9590, 11, 436, 393, 380, 764, 264, 15245, 2026, 4583, 11, 558, 30, 50764, 50764, 1436, 550, 1589, 576, 1320, 490, 472, 6889, 281, 264, 661, 13, 50930, 50930, 400, 550, 264, 3209, 1062, 1466, 257, 588, 26703, 636, 295, 29279, 264, 40019, 490, 264, 3353, 13, 51300, 51300, 407, 309, 411, 337, 1365, 11, 321, 534, 630, 406, 11441, 300, 14029, 412, 439, 13, 51558, 51558, 407, 321, 630, 406, 534, 362, 281, 360, 604, 2121, 11733, 365, 15245, 13, 51702, 51702], "temperature": 0.0, "avg_logprob": -0.2207956886291504, "compression_ratio": 1.6224899598393574, "no_speech_prob": 0.0001231309724971652}, {"id": 1516, "seek": 613948, "start": 6158.2, "end": 6163.36, "text": " So it like for example, we really did not observe that phenomenon at all.", "tokens": [50364, 1911, 11, 370, 286, 632, 257, 1168, 13, 50532, 50532, 1079, 11, 613, 8712, 488, 9590, 11, 436, 393, 380, 764, 264, 15245, 2026, 4583, 11, 558, 30, 50764, 50764, 1436, 550, 1589, 576, 1320, 490, 472, 6889, 281, 264, 661, 13, 50930, 50930, 400, 550, 264, 3209, 1062, 1466, 257, 588, 26703, 636, 295, 29279, 264, 40019, 490, 264, 3353, 13, 51300, 51300, 407, 309, 411, 337, 1365, 11, 321, 534, 630, 406, 11441, 300, 14029, 412, 439, 13, 51558, 51558, 407, 321, 630, 406, 534, 362, 281, 360, 604, 2121, 11733, 365, 15245, 13, 51702, 51702], "temperature": 0.0, "avg_logprob": -0.2207956886291504, "compression_ratio": 1.6224899598393574, "no_speech_prob": 0.0001231309724971652}, {"id": 1517, "seek": 613948, "start": 6163.36, "end": 6166.24, "text": " So we did not really have to do any special tricks with batch.", "tokens": [50364, 1911, 11, 370, 286, 632, 257, 1168, 13, 50532, 50532, 1079, 11, 613, 8712, 488, 9590, 11, 436, 393, 380, 764, 264, 15245, 2026, 4583, 11, 558, 30, 50764, 50764, 1436, 550, 1589, 576, 1320, 490, 472, 6889, 281, 264, 661, 13, 50930, 50930, 400, 550, 264, 3209, 1062, 1466, 257, 588, 26703, 636, 295, 29279, 264, 40019, 490, 264, 3353, 13, 51300, 51300, 407, 309, 411, 337, 1365, 11, 321, 534, 630, 406, 11441, 300, 14029, 412, 439, 13, 51558, 51558, 407, 321, 630, 406, 534, 362, 281, 360, 604, 2121, 11733, 365, 15245, 13, 51702, 51702], "temperature": 0.0, "avg_logprob": -0.2207956886291504, "compression_ratio": 1.6224899598393574, "no_speech_prob": 0.0001231309724971652}, {"id": 1518, "seek": 616624, "start": 6166.24, "end": 6169.84, "text": " No, we were able to use batch norm as is.", "tokens": [50364, 883, 11, 321, 645, 1075, 281, 764, 15245, 2026, 382, 307, 13, 50544, 50544, 1033, 13, 50618, 50618, 400, 309, 311, 406, 4818, 337, 439, 264, 8712, 488, 9590, 281, 406, 312, 1228, 15245, 2026, 13, 50845, 50845, 467, 311, 1392, 281, 362, 264, 15245, 2026, 4583, 13, 50970, 50970, 467, 311, 1338, 11, 309, 311, 286, 914, 11, 337, 1365, 11, 337, 18587, 293, 370, 322, 11, 436, 853, 281, 1286, 281, 20271, 15245, 51272, 51272, 2026, 570, 436, 528, 281, 45497, 257, 2416, 15245, 2744, 13, 51424, 51424, 407, 291, 1062, 362, 281, 360, 512, 46664, 294, 15245, 2026, 13, 51610, 51610, 583, 1936, 11, 291, 2644, 5042, 309, 534, 11, 570, 498, 291, 2584, 4159, 15245, 2026, 11, 51812, 51812], "temperature": 0.0, "avg_logprob": -0.22337313842773437, "compression_ratio": 1.7567567567567568, "no_speech_prob": 2.9767659725621343e-05}, {"id": 1519, "seek": 616624, "start": 6169.84, "end": 6171.32, "text": " Okay.", "tokens": [50364, 883, 11, 321, 645, 1075, 281, 764, 15245, 2026, 382, 307, 13, 50544, 50544, 1033, 13, 50618, 50618, 400, 309, 311, 406, 4818, 337, 439, 264, 8712, 488, 9590, 281, 406, 312, 1228, 15245, 2026, 13, 50845, 50845, 467, 311, 1392, 281, 362, 264, 15245, 2026, 4583, 13, 50970, 50970, 467, 311, 1338, 11, 309, 311, 286, 914, 11, 337, 1365, 11, 337, 18587, 293, 370, 322, 11, 436, 853, 281, 1286, 281, 20271, 15245, 51272, 51272, 2026, 570, 436, 528, 281, 45497, 257, 2416, 15245, 2744, 13, 51424, 51424, 407, 291, 1062, 362, 281, 360, 512, 46664, 294, 15245, 2026, 13, 51610, 51610, 583, 1936, 11, 291, 2644, 5042, 309, 534, 11, 570, 498, 291, 2584, 4159, 15245, 2026, 11, 51812, 51812], "temperature": 0.0, "avg_logprob": -0.22337313842773437, "compression_ratio": 1.7567567567567568, "no_speech_prob": 2.9767659725621343e-05}, {"id": 1520, "seek": 616624, "start": 6171.32, "end": 6175.86, "text": " And it's not necessary for all the contrastive networks to not be using batch norm.", "tokens": [50364, 883, 11, 321, 645, 1075, 281, 764, 15245, 2026, 382, 307, 13, 50544, 50544, 1033, 13, 50618, 50618, 400, 309, 311, 406, 4818, 337, 439, 264, 8712, 488, 9590, 281, 406, 312, 1228, 15245, 2026, 13, 50845, 50845, 467, 311, 1392, 281, 362, 264, 15245, 2026, 4583, 13, 50970, 50970, 467, 311, 1338, 11, 309, 311, 286, 914, 11, 337, 1365, 11, 337, 18587, 293, 370, 322, 11, 436, 853, 281, 1286, 281, 20271, 15245, 51272, 51272, 2026, 570, 436, 528, 281, 45497, 257, 2416, 15245, 2744, 13, 51424, 51424, 407, 291, 1062, 362, 281, 360, 512, 46664, 294, 15245, 2026, 13, 51610, 51610, 583, 1936, 11, 291, 2644, 5042, 309, 534, 11, 570, 498, 291, 2584, 4159, 15245, 2026, 11, 51812, 51812], "temperature": 0.0, "avg_logprob": -0.22337313842773437, "compression_ratio": 1.7567567567567568, "no_speech_prob": 2.9767659725621343e-05}, {"id": 1521, "seek": 616624, "start": 6175.86, "end": 6178.36, "text": " It's okay to have the batch norm layer.", "tokens": [50364, 883, 11, 321, 645, 1075, 281, 764, 15245, 2026, 382, 307, 13, 50544, 50544, 1033, 13, 50618, 50618, 400, 309, 311, 406, 4818, 337, 439, 264, 8712, 488, 9590, 281, 406, 312, 1228, 15245, 2026, 13, 50845, 50845, 467, 311, 1392, 281, 362, 264, 15245, 2026, 4583, 13, 50970, 50970, 467, 311, 1338, 11, 309, 311, 286, 914, 11, 337, 1365, 11, 337, 18587, 293, 370, 322, 11, 436, 853, 281, 1286, 281, 20271, 15245, 51272, 51272, 2026, 570, 436, 528, 281, 45497, 257, 2416, 15245, 2744, 13, 51424, 51424, 407, 291, 1062, 362, 281, 360, 512, 46664, 294, 15245, 2026, 13, 51610, 51610, 583, 1936, 11, 291, 2644, 5042, 309, 534, 11, 570, 498, 291, 2584, 4159, 15245, 2026, 11, 51812, 51812], "temperature": 0.0, "avg_logprob": -0.22337313842773437, "compression_ratio": 1.7567567567567568, "no_speech_prob": 2.9767659725621343e-05}, {"id": 1522, "seek": 616624, "start": 6178.36, "end": 6184.4, "text": " It's yeah, it's I mean, for example, for simpler and so on, they try to move to sync batch", "tokens": [50364, 883, 11, 321, 645, 1075, 281, 764, 15245, 2026, 382, 307, 13, 50544, 50544, 1033, 13, 50618, 50618, 400, 309, 311, 406, 4818, 337, 439, 264, 8712, 488, 9590, 281, 406, 312, 1228, 15245, 2026, 13, 50845, 50845, 467, 311, 1392, 281, 362, 264, 15245, 2026, 4583, 13, 50970, 50970, 467, 311, 1338, 11, 309, 311, 286, 914, 11, 337, 1365, 11, 337, 18587, 293, 370, 322, 11, 436, 853, 281, 1286, 281, 20271, 15245, 51272, 51272, 2026, 570, 436, 528, 281, 45497, 257, 2416, 15245, 2744, 13, 51424, 51424, 407, 291, 1062, 362, 281, 360, 512, 46664, 294, 15245, 2026, 13, 51610, 51610, 583, 1936, 11, 291, 2644, 5042, 309, 534, 11, 570, 498, 291, 2584, 4159, 15245, 2026, 11, 51812, 51812], "temperature": 0.0, "avg_logprob": -0.22337313842773437, "compression_ratio": 1.7567567567567568, "no_speech_prob": 2.9767659725621343e-05}, {"id": 1523, "seek": 616624, "start": 6184.4, "end": 6187.44, "text": " norm because they want to emulate a large batch size.", "tokens": [50364, 883, 11, 321, 645, 1075, 281, 764, 15245, 2026, 382, 307, 13, 50544, 50544, 1033, 13, 50618, 50618, 400, 309, 311, 406, 4818, 337, 439, 264, 8712, 488, 9590, 281, 406, 312, 1228, 15245, 2026, 13, 50845, 50845, 467, 311, 1392, 281, 362, 264, 15245, 2026, 4583, 13, 50970, 50970, 467, 311, 1338, 11, 309, 311, 286, 914, 11, 337, 1365, 11, 337, 18587, 293, 370, 322, 11, 436, 853, 281, 1286, 281, 20271, 15245, 51272, 51272, 2026, 570, 436, 528, 281, 45497, 257, 2416, 15245, 2744, 13, 51424, 51424, 407, 291, 1062, 362, 281, 360, 512, 46664, 294, 15245, 2026, 13, 51610, 51610, 583, 1936, 11, 291, 2644, 5042, 309, 534, 11, 570, 498, 291, 2584, 4159, 15245, 2026, 11, 51812, 51812], "temperature": 0.0, "avg_logprob": -0.22337313842773437, "compression_ratio": 1.7567567567567568, "no_speech_prob": 2.9767659725621343e-05}, {"id": 1524, "seek": 616624, "start": 6187.44, "end": 6191.16, "text": " So you might have to do some tweaks in batch norm.", "tokens": [50364, 883, 11, 321, 645, 1075, 281, 764, 15245, 2026, 382, 307, 13, 50544, 50544, 1033, 13, 50618, 50618, 400, 309, 311, 406, 4818, 337, 439, 264, 8712, 488, 9590, 281, 406, 312, 1228, 15245, 2026, 13, 50845, 50845, 467, 311, 1392, 281, 362, 264, 15245, 2026, 4583, 13, 50970, 50970, 467, 311, 1338, 11, 309, 311, 286, 914, 11, 337, 1365, 11, 337, 18587, 293, 370, 322, 11, 436, 853, 281, 1286, 281, 20271, 15245, 51272, 51272, 2026, 570, 436, 528, 281, 45497, 257, 2416, 15245, 2744, 13, 51424, 51424, 407, 291, 1062, 362, 281, 360, 512, 46664, 294, 15245, 2026, 13, 51610, 51610, 583, 1936, 11, 291, 2644, 5042, 309, 534, 11, 570, 498, 291, 2584, 4159, 15245, 2026, 11, 51812, 51812], "temperature": 0.0, "avg_logprob": -0.22337313842773437, "compression_ratio": 1.7567567567567568, "no_speech_prob": 2.9767659725621343e-05}, {"id": 1525, "seek": 616624, "start": 6191.16, "end": 6195.2, "text": " But basically, you cannot avoid it really, because if you completely remove batch norm,", "tokens": [50364, 883, 11, 321, 645, 1075, 281, 764, 15245, 2026, 382, 307, 13, 50544, 50544, 1033, 13, 50618, 50618, 400, 309, 311, 406, 4818, 337, 439, 264, 8712, 488, 9590, 281, 406, 312, 1228, 15245, 2026, 13, 50845, 50845, 467, 311, 1392, 281, 362, 264, 15245, 2026, 4583, 13, 50970, 50970, 467, 311, 1338, 11, 309, 311, 286, 914, 11, 337, 1365, 11, 337, 18587, 293, 370, 322, 11, 436, 853, 281, 1286, 281, 20271, 15245, 51272, 51272, 2026, 570, 436, 528, 281, 45497, 257, 2416, 15245, 2744, 13, 51424, 51424, 407, 291, 1062, 362, 281, 360, 512, 46664, 294, 15245, 2026, 13, 51610, 51610, 583, 1936, 11, 291, 2644, 5042, 309, 534, 11, 570, 498, 291, 2584, 4159, 15245, 2026, 11, 51812, 51812], "temperature": 0.0, "avg_logprob": -0.22337313842773437, "compression_ratio": 1.7567567567567568, "no_speech_prob": 2.9767659725621343e-05}, {"id": 1526, "seek": 619520, "start": 6195.2, "end": 6199.48, "text": " then training these like very deep networks is generally very hard anyway.", "tokens": [50364, 550, 3097, 613, 411, 588, 2452, 9590, 307, 5101, 588, 1152, 4033, 13, 50578, 50578, 1033, 11, 360, 291, 519, 300, 3026, 75, 3035, 1985, 365, 264, 15245, 2026, 7914, 570, 309, 4960, 257, 4675, 50960, 50960, 3765, 293, 439, 264, 33358, 366, 406, 2726, 412, 264, 912, 565, 30, 51178, 51178, 13813, 286, 519, 3335, 21141, 11, 436, 4682, 2835, 406, 281, 764, 264, 15245, 2026, 4583, 420, 764, 309, 51524, 51524, 3974, 2108, 3866, 18407, 82, 13, 51634, 51634, 407, 300, 300, 286, 519, 307, 472, 2649, 337, 988, 13, 51754, 51754], "temperature": 0.0, "avg_logprob": -0.23457378149032593, "compression_ratio": 1.608, "no_speech_prob": 8.08004624559544e-05}, {"id": 1527, "seek": 619520, "start": 6199.48, "end": 6207.12, "text": " Okay, do you think that Perl paper works with the batch norm layers because it uses a memory", "tokens": [50364, 550, 3097, 613, 411, 588, 2452, 9590, 307, 5101, 588, 1152, 4033, 13, 50578, 50578, 1033, 11, 360, 291, 519, 300, 3026, 75, 3035, 1985, 365, 264, 15245, 2026, 7914, 570, 309, 4960, 257, 4675, 50960, 50960, 3765, 293, 439, 264, 33358, 366, 406, 2726, 412, 264, 912, 565, 30, 51178, 51178, 13813, 286, 519, 3335, 21141, 11, 436, 4682, 2835, 406, 281, 764, 264, 15245, 2026, 4583, 420, 764, 309, 51524, 51524, 3974, 2108, 3866, 18407, 82, 13, 51634, 51634, 407, 300, 300, 286, 519, 307, 472, 2649, 337, 988, 13, 51754, 51754], "temperature": 0.0, "avg_logprob": -0.23457378149032593, "compression_ratio": 1.608, "no_speech_prob": 8.08004624559544e-05}, {"id": 1528, "seek": 619520, "start": 6207.12, "end": 6211.48, "text": " bank and all the representations are not taken at the same time?", "tokens": [50364, 550, 3097, 613, 411, 588, 2452, 9590, 307, 5101, 588, 1152, 4033, 13, 50578, 50578, 1033, 11, 360, 291, 519, 300, 3026, 75, 3035, 1985, 365, 264, 15245, 2026, 7914, 570, 309, 4960, 257, 4675, 50960, 50960, 3765, 293, 439, 264, 33358, 366, 406, 2726, 412, 264, 912, 565, 30, 51178, 51178, 13813, 286, 519, 3335, 21141, 11, 436, 4682, 2835, 406, 281, 764, 264, 15245, 2026, 4583, 420, 764, 309, 51524, 51524, 3974, 2108, 3866, 18407, 82, 13, 51634, 51634, 407, 300, 300, 286, 519, 307, 472, 2649, 337, 988, 13, 51754, 51754], "temperature": 0.0, "avg_logprob": -0.23457378149032593, "compression_ratio": 1.608, "no_speech_prob": 8.08004624559544e-05}, {"id": 1529, "seek": 619520, "start": 6211.48, "end": 6218.4, "text": " Whereas I think MoCo, they specifically mentioned not to use the batch norm layer or use it", "tokens": [50364, 550, 3097, 613, 411, 588, 2452, 9590, 307, 5101, 588, 1152, 4033, 13, 50578, 50578, 1033, 11, 360, 291, 519, 300, 3026, 75, 3035, 1985, 365, 264, 15245, 2026, 7914, 570, 309, 4960, 257, 4675, 50960, 50960, 3765, 293, 439, 264, 33358, 366, 406, 2726, 412, 264, 912, 565, 30, 51178, 51178, 13813, 286, 519, 3335, 21141, 11, 436, 4682, 2835, 406, 281, 764, 264, 15245, 2026, 4583, 420, 764, 309, 51524, 51524, 3974, 2108, 3866, 18407, 82, 13, 51634, 51634, 407, 300, 300, 286, 519, 307, 472, 2649, 337, 988, 13, 51754, 51754], "temperature": 0.0, "avg_logprob": -0.23457378149032593, "compression_ratio": 1.608, "no_speech_prob": 8.08004624559544e-05}, {"id": 1530, "seek": 619520, "start": 6218.4, "end": 6220.599999999999, "text": " spread across multiple GPUs.", "tokens": [50364, 550, 3097, 613, 411, 588, 2452, 9590, 307, 5101, 588, 1152, 4033, 13, 50578, 50578, 1033, 11, 360, 291, 519, 300, 3026, 75, 3035, 1985, 365, 264, 15245, 2026, 7914, 570, 309, 4960, 257, 4675, 50960, 50960, 3765, 293, 439, 264, 33358, 366, 406, 2726, 412, 264, 912, 565, 30, 51178, 51178, 13813, 286, 519, 3335, 21141, 11, 436, 4682, 2835, 406, 281, 764, 264, 15245, 2026, 4583, 420, 764, 309, 51524, 51524, 3974, 2108, 3866, 18407, 82, 13, 51634, 51634, 407, 300, 300, 286, 519, 307, 472, 2649, 337, 988, 13, 51754, 51754], "temperature": 0.0, "avg_logprob": -0.23457378149032593, "compression_ratio": 1.608, "no_speech_prob": 8.08004624559544e-05}, {"id": 1531, "seek": 619520, "start": 6220.599999999999, "end": 6223.0, "text": " So that that I think is one difference for sure.", "tokens": [50364, 550, 3097, 613, 411, 588, 2452, 9590, 307, 5101, 588, 1152, 4033, 13, 50578, 50578, 1033, 11, 360, 291, 519, 300, 3026, 75, 3035, 1985, 365, 264, 15245, 2026, 7914, 570, 309, 4960, 257, 4675, 50960, 50960, 3765, 293, 439, 264, 33358, 366, 406, 2726, 412, 264, 912, 565, 30, 51178, 51178, 13813, 286, 519, 3335, 21141, 11, 436, 4682, 2835, 406, 281, 764, 264, 15245, 2026, 4583, 420, 764, 309, 51524, 51524, 3974, 2108, 3866, 18407, 82, 13, 51634, 51634, 407, 300, 300, 286, 519, 307, 472, 2649, 337, 988, 13, 51754, 51754], "temperature": 0.0, "avg_logprob": -0.23457378149032593, "compression_ratio": 1.608, "no_speech_prob": 8.08004624559544e-05}, {"id": 1532, "seek": 622300, "start": 6223.0, "end": 6227.04, "text": " Because basically the negatives that you're contrasting against and the positive word", "tokens": [50364, 1436, 1936, 264, 40019, 300, 291, 434, 8712, 278, 1970, 293, 264, 3353, 1349, 50566, 50566, 366, 490, 819, 565, 4439, 11, 597, 1669, 309, 6081, 337, 15245, 2026, 281, 1333, 295, 17470, 13, 50796, 50796, 13813, 337, 264, 661, 7150, 11, 411, 3335, 21141, 293, 318, 12224, 11, 436, 434, 588, 38574, 281, 264, 1729, 51096, 51096, 15245, 300, 291, 434, 27479, 558, 586, 13, 51206, 51206, 1033, 11, 370, 307, 456, 604, 16541, 498, 321, 366, 1228, 257, 426, 6119, 4470, 2831, 813, 257, 4675, 3765, 30, 51502, 51502, 1119, 456, 604, 16541, 577, 281, 352, 466, 341, 30, 51624, 51624], "temperature": 0.0, "avg_logprob": -0.24850420270647322, "compression_ratio": 1.6080586080586081, "no_speech_prob": 1.4280486539064441e-05}, {"id": 1533, "seek": 622300, "start": 6227.04, "end": 6231.64, "text": " are from different time steps, which makes it harder for batch norm to sort of cheat.", "tokens": [50364, 1436, 1936, 264, 40019, 300, 291, 434, 8712, 278, 1970, 293, 264, 3353, 1349, 50566, 50566, 366, 490, 819, 565, 4439, 11, 597, 1669, 309, 6081, 337, 15245, 2026, 281, 1333, 295, 17470, 13, 50796, 50796, 13813, 337, 264, 661, 7150, 11, 411, 3335, 21141, 293, 318, 12224, 11, 436, 434, 588, 38574, 281, 264, 1729, 51096, 51096, 15245, 300, 291, 434, 27479, 558, 586, 13, 51206, 51206, 1033, 11, 370, 307, 456, 604, 16541, 498, 321, 366, 1228, 257, 426, 6119, 4470, 2831, 813, 257, 4675, 3765, 30, 51502, 51502, 1119, 456, 604, 16541, 577, 281, 352, 466, 341, 30, 51624, 51624], "temperature": 0.0, "avg_logprob": -0.24850420270647322, "compression_ratio": 1.6080586080586081, "no_speech_prob": 1.4280486539064441e-05}, {"id": 1534, "seek": 622300, "start": 6231.64, "end": 6237.64, "text": " Whereas for the other methods, like MoCo and SMP, they're very correlated to the particular", "tokens": [50364, 1436, 1936, 264, 40019, 300, 291, 434, 8712, 278, 1970, 293, 264, 3353, 1349, 50566, 50566, 366, 490, 819, 565, 4439, 11, 597, 1669, 309, 6081, 337, 15245, 2026, 281, 1333, 295, 17470, 13, 50796, 50796, 13813, 337, 264, 661, 7150, 11, 411, 3335, 21141, 293, 318, 12224, 11, 436, 434, 588, 38574, 281, 264, 1729, 51096, 51096, 15245, 300, 291, 434, 27479, 558, 586, 13, 51206, 51206, 1033, 11, 370, 307, 456, 604, 16541, 498, 321, 366, 1228, 257, 426, 6119, 4470, 2831, 813, 257, 4675, 3765, 30, 51502, 51502, 1119, 456, 604, 16541, 577, 281, 352, 466, 341, 30, 51624, 51624], "temperature": 0.0, "avg_logprob": -0.24850420270647322, "compression_ratio": 1.6080586080586081, "no_speech_prob": 1.4280486539064441e-05}, {"id": 1535, "seek": 622300, "start": 6237.64, "end": 6239.84, "text": " batch that you're evaluating right now.", "tokens": [50364, 1436, 1936, 264, 40019, 300, 291, 434, 8712, 278, 1970, 293, 264, 3353, 1349, 50566, 50566, 366, 490, 819, 565, 4439, 11, 597, 1669, 309, 6081, 337, 15245, 2026, 281, 1333, 295, 17470, 13, 50796, 50796, 13813, 337, 264, 661, 7150, 11, 411, 3335, 21141, 293, 318, 12224, 11, 436, 434, 588, 38574, 281, 264, 1729, 51096, 51096, 15245, 300, 291, 434, 27479, 558, 586, 13, 51206, 51206, 1033, 11, 370, 307, 456, 604, 16541, 498, 321, 366, 1228, 257, 426, 6119, 4470, 2831, 813, 257, 4675, 3765, 30, 51502, 51502, 1119, 456, 604, 16541, 577, 281, 352, 466, 341, 30, 51624, 51624], "temperature": 0.0, "avg_logprob": -0.24850420270647322, "compression_ratio": 1.6080586080586081, "no_speech_prob": 1.4280486539064441e-05}, {"id": 1536, "seek": 622300, "start": 6239.84, "end": 6245.76, "text": " Okay, so is there any suggestion if we are using a N pair loss rather than a memory bank?", "tokens": [50364, 1436, 1936, 264, 40019, 300, 291, 434, 8712, 278, 1970, 293, 264, 3353, 1349, 50566, 50566, 366, 490, 819, 565, 4439, 11, 597, 1669, 309, 6081, 337, 15245, 2026, 281, 1333, 295, 17470, 13, 50796, 50796, 13813, 337, 264, 661, 7150, 11, 411, 3335, 21141, 293, 318, 12224, 11, 436, 434, 588, 38574, 281, 264, 1729, 51096, 51096, 15245, 300, 291, 434, 27479, 558, 586, 13, 51206, 51206, 1033, 11, 370, 307, 456, 604, 16541, 498, 321, 366, 1228, 257, 426, 6119, 4470, 2831, 813, 257, 4675, 3765, 30, 51502, 51502, 1119, 456, 604, 16541, 577, 281, 352, 466, 341, 30, 51624, 51624], "temperature": 0.0, "avg_logprob": -0.24850420270647322, "compression_ratio": 1.6080586080586081, "no_speech_prob": 1.4280486539064441e-05}, {"id": 1537, "seek": 622300, "start": 6245.76, "end": 6248.2, "text": " Is there any suggestion how to go about this?", "tokens": [50364, 1436, 1936, 264, 40019, 300, 291, 434, 8712, 278, 1970, 293, 264, 3353, 1349, 50566, 50566, 366, 490, 819, 565, 4439, 11, 597, 1669, 309, 6081, 337, 15245, 2026, 281, 1333, 295, 17470, 13, 50796, 50796, 13813, 337, 264, 661, 7150, 11, 411, 3335, 21141, 293, 318, 12224, 11, 436, 434, 588, 38574, 281, 264, 1729, 51096, 51096, 15245, 300, 291, 434, 27479, 558, 586, 13, 51206, 51206, 1033, 11, 370, 307, 456, 604, 16541, 498, 321, 366, 1228, 257, 426, 6119, 4470, 2831, 813, 257, 4675, 3765, 30, 51502, 51502, 1119, 456, 604, 16541, 577, 281, 352, 466, 341, 30, 51624, 51624], "temperature": 0.0, "avg_logprob": -0.24850420270647322, "compression_ratio": 1.6080586080586081, "no_speech_prob": 1.4280486539064441e-05}, {"id": 1538, "seek": 624820, "start": 6248.2, "end": 6254.44, "text": " Whether we should just stick to Alex net and VGG, which don't use a batch norm layer or", "tokens": [50364, 8503, 321, 820, 445, 2897, 281, 5202, 2533, 293, 691, 27561, 11, 597, 500, 380, 764, 257, 15245, 2026, 4583, 420, 50676, 50676, 307, 456, 604, 636, 281, 1261, 309, 766, 30, 50969, 50969, 407, 437, 311, 257, 393, 291, 6786, 264, 3287, 257, 707, 857, 544, 30, 51186, 51186, 407, 1936, 11, 437, 286, 478, 1382, 281, 360, 307, 3847, 322, 257, 12083, 295, 2145, 13, 51486, 51486, 400, 286, 478, 1228, 257, 426, 6119, 3287, 11, 689, 286, 478, 1382, 281, 8712, 1296, 426, 10938, 2831, 51756, 51756], "temperature": 0.0, "avg_logprob": -0.17483885391898776, "compression_ratio": 1.5251141552511416, "no_speech_prob": 9.42916376516223e-05}, {"id": 1539, "seek": 624820, "start": 6254.44, "end": 6260.3, "text": " is there any way to turn it off?", "tokens": [50364, 8503, 321, 820, 445, 2897, 281, 5202, 2533, 293, 691, 27561, 11, 597, 500, 380, 764, 257, 15245, 2026, 4583, 420, 50676, 50676, 307, 456, 604, 636, 281, 1261, 309, 766, 30, 50969, 50969, 407, 437, 311, 257, 393, 291, 6786, 264, 3287, 257, 707, 857, 544, 30, 51186, 51186, 407, 1936, 11, 437, 286, 478, 1382, 281, 360, 307, 3847, 322, 257, 12083, 295, 2145, 13, 51486, 51486, 400, 286, 478, 1228, 257, 426, 6119, 3287, 11, 689, 286, 478, 1382, 281, 8712, 1296, 426, 10938, 2831, 51756, 51756], "temperature": 0.0, "avg_logprob": -0.17483885391898776, "compression_ratio": 1.5251141552511416, "no_speech_prob": 9.42916376516223e-05}, {"id": 1540, "seek": 624820, "start": 6260.3, "end": 6264.639999999999, "text": " So what's a can you describe the setting a little bit more?", "tokens": [50364, 8503, 321, 820, 445, 2897, 281, 5202, 2533, 293, 691, 27561, 11, 597, 500, 380, 764, 257, 15245, 2026, 4583, 420, 50676, 50676, 307, 456, 604, 636, 281, 1261, 309, 766, 30, 50969, 50969, 407, 437, 311, 257, 393, 291, 6786, 264, 3287, 257, 707, 857, 544, 30, 51186, 51186, 407, 1936, 11, 437, 286, 478, 1382, 281, 360, 307, 3847, 322, 257, 12083, 295, 2145, 13, 51486, 51486, 400, 286, 478, 1228, 257, 426, 6119, 3287, 11, 689, 286, 478, 1382, 281, 8712, 1296, 426, 10938, 2831, 51756, 51756], "temperature": 0.0, "avg_logprob": -0.17483885391898776, "compression_ratio": 1.5251141552511416, "no_speech_prob": 9.42916376516223e-05}, {"id": 1541, "seek": 624820, "start": 6264.639999999999, "end": 6270.639999999999, "text": " So basically, what I'm trying to do is train on a frames of videos.", "tokens": [50364, 8503, 321, 820, 445, 2897, 281, 5202, 2533, 293, 691, 27561, 11, 597, 500, 380, 764, 257, 15245, 2026, 4583, 420, 50676, 50676, 307, 456, 604, 636, 281, 1261, 309, 766, 30, 50969, 50969, 407, 437, 311, 257, 393, 291, 6786, 264, 3287, 257, 707, 857, 544, 30, 51186, 51186, 407, 1936, 11, 437, 286, 478, 1382, 281, 360, 307, 3847, 322, 257, 12083, 295, 2145, 13, 51486, 51486, 400, 286, 478, 1228, 257, 426, 6119, 3287, 11, 689, 286, 478, 1382, 281, 8712, 1296, 426, 10938, 2831, 51756, 51756], "temperature": 0.0, "avg_logprob": -0.17483885391898776, "compression_ratio": 1.5251141552511416, "no_speech_prob": 9.42916376516223e-05}, {"id": 1542, "seek": 624820, "start": 6270.639999999999, "end": 6276.04, "text": " And I'm using a N pair setting, where I'm trying to contrast between N samples rather", "tokens": [50364, 8503, 321, 820, 445, 2897, 281, 5202, 2533, 293, 691, 27561, 11, 597, 500, 380, 764, 257, 15245, 2026, 4583, 420, 50676, 50676, 307, 456, 604, 636, 281, 1261, 309, 766, 30, 50969, 50969, 407, 437, 311, 257, 393, 291, 6786, 264, 3287, 257, 707, 857, 544, 30, 51186, 51186, 407, 1936, 11, 437, 286, 478, 1382, 281, 360, 307, 3847, 322, 257, 12083, 295, 2145, 13, 51486, 51486, 400, 286, 478, 1228, 257, 426, 6119, 3287, 11, 689, 286, 478, 1382, 281, 8712, 1296, 426, 10938, 2831, 51756, 51756], "temperature": 0.0, "avg_logprob": -0.17483885391898776, "compression_ratio": 1.5251141552511416, "no_speech_prob": 9.42916376516223e-05}, {"id": 1543, "seek": 627604, "start": 6276.04, "end": 6278.56, "text": " than two or three samples.", "tokens": [50364, 813, 732, 420, 1045, 10938, 13, 50490, 50490, 400, 437, 286, 478, 5804, 466, 307, 1968, 286, 820, 312, 1228, 15245, 2026, 420, 406, 13, 50676, 50676, 400, 498, 286, 478, 406, 1228, 15245, 2026, 412, 439, 11, 550, 597, 659, 8895, 2597, 11, 659, 9482, 50918, 50918, 5245, 393, 286, 764, 30, 51178, 51178, 663, 311, 12414, 13, 51228, 51228, 407, 264, 472, 1154, 365, 960, 12083, 307, 1936, 300, 6457, 38574, 13, 51438, 51438, 407, 294, 2674, 15245, 2026, 11, 1936, 11, 264, 3389, 295, 15245, 2026, 368, 22626, 562, 291, 362, 6457, 51670, 51670, 38574, 10938, 13, 51766, 51766], "temperature": 0.0, "avg_logprob": -0.18114763039809006, "compression_ratio": 1.7095435684647302, "no_speech_prob": 5.56084378331434e-05}, {"id": 1544, "seek": 627604, "start": 6278.56, "end": 6282.28, "text": " And what I'm worried about is whether I should be using batch norm or not.", "tokens": [50364, 813, 732, 420, 1045, 10938, 13, 50490, 50490, 400, 437, 286, 478, 5804, 466, 307, 1968, 286, 820, 312, 1228, 15245, 2026, 420, 406, 13, 50676, 50676, 400, 498, 286, 478, 406, 1228, 15245, 2026, 412, 439, 11, 550, 597, 659, 8895, 2597, 11, 659, 9482, 50918, 50918, 5245, 393, 286, 764, 30, 51178, 51178, 663, 311, 12414, 13, 51228, 51228, 407, 264, 472, 1154, 365, 960, 12083, 307, 1936, 300, 6457, 38574, 13, 51438, 51438, 407, 294, 2674, 15245, 2026, 11, 1936, 11, 264, 3389, 295, 15245, 2026, 368, 22626, 562, 291, 362, 6457, 51670, 51670, 38574, 10938, 13, 51766, 51766], "temperature": 0.0, "avg_logprob": -0.18114763039809006, "compression_ratio": 1.7095435684647302, "no_speech_prob": 5.56084378331434e-05}, {"id": 1545, "seek": 627604, "start": 6282.28, "end": 6287.12, "text": " And if I'm not using batch norm at all, then which pre trained sorry, pre architecture", "tokens": [50364, 813, 732, 420, 1045, 10938, 13, 50490, 50490, 400, 437, 286, 478, 5804, 466, 307, 1968, 286, 820, 312, 1228, 15245, 2026, 420, 406, 13, 50676, 50676, 400, 498, 286, 478, 406, 1228, 15245, 2026, 412, 439, 11, 550, 597, 659, 8895, 2597, 11, 659, 9482, 50918, 50918, 5245, 393, 286, 764, 30, 51178, 51178, 663, 311, 12414, 13, 51228, 51228, 407, 264, 472, 1154, 365, 960, 12083, 307, 1936, 300, 6457, 38574, 13, 51438, 51438, 407, 294, 2674, 15245, 2026, 11, 1936, 11, 264, 3389, 295, 15245, 2026, 368, 22626, 562, 291, 362, 6457, 51670, 51670, 38574, 10938, 13, 51766, 51766], "temperature": 0.0, "avg_logprob": -0.18114763039809006, "compression_ratio": 1.7095435684647302, "no_speech_prob": 5.56084378331434e-05}, {"id": 1546, "seek": 627604, "start": 6287.12, "end": 6292.32, "text": " models can I use?", "tokens": [50364, 813, 732, 420, 1045, 10938, 13, 50490, 50490, 400, 437, 286, 478, 5804, 466, 307, 1968, 286, 820, 312, 1228, 15245, 2026, 420, 406, 13, 50676, 50676, 400, 498, 286, 478, 406, 1228, 15245, 2026, 412, 439, 11, 550, 597, 659, 8895, 2597, 11, 659, 9482, 50918, 50918, 5245, 393, 286, 764, 30, 51178, 51178, 663, 311, 12414, 13, 51228, 51228, 407, 264, 472, 1154, 365, 960, 12083, 307, 1936, 300, 6457, 38574, 13, 51438, 51438, 407, 294, 2674, 15245, 2026, 11, 1936, 11, 264, 3389, 295, 15245, 2026, 368, 22626, 562, 291, 362, 6457, 51670, 51670, 38574, 10938, 13, 51766, 51766], "temperature": 0.0, "avg_logprob": -0.18114763039809006, "compression_ratio": 1.7095435684647302, "no_speech_prob": 5.56084378331434e-05}, {"id": 1547, "seek": 627604, "start": 6292.32, "end": 6293.32, "text": " That's tricky.", "tokens": [50364, 813, 732, 420, 1045, 10938, 13, 50490, 50490, 400, 437, 286, 478, 5804, 466, 307, 1968, 286, 820, 312, 1228, 15245, 2026, 420, 406, 13, 50676, 50676, 400, 498, 286, 478, 406, 1228, 15245, 2026, 412, 439, 11, 550, 597, 659, 8895, 2597, 11, 659, 9482, 50918, 50918, 5245, 393, 286, 764, 30, 51178, 51178, 663, 311, 12414, 13, 51228, 51228, 407, 264, 472, 1154, 365, 960, 12083, 307, 1936, 300, 6457, 38574, 13, 51438, 51438, 407, 294, 2674, 15245, 2026, 11, 1936, 11, 264, 3389, 295, 15245, 2026, 368, 22626, 562, 291, 362, 6457, 51670, 51670, 38574, 10938, 13, 51766, 51766], "temperature": 0.0, "avg_logprob": -0.18114763039809006, "compression_ratio": 1.7095435684647302, "no_speech_prob": 5.56084378331434e-05}, {"id": 1548, "seek": 627604, "start": 6293.32, "end": 6297.5199999999995, "text": " So the one problem with video frames is basically that fairly correlated.", "tokens": [50364, 813, 732, 420, 1045, 10938, 13, 50490, 50490, 400, 437, 286, 478, 5804, 466, 307, 1968, 286, 820, 312, 1228, 15245, 2026, 420, 406, 13, 50676, 50676, 400, 498, 286, 478, 406, 1228, 15245, 2026, 412, 439, 11, 550, 597, 659, 8895, 2597, 11, 659, 9482, 50918, 50918, 5245, 393, 286, 764, 30, 51178, 51178, 663, 311, 12414, 13, 51228, 51228, 407, 264, 472, 1154, 365, 960, 12083, 307, 1936, 300, 6457, 38574, 13, 51438, 51438, 407, 294, 2674, 15245, 2026, 11, 1936, 11, 264, 3389, 295, 15245, 2026, 368, 22626, 562, 291, 362, 6457, 51670, 51670, 38574, 10938, 13, 51766, 51766], "temperature": 0.0, "avg_logprob": -0.18114763039809006, "compression_ratio": 1.7095435684647302, "no_speech_prob": 5.56084378331434e-05}, {"id": 1549, "seek": 627604, "start": 6297.5199999999995, "end": 6302.16, "text": " So in general batch norm, basically, the performance of batch norm degrades when you have fairly", "tokens": [50364, 813, 732, 420, 1045, 10938, 13, 50490, 50490, 400, 437, 286, 478, 5804, 466, 307, 1968, 286, 820, 312, 1228, 15245, 2026, 420, 406, 13, 50676, 50676, 400, 498, 286, 478, 406, 1228, 15245, 2026, 412, 439, 11, 550, 597, 659, 8895, 2597, 11, 659, 9482, 50918, 50918, 5245, 393, 286, 764, 30, 51178, 51178, 663, 311, 12414, 13, 51228, 51228, 407, 264, 472, 1154, 365, 960, 12083, 307, 1936, 300, 6457, 38574, 13, 51438, 51438, 407, 294, 2674, 15245, 2026, 11, 1936, 11, 264, 3389, 295, 15245, 2026, 368, 22626, 562, 291, 362, 6457, 51670, 51670, 38574, 10938, 13, 51766, 51766], "temperature": 0.0, "avg_logprob": -0.18114763039809006, "compression_ratio": 1.7095435684647302, "no_speech_prob": 5.56084378331434e-05}, {"id": 1550, "seek": 627604, "start": 6302.16, "end": 6304.08, "text": " correlated samples.", "tokens": [50364, 813, 732, 420, 1045, 10938, 13, 50490, 50490, 400, 437, 286, 478, 5804, 466, 307, 1968, 286, 820, 312, 1228, 15245, 2026, 420, 406, 13, 50676, 50676, 400, 498, 286, 478, 406, 1228, 15245, 2026, 412, 439, 11, 550, 597, 659, 8895, 2597, 11, 659, 9482, 50918, 50918, 5245, 393, 286, 764, 30, 51178, 51178, 663, 311, 12414, 13, 51228, 51228, 407, 264, 472, 1154, 365, 960, 12083, 307, 1936, 300, 6457, 38574, 13, 51438, 51438, 407, 294, 2674, 15245, 2026, 11, 1936, 11, 264, 3389, 295, 15245, 2026, 368, 22626, 562, 291, 362, 6457, 51670, 51670, 38574, 10938, 13, 51766, 51766], "temperature": 0.0, "avg_logprob": -0.18114763039809006, "compression_ratio": 1.7095435684647302, "no_speech_prob": 5.56084378331434e-05}, {"id": 1551, "seek": 630408, "start": 6304.08, "end": 6307.6, "text": " So video that becomes more and more a problem.", "tokens": [50364, 407, 960, 300, 3643, 544, 293, 544, 257, 1154, 13, 50540, 50540, 440, 17843, 1333, 295, 411, 264, 4227, 2583, 307, 1936, 300, 754, 411, 498, 291, 574, 412, 50860, 50860, 257, 7476, 11420, 295, 5202, 2533, 613, 1708, 11, 309, 486, 4090, 15245, 2026, 13, 51084, 51084, 467, 311, 445, 570, 309, 311, 709, 544, 8351, 281, 3847, 365, 300, 291, 393, 3847, 365, 257, 2946, 51244, 51244, 2539, 3314, 293, 257, 688, 291, 393, 1936, 764, 309, 337, 257, 3840, 295, 819, 30621, 51422, 51422, 9608, 13, 51490, 51490, 407, 286, 519, 291, 815, 920, 362, 281, 764, 15245, 2026, 13, 51670, 51670], "temperature": 0.0, "avg_logprob": -0.17352163011782637, "compression_ratio": 1.689922480620155, "no_speech_prob": 4.029208866995759e-06}, {"id": 1552, "seek": 630408, "start": 6307.6, "end": 6314.0, "text": " The unfortunate sort of like the sad news is basically that even like if you look at", "tokens": [50364, 407, 960, 300, 3643, 544, 293, 544, 257, 1154, 13, 50540, 50540, 440, 17843, 1333, 295, 411, 264, 4227, 2583, 307, 1936, 300, 754, 411, 498, 291, 574, 412, 50860, 50860, 257, 7476, 11420, 295, 5202, 2533, 613, 1708, 11, 309, 486, 4090, 15245, 2026, 13, 51084, 51084, 467, 311, 445, 570, 309, 311, 709, 544, 8351, 281, 3847, 365, 300, 291, 393, 3847, 365, 257, 2946, 51244, 51244, 2539, 3314, 293, 257, 688, 291, 393, 1936, 764, 309, 337, 257, 3840, 295, 819, 30621, 51422, 51422, 9608, 13, 51490, 51490, 407, 286, 519, 291, 815, 920, 362, 281, 764, 15245, 2026, 13, 51670, 51670], "temperature": 0.0, "avg_logprob": -0.17352163011782637, "compression_ratio": 1.689922480620155, "no_speech_prob": 4.029208866995759e-06}, {"id": 1553, "seek": 630408, "start": 6314.0, "end": 6318.48, "text": " a typical implementation of Alex net these days, it will include batch norm.", "tokens": [50364, 407, 960, 300, 3643, 544, 293, 544, 257, 1154, 13, 50540, 50540, 440, 17843, 1333, 295, 411, 264, 4227, 2583, 307, 1936, 300, 754, 411, 498, 291, 574, 412, 50860, 50860, 257, 7476, 11420, 295, 5202, 2533, 613, 1708, 11, 309, 486, 4090, 15245, 2026, 13, 51084, 51084, 467, 311, 445, 570, 309, 311, 709, 544, 8351, 281, 3847, 365, 300, 291, 393, 3847, 365, 257, 2946, 51244, 51244, 2539, 3314, 293, 257, 688, 291, 393, 1936, 764, 309, 337, 257, 3840, 295, 819, 30621, 51422, 51422, 9608, 13, 51490, 51490, 407, 286, 519, 291, 815, 920, 362, 281, 764, 15245, 2026, 13, 51670, 51670], "temperature": 0.0, "avg_logprob": -0.17352163011782637, "compression_ratio": 1.689922480620155, "no_speech_prob": 4.029208866995759e-06}, {"id": 1554, "seek": 630408, "start": 6318.48, "end": 6321.68, "text": " It's just because it's much more stable to train with that you can train with a higher", "tokens": [50364, 407, 960, 300, 3643, 544, 293, 544, 257, 1154, 13, 50540, 50540, 440, 17843, 1333, 295, 411, 264, 4227, 2583, 307, 1936, 300, 754, 411, 498, 291, 574, 412, 50860, 50860, 257, 7476, 11420, 295, 5202, 2533, 613, 1708, 11, 309, 486, 4090, 15245, 2026, 13, 51084, 51084, 467, 311, 445, 570, 309, 311, 709, 544, 8351, 281, 3847, 365, 300, 291, 393, 3847, 365, 257, 2946, 51244, 51244, 2539, 3314, 293, 257, 688, 291, 393, 1936, 764, 309, 337, 257, 3840, 295, 819, 30621, 51422, 51422, 9608, 13, 51490, 51490, 407, 286, 519, 291, 815, 920, 362, 281, 764, 15245, 2026, 13, 51670, 51670], "temperature": 0.0, "avg_logprob": -0.17352163011782637, "compression_ratio": 1.689922480620155, "no_speech_prob": 4.029208866995759e-06}, {"id": 1555, "seek": 630408, "start": 6321.68, "end": 6325.24, "text": " learning rate and a lot you can basically use it for a bunch of different downstream", "tokens": [50364, 407, 960, 300, 3643, 544, 293, 544, 257, 1154, 13, 50540, 50540, 440, 17843, 1333, 295, 411, 264, 4227, 2583, 307, 1936, 300, 754, 411, 498, 291, 574, 412, 50860, 50860, 257, 7476, 11420, 295, 5202, 2533, 613, 1708, 11, 309, 486, 4090, 15245, 2026, 13, 51084, 51084, 467, 311, 445, 570, 309, 311, 709, 544, 8351, 281, 3847, 365, 300, 291, 393, 3847, 365, 257, 2946, 51244, 51244, 2539, 3314, 293, 257, 688, 291, 393, 1936, 764, 309, 337, 257, 3840, 295, 819, 30621, 51422, 51422, 9608, 13, 51490, 51490, 407, 286, 519, 291, 815, 920, 362, 281, 764, 15245, 2026, 13, 51670, 51670], "temperature": 0.0, "avg_logprob": -0.17352163011782637, "compression_ratio": 1.689922480620155, "no_speech_prob": 4.029208866995759e-06}, {"id": 1556, "seek": 630408, "start": 6325.24, "end": 6326.6, "text": " tasks.", "tokens": [50364, 407, 960, 300, 3643, 544, 293, 544, 257, 1154, 13, 50540, 50540, 440, 17843, 1333, 295, 411, 264, 4227, 2583, 307, 1936, 300, 754, 411, 498, 291, 574, 412, 50860, 50860, 257, 7476, 11420, 295, 5202, 2533, 613, 1708, 11, 309, 486, 4090, 15245, 2026, 13, 51084, 51084, 467, 311, 445, 570, 309, 311, 709, 544, 8351, 281, 3847, 365, 300, 291, 393, 3847, 365, 257, 2946, 51244, 51244, 2539, 3314, 293, 257, 688, 291, 393, 1936, 764, 309, 337, 257, 3840, 295, 819, 30621, 51422, 51422, 9608, 13, 51490, 51490, 407, 286, 519, 291, 815, 920, 362, 281, 764, 15245, 2026, 13, 51670, 51670], "temperature": 0.0, "avg_logprob": -0.17352163011782637, "compression_ratio": 1.689922480620155, "no_speech_prob": 4.029208866995759e-06}, {"id": 1557, "seek": 630408, "start": 6326.6, "end": 6330.2, "text": " So I think you may still have to use batch norm.", "tokens": [50364, 407, 960, 300, 3643, 544, 293, 544, 257, 1154, 13, 50540, 50540, 440, 17843, 1333, 295, 411, 264, 4227, 2583, 307, 1936, 300, 754, 411, 498, 291, 574, 412, 50860, 50860, 257, 7476, 11420, 295, 5202, 2533, 613, 1708, 11, 309, 486, 4090, 15245, 2026, 13, 51084, 51084, 467, 311, 445, 570, 309, 311, 709, 544, 8351, 281, 3847, 365, 300, 291, 393, 3847, 365, 257, 2946, 51244, 51244, 2539, 3314, 293, 257, 688, 291, 393, 1936, 764, 309, 337, 257, 3840, 295, 819, 30621, 51422, 51422, 9608, 13, 51490, 51490, 407, 286, 519, 291, 815, 920, 362, 281, 764, 15245, 2026, 13, 51670, 51670], "temperature": 0.0, "avg_logprob": -0.17352163011782637, "compression_ratio": 1.689922480620155, "no_speech_prob": 4.029208866995759e-06}, {"id": 1558, "seek": 633020, "start": 6330.2, "end": 6335.16, "text": " If not, you can give other variants like group norm, which basically do not really depend", "tokens": [50364, 759, 406, 11, 291, 393, 976, 661, 21669, 411, 1594, 2026, 11, 597, 1936, 360, 406, 534, 5672, 50612, 50612, 322, 264, 15245, 2744, 13, 50762, 50762, 1033, 11, 1669, 2020, 13, 50812, 50812, 1044, 291, 13, 50862, 50862, 1033, 13, 50912, 50912, 1044, 291, 370, 709, 13, 51012, 51012, 1119, 3451, 13, 51062, 51062, 821, 311, 257, 688, 295, 572, 1179, 294, 4365, 13, 51382, 51382, 286, 519, 321, 920, 362, 411, 3180, 2077, 498, 561, 366, 286, 519, 456, 366, 411, 920, 867, 51636, 51636, 1411, 294, 1508, 13, 51686, 51686, 2639, 1651, 30, 51736, 51736], "temperature": 0.0, "avg_logprob": -0.28996150970458984, "compression_ratio": 1.5566037735849056, "no_speech_prob": 2.317964390385896e-05}, {"id": 1559, "seek": 633020, "start": 6335.16, "end": 6338.16, "text": " on the batch size.", "tokens": [50364, 759, 406, 11, 291, 393, 976, 661, 21669, 411, 1594, 2026, 11, 597, 1936, 360, 406, 534, 5672, 50612, 50612, 322, 264, 15245, 2744, 13, 50762, 50762, 1033, 11, 1669, 2020, 13, 50812, 50812, 1044, 291, 13, 50862, 50862, 1033, 13, 50912, 50912, 1044, 291, 370, 709, 13, 51012, 51012, 1119, 3451, 13, 51062, 51062, 821, 311, 257, 688, 295, 572, 1179, 294, 4365, 13, 51382, 51382, 286, 519, 321, 920, 362, 411, 3180, 2077, 498, 561, 366, 286, 519, 456, 366, 411, 920, 867, 51636, 51636, 1411, 294, 1508, 13, 51686, 51686, 2639, 1651, 30, 51736, 51736], "temperature": 0.0, "avg_logprob": -0.28996150970458984, "compression_ratio": 1.5566037735849056, "no_speech_prob": 2.317964390385896e-05}, {"id": 1560, "seek": 633020, "start": 6338.16, "end": 6339.16, "text": " Okay, makes sense.", "tokens": [50364, 759, 406, 11, 291, 393, 976, 661, 21669, 411, 1594, 2026, 11, 597, 1936, 360, 406, 534, 5672, 50612, 50612, 322, 264, 15245, 2744, 13, 50762, 50762, 1033, 11, 1669, 2020, 13, 50812, 50812, 1044, 291, 13, 50862, 50862, 1033, 13, 50912, 50912, 1044, 291, 370, 709, 13, 51012, 51012, 1119, 3451, 13, 51062, 51062, 821, 311, 257, 688, 295, 572, 1179, 294, 4365, 13, 51382, 51382, 286, 519, 321, 920, 362, 411, 3180, 2077, 498, 561, 366, 286, 519, 456, 366, 411, 920, 867, 51636, 51636, 1411, 294, 1508, 13, 51686, 51686, 2639, 1651, 30, 51736, 51736], "temperature": 0.0, "avg_logprob": -0.28996150970458984, "compression_ratio": 1.5566037735849056, "no_speech_prob": 2.317964390385896e-05}, {"id": 1561, "seek": 633020, "start": 6339.16, "end": 6340.16, "text": " Thank you.", "tokens": [50364, 759, 406, 11, 291, 393, 976, 661, 21669, 411, 1594, 2026, 11, 597, 1936, 360, 406, 534, 5672, 50612, 50612, 322, 264, 15245, 2744, 13, 50762, 50762, 1033, 11, 1669, 2020, 13, 50812, 50812, 1044, 291, 13, 50862, 50862, 1033, 13, 50912, 50912, 1044, 291, 370, 709, 13, 51012, 51012, 1119, 3451, 13, 51062, 51062, 821, 311, 257, 688, 295, 572, 1179, 294, 4365, 13, 51382, 51382, 286, 519, 321, 920, 362, 411, 3180, 2077, 498, 561, 366, 286, 519, 456, 366, 411, 920, 867, 51636, 51636, 1411, 294, 1508, 13, 51686, 51686, 2639, 1651, 30, 51736, 51736], "temperature": 0.0, "avg_logprob": -0.28996150970458984, "compression_ratio": 1.5566037735849056, "no_speech_prob": 2.317964390385896e-05}, {"id": 1562, "seek": 633020, "start": 6340.16, "end": 6341.16, "text": " Okay.", "tokens": [50364, 759, 406, 11, 291, 393, 976, 661, 21669, 411, 1594, 2026, 11, 597, 1936, 360, 406, 534, 5672, 50612, 50612, 322, 264, 15245, 2744, 13, 50762, 50762, 1033, 11, 1669, 2020, 13, 50812, 50812, 1044, 291, 13, 50862, 50862, 1033, 13, 50912, 50912, 1044, 291, 370, 709, 13, 51012, 51012, 1119, 3451, 13, 51062, 51062, 821, 311, 257, 688, 295, 572, 1179, 294, 4365, 13, 51382, 51382, 286, 519, 321, 920, 362, 411, 3180, 2077, 498, 561, 366, 286, 519, 456, 366, 411, 920, 867, 51636, 51636, 1411, 294, 1508, 13, 51686, 51686, 2639, 1651, 30, 51736, 51736], "temperature": 0.0, "avg_logprob": -0.28996150970458984, "compression_ratio": 1.5566037735849056, "no_speech_prob": 2.317964390385896e-05}, {"id": 1563, "seek": 633020, "start": 6341.16, "end": 6343.16, "text": " Thank you so much.", "tokens": [50364, 759, 406, 11, 291, 393, 976, 661, 21669, 411, 1594, 2026, 11, 597, 1936, 360, 406, 534, 5672, 50612, 50612, 322, 264, 15245, 2744, 13, 50762, 50762, 1033, 11, 1669, 2020, 13, 50812, 50812, 1044, 291, 13, 50862, 50862, 1033, 13, 50912, 50912, 1044, 291, 370, 709, 13, 51012, 51012, 1119, 3451, 13, 51062, 51062, 821, 311, 257, 688, 295, 572, 1179, 294, 4365, 13, 51382, 51382, 286, 519, 321, 920, 362, 411, 3180, 2077, 498, 561, 366, 286, 519, 456, 366, 411, 920, 867, 51636, 51636, 1411, 294, 1508, 13, 51686, 51686, 2639, 1651, 30, 51736, 51736], "temperature": 0.0, "avg_logprob": -0.28996150970458984, "compression_ratio": 1.5566037735849056, "no_speech_prob": 2.317964390385896e-05}, {"id": 1564, "seek": 633020, "start": 6343.16, "end": 6344.16, "text": " Ishan.", "tokens": [50364, 759, 406, 11, 291, 393, 976, 661, 21669, 411, 1594, 2026, 11, 597, 1936, 360, 406, 534, 5672, 50612, 50612, 322, 264, 15245, 2744, 13, 50762, 50762, 1033, 11, 1669, 2020, 13, 50812, 50812, 1044, 291, 13, 50862, 50862, 1033, 13, 50912, 50912, 1044, 291, 370, 709, 13, 51012, 51012, 1119, 3451, 13, 51062, 51062, 821, 311, 257, 688, 295, 572, 1179, 294, 4365, 13, 51382, 51382, 286, 519, 321, 920, 362, 411, 3180, 2077, 498, 561, 366, 286, 519, 456, 366, 411, 920, 867, 51636, 51636, 1411, 294, 1508, 13, 51686, 51686, 2639, 1651, 30, 51736, 51736], "temperature": 0.0, "avg_logprob": -0.28996150970458984, "compression_ratio": 1.5566037735849056, "no_speech_prob": 2.317964390385896e-05}, {"id": 1565, "seek": 633020, "start": 6344.16, "end": 6350.5599999999995, "text": " There's a lot of no interest in details.", "tokens": [50364, 759, 406, 11, 291, 393, 976, 661, 21669, 411, 1594, 2026, 11, 597, 1936, 360, 406, 534, 5672, 50612, 50612, 322, 264, 15245, 2744, 13, 50762, 50762, 1033, 11, 1669, 2020, 13, 50812, 50812, 1044, 291, 13, 50862, 50862, 1033, 13, 50912, 50912, 1044, 291, 370, 709, 13, 51012, 51012, 1119, 3451, 13, 51062, 51062, 821, 311, 257, 688, 295, 572, 1179, 294, 4365, 13, 51382, 51382, 286, 519, 321, 920, 362, 411, 3180, 2077, 498, 561, 366, 286, 519, 456, 366, 411, 920, 867, 51636, 51636, 1411, 294, 1508, 13, 51686, 51686, 2639, 1651, 30, 51736, 51736], "temperature": 0.0, "avg_logprob": -0.28996150970458984, "compression_ratio": 1.5566037735849056, "no_speech_prob": 2.317964390385896e-05}, {"id": 1566, "seek": 633020, "start": 6350.5599999999995, "end": 6355.639999999999, "text": " I think we still have like eight minutes if people are I think there are like still many", "tokens": [50364, 759, 406, 11, 291, 393, 976, 661, 21669, 411, 1594, 2026, 11, 597, 1936, 360, 406, 534, 5672, 50612, 50612, 322, 264, 15245, 2744, 13, 50762, 50762, 1033, 11, 1669, 2020, 13, 50812, 50812, 1044, 291, 13, 50862, 50862, 1033, 13, 50912, 50912, 1044, 291, 370, 709, 13, 51012, 51012, 1119, 3451, 13, 51062, 51062, 821, 311, 257, 688, 295, 572, 1179, 294, 4365, 13, 51382, 51382, 286, 519, 321, 920, 362, 411, 3180, 2077, 498, 561, 366, 286, 519, 456, 366, 411, 920, 867, 51636, 51636, 1411, 294, 1508, 13, 51686, 51686, 2639, 1651, 30, 51736, 51736], "temperature": 0.0, "avg_logprob": -0.28996150970458984, "compression_ratio": 1.5566037735849056, "no_speech_prob": 2.317964390385896e-05}, {"id": 1567, "seek": 633020, "start": 6355.639999999999, "end": 6356.639999999999, "text": " left in class.", "tokens": [50364, 759, 406, 11, 291, 393, 976, 661, 21669, 411, 1594, 2026, 11, 597, 1936, 360, 406, 534, 5672, 50612, 50612, 322, 264, 15245, 2744, 13, 50762, 50762, 1033, 11, 1669, 2020, 13, 50812, 50812, 1044, 291, 13, 50862, 50862, 1033, 13, 50912, 50912, 1044, 291, 370, 709, 13, 51012, 51012, 1119, 3451, 13, 51062, 51062, 821, 311, 257, 688, 295, 572, 1179, 294, 4365, 13, 51382, 51382, 286, 519, 321, 920, 362, 411, 3180, 2077, 498, 561, 366, 286, 519, 456, 366, 411, 920, 867, 51636, 51636, 1411, 294, 1508, 13, 51686, 51686, 2639, 1651, 30, 51736, 51736], "temperature": 0.0, "avg_logprob": -0.28996150970458984, "compression_ratio": 1.5566037735849056, "no_speech_prob": 2.317964390385896e-05}, {"id": 1568, "seek": 633020, "start": 6356.639999999999, "end": 6357.639999999999, "text": " Any questions?", "tokens": [50364, 759, 406, 11, 291, 393, 976, 661, 21669, 411, 1594, 2026, 11, 597, 1936, 360, 406, 534, 5672, 50612, 50612, 322, 264, 15245, 2744, 13, 50762, 50762, 1033, 11, 1669, 2020, 13, 50812, 50812, 1044, 291, 13, 50862, 50862, 1033, 13, 50912, 50912, 1044, 291, 370, 709, 13, 51012, 51012, 1119, 3451, 13, 51062, 51062, 821, 311, 257, 688, 295, 572, 1179, 294, 4365, 13, 51382, 51382, 286, 519, 321, 920, 362, 411, 3180, 2077, 498, 561, 366, 286, 519, 456, 366, 411, 920, 867, 51636, 51636, 1411, 294, 1508, 13, 51686, 51686, 2639, 1651, 30, 51736, 51736], "temperature": 0.0, "avg_logprob": -0.28996150970458984, "compression_ratio": 1.5566037735849056, "no_speech_prob": 2.317964390385896e-05}, {"id": 1569, "seek": 635764, "start": 6357.64, "end": 6363.160000000001, "text": " Yep, I had one question which I had also put forward in a lecture when we were discussing", "tokens": [50364, 7010, 11, 286, 632, 472, 1168, 597, 286, 632, 611, 829, 2128, 294, 257, 7991, 562, 321, 645, 10850, 50640, 50640, 3026, 75, 13, 50690, 50690, 407, 341, 1168, 307, 466, 264, 4470, 2445, 13, 50908, 50908, 1664, 286, 1867, 309, 558, 586, 30, 51008, 51008, 1033, 11, 370, 562, 286, 1401, 264, 3035, 11, 370, 456, 390, 257, 8482, 1433, 300, 321, 645, 15866, 51292, 51292, 934, 15866, 264, 27619, 293, 264, 691, 3927, 10290, 337, 3256, 293, 264, 16894, 3037, 13, 51648, 51648], "temperature": 0.0, "avg_logprob": -0.24392776927728763, "compression_ratio": 1.573394495412844, "no_speech_prob": 8.32506557344459e-05}, {"id": 1570, "seek": 635764, "start": 6363.160000000001, "end": 6364.160000000001, "text": " Perl.", "tokens": [50364, 7010, 11, 286, 632, 472, 1168, 597, 286, 632, 611, 829, 2128, 294, 257, 7991, 562, 321, 645, 10850, 50640, 50640, 3026, 75, 13, 50690, 50690, 407, 341, 1168, 307, 466, 264, 4470, 2445, 13, 50908, 50908, 1664, 286, 1867, 309, 558, 586, 30, 51008, 51008, 1033, 11, 370, 562, 286, 1401, 264, 3035, 11, 370, 456, 390, 257, 8482, 1433, 300, 321, 645, 15866, 51292, 51292, 934, 15866, 264, 27619, 293, 264, 691, 3927, 10290, 337, 3256, 293, 264, 16894, 3037, 13, 51648, 51648], "temperature": 0.0, "avg_logprob": -0.24392776927728763, "compression_ratio": 1.573394495412844, "no_speech_prob": 8.32506557344459e-05}, {"id": 1571, "seek": 635764, "start": 6364.160000000001, "end": 6368.52, "text": " So this question is about the loss function.", "tokens": [50364, 7010, 11, 286, 632, 472, 1168, 597, 286, 632, 611, 829, 2128, 294, 257, 7991, 562, 321, 645, 10850, 50640, 50640, 3026, 75, 13, 50690, 50690, 407, 341, 1168, 307, 466, 264, 4470, 2445, 13, 50908, 50908, 1664, 286, 1867, 309, 558, 586, 30, 51008, 51008, 1033, 11, 370, 562, 286, 1401, 264, 3035, 11, 370, 456, 390, 257, 8482, 1433, 300, 321, 645, 15866, 51292, 51292, 934, 15866, 264, 27619, 293, 264, 691, 3927, 10290, 337, 3256, 293, 264, 16894, 3037, 13, 51648, 51648], "temperature": 0.0, "avg_logprob": -0.24392776927728763, "compression_ratio": 1.573394495412844, "no_speech_prob": 8.32506557344459e-05}, {"id": 1572, "seek": 635764, "start": 6368.52, "end": 6370.52, "text": " Can I answer it right now?", "tokens": [50364, 7010, 11, 286, 632, 472, 1168, 597, 286, 632, 611, 829, 2128, 294, 257, 7991, 562, 321, 645, 10850, 50640, 50640, 3026, 75, 13, 50690, 50690, 407, 341, 1168, 307, 466, 264, 4470, 2445, 13, 50908, 50908, 1664, 286, 1867, 309, 558, 586, 30, 51008, 51008, 1033, 11, 370, 562, 286, 1401, 264, 3035, 11, 370, 456, 390, 257, 8482, 1433, 300, 321, 645, 15866, 51292, 51292, 934, 15866, 264, 27619, 293, 264, 691, 3927, 10290, 337, 3256, 293, 264, 16894, 3037, 13, 51648, 51648], "temperature": 0.0, "avg_logprob": -0.24392776927728763, "compression_ratio": 1.573394495412844, "no_speech_prob": 8.32506557344459e-05}, {"id": 1573, "seek": 635764, "start": 6370.52, "end": 6376.200000000001, "text": " Okay, so when I read the paper, so there was a probability term that we were computing", "tokens": [50364, 7010, 11, 286, 632, 472, 1168, 597, 286, 632, 611, 829, 2128, 294, 257, 7991, 562, 321, 645, 10850, 50640, 50640, 3026, 75, 13, 50690, 50690, 407, 341, 1168, 307, 466, 264, 4470, 2445, 13, 50908, 50908, 1664, 286, 1867, 309, 558, 586, 30, 51008, 51008, 1033, 11, 370, 562, 286, 1401, 264, 3035, 11, 370, 456, 390, 257, 8482, 1433, 300, 321, 645, 15866, 51292, 51292, 934, 15866, 264, 27619, 293, 264, 691, 3927, 10290, 337, 3256, 293, 264, 16894, 3037, 13, 51648, 51648], "temperature": 0.0, "avg_logprob": -0.24392776927728763, "compression_ratio": 1.573394495412844, "no_speech_prob": 8.32506557344459e-05}, {"id": 1574, "seek": 635764, "start": 6376.200000000001, "end": 6383.320000000001, "text": " after computing the VI and the VIT representation for image and the transformed version.", "tokens": [50364, 7010, 11, 286, 632, 472, 1168, 597, 286, 632, 611, 829, 2128, 294, 257, 7991, 562, 321, 645, 10850, 50640, 50640, 3026, 75, 13, 50690, 50690, 407, 341, 1168, 307, 466, 264, 4470, 2445, 13, 50908, 50908, 1664, 286, 1867, 309, 558, 586, 30, 51008, 51008, 1033, 11, 370, 562, 286, 1401, 264, 3035, 11, 370, 456, 390, 257, 8482, 1433, 300, 321, 645, 15866, 51292, 51292, 934, 15866, 264, 27619, 293, 264, 691, 3927, 10290, 337, 3256, 293, 264, 16894, 3037, 13, 51648, 51648], "temperature": 0.0, "avg_logprob": -0.24392776927728763, "compression_ratio": 1.573394495412844, "no_speech_prob": 8.32506557344459e-05}, {"id": 1575, "seek": 638332, "start": 6383.32, "end": 6389.5599999999995, "text": " And after getting those probabilities, then we were using a noise contrastive estimation", "tokens": [50364, 400, 934, 1242, 729, 33783, 11, 550, 321, 645, 1228, 257, 5658, 8712, 488, 35701, 50676, 50676, 4470, 13, 50726, 50726, 407, 286, 390, 733, 295, 9019, 300, 1582, 380, 309, 632, 668, 1101, 498, 445, 257, 3671, 3565, 295, 300, 51006, 51006, 8482, 632, 668, 4464, 1602, 13, 51146, 51146, 407, 291, 393, 764, 1293, 534, 13, 51312, 51312, 407, 264, 1778, 281, 764, 20786, 390, 1936, 544, 281, 360, 365, 577, 264, 4675, 3765, 3035, 390, 992, 51552, 51552, 493, 13, 51616, 51616], "temperature": 0.0, "avg_logprob": -0.14068188064399806, "compression_ratio": 1.5560747663551402, "no_speech_prob": 3.590163396438584e-05}, {"id": 1576, "seek": 638332, "start": 6389.5599999999995, "end": 6390.5599999999995, "text": " loss.", "tokens": [50364, 400, 934, 1242, 729, 33783, 11, 550, 321, 645, 1228, 257, 5658, 8712, 488, 35701, 50676, 50676, 4470, 13, 50726, 50726, 407, 286, 390, 733, 295, 9019, 300, 1582, 380, 309, 632, 668, 1101, 498, 445, 257, 3671, 3565, 295, 300, 51006, 51006, 8482, 632, 668, 4464, 1602, 13, 51146, 51146, 407, 291, 393, 764, 1293, 534, 13, 51312, 51312, 407, 264, 1778, 281, 764, 20786, 390, 1936, 544, 281, 360, 365, 577, 264, 4675, 3765, 3035, 390, 992, 51552, 51552, 493, 13, 51616, 51616], "temperature": 0.0, "avg_logprob": -0.14068188064399806, "compression_ratio": 1.5560747663551402, "no_speech_prob": 3.590163396438584e-05}, {"id": 1577, "seek": 638332, "start": 6390.5599999999995, "end": 6396.16, "text": " So I was kind of confused that won't it had been better if just a negative log of that", "tokens": [50364, 400, 934, 1242, 729, 33783, 11, 550, 321, 645, 1228, 257, 5658, 8712, 488, 35701, 50676, 50676, 4470, 13, 50726, 50726, 407, 286, 390, 733, 295, 9019, 300, 1582, 380, 309, 632, 668, 1101, 498, 445, 257, 3671, 3565, 295, 300, 51006, 51006, 8482, 632, 668, 4464, 1602, 13, 51146, 51146, 407, 291, 393, 764, 1293, 534, 13, 51312, 51312, 407, 264, 1778, 281, 764, 20786, 390, 1936, 544, 281, 360, 365, 577, 264, 4675, 3765, 3035, 390, 992, 51552, 51552, 493, 13, 51616, 51616], "temperature": 0.0, "avg_logprob": -0.14068188064399806, "compression_ratio": 1.5560747663551402, "no_speech_prob": 3.590163396438584e-05}, {"id": 1578, "seek": 638332, "start": 6396.16, "end": 6398.96, "text": " probability had been minimized.", "tokens": [50364, 400, 934, 1242, 729, 33783, 11, 550, 321, 645, 1228, 257, 5658, 8712, 488, 35701, 50676, 50676, 4470, 13, 50726, 50726, 407, 286, 390, 733, 295, 9019, 300, 1582, 380, 309, 632, 668, 1101, 498, 445, 257, 3671, 3565, 295, 300, 51006, 51006, 8482, 632, 668, 4464, 1602, 13, 51146, 51146, 407, 291, 393, 764, 1293, 534, 13, 51312, 51312, 407, 264, 1778, 281, 764, 20786, 390, 1936, 544, 281, 360, 365, 577, 264, 4675, 3765, 3035, 390, 992, 51552, 51552, 493, 13, 51616, 51616], "temperature": 0.0, "avg_logprob": -0.14068188064399806, "compression_ratio": 1.5560747663551402, "no_speech_prob": 3.590163396438584e-05}, {"id": 1579, "seek": 638332, "start": 6398.96, "end": 6402.28, "text": " So you can use both really.", "tokens": [50364, 400, 934, 1242, 729, 33783, 11, 550, 321, 645, 1228, 257, 5658, 8712, 488, 35701, 50676, 50676, 4470, 13, 50726, 50726, 407, 286, 390, 733, 295, 9019, 300, 1582, 380, 309, 632, 668, 1101, 498, 445, 257, 3671, 3565, 295, 300, 51006, 51006, 8482, 632, 668, 4464, 1602, 13, 51146, 51146, 407, 291, 393, 764, 1293, 534, 13, 51312, 51312, 407, 264, 1778, 281, 764, 20786, 390, 1936, 544, 281, 360, 365, 577, 264, 4675, 3765, 3035, 390, 992, 51552, 51552, 493, 13, 51616, 51616], "temperature": 0.0, "avg_logprob": -0.14068188064399806, "compression_ratio": 1.5560747663551402, "no_speech_prob": 3.590163396438584e-05}, {"id": 1580, "seek": 638332, "start": 6402.28, "end": 6407.08, "text": " So the reason to use NC was basically more to do with how the memory bank paper was set", "tokens": [50364, 400, 934, 1242, 729, 33783, 11, 550, 321, 645, 1228, 257, 5658, 8712, 488, 35701, 50676, 50676, 4470, 13, 50726, 50726, 407, 286, 390, 733, 295, 9019, 300, 1582, 380, 309, 632, 668, 1101, 498, 445, 257, 3671, 3565, 295, 300, 51006, 51006, 8482, 632, 668, 4464, 1602, 13, 51146, 51146, 407, 291, 393, 764, 1293, 534, 13, 51312, 51312, 407, 264, 1778, 281, 764, 20786, 390, 1936, 544, 281, 360, 365, 577, 264, 4675, 3765, 3035, 390, 992, 51552, 51552, 493, 13, 51616, 51616], "temperature": 0.0, "avg_logprob": -0.14068188064399806, "compression_ratio": 1.5560747663551402, "no_speech_prob": 3.590163396438584e-05}, {"id": 1581, "seek": 638332, "start": 6407.08, "end": 6408.36, "text": " up.", "tokens": [50364, 400, 934, 1242, 729, 33783, 11, 550, 321, 645, 1228, 257, 5658, 8712, 488, 35701, 50676, 50676, 4470, 13, 50726, 50726, 407, 286, 390, 733, 295, 9019, 300, 1582, 380, 309, 632, 668, 1101, 498, 445, 257, 3671, 3565, 295, 300, 51006, 51006, 8482, 632, 668, 4464, 1602, 13, 51146, 51146, 407, 291, 393, 764, 1293, 534, 13, 51312, 51312, 407, 264, 1778, 281, 764, 20786, 390, 1936, 544, 281, 360, 365, 577, 264, 4675, 3765, 3035, 390, 992, 51552, 51552, 493, 13, 51616, 51616], "temperature": 0.0, "avg_logprob": -0.14068188064399806, "compression_ratio": 1.5560747663551402, "no_speech_prob": 3.590163396438584e-05}, {"id": 1582, "seek": 640836, "start": 6408.36, "end": 6413.4, "text": " So NC you would if you have k negatives, you are basically solving k plus one problems.", "tokens": [50364, 407, 20786, 291, 576, 498, 291, 362, 350, 40019, 11, 291, 366, 1936, 12606, 350, 1804, 472, 2740, 13, 50616, 50616, 407, 264, 472, 1154, 307, 1936, 291, 1936, 362, 350, 1804, 472, 819, 17434, 2740, 50886, 50886, 300, 291, 434, 12606, 13, 50989, 50989, 407, 300, 311, 472, 636, 295, 884, 309, 13, 51054, 51054, 440, 661, 636, 295, 884, 309, 307, 1936, 437, 307, 586, 1219, 13614, 20786, 11, 597, 307, 534, 445, 51250, 51250, 2787, 41167, 13, 51304, 51304, 407, 291, 445, 3079, 257, 2787, 41167, 293, 291, 17522, 264, 3671, 3565, 22119, 337, 300, 13, 51546, 51546], "temperature": 0.0, "avg_logprob": -0.18723597109896464, "compression_ratio": 1.85, "no_speech_prob": 1.1124575394205749e-05}, {"id": 1583, "seek": 640836, "start": 6413.4, "end": 6418.799999999999, "text": " So the one problem is basically you basically have k plus one different binary problems", "tokens": [50364, 407, 20786, 291, 576, 498, 291, 362, 350, 40019, 11, 291, 366, 1936, 12606, 350, 1804, 472, 2740, 13, 50616, 50616, 407, 264, 472, 1154, 307, 1936, 291, 1936, 362, 350, 1804, 472, 819, 17434, 2740, 50886, 50886, 300, 291, 434, 12606, 13, 50989, 50989, 407, 300, 311, 472, 636, 295, 884, 309, 13, 51054, 51054, 440, 661, 636, 295, 884, 309, 307, 1936, 437, 307, 586, 1219, 13614, 20786, 11, 597, 307, 534, 445, 51250, 51250, 2787, 41167, 13, 51304, 51304, 407, 291, 445, 3079, 257, 2787, 41167, 293, 291, 17522, 264, 3671, 3565, 22119, 337, 300, 13, 51546, 51546], "temperature": 0.0, "avg_logprob": -0.18723597109896464, "compression_ratio": 1.85, "no_speech_prob": 1.1124575394205749e-05}, {"id": 1584, "seek": 640836, "start": 6418.799999999999, "end": 6420.86, "text": " that you're solving.", "tokens": [50364, 407, 20786, 291, 576, 498, 291, 362, 350, 40019, 11, 291, 366, 1936, 12606, 350, 1804, 472, 2740, 13, 50616, 50616, 407, 264, 472, 1154, 307, 1936, 291, 1936, 362, 350, 1804, 472, 819, 17434, 2740, 50886, 50886, 300, 291, 434, 12606, 13, 50989, 50989, 407, 300, 311, 472, 636, 295, 884, 309, 13, 51054, 51054, 440, 661, 636, 295, 884, 309, 307, 1936, 437, 307, 586, 1219, 13614, 20786, 11, 597, 307, 534, 445, 51250, 51250, 2787, 41167, 13, 51304, 51304, 407, 291, 445, 3079, 257, 2787, 41167, 293, 291, 17522, 264, 3671, 3565, 22119, 337, 300, 13, 51546, 51546], "temperature": 0.0, "avg_logprob": -0.18723597109896464, "compression_ratio": 1.85, "no_speech_prob": 1.1124575394205749e-05}, {"id": 1585, "seek": 640836, "start": 6420.86, "end": 6422.16, "text": " So that's one way of doing it.", "tokens": [50364, 407, 20786, 291, 576, 498, 291, 362, 350, 40019, 11, 291, 366, 1936, 12606, 350, 1804, 472, 2740, 13, 50616, 50616, 407, 264, 472, 1154, 307, 1936, 291, 1936, 362, 350, 1804, 472, 819, 17434, 2740, 50886, 50886, 300, 291, 434, 12606, 13, 50989, 50989, 407, 300, 311, 472, 636, 295, 884, 309, 13, 51054, 51054, 440, 661, 636, 295, 884, 309, 307, 1936, 437, 307, 586, 1219, 13614, 20786, 11, 597, 307, 534, 445, 51250, 51250, 2787, 41167, 13, 51304, 51304, 407, 291, 445, 3079, 257, 2787, 41167, 293, 291, 17522, 264, 3671, 3565, 22119, 337, 300, 13, 51546, 51546], "temperature": 0.0, "avg_logprob": -0.18723597109896464, "compression_ratio": 1.85, "no_speech_prob": 1.1124575394205749e-05}, {"id": 1586, "seek": 640836, "start": 6422.16, "end": 6426.08, "text": " The other way of doing it is basically what is now called info NC, which is really just", "tokens": [50364, 407, 20786, 291, 576, 498, 291, 362, 350, 40019, 11, 291, 366, 1936, 12606, 350, 1804, 472, 2740, 13, 50616, 50616, 407, 264, 472, 1154, 307, 1936, 291, 1936, 362, 350, 1804, 472, 819, 17434, 2740, 50886, 50886, 300, 291, 434, 12606, 13, 50989, 50989, 407, 300, 311, 472, 636, 295, 884, 309, 13, 51054, 51054, 440, 661, 636, 295, 884, 309, 307, 1936, 437, 307, 586, 1219, 13614, 20786, 11, 597, 307, 534, 445, 51250, 51250, 2787, 41167, 13, 51304, 51304, 407, 291, 445, 3079, 257, 2787, 41167, 293, 291, 17522, 264, 3671, 3565, 22119, 337, 300, 13, 51546, 51546], "temperature": 0.0, "avg_logprob": -0.18723597109896464, "compression_ratio": 1.85, "no_speech_prob": 1.1124575394205749e-05}, {"id": 1587, "seek": 640836, "start": 6426.08, "end": 6427.16, "text": " softmax.", "tokens": [50364, 407, 20786, 291, 576, 498, 291, 362, 350, 40019, 11, 291, 366, 1936, 12606, 350, 1804, 472, 2740, 13, 50616, 50616, 407, 264, 472, 1154, 307, 1936, 291, 1936, 362, 350, 1804, 472, 819, 17434, 2740, 50886, 50886, 300, 291, 434, 12606, 13, 50989, 50989, 407, 300, 311, 472, 636, 295, 884, 309, 13, 51054, 51054, 440, 661, 636, 295, 884, 309, 307, 1936, 437, 307, 586, 1219, 13614, 20786, 11, 597, 307, 534, 445, 51250, 51250, 2787, 41167, 13, 51304, 51304, 407, 291, 445, 3079, 257, 2787, 41167, 293, 291, 17522, 264, 3671, 3565, 22119, 337, 300, 13, 51546, 51546], "temperature": 0.0, "avg_logprob": -0.18723597109896464, "compression_ratio": 1.85, "no_speech_prob": 1.1124575394205749e-05}, {"id": 1588, "seek": 640836, "start": 6427.16, "end": 6432.0, "text": " So you just apply a softmax and you minimize the negative log likelihood for that.", "tokens": [50364, 407, 20786, 291, 576, 498, 291, 362, 350, 40019, 11, 291, 366, 1936, 12606, 350, 1804, 472, 2740, 13, 50616, 50616, 407, 264, 472, 1154, 307, 1936, 291, 1936, 362, 350, 1804, 472, 819, 17434, 2740, 50886, 50886, 300, 291, 434, 12606, 13, 50989, 50989, 407, 300, 311, 472, 636, 295, 884, 309, 13, 51054, 51054, 440, 661, 636, 295, 884, 309, 307, 1936, 437, 307, 586, 1219, 13614, 20786, 11, 597, 307, 534, 445, 51250, 51250, 2787, 41167, 13, 51304, 51304, 407, 291, 445, 3079, 257, 2787, 41167, 293, 291, 17522, 264, 3671, 3565, 22119, 337, 300, 13, 51546, 51546], "temperature": 0.0, "avg_logprob": -0.18723597109896464, "compression_ratio": 1.85, "no_speech_prob": 1.1124575394205749e-05}, {"id": 1589, "seek": 643200, "start": 6432.0, "end": 6443.04, "text": " It's because that edge, the probability function looked like a softmax.", "tokens": [50364, 467, 311, 570, 300, 4691, 11, 264, 8482, 2445, 2956, 411, 257, 2787, 41167, 13, 50916, 50916, 407, 412, 264, 565, 562, 286, 632, 3031, 309, 484, 11, 309, 767, 2729, 385, 4748, 5324, 3542, 13, 51134, 51134, 400, 370, 300, 311, 1936, 983, 286, 1143, 20786, 13, 51246, 51246, 400, 341, 390, 445, 5883, 12050, 13, 51386, 51386, 823, 562, 286, 478, 1382, 309, 484, 11, 309, 767, 2709, 385, 2531, 3542, 13, 51511, 51511], "temperature": 0.0, "avg_logprob": -0.18378152602758163, "compression_ratio": 1.5255102040816326, "no_speech_prob": 2.2471484044217505e-05}, {"id": 1590, "seek": 643200, "start": 6443.04, "end": 6447.4, "text": " So at the time when I had tried it out, it actually gave me slightly worse results.", "tokens": [50364, 467, 311, 570, 300, 4691, 11, 264, 8482, 2445, 2956, 411, 257, 2787, 41167, 13, 50916, 50916, 407, 412, 264, 565, 562, 286, 632, 3031, 309, 484, 11, 309, 767, 2729, 385, 4748, 5324, 3542, 13, 51134, 51134, 400, 370, 300, 311, 1936, 983, 286, 1143, 20786, 13, 51246, 51246, 400, 341, 390, 445, 5883, 12050, 13, 51386, 51386, 823, 562, 286, 478, 1382, 309, 484, 11, 309, 767, 2709, 385, 2531, 3542, 13, 51511, 51511], "temperature": 0.0, "avg_logprob": -0.18378152602758163, "compression_ratio": 1.5255102040816326, "no_speech_prob": 2.2471484044217505e-05}, {"id": 1591, "seek": 643200, "start": 6447.4, "end": 6449.64, "text": " And so that's basically why I used NC.", "tokens": [50364, 467, 311, 570, 300, 4691, 11, 264, 8482, 2445, 2956, 411, 257, 2787, 41167, 13, 50916, 50916, 407, 412, 264, 565, 562, 286, 632, 3031, 309, 484, 11, 309, 767, 2729, 385, 4748, 5324, 3542, 13, 51134, 51134, 400, 370, 300, 311, 1936, 983, 286, 1143, 20786, 13, 51246, 51246, 400, 341, 390, 445, 5883, 12050, 13, 51386, 51386, 823, 562, 286, 478, 1382, 309, 484, 11, 309, 767, 2709, 385, 2531, 3542, 13, 51511, 51511], "temperature": 0.0, "avg_logprob": -0.18378152602758163, "compression_ratio": 1.5255102040816326, "no_speech_prob": 2.2471484044217505e-05}, {"id": 1592, "seek": 643200, "start": 6449.64, "end": 6452.44, "text": " And this was just initial experiments.", "tokens": [50364, 467, 311, 570, 300, 4691, 11, 264, 8482, 2445, 2956, 411, 257, 2787, 41167, 13, 50916, 50916, 407, 412, 264, 565, 562, 286, 632, 3031, 309, 484, 11, 309, 767, 2729, 385, 4748, 5324, 3542, 13, 51134, 51134, 400, 370, 300, 311, 1936, 983, 286, 1143, 20786, 13, 51246, 51246, 400, 341, 390, 445, 5883, 12050, 13, 51386, 51386, 823, 562, 286, 478, 1382, 309, 484, 11, 309, 767, 2709, 385, 2531, 3542, 13, 51511, 51511], "temperature": 0.0, "avg_logprob": -0.18378152602758163, "compression_ratio": 1.5255102040816326, "no_speech_prob": 2.2471484044217505e-05}, {"id": 1593, "seek": 643200, "start": 6452.44, "end": 6454.94, "text": " Now when I'm trying it out, it actually gives me similar results.", "tokens": [50364, 467, 311, 570, 300, 4691, 11, 264, 8482, 2445, 2956, 411, 257, 2787, 41167, 13, 50916, 50916, 407, 412, 264, 565, 562, 286, 632, 3031, 309, 484, 11, 309, 767, 2729, 385, 4748, 5324, 3542, 13, 51134, 51134, 400, 370, 300, 311, 1936, 983, 286, 1143, 20786, 13, 51246, 51246, 400, 341, 390, 445, 5883, 12050, 13, 51386, 51386, 823, 562, 286, 478, 1382, 309, 484, 11, 309, 767, 2709, 385, 2531, 3542, 13, 51511, 51511], "temperature": 0.0, "avg_logprob": -0.18378152602758163, "compression_ratio": 1.5255102040816326, "no_speech_prob": 2.2471484044217505e-05}, {"id": 1594, "seek": 645494, "start": 6454.94, "end": 6462.44, "text": " So I guess in the end it does not make that much of a difference.", "tokens": [50364, 407, 286, 2041, 294, 264, 917, 309, 775, 406, 652, 300, 709, 295, 257, 2649, 13, 50739, 50739, 639, 307, 544, 4077, 281, 264, 1164, 11, 457, 321, 434, 516, 281, 362, 257, 1716, 322, 2698, 46533, 50963, 50963, 2539, 13, 51013, 51013, 407, 286, 390, 6359, 11, 393, 291, 976, 505, 1589, 322, 577, 281, 483, 309, 11, 483, 257, 2698, 46533, 2539, 51341, 51341, 2316, 1364, 382, 294, 264, 11420, 4365, 30, 51591, 51591, 1743, 341, 575, 668, 257, 7991, 322, 264, 1090, 1496, 3487, 13, 51803, 51803], "temperature": 0.0, "avg_logprob": -0.28292013251263165, "compression_ratio": 1.5851528384279476, "no_speech_prob": 4.5386528654489666e-05}, {"id": 1595, "seek": 645494, "start": 6462.44, "end": 6466.919999999999, "text": " This is more related to the course, but we're going to have a project on self supervised", "tokens": [50364, 407, 286, 2041, 294, 264, 917, 309, 775, 406, 652, 300, 709, 295, 257, 2649, 13, 50739, 50739, 639, 307, 544, 4077, 281, 264, 1164, 11, 457, 321, 434, 516, 281, 362, 257, 1716, 322, 2698, 46533, 50963, 50963, 2539, 13, 51013, 51013, 407, 286, 390, 6359, 11, 393, 291, 976, 505, 1589, 322, 577, 281, 483, 309, 11, 483, 257, 2698, 46533, 2539, 51341, 51341, 2316, 1364, 382, 294, 264, 11420, 4365, 30, 51591, 51591, 1743, 341, 575, 668, 257, 7991, 322, 264, 1090, 1496, 3487, 13, 51803, 51803], "temperature": 0.0, "avg_logprob": -0.28292013251263165, "compression_ratio": 1.5851528384279476, "no_speech_prob": 4.5386528654489666e-05}, {"id": 1596, "seek": 645494, "start": 6466.919999999999, "end": 6467.919999999999, "text": " learning.", "tokens": [50364, 407, 286, 2041, 294, 264, 917, 309, 775, 406, 652, 300, 709, 295, 257, 2649, 13, 50739, 50739, 639, 307, 544, 4077, 281, 264, 1164, 11, 457, 321, 434, 516, 281, 362, 257, 1716, 322, 2698, 46533, 50963, 50963, 2539, 13, 51013, 51013, 407, 286, 390, 6359, 11, 393, 291, 976, 505, 1589, 322, 577, 281, 483, 309, 11, 483, 257, 2698, 46533, 2539, 51341, 51341, 2316, 1364, 382, 294, 264, 11420, 4365, 30, 51591, 51591, 1743, 341, 575, 668, 257, 7991, 322, 264, 1090, 1496, 3487, 13, 51803, 51803], "temperature": 0.0, "avg_logprob": -0.28292013251263165, "compression_ratio": 1.5851528384279476, "no_speech_prob": 4.5386528654489666e-05}, {"id": 1597, "seek": 645494, "start": 6467.919999999999, "end": 6474.48, "text": " So I was wondering, can you give us information on how to get it, get a self supervised learning", "tokens": [50364, 407, 286, 2041, 294, 264, 917, 309, 775, 406, 652, 300, 709, 295, 257, 2649, 13, 50739, 50739, 639, 307, 544, 4077, 281, 264, 1164, 11, 457, 321, 434, 516, 281, 362, 257, 1716, 322, 2698, 46533, 50963, 50963, 2539, 13, 51013, 51013, 407, 286, 390, 6359, 11, 393, 291, 976, 505, 1589, 322, 577, 281, 483, 309, 11, 483, 257, 2698, 46533, 2539, 51341, 51341, 2316, 1364, 382, 294, 264, 11420, 4365, 30, 51591, 51591, 1743, 341, 575, 668, 257, 7991, 322, 264, 1090, 1496, 3487, 13, 51803, 51803], "temperature": 0.0, "avg_logprob": -0.28292013251263165, "compression_ratio": 1.5851528384279476, "no_speech_prob": 4.5386528654489666e-05}, {"id": 1598, "seek": 645494, "start": 6474.48, "end": 6479.48, "text": " model working as in the implementation details?", "tokens": [50364, 407, 286, 2041, 294, 264, 917, 309, 775, 406, 652, 300, 709, 295, 257, 2649, 13, 50739, 50739, 639, 307, 544, 4077, 281, 264, 1164, 11, 457, 321, 434, 516, 281, 362, 257, 1716, 322, 2698, 46533, 50963, 50963, 2539, 13, 51013, 51013, 407, 286, 390, 6359, 11, 393, 291, 976, 505, 1589, 322, 577, 281, 483, 309, 11, 483, 257, 2698, 46533, 2539, 51341, 51341, 2316, 1364, 382, 294, 264, 11420, 4365, 30, 51591, 51591, 1743, 341, 575, 668, 257, 7991, 322, 264, 1090, 1496, 3487, 13, 51803, 51803], "temperature": 0.0, "avg_logprob": -0.28292013251263165, "compression_ratio": 1.5851528384279476, "no_speech_prob": 4.5386528654489666e-05}, {"id": 1599, "seek": 645494, "start": 6479.48, "end": 6483.719999999999, "text": " Like this has been a lecture on the high level ideas.", "tokens": [50364, 407, 286, 2041, 294, 264, 917, 309, 775, 406, 652, 300, 709, 295, 257, 2649, 13, 50739, 50739, 639, 307, 544, 4077, 281, 264, 1164, 11, 457, 321, 434, 516, 281, 362, 257, 1716, 322, 2698, 46533, 50963, 50963, 2539, 13, 51013, 51013, 407, 286, 390, 6359, 11, 393, 291, 976, 505, 1589, 322, 577, 281, 483, 309, 11, 483, 257, 2698, 46533, 2539, 51341, 51341, 2316, 1364, 382, 294, 264, 11420, 4365, 30, 51591, 51591, 1743, 341, 575, 668, 257, 7991, 322, 264, 1090, 1496, 3487, 13, 51803, 51803], "temperature": 0.0, "avg_logprob": -0.28292013251263165, "compression_ratio": 1.5851528384279476, "no_speech_prob": 4.5386528654489666e-05}, {"id": 1600, "seek": 648372, "start": 6483.72, "end": 6489.4800000000005, "text": " So how to get it working quickly.", "tokens": [50364, 407, 577, 281, 483, 309, 1364, 2661, 13, 50652, 50652, 407, 286, 519, 11, 286, 914, 11, 456, 366, 1629, 1508, 295, 7512, 300, 366, 516, 281, 312, 709, 3571, 50860, 50860, 281, 483, 1364, 490, 264, 483, 352, 13, 50964, 50964, 407, 337, 1365, 11, 498, 291, 645, 1237, 412, 445, 659, 25111, 9608, 11, 550, 291, 576, 1936, 574, 51210, 51210, 412, 746, 411, 12447, 570, 309, 311, 257, 588, 1858, 5633, 281, 4445, 13, 51480, 51480, 509, 534, 2644, 352, 2085, 365, 309, 13, 51570, 51570, 286, 914, 11, 456, 366, 445, 588, 1326, 721, 281, 4445, 13, 51704, 51704], "temperature": 0.0, "avg_logprob": -0.19299065726143974, "compression_ratio": 1.6945606694560669, "no_speech_prob": 1.981762397917919e-05}, {"id": 1601, "seek": 648372, "start": 6489.4800000000005, "end": 6493.64, "text": " So I think, I mean, there are certain class of techniques that are going to be much easier", "tokens": [50364, 407, 577, 281, 483, 309, 1364, 2661, 13, 50652, 50652, 407, 286, 519, 11, 286, 914, 11, 456, 366, 1629, 1508, 295, 7512, 300, 366, 516, 281, 312, 709, 3571, 50860, 50860, 281, 483, 1364, 490, 264, 483, 352, 13, 50964, 50964, 407, 337, 1365, 11, 498, 291, 645, 1237, 412, 445, 659, 25111, 9608, 11, 550, 291, 576, 1936, 574, 51210, 51210, 412, 746, 411, 12447, 570, 309, 311, 257, 588, 1858, 5633, 281, 4445, 13, 51480, 51480, 509, 534, 2644, 352, 2085, 365, 309, 13, 51570, 51570, 286, 914, 11, 456, 366, 445, 588, 1326, 721, 281, 4445, 13, 51704, 51704], "temperature": 0.0, "avg_logprob": -0.19299065726143974, "compression_ratio": 1.6945606694560669, "no_speech_prob": 1.981762397917919e-05}, {"id": 1602, "seek": 648372, "start": 6493.64, "end": 6495.72, "text": " to get working from the get go.", "tokens": [50364, 407, 577, 281, 483, 309, 1364, 2661, 13, 50652, 50652, 407, 286, 519, 11, 286, 914, 11, 456, 366, 1629, 1508, 295, 7512, 300, 366, 516, 281, 312, 709, 3571, 50860, 50860, 281, 483, 1364, 490, 264, 483, 352, 13, 50964, 50964, 407, 337, 1365, 11, 498, 291, 645, 1237, 412, 445, 659, 25111, 9608, 11, 550, 291, 576, 1936, 574, 51210, 51210, 412, 746, 411, 12447, 570, 309, 311, 257, 588, 1858, 5633, 281, 4445, 13, 51480, 51480, 509, 534, 2644, 352, 2085, 365, 309, 13, 51570, 51570, 286, 914, 11, 456, 366, 445, 588, 1326, 721, 281, 4445, 13, 51704, 51704], "temperature": 0.0, "avg_logprob": -0.19299065726143974, "compression_ratio": 1.6945606694560669, "no_speech_prob": 1.981762397917919e-05}, {"id": 1603, "seek": 648372, "start": 6495.72, "end": 6500.64, "text": " So for example, if you were looking at just pretext tasks, then you would basically look", "tokens": [50364, 407, 577, 281, 483, 309, 1364, 2661, 13, 50652, 50652, 407, 286, 519, 11, 286, 914, 11, 456, 366, 1629, 1508, 295, 7512, 300, 366, 516, 281, 312, 709, 3571, 50860, 50860, 281, 483, 1364, 490, 264, 483, 352, 13, 50964, 50964, 407, 337, 1365, 11, 498, 291, 645, 1237, 412, 445, 659, 25111, 9608, 11, 550, 291, 576, 1936, 574, 51210, 51210, 412, 746, 411, 12447, 570, 309, 311, 257, 588, 1858, 5633, 281, 4445, 13, 51480, 51480, 509, 534, 2644, 352, 2085, 365, 309, 13, 51570, 51570, 286, 914, 11, 456, 366, 445, 588, 1326, 721, 281, 4445, 13, 51704, 51704], "temperature": 0.0, "avg_logprob": -0.19299065726143974, "compression_ratio": 1.6945606694560669, "no_speech_prob": 1.981762397917919e-05}, {"id": 1604, "seek": 648372, "start": 6500.64, "end": 6506.04, "text": " at something like rotation because it's a very easy task to implement.", "tokens": [50364, 407, 577, 281, 483, 309, 1364, 2661, 13, 50652, 50652, 407, 286, 519, 11, 286, 914, 11, 456, 366, 1629, 1508, 295, 7512, 300, 366, 516, 281, 312, 709, 3571, 50860, 50860, 281, 483, 1364, 490, 264, 483, 352, 13, 50964, 50964, 407, 337, 1365, 11, 498, 291, 645, 1237, 412, 445, 659, 25111, 9608, 11, 550, 291, 576, 1936, 574, 51210, 51210, 412, 746, 411, 12447, 570, 309, 311, 257, 588, 1858, 5633, 281, 4445, 13, 51480, 51480, 509, 534, 2644, 352, 2085, 365, 309, 13, 51570, 51570, 286, 914, 11, 456, 366, 445, 588, 1326, 721, 281, 4445, 13, 51704, 51704], "temperature": 0.0, "avg_logprob": -0.19299065726143974, "compression_ratio": 1.6945606694560669, "no_speech_prob": 1.981762397917919e-05}, {"id": 1605, "seek": 648372, "start": 6506.04, "end": 6507.84, "text": " You really cannot go wrong with it.", "tokens": [50364, 407, 577, 281, 483, 309, 1364, 2661, 13, 50652, 50652, 407, 286, 519, 11, 286, 914, 11, 456, 366, 1629, 1508, 295, 7512, 300, 366, 516, 281, 312, 709, 3571, 50860, 50860, 281, 483, 1364, 490, 264, 483, 352, 13, 50964, 50964, 407, 337, 1365, 11, 498, 291, 645, 1237, 412, 445, 659, 25111, 9608, 11, 550, 291, 576, 1936, 574, 51210, 51210, 412, 746, 411, 12447, 570, 309, 311, 257, 588, 1858, 5633, 281, 4445, 13, 51480, 51480, 509, 534, 2644, 352, 2085, 365, 309, 13, 51570, 51570, 286, 914, 11, 456, 366, 445, 588, 1326, 721, 281, 4445, 13, 51704, 51704], "temperature": 0.0, "avg_logprob": -0.19299065726143974, "compression_ratio": 1.6945606694560669, "no_speech_prob": 1.981762397917919e-05}, {"id": 1606, "seek": 648372, "start": 6507.84, "end": 6510.52, "text": " I mean, there are just very few things to implement.", "tokens": [50364, 407, 577, 281, 483, 309, 1364, 2661, 13, 50652, 50652, 407, 286, 519, 11, 286, 914, 11, 456, 366, 1629, 1508, 295, 7512, 300, 366, 516, 281, 312, 709, 3571, 50860, 50860, 281, 483, 1364, 490, 264, 483, 352, 13, 50964, 50964, 407, 337, 1365, 11, 498, 291, 645, 1237, 412, 445, 659, 25111, 9608, 11, 550, 291, 576, 1936, 574, 51210, 51210, 412, 746, 411, 12447, 570, 309, 311, 257, 588, 1858, 5633, 281, 4445, 13, 51480, 51480, 509, 534, 2644, 352, 2085, 365, 309, 13, 51570, 51570, 286, 914, 11, 456, 366, 445, 588, 1326, 721, 281, 4445, 13, 51704, 51704], "temperature": 0.0, "avg_logprob": -0.19299065726143974, "compression_ratio": 1.6945606694560669, "no_speech_prob": 1.981762397917919e-05}, {"id": 1607, "seek": 651052, "start": 6510.52, "end": 6514.120000000001, "text": " So just the number of moving pieces are good indicator.", "tokens": [50364, 407, 445, 264, 1230, 295, 2684, 3755, 366, 665, 16961, 13, 50544, 50544, 440, 661, 551, 281, 1604, 307, 1936, 498, 291, 434, 1333, 295, 18114, 493, 6741, 3170, 11, 50932, 50932, 550, 456, 366, 516, 281, 312, 3195, 295, 5870, 4365, 13, 51046, 51046, 440, 3793, 311, 751, 466, 11, 370, 337, 1365, 11, 264, 1900, 2539, 3314, 300, 436, 1143, 420, 264, 51262, 51262, 636, 436, 764, 15245, 2026, 420, 370, 322, 13, 51340, 51340, 759, 456, 366, 3195, 295, 613, 721, 11, 550, 1936, 309, 311, 516, 281, 312, 6081, 293, 6081, 337, 291, 51508, 51508, 281, 1333, 295, 29501, 420, 544, 293, 544, 721, 337, 291, 281, 483, 2085, 13, 51860, 51860], "temperature": 0.0, "avg_logprob": -0.21715049420372914, "compression_ratio": 1.8488372093023255, "no_speech_prob": 5.862524631083943e-06}, {"id": 1608, "seek": 651052, "start": 6514.120000000001, "end": 6521.88, "text": " The other thing to remember is basically if you're sort of implementing up existing method,", "tokens": [50364, 407, 445, 264, 1230, 295, 2684, 3755, 366, 665, 16961, 13, 50544, 50544, 440, 661, 551, 281, 1604, 307, 1936, 498, 291, 434, 1333, 295, 18114, 493, 6741, 3170, 11, 50932, 50932, 550, 456, 366, 516, 281, 312, 3195, 295, 5870, 4365, 13, 51046, 51046, 440, 3793, 311, 751, 466, 11, 370, 337, 1365, 11, 264, 1900, 2539, 3314, 300, 436, 1143, 420, 264, 51262, 51262, 636, 436, 764, 15245, 2026, 420, 370, 322, 13, 51340, 51340, 759, 456, 366, 3195, 295, 613, 721, 11, 550, 1936, 309, 311, 516, 281, 312, 6081, 293, 6081, 337, 291, 51508, 51508, 281, 1333, 295, 29501, 420, 544, 293, 544, 721, 337, 291, 281, 483, 2085, 13, 51860, 51860], "temperature": 0.0, "avg_logprob": -0.21715049420372914, "compression_ratio": 1.8488372093023255, "no_speech_prob": 5.862524631083943e-06}, {"id": 1609, "seek": 651052, "start": 6521.88, "end": 6524.160000000001, "text": " then there are going to be lots of tiny details.", "tokens": [50364, 407, 445, 264, 1230, 295, 2684, 3755, 366, 665, 16961, 13, 50544, 50544, 440, 661, 551, 281, 1604, 307, 1936, 498, 291, 434, 1333, 295, 18114, 493, 6741, 3170, 11, 50932, 50932, 550, 456, 366, 516, 281, 312, 3195, 295, 5870, 4365, 13, 51046, 51046, 440, 3793, 311, 751, 466, 11, 370, 337, 1365, 11, 264, 1900, 2539, 3314, 300, 436, 1143, 420, 264, 51262, 51262, 636, 436, 764, 15245, 2026, 420, 370, 322, 13, 51340, 51340, 759, 456, 366, 3195, 295, 613, 721, 11, 550, 1936, 309, 311, 516, 281, 312, 6081, 293, 6081, 337, 291, 51508, 51508, 281, 1333, 295, 29501, 420, 544, 293, 544, 721, 337, 291, 281, 483, 2085, 13, 51860, 51860], "temperature": 0.0, "avg_logprob": -0.21715049420372914, "compression_ratio": 1.8488372093023255, "no_speech_prob": 5.862524631083943e-06}, {"id": 1610, "seek": 651052, "start": 6524.160000000001, "end": 6528.4800000000005, "text": " The author's talk about, so for example, the exact learning rate that they used or the", "tokens": [50364, 407, 445, 264, 1230, 295, 2684, 3755, 366, 665, 16961, 13, 50544, 50544, 440, 661, 551, 281, 1604, 307, 1936, 498, 291, 434, 1333, 295, 18114, 493, 6741, 3170, 11, 50932, 50932, 550, 456, 366, 516, 281, 312, 3195, 295, 5870, 4365, 13, 51046, 51046, 440, 3793, 311, 751, 466, 11, 370, 337, 1365, 11, 264, 1900, 2539, 3314, 300, 436, 1143, 420, 264, 51262, 51262, 636, 436, 764, 15245, 2026, 420, 370, 322, 13, 51340, 51340, 759, 456, 366, 3195, 295, 613, 721, 11, 550, 1936, 309, 311, 516, 281, 312, 6081, 293, 6081, 337, 291, 51508, 51508, 281, 1333, 295, 29501, 420, 544, 293, 544, 721, 337, 291, 281, 483, 2085, 13, 51860, 51860], "temperature": 0.0, "avg_logprob": -0.21715049420372914, "compression_ratio": 1.8488372093023255, "no_speech_prob": 5.862524631083943e-06}, {"id": 1611, "seek": 651052, "start": 6528.4800000000005, "end": 6530.040000000001, "text": " way they use batch norm or so on.", "tokens": [50364, 407, 445, 264, 1230, 295, 2684, 3755, 366, 665, 16961, 13, 50544, 50544, 440, 661, 551, 281, 1604, 307, 1936, 498, 291, 434, 1333, 295, 18114, 493, 6741, 3170, 11, 50932, 50932, 550, 456, 366, 516, 281, 312, 3195, 295, 5870, 4365, 13, 51046, 51046, 440, 3793, 311, 751, 466, 11, 370, 337, 1365, 11, 264, 1900, 2539, 3314, 300, 436, 1143, 420, 264, 51262, 51262, 636, 436, 764, 15245, 2026, 420, 370, 322, 13, 51340, 51340, 759, 456, 366, 3195, 295, 613, 721, 11, 550, 1936, 309, 311, 516, 281, 312, 6081, 293, 6081, 337, 291, 51508, 51508, 281, 1333, 295, 29501, 420, 544, 293, 544, 721, 337, 291, 281, 483, 2085, 13, 51860, 51860], "temperature": 0.0, "avg_logprob": -0.21715049420372914, "compression_ratio": 1.8488372093023255, "no_speech_prob": 5.862524631083943e-06}, {"id": 1612, "seek": 651052, "start": 6530.040000000001, "end": 6533.400000000001, "text": " If there are lots of these things, then basically it's going to be harder and harder for you", "tokens": [50364, 407, 445, 264, 1230, 295, 2684, 3755, 366, 665, 16961, 13, 50544, 50544, 440, 661, 551, 281, 1604, 307, 1936, 498, 291, 434, 1333, 295, 18114, 493, 6741, 3170, 11, 50932, 50932, 550, 456, 366, 516, 281, 312, 3195, 295, 5870, 4365, 13, 51046, 51046, 440, 3793, 311, 751, 466, 11, 370, 337, 1365, 11, 264, 1900, 2539, 3314, 300, 436, 1143, 420, 264, 51262, 51262, 636, 436, 764, 15245, 2026, 420, 370, 322, 13, 51340, 51340, 759, 456, 366, 3195, 295, 613, 721, 11, 550, 1936, 309, 311, 516, 281, 312, 6081, 293, 6081, 337, 291, 51508, 51508, 281, 1333, 295, 29501, 420, 544, 293, 544, 721, 337, 291, 281, 483, 2085, 13, 51860, 51860], "temperature": 0.0, "avg_logprob": -0.21715049420372914, "compression_ratio": 1.8488372093023255, "no_speech_prob": 5.862524631083943e-06}, {"id": 1613, "seek": 651052, "start": 6533.400000000001, "end": 6540.4400000000005, "text": " to sort of reproduce or more and more things for you to get wrong.", "tokens": [50364, 407, 445, 264, 1230, 295, 2684, 3755, 366, 665, 16961, 13, 50544, 50544, 440, 661, 551, 281, 1604, 307, 1936, 498, 291, 434, 1333, 295, 18114, 493, 6741, 3170, 11, 50932, 50932, 550, 456, 366, 516, 281, 312, 3195, 295, 5870, 4365, 13, 51046, 51046, 440, 3793, 311, 751, 466, 11, 370, 337, 1365, 11, 264, 1900, 2539, 3314, 300, 436, 1143, 420, 264, 51262, 51262, 636, 436, 764, 15245, 2026, 420, 370, 322, 13, 51340, 51340, 759, 456, 366, 3195, 295, 613, 721, 11, 550, 1936, 309, 311, 516, 281, 312, 6081, 293, 6081, 337, 291, 51508, 51508, 281, 1333, 295, 29501, 420, 544, 293, 544, 721, 337, 291, 281, 483, 2085, 13, 51860, 51860], "temperature": 0.0, "avg_logprob": -0.21715049420372914, "compression_ratio": 1.8488372093023255, "no_speech_prob": 5.862524631083943e-06}, {"id": 1614, "seek": 654044, "start": 6540.44, "end": 6542.16, "text": " Second thing to remember is data augmentation.", "tokens": [50364, 5736, 551, 281, 1604, 307, 1412, 14501, 19631, 13, 50450, 50450, 11888, 14501, 19631, 300, 366, 534, 4924, 13, 50548, 50548, 407, 498, 291, 483, 1340, 1364, 11, 291, 576, 853, 281, 1333, 295, 909, 544, 1412, 29919, 763, 50830, 50830, 281, 309, 13, 51020, 51020, 400, 576, 291, 2748, 505, 1382, 6418, 420, 360, 291, 519, 300, 576, 312, 886, 2252, 281, 51198, 51198, 360, 294, 472, 1618, 30, 51340, 51340, 286, 478, 406, 988, 437, 264, 3287, 307, 534, 13, 51458, 51458, 407, 286, 478, 406, 988, 498, 286, 393, 2871, 322, 300, 13, 51596, 51596, 1033, 13, 51646, 51646, 2561, 13, 51696, 51696], "temperature": 0.0, "avg_logprob": -0.2971048355102539, "compression_ratio": 1.6902654867256637, "no_speech_prob": 3.822373037110083e-05}, {"id": 1615, "seek": 654044, "start": 6542.16, "end": 6544.12, "text": " Data augmentation that are really critical.", "tokens": [50364, 5736, 551, 281, 1604, 307, 1412, 14501, 19631, 13, 50450, 50450, 11888, 14501, 19631, 300, 366, 534, 4924, 13, 50548, 50548, 407, 498, 291, 483, 1340, 1364, 11, 291, 576, 853, 281, 1333, 295, 909, 544, 1412, 29919, 763, 50830, 50830, 281, 309, 13, 51020, 51020, 400, 576, 291, 2748, 505, 1382, 6418, 420, 360, 291, 519, 300, 576, 312, 886, 2252, 281, 51198, 51198, 360, 294, 472, 1618, 30, 51340, 51340, 286, 478, 406, 988, 437, 264, 3287, 307, 534, 13, 51458, 51458, 407, 286, 478, 406, 988, 498, 286, 393, 2871, 322, 300, 13, 51596, 51596, 1033, 13, 51646, 51646, 2561, 13, 51696, 51696], "temperature": 0.0, "avg_logprob": -0.2971048355102539, "compression_ratio": 1.6902654867256637, "no_speech_prob": 3.822373037110083e-05}, {"id": 1616, "seek": 654044, "start": 6544.12, "end": 6549.759999999999, "text": " So if you get anything working, you would try to sort of add more data augmentations", "tokens": [50364, 5736, 551, 281, 1604, 307, 1412, 14501, 19631, 13, 50450, 50450, 11888, 14501, 19631, 300, 366, 534, 4924, 13, 50548, 50548, 407, 498, 291, 483, 1340, 1364, 11, 291, 576, 853, 281, 1333, 295, 909, 544, 1412, 29919, 763, 50830, 50830, 281, 309, 13, 51020, 51020, 400, 576, 291, 2748, 505, 1382, 6418, 420, 360, 291, 519, 300, 576, 312, 886, 2252, 281, 51198, 51198, 360, 294, 472, 1618, 30, 51340, 51340, 286, 478, 406, 988, 437, 264, 3287, 307, 534, 13, 51458, 51458, 407, 286, 478, 406, 988, 498, 286, 393, 2871, 322, 300, 13, 51596, 51596, 1033, 13, 51646, 51646, 2561, 13, 51696, 51696], "temperature": 0.0, "avg_logprob": -0.2971048355102539, "compression_ratio": 1.6902654867256637, "no_speech_prob": 3.822373037110083e-05}, {"id": 1617, "seek": 654044, "start": 6549.759999999999, "end": 6553.5599999999995, "text": " to it.", "tokens": [50364, 5736, 551, 281, 1604, 307, 1412, 14501, 19631, 13, 50450, 50450, 11888, 14501, 19631, 300, 366, 534, 4924, 13, 50548, 50548, 407, 498, 291, 483, 1340, 1364, 11, 291, 576, 853, 281, 1333, 295, 909, 544, 1412, 29919, 763, 50830, 50830, 281, 309, 13, 51020, 51020, 400, 576, 291, 2748, 505, 1382, 6418, 420, 360, 291, 519, 300, 576, 312, 886, 2252, 281, 51198, 51198, 360, 294, 472, 1618, 30, 51340, 51340, 286, 478, 406, 988, 437, 264, 3287, 307, 534, 13, 51458, 51458, 407, 286, 478, 406, 988, 498, 286, 393, 2871, 322, 300, 13, 51596, 51596, 1033, 13, 51646, 51646, 2561, 13, 51696, 51696], "temperature": 0.0, "avg_logprob": -0.2971048355102539, "compression_ratio": 1.6902654867256637, "no_speech_prob": 3.822373037110083e-05}, {"id": 1618, "seek": 654044, "start": 6553.5599999999995, "end": 6557.12, "text": " And would you recommend us trying poll or do you think that would be too difficult to", "tokens": [50364, 5736, 551, 281, 1604, 307, 1412, 14501, 19631, 13, 50450, 50450, 11888, 14501, 19631, 300, 366, 534, 4924, 13, 50548, 50548, 407, 498, 291, 483, 1340, 1364, 11, 291, 576, 853, 281, 1333, 295, 909, 544, 1412, 29919, 763, 50830, 50830, 281, 309, 13, 51020, 51020, 400, 576, 291, 2748, 505, 1382, 6418, 420, 360, 291, 519, 300, 576, 312, 886, 2252, 281, 51198, 51198, 360, 294, 472, 1618, 30, 51340, 51340, 286, 478, 406, 988, 437, 264, 3287, 307, 534, 13, 51458, 51458, 407, 286, 478, 406, 988, 498, 286, 393, 2871, 322, 300, 13, 51596, 51596, 1033, 13, 51646, 51646, 2561, 13, 51696, 51696], "temperature": 0.0, "avg_logprob": -0.2971048355102539, "compression_ratio": 1.6902654867256637, "no_speech_prob": 3.822373037110083e-05}, {"id": 1619, "seek": 654044, "start": 6557.12, "end": 6559.96, "text": " do in one month?", "tokens": [50364, 5736, 551, 281, 1604, 307, 1412, 14501, 19631, 13, 50450, 50450, 11888, 14501, 19631, 300, 366, 534, 4924, 13, 50548, 50548, 407, 498, 291, 483, 1340, 1364, 11, 291, 576, 853, 281, 1333, 295, 909, 544, 1412, 29919, 763, 50830, 50830, 281, 309, 13, 51020, 51020, 400, 576, 291, 2748, 505, 1382, 6418, 420, 360, 291, 519, 300, 576, 312, 886, 2252, 281, 51198, 51198, 360, 294, 472, 1618, 30, 51340, 51340, 286, 478, 406, 988, 437, 264, 3287, 307, 534, 13, 51458, 51458, 407, 286, 478, 406, 988, 498, 286, 393, 2871, 322, 300, 13, 51596, 51596, 1033, 13, 51646, 51646, 2561, 13, 51696, 51696], "temperature": 0.0, "avg_logprob": -0.2971048355102539, "compression_ratio": 1.6902654867256637, "no_speech_prob": 3.822373037110083e-05}, {"id": 1620, "seek": 654044, "start": 6559.96, "end": 6562.32, "text": " I'm not sure what the setting is really.", "tokens": [50364, 5736, 551, 281, 1604, 307, 1412, 14501, 19631, 13, 50450, 50450, 11888, 14501, 19631, 300, 366, 534, 4924, 13, 50548, 50548, 407, 498, 291, 483, 1340, 1364, 11, 291, 576, 853, 281, 1333, 295, 909, 544, 1412, 29919, 763, 50830, 50830, 281, 309, 13, 51020, 51020, 400, 576, 291, 2748, 505, 1382, 6418, 420, 360, 291, 519, 300, 576, 312, 886, 2252, 281, 51198, 51198, 360, 294, 472, 1618, 30, 51340, 51340, 286, 478, 406, 988, 437, 264, 3287, 307, 534, 13, 51458, 51458, 407, 286, 478, 406, 988, 498, 286, 393, 2871, 322, 300, 13, 51596, 51596, 1033, 13, 51646, 51646, 2561, 13, 51696, 51696], "temperature": 0.0, "avg_logprob": -0.2971048355102539, "compression_ratio": 1.6902654867256637, "no_speech_prob": 3.822373037110083e-05}, {"id": 1621, "seek": 654044, "start": 6562.32, "end": 6565.08, "text": " So I'm not sure if I can comment on that.", "tokens": [50364, 5736, 551, 281, 1604, 307, 1412, 14501, 19631, 13, 50450, 50450, 11888, 14501, 19631, 300, 366, 534, 4924, 13, 50548, 50548, 407, 498, 291, 483, 1340, 1364, 11, 291, 576, 853, 281, 1333, 295, 909, 544, 1412, 29919, 763, 50830, 50830, 281, 309, 13, 51020, 51020, 400, 576, 291, 2748, 505, 1382, 6418, 420, 360, 291, 519, 300, 576, 312, 886, 2252, 281, 51198, 51198, 360, 294, 472, 1618, 30, 51340, 51340, 286, 478, 406, 988, 437, 264, 3287, 307, 534, 13, 51458, 51458, 407, 286, 478, 406, 988, 498, 286, 393, 2871, 322, 300, 13, 51596, 51596, 1033, 13, 51646, 51646, 2561, 13, 51696, 51696], "temperature": 0.0, "avg_logprob": -0.2971048355102539, "compression_ratio": 1.6902654867256637, "no_speech_prob": 3.822373037110083e-05}, {"id": 1622, "seek": 654044, "start": 6565.08, "end": 6566.08, "text": " Okay.", "tokens": [50364, 5736, 551, 281, 1604, 307, 1412, 14501, 19631, 13, 50450, 50450, 11888, 14501, 19631, 300, 366, 534, 4924, 13, 50548, 50548, 407, 498, 291, 483, 1340, 1364, 11, 291, 576, 853, 281, 1333, 295, 909, 544, 1412, 29919, 763, 50830, 50830, 281, 309, 13, 51020, 51020, 400, 576, 291, 2748, 505, 1382, 6418, 420, 360, 291, 519, 300, 576, 312, 886, 2252, 281, 51198, 51198, 360, 294, 472, 1618, 30, 51340, 51340, 286, 478, 406, 988, 437, 264, 3287, 307, 534, 13, 51458, 51458, 407, 286, 478, 406, 988, 498, 286, 393, 2871, 322, 300, 13, 51596, 51596, 1033, 13, 51646, 51646, 2561, 13, 51696, 51696], "temperature": 0.0, "avg_logprob": -0.2971048355102539, "compression_ratio": 1.6902654867256637, "no_speech_prob": 3.822373037110083e-05}, {"id": 1623, "seek": 654044, "start": 6566.08, "end": 6567.08, "text": " Thanks.", "tokens": [50364, 5736, 551, 281, 1604, 307, 1412, 14501, 19631, 13, 50450, 50450, 11888, 14501, 19631, 300, 366, 534, 4924, 13, 50548, 50548, 407, 498, 291, 483, 1340, 1364, 11, 291, 576, 853, 281, 1333, 295, 909, 544, 1412, 29919, 763, 50830, 50830, 281, 309, 13, 51020, 51020, 400, 576, 291, 2748, 505, 1382, 6418, 420, 360, 291, 519, 300, 576, 312, 886, 2252, 281, 51198, 51198, 360, 294, 472, 1618, 30, 51340, 51340, 286, 478, 406, 988, 437, 264, 3287, 307, 534, 13, 51458, 51458, 407, 286, 478, 406, 988, 498, 286, 393, 2871, 322, 300, 13, 51596, 51596, 1033, 13, 51646, 51646, 2561, 13, 51696, 51696], "temperature": 0.0, "avg_logprob": -0.2971048355102539, "compression_ratio": 1.6902654867256637, "no_speech_prob": 3.822373037110083e-05}, {"id": 1624, "seek": 656708, "start": 6567.08, "end": 6571.4, "text": " And just one more thing, did you try using momentum contrast on polls instead of memory", "tokens": [50364, 400, 445, 472, 544, 551, 11, 630, 291, 853, 1228, 11244, 8712, 322, 24264, 2602, 295, 4675, 50580, 50580, 3765, 30, 50630, 50630, 286, 2378, 380, 13, 50718, 50718, 407, 321, 1936, 4259, 281, 264, 917, 281, 917, 3037, 11, 597, 307, 411, 2531, 281, 437, 38163, 307, 13, 50942, 50942, 407, 264, 551, 307, 11, 286, 914, 11, 291, 393, 1936, 5448, 257, 3840, 295, 40019, 490, 819, 51222, 51222, 18407, 82, 293, 3488, 428, 15245, 2744, 13, 51324, 51324, 663, 767, 5101, 3665, 257, 688, 13, 51462, 51462, 286, 576, 9091, 3335, 21141, 576, 854, 257, 688, 382, 731, 13, 51606, 51606], "temperature": 0.0, "avg_logprob": -0.2532340895454839, "compression_ratio": 1.5384615384615385, "no_speech_prob": 2.144189966202248e-05}, {"id": 1625, "seek": 656708, "start": 6571.4, "end": 6572.4, "text": " bank?", "tokens": [50364, 400, 445, 472, 544, 551, 11, 630, 291, 853, 1228, 11244, 8712, 322, 24264, 2602, 295, 4675, 50580, 50580, 3765, 30, 50630, 50630, 286, 2378, 380, 13, 50718, 50718, 407, 321, 1936, 4259, 281, 264, 917, 281, 917, 3037, 11, 597, 307, 411, 2531, 281, 437, 38163, 307, 13, 50942, 50942, 407, 264, 551, 307, 11, 286, 914, 11, 291, 393, 1936, 5448, 257, 3840, 295, 40019, 490, 819, 51222, 51222, 18407, 82, 293, 3488, 428, 15245, 2744, 13, 51324, 51324, 663, 767, 5101, 3665, 257, 688, 13, 51462, 51462, 286, 576, 9091, 3335, 21141, 576, 854, 257, 688, 382, 731, 13, 51606, 51606], "temperature": 0.0, "avg_logprob": -0.2532340895454839, "compression_ratio": 1.5384615384615385, "no_speech_prob": 2.144189966202248e-05}, {"id": 1626, "seek": 656708, "start": 6572.4, "end": 6574.16, "text": " I haven't.", "tokens": [50364, 400, 445, 472, 544, 551, 11, 630, 291, 853, 1228, 11244, 8712, 322, 24264, 2602, 295, 4675, 50580, 50580, 3765, 30, 50630, 50630, 286, 2378, 380, 13, 50718, 50718, 407, 321, 1936, 4259, 281, 264, 917, 281, 917, 3037, 11, 597, 307, 411, 2531, 281, 437, 38163, 307, 13, 50942, 50942, 407, 264, 551, 307, 11, 286, 914, 11, 291, 393, 1936, 5448, 257, 3840, 295, 40019, 490, 819, 51222, 51222, 18407, 82, 293, 3488, 428, 15245, 2744, 13, 51324, 51324, 663, 767, 5101, 3665, 257, 688, 13, 51462, 51462, 286, 576, 9091, 3335, 21141, 576, 854, 257, 688, 382, 731, 13, 51606, 51606], "temperature": 0.0, "avg_logprob": -0.2532340895454839, "compression_ratio": 1.5384615384615385, "no_speech_prob": 2.144189966202248e-05}, {"id": 1627, "seek": 656708, "start": 6574.16, "end": 6578.64, "text": " So we basically moved to the end to end version, which is like similar to what Cynthia is.", "tokens": [50364, 400, 445, 472, 544, 551, 11, 630, 291, 853, 1228, 11244, 8712, 322, 24264, 2602, 295, 4675, 50580, 50580, 3765, 30, 50630, 50630, 286, 2378, 380, 13, 50718, 50718, 407, 321, 1936, 4259, 281, 264, 917, 281, 917, 3037, 11, 597, 307, 411, 2531, 281, 437, 38163, 307, 13, 50942, 50942, 407, 264, 551, 307, 11, 286, 914, 11, 291, 393, 1936, 5448, 257, 3840, 295, 40019, 490, 819, 51222, 51222, 18407, 82, 293, 3488, 428, 15245, 2744, 13, 51324, 51324, 663, 767, 5101, 3665, 257, 688, 13, 51462, 51462, 286, 576, 9091, 3335, 21141, 576, 854, 257, 688, 382, 731, 13, 51606, 51606], "temperature": 0.0, "avg_logprob": -0.2532340895454839, "compression_ratio": 1.5384615384615385, "no_speech_prob": 2.144189966202248e-05}, {"id": 1628, "seek": 656708, "start": 6578.64, "end": 6584.24, "text": " So the thing is, I mean, you can basically gather a bunch of negatives from different", "tokens": [50364, 400, 445, 472, 544, 551, 11, 630, 291, 853, 1228, 11244, 8712, 322, 24264, 2602, 295, 4675, 50580, 50580, 3765, 30, 50630, 50630, 286, 2378, 380, 13, 50718, 50718, 407, 321, 1936, 4259, 281, 264, 917, 281, 917, 3037, 11, 597, 307, 411, 2531, 281, 437, 38163, 307, 13, 50942, 50942, 407, 264, 551, 307, 11, 286, 914, 11, 291, 393, 1936, 5448, 257, 3840, 295, 40019, 490, 819, 51222, 51222, 18407, 82, 293, 3488, 428, 15245, 2744, 13, 51324, 51324, 663, 767, 5101, 3665, 257, 688, 13, 51462, 51462, 286, 576, 9091, 3335, 21141, 576, 854, 257, 688, 382, 731, 13, 51606, 51606], "temperature": 0.0, "avg_logprob": -0.2532340895454839, "compression_ratio": 1.5384615384615385, "no_speech_prob": 2.144189966202248e-05}, {"id": 1629, "seek": 656708, "start": 6584.24, "end": 6586.28, "text": " GPUs and increase your batch size.", "tokens": [50364, 400, 445, 472, 544, 551, 11, 630, 291, 853, 1228, 11244, 8712, 322, 24264, 2602, 295, 4675, 50580, 50580, 3765, 30, 50630, 50630, 286, 2378, 380, 13, 50718, 50718, 407, 321, 1936, 4259, 281, 264, 917, 281, 917, 3037, 11, 597, 307, 411, 2531, 281, 437, 38163, 307, 13, 50942, 50942, 407, 264, 551, 307, 11, 286, 914, 11, 291, 393, 1936, 5448, 257, 3840, 295, 40019, 490, 819, 51222, 51222, 18407, 82, 293, 3488, 428, 15245, 2744, 13, 51324, 51324, 663, 767, 5101, 3665, 257, 688, 13, 51462, 51462, 286, 576, 9091, 3335, 21141, 576, 854, 257, 688, 382, 731, 13, 51606, 51606], "temperature": 0.0, "avg_logprob": -0.2532340895454839, "compression_ratio": 1.5384615384615385, "no_speech_prob": 2.144189966202248e-05}, {"id": 1630, "seek": 656708, "start": 6586.28, "end": 6589.04, "text": " That actually generally helps a lot.", "tokens": [50364, 400, 445, 472, 544, 551, 11, 630, 291, 853, 1228, 11244, 8712, 322, 24264, 2602, 295, 4675, 50580, 50580, 3765, 30, 50630, 50630, 286, 2378, 380, 13, 50718, 50718, 407, 321, 1936, 4259, 281, 264, 917, 281, 917, 3037, 11, 597, 307, 411, 2531, 281, 437, 38163, 307, 13, 50942, 50942, 407, 264, 551, 307, 11, 286, 914, 11, 291, 393, 1936, 5448, 257, 3840, 295, 40019, 490, 819, 51222, 51222, 18407, 82, 293, 3488, 428, 15245, 2744, 13, 51324, 51324, 663, 767, 5101, 3665, 257, 688, 13, 51462, 51462, 286, 576, 9091, 3335, 21141, 576, 854, 257, 688, 382, 731, 13, 51606, 51606], "temperature": 0.0, "avg_logprob": -0.2532340895454839, "compression_ratio": 1.5384615384615385, "no_speech_prob": 2.144189966202248e-05}, {"id": 1631, "seek": 656708, "start": 6589.04, "end": 6591.92, "text": " I would suspect MoCo would help a lot as well.", "tokens": [50364, 400, 445, 472, 544, 551, 11, 630, 291, 853, 1228, 11244, 8712, 322, 24264, 2602, 295, 4675, 50580, 50580, 3765, 30, 50630, 50630, 286, 2378, 380, 13, 50718, 50718, 407, 321, 1936, 4259, 281, 264, 917, 281, 917, 3037, 11, 597, 307, 411, 2531, 281, 437, 38163, 307, 13, 50942, 50942, 407, 264, 551, 307, 11, 286, 914, 11, 291, 393, 1936, 5448, 257, 3840, 295, 40019, 490, 819, 51222, 51222, 18407, 82, 293, 3488, 428, 15245, 2744, 13, 51324, 51324, 663, 767, 5101, 3665, 257, 688, 13, 51462, 51462, 286, 576, 9091, 3335, 21141, 576, 854, 257, 688, 382, 731, 13, 51606, 51606], "temperature": 0.0, "avg_logprob": -0.2532340895454839, "compression_ratio": 1.5384615384615385, "no_speech_prob": 2.144189966202248e-05}, {"id": 1632, "seek": 659192, "start": 6591.92, "end": 6597.76, "text": " I think MoCo got improved performance over Cynthia by replacing end to end training with", "tokens": [50364, 286, 519, 3335, 21141, 658, 9689, 3389, 670, 38163, 538, 19139, 917, 281, 917, 3097, 365, 50656, 50656, 3335, 21141, 13, 50706, 50706, 1779, 13, 50756, 50756, 286, 519, 264, 3547, 366, 920, 6457, 2531, 13, 50952, 50952, 400, 456, 366, 1359, 7300, 294, 13344, 20618, 300, 291, 1333, 295, 536, 2108, 613, 51142, 51142, 10577, 13, 51192, 51192, 407, 1338, 11, 286, 519, 370, 321, 434, 5038, 281, 1333, 295, 4374, 257, 544, 31677, 13344, 51474, 51474, 18927, 13, 51524, 51524, 407, 321, 630, 300, 1036, 1064, 13, 51574, 51574, 8590, 11, 300, 390, 294, 17773, 886, 13, 51650, 51650, 407, 321, 434, 1382, 281, 1333, 295, 4374, 746, 294, 9953, 51, 284, 339, 586, 11, 597, 486, 2893, 257, 688, 295, 51842, 51842], "temperature": 0.0, "avg_logprob": -0.1875875127597118, "compression_ratio": 1.6768707482993197, "no_speech_prob": 3.5351942642591894e-05}, {"id": 1633, "seek": 659192, "start": 6597.76, "end": 6598.76, "text": " MoCo.", "tokens": [50364, 286, 519, 3335, 21141, 658, 9689, 3389, 670, 38163, 538, 19139, 917, 281, 917, 3097, 365, 50656, 50656, 3335, 21141, 13, 50706, 50706, 1779, 13, 50756, 50756, 286, 519, 264, 3547, 366, 920, 6457, 2531, 13, 50952, 50952, 400, 456, 366, 1359, 7300, 294, 13344, 20618, 300, 291, 1333, 295, 536, 2108, 613, 51142, 51142, 10577, 13, 51192, 51192, 407, 1338, 11, 286, 519, 370, 321, 434, 5038, 281, 1333, 295, 4374, 257, 544, 31677, 13344, 51474, 51474, 18927, 13, 51524, 51524, 407, 321, 630, 300, 1036, 1064, 13, 51574, 51574, 8590, 11, 300, 390, 294, 17773, 886, 13, 51650, 51650, 407, 321, 434, 1382, 281, 1333, 295, 4374, 746, 294, 9953, 51, 284, 339, 586, 11, 597, 486, 2893, 257, 688, 295, 51842, 51842], "temperature": 0.0, "avg_logprob": -0.1875875127597118, "compression_ratio": 1.6768707482993197, "no_speech_prob": 3.5351942642591894e-05}, {"id": 1634, "seek": 659192, "start": 6598.76, "end": 6599.76, "text": " Right.", "tokens": [50364, 286, 519, 3335, 21141, 658, 9689, 3389, 670, 38163, 538, 19139, 917, 281, 917, 3097, 365, 50656, 50656, 3335, 21141, 13, 50706, 50706, 1779, 13, 50756, 50756, 286, 519, 264, 3547, 366, 920, 6457, 2531, 13, 50952, 50952, 400, 456, 366, 1359, 7300, 294, 13344, 20618, 300, 291, 1333, 295, 536, 2108, 613, 51142, 51142, 10577, 13, 51192, 51192, 407, 1338, 11, 286, 519, 370, 321, 434, 5038, 281, 1333, 295, 4374, 257, 544, 31677, 13344, 51474, 51474, 18927, 13, 51524, 51524, 407, 321, 630, 300, 1036, 1064, 13, 51574, 51574, 8590, 11, 300, 390, 294, 17773, 886, 13, 51650, 51650, 407, 321, 434, 1382, 281, 1333, 295, 4374, 746, 294, 9953, 51, 284, 339, 586, 11, 597, 486, 2893, 257, 688, 295, 51842, 51842], "temperature": 0.0, "avg_logprob": -0.1875875127597118, "compression_ratio": 1.6768707482993197, "no_speech_prob": 3.5351942642591894e-05}, {"id": 1635, "seek": 659192, "start": 6599.76, "end": 6603.68, "text": " I think the numbers are still fairly similar.", "tokens": [50364, 286, 519, 3335, 21141, 658, 9689, 3389, 670, 38163, 538, 19139, 917, 281, 917, 3097, 365, 50656, 50656, 3335, 21141, 13, 50706, 50706, 1779, 13, 50756, 50756, 286, 519, 264, 3547, 366, 920, 6457, 2531, 13, 50952, 50952, 400, 456, 366, 1359, 7300, 294, 13344, 20618, 300, 291, 1333, 295, 536, 2108, 613, 51142, 51142, 10577, 13, 51192, 51192, 407, 1338, 11, 286, 519, 370, 321, 434, 5038, 281, 1333, 295, 4374, 257, 544, 31677, 13344, 51474, 51474, 18927, 13, 51524, 51524, 407, 321, 630, 300, 1036, 1064, 13, 51574, 51574, 8590, 11, 300, 390, 294, 17773, 886, 13, 51650, 51650, 407, 321, 434, 1382, 281, 1333, 295, 4374, 746, 294, 9953, 51, 284, 339, 586, 11, 597, 486, 2893, 257, 688, 295, 51842, 51842], "temperature": 0.0, "avg_logprob": -0.1875875127597118, "compression_ratio": 1.6768707482993197, "no_speech_prob": 3.5351942642591894e-05}, {"id": 1636, "seek": 659192, "start": 6603.68, "end": 6607.4800000000005, "text": " And there are small differences in evaluation protocols that you sort of see across these", "tokens": [50364, 286, 519, 3335, 21141, 658, 9689, 3389, 670, 38163, 538, 19139, 917, 281, 917, 3097, 365, 50656, 50656, 3335, 21141, 13, 50706, 50706, 1779, 13, 50756, 50756, 286, 519, 264, 3547, 366, 920, 6457, 2531, 13, 50952, 50952, 400, 456, 366, 1359, 7300, 294, 13344, 20618, 300, 291, 1333, 295, 536, 2108, 613, 51142, 51142, 10577, 13, 51192, 51192, 407, 1338, 11, 286, 519, 370, 321, 434, 5038, 281, 1333, 295, 4374, 257, 544, 31677, 13344, 51474, 51474, 18927, 13, 51524, 51524, 407, 321, 630, 300, 1036, 1064, 13, 51574, 51574, 8590, 11, 300, 390, 294, 17773, 886, 13, 51650, 51650, 407, 321, 434, 1382, 281, 1333, 295, 4374, 746, 294, 9953, 51, 284, 339, 586, 11, 597, 486, 2893, 257, 688, 295, 51842, 51842], "temperature": 0.0, "avg_logprob": -0.1875875127597118, "compression_ratio": 1.6768707482993197, "no_speech_prob": 3.5351942642591894e-05}, {"id": 1637, "seek": 659192, "start": 6607.4800000000005, "end": 6608.4800000000005, "text": " papers.", "tokens": [50364, 286, 519, 3335, 21141, 658, 9689, 3389, 670, 38163, 538, 19139, 917, 281, 917, 3097, 365, 50656, 50656, 3335, 21141, 13, 50706, 50706, 1779, 13, 50756, 50756, 286, 519, 264, 3547, 366, 920, 6457, 2531, 13, 50952, 50952, 400, 456, 366, 1359, 7300, 294, 13344, 20618, 300, 291, 1333, 295, 536, 2108, 613, 51142, 51142, 10577, 13, 51192, 51192, 407, 1338, 11, 286, 519, 370, 321, 434, 5038, 281, 1333, 295, 4374, 257, 544, 31677, 13344, 51474, 51474, 18927, 13, 51524, 51524, 407, 321, 630, 300, 1036, 1064, 13, 51574, 51574, 8590, 11, 300, 390, 294, 17773, 886, 13, 51650, 51650, 407, 321, 434, 1382, 281, 1333, 295, 4374, 746, 294, 9953, 51, 284, 339, 586, 11, 597, 486, 2893, 257, 688, 295, 51842, 51842], "temperature": 0.0, "avg_logprob": -0.1875875127597118, "compression_ratio": 1.6768707482993197, "no_speech_prob": 3.5351942642591894e-05}, {"id": 1638, "seek": 659192, "start": 6608.4800000000005, "end": 6614.12, "text": " So yeah, I think so we're planning to sort of release a more standardized evaluation", "tokens": [50364, 286, 519, 3335, 21141, 658, 9689, 3389, 670, 38163, 538, 19139, 917, 281, 917, 3097, 365, 50656, 50656, 3335, 21141, 13, 50706, 50706, 1779, 13, 50756, 50756, 286, 519, 264, 3547, 366, 920, 6457, 2531, 13, 50952, 50952, 400, 456, 366, 1359, 7300, 294, 13344, 20618, 300, 291, 1333, 295, 536, 2108, 613, 51142, 51142, 10577, 13, 51192, 51192, 407, 1338, 11, 286, 519, 370, 321, 434, 5038, 281, 1333, 295, 4374, 257, 544, 31677, 13344, 51474, 51474, 18927, 13, 51524, 51524, 407, 321, 630, 300, 1036, 1064, 13, 51574, 51574, 8590, 11, 300, 390, 294, 17773, 886, 13, 51650, 51650, 407, 321, 434, 1382, 281, 1333, 295, 4374, 746, 294, 9953, 51, 284, 339, 586, 11, 597, 486, 2893, 257, 688, 295, 51842, 51842], "temperature": 0.0, "avg_logprob": -0.1875875127597118, "compression_ratio": 1.6768707482993197, "no_speech_prob": 3.5351942642591894e-05}, {"id": 1639, "seek": 659192, "start": 6614.12, "end": 6615.12, "text": " benchmark.", "tokens": [50364, 286, 519, 3335, 21141, 658, 9689, 3389, 670, 38163, 538, 19139, 917, 281, 917, 3097, 365, 50656, 50656, 3335, 21141, 13, 50706, 50706, 1779, 13, 50756, 50756, 286, 519, 264, 3547, 366, 920, 6457, 2531, 13, 50952, 50952, 400, 456, 366, 1359, 7300, 294, 13344, 20618, 300, 291, 1333, 295, 536, 2108, 613, 51142, 51142, 10577, 13, 51192, 51192, 407, 1338, 11, 286, 519, 370, 321, 434, 5038, 281, 1333, 295, 4374, 257, 544, 31677, 13344, 51474, 51474, 18927, 13, 51524, 51524, 407, 321, 630, 300, 1036, 1064, 13, 51574, 51574, 8590, 11, 300, 390, 294, 17773, 886, 13, 51650, 51650, 407, 321, 434, 1382, 281, 1333, 295, 4374, 746, 294, 9953, 51, 284, 339, 586, 11, 597, 486, 2893, 257, 688, 295, 51842, 51842], "temperature": 0.0, "avg_logprob": -0.1875875127597118, "compression_ratio": 1.6768707482993197, "no_speech_prob": 3.5351942642591894e-05}, {"id": 1640, "seek": 659192, "start": 6615.12, "end": 6616.12, "text": " So we did that last year.", "tokens": [50364, 286, 519, 3335, 21141, 658, 9689, 3389, 670, 38163, 538, 19139, 917, 281, 917, 3097, 365, 50656, 50656, 3335, 21141, 13, 50706, 50706, 1779, 13, 50756, 50756, 286, 519, 264, 3547, 366, 920, 6457, 2531, 13, 50952, 50952, 400, 456, 366, 1359, 7300, 294, 13344, 20618, 300, 291, 1333, 295, 536, 2108, 613, 51142, 51142, 10577, 13, 51192, 51192, 407, 1338, 11, 286, 519, 370, 321, 434, 5038, 281, 1333, 295, 4374, 257, 544, 31677, 13344, 51474, 51474, 18927, 13, 51524, 51524, 407, 321, 630, 300, 1036, 1064, 13, 51574, 51574, 8590, 11, 300, 390, 294, 17773, 886, 13, 51650, 51650, 407, 321, 434, 1382, 281, 1333, 295, 4374, 746, 294, 9953, 51, 284, 339, 586, 11, 597, 486, 2893, 257, 688, 295, 51842, 51842], "temperature": 0.0, "avg_logprob": -0.1875875127597118, "compression_ratio": 1.6768707482993197, "no_speech_prob": 3.5351942642591894e-05}, {"id": 1641, "seek": 659192, "start": 6616.12, "end": 6617.64, "text": " Unfortunately, that was in cafe too.", "tokens": [50364, 286, 519, 3335, 21141, 658, 9689, 3389, 670, 38163, 538, 19139, 917, 281, 917, 3097, 365, 50656, 50656, 3335, 21141, 13, 50706, 50706, 1779, 13, 50756, 50756, 286, 519, 264, 3547, 366, 920, 6457, 2531, 13, 50952, 50952, 400, 456, 366, 1359, 7300, 294, 13344, 20618, 300, 291, 1333, 295, 536, 2108, 613, 51142, 51142, 10577, 13, 51192, 51192, 407, 1338, 11, 286, 519, 370, 321, 434, 5038, 281, 1333, 295, 4374, 257, 544, 31677, 13344, 51474, 51474, 18927, 13, 51524, 51524, 407, 321, 630, 300, 1036, 1064, 13, 51574, 51574, 8590, 11, 300, 390, 294, 17773, 886, 13, 51650, 51650, 407, 321, 434, 1382, 281, 1333, 295, 4374, 746, 294, 9953, 51, 284, 339, 586, 11, 597, 486, 2893, 257, 688, 295, 51842, 51842], "temperature": 0.0, "avg_logprob": -0.1875875127597118, "compression_ratio": 1.6768707482993197, "no_speech_prob": 3.5351942642591894e-05}, {"id": 1642, "seek": 659192, "start": 6617.64, "end": 6621.4800000000005, "text": " So we're trying to sort of release something in PyTorch now, which will provide a lot of", "tokens": [50364, 286, 519, 3335, 21141, 658, 9689, 3389, 670, 38163, 538, 19139, 917, 281, 917, 3097, 365, 50656, 50656, 3335, 21141, 13, 50706, 50706, 1779, 13, 50756, 50756, 286, 519, 264, 3547, 366, 920, 6457, 2531, 13, 50952, 50952, 400, 456, 366, 1359, 7300, 294, 13344, 20618, 300, 291, 1333, 295, 536, 2108, 613, 51142, 51142, 10577, 13, 51192, 51192, 407, 1338, 11, 286, 519, 370, 321, 434, 5038, 281, 1333, 295, 4374, 257, 544, 31677, 13344, 51474, 51474, 18927, 13, 51524, 51524, 407, 321, 630, 300, 1036, 1064, 13, 51574, 51574, 8590, 11, 300, 390, 294, 17773, 886, 13, 51650, 51650, 407, 321, 434, 1382, 281, 1333, 295, 4374, 746, 294, 9953, 51, 284, 339, 586, 11, 597, 486, 2893, 257, 688, 295, 51842, 51842], "temperature": 0.0, "avg_logprob": -0.1875875127597118, "compression_ratio": 1.6768707482993197, "no_speech_prob": 3.5351942642591894e-05}, {"id": 1643, "seek": 662148, "start": 6621.48, "end": 6622.839999999999, "text": " standardized implementation.", "tokens": [50364, 31677, 11420, 13, 50432, 50432, 407, 411, 3026, 75, 293, 257, 3840, 295, 613, 293, 257, 31677, 13344, 10336, 337, 1203, 13, 50670, 50670, 2561, 257, 688, 13, 50770, 50770, 1119, 3451, 11, 286, 632, 257, 1168, 466, 341, 10200, 12, 3711, 2539, 13, 51066, 51066, 407, 437, 360, 291, 519, 307, 264, 1785, 295, 411, 1337, 1166, 7150, 30, 51280, 51280, 400, 630, 291, 519, 466, 21928, 411, 8712, 488, 7150, 365, 1337, 1166, 7150, 411, 38163, 51598, 51598, 767, 575, 257, 819, 1901, 30, 51774, 51774], "temperature": 0.0, "avg_logprob": -0.3001238293117947, "compression_ratio": 1.6506550218340612, "no_speech_prob": 2.2252299913816387e-06}, {"id": 1644, "seek": 662148, "start": 6622.839999999999, "end": 6627.599999999999, "text": " So like Perl and a bunch of these and a standardized evaluation protocol for everything.", "tokens": [50364, 31677, 11420, 13, 50432, 50432, 407, 411, 3026, 75, 293, 257, 3840, 295, 613, 293, 257, 31677, 13344, 10336, 337, 1203, 13, 50670, 50670, 2561, 257, 688, 13, 50770, 50770, 1119, 3451, 11, 286, 632, 257, 1168, 466, 341, 10200, 12, 3711, 2539, 13, 51066, 51066, 407, 437, 360, 291, 519, 307, 264, 1785, 295, 411, 1337, 1166, 7150, 30, 51280, 51280, 400, 630, 291, 519, 466, 21928, 411, 8712, 488, 7150, 365, 1337, 1166, 7150, 411, 38163, 51598, 51598, 767, 575, 257, 819, 1901, 30, 51774, 51774], "temperature": 0.0, "avg_logprob": -0.3001238293117947, "compression_ratio": 1.6506550218340612, "no_speech_prob": 2.2252299913816387e-06}, {"id": 1645, "seek": 662148, "start": 6627.599999999999, "end": 6629.599999999999, "text": " Thanks a lot.", "tokens": [50364, 31677, 11420, 13, 50432, 50432, 407, 411, 3026, 75, 293, 257, 3840, 295, 613, 293, 257, 31677, 13344, 10336, 337, 1203, 13, 50670, 50670, 2561, 257, 688, 13, 50770, 50770, 1119, 3451, 11, 286, 632, 257, 1168, 466, 341, 10200, 12, 3711, 2539, 13, 51066, 51066, 407, 437, 360, 291, 519, 307, 264, 1785, 295, 411, 1337, 1166, 7150, 30, 51280, 51280, 400, 630, 291, 519, 466, 21928, 411, 8712, 488, 7150, 365, 1337, 1166, 7150, 411, 38163, 51598, 51598, 767, 575, 257, 819, 1901, 30, 51774, 51774], "temperature": 0.0, "avg_logprob": -0.3001238293117947, "compression_ratio": 1.6506550218340612, "no_speech_prob": 2.2252299913816387e-06}, {"id": 1646, "seek": 662148, "start": 6629.599999999999, "end": 6635.5199999999995, "text": " Ishan, I had a question about this sensor-wise learning.", "tokens": [50364, 31677, 11420, 13, 50432, 50432, 407, 411, 3026, 75, 293, 257, 3840, 295, 613, 293, 257, 31677, 13344, 10336, 337, 1203, 13, 50670, 50670, 2561, 257, 688, 13, 50770, 50770, 1119, 3451, 11, 286, 632, 257, 1168, 466, 341, 10200, 12, 3711, 2539, 13, 51066, 51066, 407, 437, 360, 291, 519, 307, 264, 1785, 295, 411, 1337, 1166, 7150, 30, 51280, 51280, 400, 630, 291, 519, 466, 21928, 411, 8712, 488, 7150, 365, 1337, 1166, 7150, 411, 38163, 51598, 51598, 767, 575, 257, 819, 1901, 30, 51774, 51774], "temperature": 0.0, "avg_logprob": -0.3001238293117947, "compression_ratio": 1.6506550218340612, "no_speech_prob": 2.2252299913816387e-06}, {"id": 1647, "seek": 662148, "start": 6635.5199999999995, "end": 6639.799999999999, "text": " So what do you think is the state of like generative methods?", "tokens": [50364, 31677, 11420, 13, 50432, 50432, 407, 411, 3026, 75, 293, 257, 3840, 295, 613, 293, 257, 31677, 13344, 10336, 337, 1203, 13, 50670, 50670, 2561, 257, 688, 13, 50770, 50770, 1119, 3451, 11, 286, 632, 257, 1168, 466, 341, 10200, 12, 3711, 2539, 13, 51066, 51066, 407, 437, 360, 291, 519, 307, 264, 1785, 295, 411, 1337, 1166, 7150, 30, 51280, 51280, 400, 630, 291, 519, 466, 21928, 411, 8712, 488, 7150, 365, 1337, 1166, 7150, 411, 38163, 51598, 51598, 767, 575, 257, 819, 1901, 30, 51774, 51774], "temperature": 0.0, "avg_logprob": -0.3001238293117947, "compression_ratio": 1.6506550218340612, "no_speech_prob": 2.2252299913816387e-06}, {"id": 1648, "seek": 662148, "start": 6639.799999999999, "end": 6646.16, "text": " And did you think about combining like contrastive methods with generative methods like Cynthia", "tokens": [50364, 31677, 11420, 13, 50432, 50432, 407, 411, 3026, 75, 293, 257, 3840, 295, 613, 293, 257, 31677, 13344, 10336, 337, 1203, 13, 50670, 50670, 2561, 257, 688, 13, 50770, 50770, 1119, 3451, 11, 286, 632, 257, 1168, 466, 341, 10200, 12, 3711, 2539, 13, 51066, 51066, 407, 437, 360, 291, 519, 307, 264, 1785, 295, 411, 1337, 1166, 7150, 30, 51280, 51280, 400, 630, 291, 519, 466, 21928, 411, 8712, 488, 7150, 365, 1337, 1166, 7150, 411, 38163, 51598, 51598, 767, 575, 257, 819, 1901, 30, 51774, 51774], "temperature": 0.0, "avg_logprob": -0.3001238293117947, "compression_ratio": 1.6506550218340612, "no_speech_prob": 2.2252299913816387e-06}, {"id": 1649, "seek": 662148, "start": 6646.16, "end": 6649.679999999999, "text": " actually has a different space?", "tokens": [50364, 31677, 11420, 13, 50432, 50432, 407, 411, 3026, 75, 293, 257, 3840, 295, 613, 293, 257, 31677, 13344, 10336, 337, 1203, 13, 50670, 50670, 2561, 257, 688, 13, 50770, 50770, 1119, 3451, 11, 286, 632, 257, 1168, 466, 341, 10200, 12, 3711, 2539, 13, 51066, 51066, 407, 437, 360, 291, 519, 307, 264, 1785, 295, 411, 1337, 1166, 7150, 30, 51280, 51280, 400, 630, 291, 519, 466, 21928, 411, 8712, 488, 7150, 365, 1337, 1166, 7150, 411, 38163, 51598, 51598, 767, 575, 257, 819, 1901, 30, 51774, 51774], "temperature": 0.0, "avg_logprob": -0.3001238293117947, "compression_ratio": 1.6506550218340612, "no_speech_prob": 2.2252299913816387e-06}, {"id": 1650, "seek": 664968, "start": 6649.68, "end": 6653.64, "text": " So they have like a linear layer on top of the feature representation where they compute", "tokens": [50364, 407, 436, 362, 411, 257, 8213, 4583, 322, 1192, 295, 264, 4111, 10290, 689, 436, 14722, 50562, 50562, 264, 3539, 4111, 10290, 689, 436, 630, 264, 8712, 488, 4470, 11, 264, 426, 4969, 1507, 13, 50874, 50874, 407, 411, 11, 360, 291, 519, 411, 1419, 1071, 1378, 411, 300, 1936, 2212, 411, 257, 9086, 51162, 51162, 295, 3256, 11, 291, 445, 853, 281, 4373, 484, 300, 9086, 295, 3256, 293, 291, 362, 300, 1589, 570, 51485, 51485, 291, 9086, 300, 3256, 11, 558, 30, 51594, 51594, 400, 764, 264, 460, 1770, 420, 746, 13, 51768, 51768], "temperature": 0.0, "avg_logprob": -0.2033008069408183, "compression_ratio": 1.774891774891775, "no_speech_prob": 2.026056108661578e-06}, {"id": 1651, "seek": 664968, "start": 6653.64, "end": 6659.88, "text": " the actual feature representation where they did the contrastive loss, the NCE stuff.", "tokens": [50364, 407, 436, 362, 411, 257, 8213, 4583, 322, 1192, 295, 264, 4111, 10290, 689, 436, 14722, 50562, 50562, 264, 3539, 4111, 10290, 689, 436, 630, 264, 8712, 488, 4470, 11, 264, 426, 4969, 1507, 13, 50874, 50874, 407, 411, 11, 360, 291, 519, 411, 1419, 1071, 1378, 411, 300, 1936, 2212, 411, 257, 9086, 51162, 51162, 295, 3256, 11, 291, 445, 853, 281, 4373, 484, 300, 9086, 295, 3256, 293, 291, 362, 300, 1589, 570, 51485, 51485, 291, 9086, 300, 3256, 11, 558, 30, 51594, 51594, 400, 764, 264, 460, 1770, 420, 746, 13, 51768, 51768], "temperature": 0.0, "avg_logprob": -0.2033008069408183, "compression_ratio": 1.774891774891775, "no_speech_prob": 2.026056108661578e-06}, {"id": 1652, "seek": 664968, "start": 6659.88, "end": 6665.64, "text": " So like, do you think like having another head like that basically given like a crop", "tokens": [50364, 407, 436, 362, 411, 257, 8213, 4583, 322, 1192, 295, 264, 4111, 10290, 689, 436, 14722, 50562, 50562, 264, 3539, 4111, 10290, 689, 436, 630, 264, 8712, 488, 4470, 11, 264, 426, 4969, 1507, 13, 50874, 50874, 407, 411, 11, 360, 291, 519, 411, 1419, 1071, 1378, 411, 300, 1936, 2212, 411, 257, 9086, 51162, 51162, 295, 3256, 11, 291, 445, 853, 281, 4373, 484, 300, 9086, 295, 3256, 293, 291, 362, 300, 1589, 570, 51485, 51485, 291, 9086, 300, 3256, 11, 558, 30, 51594, 51594, 400, 764, 264, 460, 1770, 420, 746, 13, 51768, 51768], "temperature": 0.0, "avg_logprob": -0.2033008069408183, "compression_ratio": 1.774891774891775, "no_speech_prob": 2.026056108661578e-06}, {"id": 1653, "seek": 664968, "start": 6665.64, "end": 6672.1, "text": " of image, you just try to scale out that crop of image and you have that information because", "tokens": [50364, 407, 436, 362, 411, 257, 8213, 4583, 322, 1192, 295, 264, 4111, 10290, 689, 436, 14722, 50562, 50562, 264, 3539, 4111, 10290, 689, 436, 630, 264, 8712, 488, 4470, 11, 264, 426, 4969, 1507, 13, 50874, 50874, 407, 411, 11, 360, 291, 519, 411, 1419, 1071, 1378, 411, 300, 1936, 2212, 411, 257, 9086, 51162, 51162, 295, 3256, 11, 291, 445, 853, 281, 4373, 484, 300, 9086, 295, 3256, 293, 291, 362, 300, 1589, 570, 51485, 51485, 291, 9086, 300, 3256, 11, 558, 30, 51594, 51594, 400, 764, 264, 460, 1770, 420, 746, 13, 51768, 51768], "temperature": 0.0, "avg_logprob": -0.2033008069408183, "compression_ratio": 1.774891774891775, "no_speech_prob": 2.026056108661578e-06}, {"id": 1654, "seek": 664968, "start": 6672.1, "end": 6674.280000000001, "text": " you crop that image, right?", "tokens": [50364, 407, 436, 362, 411, 257, 8213, 4583, 322, 1192, 295, 264, 4111, 10290, 689, 436, 14722, 50562, 50562, 264, 3539, 4111, 10290, 689, 436, 630, 264, 8712, 488, 4470, 11, 264, 426, 4969, 1507, 13, 50874, 50874, 407, 411, 11, 360, 291, 519, 411, 1419, 1071, 1378, 411, 300, 1936, 2212, 411, 257, 9086, 51162, 51162, 295, 3256, 11, 291, 445, 853, 281, 4373, 484, 300, 9086, 295, 3256, 293, 291, 362, 300, 1589, 570, 51485, 51485, 291, 9086, 300, 3256, 11, 558, 30, 51594, 51594, 400, 764, 264, 460, 1770, 420, 746, 13, 51768, 51768], "temperature": 0.0, "avg_logprob": -0.2033008069408183, "compression_ratio": 1.774891774891775, "no_speech_prob": 2.026056108661578e-06}, {"id": 1655, "seek": 664968, "start": 6674.280000000001, "end": 6677.76, "text": " And use the GAN or something.", "tokens": [50364, 407, 436, 362, 411, 257, 8213, 4583, 322, 1192, 295, 264, 4111, 10290, 689, 436, 14722, 50562, 50562, 264, 3539, 4111, 10290, 689, 436, 630, 264, 8712, 488, 4470, 11, 264, 426, 4969, 1507, 13, 50874, 50874, 407, 411, 11, 360, 291, 519, 411, 1419, 1071, 1378, 411, 300, 1936, 2212, 411, 257, 9086, 51162, 51162, 295, 3256, 11, 291, 445, 853, 281, 4373, 484, 300, 9086, 295, 3256, 293, 291, 362, 300, 1589, 570, 51485, 51485, 291, 9086, 300, 3256, 11, 558, 30, 51594, 51594, 400, 764, 264, 460, 1770, 420, 746, 13, 51768, 51768], "temperature": 0.0, "avg_logprob": -0.2033008069408183, "compression_ratio": 1.774891774891775, "no_speech_prob": 2.026056108661578e-06}, {"id": 1656, "seek": 667776, "start": 6677.76, "end": 6681.96, "text": " So I mean, it is definitely a good idea.", "tokens": [50364, 407, 286, 914, 11, 309, 307, 2138, 257, 665, 1558, 13, 50574, 50574, 286, 519, 309, 311, 445, 264, 12414, 644, 307, 1242, 613, 721, 281, 3847, 382, 445, 2107, 12, 83, 470, 22640, 13, 50840, 50840, 407, 9105, 11, 411, 286, 2378, 380, 534, 3031, 604, 1337, 1166, 11587, 13, 51043, 51043, 682, 452, 1752, 11, 300, 311, 4748, 544, 962, 20539, 293, 6081, 281, 483, 281, 589, 13, 51266, 51266, 583, 286, 360, 3986, 13, 51316, 51316, 286, 519, 1333, 295, 294, 264, 2854, 1433, 11, 436, 366, 411, 11, 436, 366, 1333, 295, 264, 721, 281, 1879, 51520, 51520, 322, 13, 51670, 51670, 1044, 291, 13, 51720, 51720], "temperature": 0.0, "avg_logprob": -0.1804446161320779, "compression_ratio": 1.6317991631799162, "no_speech_prob": 6.8532776822394226e-06}, {"id": 1657, "seek": 667776, "start": 6681.96, "end": 6687.280000000001, "text": " I think it's just the tricky part is getting these things to train as just non-trivial.", "tokens": [50364, 407, 286, 914, 11, 309, 307, 2138, 257, 665, 1558, 13, 50574, 50574, 286, 519, 309, 311, 445, 264, 12414, 644, 307, 1242, 613, 721, 281, 3847, 382, 445, 2107, 12, 83, 470, 22640, 13, 50840, 50840, 407, 9105, 11, 411, 286, 2378, 380, 534, 3031, 604, 1337, 1166, 11587, 13, 51043, 51043, 682, 452, 1752, 11, 300, 311, 4748, 544, 962, 20539, 293, 6081, 281, 483, 281, 589, 13, 51266, 51266, 583, 286, 360, 3986, 13, 51316, 51316, 286, 519, 1333, 295, 294, 264, 2854, 1433, 11, 436, 366, 411, 11, 436, 366, 1333, 295, 264, 721, 281, 1879, 51520, 51520, 322, 13, 51670, 51670, 1044, 291, 13, 51720, 51720], "temperature": 0.0, "avg_logprob": -0.1804446161320779, "compression_ratio": 1.6317991631799162, "no_speech_prob": 6.8532776822394226e-06}, {"id": 1658, "seek": 667776, "start": 6687.280000000001, "end": 6691.34, "text": " So initially, like I haven't really tried any generative approaches.", "tokens": [50364, 407, 286, 914, 11, 309, 307, 2138, 257, 665, 1558, 13, 50574, 50574, 286, 519, 309, 311, 445, 264, 12414, 644, 307, 1242, 613, 721, 281, 3847, 382, 445, 2107, 12, 83, 470, 22640, 13, 50840, 50840, 407, 9105, 11, 411, 286, 2378, 380, 534, 3031, 604, 1337, 1166, 11587, 13, 51043, 51043, 682, 452, 1752, 11, 300, 311, 4748, 544, 962, 20539, 293, 6081, 281, 483, 281, 589, 13, 51266, 51266, 583, 286, 360, 3986, 13, 51316, 51316, 286, 519, 1333, 295, 294, 264, 2854, 1433, 11, 436, 366, 411, 11, 436, 366, 1333, 295, 264, 721, 281, 1879, 51520, 51520, 322, 13, 51670, 51670, 1044, 291, 13, 51720, 51720], "temperature": 0.0, "avg_logprob": -0.1804446161320779, "compression_ratio": 1.6317991631799162, "no_speech_prob": 6.8532776822394226e-06}, {"id": 1659, "seek": 667776, "start": 6691.34, "end": 6695.8, "text": " In my experience, that's slightly more finicky and harder to get to work.", "tokens": [50364, 407, 286, 914, 11, 309, 307, 2138, 257, 665, 1558, 13, 50574, 50574, 286, 519, 309, 311, 445, 264, 12414, 644, 307, 1242, 613, 721, 281, 3847, 382, 445, 2107, 12, 83, 470, 22640, 13, 50840, 50840, 407, 9105, 11, 411, 286, 2378, 380, 534, 3031, 604, 1337, 1166, 11587, 13, 51043, 51043, 682, 452, 1752, 11, 300, 311, 4748, 544, 962, 20539, 293, 6081, 281, 483, 281, 589, 13, 51266, 51266, 583, 286, 360, 3986, 13, 51316, 51316, 286, 519, 1333, 295, 294, 264, 2854, 1433, 11, 436, 366, 411, 11, 436, 366, 1333, 295, 264, 721, 281, 1879, 51520, 51520, 322, 13, 51670, 51670, 1044, 291, 13, 51720, 51720], "temperature": 0.0, "avg_logprob": -0.1804446161320779, "compression_ratio": 1.6317991631799162, "no_speech_prob": 6.8532776822394226e-06}, {"id": 1660, "seek": 667776, "start": 6695.8, "end": 6696.8, "text": " But I do agree.", "tokens": [50364, 407, 286, 914, 11, 309, 307, 2138, 257, 665, 1558, 13, 50574, 50574, 286, 519, 309, 311, 445, 264, 12414, 644, 307, 1242, 613, 721, 281, 3847, 382, 445, 2107, 12, 83, 470, 22640, 13, 50840, 50840, 407, 9105, 11, 411, 286, 2378, 380, 534, 3031, 604, 1337, 1166, 11587, 13, 51043, 51043, 682, 452, 1752, 11, 300, 311, 4748, 544, 962, 20539, 293, 6081, 281, 483, 281, 589, 13, 51266, 51266, 583, 286, 360, 3986, 13, 51316, 51316, 286, 519, 1333, 295, 294, 264, 2854, 1433, 11, 436, 366, 411, 11, 436, 366, 1333, 295, 264, 721, 281, 1879, 51520, 51520, 322, 13, 51670, 51670, 1044, 291, 13, 51720, 51720], "temperature": 0.0, "avg_logprob": -0.1804446161320779, "compression_ratio": 1.6317991631799162, "no_speech_prob": 6.8532776822394226e-06}, {"id": 1661, "seek": 667776, "start": 6696.8, "end": 6700.88, "text": " I think sort of in the longer term, they are like, they are sort of the things to focus", "tokens": [50364, 407, 286, 914, 11, 309, 307, 2138, 257, 665, 1558, 13, 50574, 50574, 286, 519, 309, 311, 445, 264, 12414, 644, 307, 1242, 613, 721, 281, 3847, 382, 445, 2107, 12, 83, 470, 22640, 13, 50840, 50840, 407, 9105, 11, 411, 286, 2378, 380, 534, 3031, 604, 1337, 1166, 11587, 13, 51043, 51043, 682, 452, 1752, 11, 300, 311, 4748, 544, 962, 20539, 293, 6081, 281, 483, 281, 589, 13, 51266, 51266, 583, 286, 360, 3986, 13, 51316, 51316, 286, 519, 1333, 295, 294, 264, 2854, 1433, 11, 436, 366, 411, 11, 436, 366, 1333, 295, 264, 721, 281, 1879, 51520, 51520, 322, 13, 51670, 51670, 1044, 291, 13, 51720, 51720], "temperature": 0.0, "avg_logprob": -0.1804446161320779, "compression_ratio": 1.6317991631799162, "no_speech_prob": 6.8532776822394226e-06}, {"id": 1662, "seek": 667776, "start": 6700.88, "end": 6703.88, "text": " on.", "tokens": [50364, 407, 286, 914, 11, 309, 307, 2138, 257, 665, 1558, 13, 50574, 50574, 286, 519, 309, 311, 445, 264, 12414, 644, 307, 1242, 613, 721, 281, 3847, 382, 445, 2107, 12, 83, 470, 22640, 13, 50840, 50840, 407, 9105, 11, 411, 286, 2378, 380, 534, 3031, 604, 1337, 1166, 11587, 13, 51043, 51043, 682, 452, 1752, 11, 300, 311, 4748, 544, 962, 20539, 293, 6081, 281, 483, 281, 589, 13, 51266, 51266, 583, 286, 360, 3986, 13, 51316, 51316, 286, 519, 1333, 295, 294, 264, 2854, 1433, 11, 436, 366, 411, 11, 436, 366, 1333, 295, 264, 721, 281, 1879, 51520, 51520, 322, 13, 51670, 51670, 1044, 291, 13, 51720, 51720], "temperature": 0.0, "avg_logprob": -0.1804446161320779, "compression_ratio": 1.6317991631799162, "no_speech_prob": 6.8532776822394226e-06}, {"id": 1663, "seek": 667776, "start": 6703.88, "end": 6704.88, "text": " Thank you.", "tokens": [50364, 407, 286, 914, 11, 309, 307, 2138, 257, 665, 1558, 13, 50574, 50574, 286, 519, 309, 311, 445, 264, 12414, 644, 307, 1242, 613, 721, 281, 3847, 382, 445, 2107, 12, 83, 470, 22640, 13, 50840, 50840, 407, 9105, 11, 411, 286, 2378, 380, 534, 3031, 604, 1337, 1166, 11587, 13, 51043, 51043, 682, 452, 1752, 11, 300, 311, 4748, 544, 962, 20539, 293, 6081, 281, 483, 281, 589, 13, 51266, 51266, 583, 286, 360, 3986, 13, 51316, 51316, 286, 519, 1333, 295, 294, 264, 2854, 1433, 11, 436, 366, 411, 11, 436, 366, 1333, 295, 264, 721, 281, 1879, 51520, 51520, 322, 13, 51670, 51670, 1044, 291, 13, 51720, 51720], "temperature": 0.0, "avg_logprob": -0.1804446161320779, "compression_ratio": 1.6317991631799162, "no_speech_prob": 6.8532776822394226e-06}, {"id": 1664, "seek": 670488, "start": 6704.88, "end": 6708.08, "text": " Last question.", "tokens": [50364, 5264, 1168, 13, 50524, 50524, 883, 11, 300, 311, 309, 13, 50782, 50782, 286, 2041, 13, 50832, 50832, 876, 11, 286, 393, 767, 1029, 257, 1168, 13, 51064, 51064, 407, 341, 307, 8595, 42923, 399, 767, 13, 51166, 51166, 407, 291, 645, 3585, 385, 577, 32884, 23119, 37870, 2709, 257, 29021, 3779, 11, 558, 30, 51530, 51530, 407, 393, 291, 20945, 322, 300, 30, 51650, 51650, 1436, 309, 1333, 295, 8637, 264, 15697, 295, 527, 2316, 11, 558, 30, 51800, 51800], "temperature": 0.0, "avg_logprob": -0.26976095911968184, "compression_ratio": 1.51, "no_speech_prob": 3.758497041417286e-05}, {"id": 1665, "seek": 670488, "start": 6708.08, "end": 6713.24, "text": " No, that's it.", "tokens": [50364, 5264, 1168, 13, 50524, 50524, 883, 11, 300, 311, 309, 13, 50782, 50782, 286, 2041, 13, 50832, 50832, 876, 11, 286, 393, 767, 1029, 257, 1168, 13, 51064, 51064, 407, 341, 307, 8595, 42923, 399, 767, 13, 51166, 51166, 407, 291, 645, 3585, 385, 577, 32884, 23119, 37870, 2709, 257, 29021, 3779, 11, 558, 30, 51530, 51530, 407, 393, 291, 20945, 322, 300, 30, 51650, 51650, 1436, 309, 1333, 295, 8637, 264, 15697, 295, 527, 2316, 11, 558, 30, 51800, 51800], "temperature": 0.0, "avg_logprob": -0.26976095911968184, "compression_ratio": 1.51, "no_speech_prob": 3.758497041417286e-05}, {"id": 1666, "seek": 670488, "start": 6713.24, "end": 6714.24, "text": " I guess.", "tokens": [50364, 5264, 1168, 13, 50524, 50524, 883, 11, 300, 311, 309, 13, 50782, 50782, 286, 2041, 13, 50832, 50832, 876, 11, 286, 393, 767, 1029, 257, 1168, 13, 51064, 51064, 407, 341, 307, 8595, 42923, 399, 767, 13, 51166, 51166, 407, 291, 645, 3585, 385, 577, 32884, 23119, 37870, 2709, 257, 29021, 3779, 11, 558, 30, 51530, 51530, 407, 393, 291, 20945, 322, 300, 30, 51650, 51650, 1436, 309, 1333, 295, 8637, 264, 15697, 295, 527, 2316, 11, 558, 30, 51800, 51800], "temperature": 0.0, "avg_logprob": -0.26976095911968184, "compression_ratio": 1.51, "no_speech_prob": 3.758497041417286e-05}, {"id": 1667, "seek": 670488, "start": 6714.24, "end": 6718.88, "text": " Oh, I can actually ask a question.", "tokens": [50364, 5264, 1168, 13, 50524, 50524, 883, 11, 300, 311, 309, 13, 50782, 50782, 286, 2041, 13, 50832, 50832, 876, 11, 286, 393, 767, 1029, 257, 1168, 13, 51064, 51064, 407, 341, 307, 8595, 42923, 399, 767, 13, 51166, 51166, 407, 291, 645, 3585, 385, 577, 32884, 23119, 37870, 2709, 257, 29021, 3779, 11, 558, 30, 51530, 51530, 407, 393, 291, 20945, 322, 300, 30, 51650, 51650, 1436, 309, 1333, 295, 8637, 264, 15697, 295, 527, 2316, 11, 558, 30, 51800, 51800], "temperature": 0.0, "avg_logprob": -0.26976095911968184, "compression_ratio": 1.51, "no_speech_prob": 3.758497041417286e-05}, {"id": 1668, "seek": 670488, "start": 6718.88, "end": 6720.92, "text": " So this is regarding distillation actually.", "tokens": [50364, 5264, 1168, 13, 50524, 50524, 883, 11, 300, 311, 309, 13, 50782, 50782, 286, 2041, 13, 50832, 50832, 876, 11, 286, 393, 767, 1029, 257, 1168, 13, 51064, 51064, 407, 341, 307, 8595, 42923, 399, 767, 13, 51166, 51166, 407, 291, 645, 3585, 385, 577, 32884, 23119, 37870, 2709, 257, 29021, 3779, 11, 558, 30, 51530, 51530, 407, 393, 291, 20945, 322, 300, 30, 51650, 51650, 1436, 309, 1333, 295, 8637, 264, 15697, 295, 527, 2316, 11, 558, 30, 51800, 51800], "temperature": 0.0, "avg_logprob": -0.26976095911968184, "compression_ratio": 1.51, "no_speech_prob": 3.758497041417286e-05}, {"id": 1669, "seek": 670488, "start": 6720.92, "end": 6728.2, "text": " So you were telling me how predicting softer distributions gives a richer target, right?", "tokens": [50364, 5264, 1168, 13, 50524, 50524, 883, 11, 300, 311, 309, 13, 50782, 50782, 286, 2041, 13, 50832, 50832, 876, 11, 286, 393, 767, 1029, 257, 1168, 13, 51064, 51064, 407, 341, 307, 8595, 42923, 399, 767, 13, 51166, 51166, 407, 291, 645, 3585, 385, 577, 32884, 23119, 37870, 2709, 257, 29021, 3779, 11, 558, 30, 51530, 51530, 407, 393, 291, 20945, 322, 300, 30, 51650, 51650, 1436, 309, 1333, 295, 8637, 264, 15697, 295, 527, 2316, 11, 558, 30, 51800, 51800], "temperature": 0.0, "avg_logprob": -0.26976095911968184, "compression_ratio": 1.51, "no_speech_prob": 3.758497041417286e-05}, {"id": 1670, "seek": 670488, "start": 6728.2, "end": 6730.6, "text": " So can you elaborate on that?", "tokens": [50364, 5264, 1168, 13, 50524, 50524, 883, 11, 300, 311, 309, 13, 50782, 50782, 286, 2041, 13, 50832, 50832, 876, 11, 286, 393, 767, 1029, 257, 1168, 13, 51064, 51064, 407, 341, 307, 8595, 42923, 399, 767, 13, 51166, 51166, 407, 291, 645, 3585, 385, 577, 32884, 23119, 37870, 2709, 257, 29021, 3779, 11, 558, 30, 51530, 51530, 407, 393, 291, 20945, 322, 300, 30, 51650, 51650, 1436, 309, 1333, 295, 8637, 264, 15697, 295, 527, 2316, 11, 558, 30, 51800, 51800], "temperature": 0.0, "avg_logprob": -0.26976095911968184, "compression_ratio": 1.51, "no_speech_prob": 3.758497041417286e-05}, {"id": 1671, "seek": 670488, "start": 6730.6, "end": 6733.6, "text": " Because it sort of increases the uncertainty of our model, right?", "tokens": [50364, 5264, 1168, 13, 50524, 50524, 883, 11, 300, 311, 309, 13, 50782, 50782, 286, 2041, 13, 50832, 50832, 876, 11, 286, 393, 767, 1029, 257, 1168, 13, 51064, 51064, 407, 341, 307, 8595, 42923, 399, 767, 13, 51166, 51166, 407, 291, 645, 3585, 385, 577, 32884, 23119, 37870, 2709, 257, 29021, 3779, 11, 558, 30, 51530, 51530, 407, 393, 291, 20945, 322, 300, 30, 51650, 51650, 1436, 309, 1333, 295, 8637, 264, 15697, 295, 527, 2316, 11, 558, 30, 51800, 51800], "temperature": 0.0, "avg_logprob": -0.26976095911968184, "compression_ratio": 1.51, "no_speech_prob": 3.758497041417286e-05}, {"id": 1672, "seek": 673360, "start": 6733.6, "end": 6738.200000000001, "text": " We are predicting from a one-hot distribution and then making it softer and then we're predicting", "tokens": [50364, 492, 366, 32884, 490, 257, 472, 12, 12194, 7316, 293, 550, 1455, 309, 23119, 293, 550, 321, 434, 32884, 50594, 50594, 322, 300, 13, 50644, 50644, 407, 544, 15697, 13, 50694, 50694, 400, 544, 3570, 11, 411, 11, 983, 360, 436, 818, 309, 42923, 399, 30, 50808, 50808, 1436, 286, 1333, 295, 841, 411, 291, 643, 544, 9834, 281, 2696, 337, 341, 29021, 3779, 13, 51084, 51084, 1779, 13, 51188, 51188, 407, 264, 472, 551, 307, 1936, 498, 291, 3847, 322, 472, 12, 12194, 16949, 11, 428, 5245, 3928, 281, 312, 51504, 51504, 588, 670, 24697, 1078, 294, 2674, 13, 51586, 51586, 407, 498, 291, 362, 2198, 295, 613, 11733, 1219, 7645, 899, 6259, 571, 11, 597, 307, 1333, 295, 586, 885, 51858, 51858], "temperature": 0.0, "avg_logprob": -0.18471393887958829, "compression_ratio": 1.6842105263157894, "no_speech_prob": 3.071213359362446e-05}, {"id": 1673, "seek": 673360, "start": 6738.200000000001, "end": 6739.200000000001, "text": " on that.", "tokens": [50364, 492, 366, 32884, 490, 257, 472, 12, 12194, 7316, 293, 550, 1455, 309, 23119, 293, 550, 321, 434, 32884, 50594, 50594, 322, 300, 13, 50644, 50644, 407, 544, 15697, 13, 50694, 50694, 400, 544, 3570, 11, 411, 11, 983, 360, 436, 818, 309, 42923, 399, 30, 50808, 50808, 1436, 286, 1333, 295, 841, 411, 291, 643, 544, 9834, 281, 2696, 337, 341, 29021, 3779, 13, 51084, 51084, 1779, 13, 51188, 51188, 407, 264, 472, 551, 307, 1936, 498, 291, 3847, 322, 472, 12, 12194, 16949, 11, 428, 5245, 3928, 281, 312, 51504, 51504, 588, 670, 24697, 1078, 294, 2674, 13, 51586, 51586, 407, 498, 291, 362, 2198, 295, 613, 11733, 1219, 7645, 899, 6259, 571, 11, 597, 307, 1333, 295, 586, 885, 51858, 51858], "temperature": 0.0, "avg_logprob": -0.18471393887958829, "compression_ratio": 1.6842105263157894, "no_speech_prob": 3.071213359362446e-05}, {"id": 1674, "seek": 673360, "start": 6739.200000000001, "end": 6740.200000000001, "text": " So more uncertainty.", "tokens": [50364, 492, 366, 32884, 490, 257, 472, 12, 12194, 7316, 293, 550, 1455, 309, 23119, 293, 550, 321, 434, 32884, 50594, 50594, 322, 300, 13, 50644, 50644, 407, 544, 15697, 13, 50694, 50694, 400, 544, 3570, 11, 411, 11, 983, 360, 436, 818, 309, 42923, 399, 30, 50808, 50808, 1436, 286, 1333, 295, 841, 411, 291, 643, 544, 9834, 281, 2696, 337, 341, 29021, 3779, 13, 51084, 51084, 1779, 13, 51188, 51188, 407, 264, 472, 551, 307, 1936, 498, 291, 3847, 322, 472, 12, 12194, 16949, 11, 428, 5245, 3928, 281, 312, 51504, 51504, 588, 670, 24697, 1078, 294, 2674, 13, 51586, 51586, 407, 498, 291, 362, 2198, 295, 613, 11733, 1219, 7645, 899, 6259, 571, 11, 597, 307, 1333, 295, 586, 885, 51858, 51858], "temperature": 0.0, "avg_logprob": -0.18471393887958829, "compression_ratio": 1.6842105263157894, "no_speech_prob": 3.071213359362446e-05}, {"id": 1675, "seek": 673360, "start": 6740.200000000001, "end": 6742.4800000000005, "text": " And moreover, like, why do they call it distillation?", "tokens": [50364, 492, 366, 32884, 490, 257, 472, 12, 12194, 7316, 293, 550, 1455, 309, 23119, 293, 550, 321, 434, 32884, 50594, 50594, 322, 300, 13, 50644, 50644, 407, 544, 15697, 13, 50694, 50694, 400, 544, 3570, 11, 411, 11, 983, 360, 436, 818, 309, 42923, 399, 30, 50808, 50808, 1436, 286, 1333, 295, 841, 411, 291, 643, 544, 9834, 281, 2696, 337, 341, 29021, 3779, 13, 51084, 51084, 1779, 13, 51188, 51188, 407, 264, 472, 551, 307, 1936, 498, 291, 3847, 322, 472, 12, 12194, 16949, 11, 428, 5245, 3928, 281, 312, 51504, 51504, 588, 670, 24697, 1078, 294, 2674, 13, 51586, 51586, 407, 498, 291, 362, 2198, 295, 613, 11733, 1219, 7645, 899, 6259, 571, 11, 597, 307, 1333, 295, 586, 885, 51858, 51858], "temperature": 0.0, "avg_logprob": -0.18471393887958829, "compression_ratio": 1.6842105263157894, "no_speech_prob": 3.071213359362446e-05}, {"id": 1676, "seek": 673360, "start": 6742.4800000000005, "end": 6748.0, "text": " Because I sort of feel like you need more parameters to account for this richer target.", "tokens": [50364, 492, 366, 32884, 490, 257, 472, 12, 12194, 7316, 293, 550, 1455, 309, 23119, 293, 550, 321, 434, 32884, 50594, 50594, 322, 300, 13, 50644, 50644, 407, 544, 15697, 13, 50694, 50694, 400, 544, 3570, 11, 411, 11, 983, 360, 436, 818, 309, 42923, 399, 30, 50808, 50808, 1436, 286, 1333, 295, 841, 411, 291, 643, 544, 9834, 281, 2696, 337, 341, 29021, 3779, 13, 51084, 51084, 1779, 13, 51188, 51188, 407, 264, 472, 551, 307, 1936, 498, 291, 3847, 322, 472, 12, 12194, 16949, 11, 428, 5245, 3928, 281, 312, 51504, 51504, 588, 670, 24697, 1078, 294, 2674, 13, 51586, 51586, 407, 498, 291, 362, 2198, 295, 613, 11733, 1219, 7645, 899, 6259, 571, 11, 597, 307, 1333, 295, 586, 885, 51858, 51858], "temperature": 0.0, "avg_logprob": -0.18471393887958829, "compression_ratio": 1.6842105263157894, "no_speech_prob": 3.071213359362446e-05}, {"id": 1677, "seek": 673360, "start": 6748.0, "end": 6750.08, "text": " Right.", "tokens": [50364, 492, 366, 32884, 490, 257, 472, 12, 12194, 7316, 293, 550, 1455, 309, 23119, 293, 550, 321, 434, 32884, 50594, 50594, 322, 300, 13, 50644, 50644, 407, 544, 15697, 13, 50694, 50694, 400, 544, 3570, 11, 411, 11, 983, 360, 436, 818, 309, 42923, 399, 30, 50808, 50808, 1436, 286, 1333, 295, 841, 411, 291, 643, 544, 9834, 281, 2696, 337, 341, 29021, 3779, 13, 51084, 51084, 1779, 13, 51188, 51188, 407, 264, 472, 551, 307, 1936, 498, 291, 3847, 322, 472, 12, 12194, 16949, 11, 428, 5245, 3928, 281, 312, 51504, 51504, 588, 670, 24697, 1078, 294, 2674, 13, 51586, 51586, 407, 498, 291, 362, 2198, 295, 613, 11733, 1219, 7645, 899, 6259, 571, 11, 597, 307, 1333, 295, 586, 885, 51858, 51858], "temperature": 0.0, "avg_logprob": -0.18471393887958829, "compression_ratio": 1.6842105263157894, "no_speech_prob": 3.071213359362446e-05}, {"id": 1678, "seek": 673360, "start": 6750.08, "end": 6756.400000000001, "text": " So the one thing is basically if you train on one-hot labels, your models tend to be", "tokens": [50364, 492, 366, 32884, 490, 257, 472, 12, 12194, 7316, 293, 550, 1455, 309, 23119, 293, 550, 321, 434, 32884, 50594, 50594, 322, 300, 13, 50644, 50644, 407, 544, 15697, 13, 50694, 50694, 400, 544, 3570, 11, 411, 11, 983, 360, 436, 818, 309, 42923, 399, 30, 50808, 50808, 1436, 286, 1333, 295, 841, 411, 291, 643, 544, 9834, 281, 2696, 337, 341, 29021, 3779, 13, 51084, 51084, 1779, 13, 51188, 51188, 407, 264, 472, 551, 307, 1936, 498, 291, 3847, 322, 472, 12, 12194, 16949, 11, 428, 5245, 3928, 281, 312, 51504, 51504, 588, 670, 24697, 1078, 294, 2674, 13, 51586, 51586, 407, 498, 291, 362, 2198, 295, 613, 11733, 1219, 7645, 899, 6259, 571, 11, 597, 307, 1333, 295, 586, 885, 51858, 51858], "temperature": 0.0, "avg_logprob": -0.18471393887958829, "compression_ratio": 1.6842105263157894, "no_speech_prob": 3.071213359362446e-05}, {"id": 1679, "seek": 673360, "start": 6756.400000000001, "end": 6758.04, "text": " very overconfident in general.", "tokens": [50364, 492, 366, 32884, 490, 257, 472, 12, 12194, 7316, 293, 550, 1455, 309, 23119, 293, 550, 321, 434, 32884, 50594, 50594, 322, 300, 13, 50644, 50644, 407, 544, 15697, 13, 50694, 50694, 400, 544, 3570, 11, 411, 11, 983, 360, 436, 818, 309, 42923, 399, 30, 50808, 50808, 1436, 286, 1333, 295, 841, 411, 291, 643, 544, 9834, 281, 2696, 337, 341, 29021, 3779, 13, 51084, 51084, 1779, 13, 51188, 51188, 407, 264, 472, 551, 307, 1936, 498, 291, 3847, 322, 472, 12, 12194, 16949, 11, 428, 5245, 3928, 281, 312, 51504, 51504, 588, 670, 24697, 1078, 294, 2674, 13, 51586, 51586, 407, 498, 291, 362, 2198, 295, 613, 11733, 1219, 7645, 899, 6259, 571, 11, 597, 307, 1333, 295, 586, 885, 51858, 51858], "temperature": 0.0, "avg_logprob": -0.18471393887958829, "compression_ratio": 1.6842105263157894, "no_speech_prob": 3.071213359362446e-05}, {"id": 1680, "seek": 673360, "start": 6758.04, "end": 6763.4800000000005, "text": " So if you have heard of these tricks called label smoothing, which is sort of now being", "tokens": [50364, 492, 366, 32884, 490, 257, 472, 12, 12194, 7316, 293, 550, 1455, 309, 23119, 293, 550, 321, 434, 32884, 50594, 50594, 322, 300, 13, 50644, 50644, 407, 544, 15697, 13, 50694, 50694, 400, 544, 3570, 11, 411, 11, 983, 360, 436, 818, 309, 42923, 399, 30, 50808, 50808, 1436, 286, 1333, 295, 841, 411, 291, 643, 544, 9834, 281, 2696, 337, 341, 29021, 3779, 13, 51084, 51084, 1779, 13, 51188, 51188, 407, 264, 472, 551, 307, 1936, 498, 291, 3847, 322, 472, 12, 12194, 16949, 11, 428, 5245, 3928, 281, 312, 51504, 51504, 588, 670, 24697, 1078, 294, 2674, 13, 51586, 51586, 407, 498, 291, 362, 2198, 295, 613, 11733, 1219, 7645, 899, 6259, 571, 11, 597, 307, 1333, 295, 586, 885, 51858, 51858], "temperature": 0.0, "avg_logprob": -0.18471393887958829, "compression_ratio": 1.6842105263157894, "no_speech_prob": 3.071213359362446e-05}, {"id": 1681, "seek": 676348, "start": 6763.48, "end": 6768.639999999999, "text": " used by a bunch of methods, label smoothing is like, you can think of it like the sort", "tokens": [50364, 1143, 538, 257, 3840, 295, 7150, 11, 7645, 899, 6259, 571, 307, 411, 11, 291, 393, 519, 295, 309, 411, 264, 1333, 50622, 50622, 295, 22811, 3037, 295, 42923, 399, 13, 50714, 50714, 407, 291, 362, 257, 472, 12, 12194, 8062, 300, 291, 645, 1382, 281, 6069, 11, 457, 2831, 813, 1382, 50886, 50886, 281, 6069, 364, 2302, 472, 12, 12194, 8062, 11, 437, 291, 360, 307, 291, 747, 512, 8482, 2758, 484, 51062, 51062, 295, 300, 13, 51112, 51112, 407, 291, 486, 6069, 472, 293, 257, 3840, 295, 35193, 13, 51250, 51250, 407, 661, 813, 884, 300, 11, 291, 6069, 584, 1958, 13, 23247, 293, 291, 909, 1958, 13, 16, 11, 1958, 13, 16, 11, 1958, 13, 16, 11, 1958, 13, 17, 13, 51528, 51528, 286, 411, 264, 29837, 1045, 16949, 281, 445, 909, 257, 9452, 7316, 281, 264, 29837, 13, 51746, 51746], "temperature": 0.0, "avg_logprob": -0.17853412889454462, "compression_ratio": 1.8763636363636365, "no_speech_prob": 0.00010228054452454671}, {"id": 1682, "seek": 676348, "start": 6768.639999999999, "end": 6770.48, "text": " of simplest version of distillation.", "tokens": [50364, 1143, 538, 257, 3840, 295, 7150, 11, 7645, 899, 6259, 571, 307, 411, 11, 291, 393, 519, 295, 309, 411, 264, 1333, 50622, 50622, 295, 22811, 3037, 295, 42923, 399, 13, 50714, 50714, 407, 291, 362, 257, 472, 12, 12194, 8062, 300, 291, 645, 1382, 281, 6069, 11, 457, 2831, 813, 1382, 50886, 50886, 281, 6069, 364, 2302, 472, 12, 12194, 8062, 11, 437, 291, 360, 307, 291, 747, 512, 8482, 2758, 484, 51062, 51062, 295, 300, 13, 51112, 51112, 407, 291, 486, 6069, 472, 293, 257, 3840, 295, 35193, 13, 51250, 51250, 407, 661, 813, 884, 300, 11, 291, 6069, 584, 1958, 13, 23247, 293, 291, 909, 1958, 13, 16, 11, 1958, 13, 16, 11, 1958, 13, 16, 11, 1958, 13, 17, 13, 51528, 51528, 286, 411, 264, 29837, 1045, 16949, 281, 445, 909, 257, 9452, 7316, 281, 264, 29837, 13, 51746, 51746], "temperature": 0.0, "avg_logprob": -0.17853412889454462, "compression_ratio": 1.8763636363636365, "no_speech_prob": 0.00010228054452454671}, {"id": 1683, "seek": 676348, "start": 6770.48, "end": 6773.919999999999, "text": " So you have a one-hot vector that you were trying to predict, but rather than trying", "tokens": [50364, 1143, 538, 257, 3840, 295, 7150, 11, 7645, 899, 6259, 571, 307, 411, 11, 291, 393, 519, 295, 309, 411, 264, 1333, 50622, 50622, 295, 22811, 3037, 295, 42923, 399, 13, 50714, 50714, 407, 291, 362, 257, 472, 12, 12194, 8062, 300, 291, 645, 1382, 281, 6069, 11, 457, 2831, 813, 1382, 50886, 50886, 281, 6069, 364, 2302, 472, 12, 12194, 8062, 11, 437, 291, 360, 307, 291, 747, 512, 8482, 2758, 484, 51062, 51062, 295, 300, 13, 51112, 51112, 407, 291, 486, 6069, 472, 293, 257, 3840, 295, 35193, 13, 51250, 51250, 407, 661, 813, 884, 300, 11, 291, 6069, 584, 1958, 13, 23247, 293, 291, 909, 1958, 13, 16, 11, 1958, 13, 16, 11, 1958, 13, 16, 11, 1958, 13, 17, 13, 51528, 51528, 286, 411, 264, 29837, 1045, 16949, 281, 445, 909, 257, 9452, 7316, 281, 264, 29837, 13, 51746, 51746], "temperature": 0.0, "avg_logprob": -0.17853412889454462, "compression_ratio": 1.8763636363636365, "no_speech_prob": 0.00010228054452454671}, {"id": 1684, "seek": 676348, "start": 6773.919999999999, "end": 6777.44, "text": " to predict an entire one-hot vector, what you do is you take some probability mass out", "tokens": [50364, 1143, 538, 257, 3840, 295, 7150, 11, 7645, 899, 6259, 571, 307, 411, 11, 291, 393, 519, 295, 309, 411, 264, 1333, 50622, 50622, 295, 22811, 3037, 295, 42923, 399, 13, 50714, 50714, 407, 291, 362, 257, 472, 12, 12194, 8062, 300, 291, 645, 1382, 281, 6069, 11, 457, 2831, 813, 1382, 50886, 50886, 281, 6069, 364, 2302, 472, 12, 12194, 8062, 11, 437, 291, 360, 307, 291, 747, 512, 8482, 2758, 484, 51062, 51062, 295, 300, 13, 51112, 51112, 407, 291, 486, 6069, 472, 293, 257, 3840, 295, 35193, 13, 51250, 51250, 407, 661, 813, 884, 300, 11, 291, 6069, 584, 1958, 13, 23247, 293, 291, 909, 1958, 13, 16, 11, 1958, 13, 16, 11, 1958, 13, 16, 11, 1958, 13, 17, 13, 51528, 51528, 286, 411, 264, 29837, 1045, 16949, 281, 445, 909, 257, 9452, 7316, 281, 264, 29837, 13, 51746, 51746], "temperature": 0.0, "avg_logprob": -0.17853412889454462, "compression_ratio": 1.8763636363636365, "no_speech_prob": 0.00010228054452454671}, {"id": 1685, "seek": 676348, "start": 6777.44, "end": 6778.44, "text": " of that.", "tokens": [50364, 1143, 538, 257, 3840, 295, 7150, 11, 7645, 899, 6259, 571, 307, 411, 11, 291, 393, 519, 295, 309, 411, 264, 1333, 50622, 50622, 295, 22811, 3037, 295, 42923, 399, 13, 50714, 50714, 407, 291, 362, 257, 472, 12, 12194, 8062, 300, 291, 645, 1382, 281, 6069, 11, 457, 2831, 813, 1382, 50886, 50886, 281, 6069, 364, 2302, 472, 12, 12194, 8062, 11, 437, 291, 360, 307, 291, 747, 512, 8482, 2758, 484, 51062, 51062, 295, 300, 13, 51112, 51112, 407, 291, 486, 6069, 472, 293, 257, 3840, 295, 35193, 13, 51250, 51250, 407, 661, 813, 884, 300, 11, 291, 6069, 584, 1958, 13, 23247, 293, 291, 909, 1958, 13, 16, 11, 1958, 13, 16, 11, 1958, 13, 16, 11, 1958, 13, 17, 13, 51528, 51528, 286, 411, 264, 29837, 1045, 16949, 281, 445, 909, 257, 9452, 7316, 281, 264, 29837, 13, 51746, 51746], "temperature": 0.0, "avg_logprob": -0.17853412889454462, "compression_ratio": 1.8763636363636365, "no_speech_prob": 0.00010228054452454671}, {"id": 1686, "seek": 676348, "start": 6778.44, "end": 6781.2, "text": " So you will predict one and a bunch of zeros.", "tokens": [50364, 1143, 538, 257, 3840, 295, 7150, 11, 7645, 899, 6259, 571, 307, 411, 11, 291, 393, 519, 295, 309, 411, 264, 1333, 50622, 50622, 295, 22811, 3037, 295, 42923, 399, 13, 50714, 50714, 407, 291, 362, 257, 472, 12, 12194, 8062, 300, 291, 645, 1382, 281, 6069, 11, 457, 2831, 813, 1382, 50886, 50886, 281, 6069, 364, 2302, 472, 12, 12194, 8062, 11, 437, 291, 360, 307, 291, 747, 512, 8482, 2758, 484, 51062, 51062, 295, 300, 13, 51112, 51112, 407, 291, 486, 6069, 472, 293, 257, 3840, 295, 35193, 13, 51250, 51250, 407, 661, 813, 884, 300, 11, 291, 6069, 584, 1958, 13, 23247, 293, 291, 909, 1958, 13, 16, 11, 1958, 13, 16, 11, 1958, 13, 16, 11, 1958, 13, 17, 13, 51528, 51528, 286, 411, 264, 29837, 1045, 16949, 281, 445, 909, 257, 9452, 7316, 281, 264, 29837, 13, 51746, 51746], "temperature": 0.0, "avg_logprob": -0.17853412889454462, "compression_ratio": 1.8763636363636365, "no_speech_prob": 0.00010228054452454671}, {"id": 1687, "seek": 676348, "start": 6781.2, "end": 6786.759999999999, "text": " So other than doing that, you predict say 0.97 and you add 0.1, 0.1, 0.1, 0.2.", "tokens": [50364, 1143, 538, 257, 3840, 295, 7150, 11, 7645, 899, 6259, 571, 307, 411, 11, 291, 393, 519, 295, 309, 411, 264, 1333, 50622, 50622, 295, 22811, 3037, 295, 42923, 399, 13, 50714, 50714, 407, 291, 362, 257, 472, 12, 12194, 8062, 300, 291, 645, 1382, 281, 6069, 11, 457, 2831, 813, 1382, 50886, 50886, 281, 6069, 364, 2302, 472, 12, 12194, 8062, 11, 437, 291, 360, 307, 291, 747, 512, 8482, 2758, 484, 51062, 51062, 295, 300, 13, 51112, 51112, 407, 291, 486, 6069, 472, 293, 257, 3840, 295, 35193, 13, 51250, 51250, 407, 661, 813, 884, 300, 11, 291, 6069, 584, 1958, 13, 23247, 293, 291, 909, 1958, 13, 16, 11, 1958, 13, 16, 11, 1958, 13, 16, 11, 1958, 13, 17, 13, 51528, 51528, 286, 411, 264, 29837, 1045, 16949, 281, 445, 909, 257, 9452, 7316, 281, 264, 29837, 13, 51746, 51746], "temperature": 0.0, "avg_logprob": -0.17853412889454462, "compression_ratio": 1.8763636363636365, "no_speech_prob": 0.00010228054452454671}, {"id": 1688, "seek": 676348, "start": 6786.759999999999, "end": 6791.12, "text": " I like the remainder three labels to just add a uniform distribution to the remainder.", "tokens": [50364, 1143, 538, 257, 3840, 295, 7150, 11, 7645, 899, 6259, 571, 307, 411, 11, 291, 393, 519, 295, 309, 411, 264, 1333, 50622, 50622, 295, 22811, 3037, 295, 42923, 399, 13, 50714, 50714, 407, 291, 362, 257, 472, 12, 12194, 8062, 300, 291, 645, 1382, 281, 6069, 11, 457, 2831, 813, 1382, 50886, 50886, 281, 6069, 364, 2302, 472, 12, 12194, 8062, 11, 437, 291, 360, 307, 291, 747, 512, 8482, 2758, 484, 51062, 51062, 295, 300, 13, 51112, 51112, 407, 291, 486, 6069, 472, 293, 257, 3840, 295, 35193, 13, 51250, 51250, 407, 661, 813, 884, 300, 11, 291, 6069, 584, 1958, 13, 23247, 293, 291, 909, 1958, 13, 16, 11, 1958, 13, 16, 11, 1958, 13, 16, 11, 1958, 13, 17, 13, 51528, 51528, 286, 411, 264, 29837, 1045, 16949, 281, 445, 909, 257, 9452, 7316, 281, 264, 29837, 13, 51746, 51746], "temperature": 0.0, "avg_logprob": -0.17853412889454462, "compression_ratio": 1.8763636363636365, "no_speech_prob": 0.00010228054452454671}, {"id": 1689, "seek": 679112, "start": 6791.12, "end": 6793.5599999999995, "text": " So distillation is a sort of more informed way of doing this.", "tokens": [50364, 407, 42923, 399, 307, 257, 1333, 295, 544, 11740, 636, 295, 884, 341, 13, 50486, 50486, 407, 2831, 813, 411, 16979, 1333, 295, 5662, 264, 8482, 295, 257, 4974, 38967, 1508, 11, 50764, 50764, 291, 767, 362, 257, 3209, 597, 390, 659, 12, 17227, 2001, 11, 597, 307, 1238, 665, 281, 341, 13, 51064, 51064, 682, 2674, 11, 4722, 37870, 366, 588, 4420, 337, 659, 12, 17227, 1760, 7150, 570, 5245, 51348, 51348, 3928, 281, 312, 670, 24697, 1078, 13, 51398, 51398, 6001, 12, 17227, 1760, 322, 411, 4722, 7316, 307, 767, 4748, 3571, 813, 19618, 51616, 51616, 2740, 13, 51666, 51666, 407, 291, 393, 589, 4748, 4663, 382, 731, 13, 51786, 51786], "temperature": 0.0, "avg_logprob": -0.2020543969195822, "compression_ratio": 1.7826086956521738, "no_speech_prob": 6.540193680848461e-06}, {"id": 1690, "seek": 679112, "start": 6793.5599999999995, "end": 6799.12, "text": " So rather than like randomly sort of increasing the probability of a random unrelated class,", "tokens": [50364, 407, 42923, 399, 307, 257, 1333, 295, 544, 11740, 636, 295, 884, 341, 13, 50486, 50486, 407, 2831, 813, 411, 16979, 1333, 295, 5662, 264, 8482, 295, 257, 4974, 38967, 1508, 11, 50764, 50764, 291, 767, 362, 257, 3209, 597, 390, 659, 12, 17227, 2001, 11, 597, 307, 1238, 665, 281, 341, 13, 51064, 51064, 682, 2674, 11, 4722, 37870, 366, 588, 4420, 337, 659, 12, 17227, 1760, 7150, 570, 5245, 51348, 51348, 3928, 281, 312, 670, 24697, 1078, 13, 51398, 51398, 6001, 12, 17227, 1760, 322, 411, 4722, 7316, 307, 767, 4748, 3571, 813, 19618, 51616, 51616, 2740, 13, 51666, 51666, 407, 291, 393, 589, 4748, 4663, 382, 731, 13, 51786, 51786], "temperature": 0.0, "avg_logprob": -0.2020543969195822, "compression_ratio": 1.7826086956521738, "no_speech_prob": 6.540193680848461e-06}, {"id": 1691, "seek": 679112, "start": 6799.12, "end": 6805.12, "text": " you actually have a network which was pre-trained, which is pretty good to this.", "tokens": [50364, 407, 42923, 399, 307, 257, 1333, 295, 544, 11740, 636, 295, 884, 341, 13, 50486, 50486, 407, 2831, 813, 411, 16979, 1333, 295, 5662, 264, 8482, 295, 257, 4974, 38967, 1508, 11, 50764, 50764, 291, 767, 362, 257, 3209, 597, 390, 659, 12, 17227, 2001, 11, 597, 307, 1238, 665, 281, 341, 13, 51064, 51064, 682, 2674, 11, 4722, 37870, 366, 588, 4420, 337, 659, 12, 17227, 1760, 7150, 570, 5245, 51348, 51348, 3928, 281, 312, 670, 24697, 1078, 13, 51398, 51398, 6001, 12, 17227, 1760, 322, 411, 4722, 7316, 307, 767, 4748, 3571, 813, 19618, 51616, 51616, 2740, 13, 51666, 51666, 407, 291, 393, 589, 4748, 4663, 382, 731, 13, 51786, 51786], "temperature": 0.0, "avg_logprob": -0.2020543969195822, "compression_ratio": 1.7826086956521738, "no_speech_prob": 6.540193680848461e-06}, {"id": 1692, "seek": 679112, "start": 6805.12, "end": 6810.8, "text": " In general, software distributions are very useful for pre-training methods because models", "tokens": [50364, 407, 42923, 399, 307, 257, 1333, 295, 544, 11740, 636, 295, 884, 341, 13, 50486, 50486, 407, 2831, 813, 411, 16979, 1333, 295, 5662, 264, 8482, 295, 257, 4974, 38967, 1508, 11, 50764, 50764, 291, 767, 362, 257, 3209, 597, 390, 659, 12, 17227, 2001, 11, 597, 307, 1238, 665, 281, 341, 13, 51064, 51064, 682, 2674, 11, 4722, 37870, 366, 588, 4420, 337, 659, 12, 17227, 1760, 7150, 570, 5245, 51348, 51348, 3928, 281, 312, 670, 24697, 1078, 13, 51398, 51398, 6001, 12, 17227, 1760, 322, 411, 4722, 7316, 307, 767, 4748, 3571, 813, 19618, 51616, 51616, 2740, 13, 51666, 51666, 407, 291, 393, 589, 4748, 4663, 382, 731, 13, 51786, 51786], "temperature": 0.0, "avg_logprob": -0.2020543969195822, "compression_ratio": 1.7826086956521738, "no_speech_prob": 6.540193680848461e-06}, {"id": 1693, "seek": 679112, "start": 6810.8, "end": 6811.8, "text": " tend to be overconfident.", "tokens": [50364, 407, 42923, 399, 307, 257, 1333, 295, 544, 11740, 636, 295, 884, 341, 13, 50486, 50486, 407, 2831, 813, 411, 16979, 1333, 295, 5662, 264, 8482, 295, 257, 4974, 38967, 1508, 11, 50764, 50764, 291, 767, 362, 257, 3209, 597, 390, 659, 12, 17227, 2001, 11, 597, 307, 1238, 665, 281, 341, 13, 51064, 51064, 682, 2674, 11, 4722, 37870, 366, 588, 4420, 337, 659, 12, 17227, 1760, 7150, 570, 5245, 51348, 51348, 3928, 281, 312, 670, 24697, 1078, 13, 51398, 51398, 6001, 12, 17227, 1760, 322, 411, 4722, 7316, 307, 767, 4748, 3571, 813, 19618, 51616, 51616, 2740, 13, 51666, 51666, 407, 291, 393, 589, 4748, 4663, 382, 731, 13, 51786, 51786], "temperature": 0.0, "avg_logprob": -0.2020543969195822, "compression_ratio": 1.7826086956521738, "no_speech_prob": 6.540193680848461e-06}, {"id": 1694, "seek": 679112, "start": 6811.8, "end": 6816.16, "text": " Pre-training on like software distribution is actually slightly easier than optimization", "tokens": [50364, 407, 42923, 399, 307, 257, 1333, 295, 544, 11740, 636, 295, 884, 341, 13, 50486, 50486, 407, 2831, 813, 411, 16979, 1333, 295, 5662, 264, 8482, 295, 257, 4974, 38967, 1508, 11, 50764, 50764, 291, 767, 362, 257, 3209, 597, 390, 659, 12, 17227, 2001, 11, 597, 307, 1238, 665, 281, 341, 13, 51064, 51064, 682, 2674, 11, 4722, 37870, 366, 588, 4420, 337, 659, 12, 17227, 1760, 7150, 570, 5245, 51348, 51348, 3928, 281, 312, 670, 24697, 1078, 13, 51398, 51398, 6001, 12, 17227, 1760, 322, 411, 4722, 7316, 307, 767, 4748, 3571, 813, 19618, 51616, 51616, 2740, 13, 51666, 51666, 407, 291, 393, 589, 4748, 4663, 382, 731, 13, 51786, 51786], "temperature": 0.0, "avg_logprob": -0.2020543969195822, "compression_ratio": 1.7826086956521738, "no_speech_prob": 6.540193680848461e-06}, {"id": 1695, "seek": 679112, "start": 6816.16, "end": 6817.16, "text": " problems.", "tokens": [50364, 407, 42923, 399, 307, 257, 1333, 295, 544, 11740, 636, 295, 884, 341, 13, 50486, 50486, 407, 2831, 813, 411, 16979, 1333, 295, 5662, 264, 8482, 295, 257, 4974, 38967, 1508, 11, 50764, 50764, 291, 767, 362, 257, 3209, 597, 390, 659, 12, 17227, 2001, 11, 597, 307, 1238, 665, 281, 341, 13, 51064, 51064, 682, 2674, 11, 4722, 37870, 366, 588, 4420, 337, 659, 12, 17227, 1760, 7150, 570, 5245, 51348, 51348, 3928, 281, 312, 670, 24697, 1078, 13, 51398, 51398, 6001, 12, 17227, 1760, 322, 411, 4722, 7316, 307, 767, 4748, 3571, 813, 19618, 51616, 51616, 2740, 13, 51666, 51666, 407, 291, 393, 589, 4748, 4663, 382, 731, 13, 51786, 51786], "temperature": 0.0, "avg_logprob": -0.2020543969195822, "compression_ratio": 1.7826086956521738, "no_speech_prob": 6.540193680848461e-06}, {"id": 1696, "seek": 679112, "start": 6817.16, "end": 6819.5599999999995, "text": " So you can work slightly faster as well.", "tokens": [50364, 407, 42923, 399, 307, 257, 1333, 295, 544, 11740, 636, 295, 884, 341, 13, 50486, 50486, 407, 2831, 813, 411, 16979, 1333, 295, 5662, 264, 8482, 295, 257, 4974, 38967, 1508, 11, 50764, 50764, 291, 767, 362, 257, 3209, 597, 390, 659, 12, 17227, 2001, 11, 597, 307, 1238, 665, 281, 341, 13, 51064, 51064, 682, 2674, 11, 4722, 37870, 366, 588, 4420, 337, 659, 12, 17227, 1760, 7150, 570, 5245, 51348, 51348, 3928, 281, 312, 670, 24697, 1078, 13, 51398, 51398, 6001, 12, 17227, 1760, 322, 411, 4722, 7316, 307, 767, 4748, 3571, 813, 19618, 51616, 51616, 2740, 13, 51666, 51666, 407, 291, 393, 589, 4748, 4663, 382, 731, 13, 51786, 51786], "temperature": 0.0, "avg_logprob": -0.2020543969195822, "compression_ratio": 1.7826086956521738, "no_speech_prob": 6.540193680848461e-06}, {"id": 1697, "seek": 681956, "start": 6819.56, "end": 6824.96, "text": " So both of these benefits are present in distillation and also something like label smoothing.", "tokens": [50364, 407, 1293, 295, 613, 5311, 366, 1974, 294, 42923, 399, 293, 611, 746, 411, 7645, 899, 6259, 571, 13, 50634, 50634, 2743, 570, 5508, 16949, 2089, 291, 281, 362, 257, 3000, 12, 16129, 3857, 420, 257, 3857, 12, 16129, 3000, 13, 50920, 50920, 407, 498, 291, 362, 257, 588, 955, 3209, 300, 575, 668, 8895, 322, 588, 867, 10938, 11, 309, 486, 51134, 51134, 767, 362, 257, 2296, 1558, 295, 437, 307, 364, 39465, 4317, 3256, 13, 51426, 51426, 400, 4412, 11, 498, 291, 393, 767, 1466, 300, 2787, 1558, 11, 291, 434, 516, 281, 312, 2539, 544, 51659, 51659], "temperature": 0.0, "avg_logprob": -0.0992427339740828, "compression_ratio": 1.6947791164658634, "no_speech_prob": 2.7519752620719373e-05}, {"id": 1698, "seek": 681956, "start": 6824.96, "end": 6830.68, "text": " Also because smooth labels allow you to have a dog-looking cat or a cat-looking dog.", "tokens": [50364, 407, 1293, 295, 613, 5311, 366, 1974, 294, 42923, 399, 293, 611, 746, 411, 7645, 899, 6259, 571, 13, 50634, 50634, 2743, 570, 5508, 16949, 2089, 291, 281, 362, 257, 3000, 12, 16129, 3857, 420, 257, 3857, 12, 16129, 3000, 13, 50920, 50920, 407, 498, 291, 362, 257, 588, 955, 3209, 300, 575, 668, 8895, 322, 588, 867, 10938, 11, 309, 486, 51134, 51134, 767, 362, 257, 2296, 1558, 295, 437, 307, 364, 39465, 4317, 3256, 13, 51426, 51426, 400, 4412, 11, 498, 291, 393, 767, 1466, 300, 2787, 1558, 11, 291, 434, 516, 281, 312, 2539, 544, 51659, 51659], "temperature": 0.0, "avg_logprob": -0.0992427339740828, "compression_ratio": 1.6947791164658634, "no_speech_prob": 2.7519752620719373e-05}, {"id": 1699, "seek": 681956, "start": 6830.68, "end": 6834.96, "text": " So if you have a very big network that has been trained on very many samples, it will", "tokens": [50364, 407, 1293, 295, 613, 5311, 366, 1974, 294, 42923, 399, 293, 611, 746, 411, 7645, 899, 6259, 571, 13, 50634, 50634, 2743, 570, 5508, 16949, 2089, 291, 281, 362, 257, 3000, 12, 16129, 3857, 420, 257, 3857, 12, 16129, 3000, 13, 50920, 50920, 407, 498, 291, 362, 257, 588, 955, 3209, 300, 575, 668, 8895, 322, 588, 867, 10938, 11, 309, 486, 51134, 51134, 767, 362, 257, 2296, 1558, 295, 437, 307, 364, 39465, 4317, 3256, 13, 51426, 51426, 400, 4412, 11, 498, 291, 393, 767, 1466, 300, 2787, 1558, 11, 291, 434, 516, 281, 312, 2539, 544, 51659, 51659], "temperature": 0.0, "avg_logprob": -0.0992427339740828, "compression_ratio": 1.6947791164658634, "no_speech_prob": 2.7519752620719373e-05}, {"id": 1700, "seek": 681956, "start": 6834.96, "end": 6840.8, "text": " actually have a proper idea of what is an ambiguous perhaps image.", "tokens": [50364, 407, 1293, 295, 613, 5311, 366, 1974, 294, 42923, 399, 293, 611, 746, 411, 7645, 899, 6259, 571, 13, 50634, 50634, 2743, 570, 5508, 16949, 2089, 291, 281, 362, 257, 3000, 12, 16129, 3857, 420, 257, 3857, 12, 16129, 3000, 13, 50920, 50920, 407, 498, 291, 362, 257, 588, 955, 3209, 300, 575, 668, 8895, 322, 588, 867, 10938, 11, 309, 486, 51134, 51134, 767, 362, 257, 2296, 1558, 295, 437, 307, 364, 39465, 4317, 3256, 13, 51426, 51426, 400, 4412, 11, 498, 291, 393, 767, 1466, 300, 2787, 1558, 11, 291, 434, 516, 281, 312, 2539, 544, 51659, 51659], "temperature": 0.0, "avg_logprob": -0.0992427339740828, "compression_ratio": 1.6947791164658634, "no_speech_prob": 2.7519752620719373e-05}, {"id": 1701, "seek": 681956, "start": 6840.8, "end": 6845.46, "text": " And therefore, if you can actually learn that soft idea, you're going to be learning more", "tokens": [50364, 407, 1293, 295, 613, 5311, 366, 1974, 294, 42923, 399, 293, 611, 746, 411, 7645, 899, 6259, 571, 13, 50634, 50634, 2743, 570, 5508, 16949, 2089, 291, 281, 362, 257, 3000, 12, 16129, 3857, 420, 257, 3857, 12, 16129, 3000, 13, 50920, 50920, 407, 498, 291, 362, 257, 588, 955, 3209, 300, 575, 668, 8895, 322, 588, 867, 10938, 11, 309, 486, 51134, 51134, 767, 362, 257, 2296, 1558, 295, 437, 307, 364, 39465, 4317, 3256, 13, 51426, 51426, 400, 4412, 11, 498, 291, 393, 767, 1466, 300, 2787, 1558, 11, 291, 434, 516, 281, 312, 2539, 544, 51659, 51659], "temperature": 0.0, "avg_logprob": -0.0992427339740828, "compression_ratio": 1.6947791164658634, "no_speech_prob": 2.7519752620719373e-05}, {"id": 1702, "seek": 684546, "start": 6845.46, "end": 6851.12, "text": " than if you just give that one hot label.", "tokens": [50364, 813, 498, 291, 445, 976, 300, 472, 2368, 7645, 13, 50647, 50647, 286, 519, 321, 366, 2614, 484, 295, 565, 13, 50765, 50765, 286, 519, 321, 366, 484, 295, 565, 411, 1922, 364, 1773, 2057, 11, 457, 341, 390, 264, 1168, 293, 1867, 51025, 51025, 5481, 13, 51075, 51075, 759, 456, 366, 572, 534, 11, 534, 19022, 1651, 920, 32110, 11, 286, 486, 312, 5141, 309, 11, 818, 51637, 51637, 264, 917, 295, 264, 6898, 13, 51758, 51758, 407, 1309, 291, 337, 15164, 294, 13, 51833, 51833], "temperature": 0.0, "avg_logprob": -0.2096389170443074, "compression_ratio": 1.643979057591623, "no_speech_prob": 0.00018143308989237994}, {"id": 1703, "seek": 684546, "start": 6851.12, "end": 6853.4800000000005, "text": " I think we are running out of time.", "tokens": [50364, 813, 498, 291, 445, 976, 300, 472, 2368, 7645, 13, 50647, 50647, 286, 519, 321, 366, 2614, 484, 295, 565, 13, 50765, 50765, 286, 519, 321, 366, 484, 295, 565, 411, 1922, 364, 1773, 2057, 11, 457, 341, 390, 264, 1168, 293, 1867, 51025, 51025, 5481, 13, 51075, 51075, 759, 456, 366, 572, 534, 11, 534, 19022, 1651, 920, 32110, 11, 286, 486, 312, 5141, 309, 11, 818, 51637, 51637, 264, 917, 295, 264, 6898, 13, 51758, 51758, 407, 1309, 291, 337, 15164, 294, 13, 51833, 51833], "temperature": 0.0, "avg_logprob": -0.2096389170443074, "compression_ratio": 1.643979057591623, "no_speech_prob": 0.00018143308989237994}, {"id": 1704, "seek": 684546, "start": 6853.4800000000005, "end": 6858.68, "text": " I think we are out of time like half an hour ago, but this was the question and answer", "tokens": [50364, 813, 498, 291, 445, 976, 300, 472, 2368, 7645, 13, 50647, 50647, 286, 519, 321, 366, 2614, 484, 295, 565, 13, 50765, 50765, 286, 519, 321, 366, 484, 295, 565, 411, 1922, 364, 1773, 2057, 11, 457, 341, 390, 264, 1168, 293, 1867, 51025, 51025, 5481, 13, 51075, 51075, 759, 456, 366, 572, 534, 11, 534, 19022, 1651, 920, 32110, 11, 286, 486, 312, 5141, 309, 11, 818, 51637, 51637, 264, 917, 295, 264, 6898, 13, 51758, 51758, 407, 1309, 291, 337, 15164, 294, 13, 51833, 51833], "temperature": 0.0, "avg_logprob": -0.2096389170443074, "compression_ratio": 1.643979057591623, "no_speech_prob": 0.00018143308989237994}, {"id": 1705, "seek": 684546, "start": 6858.68, "end": 6859.68, "text": " session.", "tokens": [50364, 813, 498, 291, 445, 976, 300, 472, 2368, 7645, 13, 50647, 50647, 286, 519, 321, 366, 2614, 484, 295, 565, 13, 50765, 50765, 286, 519, 321, 366, 484, 295, 565, 411, 1922, 364, 1773, 2057, 11, 457, 341, 390, 264, 1168, 293, 1867, 51025, 51025, 5481, 13, 51075, 51075, 759, 456, 366, 572, 534, 11, 534, 19022, 1651, 920, 32110, 11, 286, 486, 312, 5141, 309, 11, 818, 51637, 51637, 264, 917, 295, 264, 6898, 13, 51758, 51758, 407, 1309, 291, 337, 15164, 294, 13, 51833, 51833], "temperature": 0.0, "avg_logprob": -0.2096389170443074, "compression_ratio": 1.643979057591623, "no_speech_prob": 0.00018143308989237994}, {"id": 1706, "seek": 684546, "start": 6859.68, "end": 6870.92, "text": " If there are no really, really urgent questions still pending, I will be calling it, call", "tokens": [50364, 813, 498, 291, 445, 976, 300, 472, 2368, 7645, 13, 50647, 50647, 286, 519, 321, 366, 2614, 484, 295, 565, 13, 50765, 50765, 286, 519, 321, 366, 484, 295, 565, 411, 1922, 364, 1773, 2057, 11, 457, 341, 390, 264, 1168, 293, 1867, 51025, 51025, 5481, 13, 51075, 51075, 759, 456, 366, 572, 534, 11, 534, 19022, 1651, 920, 32110, 11, 286, 486, 312, 5141, 309, 11, 818, 51637, 51637, 264, 917, 295, 264, 6898, 13, 51758, 51758, 407, 1309, 291, 337, 15164, 294, 13, 51833, 51833], "temperature": 0.0, "avg_logprob": -0.2096389170443074, "compression_ratio": 1.643979057591623, "no_speech_prob": 0.00018143308989237994}, {"id": 1707, "seek": 684546, "start": 6870.92, "end": 6873.34, "text": " the end of the lesson.", "tokens": [50364, 813, 498, 291, 445, 976, 300, 472, 2368, 7645, 13, 50647, 50647, 286, 519, 321, 366, 2614, 484, 295, 565, 13, 50765, 50765, 286, 519, 321, 366, 484, 295, 565, 411, 1922, 364, 1773, 2057, 11, 457, 341, 390, 264, 1168, 293, 1867, 51025, 51025, 5481, 13, 51075, 51075, 759, 456, 366, 572, 534, 11, 534, 19022, 1651, 920, 32110, 11, 286, 486, 312, 5141, 309, 11, 818, 51637, 51637, 264, 917, 295, 264, 6898, 13, 51758, 51758, 407, 1309, 291, 337, 15164, 294, 13, 51833, 51833], "temperature": 0.0, "avg_logprob": -0.2096389170443074, "compression_ratio": 1.643979057591623, "no_speech_prob": 0.00018143308989237994}, {"id": 1708, "seek": 684546, "start": 6873.34, "end": 6874.84, "text": " So thank you for tuning in.", "tokens": [50364, 813, 498, 291, 445, 976, 300, 472, 2368, 7645, 13, 50647, 50647, 286, 519, 321, 366, 2614, 484, 295, 565, 13, 50765, 50765, 286, 519, 321, 366, 484, 295, 565, 411, 1922, 364, 1773, 2057, 11, 457, 341, 390, 264, 1168, 293, 1867, 51025, 51025, 5481, 13, 51075, 51075, 759, 456, 366, 572, 534, 11, 534, 19022, 1651, 920, 32110, 11, 286, 486, 312, 5141, 309, 11, 818, 51637, 51637, 264, 917, 295, 264, 6898, 13, 51758, 51758, 407, 1309, 291, 337, 15164, 294, 13, 51833, 51833], "temperature": 0.0, "avg_logprob": -0.2096389170443074, "compression_ratio": 1.643979057591623, "no_speech_prob": 0.00018143308989237994}, {"id": 1709, "seek": 687484, "start": 6874.84, "end": 6879.360000000001, "text": " I'll see you tomorrow at the practical session.", "tokens": [50364, 286, 603, 536, 291, 4153, 412, 264, 8496, 5481, 13, 50590, 50590, 1468, 380, 2870, 281, 808, 13, 50760, 50760, 400, 300, 390, 309, 13, 50810, 50810, 407, 1309, 291, 370, 709, 11, 1119, 3451, 13, 50912, 50912, 400, 286, 603, 536, 291, 926, 13, 50962, 50962, 1044, 291, 11, 1119, 3451, 13, 51012, 51012, 1044, 291, 11, 1518, 13, 51062, 51062, 3664, 1127, 11, 1518, 13, 51112, 51112, 4621, 12, 6650, 13, 51112], "temperature": 0.0, "avg_logprob": -0.13432608152690687, "compression_ratio": 1.5144927536231885, "no_speech_prob": 8.076772064669058e-05}, {"id": 1710, "seek": 687484, "start": 6879.360000000001, "end": 6882.76, "text": " Don't forget to come.", "tokens": [50364, 286, 603, 536, 291, 4153, 412, 264, 8496, 5481, 13, 50590, 50590, 1468, 380, 2870, 281, 808, 13, 50760, 50760, 400, 300, 390, 309, 13, 50810, 50810, 407, 1309, 291, 370, 709, 11, 1119, 3451, 13, 50912, 50912, 400, 286, 603, 536, 291, 926, 13, 50962, 50962, 1044, 291, 11, 1119, 3451, 13, 51012, 51012, 1044, 291, 11, 1518, 13, 51062, 51062, 3664, 1127, 11, 1518, 13, 51112, 51112, 4621, 12, 6650, 13, 51112], "temperature": 0.0, "avg_logprob": -0.13432608152690687, "compression_ratio": 1.5144927536231885, "no_speech_prob": 8.076772064669058e-05}, {"id": 1711, "seek": 687484, "start": 6882.76, "end": 6883.76, "text": " And that was it.", "tokens": [50364, 286, 603, 536, 291, 4153, 412, 264, 8496, 5481, 13, 50590, 50590, 1468, 380, 2870, 281, 808, 13, 50760, 50760, 400, 300, 390, 309, 13, 50810, 50810, 407, 1309, 291, 370, 709, 11, 1119, 3451, 13, 50912, 50912, 400, 286, 603, 536, 291, 926, 13, 50962, 50962, 1044, 291, 11, 1119, 3451, 13, 51012, 51012, 1044, 291, 11, 1518, 13, 51062, 51062, 3664, 1127, 11, 1518, 13, 51112, 51112, 4621, 12, 6650, 13, 51112], "temperature": 0.0, "avg_logprob": -0.13432608152690687, "compression_ratio": 1.5144927536231885, "no_speech_prob": 8.076772064669058e-05}, {"id": 1712, "seek": 687484, "start": 6883.76, "end": 6885.8, "text": " So thank you so much, Ishan.", "tokens": [50364, 286, 603, 536, 291, 4153, 412, 264, 8496, 5481, 13, 50590, 50590, 1468, 380, 2870, 281, 808, 13, 50760, 50760, 400, 300, 390, 309, 13, 50810, 50810, 407, 1309, 291, 370, 709, 11, 1119, 3451, 13, 50912, 50912, 400, 286, 603, 536, 291, 926, 13, 50962, 50962, 1044, 291, 11, 1119, 3451, 13, 51012, 51012, 1044, 291, 11, 1518, 13, 51062, 51062, 3664, 1127, 11, 1518, 13, 51112, 51112, 4621, 12, 6650, 13, 51112], "temperature": 0.0, "avg_logprob": -0.13432608152690687, "compression_ratio": 1.5144927536231885, "no_speech_prob": 8.076772064669058e-05}, {"id": 1713, "seek": 687484, "start": 6885.8, "end": 6886.8, "text": " And I'll see you around.", "tokens": [50364, 286, 603, 536, 291, 4153, 412, 264, 8496, 5481, 13, 50590, 50590, 1468, 380, 2870, 281, 808, 13, 50760, 50760, 400, 300, 390, 309, 13, 50810, 50810, 407, 1309, 291, 370, 709, 11, 1119, 3451, 13, 50912, 50912, 400, 286, 603, 536, 291, 926, 13, 50962, 50962, 1044, 291, 11, 1119, 3451, 13, 51012, 51012, 1044, 291, 11, 1518, 13, 51062, 51062, 3664, 1127, 11, 1518, 13, 51112, 51112, 4621, 12, 6650, 13, 51112], "temperature": 0.0, "avg_logprob": -0.13432608152690687, "compression_ratio": 1.5144927536231885, "no_speech_prob": 8.076772064669058e-05}, {"id": 1714, "seek": 687484, "start": 6886.8, "end": 6887.8, "text": " Thank you, Ishan.", "tokens": [50364, 286, 603, 536, 291, 4153, 412, 264, 8496, 5481, 13, 50590, 50590, 1468, 380, 2870, 281, 808, 13, 50760, 50760, 400, 300, 390, 309, 13, 50810, 50810, 407, 1309, 291, 370, 709, 11, 1119, 3451, 13, 50912, 50912, 400, 286, 603, 536, 291, 926, 13, 50962, 50962, 1044, 291, 11, 1119, 3451, 13, 51012, 51012, 1044, 291, 11, 1518, 13, 51062, 51062, 3664, 1127, 11, 1518, 13, 51112, 51112, 4621, 12, 6650, 13, 51112], "temperature": 0.0, "avg_logprob": -0.13432608152690687, "compression_ratio": 1.5144927536231885, "no_speech_prob": 8.076772064669058e-05}, {"id": 1715, "seek": 687484, "start": 6887.8, "end": 6888.8, "text": " Thank you, everyone.", "tokens": [50364, 286, 603, 536, 291, 4153, 412, 264, 8496, 5481, 13, 50590, 50590, 1468, 380, 2870, 281, 808, 13, 50760, 50760, 400, 300, 390, 309, 13, 50810, 50810, 407, 1309, 291, 370, 709, 11, 1119, 3451, 13, 50912, 50912, 400, 286, 603, 536, 291, 926, 13, 50962, 50962, 1044, 291, 11, 1119, 3451, 13, 51012, 51012, 1044, 291, 11, 1518, 13, 51062, 51062, 3664, 1127, 11, 1518, 13, 51112, 51112, 4621, 12, 6650, 13, 51112], "temperature": 0.0, "avg_logprob": -0.13432608152690687, "compression_ratio": 1.5144927536231885, "no_speech_prob": 8.076772064669058e-05}, {"id": 1716, "seek": 687484, "start": 6888.8, "end": 6889.8, "text": " Take care, everyone.", "tokens": [50364, 286, 603, 536, 291, 4153, 412, 264, 8496, 5481, 13, 50590, 50590, 1468, 380, 2870, 281, 808, 13, 50760, 50760, 400, 300, 390, 309, 13, 50810, 50810, 407, 1309, 291, 370, 709, 11, 1119, 3451, 13, 50912, 50912, 400, 286, 603, 536, 291, 926, 13, 50962, 50962, 1044, 291, 11, 1119, 3451, 13, 51012, 51012, 1044, 291, 11, 1518, 13, 51062, 51062, 3664, 1127, 11, 1518, 13, 51112, 51112, 4621, 12, 6650, 13, 51112], "temperature": 0.0, "avg_logprob": -0.13432608152690687, "compression_ratio": 1.5144927536231885, "no_speech_prob": 8.076772064669058e-05}, {"id": 1717, "seek": 688980, "start": 6889.8, "end": 6905.04, "text": " Bye-bye.", "tokens": [50364, 4621, 12, 6650, 13, 51126], "temperature": 0.0, "avg_logprob": -0.8560143879481724, "compression_ratio": 0.5, "no_speech_prob": 3.169873161823489e-05}], "language": "en", "video_id": "0KeR6i1_56g", "entity": "Yann LeCun"}}