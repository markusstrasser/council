{"video_id": "8Rl_2WQbmlc", "title": "6.6 Bias and variance |Establishing a baseline level of performance -[Machine Learning | Andrew Ng]", "description": "Second Course:\nAdvanced Learning Algorithms.\n\n\nIf you liked the content please subscribe and put a little blue thumb.\nTake heart!", "author": "Machine Learning", "keywords": [], "channel_url": "https://www.youtube.com/channel/UClG5HEAJJFOavT_UolqYROQ", "length": 566, "views": 88, "publish_date": "11/04/2022", "timestamp": 1661817600, "entity": "ML Specialization, Andrew Ng (2022)", "transcript": {"text": " Let's look at some concrete numbers for what JTrain and JCV might be and see how you can judge if a learning algorithm has high bias or high variance. And for the examples in this video, I'm going to use as a running example the application of speech recognition, which is something I've worked on multiple times over the years. Let's take a look. A lot of users doing web search on a mobile phone will use speech recognition rather than type on the tiny keyboards on their phones because speaking to a phone is often faster than typing. And so typical audio that a web search engine would get would be like this. What is today's weather? Or like this. Coffee shops near me. And there's the job of the speech recognition algorithm to output the transcripts, what is today's weather or coffee shops near me. Now if you were to train a speech recognition system and measure the training error, and the training error means what's the percentage of audio clips in your training set that the algorithm does not transcribe correctly in its entirety. Let's say the training error for this data set is 10.8%, meaning that it transcribes it perfectly for 89.2% of your training set, but makes some mistake in 10.8% of your training set. And if you were to also measure your speech recognition algorithm's performance on a separate cross-validation set, let's say it gets 14.8% error. So if you were to look at these numbers, it looks like the training error is really high, it got 10% wrong, and then the cross-validation error is higher, but getting 10% of even your training set wrong, that seems pretty high. And it seems like that 10% error would lead you to conclude it has to have high bias because it's not doing well on your training set. But it turns out that when analyzing speech recognition, it's useful to also measure one other thing, which is what is the human level of performance. In other words, how well can even humans transcribe speech accurately from these audio clips? And concretely, let's say that you measure how well fluent speakers can transcribe audio clips and you find that it is 10.6%, and you find that human level performance achieves 10.6% error. Why is human level error so high? It turns out that for web search, there are a lot of audio clips that sound like this. I'm going to navigate to somewhere on the... And there's a lot of noisy audio where really no one can accurately transcribe what was said because of the noise in the audio. And if even a human makes 10.6% error, then it seems difficult to expect a learning algorithm to do much better. And so in order to judge if the training error is high, it turns out to be more useful to see if the training error is much higher than a human level of performance. And in this example, it does just 0.2% worse than humans. Given that humans are actually really good at recognizing speech, I think if I can build a speech recognition system that achieves 10.6% error matching human performance, I'd be pretty happy. So it's just doing a little bit worse than humans. But in contrast, the gap or the difference between JCV and JTrain is much larger. There's actually a 4% gap there. So whereas previously we had said maybe 10.8% error means this is high bias, when we benchmark it to human level performance, we see that the algorithm is actually doing quite well on the training set. But the bigger problem is the cross validation error is much higher than the training error, which is why I would conclude that this algorithm actually has more of a variance problem than a bias problem. So it turns out when judging if the training error is high, it's often useful to establish a baseline level of performance. And by baseline level of performance, I mean, what is the level of error you can reasonably hope your learning algorithm to eventually get to? And one common way to establish a baseline level of performance is to measure how well humans can do on this task. Because humans are really good at understanding speech data or processing images or understanding text, human level performance is often a good benchmark when you are using unstructured data such as audio, images or text. Another way to estimate a baseline level of performance is if there's some competing algorithm, maybe a previous implementation that someone else implemented or even a competitor's algorithm to establish a baseline level of performance, if you can measure that. Or sometimes you might guess based on prior experience. And if you have access to this baseline level of performance, that is, what is the level of error you can reasonably hope to get to? Or what is the design level of performance that you want your algorithm to get to? Then when judging, if an algorithm has high bias or variance, you would look at the baseline level of performance and the training error and the cross validation error. And the two key quantities to measure are then what is the difference between training error and the baseline level that you hope to get to? So this is 0.2, and if this is large, then you would say you have a high bias problem. And you would then also look at this gap between your training error and your cross validation error. And if this is high, then you would conclude you have a high variance problem. And that's why in this example, we concluded we have a high variance problem. Whereas, let's look at the second example. If the baseline level of performance, that is, human level performance and training error and cross validation error look like this, then this first gap is 4.4%. And so there's actually a big gap. The training error is much higher than what humans can do and what we hope to get to. Whereas the cross validation error is just a little bit bigger than the training error. And so if your training error and cross validation error look like this, I would say this algorithm has high bias. And so by looking at these numbers, training error and cross validation error, you can get a sense, intuitively or informally, of the degree to which your algorithm has a high bias or high variance problem. And so just to summarize, this gap between these first two numbers gives you a sense of whether you have a high bias problem. And the gap between these two numbers give you a sense of whether you have a high variance problem. And sometimes the baseline level of performance could be 0%. If your goal is to achieve perfect performance, then the baseline level of performance could be 0%. But for some applications, like the speech recognition application, where some audio is just noisy, then the baseline level of performance could be much higher than 0. And the method described on this slide will give you a better read in terms of whether your algorithm suffers from bias or variance. And by the way, it is possible for your algorithm to have high bias and high variance. So concretely, if you get numbers like these, then the gap between the baseline and the training error is large. That would be a 4.6%. And the gap between training error and cross validation error is also large. This is 4.2%. And so if it looks like this, you would conclude that your algorithm has high bias and high variance, although hopefully this won't happen that often for your learning applications. So to summarize, we've seen that looking at whether your training error is large is a way to tell if your algorithm has high bias. But on applications where the data is sometimes just noisy and is infeasible or unrealistic to ever expect to get to zero error, then it's useful to establish this baseline level of performance so that rather than just asking, is my training error large? You can ask, is my training error large relative to what I hope I could get to eventually, such as is my training error large relative to what humans can do on the task? And that gives you a more accurate read on how far away you are in terms of a training error from where you hope to get to. And then similarly, looking at whether your cross validation error is much larger than your training error gives you a sense of whether or not your algorithm may have a high variance problem as well. And in practice, this is how I often will look at these numbers to judge if my learning algorithm has a high bias or high variance problem. Now, to further hone our intuition about how a learning algorithm is doing, there's one other thing that I found useful to think about, which is the learning curve. Let's take a look at what that means in the next video.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 8.0, "text": " Let's look at some concrete numbers for what JTrain and JCV might be and see how you can", "tokens": [50364, 961, 311, 574, 412, 512, 9859, 3547, 337, 437, 508, 51, 7146, 293, 49802, 53, 1062, 312, 293, 536, 577, 291, 393, 50764, 50764, 6995, 498, 257, 2539, 9284, 575, 1090, 12577, 420, 1090, 21977, 13, 50978, 50978, 400, 337, 264, 5110, 294, 341, 960, 11, 286, 478, 516, 281, 764, 382, 257, 2614, 1365, 264, 3861, 51232, 51232, 295, 6218, 11150, 11, 597, 307, 746, 286, 600, 2732, 322, 3866, 1413, 670, 264, 924, 13, 51474, 51474, 961, 311, 747, 257, 574, 13, 51524, 51524, 316, 688, 295, 5022, 884, 3670, 3164, 322, 257, 6013, 2593, 486, 764, 6218, 11150, 2831, 813, 51846, 51846], "temperature": 0.0, "avg_logprob": -0.12916056018009364, "compression_ratio": 1.6066176470588236, "no_speech_prob": 0.0073429252952337265}, {"id": 1, "seek": 0, "start": 8.0, "end": 12.280000000000001, "text": " judge if a learning algorithm has high bias or high variance.", "tokens": [50364, 961, 311, 574, 412, 512, 9859, 3547, 337, 437, 508, 51, 7146, 293, 49802, 53, 1062, 312, 293, 536, 577, 291, 393, 50764, 50764, 6995, 498, 257, 2539, 9284, 575, 1090, 12577, 420, 1090, 21977, 13, 50978, 50978, 400, 337, 264, 5110, 294, 341, 960, 11, 286, 478, 516, 281, 764, 382, 257, 2614, 1365, 264, 3861, 51232, 51232, 295, 6218, 11150, 11, 597, 307, 746, 286, 600, 2732, 322, 3866, 1413, 670, 264, 924, 13, 51474, 51474, 961, 311, 747, 257, 574, 13, 51524, 51524, 316, 688, 295, 5022, 884, 3670, 3164, 322, 257, 6013, 2593, 486, 764, 6218, 11150, 2831, 813, 51846, 51846], "temperature": 0.0, "avg_logprob": -0.12916056018009364, "compression_ratio": 1.6066176470588236, "no_speech_prob": 0.0073429252952337265}, {"id": 2, "seek": 0, "start": 12.280000000000001, "end": 17.36, "text": " And for the examples in this video, I'm going to use as a running example the application", "tokens": [50364, 961, 311, 574, 412, 512, 9859, 3547, 337, 437, 508, 51, 7146, 293, 49802, 53, 1062, 312, 293, 536, 577, 291, 393, 50764, 50764, 6995, 498, 257, 2539, 9284, 575, 1090, 12577, 420, 1090, 21977, 13, 50978, 50978, 400, 337, 264, 5110, 294, 341, 960, 11, 286, 478, 516, 281, 764, 382, 257, 2614, 1365, 264, 3861, 51232, 51232, 295, 6218, 11150, 11, 597, 307, 746, 286, 600, 2732, 322, 3866, 1413, 670, 264, 924, 13, 51474, 51474, 961, 311, 747, 257, 574, 13, 51524, 51524, 316, 688, 295, 5022, 884, 3670, 3164, 322, 257, 6013, 2593, 486, 764, 6218, 11150, 2831, 813, 51846, 51846], "temperature": 0.0, "avg_logprob": -0.12916056018009364, "compression_ratio": 1.6066176470588236, "no_speech_prob": 0.0073429252952337265}, {"id": 3, "seek": 0, "start": 17.36, "end": 22.2, "text": " of speech recognition, which is something I've worked on multiple times over the years.", "tokens": [50364, 961, 311, 574, 412, 512, 9859, 3547, 337, 437, 508, 51, 7146, 293, 49802, 53, 1062, 312, 293, 536, 577, 291, 393, 50764, 50764, 6995, 498, 257, 2539, 9284, 575, 1090, 12577, 420, 1090, 21977, 13, 50978, 50978, 400, 337, 264, 5110, 294, 341, 960, 11, 286, 478, 516, 281, 764, 382, 257, 2614, 1365, 264, 3861, 51232, 51232, 295, 6218, 11150, 11, 597, 307, 746, 286, 600, 2732, 322, 3866, 1413, 670, 264, 924, 13, 51474, 51474, 961, 311, 747, 257, 574, 13, 51524, 51524, 316, 688, 295, 5022, 884, 3670, 3164, 322, 257, 6013, 2593, 486, 764, 6218, 11150, 2831, 813, 51846, 51846], "temperature": 0.0, "avg_logprob": -0.12916056018009364, "compression_ratio": 1.6066176470588236, "no_speech_prob": 0.0073429252952337265}, {"id": 4, "seek": 0, "start": 22.2, "end": 23.2, "text": " Let's take a look.", "tokens": [50364, 961, 311, 574, 412, 512, 9859, 3547, 337, 437, 508, 51, 7146, 293, 49802, 53, 1062, 312, 293, 536, 577, 291, 393, 50764, 50764, 6995, 498, 257, 2539, 9284, 575, 1090, 12577, 420, 1090, 21977, 13, 50978, 50978, 400, 337, 264, 5110, 294, 341, 960, 11, 286, 478, 516, 281, 764, 382, 257, 2614, 1365, 264, 3861, 51232, 51232, 295, 6218, 11150, 11, 597, 307, 746, 286, 600, 2732, 322, 3866, 1413, 670, 264, 924, 13, 51474, 51474, 961, 311, 747, 257, 574, 13, 51524, 51524, 316, 688, 295, 5022, 884, 3670, 3164, 322, 257, 6013, 2593, 486, 764, 6218, 11150, 2831, 813, 51846, 51846], "temperature": 0.0, "avg_logprob": -0.12916056018009364, "compression_ratio": 1.6066176470588236, "no_speech_prob": 0.0073429252952337265}, {"id": 5, "seek": 0, "start": 23.2, "end": 29.64, "text": " A lot of users doing web search on a mobile phone will use speech recognition rather than", "tokens": [50364, 961, 311, 574, 412, 512, 9859, 3547, 337, 437, 508, 51, 7146, 293, 49802, 53, 1062, 312, 293, 536, 577, 291, 393, 50764, 50764, 6995, 498, 257, 2539, 9284, 575, 1090, 12577, 420, 1090, 21977, 13, 50978, 50978, 400, 337, 264, 5110, 294, 341, 960, 11, 286, 478, 516, 281, 764, 382, 257, 2614, 1365, 264, 3861, 51232, 51232, 295, 6218, 11150, 11, 597, 307, 746, 286, 600, 2732, 322, 3866, 1413, 670, 264, 924, 13, 51474, 51474, 961, 311, 747, 257, 574, 13, 51524, 51524, 316, 688, 295, 5022, 884, 3670, 3164, 322, 257, 6013, 2593, 486, 764, 6218, 11150, 2831, 813, 51846, 51846], "temperature": 0.0, "avg_logprob": -0.12916056018009364, "compression_ratio": 1.6066176470588236, "no_speech_prob": 0.0073429252952337265}, {"id": 6, "seek": 2964, "start": 29.64, "end": 34.44, "text": " type on the tiny keyboards on their phones because speaking to a phone is often faster", "tokens": [50364, 2010, 322, 264, 5870, 47808, 322, 641, 10216, 570, 4124, 281, 257, 2593, 307, 2049, 4663, 50604, 50604, 813, 18444, 13, 50704, 50704, 400, 370, 7476, 6278, 300, 257, 3670, 3164, 2848, 576, 483, 576, 312, 411, 341, 13, 51008, 51008, 708, 307, 965, 311, 5503, 30, 51104, 51104, 1610, 411, 341, 13, 51154, 51154, 25481, 14457, 2651, 385, 13, 51240, 51240, 400, 456, 311, 264, 1691, 295, 264, 6218, 11150, 9284, 281, 5598, 264, 24444, 82, 11, 437, 51432, 51432, 307, 965, 311, 5503, 420, 4982, 14457, 2651, 385, 13, 51618, 51618], "temperature": 0.0, "avg_logprob": -0.21302189074064556, "compression_ratio": 1.695852534562212, "no_speech_prob": 6.30180657026358e-05}, {"id": 7, "seek": 2964, "start": 34.44, "end": 36.44, "text": " than typing.", "tokens": [50364, 2010, 322, 264, 5870, 47808, 322, 641, 10216, 570, 4124, 281, 257, 2593, 307, 2049, 4663, 50604, 50604, 813, 18444, 13, 50704, 50704, 400, 370, 7476, 6278, 300, 257, 3670, 3164, 2848, 576, 483, 576, 312, 411, 341, 13, 51008, 51008, 708, 307, 965, 311, 5503, 30, 51104, 51104, 1610, 411, 341, 13, 51154, 51154, 25481, 14457, 2651, 385, 13, 51240, 51240, 400, 456, 311, 264, 1691, 295, 264, 6218, 11150, 9284, 281, 5598, 264, 24444, 82, 11, 437, 51432, 51432, 307, 965, 311, 5503, 420, 4982, 14457, 2651, 385, 13, 51618, 51618], "temperature": 0.0, "avg_logprob": -0.21302189074064556, "compression_ratio": 1.695852534562212, "no_speech_prob": 6.30180657026358e-05}, {"id": 8, "seek": 2964, "start": 36.44, "end": 42.52, "text": " And so typical audio that a web search engine would get would be like this.", "tokens": [50364, 2010, 322, 264, 5870, 47808, 322, 641, 10216, 570, 4124, 281, 257, 2593, 307, 2049, 4663, 50604, 50604, 813, 18444, 13, 50704, 50704, 400, 370, 7476, 6278, 300, 257, 3670, 3164, 2848, 576, 483, 576, 312, 411, 341, 13, 51008, 51008, 708, 307, 965, 311, 5503, 30, 51104, 51104, 1610, 411, 341, 13, 51154, 51154, 25481, 14457, 2651, 385, 13, 51240, 51240, 400, 456, 311, 264, 1691, 295, 264, 6218, 11150, 9284, 281, 5598, 264, 24444, 82, 11, 437, 51432, 51432, 307, 965, 311, 5503, 420, 4982, 14457, 2651, 385, 13, 51618, 51618], "temperature": 0.0, "avg_logprob": -0.21302189074064556, "compression_ratio": 1.695852534562212, "no_speech_prob": 6.30180657026358e-05}, {"id": 9, "seek": 2964, "start": 42.52, "end": 44.44, "text": " What is today's weather?", "tokens": [50364, 2010, 322, 264, 5870, 47808, 322, 641, 10216, 570, 4124, 281, 257, 2593, 307, 2049, 4663, 50604, 50604, 813, 18444, 13, 50704, 50704, 400, 370, 7476, 6278, 300, 257, 3670, 3164, 2848, 576, 483, 576, 312, 411, 341, 13, 51008, 51008, 708, 307, 965, 311, 5503, 30, 51104, 51104, 1610, 411, 341, 13, 51154, 51154, 25481, 14457, 2651, 385, 13, 51240, 51240, 400, 456, 311, 264, 1691, 295, 264, 6218, 11150, 9284, 281, 5598, 264, 24444, 82, 11, 437, 51432, 51432, 307, 965, 311, 5503, 420, 4982, 14457, 2651, 385, 13, 51618, 51618], "temperature": 0.0, "avg_logprob": -0.21302189074064556, "compression_ratio": 1.695852534562212, "no_speech_prob": 6.30180657026358e-05}, {"id": 10, "seek": 2964, "start": 44.44, "end": 45.44, "text": " Or like this.", "tokens": [50364, 2010, 322, 264, 5870, 47808, 322, 641, 10216, 570, 4124, 281, 257, 2593, 307, 2049, 4663, 50604, 50604, 813, 18444, 13, 50704, 50704, 400, 370, 7476, 6278, 300, 257, 3670, 3164, 2848, 576, 483, 576, 312, 411, 341, 13, 51008, 51008, 708, 307, 965, 311, 5503, 30, 51104, 51104, 1610, 411, 341, 13, 51154, 51154, 25481, 14457, 2651, 385, 13, 51240, 51240, 400, 456, 311, 264, 1691, 295, 264, 6218, 11150, 9284, 281, 5598, 264, 24444, 82, 11, 437, 51432, 51432, 307, 965, 311, 5503, 420, 4982, 14457, 2651, 385, 13, 51618, 51618], "temperature": 0.0, "avg_logprob": -0.21302189074064556, "compression_ratio": 1.695852534562212, "no_speech_prob": 6.30180657026358e-05}, {"id": 11, "seek": 2964, "start": 45.44, "end": 47.16, "text": " Coffee shops near me.", "tokens": [50364, 2010, 322, 264, 5870, 47808, 322, 641, 10216, 570, 4124, 281, 257, 2593, 307, 2049, 4663, 50604, 50604, 813, 18444, 13, 50704, 50704, 400, 370, 7476, 6278, 300, 257, 3670, 3164, 2848, 576, 483, 576, 312, 411, 341, 13, 51008, 51008, 708, 307, 965, 311, 5503, 30, 51104, 51104, 1610, 411, 341, 13, 51154, 51154, 25481, 14457, 2651, 385, 13, 51240, 51240, 400, 456, 311, 264, 1691, 295, 264, 6218, 11150, 9284, 281, 5598, 264, 24444, 82, 11, 437, 51432, 51432, 307, 965, 311, 5503, 420, 4982, 14457, 2651, 385, 13, 51618, 51618], "temperature": 0.0, "avg_logprob": -0.21302189074064556, "compression_ratio": 1.695852534562212, "no_speech_prob": 6.30180657026358e-05}, {"id": 12, "seek": 2964, "start": 47.16, "end": 51.0, "text": " And there's the job of the speech recognition algorithm to output the transcripts, what", "tokens": [50364, 2010, 322, 264, 5870, 47808, 322, 641, 10216, 570, 4124, 281, 257, 2593, 307, 2049, 4663, 50604, 50604, 813, 18444, 13, 50704, 50704, 400, 370, 7476, 6278, 300, 257, 3670, 3164, 2848, 576, 483, 576, 312, 411, 341, 13, 51008, 51008, 708, 307, 965, 311, 5503, 30, 51104, 51104, 1610, 411, 341, 13, 51154, 51154, 25481, 14457, 2651, 385, 13, 51240, 51240, 400, 456, 311, 264, 1691, 295, 264, 6218, 11150, 9284, 281, 5598, 264, 24444, 82, 11, 437, 51432, 51432, 307, 965, 311, 5503, 420, 4982, 14457, 2651, 385, 13, 51618, 51618], "temperature": 0.0, "avg_logprob": -0.21302189074064556, "compression_ratio": 1.695852534562212, "no_speech_prob": 6.30180657026358e-05}, {"id": 13, "seek": 2964, "start": 51.0, "end": 54.72, "text": " is today's weather or coffee shops near me.", "tokens": [50364, 2010, 322, 264, 5870, 47808, 322, 641, 10216, 570, 4124, 281, 257, 2593, 307, 2049, 4663, 50604, 50604, 813, 18444, 13, 50704, 50704, 400, 370, 7476, 6278, 300, 257, 3670, 3164, 2848, 576, 483, 576, 312, 411, 341, 13, 51008, 51008, 708, 307, 965, 311, 5503, 30, 51104, 51104, 1610, 411, 341, 13, 51154, 51154, 25481, 14457, 2651, 385, 13, 51240, 51240, 400, 456, 311, 264, 1691, 295, 264, 6218, 11150, 9284, 281, 5598, 264, 24444, 82, 11, 437, 51432, 51432, 307, 965, 311, 5503, 420, 4982, 14457, 2651, 385, 13, 51618, 51618], "temperature": 0.0, "avg_logprob": -0.21302189074064556, "compression_ratio": 1.695852534562212, "no_speech_prob": 6.30180657026358e-05}, {"id": 14, "seek": 5472, "start": 54.72, "end": 61.04, "text": " Now if you were to train a speech recognition system and measure the training error, and", "tokens": [50364, 823, 498, 291, 645, 281, 3847, 257, 6218, 11150, 1185, 293, 3481, 264, 3097, 6713, 11, 293, 50680, 50680, 264, 3097, 6713, 1355, 437, 311, 264, 9668, 295, 6278, 13117, 294, 428, 3097, 992, 300, 264, 50966, 50966, 9284, 775, 406, 1145, 8056, 8944, 294, 1080, 31557, 13, 51172, 51172, 961, 311, 584, 264, 3097, 6713, 337, 341, 1412, 992, 307, 1266, 13, 23, 8923, 3620, 300, 309, 1145, 1142, 6446, 51496, 51496], "temperature": 0.0, "avg_logprob": -0.11395200093587239, "compression_ratio": 1.694736842105263, "no_speech_prob": 5.2551681619661395e-06}, {"id": 15, "seek": 5472, "start": 61.04, "end": 66.76, "text": " the training error means what's the percentage of audio clips in your training set that the", "tokens": [50364, 823, 498, 291, 645, 281, 3847, 257, 6218, 11150, 1185, 293, 3481, 264, 3097, 6713, 11, 293, 50680, 50680, 264, 3097, 6713, 1355, 437, 311, 264, 9668, 295, 6278, 13117, 294, 428, 3097, 992, 300, 264, 50966, 50966, 9284, 775, 406, 1145, 8056, 8944, 294, 1080, 31557, 13, 51172, 51172, 961, 311, 584, 264, 3097, 6713, 337, 341, 1412, 992, 307, 1266, 13, 23, 8923, 3620, 300, 309, 1145, 1142, 6446, 51496, 51496], "temperature": 0.0, "avg_logprob": -0.11395200093587239, "compression_ratio": 1.694736842105263, "no_speech_prob": 5.2551681619661395e-06}, {"id": 16, "seek": 5472, "start": 66.76, "end": 70.88, "text": " algorithm does not transcribe correctly in its entirety.", "tokens": [50364, 823, 498, 291, 645, 281, 3847, 257, 6218, 11150, 1185, 293, 3481, 264, 3097, 6713, 11, 293, 50680, 50680, 264, 3097, 6713, 1355, 437, 311, 264, 9668, 295, 6278, 13117, 294, 428, 3097, 992, 300, 264, 50966, 50966, 9284, 775, 406, 1145, 8056, 8944, 294, 1080, 31557, 13, 51172, 51172, 961, 311, 584, 264, 3097, 6713, 337, 341, 1412, 992, 307, 1266, 13, 23, 8923, 3620, 300, 309, 1145, 1142, 6446, 51496, 51496], "temperature": 0.0, "avg_logprob": -0.11395200093587239, "compression_ratio": 1.694736842105263, "no_speech_prob": 5.2551681619661395e-06}, {"id": 17, "seek": 5472, "start": 70.88, "end": 77.36, "text": " Let's say the training error for this data set is 10.8%, meaning that it transcribes", "tokens": [50364, 823, 498, 291, 645, 281, 3847, 257, 6218, 11150, 1185, 293, 3481, 264, 3097, 6713, 11, 293, 50680, 50680, 264, 3097, 6713, 1355, 437, 311, 264, 9668, 295, 6278, 13117, 294, 428, 3097, 992, 300, 264, 50966, 50966, 9284, 775, 406, 1145, 8056, 8944, 294, 1080, 31557, 13, 51172, 51172, 961, 311, 584, 264, 3097, 6713, 337, 341, 1412, 992, 307, 1266, 13, 23, 8923, 3620, 300, 309, 1145, 1142, 6446, 51496, 51496], "temperature": 0.0, "avg_logprob": -0.11395200093587239, "compression_ratio": 1.694736842105263, "no_speech_prob": 5.2551681619661395e-06}, {"id": 18, "seek": 7736, "start": 77.36, "end": 85.28, "text": " it perfectly for 89.2% of your training set, but makes some mistake in 10.8% of your training", "tokens": [50364, 309, 6239, 337, 31877, 13, 17, 4, 295, 428, 3097, 992, 11, 457, 1669, 512, 6146, 294, 1266, 13, 23, 4, 295, 428, 3097, 50760, 50760, 992, 13, 50834, 50834, 400, 498, 291, 645, 281, 611, 3481, 428, 6218, 11150, 9284, 311, 3389, 322, 257, 4994, 51086, 51086, 3278, 12, 3337, 327, 399, 992, 11, 718, 311, 584, 309, 2170, 3499, 13, 23, 4, 6713, 13, 51394, 51394, 407, 498, 291, 645, 281, 574, 412, 613, 3547, 11, 309, 1542, 411, 264, 3097, 6713, 307, 534, 1090, 11, 51658, 51658], "temperature": 0.0, "avg_logprob": -0.10740118441374405, "compression_ratio": 1.6028708133971292, "no_speech_prob": 1.0844954658750794e-06}, {"id": 19, "seek": 7736, "start": 85.28, "end": 86.76, "text": " set.", "tokens": [50364, 309, 6239, 337, 31877, 13, 17, 4, 295, 428, 3097, 992, 11, 457, 1669, 512, 6146, 294, 1266, 13, 23, 4, 295, 428, 3097, 50760, 50760, 992, 13, 50834, 50834, 400, 498, 291, 645, 281, 611, 3481, 428, 6218, 11150, 9284, 311, 3389, 322, 257, 4994, 51086, 51086, 3278, 12, 3337, 327, 399, 992, 11, 718, 311, 584, 309, 2170, 3499, 13, 23, 4, 6713, 13, 51394, 51394, 407, 498, 291, 645, 281, 574, 412, 613, 3547, 11, 309, 1542, 411, 264, 3097, 6713, 307, 534, 1090, 11, 51658, 51658], "temperature": 0.0, "avg_logprob": -0.10740118441374405, "compression_ratio": 1.6028708133971292, "no_speech_prob": 1.0844954658750794e-06}, {"id": 20, "seek": 7736, "start": 86.76, "end": 91.8, "text": " And if you were to also measure your speech recognition algorithm's performance on a separate", "tokens": [50364, 309, 6239, 337, 31877, 13, 17, 4, 295, 428, 3097, 992, 11, 457, 1669, 512, 6146, 294, 1266, 13, 23, 4, 295, 428, 3097, 50760, 50760, 992, 13, 50834, 50834, 400, 498, 291, 645, 281, 611, 3481, 428, 6218, 11150, 9284, 311, 3389, 322, 257, 4994, 51086, 51086, 3278, 12, 3337, 327, 399, 992, 11, 718, 311, 584, 309, 2170, 3499, 13, 23, 4, 6713, 13, 51394, 51394, 407, 498, 291, 645, 281, 574, 412, 613, 3547, 11, 309, 1542, 411, 264, 3097, 6713, 307, 534, 1090, 11, 51658, 51658], "temperature": 0.0, "avg_logprob": -0.10740118441374405, "compression_ratio": 1.6028708133971292, "no_speech_prob": 1.0844954658750794e-06}, {"id": 21, "seek": 7736, "start": 91.8, "end": 97.96000000000001, "text": " cross-validation set, let's say it gets 14.8% error.", "tokens": [50364, 309, 6239, 337, 31877, 13, 17, 4, 295, 428, 3097, 992, 11, 457, 1669, 512, 6146, 294, 1266, 13, 23, 4, 295, 428, 3097, 50760, 50760, 992, 13, 50834, 50834, 400, 498, 291, 645, 281, 611, 3481, 428, 6218, 11150, 9284, 311, 3389, 322, 257, 4994, 51086, 51086, 3278, 12, 3337, 327, 399, 992, 11, 718, 311, 584, 309, 2170, 3499, 13, 23, 4, 6713, 13, 51394, 51394, 407, 498, 291, 645, 281, 574, 412, 613, 3547, 11, 309, 1542, 411, 264, 3097, 6713, 307, 534, 1090, 11, 51658, 51658], "temperature": 0.0, "avg_logprob": -0.10740118441374405, "compression_ratio": 1.6028708133971292, "no_speech_prob": 1.0844954658750794e-06}, {"id": 22, "seek": 7736, "start": 97.96000000000001, "end": 103.24, "text": " So if you were to look at these numbers, it looks like the training error is really high,", "tokens": [50364, 309, 6239, 337, 31877, 13, 17, 4, 295, 428, 3097, 992, 11, 457, 1669, 512, 6146, 294, 1266, 13, 23, 4, 295, 428, 3097, 50760, 50760, 992, 13, 50834, 50834, 400, 498, 291, 645, 281, 611, 3481, 428, 6218, 11150, 9284, 311, 3389, 322, 257, 4994, 51086, 51086, 3278, 12, 3337, 327, 399, 992, 11, 718, 311, 584, 309, 2170, 3499, 13, 23, 4, 6713, 13, 51394, 51394, 407, 498, 291, 645, 281, 574, 412, 613, 3547, 11, 309, 1542, 411, 264, 3097, 6713, 307, 534, 1090, 11, 51658, 51658], "temperature": 0.0, "avg_logprob": -0.10740118441374405, "compression_ratio": 1.6028708133971292, "no_speech_prob": 1.0844954658750794e-06}, {"id": 23, "seek": 10324, "start": 103.24, "end": 109.52, "text": " it got 10% wrong, and then the cross-validation error is higher, but getting 10% of even your", "tokens": [50364, 309, 658, 1266, 4, 2085, 11, 293, 550, 264, 3278, 12, 3337, 327, 399, 6713, 307, 2946, 11, 457, 1242, 1266, 4, 295, 754, 428, 50678, 50678, 3097, 992, 2085, 11, 300, 2544, 1238, 1090, 13, 50842, 50842, 400, 309, 2544, 411, 300, 1266, 4, 6713, 576, 1477, 291, 281, 16886, 309, 575, 281, 362, 1090, 12577, 570, 51082, 51082, 309, 311, 406, 884, 731, 322, 428, 3097, 992, 13, 51190, 51190, 583, 309, 4523, 484, 300, 562, 23663, 6218, 11150, 11, 309, 311, 4420, 281, 611, 3481, 472, 51476, 51476, 661, 551, 11, 597, 307, 437, 307, 264, 1952, 1496, 295, 3389, 13, 51738, 51738], "temperature": 0.0, "avg_logprob": -0.10019810994466145, "compression_ratio": 1.6588235294117648, "no_speech_prob": 1.3709401400774368e-06}, {"id": 24, "seek": 10324, "start": 109.52, "end": 112.8, "text": " training set wrong, that seems pretty high.", "tokens": [50364, 309, 658, 1266, 4, 2085, 11, 293, 550, 264, 3278, 12, 3337, 327, 399, 6713, 307, 2946, 11, 457, 1242, 1266, 4, 295, 754, 428, 50678, 50678, 3097, 992, 2085, 11, 300, 2544, 1238, 1090, 13, 50842, 50842, 400, 309, 2544, 411, 300, 1266, 4, 6713, 576, 1477, 291, 281, 16886, 309, 575, 281, 362, 1090, 12577, 570, 51082, 51082, 309, 311, 406, 884, 731, 322, 428, 3097, 992, 13, 51190, 51190, 583, 309, 4523, 484, 300, 562, 23663, 6218, 11150, 11, 309, 311, 4420, 281, 611, 3481, 472, 51476, 51476, 661, 551, 11, 597, 307, 437, 307, 264, 1952, 1496, 295, 3389, 13, 51738, 51738], "temperature": 0.0, "avg_logprob": -0.10019810994466145, "compression_ratio": 1.6588235294117648, "no_speech_prob": 1.3709401400774368e-06}, {"id": 25, "seek": 10324, "start": 112.8, "end": 117.6, "text": " And it seems like that 10% error would lead you to conclude it has to have high bias because", "tokens": [50364, 309, 658, 1266, 4, 2085, 11, 293, 550, 264, 3278, 12, 3337, 327, 399, 6713, 307, 2946, 11, 457, 1242, 1266, 4, 295, 754, 428, 50678, 50678, 3097, 992, 2085, 11, 300, 2544, 1238, 1090, 13, 50842, 50842, 400, 309, 2544, 411, 300, 1266, 4, 6713, 576, 1477, 291, 281, 16886, 309, 575, 281, 362, 1090, 12577, 570, 51082, 51082, 309, 311, 406, 884, 731, 322, 428, 3097, 992, 13, 51190, 51190, 583, 309, 4523, 484, 300, 562, 23663, 6218, 11150, 11, 309, 311, 4420, 281, 611, 3481, 472, 51476, 51476, 661, 551, 11, 597, 307, 437, 307, 264, 1952, 1496, 295, 3389, 13, 51738, 51738], "temperature": 0.0, "avg_logprob": -0.10019810994466145, "compression_ratio": 1.6588235294117648, "no_speech_prob": 1.3709401400774368e-06}, {"id": 26, "seek": 10324, "start": 117.6, "end": 119.75999999999999, "text": " it's not doing well on your training set.", "tokens": [50364, 309, 658, 1266, 4, 2085, 11, 293, 550, 264, 3278, 12, 3337, 327, 399, 6713, 307, 2946, 11, 457, 1242, 1266, 4, 295, 754, 428, 50678, 50678, 3097, 992, 2085, 11, 300, 2544, 1238, 1090, 13, 50842, 50842, 400, 309, 2544, 411, 300, 1266, 4, 6713, 576, 1477, 291, 281, 16886, 309, 575, 281, 362, 1090, 12577, 570, 51082, 51082, 309, 311, 406, 884, 731, 322, 428, 3097, 992, 13, 51190, 51190, 583, 309, 4523, 484, 300, 562, 23663, 6218, 11150, 11, 309, 311, 4420, 281, 611, 3481, 472, 51476, 51476, 661, 551, 11, 597, 307, 437, 307, 264, 1952, 1496, 295, 3389, 13, 51738, 51738], "temperature": 0.0, "avg_logprob": -0.10019810994466145, "compression_ratio": 1.6588235294117648, "no_speech_prob": 1.3709401400774368e-06}, {"id": 27, "seek": 10324, "start": 119.75999999999999, "end": 125.47999999999999, "text": " But it turns out that when analyzing speech recognition, it's useful to also measure one", "tokens": [50364, 309, 658, 1266, 4, 2085, 11, 293, 550, 264, 3278, 12, 3337, 327, 399, 6713, 307, 2946, 11, 457, 1242, 1266, 4, 295, 754, 428, 50678, 50678, 3097, 992, 2085, 11, 300, 2544, 1238, 1090, 13, 50842, 50842, 400, 309, 2544, 411, 300, 1266, 4, 6713, 576, 1477, 291, 281, 16886, 309, 575, 281, 362, 1090, 12577, 570, 51082, 51082, 309, 311, 406, 884, 731, 322, 428, 3097, 992, 13, 51190, 51190, 583, 309, 4523, 484, 300, 562, 23663, 6218, 11150, 11, 309, 311, 4420, 281, 611, 3481, 472, 51476, 51476, 661, 551, 11, 597, 307, 437, 307, 264, 1952, 1496, 295, 3389, 13, 51738, 51738], "temperature": 0.0, "avg_logprob": -0.10019810994466145, "compression_ratio": 1.6588235294117648, "no_speech_prob": 1.3709401400774368e-06}, {"id": 28, "seek": 10324, "start": 125.47999999999999, "end": 130.72, "text": " other thing, which is what is the human level of performance.", "tokens": [50364, 309, 658, 1266, 4, 2085, 11, 293, 550, 264, 3278, 12, 3337, 327, 399, 6713, 307, 2946, 11, 457, 1242, 1266, 4, 295, 754, 428, 50678, 50678, 3097, 992, 2085, 11, 300, 2544, 1238, 1090, 13, 50842, 50842, 400, 309, 2544, 411, 300, 1266, 4, 6713, 576, 1477, 291, 281, 16886, 309, 575, 281, 362, 1090, 12577, 570, 51082, 51082, 309, 311, 406, 884, 731, 322, 428, 3097, 992, 13, 51190, 51190, 583, 309, 4523, 484, 300, 562, 23663, 6218, 11150, 11, 309, 311, 4420, 281, 611, 3481, 472, 51476, 51476, 661, 551, 11, 597, 307, 437, 307, 264, 1952, 1496, 295, 3389, 13, 51738, 51738], "temperature": 0.0, "avg_logprob": -0.10019810994466145, "compression_ratio": 1.6588235294117648, "no_speech_prob": 1.3709401400774368e-06}, {"id": 29, "seek": 13072, "start": 130.72, "end": 136.72, "text": " In other words, how well can even humans transcribe speech accurately from these audio clips?", "tokens": [50364, 682, 661, 2283, 11, 577, 731, 393, 754, 6255, 1145, 8056, 6218, 20095, 490, 613, 6278, 13117, 30, 50664, 50664, 400, 39481, 736, 11, 718, 311, 584, 300, 291, 3481, 577, 731, 40799, 9518, 393, 1145, 8056, 6278, 51040, 51040, 13117, 293, 291, 915, 300, 309, 307, 1266, 13, 21, 8923, 293, 291, 915, 300, 1952, 1496, 3389, 3538, 977, 51344, 51344, 1266, 13, 21, 4, 6713, 13, 51496, 51496, 1545, 307, 1952, 1496, 6713, 370, 1090, 30, 51686, 51686], "temperature": 0.0, "avg_logprob": -0.11610127658378787, "compression_ratio": 1.6256410256410256, "no_speech_prob": 2.2603076104132924e-06}, {"id": 30, "seek": 13072, "start": 136.72, "end": 144.24, "text": " And concretely, let's say that you measure how well fluent speakers can transcribe audio", "tokens": [50364, 682, 661, 2283, 11, 577, 731, 393, 754, 6255, 1145, 8056, 6218, 20095, 490, 613, 6278, 13117, 30, 50664, 50664, 400, 39481, 736, 11, 718, 311, 584, 300, 291, 3481, 577, 731, 40799, 9518, 393, 1145, 8056, 6278, 51040, 51040, 13117, 293, 291, 915, 300, 309, 307, 1266, 13, 21, 8923, 293, 291, 915, 300, 1952, 1496, 3389, 3538, 977, 51344, 51344, 1266, 13, 21, 4, 6713, 13, 51496, 51496, 1545, 307, 1952, 1496, 6713, 370, 1090, 30, 51686, 51686], "temperature": 0.0, "avg_logprob": -0.11610127658378787, "compression_ratio": 1.6256410256410256, "no_speech_prob": 2.2603076104132924e-06}, {"id": 31, "seek": 13072, "start": 144.24, "end": 150.32, "text": " clips and you find that it is 10.6%, and you find that human level performance achieves", "tokens": [50364, 682, 661, 2283, 11, 577, 731, 393, 754, 6255, 1145, 8056, 6218, 20095, 490, 613, 6278, 13117, 30, 50664, 50664, 400, 39481, 736, 11, 718, 311, 584, 300, 291, 3481, 577, 731, 40799, 9518, 393, 1145, 8056, 6278, 51040, 51040, 13117, 293, 291, 915, 300, 309, 307, 1266, 13, 21, 8923, 293, 291, 915, 300, 1952, 1496, 3389, 3538, 977, 51344, 51344, 1266, 13, 21, 4, 6713, 13, 51496, 51496, 1545, 307, 1952, 1496, 6713, 370, 1090, 30, 51686, 51686], "temperature": 0.0, "avg_logprob": -0.11610127658378787, "compression_ratio": 1.6256410256410256, "no_speech_prob": 2.2603076104132924e-06}, {"id": 32, "seek": 13072, "start": 150.32, "end": 153.36, "text": " 10.6% error.", "tokens": [50364, 682, 661, 2283, 11, 577, 731, 393, 754, 6255, 1145, 8056, 6218, 20095, 490, 613, 6278, 13117, 30, 50664, 50664, 400, 39481, 736, 11, 718, 311, 584, 300, 291, 3481, 577, 731, 40799, 9518, 393, 1145, 8056, 6278, 51040, 51040, 13117, 293, 291, 915, 300, 309, 307, 1266, 13, 21, 8923, 293, 291, 915, 300, 1952, 1496, 3389, 3538, 977, 51344, 51344, 1266, 13, 21, 4, 6713, 13, 51496, 51496, 1545, 307, 1952, 1496, 6713, 370, 1090, 30, 51686, 51686], "temperature": 0.0, "avg_logprob": -0.11610127658378787, "compression_ratio": 1.6256410256410256, "no_speech_prob": 2.2603076104132924e-06}, {"id": 33, "seek": 13072, "start": 153.36, "end": 157.16, "text": " Why is human level error so high?", "tokens": [50364, 682, 661, 2283, 11, 577, 731, 393, 754, 6255, 1145, 8056, 6218, 20095, 490, 613, 6278, 13117, 30, 50664, 50664, 400, 39481, 736, 11, 718, 311, 584, 300, 291, 3481, 577, 731, 40799, 9518, 393, 1145, 8056, 6278, 51040, 51040, 13117, 293, 291, 915, 300, 309, 307, 1266, 13, 21, 8923, 293, 291, 915, 300, 1952, 1496, 3389, 3538, 977, 51344, 51344, 1266, 13, 21, 4, 6713, 13, 51496, 51496, 1545, 307, 1952, 1496, 6713, 370, 1090, 30, 51686, 51686], "temperature": 0.0, "avg_logprob": -0.11610127658378787, "compression_ratio": 1.6256410256410256, "no_speech_prob": 2.2603076104132924e-06}, {"id": 34, "seek": 15716, "start": 157.16, "end": 163.0, "text": " It turns out that for web search, there are a lot of audio clips that sound like this.", "tokens": [50364, 467, 4523, 484, 300, 337, 3670, 3164, 11, 456, 366, 257, 688, 295, 6278, 13117, 300, 1626, 411, 341, 13, 50656, 50656, 286, 478, 516, 281, 12350, 281, 4079, 322, 264, 485, 50834, 50834, 400, 456, 311, 257, 688, 295, 24518, 6278, 689, 534, 572, 472, 393, 20095, 1145, 8056, 437, 390, 51086, 51086, 848, 570, 295, 264, 5658, 294, 264, 6278, 13, 51257, 51257, 400, 498, 754, 257, 1952, 1669, 1266, 13, 21, 4, 6713, 11, 550, 309, 2544, 2252, 281, 2066, 257, 2539, 9284, 51630, 51630, 281, 360, 709, 1101, 13, 51706, 51706], "temperature": 0.0, "avg_logprob": -0.14377546802009503, "compression_ratio": 1.576271186440678, "no_speech_prob": 7.646402082173154e-06}, {"id": 35, "seek": 15716, "start": 163.0, "end": 166.56, "text": " I'm going to navigate to somewhere on the...", "tokens": [50364, 467, 4523, 484, 300, 337, 3670, 3164, 11, 456, 366, 257, 688, 295, 6278, 13117, 300, 1626, 411, 341, 13, 50656, 50656, 286, 478, 516, 281, 12350, 281, 4079, 322, 264, 485, 50834, 50834, 400, 456, 311, 257, 688, 295, 24518, 6278, 689, 534, 572, 472, 393, 20095, 1145, 8056, 437, 390, 51086, 51086, 848, 570, 295, 264, 5658, 294, 264, 6278, 13, 51257, 51257, 400, 498, 754, 257, 1952, 1669, 1266, 13, 21, 4, 6713, 11, 550, 309, 2544, 2252, 281, 2066, 257, 2539, 9284, 51630, 51630, 281, 360, 709, 1101, 13, 51706, 51706], "temperature": 0.0, "avg_logprob": -0.14377546802009503, "compression_ratio": 1.576271186440678, "no_speech_prob": 7.646402082173154e-06}, {"id": 36, "seek": 15716, "start": 166.56, "end": 171.6, "text": " And there's a lot of noisy audio where really no one can accurately transcribe what was", "tokens": [50364, 467, 4523, 484, 300, 337, 3670, 3164, 11, 456, 366, 257, 688, 295, 6278, 13117, 300, 1626, 411, 341, 13, 50656, 50656, 286, 478, 516, 281, 12350, 281, 4079, 322, 264, 485, 50834, 50834, 400, 456, 311, 257, 688, 295, 24518, 6278, 689, 534, 572, 472, 393, 20095, 1145, 8056, 437, 390, 51086, 51086, 848, 570, 295, 264, 5658, 294, 264, 6278, 13, 51257, 51257, 400, 498, 754, 257, 1952, 1669, 1266, 13, 21, 4, 6713, 11, 550, 309, 2544, 2252, 281, 2066, 257, 2539, 9284, 51630, 51630, 281, 360, 709, 1101, 13, 51706, 51706], "temperature": 0.0, "avg_logprob": -0.14377546802009503, "compression_ratio": 1.576271186440678, "no_speech_prob": 7.646402082173154e-06}, {"id": 37, "seek": 15716, "start": 171.6, "end": 175.01999999999998, "text": " said because of the noise in the audio.", "tokens": [50364, 467, 4523, 484, 300, 337, 3670, 3164, 11, 456, 366, 257, 688, 295, 6278, 13117, 300, 1626, 411, 341, 13, 50656, 50656, 286, 478, 516, 281, 12350, 281, 4079, 322, 264, 485, 50834, 50834, 400, 456, 311, 257, 688, 295, 24518, 6278, 689, 534, 572, 472, 393, 20095, 1145, 8056, 437, 390, 51086, 51086, 848, 570, 295, 264, 5658, 294, 264, 6278, 13, 51257, 51257, 400, 498, 754, 257, 1952, 1669, 1266, 13, 21, 4, 6713, 11, 550, 309, 2544, 2252, 281, 2066, 257, 2539, 9284, 51630, 51630, 281, 360, 709, 1101, 13, 51706, 51706], "temperature": 0.0, "avg_logprob": -0.14377546802009503, "compression_ratio": 1.576271186440678, "no_speech_prob": 7.646402082173154e-06}, {"id": 38, "seek": 15716, "start": 175.01999999999998, "end": 182.48, "text": " And if even a human makes 10.6% error, then it seems difficult to expect a learning algorithm", "tokens": [50364, 467, 4523, 484, 300, 337, 3670, 3164, 11, 456, 366, 257, 688, 295, 6278, 13117, 300, 1626, 411, 341, 13, 50656, 50656, 286, 478, 516, 281, 12350, 281, 4079, 322, 264, 485, 50834, 50834, 400, 456, 311, 257, 688, 295, 24518, 6278, 689, 534, 572, 472, 393, 20095, 1145, 8056, 437, 390, 51086, 51086, 848, 570, 295, 264, 5658, 294, 264, 6278, 13, 51257, 51257, 400, 498, 754, 257, 1952, 1669, 1266, 13, 21, 4, 6713, 11, 550, 309, 2544, 2252, 281, 2066, 257, 2539, 9284, 51630, 51630, 281, 360, 709, 1101, 13, 51706, 51706], "temperature": 0.0, "avg_logprob": -0.14377546802009503, "compression_ratio": 1.576271186440678, "no_speech_prob": 7.646402082173154e-06}, {"id": 39, "seek": 15716, "start": 182.48, "end": 184.0, "text": " to do much better.", "tokens": [50364, 467, 4523, 484, 300, 337, 3670, 3164, 11, 456, 366, 257, 688, 295, 6278, 13117, 300, 1626, 411, 341, 13, 50656, 50656, 286, 478, 516, 281, 12350, 281, 4079, 322, 264, 485, 50834, 50834, 400, 456, 311, 257, 688, 295, 24518, 6278, 689, 534, 572, 472, 393, 20095, 1145, 8056, 437, 390, 51086, 51086, 848, 570, 295, 264, 5658, 294, 264, 6278, 13, 51257, 51257, 400, 498, 754, 257, 1952, 1669, 1266, 13, 21, 4, 6713, 11, 550, 309, 2544, 2252, 281, 2066, 257, 2539, 9284, 51630, 51630, 281, 360, 709, 1101, 13, 51706, 51706], "temperature": 0.0, "avg_logprob": -0.14377546802009503, "compression_ratio": 1.576271186440678, "no_speech_prob": 7.646402082173154e-06}, {"id": 40, "seek": 18400, "start": 184.0, "end": 190.08, "text": " And so in order to judge if the training error is high, it turns out to be more useful to", "tokens": [50364, 400, 370, 294, 1668, 281, 6995, 498, 264, 3097, 6713, 307, 1090, 11, 309, 4523, 484, 281, 312, 544, 4420, 281, 50668, 50668, 536, 498, 264, 3097, 6713, 307, 709, 2946, 813, 257, 1952, 1496, 295, 3389, 13, 50958, 50958, 400, 294, 341, 1365, 11, 309, 775, 445, 1958, 13, 17, 4, 5324, 813, 6255, 13, 51170, 51170, 18600, 300, 6255, 366, 767, 534, 665, 412, 18538, 6218, 11, 286, 519, 498, 286, 393, 1322, 51346, 51346, 257, 6218, 11150, 1185, 300, 3538, 977, 1266, 13, 21, 4, 6713, 14324, 1952, 3389, 11, 286, 1116, 51602, 51602, 312, 1238, 2055, 13, 51652, 51652, 407, 309, 311, 445, 884, 257, 707, 857, 5324, 813, 6255, 13, 51814, 51814], "temperature": 0.0, "avg_logprob": -0.10008130754743304, "compression_ratio": 1.713235294117647, "no_speech_prob": 3.989649997038214e-07}, {"id": 41, "seek": 18400, "start": 190.08, "end": 195.88, "text": " see if the training error is much higher than a human level of performance.", "tokens": [50364, 400, 370, 294, 1668, 281, 6995, 498, 264, 3097, 6713, 307, 1090, 11, 309, 4523, 484, 281, 312, 544, 4420, 281, 50668, 50668, 536, 498, 264, 3097, 6713, 307, 709, 2946, 813, 257, 1952, 1496, 295, 3389, 13, 50958, 50958, 400, 294, 341, 1365, 11, 309, 775, 445, 1958, 13, 17, 4, 5324, 813, 6255, 13, 51170, 51170, 18600, 300, 6255, 366, 767, 534, 665, 412, 18538, 6218, 11, 286, 519, 498, 286, 393, 1322, 51346, 51346, 257, 6218, 11150, 1185, 300, 3538, 977, 1266, 13, 21, 4, 6713, 14324, 1952, 3389, 11, 286, 1116, 51602, 51602, 312, 1238, 2055, 13, 51652, 51652, 407, 309, 311, 445, 884, 257, 707, 857, 5324, 813, 6255, 13, 51814, 51814], "temperature": 0.0, "avg_logprob": -0.10008130754743304, "compression_ratio": 1.713235294117647, "no_speech_prob": 3.989649997038214e-07}, {"id": 42, "seek": 18400, "start": 195.88, "end": 200.12, "text": " And in this example, it does just 0.2% worse than humans.", "tokens": [50364, 400, 370, 294, 1668, 281, 6995, 498, 264, 3097, 6713, 307, 1090, 11, 309, 4523, 484, 281, 312, 544, 4420, 281, 50668, 50668, 536, 498, 264, 3097, 6713, 307, 709, 2946, 813, 257, 1952, 1496, 295, 3389, 13, 50958, 50958, 400, 294, 341, 1365, 11, 309, 775, 445, 1958, 13, 17, 4, 5324, 813, 6255, 13, 51170, 51170, 18600, 300, 6255, 366, 767, 534, 665, 412, 18538, 6218, 11, 286, 519, 498, 286, 393, 1322, 51346, 51346, 257, 6218, 11150, 1185, 300, 3538, 977, 1266, 13, 21, 4, 6713, 14324, 1952, 3389, 11, 286, 1116, 51602, 51602, 312, 1238, 2055, 13, 51652, 51652, 407, 309, 311, 445, 884, 257, 707, 857, 5324, 813, 6255, 13, 51814, 51814], "temperature": 0.0, "avg_logprob": -0.10008130754743304, "compression_ratio": 1.713235294117647, "no_speech_prob": 3.989649997038214e-07}, {"id": 43, "seek": 18400, "start": 200.12, "end": 203.64, "text": " Given that humans are actually really good at recognizing speech, I think if I can build", "tokens": [50364, 400, 370, 294, 1668, 281, 6995, 498, 264, 3097, 6713, 307, 1090, 11, 309, 4523, 484, 281, 312, 544, 4420, 281, 50668, 50668, 536, 498, 264, 3097, 6713, 307, 709, 2946, 813, 257, 1952, 1496, 295, 3389, 13, 50958, 50958, 400, 294, 341, 1365, 11, 309, 775, 445, 1958, 13, 17, 4, 5324, 813, 6255, 13, 51170, 51170, 18600, 300, 6255, 366, 767, 534, 665, 412, 18538, 6218, 11, 286, 519, 498, 286, 393, 1322, 51346, 51346, 257, 6218, 11150, 1185, 300, 3538, 977, 1266, 13, 21, 4, 6713, 14324, 1952, 3389, 11, 286, 1116, 51602, 51602, 312, 1238, 2055, 13, 51652, 51652, 407, 309, 311, 445, 884, 257, 707, 857, 5324, 813, 6255, 13, 51814, 51814], "temperature": 0.0, "avg_logprob": -0.10008130754743304, "compression_ratio": 1.713235294117647, "no_speech_prob": 3.989649997038214e-07}, {"id": 44, "seek": 18400, "start": 203.64, "end": 208.76, "text": " a speech recognition system that achieves 10.6% error matching human performance, I'd", "tokens": [50364, 400, 370, 294, 1668, 281, 6995, 498, 264, 3097, 6713, 307, 1090, 11, 309, 4523, 484, 281, 312, 544, 4420, 281, 50668, 50668, 536, 498, 264, 3097, 6713, 307, 709, 2946, 813, 257, 1952, 1496, 295, 3389, 13, 50958, 50958, 400, 294, 341, 1365, 11, 309, 775, 445, 1958, 13, 17, 4, 5324, 813, 6255, 13, 51170, 51170, 18600, 300, 6255, 366, 767, 534, 665, 412, 18538, 6218, 11, 286, 519, 498, 286, 393, 1322, 51346, 51346, 257, 6218, 11150, 1185, 300, 3538, 977, 1266, 13, 21, 4, 6713, 14324, 1952, 3389, 11, 286, 1116, 51602, 51602, 312, 1238, 2055, 13, 51652, 51652, 407, 309, 311, 445, 884, 257, 707, 857, 5324, 813, 6255, 13, 51814, 51814], "temperature": 0.0, "avg_logprob": -0.10008130754743304, "compression_ratio": 1.713235294117647, "no_speech_prob": 3.989649997038214e-07}, {"id": 45, "seek": 18400, "start": 208.76, "end": 209.76, "text": " be pretty happy.", "tokens": [50364, 400, 370, 294, 1668, 281, 6995, 498, 264, 3097, 6713, 307, 1090, 11, 309, 4523, 484, 281, 312, 544, 4420, 281, 50668, 50668, 536, 498, 264, 3097, 6713, 307, 709, 2946, 813, 257, 1952, 1496, 295, 3389, 13, 50958, 50958, 400, 294, 341, 1365, 11, 309, 775, 445, 1958, 13, 17, 4, 5324, 813, 6255, 13, 51170, 51170, 18600, 300, 6255, 366, 767, 534, 665, 412, 18538, 6218, 11, 286, 519, 498, 286, 393, 1322, 51346, 51346, 257, 6218, 11150, 1185, 300, 3538, 977, 1266, 13, 21, 4, 6713, 14324, 1952, 3389, 11, 286, 1116, 51602, 51602, 312, 1238, 2055, 13, 51652, 51652, 407, 309, 311, 445, 884, 257, 707, 857, 5324, 813, 6255, 13, 51814, 51814], "temperature": 0.0, "avg_logprob": -0.10008130754743304, "compression_ratio": 1.713235294117647, "no_speech_prob": 3.989649997038214e-07}, {"id": 46, "seek": 18400, "start": 209.76, "end": 213.0, "text": " So it's just doing a little bit worse than humans.", "tokens": [50364, 400, 370, 294, 1668, 281, 6995, 498, 264, 3097, 6713, 307, 1090, 11, 309, 4523, 484, 281, 312, 544, 4420, 281, 50668, 50668, 536, 498, 264, 3097, 6713, 307, 709, 2946, 813, 257, 1952, 1496, 295, 3389, 13, 50958, 50958, 400, 294, 341, 1365, 11, 309, 775, 445, 1958, 13, 17, 4, 5324, 813, 6255, 13, 51170, 51170, 18600, 300, 6255, 366, 767, 534, 665, 412, 18538, 6218, 11, 286, 519, 498, 286, 393, 1322, 51346, 51346, 257, 6218, 11150, 1185, 300, 3538, 977, 1266, 13, 21, 4, 6713, 14324, 1952, 3389, 11, 286, 1116, 51602, 51602, 312, 1238, 2055, 13, 51652, 51652, 407, 309, 311, 445, 884, 257, 707, 857, 5324, 813, 6255, 13, 51814, 51814], "temperature": 0.0, "avg_logprob": -0.10008130754743304, "compression_ratio": 1.713235294117647, "no_speech_prob": 3.989649997038214e-07}, {"id": 47, "seek": 21300, "start": 213.0, "end": 219.56, "text": " But in contrast, the gap or the difference between JCV and JTrain is much larger.", "tokens": [50364, 583, 294, 8712, 11, 264, 7417, 420, 264, 2649, 1296, 49802, 53, 293, 508, 51, 7146, 307, 709, 4833, 13, 50692, 50692, 821, 311, 767, 257, 1017, 4, 7417, 456, 13, 50838, 50838, 407, 9735, 8046, 321, 632, 848, 1310, 1266, 13, 23, 4, 6713, 1355, 341, 307, 1090, 12577, 11, 562, 321, 18927, 51258, 51258, 309, 281, 1952, 1496, 3389, 11, 321, 536, 300, 264, 9284, 307, 767, 884, 1596, 731, 51470, 51470, 322, 264, 3097, 992, 13, 51558, 51558], "temperature": 0.0, "avg_logprob": -0.15081409086664038, "compression_ratio": 1.4429223744292237, "no_speech_prob": 1.994689910134184e-06}, {"id": 48, "seek": 21300, "start": 219.56, "end": 222.48, "text": " There's actually a 4% gap there.", "tokens": [50364, 583, 294, 8712, 11, 264, 7417, 420, 264, 2649, 1296, 49802, 53, 293, 508, 51, 7146, 307, 709, 4833, 13, 50692, 50692, 821, 311, 767, 257, 1017, 4, 7417, 456, 13, 50838, 50838, 407, 9735, 8046, 321, 632, 848, 1310, 1266, 13, 23, 4, 6713, 1355, 341, 307, 1090, 12577, 11, 562, 321, 18927, 51258, 51258, 309, 281, 1952, 1496, 3389, 11, 321, 536, 300, 264, 9284, 307, 767, 884, 1596, 731, 51470, 51470, 322, 264, 3097, 992, 13, 51558, 51558], "temperature": 0.0, "avg_logprob": -0.15081409086664038, "compression_ratio": 1.4429223744292237, "no_speech_prob": 1.994689910134184e-06}, {"id": 49, "seek": 21300, "start": 222.48, "end": 230.88, "text": " So whereas previously we had said maybe 10.8% error means this is high bias, when we benchmark", "tokens": [50364, 583, 294, 8712, 11, 264, 7417, 420, 264, 2649, 1296, 49802, 53, 293, 508, 51, 7146, 307, 709, 4833, 13, 50692, 50692, 821, 311, 767, 257, 1017, 4, 7417, 456, 13, 50838, 50838, 407, 9735, 8046, 321, 632, 848, 1310, 1266, 13, 23, 4, 6713, 1355, 341, 307, 1090, 12577, 11, 562, 321, 18927, 51258, 51258, 309, 281, 1952, 1496, 3389, 11, 321, 536, 300, 264, 9284, 307, 767, 884, 1596, 731, 51470, 51470, 322, 264, 3097, 992, 13, 51558, 51558], "temperature": 0.0, "avg_logprob": -0.15081409086664038, "compression_ratio": 1.4429223744292237, "no_speech_prob": 1.994689910134184e-06}, {"id": 50, "seek": 21300, "start": 230.88, "end": 235.12, "text": " it to human level performance, we see that the algorithm is actually doing quite well", "tokens": [50364, 583, 294, 8712, 11, 264, 7417, 420, 264, 2649, 1296, 49802, 53, 293, 508, 51, 7146, 307, 709, 4833, 13, 50692, 50692, 821, 311, 767, 257, 1017, 4, 7417, 456, 13, 50838, 50838, 407, 9735, 8046, 321, 632, 848, 1310, 1266, 13, 23, 4, 6713, 1355, 341, 307, 1090, 12577, 11, 562, 321, 18927, 51258, 51258, 309, 281, 1952, 1496, 3389, 11, 321, 536, 300, 264, 9284, 307, 767, 884, 1596, 731, 51470, 51470, 322, 264, 3097, 992, 13, 51558, 51558], "temperature": 0.0, "avg_logprob": -0.15081409086664038, "compression_ratio": 1.4429223744292237, "no_speech_prob": 1.994689910134184e-06}, {"id": 51, "seek": 21300, "start": 235.12, "end": 236.88, "text": " on the training set.", "tokens": [50364, 583, 294, 8712, 11, 264, 7417, 420, 264, 2649, 1296, 49802, 53, 293, 508, 51, 7146, 307, 709, 4833, 13, 50692, 50692, 821, 311, 767, 257, 1017, 4, 7417, 456, 13, 50838, 50838, 407, 9735, 8046, 321, 632, 848, 1310, 1266, 13, 23, 4, 6713, 1355, 341, 307, 1090, 12577, 11, 562, 321, 18927, 51258, 51258, 309, 281, 1952, 1496, 3389, 11, 321, 536, 300, 264, 9284, 307, 767, 884, 1596, 731, 51470, 51470, 322, 264, 3097, 992, 13, 51558, 51558], "temperature": 0.0, "avg_logprob": -0.15081409086664038, "compression_ratio": 1.4429223744292237, "no_speech_prob": 1.994689910134184e-06}, {"id": 52, "seek": 23688, "start": 236.88, "end": 243.4, "text": " But the bigger problem is the cross validation error is much higher than the training error,", "tokens": [50364, 583, 264, 3801, 1154, 307, 264, 3278, 24071, 6713, 307, 709, 2946, 813, 264, 3097, 6713, 11, 50690, 50690, 597, 307, 983, 286, 576, 16886, 300, 341, 9284, 767, 575, 544, 295, 257, 21977, 1154, 813, 50972, 50972, 257, 12577, 1154, 13, 51070, 51070, 407, 309, 4523, 484, 562, 23587, 498, 264, 3097, 6713, 307, 1090, 11, 309, 311, 2049, 4420, 281, 8327, 51508, 51508, 257, 20518, 1496, 295, 3389, 13, 51622, 51622, 400, 538, 20518, 1496, 295, 3389, 11, 286, 914, 11, 437, 307, 264, 1496, 295, 6713, 291, 393, 23551, 51846, 51846], "temperature": 0.0, "avg_logprob": -0.088347593943278, "compression_ratio": 1.7531380753138075, "no_speech_prob": 1.4367310541274492e-06}, {"id": 53, "seek": 23688, "start": 243.4, "end": 249.04, "text": " which is why I would conclude that this algorithm actually has more of a variance problem than", "tokens": [50364, 583, 264, 3801, 1154, 307, 264, 3278, 24071, 6713, 307, 709, 2946, 813, 264, 3097, 6713, 11, 50690, 50690, 597, 307, 983, 286, 576, 16886, 300, 341, 9284, 767, 575, 544, 295, 257, 21977, 1154, 813, 50972, 50972, 257, 12577, 1154, 13, 51070, 51070, 407, 309, 4523, 484, 562, 23587, 498, 264, 3097, 6713, 307, 1090, 11, 309, 311, 2049, 4420, 281, 8327, 51508, 51508, 257, 20518, 1496, 295, 3389, 13, 51622, 51622, 400, 538, 20518, 1496, 295, 3389, 11, 286, 914, 11, 437, 307, 264, 1496, 295, 6713, 291, 393, 23551, 51846, 51846], "temperature": 0.0, "avg_logprob": -0.088347593943278, "compression_ratio": 1.7531380753138075, "no_speech_prob": 1.4367310541274492e-06}, {"id": 54, "seek": 23688, "start": 249.04, "end": 251.0, "text": " a bias problem.", "tokens": [50364, 583, 264, 3801, 1154, 307, 264, 3278, 24071, 6713, 307, 709, 2946, 813, 264, 3097, 6713, 11, 50690, 50690, 597, 307, 983, 286, 576, 16886, 300, 341, 9284, 767, 575, 544, 295, 257, 21977, 1154, 813, 50972, 50972, 257, 12577, 1154, 13, 51070, 51070, 407, 309, 4523, 484, 562, 23587, 498, 264, 3097, 6713, 307, 1090, 11, 309, 311, 2049, 4420, 281, 8327, 51508, 51508, 257, 20518, 1496, 295, 3389, 13, 51622, 51622, 400, 538, 20518, 1496, 295, 3389, 11, 286, 914, 11, 437, 307, 264, 1496, 295, 6713, 291, 393, 23551, 51846, 51846], "temperature": 0.0, "avg_logprob": -0.088347593943278, "compression_ratio": 1.7531380753138075, "no_speech_prob": 1.4367310541274492e-06}, {"id": 55, "seek": 23688, "start": 251.0, "end": 259.76, "text": " So it turns out when judging if the training error is high, it's often useful to establish", "tokens": [50364, 583, 264, 3801, 1154, 307, 264, 3278, 24071, 6713, 307, 709, 2946, 813, 264, 3097, 6713, 11, 50690, 50690, 597, 307, 983, 286, 576, 16886, 300, 341, 9284, 767, 575, 544, 295, 257, 21977, 1154, 813, 50972, 50972, 257, 12577, 1154, 13, 51070, 51070, 407, 309, 4523, 484, 562, 23587, 498, 264, 3097, 6713, 307, 1090, 11, 309, 311, 2049, 4420, 281, 8327, 51508, 51508, 257, 20518, 1496, 295, 3389, 13, 51622, 51622, 400, 538, 20518, 1496, 295, 3389, 11, 286, 914, 11, 437, 307, 264, 1496, 295, 6713, 291, 393, 23551, 51846, 51846], "temperature": 0.0, "avg_logprob": -0.088347593943278, "compression_ratio": 1.7531380753138075, "no_speech_prob": 1.4367310541274492e-06}, {"id": 56, "seek": 23688, "start": 259.76, "end": 262.04, "text": " a baseline level of performance.", "tokens": [50364, 583, 264, 3801, 1154, 307, 264, 3278, 24071, 6713, 307, 709, 2946, 813, 264, 3097, 6713, 11, 50690, 50690, 597, 307, 983, 286, 576, 16886, 300, 341, 9284, 767, 575, 544, 295, 257, 21977, 1154, 813, 50972, 50972, 257, 12577, 1154, 13, 51070, 51070, 407, 309, 4523, 484, 562, 23587, 498, 264, 3097, 6713, 307, 1090, 11, 309, 311, 2049, 4420, 281, 8327, 51508, 51508, 257, 20518, 1496, 295, 3389, 13, 51622, 51622, 400, 538, 20518, 1496, 295, 3389, 11, 286, 914, 11, 437, 307, 264, 1496, 295, 6713, 291, 393, 23551, 51846, 51846], "temperature": 0.0, "avg_logprob": -0.088347593943278, "compression_ratio": 1.7531380753138075, "no_speech_prob": 1.4367310541274492e-06}, {"id": 57, "seek": 23688, "start": 262.04, "end": 266.52, "text": " And by baseline level of performance, I mean, what is the level of error you can reasonably", "tokens": [50364, 583, 264, 3801, 1154, 307, 264, 3278, 24071, 6713, 307, 709, 2946, 813, 264, 3097, 6713, 11, 50690, 50690, 597, 307, 983, 286, 576, 16886, 300, 341, 9284, 767, 575, 544, 295, 257, 21977, 1154, 813, 50972, 50972, 257, 12577, 1154, 13, 51070, 51070, 407, 309, 4523, 484, 562, 23587, 498, 264, 3097, 6713, 307, 1090, 11, 309, 311, 2049, 4420, 281, 8327, 51508, 51508, 257, 20518, 1496, 295, 3389, 13, 51622, 51622, 400, 538, 20518, 1496, 295, 3389, 11, 286, 914, 11, 437, 307, 264, 1496, 295, 6713, 291, 393, 23551, 51846, 51846], "temperature": 0.0, "avg_logprob": -0.088347593943278, "compression_ratio": 1.7531380753138075, "no_speech_prob": 1.4367310541274492e-06}, {"id": 58, "seek": 26652, "start": 266.52, "end": 271.2, "text": " hope your learning algorithm to eventually get to?", "tokens": [50364, 1454, 428, 2539, 9284, 281, 4728, 483, 281, 30, 50598, 50598, 400, 472, 2689, 636, 281, 8327, 257, 20518, 1496, 295, 3389, 307, 281, 3481, 577, 731, 50882, 50882, 6255, 393, 360, 322, 341, 5633, 13, 51011, 51011, 1436, 6255, 366, 534, 665, 412, 3701, 6218, 1412, 420, 9007, 5267, 420, 3701, 51274, 51274, 2487, 11, 1952, 1496, 3389, 307, 2049, 257, 665, 18927, 562, 291, 366, 1228, 18799, 46847, 1412, 51590, 51590, 1270, 382, 6278, 11, 5267, 420, 2487, 13, 51777, 51777], "temperature": 0.0, "avg_logprob": -0.13098153507008273, "compression_ratio": 1.6973684210526316, "no_speech_prob": 2.29587203648407e-06}, {"id": 59, "seek": 26652, "start": 271.2, "end": 276.88, "text": " And one common way to establish a baseline level of performance is to measure how well", "tokens": [50364, 1454, 428, 2539, 9284, 281, 4728, 483, 281, 30, 50598, 50598, 400, 472, 2689, 636, 281, 8327, 257, 20518, 1496, 295, 3389, 307, 281, 3481, 577, 731, 50882, 50882, 6255, 393, 360, 322, 341, 5633, 13, 51011, 51011, 1436, 6255, 366, 534, 665, 412, 3701, 6218, 1412, 420, 9007, 5267, 420, 3701, 51274, 51274, 2487, 11, 1952, 1496, 3389, 307, 2049, 257, 665, 18927, 562, 291, 366, 1228, 18799, 46847, 1412, 51590, 51590, 1270, 382, 6278, 11, 5267, 420, 2487, 13, 51777, 51777], "temperature": 0.0, "avg_logprob": -0.13098153507008273, "compression_ratio": 1.6973684210526316, "no_speech_prob": 2.29587203648407e-06}, {"id": 60, "seek": 26652, "start": 276.88, "end": 279.46, "text": " humans can do on this task.", "tokens": [50364, 1454, 428, 2539, 9284, 281, 4728, 483, 281, 30, 50598, 50598, 400, 472, 2689, 636, 281, 8327, 257, 20518, 1496, 295, 3389, 307, 281, 3481, 577, 731, 50882, 50882, 6255, 393, 360, 322, 341, 5633, 13, 51011, 51011, 1436, 6255, 366, 534, 665, 412, 3701, 6218, 1412, 420, 9007, 5267, 420, 3701, 51274, 51274, 2487, 11, 1952, 1496, 3389, 307, 2049, 257, 665, 18927, 562, 291, 366, 1228, 18799, 46847, 1412, 51590, 51590, 1270, 382, 6278, 11, 5267, 420, 2487, 13, 51777, 51777], "temperature": 0.0, "avg_logprob": -0.13098153507008273, "compression_ratio": 1.6973684210526316, "no_speech_prob": 2.29587203648407e-06}, {"id": 61, "seek": 26652, "start": 279.46, "end": 284.71999999999997, "text": " Because humans are really good at understanding speech data or processing images or understanding", "tokens": [50364, 1454, 428, 2539, 9284, 281, 4728, 483, 281, 30, 50598, 50598, 400, 472, 2689, 636, 281, 8327, 257, 20518, 1496, 295, 3389, 307, 281, 3481, 577, 731, 50882, 50882, 6255, 393, 360, 322, 341, 5633, 13, 51011, 51011, 1436, 6255, 366, 534, 665, 412, 3701, 6218, 1412, 420, 9007, 5267, 420, 3701, 51274, 51274, 2487, 11, 1952, 1496, 3389, 307, 2049, 257, 665, 18927, 562, 291, 366, 1228, 18799, 46847, 1412, 51590, 51590, 1270, 382, 6278, 11, 5267, 420, 2487, 13, 51777, 51777], "temperature": 0.0, "avg_logprob": -0.13098153507008273, "compression_ratio": 1.6973684210526316, "no_speech_prob": 2.29587203648407e-06}, {"id": 62, "seek": 26652, "start": 284.71999999999997, "end": 291.03999999999996, "text": " text, human level performance is often a good benchmark when you are using unstructured data", "tokens": [50364, 1454, 428, 2539, 9284, 281, 4728, 483, 281, 30, 50598, 50598, 400, 472, 2689, 636, 281, 8327, 257, 20518, 1496, 295, 3389, 307, 281, 3481, 577, 731, 50882, 50882, 6255, 393, 360, 322, 341, 5633, 13, 51011, 51011, 1436, 6255, 366, 534, 665, 412, 3701, 6218, 1412, 420, 9007, 5267, 420, 3701, 51274, 51274, 2487, 11, 1952, 1496, 3389, 307, 2049, 257, 665, 18927, 562, 291, 366, 1228, 18799, 46847, 1412, 51590, 51590, 1270, 382, 6278, 11, 5267, 420, 2487, 13, 51777, 51777], "temperature": 0.0, "avg_logprob": -0.13098153507008273, "compression_ratio": 1.6973684210526316, "no_speech_prob": 2.29587203648407e-06}, {"id": 63, "seek": 26652, "start": 291.03999999999996, "end": 294.78, "text": " such as audio, images or text.", "tokens": [50364, 1454, 428, 2539, 9284, 281, 4728, 483, 281, 30, 50598, 50598, 400, 472, 2689, 636, 281, 8327, 257, 20518, 1496, 295, 3389, 307, 281, 3481, 577, 731, 50882, 50882, 6255, 393, 360, 322, 341, 5633, 13, 51011, 51011, 1436, 6255, 366, 534, 665, 412, 3701, 6218, 1412, 420, 9007, 5267, 420, 3701, 51274, 51274, 2487, 11, 1952, 1496, 3389, 307, 2049, 257, 665, 18927, 562, 291, 366, 1228, 18799, 46847, 1412, 51590, 51590, 1270, 382, 6278, 11, 5267, 420, 2487, 13, 51777, 51777], "temperature": 0.0, "avg_logprob": -0.13098153507008273, "compression_ratio": 1.6973684210526316, "no_speech_prob": 2.29587203648407e-06}, {"id": 64, "seek": 29478, "start": 294.78, "end": 300.15999999999997, "text": " Another way to estimate a baseline level of performance is if there's some competing algorithm,", "tokens": [50364, 3996, 636, 281, 12539, 257, 20518, 1496, 295, 3389, 307, 498, 456, 311, 512, 15439, 9284, 11, 50633, 50633, 1310, 257, 3894, 11420, 300, 1580, 1646, 12270, 420, 754, 257, 27266, 311, 9284, 50937, 50937, 281, 8327, 257, 20518, 1496, 295, 3389, 11, 498, 291, 393, 3481, 300, 13, 51195, 51195, 1610, 2171, 291, 1062, 2041, 2361, 322, 4059, 1752, 13, 51473, 51473, 400, 498, 291, 362, 2105, 281, 341, 20518, 1496, 295, 3389, 11, 300, 307, 11, 437, 307, 264, 1496, 51763, 51763], "temperature": 0.0, "avg_logprob": -0.12755539250928302, "compression_ratio": 1.8883720930232557, "no_speech_prob": 1.3419095012068283e-05}, {"id": 65, "seek": 29478, "start": 300.15999999999997, "end": 306.23999999999995, "text": " maybe a previous implementation that someone else implemented or even a competitor's algorithm", "tokens": [50364, 3996, 636, 281, 12539, 257, 20518, 1496, 295, 3389, 307, 498, 456, 311, 512, 15439, 9284, 11, 50633, 50633, 1310, 257, 3894, 11420, 300, 1580, 1646, 12270, 420, 754, 257, 27266, 311, 9284, 50937, 50937, 281, 8327, 257, 20518, 1496, 295, 3389, 11, 498, 291, 393, 3481, 300, 13, 51195, 51195, 1610, 2171, 291, 1062, 2041, 2361, 322, 4059, 1752, 13, 51473, 51473, 400, 498, 291, 362, 2105, 281, 341, 20518, 1496, 295, 3389, 11, 300, 307, 11, 437, 307, 264, 1496, 51763, 51763], "temperature": 0.0, "avg_logprob": -0.12755539250928302, "compression_ratio": 1.8883720930232557, "no_speech_prob": 1.3419095012068283e-05}, {"id": 66, "seek": 29478, "start": 306.23999999999995, "end": 311.4, "text": " to establish a baseline level of performance, if you can measure that.", "tokens": [50364, 3996, 636, 281, 12539, 257, 20518, 1496, 295, 3389, 307, 498, 456, 311, 512, 15439, 9284, 11, 50633, 50633, 1310, 257, 3894, 11420, 300, 1580, 1646, 12270, 420, 754, 257, 27266, 311, 9284, 50937, 50937, 281, 8327, 257, 20518, 1496, 295, 3389, 11, 498, 291, 393, 3481, 300, 13, 51195, 51195, 1610, 2171, 291, 1062, 2041, 2361, 322, 4059, 1752, 13, 51473, 51473, 400, 498, 291, 362, 2105, 281, 341, 20518, 1496, 295, 3389, 11, 300, 307, 11, 437, 307, 264, 1496, 51763, 51763], "temperature": 0.0, "avg_logprob": -0.12755539250928302, "compression_ratio": 1.8883720930232557, "no_speech_prob": 1.3419095012068283e-05}, {"id": 67, "seek": 29478, "start": 311.4, "end": 316.96, "text": " Or sometimes you might guess based on prior experience.", "tokens": [50364, 3996, 636, 281, 12539, 257, 20518, 1496, 295, 3389, 307, 498, 456, 311, 512, 15439, 9284, 11, 50633, 50633, 1310, 257, 3894, 11420, 300, 1580, 1646, 12270, 420, 754, 257, 27266, 311, 9284, 50937, 50937, 281, 8327, 257, 20518, 1496, 295, 3389, 11, 498, 291, 393, 3481, 300, 13, 51195, 51195, 1610, 2171, 291, 1062, 2041, 2361, 322, 4059, 1752, 13, 51473, 51473, 400, 498, 291, 362, 2105, 281, 341, 20518, 1496, 295, 3389, 11, 300, 307, 11, 437, 307, 264, 1496, 51763, 51763], "temperature": 0.0, "avg_logprob": -0.12755539250928302, "compression_ratio": 1.8883720930232557, "no_speech_prob": 1.3419095012068283e-05}, {"id": 68, "seek": 29478, "start": 316.96, "end": 322.76, "text": " And if you have access to this baseline level of performance, that is, what is the level", "tokens": [50364, 3996, 636, 281, 12539, 257, 20518, 1496, 295, 3389, 307, 498, 456, 311, 512, 15439, 9284, 11, 50633, 50633, 1310, 257, 3894, 11420, 300, 1580, 1646, 12270, 420, 754, 257, 27266, 311, 9284, 50937, 50937, 281, 8327, 257, 20518, 1496, 295, 3389, 11, 498, 291, 393, 3481, 300, 13, 51195, 51195, 1610, 2171, 291, 1062, 2041, 2361, 322, 4059, 1752, 13, 51473, 51473, 400, 498, 291, 362, 2105, 281, 341, 20518, 1496, 295, 3389, 11, 300, 307, 11, 437, 307, 264, 1496, 51763, 51763], "temperature": 0.0, "avg_logprob": -0.12755539250928302, "compression_ratio": 1.8883720930232557, "no_speech_prob": 1.3419095012068283e-05}, {"id": 69, "seek": 32276, "start": 322.76, "end": 324.88, "text": " of error you can reasonably hope to get to?", "tokens": [50364, 295, 6713, 291, 393, 23551, 1454, 281, 483, 281, 30, 50470, 50470, 1610, 437, 307, 264, 1715, 1496, 295, 3389, 300, 291, 528, 428, 9284, 281, 483, 281, 30, 50704, 50704, 1396, 562, 23587, 11, 498, 364, 9284, 575, 1090, 12577, 420, 21977, 11, 291, 576, 574, 412, 264, 20518, 51006, 51006, 1496, 295, 3389, 293, 264, 3097, 6713, 293, 264, 3278, 24071, 6713, 13, 51244, 51244, 400, 264, 732, 2141, 22927, 281, 3481, 366, 550, 437, 307, 264, 2649, 1296, 3097, 51536, 51536, 6713, 293, 264, 20518, 1496, 300, 291, 1454, 281, 483, 281, 30, 51746, 51746], "temperature": 0.0, "avg_logprob": -0.1282978057861328, "compression_ratio": 1.9039301310043668, "no_speech_prob": 3.446504706516862e-06}, {"id": 70, "seek": 32276, "start": 324.88, "end": 329.56, "text": " Or what is the design level of performance that you want your algorithm to get to?", "tokens": [50364, 295, 6713, 291, 393, 23551, 1454, 281, 483, 281, 30, 50470, 50470, 1610, 437, 307, 264, 1715, 1496, 295, 3389, 300, 291, 528, 428, 9284, 281, 483, 281, 30, 50704, 50704, 1396, 562, 23587, 11, 498, 364, 9284, 575, 1090, 12577, 420, 21977, 11, 291, 576, 574, 412, 264, 20518, 51006, 51006, 1496, 295, 3389, 293, 264, 3097, 6713, 293, 264, 3278, 24071, 6713, 13, 51244, 51244, 400, 264, 732, 2141, 22927, 281, 3481, 366, 550, 437, 307, 264, 2649, 1296, 3097, 51536, 51536, 6713, 293, 264, 20518, 1496, 300, 291, 1454, 281, 483, 281, 30, 51746, 51746], "temperature": 0.0, "avg_logprob": -0.1282978057861328, "compression_ratio": 1.9039301310043668, "no_speech_prob": 3.446504706516862e-06}, {"id": 71, "seek": 32276, "start": 329.56, "end": 335.59999999999997, "text": " Then when judging, if an algorithm has high bias or variance, you would look at the baseline", "tokens": [50364, 295, 6713, 291, 393, 23551, 1454, 281, 483, 281, 30, 50470, 50470, 1610, 437, 307, 264, 1715, 1496, 295, 3389, 300, 291, 528, 428, 9284, 281, 483, 281, 30, 50704, 50704, 1396, 562, 23587, 11, 498, 364, 9284, 575, 1090, 12577, 420, 21977, 11, 291, 576, 574, 412, 264, 20518, 51006, 51006, 1496, 295, 3389, 293, 264, 3097, 6713, 293, 264, 3278, 24071, 6713, 13, 51244, 51244, 400, 264, 732, 2141, 22927, 281, 3481, 366, 550, 437, 307, 264, 2649, 1296, 3097, 51536, 51536, 6713, 293, 264, 20518, 1496, 300, 291, 1454, 281, 483, 281, 30, 51746, 51746], "temperature": 0.0, "avg_logprob": -0.1282978057861328, "compression_ratio": 1.9039301310043668, "no_speech_prob": 3.446504706516862e-06}, {"id": 72, "seek": 32276, "start": 335.59999999999997, "end": 340.36, "text": " level of performance and the training error and the cross validation error.", "tokens": [50364, 295, 6713, 291, 393, 23551, 1454, 281, 483, 281, 30, 50470, 50470, 1610, 437, 307, 264, 1715, 1496, 295, 3389, 300, 291, 528, 428, 9284, 281, 483, 281, 30, 50704, 50704, 1396, 562, 23587, 11, 498, 364, 9284, 575, 1090, 12577, 420, 21977, 11, 291, 576, 574, 412, 264, 20518, 51006, 51006, 1496, 295, 3389, 293, 264, 3097, 6713, 293, 264, 3278, 24071, 6713, 13, 51244, 51244, 400, 264, 732, 2141, 22927, 281, 3481, 366, 550, 437, 307, 264, 2649, 1296, 3097, 51536, 51536, 6713, 293, 264, 20518, 1496, 300, 291, 1454, 281, 483, 281, 30, 51746, 51746], "temperature": 0.0, "avg_logprob": -0.1282978057861328, "compression_ratio": 1.9039301310043668, "no_speech_prob": 3.446504706516862e-06}, {"id": 73, "seek": 32276, "start": 340.36, "end": 346.2, "text": " And the two key quantities to measure are then what is the difference between training", "tokens": [50364, 295, 6713, 291, 393, 23551, 1454, 281, 483, 281, 30, 50470, 50470, 1610, 437, 307, 264, 1715, 1496, 295, 3389, 300, 291, 528, 428, 9284, 281, 483, 281, 30, 50704, 50704, 1396, 562, 23587, 11, 498, 364, 9284, 575, 1090, 12577, 420, 21977, 11, 291, 576, 574, 412, 264, 20518, 51006, 51006, 1496, 295, 3389, 293, 264, 3097, 6713, 293, 264, 3278, 24071, 6713, 13, 51244, 51244, 400, 264, 732, 2141, 22927, 281, 3481, 366, 550, 437, 307, 264, 2649, 1296, 3097, 51536, 51536, 6713, 293, 264, 20518, 1496, 300, 291, 1454, 281, 483, 281, 30, 51746, 51746], "temperature": 0.0, "avg_logprob": -0.1282978057861328, "compression_ratio": 1.9039301310043668, "no_speech_prob": 3.446504706516862e-06}, {"id": 74, "seek": 32276, "start": 346.2, "end": 350.4, "text": " error and the baseline level that you hope to get to?", "tokens": [50364, 295, 6713, 291, 393, 23551, 1454, 281, 483, 281, 30, 50470, 50470, 1610, 437, 307, 264, 1715, 1496, 295, 3389, 300, 291, 528, 428, 9284, 281, 483, 281, 30, 50704, 50704, 1396, 562, 23587, 11, 498, 364, 9284, 575, 1090, 12577, 420, 21977, 11, 291, 576, 574, 412, 264, 20518, 51006, 51006, 1496, 295, 3389, 293, 264, 3097, 6713, 293, 264, 3278, 24071, 6713, 13, 51244, 51244, 400, 264, 732, 2141, 22927, 281, 3481, 366, 550, 437, 307, 264, 2649, 1296, 3097, 51536, 51536, 6713, 293, 264, 20518, 1496, 300, 291, 1454, 281, 483, 281, 30, 51746, 51746], "temperature": 0.0, "avg_logprob": -0.1282978057861328, "compression_ratio": 1.9039301310043668, "no_speech_prob": 3.446504706516862e-06}, {"id": 75, "seek": 35040, "start": 350.4, "end": 356.88, "text": " So this is 0.2, and if this is large, then you would say you have a high bias problem.", "tokens": [50364, 407, 341, 307, 1958, 13, 17, 11, 293, 498, 341, 307, 2416, 11, 550, 291, 576, 584, 291, 362, 257, 1090, 12577, 1154, 13, 50688, 50688, 400, 291, 576, 550, 611, 574, 412, 341, 7417, 1296, 428, 3097, 6713, 293, 428, 3278, 24071, 50958, 50958, 6713, 13, 51008, 51008, 400, 498, 341, 307, 1090, 11, 550, 291, 576, 16886, 291, 362, 257, 1090, 21977, 1154, 13, 51218, 51218, 400, 300, 311, 983, 294, 341, 1365, 11, 321, 22960, 321, 362, 257, 1090, 21977, 1154, 13, 51476, 51476, 13813, 11, 718, 311, 574, 412, 264, 1150, 1365, 13, 51668, 51668], "temperature": 0.0, "avg_logprob": -0.105920678318137, "compression_ratio": 1.94, "no_speech_prob": 4.1573102862457745e-06}, {"id": 76, "seek": 35040, "start": 356.88, "end": 362.28, "text": " And you would then also look at this gap between your training error and your cross validation", "tokens": [50364, 407, 341, 307, 1958, 13, 17, 11, 293, 498, 341, 307, 2416, 11, 550, 291, 576, 584, 291, 362, 257, 1090, 12577, 1154, 13, 50688, 50688, 400, 291, 576, 550, 611, 574, 412, 341, 7417, 1296, 428, 3097, 6713, 293, 428, 3278, 24071, 50958, 50958, 6713, 13, 51008, 51008, 400, 498, 341, 307, 1090, 11, 550, 291, 576, 16886, 291, 362, 257, 1090, 21977, 1154, 13, 51218, 51218, 400, 300, 311, 983, 294, 341, 1365, 11, 321, 22960, 321, 362, 257, 1090, 21977, 1154, 13, 51476, 51476, 13813, 11, 718, 311, 574, 412, 264, 1150, 1365, 13, 51668, 51668], "temperature": 0.0, "avg_logprob": -0.105920678318137, "compression_ratio": 1.94, "no_speech_prob": 4.1573102862457745e-06}, {"id": 77, "seek": 35040, "start": 362.28, "end": 363.28, "text": " error.", "tokens": [50364, 407, 341, 307, 1958, 13, 17, 11, 293, 498, 341, 307, 2416, 11, 550, 291, 576, 584, 291, 362, 257, 1090, 12577, 1154, 13, 50688, 50688, 400, 291, 576, 550, 611, 574, 412, 341, 7417, 1296, 428, 3097, 6713, 293, 428, 3278, 24071, 50958, 50958, 6713, 13, 51008, 51008, 400, 498, 341, 307, 1090, 11, 550, 291, 576, 16886, 291, 362, 257, 1090, 21977, 1154, 13, 51218, 51218, 400, 300, 311, 983, 294, 341, 1365, 11, 321, 22960, 321, 362, 257, 1090, 21977, 1154, 13, 51476, 51476, 13813, 11, 718, 311, 574, 412, 264, 1150, 1365, 13, 51668, 51668], "temperature": 0.0, "avg_logprob": -0.105920678318137, "compression_ratio": 1.94, "no_speech_prob": 4.1573102862457745e-06}, {"id": 78, "seek": 35040, "start": 363.28, "end": 367.47999999999996, "text": " And if this is high, then you would conclude you have a high variance problem.", "tokens": [50364, 407, 341, 307, 1958, 13, 17, 11, 293, 498, 341, 307, 2416, 11, 550, 291, 576, 584, 291, 362, 257, 1090, 12577, 1154, 13, 50688, 50688, 400, 291, 576, 550, 611, 574, 412, 341, 7417, 1296, 428, 3097, 6713, 293, 428, 3278, 24071, 50958, 50958, 6713, 13, 51008, 51008, 400, 498, 341, 307, 1090, 11, 550, 291, 576, 16886, 291, 362, 257, 1090, 21977, 1154, 13, 51218, 51218, 400, 300, 311, 983, 294, 341, 1365, 11, 321, 22960, 321, 362, 257, 1090, 21977, 1154, 13, 51476, 51476, 13813, 11, 718, 311, 574, 412, 264, 1150, 1365, 13, 51668, 51668], "temperature": 0.0, "avg_logprob": -0.105920678318137, "compression_ratio": 1.94, "no_speech_prob": 4.1573102862457745e-06}, {"id": 79, "seek": 35040, "start": 367.47999999999996, "end": 372.64, "text": " And that's why in this example, we concluded we have a high variance problem.", "tokens": [50364, 407, 341, 307, 1958, 13, 17, 11, 293, 498, 341, 307, 2416, 11, 550, 291, 576, 584, 291, 362, 257, 1090, 12577, 1154, 13, 50688, 50688, 400, 291, 576, 550, 611, 574, 412, 341, 7417, 1296, 428, 3097, 6713, 293, 428, 3278, 24071, 50958, 50958, 6713, 13, 51008, 51008, 400, 498, 341, 307, 1090, 11, 550, 291, 576, 16886, 291, 362, 257, 1090, 21977, 1154, 13, 51218, 51218, 400, 300, 311, 983, 294, 341, 1365, 11, 321, 22960, 321, 362, 257, 1090, 21977, 1154, 13, 51476, 51476, 13813, 11, 718, 311, 574, 412, 264, 1150, 1365, 13, 51668, 51668], "temperature": 0.0, "avg_logprob": -0.105920678318137, "compression_ratio": 1.94, "no_speech_prob": 4.1573102862457745e-06}, {"id": 80, "seek": 35040, "start": 372.64, "end": 376.47999999999996, "text": " Whereas, let's look at the second example.", "tokens": [50364, 407, 341, 307, 1958, 13, 17, 11, 293, 498, 341, 307, 2416, 11, 550, 291, 576, 584, 291, 362, 257, 1090, 12577, 1154, 13, 50688, 50688, 400, 291, 576, 550, 611, 574, 412, 341, 7417, 1296, 428, 3097, 6713, 293, 428, 3278, 24071, 50958, 50958, 6713, 13, 51008, 51008, 400, 498, 341, 307, 1090, 11, 550, 291, 576, 16886, 291, 362, 257, 1090, 21977, 1154, 13, 51218, 51218, 400, 300, 311, 983, 294, 341, 1365, 11, 321, 22960, 321, 362, 257, 1090, 21977, 1154, 13, 51476, 51476, 13813, 11, 718, 311, 574, 412, 264, 1150, 1365, 13, 51668, 51668], "temperature": 0.0, "avg_logprob": -0.105920678318137, "compression_ratio": 1.94, "no_speech_prob": 4.1573102862457745e-06}, {"id": 81, "seek": 37648, "start": 376.48, "end": 381.08000000000004, "text": " If the baseline level of performance, that is, human level performance and training error", "tokens": [50364, 759, 264, 20518, 1496, 295, 3389, 11, 300, 307, 11, 1952, 1496, 3389, 293, 3097, 6713, 50594, 50594, 293, 3278, 24071, 6713, 574, 411, 341, 11, 550, 341, 700, 7417, 307, 1017, 13, 19, 6856, 50962, 50962, 400, 370, 456, 311, 767, 257, 955, 7417, 13, 51028, 51028, 440, 3097, 6713, 307, 709, 2946, 813, 437, 6255, 393, 360, 293, 437, 321, 1454, 281, 483, 281, 13, 51280, 51280, 13813, 264, 3278, 24071, 6713, 307, 445, 257, 707, 857, 3801, 813, 264, 3097, 6713, 13, 51496, 51496, 400, 370, 498, 428, 3097, 6713, 293, 3278, 24071, 6713, 574, 411, 341, 11, 286, 576, 584, 341, 9284, 51744, 51744], "temperature": 0.0, "avg_logprob": -0.12484092712402343, "compression_ratio": 1.9747899159663866, "no_speech_prob": 5.5074870033422485e-06}, {"id": 82, "seek": 37648, "start": 381.08000000000004, "end": 388.44, "text": " and cross validation error look like this, then this first gap is 4.4%.", "tokens": [50364, 759, 264, 20518, 1496, 295, 3389, 11, 300, 307, 11, 1952, 1496, 3389, 293, 3097, 6713, 50594, 50594, 293, 3278, 24071, 6713, 574, 411, 341, 11, 550, 341, 700, 7417, 307, 1017, 13, 19, 6856, 50962, 50962, 400, 370, 456, 311, 767, 257, 955, 7417, 13, 51028, 51028, 440, 3097, 6713, 307, 709, 2946, 813, 437, 6255, 393, 360, 293, 437, 321, 1454, 281, 483, 281, 13, 51280, 51280, 13813, 264, 3278, 24071, 6713, 307, 445, 257, 707, 857, 3801, 813, 264, 3097, 6713, 13, 51496, 51496, 400, 370, 498, 428, 3097, 6713, 293, 3278, 24071, 6713, 574, 411, 341, 11, 286, 576, 584, 341, 9284, 51744, 51744], "temperature": 0.0, "avg_logprob": -0.12484092712402343, "compression_ratio": 1.9747899159663866, "no_speech_prob": 5.5074870033422485e-06}, {"id": 83, "seek": 37648, "start": 388.44, "end": 389.76, "text": " And so there's actually a big gap.", "tokens": [50364, 759, 264, 20518, 1496, 295, 3389, 11, 300, 307, 11, 1952, 1496, 3389, 293, 3097, 6713, 50594, 50594, 293, 3278, 24071, 6713, 574, 411, 341, 11, 550, 341, 700, 7417, 307, 1017, 13, 19, 6856, 50962, 50962, 400, 370, 456, 311, 767, 257, 955, 7417, 13, 51028, 51028, 440, 3097, 6713, 307, 709, 2946, 813, 437, 6255, 393, 360, 293, 437, 321, 1454, 281, 483, 281, 13, 51280, 51280, 13813, 264, 3278, 24071, 6713, 307, 445, 257, 707, 857, 3801, 813, 264, 3097, 6713, 13, 51496, 51496, 400, 370, 498, 428, 3097, 6713, 293, 3278, 24071, 6713, 574, 411, 341, 11, 286, 576, 584, 341, 9284, 51744, 51744], "temperature": 0.0, "avg_logprob": -0.12484092712402343, "compression_ratio": 1.9747899159663866, "no_speech_prob": 5.5074870033422485e-06}, {"id": 84, "seek": 37648, "start": 389.76, "end": 394.8, "text": " The training error is much higher than what humans can do and what we hope to get to.", "tokens": [50364, 759, 264, 20518, 1496, 295, 3389, 11, 300, 307, 11, 1952, 1496, 3389, 293, 3097, 6713, 50594, 50594, 293, 3278, 24071, 6713, 574, 411, 341, 11, 550, 341, 700, 7417, 307, 1017, 13, 19, 6856, 50962, 50962, 400, 370, 456, 311, 767, 257, 955, 7417, 13, 51028, 51028, 440, 3097, 6713, 307, 709, 2946, 813, 437, 6255, 393, 360, 293, 437, 321, 1454, 281, 483, 281, 13, 51280, 51280, 13813, 264, 3278, 24071, 6713, 307, 445, 257, 707, 857, 3801, 813, 264, 3097, 6713, 13, 51496, 51496, 400, 370, 498, 428, 3097, 6713, 293, 3278, 24071, 6713, 574, 411, 341, 11, 286, 576, 584, 341, 9284, 51744, 51744], "temperature": 0.0, "avg_logprob": -0.12484092712402343, "compression_ratio": 1.9747899159663866, "no_speech_prob": 5.5074870033422485e-06}, {"id": 85, "seek": 37648, "start": 394.8, "end": 399.12, "text": " Whereas the cross validation error is just a little bit bigger than the training error.", "tokens": [50364, 759, 264, 20518, 1496, 295, 3389, 11, 300, 307, 11, 1952, 1496, 3389, 293, 3097, 6713, 50594, 50594, 293, 3278, 24071, 6713, 574, 411, 341, 11, 550, 341, 700, 7417, 307, 1017, 13, 19, 6856, 50962, 50962, 400, 370, 456, 311, 767, 257, 955, 7417, 13, 51028, 51028, 440, 3097, 6713, 307, 709, 2946, 813, 437, 6255, 393, 360, 293, 437, 321, 1454, 281, 483, 281, 13, 51280, 51280, 13813, 264, 3278, 24071, 6713, 307, 445, 257, 707, 857, 3801, 813, 264, 3097, 6713, 13, 51496, 51496, 400, 370, 498, 428, 3097, 6713, 293, 3278, 24071, 6713, 574, 411, 341, 11, 286, 576, 584, 341, 9284, 51744, 51744], "temperature": 0.0, "avg_logprob": -0.12484092712402343, "compression_ratio": 1.9747899159663866, "no_speech_prob": 5.5074870033422485e-06}, {"id": 86, "seek": 37648, "start": 399.12, "end": 404.08000000000004, "text": " And so if your training error and cross validation error look like this, I would say this algorithm", "tokens": [50364, 759, 264, 20518, 1496, 295, 3389, 11, 300, 307, 11, 1952, 1496, 3389, 293, 3097, 6713, 50594, 50594, 293, 3278, 24071, 6713, 574, 411, 341, 11, 550, 341, 700, 7417, 307, 1017, 13, 19, 6856, 50962, 50962, 400, 370, 456, 311, 767, 257, 955, 7417, 13, 51028, 51028, 440, 3097, 6713, 307, 709, 2946, 813, 437, 6255, 393, 360, 293, 437, 321, 1454, 281, 483, 281, 13, 51280, 51280, 13813, 264, 3278, 24071, 6713, 307, 445, 257, 707, 857, 3801, 813, 264, 3097, 6713, 13, 51496, 51496, 400, 370, 498, 428, 3097, 6713, 293, 3278, 24071, 6713, 574, 411, 341, 11, 286, 576, 584, 341, 9284, 51744, 51744], "temperature": 0.0, "avg_logprob": -0.12484092712402343, "compression_ratio": 1.9747899159663866, "no_speech_prob": 5.5074870033422485e-06}, {"id": 87, "seek": 40408, "start": 404.08, "end": 406.71999999999997, "text": " has high bias.", "tokens": [50364, 575, 1090, 12577, 13, 50496, 50496, 400, 370, 538, 1237, 412, 613, 3547, 11, 3097, 6713, 293, 3278, 24071, 6713, 11, 291, 393, 50726, 50726, 483, 257, 2020, 11, 46506, 420, 1356, 379, 11, 295, 264, 4314, 281, 597, 428, 9284, 575, 257, 1090, 51012, 51012, 12577, 420, 1090, 21977, 1154, 13, 51156, 51156, 400, 370, 445, 281, 20858, 11, 341, 7417, 1296, 613, 700, 732, 3547, 2709, 291, 257, 2020, 51448, 51448, 295, 1968, 291, 362, 257, 1090, 12577, 1154, 13, 51618, 51618], "temperature": 0.0, "avg_logprob": -0.09582260043122047, "compression_ratio": 1.6763285024154588, "no_speech_prob": 8.664476808917243e-06}, {"id": 88, "seek": 40408, "start": 406.71999999999997, "end": 411.32, "text": " And so by looking at these numbers, training error and cross validation error, you can", "tokens": [50364, 575, 1090, 12577, 13, 50496, 50496, 400, 370, 538, 1237, 412, 613, 3547, 11, 3097, 6713, 293, 3278, 24071, 6713, 11, 291, 393, 50726, 50726, 483, 257, 2020, 11, 46506, 420, 1356, 379, 11, 295, 264, 4314, 281, 597, 428, 9284, 575, 257, 1090, 51012, 51012, 12577, 420, 1090, 21977, 1154, 13, 51156, 51156, 400, 370, 445, 281, 20858, 11, 341, 7417, 1296, 613, 700, 732, 3547, 2709, 291, 257, 2020, 51448, 51448, 295, 1968, 291, 362, 257, 1090, 12577, 1154, 13, 51618, 51618], "temperature": 0.0, "avg_logprob": -0.09582260043122047, "compression_ratio": 1.6763285024154588, "no_speech_prob": 8.664476808917243e-06}, {"id": 89, "seek": 40408, "start": 411.32, "end": 417.03999999999996, "text": " get a sense, intuitively or informally, of the degree to which your algorithm has a high", "tokens": [50364, 575, 1090, 12577, 13, 50496, 50496, 400, 370, 538, 1237, 412, 613, 3547, 11, 3097, 6713, 293, 3278, 24071, 6713, 11, 291, 393, 50726, 50726, 483, 257, 2020, 11, 46506, 420, 1356, 379, 11, 295, 264, 4314, 281, 597, 428, 9284, 575, 257, 1090, 51012, 51012, 12577, 420, 1090, 21977, 1154, 13, 51156, 51156, 400, 370, 445, 281, 20858, 11, 341, 7417, 1296, 613, 700, 732, 3547, 2709, 291, 257, 2020, 51448, 51448, 295, 1968, 291, 362, 257, 1090, 12577, 1154, 13, 51618, 51618], "temperature": 0.0, "avg_logprob": -0.09582260043122047, "compression_ratio": 1.6763285024154588, "no_speech_prob": 8.664476808917243e-06}, {"id": 90, "seek": 40408, "start": 417.03999999999996, "end": 419.91999999999996, "text": " bias or high variance problem.", "tokens": [50364, 575, 1090, 12577, 13, 50496, 50496, 400, 370, 538, 1237, 412, 613, 3547, 11, 3097, 6713, 293, 3278, 24071, 6713, 11, 291, 393, 50726, 50726, 483, 257, 2020, 11, 46506, 420, 1356, 379, 11, 295, 264, 4314, 281, 597, 428, 9284, 575, 257, 1090, 51012, 51012, 12577, 420, 1090, 21977, 1154, 13, 51156, 51156, 400, 370, 445, 281, 20858, 11, 341, 7417, 1296, 613, 700, 732, 3547, 2709, 291, 257, 2020, 51448, 51448, 295, 1968, 291, 362, 257, 1090, 12577, 1154, 13, 51618, 51618], "temperature": 0.0, "avg_logprob": -0.09582260043122047, "compression_ratio": 1.6763285024154588, "no_speech_prob": 8.664476808917243e-06}, {"id": 91, "seek": 40408, "start": 419.91999999999996, "end": 425.76, "text": " And so just to summarize, this gap between these first two numbers gives you a sense", "tokens": [50364, 575, 1090, 12577, 13, 50496, 50496, 400, 370, 538, 1237, 412, 613, 3547, 11, 3097, 6713, 293, 3278, 24071, 6713, 11, 291, 393, 50726, 50726, 483, 257, 2020, 11, 46506, 420, 1356, 379, 11, 295, 264, 4314, 281, 597, 428, 9284, 575, 257, 1090, 51012, 51012, 12577, 420, 1090, 21977, 1154, 13, 51156, 51156, 400, 370, 445, 281, 20858, 11, 341, 7417, 1296, 613, 700, 732, 3547, 2709, 291, 257, 2020, 51448, 51448, 295, 1968, 291, 362, 257, 1090, 12577, 1154, 13, 51618, 51618], "temperature": 0.0, "avg_logprob": -0.09582260043122047, "compression_ratio": 1.6763285024154588, "no_speech_prob": 8.664476808917243e-06}, {"id": 92, "seek": 40408, "start": 425.76, "end": 429.15999999999997, "text": " of whether you have a high bias problem.", "tokens": [50364, 575, 1090, 12577, 13, 50496, 50496, 400, 370, 538, 1237, 412, 613, 3547, 11, 3097, 6713, 293, 3278, 24071, 6713, 11, 291, 393, 50726, 50726, 483, 257, 2020, 11, 46506, 420, 1356, 379, 11, 295, 264, 4314, 281, 597, 428, 9284, 575, 257, 1090, 51012, 51012, 12577, 420, 1090, 21977, 1154, 13, 51156, 51156, 400, 370, 445, 281, 20858, 11, 341, 7417, 1296, 613, 700, 732, 3547, 2709, 291, 257, 2020, 51448, 51448, 295, 1968, 291, 362, 257, 1090, 12577, 1154, 13, 51618, 51618], "temperature": 0.0, "avg_logprob": -0.09582260043122047, "compression_ratio": 1.6763285024154588, "no_speech_prob": 8.664476808917243e-06}, {"id": 93, "seek": 42916, "start": 429.16, "end": 434.32000000000005, "text": " And the gap between these two numbers give you a sense of whether you have a high variance", "tokens": [50364, 400, 264, 7417, 1296, 613, 732, 3547, 976, 291, 257, 2020, 295, 1968, 291, 362, 257, 1090, 21977, 50622, 50622, 1154, 13, 50672, 50672, 400, 2171, 264, 20518, 1496, 295, 3389, 727, 312, 1958, 6856, 50830, 50830, 759, 428, 3387, 307, 281, 4584, 2176, 3389, 11, 550, 264, 20518, 1496, 295, 3389, 727, 51038, 51038, 312, 1958, 6856, 51130, 51130, 583, 337, 512, 5821, 11, 411, 264, 6218, 11150, 3861, 11, 689, 512, 6278, 51322, 51322, 307, 445, 24518, 11, 550, 264, 20518, 1496, 295, 3389, 727, 312, 709, 2946, 813, 1958, 13, 51548, 51548, 400, 264, 3170, 7619, 322, 341, 4137, 486, 976, 291, 257, 1101, 1401, 294, 2115, 295, 1968, 51768, 51768], "temperature": 0.0, "avg_logprob": -0.11974568202577789, "compression_ratio": 2.0436507936507935, "no_speech_prob": 2.812985485434183e-06}, {"id": 94, "seek": 42916, "start": 434.32000000000005, "end": 435.32000000000005, "text": " problem.", "tokens": [50364, 400, 264, 7417, 1296, 613, 732, 3547, 976, 291, 257, 2020, 295, 1968, 291, 362, 257, 1090, 21977, 50622, 50622, 1154, 13, 50672, 50672, 400, 2171, 264, 20518, 1496, 295, 3389, 727, 312, 1958, 6856, 50830, 50830, 759, 428, 3387, 307, 281, 4584, 2176, 3389, 11, 550, 264, 20518, 1496, 295, 3389, 727, 51038, 51038, 312, 1958, 6856, 51130, 51130, 583, 337, 512, 5821, 11, 411, 264, 6218, 11150, 3861, 11, 689, 512, 6278, 51322, 51322, 307, 445, 24518, 11, 550, 264, 20518, 1496, 295, 3389, 727, 312, 709, 2946, 813, 1958, 13, 51548, 51548, 400, 264, 3170, 7619, 322, 341, 4137, 486, 976, 291, 257, 1101, 1401, 294, 2115, 295, 1968, 51768, 51768], "temperature": 0.0, "avg_logprob": -0.11974568202577789, "compression_ratio": 2.0436507936507935, "no_speech_prob": 2.812985485434183e-06}, {"id": 95, "seek": 42916, "start": 435.32000000000005, "end": 438.48, "text": " And sometimes the baseline level of performance could be 0%.", "tokens": [50364, 400, 264, 7417, 1296, 613, 732, 3547, 976, 291, 257, 2020, 295, 1968, 291, 362, 257, 1090, 21977, 50622, 50622, 1154, 13, 50672, 50672, 400, 2171, 264, 20518, 1496, 295, 3389, 727, 312, 1958, 6856, 50830, 50830, 759, 428, 3387, 307, 281, 4584, 2176, 3389, 11, 550, 264, 20518, 1496, 295, 3389, 727, 51038, 51038, 312, 1958, 6856, 51130, 51130, 583, 337, 512, 5821, 11, 411, 264, 6218, 11150, 3861, 11, 689, 512, 6278, 51322, 51322, 307, 445, 24518, 11, 550, 264, 20518, 1496, 295, 3389, 727, 312, 709, 2946, 813, 1958, 13, 51548, 51548, 400, 264, 3170, 7619, 322, 341, 4137, 486, 976, 291, 257, 1101, 1401, 294, 2115, 295, 1968, 51768, 51768], "temperature": 0.0, "avg_logprob": -0.11974568202577789, "compression_ratio": 2.0436507936507935, "no_speech_prob": 2.812985485434183e-06}, {"id": 96, "seek": 42916, "start": 438.48, "end": 442.64000000000004, "text": " If your goal is to achieve perfect performance, then the baseline level of performance could", "tokens": [50364, 400, 264, 7417, 1296, 613, 732, 3547, 976, 291, 257, 2020, 295, 1968, 291, 362, 257, 1090, 21977, 50622, 50622, 1154, 13, 50672, 50672, 400, 2171, 264, 20518, 1496, 295, 3389, 727, 312, 1958, 6856, 50830, 50830, 759, 428, 3387, 307, 281, 4584, 2176, 3389, 11, 550, 264, 20518, 1496, 295, 3389, 727, 51038, 51038, 312, 1958, 6856, 51130, 51130, 583, 337, 512, 5821, 11, 411, 264, 6218, 11150, 3861, 11, 689, 512, 6278, 51322, 51322, 307, 445, 24518, 11, 550, 264, 20518, 1496, 295, 3389, 727, 312, 709, 2946, 813, 1958, 13, 51548, 51548, 400, 264, 3170, 7619, 322, 341, 4137, 486, 976, 291, 257, 1101, 1401, 294, 2115, 295, 1968, 51768, 51768], "temperature": 0.0, "avg_logprob": -0.11974568202577789, "compression_ratio": 2.0436507936507935, "no_speech_prob": 2.812985485434183e-06}, {"id": 97, "seek": 42916, "start": 442.64000000000004, "end": 444.48, "text": " be 0%.", "tokens": [50364, 400, 264, 7417, 1296, 613, 732, 3547, 976, 291, 257, 2020, 295, 1968, 291, 362, 257, 1090, 21977, 50622, 50622, 1154, 13, 50672, 50672, 400, 2171, 264, 20518, 1496, 295, 3389, 727, 312, 1958, 6856, 50830, 50830, 759, 428, 3387, 307, 281, 4584, 2176, 3389, 11, 550, 264, 20518, 1496, 295, 3389, 727, 51038, 51038, 312, 1958, 6856, 51130, 51130, 583, 337, 512, 5821, 11, 411, 264, 6218, 11150, 3861, 11, 689, 512, 6278, 51322, 51322, 307, 445, 24518, 11, 550, 264, 20518, 1496, 295, 3389, 727, 312, 709, 2946, 813, 1958, 13, 51548, 51548, 400, 264, 3170, 7619, 322, 341, 4137, 486, 976, 291, 257, 1101, 1401, 294, 2115, 295, 1968, 51768, 51768], "temperature": 0.0, "avg_logprob": -0.11974568202577789, "compression_ratio": 2.0436507936507935, "no_speech_prob": 2.812985485434183e-06}, {"id": 98, "seek": 42916, "start": 444.48, "end": 448.32000000000005, "text": " But for some applications, like the speech recognition application, where some audio", "tokens": [50364, 400, 264, 7417, 1296, 613, 732, 3547, 976, 291, 257, 2020, 295, 1968, 291, 362, 257, 1090, 21977, 50622, 50622, 1154, 13, 50672, 50672, 400, 2171, 264, 20518, 1496, 295, 3389, 727, 312, 1958, 6856, 50830, 50830, 759, 428, 3387, 307, 281, 4584, 2176, 3389, 11, 550, 264, 20518, 1496, 295, 3389, 727, 51038, 51038, 312, 1958, 6856, 51130, 51130, 583, 337, 512, 5821, 11, 411, 264, 6218, 11150, 3861, 11, 689, 512, 6278, 51322, 51322, 307, 445, 24518, 11, 550, 264, 20518, 1496, 295, 3389, 727, 312, 709, 2946, 813, 1958, 13, 51548, 51548, 400, 264, 3170, 7619, 322, 341, 4137, 486, 976, 291, 257, 1101, 1401, 294, 2115, 295, 1968, 51768, 51768], "temperature": 0.0, "avg_logprob": -0.11974568202577789, "compression_ratio": 2.0436507936507935, "no_speech_prob": 2.812985485434183e-06}, {"id": 99, "seek": 42916, "start": 448.32000000000005, "end": 452.84000000000003, "text": " is just noisy, then the baseline level of performance could be much higher than 0.", "tokens": [50364, 400, 264, 7417, 1296, 613, 732, 3547, 976, 291, 257, 2020, 295, 1968, 291, 362, 257, 1090, 21977, 50622, 50622, 1154, 13, 50672, 50672, 400, 2171, 264, 20518, 1496, 295, 3389, 727, 312, 1958, 6856, 50830, 50830, 759, 428, 3387, 307, 281, 4584, 2176, 3389, 11, 550, 264, 20518, 1496, 295, 3389, 727, 51038, 51038, 312, 1958, 6856, 51130, 51130, 583, 337, 512, 5821, 11, 411, 264, 6218, 11150, 3861, 11, 689, 512, 6278, 51322, 51322, 307, 445, 24518, 11, 550, 264, 20518, 1496, 295, 3389, 727, 312, 709, 2946, 813, 1958, 13, 51548, 51548, 400, 264, 3170, 7619, 322, 341, 4137, 486, 976, 291, 257, 1101, 1401, 294, 2115, 295, 1968, 51768, 51768], "temperature": 0.0, "avg_logprob": -0.11974568202577789, "compression_ratio": 2.0436507936507935, "no_speech_prob": 2.812985485434183e-06}, {"id": 100, "seek": 42916, "start": 452.84000000000003, "end": 457.24, "text": " And the method described on this slide will give you a better read in terms of whether", "tokens": [50364, 400, 264, 7417, 1296, 613, 732, 3547, 976, 291, 257, 2020, 295, 1968, 291, 362, 257, 1090, 21977, 50622, 50622, 1154, 13, 50672, 50672, 400, 2171, 264, 20518, 1496, 295, 3389, 727, 312, 1958, 6856, 50830, 50830, 759, 428, 3387, 307, 281, 4584, 2176, 3389, 11, 550, 264, 20518, 1496, 295, 3389, 727, 51038, 51038, 312, 1958, 6856, 51130, 51130, 583, 337, 512, 5821, 11, 411, 264, 6218, 11150, 3861, 11, 689, 512, 6278, 51322, 51322, 307, 445, 24518, 11, 550, 264, 20518, 1496, 295, 3389, 727, 312, 709, 2946, 813, 1958, 13, 51548, 51548, 400, 264, 3170, 7619, 322, 341, 4137, 486, 976, 291, 257, 1101, 1401, 294, 2115, 295, 1968, 51768, 51768], "temperature": 0.0, "avg_logprob": -0.11974568202577789, "compression_ratio": 2.0436507936507935, "no_speech_prob": 2.812985485434183e-06}, {"id": 101, "seek": 45724, "start": 457.24, "end": 460.36, "text": " your algorithm suffers from bias or variance.", "tokens": [50364, 428, 9284, 33776, 490, 12577, 420, 21977, 13, 50520, 50520, 400, 538, 264, 636, 11, 309, 307, 1944, 337, 428, 9284, 281, 362, 1090, 12577, 293, 1090, 21977, 13, 50788, 50788, 407, 39481, 736, 11, 498, 291, 483, 3547, 411, 613, 11, 550, 264, 7417, 1296, 264, 20518, 293, 264, 51134, 51134, 3097, 6713, 307, 2416, 13, 51224, 51224, 663, 576, 312, 257, 1017, 13, 21, 6856, 51378, 51378, 400, 264, 7417, 1296, 3097, 6713, 293, 3278, 24071, 6713, 307, 611, 2416, 13, 51596, 51596, 639, 307, 1017, 13, 17, 6856, 51674, 51674], "temperature": 0.0, "avg_logprob": -0.10714934499640213, "compression_ratio": 1.7129186602870814, "no_speech_prob": 1.9947049167967634e-06}, {"id": 102, "seek": 45724, "start": 460.36, "end": 465.72, "text": " And by the way, it is possible for your algorithm to have high bias and high variance.", "tokens": [50364, 428, 9284, 33776, 490, 12577, 420, 21977, 13, 50520, 50520, 400, 538, 264, 636, 11, 309, 307, 1944, 337, 428, 9284, 281, 362, 1090, 12577, 293, 1090, 21977, 13, 50788, 50788, 407, 39481, 736, 11, 498, 291, 483, 3547, 411, 613, 11, 550, 264, 7417, 1296, 264, 20518, 293, 264, 51134, 51134, 3097, 6713, 307, 2416, 13, 51224, 51224, 663, 576, 312, 257, 1017, 13, 21, 6856, 51378, 51378, 400, 264, 7417, 1296, 3097, 6713, 293, 3278, 24071, 6713, 307, 611, 2416, 13, 51596, 51596, 639, 307, 1017, 13, 17, 6856, 51674, 51674], "temperature": 0.0, "avg_logprob": -0.10714934499640213, "compression_ratio": 1.7129186602870814, "no_speech_prob": 1.9947049167967634e-06}, {"id": 103, "seek": 45724, "start": 465.72, "end": 472.64, "text": " So concretely, if you get numbers like these, then the gap between the baseline and the", "tokens": [50364, 428, 9284, 33776, 490, 12577, 420, 21977, 13, 50520, 50520, 400, 538, 264, 636, 11, 309, 307, 1944, 337, 428, 9284, 281, 362, 1090, 12577, 293, 1090, 21977, 13, 50788, 50788, 407, 39481, 736, 11, 498, 291, 483, 3547, 411, 613, 11, 550, 264, 7417, 1296, 264, 20518, 293, 264, 51134, 51134, 3097, 6713, 307, 2416, 13, 51224, 51224, 663, 576, 312, 257, 1017, 13, 21, 6856, 51378, 51378, 400, 264, 7417, 1296, 3097, 6713, 293, 3278, 24071, 6713, 307, 611, 2416, 13, 51596, 51596, 639, 307, 1017, 13, 17, 6856, 51674, 51674], "temperature": 0.0, "avg_logprob": -0.10714934499640213, "compression_ratio": 1.7129186602870814, "no_speech_prob": 1.9947049167967634e-06}, {"id": 104, "seek": 45724, "start": 472.64, "end": 474.44, "text": " training error is large.", "tokens": [50364, 428, 9284, 33776, 490, 12577, 420, 21977, 13, 50520, 50520, 400, 538, 264, 636, 11, 309, 307, 1944, 337, 428, 9284, 281, 362, 1090, 12577, 293, 1090, 21977, 13, 50788, 50788, 407, 39481, 736, 11, 498, 291, 483, 3547, 411, 613, 11, 550, 264, 7417, 1296, 264, 20518, 293, 264, 51134, 51134, 3097, 6713, 307, 2416, 13, 51224, 51224, 663, 576, 312, 257, 1017, 13, 21, 6856, 51378, 51378, 400, 264, 7417, 1296, 3097, 6713, 293, 3278, 24071, 6713, 307, 611, 2416, 13, 51596, 51596, 639, 307, 1017, 13, 17, 6856, 51674, 51674], "temperature": 0.0, "avg_logprob": -0.10714934499640213, "compression_ratio": 1.7129186602870814, "no_speech_prob": 1.9947049167967634e-06}, {"id": 105, "seek": 45724, "start": 474.44, "end": 477.52, "text": " That would be a 4.6%.", "tokens": [50364, 428, 9284, 33776, 490, 12577, 420, 21977, 13, 50520, 50520, 400, 538, 264, 636, 11, 309, 307, 1944, 337, 428, 9284, 281, 362, 1090, 12577, 293, 1090, 21977, 13, 50788, 50788, 407, 39481, 736, 11, 498, 291, 483, 3547, 411, 613, 11, 550, 264, 7417, 1296, 264, 20518, 293, 264, 51134, 51134, 3097, 6713, 307, 2416, 13, 51224, 51224, 663, 576, 312, 257, 1017, 13, 21, 6856, 51378, 51378, 400, 264, 7417, 1296, 3097, 6713, 293, 3278, 24071, 6713, 307, 611, 2416, 13, 51596, 51596, 639, 307, 1017, 13, 17, 6856, 51674, 51674], "temperature": 0.0, "avg_logprob": -0.10714934499640213, "compression_ratio": 1.7129186602870814, "no_speech_prob": 1.9947049167967634e-06}, {"id": 106, "seek": 45724, "start": 477.52, "end": 481.88, "text": " And the gap between training error and cross validation error is also large.", "tokens": [50364, 428, 9284, 33776, 490, 12577, 420, 21977, 13, 50520, 50520, 400, 538, 264, 636, 11, 309, 307, 1944, 337, 428, 9284, 281, 362, 1090, 12577, 293, 1090, 21977, 13, 50788, 50788, 407, 39481, 736, 11, 498, 291, 483, 3547, 411, 613, 11, 550, 264, 7417, 1296, 264, 20518, 293, 264, 51134, 51134, 3097, 6713, 307, 2416, 13, 51224, 51224, 663, 576, 312, 257, 1017, 13, 21, 6856, 51378, 51378, 400, 264, 7417, 1296, 3097, 6713, 293, 3278, 24071, 6713, 307, 611, 2416, 13, 51596, 51596, 639, 307, 1017, 13, 17, 6856, 51674, 51674], "temperature": 0.0, "avg_logprob": -0.10714934499640213, "compression_ratio": 1.7129186602870814, "no_speech_prob": 1.9947049167967634e-06}, {"id": 107, "seek": 45724, "start": 481.88, "end": 483.44, "text": " This is 4.2%.", "tokens": [50364, 428, 9284, 33776, 490, 12577, 420, 21977, 13, 50520, 50520, 400, 538, 264, 636, 11, 309, 307, 1944, 337, 428, 9284, 281, 362, 1090, 12577, 293, 1090, 21977, 13, 50788, 50788, 407, 39481, 736, 11, 498, 291, 483, 3547, 411, 613, 11, 550, 264, 7417, 1296, 264, 20518, 293, 264, 51134, 51134, 3097, 6713, 307, 2416, 13, 51224, 51224, 663, 576, 312, 257, 1017, 13, 21, 6856, 51378, 51378, 400, 264, 7417, 1296, 3097, 6713, 293, 3278, 24071, 6713, 307, 611, 2416, 13, 51596, 51596, 639, 307, 1017, 13, 17, 6856, 51674, 51674], "temperature": 0.0, "avg_logprob": -0.10714934499640213, "compression_ratio": 1.7129186602870814, "no_speech_prob": 1.9947049167967634e-06}, {"id": 108, "seek": 48344, "start": 483.44, "end": 487.71999999999997, "text": " And so if it looks like this, you would conclude that your algorithm has high bias and high", "tokens": [50364, 400, 370, 498, 309, 1542, 411, 341, 11, 291, 576, 16886, 300, 428, 9284, 575, 1090, 12577, 293, 1090, 50578, 50578, 21977, 11, 4878, 4696, 341, 1582, 380, 1051, 300, 2049, 337, 428, 2539, 5821, 13, 50854, 50854, 407, 281, 20858, 11, 321, 600, 1612, 300, 1237, 412, 1968, 428, 3097, 6713, 307, 2416, 307, 257, 51092, 51092, 636, 281, 980, 498, 428, 9284, 575, 1090, 12577, 13, 51264, 51264, 583, 322, 5821, 689, 264, 1412, 307, 2171, 445, 24518, 293, 307, 1536, 68, 296, 964, 420, 42867, 51560, 51560, 281, 1562, 2066, 281, 483, 281, 4018, 6713, 11, 550, 309, 311, 4420, 281, 8327, 341, 20518, 1496, 51826, 51826], "temperature": 0.0, "avg_logprob": -0.08903364624295916, "compression_ratio": 1.7411347517730495, "no_speech_prob": 2.5359906885569217e-07}, {"id": 109, "seek": 48344, "start": 487.71999999999997, "end": 493.24, "text": " variance, although hopefully this won't happen that often for your learning applications.", "tokens": [50364, 400, 370, 498, 309, 1542, 411, 341, 11, 291, 576, 16886, 300, 428, 9284, 575, 1090, 12577, 293, 1090, 50578, 50578, 21977, 11, 4878, 4696, 341, 1582, 380, 1051, 300, 2049, 337, 428, 2539, 5821, 13, 50854, 50854, 407, 281, 20858, 11, 321, 600, 1612, 300, 1237, 412, 1968, 428, 3097, 6713, 307, 2416, 307, 257, 51092, 51092, 636, 281, 980, 498, 428, 9284, 575, 1090, 12577, 13, 51264, 51264, 583, 322, 5821, 689, 264, 1412, 307, 2171, 445, 24518, 293, 307, 1536, 68, 296, 964, 420, 42867, 51560, 51560, 281, 1562, 2066, 281, 483, 281, 4018, 6713, 11, 550, 309, 311, 4420, 281, 8327, 341, 20518, 1496, 51826, 51826], "temperature": 0.0, "avg_logprob": -0.08903364624295916, "compression_ratio": 1.7411347517730495, "no_speech_prob": 2.5359906885569217e-07}, {"id": 110, "seek": 48344, "start": 493.24, "end": 498.0, "text": " So to summarize, we've seen that looking at whether your training error is large is a", "tokens": [50364, 400, 370, 498, 309, 1542, 411, 341, 11, 291, 576, 16886, 300, 428, 9284, 575, 1090, 12577, 293, 1090, 50578, 50578, 21977, 11, 4878, 4696, 341, 1582, 380, 1051, 300, 2049, 337, 428, 2539, 5821, 13, 50854, 50854, 407, 281, 20858, 11, 321, 600, 1612, 300, 1237, 412, 1968, 428, 3097, 6713, 307, 2416, 307, 257, 51092, 51092, 636, 281, 980, 498, 428, 9284, 575, 1090, 12577, 13, 51264, 51264, 583, 322, 5821, 689, 264, 1412, 307, 2171, 445, 24518, 293, 307, 1536, 68, 296, 964, 420, 42867, 51560, 51560, 281, 1562, 2066, 281, 483, 281, 4018, 6713, 11, 550, 309, 311, 4420, 281, 8327, 341, 20518, 1496, 51826, 51826], "temperature": 0.0, "avg_logprob": -0.08903364624295916, "compression_ratio": 1.7411347517730495, "no_speech_prob": 2.5359906885569217e-07}, {"id": 111, "seek": 48344, "start": 498.0, "end": 501.44, "text": " way to tell if your algorithm has high bias.", "tokens": [50364, 400, 370, 498, 309, 1542, 411, 341, 11, 291, 576, 16886, 300, 428, 9284, 575, 1090, 12577, 293, 1090, 50578, 50578, 21977, 11, 4878, 4696, 341, 1582, 380, 1051, 300, 2049, 337, 428, 2539, 5821, 13, 50854, 50854, 407, 281, 20858, 11, 321, 600, 1612, 300, 1237, 412, 1968, 428, 3097, 6713, 307, 2416, 307, 257, 51092, 51092, 636, 281, 980, 498, 428, 9284, 575, 1090, 12577, 13, 51264, 51264, 583, 322, 5821, 689, 264, 1412, 307, 2171, 445, 24518, 293, 307, 1536, 68, 296, 964, 420, 42867, 51560, 51560, 281, 1562, 2066, 281, 483, 281, 4018, 6713, 11, 550, 309, 311, 4420, 281, 8327, 341, 20518, 1496, 51826, 51826], "temperature": 0.0, "avg_logprob": -0.08903364624295916, "compression_ratio": 1.7411347517730495, "no_speech_prob": 2.5359906885569217e-07}, {"id": 112, "seek": 48344, "start": 501.44, "end": 507.36, "text": " But on applications where the data is sometimes just noisy and is infeasible or unrealistic", "tokens": [50364, 400, 370, 498, 309, 1542, 411, 341, 11, 291, 576, 16886, 300, 428, 9284, 575, 1090, 12577, 293, 1090, 50578, 50578, 21977, 11, 4878, 4696, 341, 1582, 380, 1051, 300, 2049, 337, 428, 2539, 5821, 13, 50854, 50854, 407, 281, 20858, 11, 321, 600, 1612, 300, 1237, 412, 1968, 428, 3097, 6713, 307, 2416, 307, 257, 51092, 51092, 636, 281, 980, 498, 428, 9284, 575, 1090, 12577, 13, 51264, 51264, 583, 322, 5821, 689, 264, 1412, 307, 2171, 445, 24518, 293, 307, 1536, 68, 296, 964, 420, 42867, 51560, 51560, 281, 1562, 2066, 281, 483, 281, 4018, 6713, 11, 550, 309, 311, 4420, 281, 8327, 341, 20518, 1496, 51826, 51826], "temperature": 0.0, "avg_logprob": -0.08903364624295916, "compression_ratio": 1.7411347517730495, "no_speech_prob": 2.5359906885569217e-07}, {"id": 113, "seek": 48344, "start": 507.36, "end": 512.68, "text": " to ever expect to get to zero error, then it's useful to establish this baseline level", "tokens": [50364, 400, 370, 498, 309, 1542, 411, 341, 11, 291, 576, 16886, 300, 428, 9284, 575, 1090, 12577, 293, 1090, 50578, 50578, 21977, 11, 4878, 4696, 341, 1582, 380, 1051, 300, 2049, 337, 428, 2539, 5821, 13, 50854, 50854, 407, 281, 20858, 11, 321, 600, 1612, 300, 1237, 412, 1968, 428, 3097, 6713, 307, 2416, 307, 257, 51092, 51092, 636, 281, 980, 498, 428, 9284, 575, 1090, 12577, 13, 51264, 51264, 583, 322, 5821, 689, 264, 1412, 307, 2171, 445, 24518, 293, 307, 1536, 68, 296, 964, 420, 42867, 51560, 51560, 281, 1562, 2066, 281, 483, 281, 4018, 6713, 11, 550, 309, 311, 4420, 281, 8327, 341, 20518, 1496, 51826, 51826], "temperature": 0.0, "avg_logprob": -0.08903364624295916, "compression_ratio": 1.7411347517730495, "no_speech_prob": 2.5359906885569217e-07}, {"id": 114, "seek": 51268, "start": 512.68, "end": 516.56, "text": " of performance so that rather than just asking, is my training error large?", "tokens": [50364, 295, 3389, 370, 300, 2831, 813, 445, 3365, 11, 307, 452, 3097, 6713, 2416, 30, 50558, 50558, 509, 393, 1029, 11, 307, 452, 3097, 6713, 2416, 4972, 281, 437, 286, 1454, 286, 727, 483, 281, 4728, 11, 50836, 50836, 1270, 382, 307, 452, 3097, 6713, 2416, 4972, 281, 437, 6255, 393, 360, 322, 264, 5633, 30, 51062, 51062, 400, 300, 2709, 291, 257, 544, 8559, 1401, 322, 577, 1400, 1314, 291, 366, 294, 2115, 295, 257, 3097, 51296, 51296, 6713, 490, 689, 291, 1454, 281, 483, 281, 13, 51444, 51444, 400, 550, 14138, 11, 1237, 412, 1968, 428, 3278, 24071, 6713, 307, 709, 4833, 813, 51630, 51630], "temperature": 0.0, "avg_logprob": -0.14144116147942498, "compression_ratio": 1.9, "no_speech_prob": 8.267739758593962e-06}, {"id": 115, "seek": 51268, "start": 516.56, "end": 522.12, "text": " You can ask, is my training error large relative to what I hope I could get to eventually,", "tokens": [50364, 295, 3389, 370, 300, 2831, 813, 445, 3365, 11, 307, 452, 3097, 6713, 2416, 30, 50558, 50558, 509, 393, 1029, 11, 307, 452, 3097, 6713, 2416, 4972, 281, 437, 286, 1454, 286, 727, 483, 281, 4728, 11, 50836, 50836, 1270, 382, 307, 452, 3097, 6713, 2416, 4972, 281, 437, 6255, 393, 360, 322, 264, 5633, 30, 51062, 51062, 400, 300, 2709, 291, 257, 544, 8559, 1401, 322, 577, 1400, 1314, 291, 366, 294, 2115, 295, 257, 3097, 51296, 51296, 6713, 490, 689, 291, 1454, 281, 483, 281, 13, 51444, 51444, 400, 550, 14138, 11, 1237, 412, 1968, 428, 3278, 24071, 6713, 307, 709, 4833, 813, 51630, 51630], "temperature": 0.0, "avg_logprob": -0.14144116147942498, "compression_ratio": 1.9, "no_speech_prob": 8.267739758593962e-06}, {"id": 116, "seek": 51268, "start": 522.12, "end": 526.64, "text": " such as is my training error large relative to what humans can do on the task?", "tokens": [50364, 295, 3389, 370, 300, 2831, 813, 445, 3365, 11, 307, 452, 3097, 6713, 2416, 30, 50558, 50558, 509, 393, 1029, 11, 307, 452, 3097, 6713, 2416, 4972, 281, 437, 286, 1454, 286, 727, 483, 281, 4728, 11, 50836, 50836, 1270, 382, 307, 452, 3097, 6713, 2416, 4972, 281, 437, 6255, 393, 360, 322, 264, 5633, 30, 51062, 51062, 400, 300, 2709, 291, 257, 544, 8559, 1401, 322, 577, 1400, 1314, 291, 366, 294, 2115, 295, 257, 3097, 51296, 51296, 6713, 490, 689, 291, 1454, 281, 483, 281, 13, 51444, 51444, 400, 550, 14138, 11, 1237, 412, 1968, 428, 3278, 24071, 6713, 307, 709, 4833, 813, 51630, 51630], "temperature": 0.0, "avg_logprob": -0.14144116147942498, "compression_ratio": 1.9, "no_speech_prob": 8.267739758593962e-06}, {"id": 117, "seek": 51268, "start": 526.64, "end": 531.3199999999999, "text": " And that gives you a more accurate read on how far away you are in terms of a training", "tokens": [50364, 295, 3389, 370, 300, 2831, 813, 445, 3365, 11, 307, 452, 3097, 6713, 2416, 30, 50558, 50558, 509, 393, 1029, 11, 307, 452, 3097, 6713, 2416, 4972, 281, 437, 286, 1454, 286, 727, 483, 281, 4728, 11, 50836, 50836, 1270, 382, 307, 452, 3097, 6713, 2416, 4972, 281, 437, 6255, 393, 360, 322, 264, 5633, 30, 51062, 51062, 400, 300, 2709, 291, 257, 544, 8559, 1401, 322, 577, 1400, 1314, 291, 366, 294, 2115, 295, 257, 3097, 51296, 51296, 6713, 490, 689, 291, 1454, 281, 483, 281, 13, 51444, 51444, 400, 550, 14138, 11, 1237, 412, 1968, 428, 3278, 24071, 6713, 307, 709, 4833, 813, 51630, 51630], "temperature": 0.0, "avg_logprob": -0.14144116147942498, "compression_ratio": 1.9, "no_speech_prob": 8.267739758593962e-06}, {"id": 118, "seek": 51268, "start": 531.3199999999999, "end": 534.28, "text": " error from where you hope to get to.", "tokens": [50364, 295, 3389, 370, 300, 2831, 813, 445, 3365, 11, 307, 452, 3097, 6713, 2416, 30, 50558, 50558, 509, 393, 1029, 11, 307, 452, 3097, 6713, 2416, 4972, 281, 437, 286, 1454, 286, 727, 483, 281, 4728, 11, 50836, 50836, 1270, 382, 307, 452, 3097, 6713, 2416, 4972, 281, 437, 6255, 393, 360, 322, 264, 5633, 30, 51062, 51062, 400, 300, 2709, 291, 257, 544, 8559, 1401, 322, 577, 1400, 1314, 291, 366, 294, 2115, 295, 257, 3097, 51296, 51296, 6713, 490, 689, 291, 1454, 281, 483, 281, 13, 51444, 51444, 400, 550, 14138, 11, 1237, 412, 1968, 428, 3278, 24071, 6713, 307, 709, 4833, 813, 51630, 51630], "temperature": 0.0, "avg_logprob": -0.14144116147942498, "compression_ratio": 1.9, "no_speech_prob": 8.267739758593962e-06}, {"id": 119, "seek": 51268, "start": 534.28, "end": 538.0, "text": " And then similarly, looking at whether your cross validation error is much larger than", "tokens": [50364, 295, 3389, 370, 300, 2831, 813, 445, 3365, 11, 307, 452, 3097, 6713, 2416, 30, 50558, 50558, 509, 393, 1029, 11, 307, 452, 3097, 6713, 2416, 4972, 281, 437, 286, 1454, 286, 727, 483, 281, 4728, 11, 50836, 50836, 1270, 382, 307, 452, 3097, 6713, 2416, 4972, 281, 437, 6255, 393, 360, 322, 264, 5633, 30, 51062, 51062, 400, 300, 2709, 291, 257, 544, 8559, 1401, 322, 577, 1400, 1314, 291, 366, 294, 2115, 295, 257, 3097, 51296, 51296, 6713, 490, 689, 291, 1454, 281, 483, 281, 13, 51444, 51444, 400, 550, 14138, 11, 1237, 412, 1968, 428, 3278, 24071, 6713, 307, 709, 4833, 813, 51630, 51630], "temperature": 0.0, "avg_logprob": -0.14144116147942498, "compression_ratio": 1.9, "no_speech_prob": 8.267739758593962e-06}, {"id": 120, "seek": 53800, "start": 538.0, "end": 543.12, "text": " your training error gives you a sense of whether or not your algorithm may have a high variance", "tokens": [50364, 428, 3097, 6713, 2709, 291, 257, 2020, 295, 1968, 420, 406, 428, 9284, 815, 362, 257, 1090, 21977, 50620, 50620, 1154, 382, 731, 13, 50718, 50718, 400, 294, 3124, 11, 341, 307, 577, 286, 2049, 486, 574, 412, 613, 3547, 281, 6995, 498, 452, 2539, 50918, 50918, 9284, 575, 257, 1090, 12577, 420, 1090, 21977, 1154, 13, 51078, 51078, 823, 11, 281, 3052, 43212, 527, 24002, 466, 577, 257, 2539, 9284, 307, 884, 11, 456, 311, 472, 51342, 51342, 661, 551, 300, 286, 1352, 4420, 281, 519, 466, 11, 597, 307, 264, 2539, 7605, 13, 51626, 51626], "temperature": 0.0, "avg_logprob": -0.11215258126307015, "compression_ratio": 1.709016393442623, "no_speech_prob": 8.012834769033361e-06}, {"id": 121, "seek": 53800, "start": 543.12, "end": 545.08, "text": " problem as well.", "tokens": [50364, 428, 3097, 6713, 2709, 291, 257, 2020, 295, 1968, 420, 406, 428, 9284, 815, 362, 257, 1090, 21977, 50620, 50620, 1154, 382, 731, 13, 50718, 50718, 400, 294, 3124, 11, 341, 307, 577, 286, 2049, 486, 574, 412, 613, 3547, 281, 6995, 498, 452, 2539, 50918, 50918, 9284, 575, 257, 1090, 12577, 420, 1090, 21977, 1154, 13, 51078, 51078, 823, 11, 281, 3052, 43212, 527, 24002, 466, 577, 257, 2539, 9284, 307, 884, 11, 456, 311, 472, 51342, 51342, 661, 551, 300, 286, 1352, 4420, 281, 519, 466, 11, 597, 307, 264, 2539, 7605, 13, 51626, 51626], "temperature": 0.0, "avg_logprob": -0.11215258126307015, "compression_ratio": 1.709016393442623, "no_speech_prob": 8.012834769033361e-06}, {"id": 122, "seek": 53800, "start": 545.08, "end": 549.08, "text": " And in practice, this is how I often will look at these numbers to judge if my learning", "tokens": [50364, 428, 3097, 6713, 2709, 291, 257, 2020, 295, 1968, 420, 406, 428, 9284, 815, 362, 257, 1090, 21977, 50620, 50620, 1154, 382, 731, 13, 50718, 50718, 400, 294, 3124, 11, 341, 307, 577, 286, 2049, 486, 574, 412, 613, 3547, 281, 6995, 498, 452, 2539, 50918, 50918, 9284, 575, 257, 1090, 12577, 420, 1090, 21977, 1154, 13, 51078, 51078, 823, 11, 281, 3052, 43212, 527, 24002, 466, 577, 257, 2539, 9284, 307, 884, 11, 456, 311, 472, 51342, 51342, 661, 551, 300, 286, 1352, 4420, 281, 519, 466, 11, 597, 307, 264, 2539, 7605, 13, 51626, 51626], "temperature": 0.0, "avg_logprob": -0.11215258126307015, "compression_ratio": 1.709016393442623, "no_speech_prob": 8.012834769033361e-06}, {"id": 123, "seek": 53800, "start": 549.08, "end": 552.28, "text": " algorithm has a high bias or high variance problem.", "tokens": [50364, 428, 3097, 6713, 2709, 291, 257, 2020, 295, 1968, 420, 406, 428, 9284, 815, 362, 257, 1090, 21977, 50620, 50620, 1154, 382, 731, 13, 50718, 50718, 400, 294, 3124, 11, 341, 307, 577, 286, 2049, 486, 574, 412, 613, 3547, 281, 6995, 498, 452, 2539, 50918, 50918, 9284, 575, 257, 1090, 12577, 420, 1090, 21977, 1154, 13, 51078, 51078, 823, 11, 281, 3052, 43212, 527, 24002, 466, 577, 257, 2539, 9284, 307, 884, 11, 456, 311, 472, 51342, 51342, 661, 551, 300, 286, 1352, 4420, 281, 519, 466, 11, 597, 307, 264, 2539, 7605, 13, 51626, 51626], "temperature": 0.0, "avg_logprob": -0.11215258126307015, "compression_ratio": 1.709016393442623, "no_speech_prob": 8.012834769033361e-06}, {"id": 124, "seek": 53800, "start": 552.28, "end": 557.56, "text": " Now, to further hone our intuition about how a learning algorithm is doing, there's one", "tokens": [50364, 428, 3097, 6713, 2709, 291, 257, 2020, 295, 1968, 420, 406, 428, 9284, 815, 362, 257, 1090, 21977, 50620, 50620, 1154, 382, 731, 13, 50718, 50718, 400, 294, 3124, 11, 341, 307, 577, 286, 2049, 486, 574, 412, 613, 3547, 281, 6995, 498, 452, 2539, 50918, 50918, 9284, 575, 257, 1090, 12577, 420, 1090, 21977, 1154, 13, 51078, 51078, 823, 11, 281, 3052, 43212, 527, 24002, 466, 577, 257, 2539, 9284, 307, 884, 11, 456, 311, 472, 51342, 51342, 661, 551, 300, 286, 1352, 4420, 281, 519, 466, 11, 597, 307, 264, 2539, 7605, 13, 51626, 51626], "temperature": 0.0, "avg_logprob": -0.11215258126307015, "compression_ratio": 1.709016393442623, "no_speech_prob": 8.012834769033361e-06}, {"id": 125, "seek": 53800, "start": 557.56, "end": 563.24, "text": " other thing that I found useful to think about, which is the learning curve.", "tokens": [50364, 428, 3097, 6713, 2709, 291, 257, 2020, 295, 1968, 420, 406, 428, 9284, 815, 362, 257, 1090, 21977, 50620, 50620, 1154, 382, 731, 13, 50718, 50718, 400, 294, 3124, 11, 341, 307, 577, 286, 2049, 486, 574, 412, 613, 3547, 281, 6995, 498, 452, 2539, 50918, 50918, 9284, 575, 257, 1090, 12577, 420, 1090, 21977, 1154, 13, 51078, 51078, 823, 11, 281, 3052, 43212, 527, 24002, 466, 577, 257, 2539, 9284, 307, 884, 11, 456, 311, 472, 51342, 51342, 661, 551, 300, 286, 1352, 4420, 281, 519, 466, 11, 597, 307, 264, 2539, 7605, 13, 51626, 51626], "temperature": 0.0, "avg_logprob": -0.11215258126307015, "compression_ratio": 1.709016393442623, "no_speech_prob": 8.012834769033361e-06}, {"id": 126, "seek": 56324, "start": 563.24, "end": 570.24, "text": " Let's take a look at what that means in the next video.", "tokens": [50364, 961, 311, 747, 257, 574, 412, 437, 300, 1355, 294, 264, 958, 960, 13, 50714], "temperature": 0.0, "avg_logprob": -0.28778502520392923, "compression_ratio": 0.9482758620689655, "no_speech_prob": 0.00023008206335362047}], "language": "en", "video_id": "8Rl_2WQbmlc", "entity": "ML Specialization, Andrew Ng (2022)"}}