{"video_id": "3iDMb-EUQPA", "title": "4.14 Vectorization (optional) | How neural networks are implemented efficiently-- [ML- Andrew Ng]", "description": "Second Course:\nAdvanced Learning Algorithms.\n\n\nIf you liked the content please subscribe and put a little blue thumb.\nTake heart!", "author": "Machine Learning", "keywords": [], "channel_url": "https://www.youtube.com/channel/UClG5HEAJJFOavT_UolqYROQ", "length": 263, "views": 102, "publish_date": "11/04/2022", "timestamp": 1661385600, "entity": "ML Specialization, Andrew Ng (2022)", "transcript": {"text": " One of the reasons that deep learning researchers have been able to scale up neural networks and build really large neural networks over the last decade is because neural networks can be vectorized. They can be implemented very efficiently using matrix multiplications. And it turns out that parallel computing hardware, including GPUs, but also some CPU functions are very good at doing very large matrix multiplications. In this video, we'll take a look at how these vectorized implementations of neural networks work. Without these ideas, I don't think deep learning would be anywhere near success in scale today. Here on the left is the code that you had seen previously of how you would implement for a prop or for a propagation in a single layer. This here is the input w, the weights of the first, second, and third neurons, say, parameters b. And then this is the same code as what you saw before. And this will output three numbers, say, like that. And if you actually implement this computation, you get 101. It turns out you can develop a vectorized implementation of this function as follows. Set x to be equal to this. Notice the double square brackets. So this is now a 2D array, like in TensorFlow. W is the same as before. And b, I'm now using capital B, is also a 1 by 3 2D array. And then it turns out that all of these steps, this for loop inside, can be replaced with just a couple lines of code. Z equals np.matmul. Matmul is how NumPy carries out matrix multiplication, where now x and w are both matrices. And so you just multiply them together. And it turns out that this for loop, all of these lines of code, can be replaced with just a couple lines of code, which gives a vectorized implementation of this function. So you compute z, which is now a matrix again, as NumPy.matmul between a in and w, where here a in and w are both matrices. And matmul is how NumPy carries out a matrix multiplication. It multiplies two matrices together and then adds the matrix b to it. And then a here, or a out, is equal to the activation function g, that is a sigmoid function, multiplied element-wise to this matrix z. And then you finally return a out. So this is what the code looks like. Notice that in the vectorized implementation, all of these quantities, x, which is fed into the value of a in, as well as w, b, as well as z, and a out, all of these are now 2D arrays. All of these are matrices. And this turns out to be a very efficient implementation of one step of forward propagation through a dense layer in the neural network. So this is code for a vectorized implementation of forward prop in a neural network. But what is this code doing and how does it actually work? And what is this matmul actually doing? In the next two videos, both also optional, we'll go over matrix multiplication and how that works. If you're familiar with linear algebra, if you're familiar with vectors, matrices, transposes, and matrix matrix multiplications, you can safely just quickly skim over these two videos and jump to the last video of this week. And then in the last video of this week, also optional, we'll dive into more detail to explain how matmul gives you this vectorized implementation. And so with that, let's go on to the next video where we'll take a look at what matrix multiplication is.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 7.16, "text": " One of the reasons that deep learning researchers have been able to scale up neural networks", "tokens": [50364, 1485, 295, 264, 4112, 300, 2452, 2539, 10309, 362, 668, 1075, 281, 4373, 493, 18161, 9590, 50722, 50722, 293, 1322, 534, 2416, 18161, 9590, 670, 264, 1036, 10378, 307, 570, 18161, 9590, 50976, 50976, 393, 312, 8062, 1602, 13, 51072, 51072, 814, 393, 312, 12270, 588, 19621, 1228, 8141, 17596, 763, 13, 51330, 51330, 400, 309, 4523, 484, 300, 8952, 15866, 8837, 11, 3009, 18407, 82, 11, 457, 611, 512, 13199, 6828, 51664, 51664], "temperature": 0.0, "avg_logprob": -0.13960958781995272, "compression_ratio": 1.5826086956521739, "no_speech_prob": 0.005299638025462627}, {"id": 1, "seek": 0, "start": 7.16, "end": 12.24, "text": " and build really large neural networks over the last decade is because neural networks", "tokens": [50364, 1485, 295, 264, 4112, 300, 2452, 2539, 10309, 362, 668, 1075, 281, 4373, 493, 18161, 9590, 50722, 50722, 293, 1322, 534, 2416, 18161, 9590, 670, 264, 1036, 10378, 307, 570, 18161, 9590, 50976, 50976, 393, 312, 8062, 1602, 13, 51072, 51072, 814, 393, 312, 12270, 588, 19621, 1228, 8141, 17596, 763, 13, 51330, 51330, 400, 309, 4523, 484, 300, 8952, 15866, 8837, 11, 3009, 18407, 82, 11, 457, 611, 512, 13199, 6828, 51664, 51664], "temperature": 0.0, "avg_logprob": -0.13960958781995272, "compression_ratio": 1.5826086956521739, "no_speech_prob": 0.005299638025462627}, {"id": 2, "seek": 0, "start": 12.24, "end": 14.16, "text": " can be vectorized.", "tokens": [50364, 1485, 295, 264, 4112, 300, 2452, 2539, 10309, 362, 668, 1075, 281, 4373, 493, 18161, 9590, 50722, 50722, 293, 1322, 534, 2416, 18161, 9590, 670, 264, 1036, 10378, 307, 570, 18161, 9590, 50976, 50976, 393, 312, 8062, 1602, 13, 51072, 51072, 814, 393, 312, 12270, 588, 19621, 1228, 8141, 17596, 763, 13, 51330, 51330, 400, 309, 4523, 484, 300, 8952, 15866, 8837, 11, 3009, 18407, 82, 11, 457, 611, 512, 13199, 6828, 51664, 51664], "temperature": 0.0, "avg_logprob": -0.13960958781995272, "compression_ratio": 1.5826086956521739, "no_speech_prob": 0.005299638025462627}, {"id": 3, "seek": 0, "start": 14.16, "end": 19.32, "text": " They can be implemented very efficiently using matrix multiplications.", "tokens": [50364, 1485, 295, 264, 4112, 300, 2452, 2539, 10309, 362, 668, 1075, 281, 4373, 493, 18161, 9590, 50722, 50722, 293, 1322, 534, 2416, 18161, 9590, 670, 264, 1036, 10378, 307, 570, 18161, 9590, 50976, 50976, 393, 312, 8062, 1602, 13, 51072, 51072, 814, 393, 312, 12270, 588, 19621, 1228, 8141, 17596, 763, 13, 51330, 51330, 400, 309, 4523, 484, 300, 8952, 15866, 8837, 11, 3009, 18407, 82, 11, 457, 611, 512, 13199, 6828, 51664, 51664], "temperature": 0.0, "avg_logprob": -0.13960958781995272, "compression_ratio": 1.5826086956521739, "no_speech_prob": 0.005299638025462627}, {"id": 4, "seek": 0, "start": 19.32, "end": 26.0, "text": " And it turns out that parallel computing hardware, including GPUs, but also some CPU functions", "tokens": [50364, 1485, 295, 264, 4112, 300, 2452, 2539, 10309, 362, 668, 1075, 281, 4373, 493, 18161, 9590, 50722, 50722, 293, 1322, 534, 2416, 18161, 9590, 670, 264, 1036, 10378, 307, 570, 18161, 9590, 50976, 50976, 393, 312, 8062, 1602, 13, 51072, 51072, 814, 393, 312, 12270, 588, 19621, 1228, 8141, 17596, 763, 13, 51330, 51330, 400, 309, 4523, 484, 300, 8952, 15866, 8837, 11, 3009, 18407, 82, 11, 457, 611, 512, 13199, 6828, 51664, 51664], "temperature": 0.0, "avg_logprob": -0.13960958781995272, "compression_ratio": 1.5826086956521739, "no_speech_prob": 0.005299638025462627}, {"id": 5, "seek": 2600, "start": 26.0, "end": 30.48, "text": " are very good at doing very large matrix multiplications.", "tokens": [50364, 366, 588, 665, 412, 884, 588, 2416, 8141, 17596, 763, 13, 50588, 50588, 682, 341, 960, 11, 321, 603, 747, 257, 574, 412, 577, 613, 8062, 1602, 4445, 763, 295, 18161, 9590, 50864, 50864, 589, 13, 50914, 50914, 9129, 613, 3487, 11, 286, 500, 380, 519, 2452, 2539, 576, 312, 4992, 2651, 2245, 294, 4373, 965, 13, 51195, 51195, 1692, 322, 264, 1411, 307, 264, 3089, 300, 291, 632, 1612, 8046, 295, 577, 291, 576, 4445, 51528, 51528, 337, 257, 2365, 420, 337, 257, 38377, 294, 257, 2167, 4583, 13, 51834, 51834], "temperature": 0.0, "avg_logprob": -0.12311572216926737, "compression_ratio": 1.5925925925925926, "no_speech_prob": 9.079713890969288e-06}, {"id": 6, "seek": 2600, "start": 30.48, "end": 36.0, "text": " In this video, we'll take a look at how these vectorized implementations of neural networks", "tokens": [50364, 366, 588, 665, 412, 884, 588, 2416, 8141, 17596, 763, 13, 50588, 50588, 682, 341, 960, 11, 321, 603, 747, 257, 574, 412, 577, 613, 8062, 1602, 4445, 763, 295, 18161, 9590, 50864, 50864, 589, 13, 50914, 50914, 9129, 613, 3487, 11, 286, 500, 380, 519, 2452, 2539, 576, 312, 4992, 2651, 2245, 294, 4373, 965, 13, 51195, 51195, 1692, 322, 264, 1411, 307, 264, 3089, 300, 291, 632, 1612, 8046, 295, 577, 291, 576, 4445, 51528, 51528, 337, 257, 2365, 420, 337, 257, 38377, 294, 257, 2167, 4583, 13, 51834, 51834], "temperature": 0.0, "avg_logprob": -0.12311572216926737, "compression_ratio": 1.5925925925925926, "no_speech_prob": 9.079713890969288e-06}, {"id": 7, "seek": 2600, "start": 36.0, "end": 37.0, "text": " work.", "tokens": [50364, 366, 588, 665, 412, 884, 588, 2416, 8141, 17596, 763, 13, 50588, 50588, 682, 341, 960, 11, 321, 603, 747, 257, 574, 412, 577, 613, 8062, 1602, 4445, 763, 295, 18161, 9590, 50864, 50864, 589, 13, 50914, 50914, 9129, 613, 3487, 11, 286, 500, 380, 519, 2452, 2539, 576, 312, 4992, 2651, 2245, 294, 4373, 965, 13, 51195, 51195, 1692, 322, 264, 1411, 307, 264, 3089, 300, 291, 632, 1612, 8046, 295, 577, 291, 576, 4445, 51528, 51528, 337, 257, 2365, 420, 337, 257, 38377, 294, 257, 2167, 4583, 13, 51834, 51834], "temperature": 0.0, "avg_logprob": -0.12311572216926737, "compression_ratio": 1.5925925925925926, "no_speech_prob": 9.079713890969288e-06}, {"id": 8, "seek": 2600, "start": 37.0, "end": 42.620000000000005, "text": " Without these ideas, I don't think deep learning would be anywhere near success in scale today.", "tokens": [50364, 366, 588, 665, 412, 884, 588, 2416, 8141, 17596, 763, 13, 50588, 50588, 682, 341, 960, 11, 321, 603, 747, 257, 574, 412, 577, 613, 8062, 1602, 4445, 763, 295, 18161, 9590, 50864, 50864, 589, 13, 50914, 50914, 9129, 613, 3487, 11, 286, 500, 380, 519, 2452, 2539, 576, 312, 4992, 2651, 2245, 294, 4373, 965, 13, 51195, 51195, 1692, 322, 264, 1411, 307, 264, 3089, 300, 291, 632, 1612, 8046, 295, 577, 291, 576, 4445, 51528, 51528, 337, 257, 2365, 420, 337, 257, 38377, 294, 257, 2167, 4583, 13, 51834, 51834], "temperature": 0.0, "avg_logprob": -0.12311572216926737, "compression_ratio": 1.5925925925925926, "no_speech_prob": 9.079713890969288e-06}, {"id": 9, "seek": 2600, "start": 42.620000000000005, "end": 49.28, "text": " Here on the left is the code that you had seen previously of how you would implement", "tokens": [50364, 366, 588, 665, 412, 884, 588, 2416, 8141, 17596, 763, 13, 50588, 50588, 682, 341, 960, 11, 321, 603, 747, 257, 574, 412, 577, 613, 8062, 1602, 4445, 763, 295, 18161, 9590, 50864, 50864, 589, 13, 50914, 50914, 9129, 613, 3487, 11, 286, 500, 380, 519, 2452, 2539, 576, 312, 4992, 2651, 2245, 294, 4373, 965, 13, 51195, 51195, 1692, 322, 264, 1411, 307, 264, 3089, 300, 291, 632, 1612, 8046, 295, 577, 291, 576, 4445, 51528, 51528, 337, 257, 2365, 420, 337, 257, 38377, 294, 257, 2167, 4583, 13, 51834, 51834], "temperature": 0.0, "avg_logprob": -0.12311572216926737, "compression_ratio": 1.5925925925925926, "no_speech_prob": 9.079713890969288e-06}, {"id": 10, "seek": 2600, "start": 49.28, "end": 55.400000000000006, "text": " for a prop or for a propagation in a single layer.", "tokens": [50364, 366, 588, 665, 412, 884, 588, 2416, 8141, 17596, 763, 13, 50588, 50588, 682, 341, 960, 11, 321, 603, 747, 257, 574, 412, 577, 613, 8062, 1602, 4445, 763, 295, 18161, 9590, 50864, 50864, 589, 13, 50914, 50914, 9129, 613, 3487, 11, 286, 500, 380, 519, 2452, 2539, 576, 312, 4992, 2651, 2245, 294, 4373, 965, 13, 51195, 51195, 1692, 322, 264, 1411, 307, 264, 3089, 300, 291, 632, 1612, 8046, 295, 577, 291, 576, 4445, 51528, 51528, 337, 257, 2365, 420, 337, 257, 38377, 294, 257, 2167, 4583, 13, 51834, 51834], "temperature": 0.0, "avg_logprob": -0.12311572216926737, "compression_ratio": 1.5925925925925926, "no_speech_prob": 9.079713890969288e-06}, {"id": 11, "seek": 5540, "start": 55.4, "end": 64.6, "text": " This here is the input w, the weights of the first, second, and third neurons, say, parameters", "tokens": [50364, 639, 510, 307, 264, 4846, 261, 11, 264, 17443, 295, 264, 700, 11, 1150, 11, 293, 2636, 22027, 11, 584, 11, 9834, 50824, 50824, 272, 13, 50874, 50874, 400, 550, 341, 307, 264, 912, 3089, 382, 437, 291, 1866, 949, 13, 51040, 51040, 400, 341, 486, 5598, 1045, 3547, 11, 584, 11, 411, 300, 13, 51217, 51217, 400, 498, 291, 767, 4445, 341, 24903, 11, 291, 483, 21055, 13, 51480, 51480], "temperature": 0.0, "avg_logprob": -0.16040280747087035, "compression_ratio": 1.5317919075144508, "no_speech_prob": 8.09099874459207e-05}, {"id": 12, "seek": 5540, "start": 64.6, "end": 65.6, "text": " b.", "tokens": [50364, 639, 510, 307, 264, 4846, 261, 11, 264, 17443, 295, 264, 700, 11, 1150, 11, 293, 2636, 22027, 11, 584, 11, 9834, 50824, 50824, 272, 13, 50874, 50874, 400, 550, 341, 307, 264, 912, 3089, 382, 437, 291, 1866, 949, 13, 51040, 51040, 400, 341, 486, 5598, 1045, 3547, 11, 584, 11, 411, 300, 13, 51217, 51217, 400, 498, 291, 767, 4445, 341, 24903, 11, 291, 483, 21055, 13, 51480, 51480], "temperature": 0.0, "avg_logprob": -0.16040280747087035, "compression_ratio": 1.5317919075144508, "no_speech_prob": 8.09099874459207e-05}, {"id": 13, "seek": 5540, "start": 65.6, "end": 68.92, "text": " And then this is the same code as what you saw before.", "tokens": [50364, 639, 510, 307, 264, 4846, 261, 11, 264, 17443, 295, 264, 700, 11, 1150, 11, 293, 2636, 22027, 11, 584, 11, 9834, 50824, 50824, 272, 13, 50874, 50874, 400, 550, 341, 307, 264, 912, 3089, 382, 437, 291, 1866, 949, 13, 51040, 51040, 400, 341, 486, 5598, 1045, 3547, 11, 584, 11, 411, 300, 13, 51217, 51217, 400, 498, 291, 767, 4445, 341, 24903, 11, 291, 483, 21055, 13, 51480, 51480], "temperature": 0.0, "avg_logprob": -0.16040280747087035, "compression_ratio": 1.5317919075144508, "no_speech_prob": 8.09099874459207e-05}, {"id": 14, "seek": 5540, "start": 68.92, "end": 72.46, "text": " And this will output three numbers, say, like that.", "tokens": [50364, 639, 510, 307, 264, 4846, 261, 11, 264, 17443, 295, 264, 700, 11, 1150, 11, 293, 2636, 22027, 11, 584, 11, 9834, 50824, 50824, 272, 13, 50874, 50874, 400, 550, 341, 307, 264, 912, 3089, 382, 437, 291, 1866, 949, 13, 51040, 51040, 400, 341, 486, 5598, 1045, 3547, 11, 584, 11, 411, 300, 13, 51217, 51217, 400, 498, 291, 767, 4445, 341, 24903, 11, 291, 483, 21055, 13, 51480, 51480], "temperature": 0.0, "avg_logprob": -0.16040280747087035, "compression_ratio": 1.5317919075144508, "no_speech_prob": 8.09099874459207e-05}, {"id": 15, "seek": 5540, "start": 72.46, "end": 77.72, "text": " And if you actually implement this computation, you get 101.", "tokens": [50364, 639, 510, 307, 264, 4846, 261, 11, 264, 17443, 295, 264, 700, 11, 1150, 11, 293, 2636, 22027, 11, 584, 11, 9834, 50824, 50824, 272, 13, 50874, 50874, 400, 550, 341, 307, 264, 912, 3089, 382, 437, 291, 1866, 949, 13, 51040, 51040, 400, 341, 486, 5598, 1045, 3547, 11, 584, 11, 411, 300, 13, 51217, 51217, 400, 498, 291, 767, 4445, 341, 24903, 11, 291, 483, 21055, 13, 51480, 51480], "temperature": 0.0, "avg_logprob": -0.16040280747087035, "compression_ratio": 1.5317919075144508, "no_speech_prob": 8.09099874459207e-05}, {"id": 16, "seek": 7772, "start": 77.72, "end": 86.56, "text": " It turns out you can develop a vectorized implementation of this function as follows.", "tokens": [50364, 467, 4523, 484, 291, 393, 1499, 257, 8062, 1602, 11420, 295, 341, 2445, 382, 10002, 13, 50806, 50806, 8928, 2031, 281, 312, 2681, 281, 341, 13, 50968, 50968, 13428, 264, 3834, 3732, 26179, 13, 51059, 51059, 407, 341, 307, 586, 257, 568, 35, 10225, 11, 411, 294, 37624, 13, 51316, 51316, 343, 307, 264, 912, 382, 949, 13, 51416, 51416], "temperature": 0.0, "avg_logprob": -0.19897062547745242, "compression_ratio": 1.3518518518518519, "no_speech_prob": 1.3925007351645036e-06}, {"id": 17, "seek": 7772, "start": 86.56, "end": 89.8, "text": " Set x to be equal to this.", "tokens": [50364, 467, 4523, 484, 291, 393, 1499, 257, 8062, 1602, 11420, 295, 341, 2445, 382, 10002, 13, 50806, 50806, 8928, 2031, 281, 312, 2681, 281, 341, 13, 50968, 50968, 13428, 264, 3834, 3732, 26179, 13, 51059, 51059, 407, 341, 307, 586, 257, 568, 35, 10225, 11, 411, 294, 37624, 13, 51316, 51316, 343, 307, 264, 912, 382, 949, 13, 51416, 51416], "temperature": 0.0, "avg_logprob": -0.19897062547745242, "compression_ratio": 1.3518518518518519, "no_speech_prob": 1.3925007351645036e-06}, {"id": 18, "seek": 7772, "start": 89.8, "end": 91.62, "text": " Notice the double square brackets.", "tokens": [50364, 467, 4523, 484, 291, 393, 1499, 257, 8062, 1602, 11420, 295, 341, 2445, 382, 10002, 13, 50806, 50806, 8928, 2031, 281, 312, 2681, 281, 341, 13, 50968, 50968, 13428, 264, 3834, 3732, 26179, 13, 51059, 51059, 407, 341, 307, 586, 257, 568, 35, 10225, 11, 411, 294, 37624, 13, 51316, 51316, 343, 307, 264, 912, 382, 949, 13, 51416, 51416], "temperature": 0.0, "avg_logprob": -0.19897062547745242, "compression_ratio": 1.3518518518518519, "no_speech_prob": 1.3925007351645036e-06}, {"id": 19, "seek": 7772, "start": 91.62, "end": 96.75999999999999, "text": " So this is now a 2D array, like in TensorFlow.", "tokens": [50364, 467, 4523, 484, 291, 393, 1499, 257, 8062, 1602, 11420, 295, 341, 2445, 382, 10002, 13, 50806, 50806, 8928, 2031, 281, 312, 2681, 281, 341, 13, 50968, 50968, 13428, 264, 3834, 3732, 26179, 13, 51059, 51059, 407, 341, 307, 586, 257, 568, 35, 10225, 11, 411, 294, 37624, 13, 51316, 51316, 343, 307, 264, 912, 382, 949, 13, 51416, 51416], "temperature": 0.0, "avg_logprob": -0.19897062547745242, "compression_ratio": 1.3518518518518519, "no_speech_prob": 1.3925007351645036e-06}, {"id": 20, "seek": 7772, "start": 96.75999999999999, "end": 98.75999999999999, "text": " W is the same as before.", "tokens": [50364, 467, 4523, 484, 291, 393, 1499, 257, 8062, 1602, 11420, 295, 341, 2445, 382, 10002, 13, 50806, 50806, 8928, 2031, 281, 312, 2681, 281, 341, 13, 50968, 50968, 13428, 264, 3834, 3732, 26179, 13, 51059, 51059, 407, 341, 307, 586, 257, 568, 35, 10225, 11, 411, 294, 37624, 13, 51316, 51316, 343, 307, 264, 912, 382, 949, 13, 51416, 51416], "temperature": 0.0, "avg_logprob": -0.19897062547745242, "compression_ratio": 1.3518518518518519, "no_speech_prob": 1.3925007351645036e-06}, {"id": 21, "seek": 9876, "start": 98.76, "end": 108.96000000000001, "text": " And b, I'm now using capital B, is also a 1 by 3 2D array.", "tokens": [50364, 400, 272, 11, 286, 478, 586, 1228, 4238, 363, 11, 307, 611, 257, 502, 538, 805, 568, 35, 10225, 13, 50874, 50874, 400, 550, 309, 4523, 484, 300, 439, 295, 613, 4439, 11, 341, 337, 6367, 1854, 11, 393, 312, 10772, 365, 51232, 51232, 445, 257, 1916, 3876, 295, 3089, 13, 51328, 51328, 1176, 6915, 33808, 13, 15677, 76, 425, 13, 51438, 51438], "temperature": 0.0, "avg_logprob": -0.20778298011192908, "compression_ratio": 1.2792207792207793, "no_speech_prob": 2.769374077615794e-06}, {"id": 22, "seek": 9876, "start": 108.96000000000001, "end": 116.12, "text": " And then it turns out that all of these steps, this for loop inside, can be replaced with", "tokens": [50364, 400, 272, 11, 286, 478, 586, 1228, 4238, 363, 11, 307, 611, 257, 502, 538, 805, 568, 35, 10225, 13, 50874, 50874, 400, 550, 309, 4523, 484, 300, 439, 295, 613, 4439, 11, 341, 337, 6367, 1854, 11, 393, 312, 10772, 365, 51232, 51232, 445, 257, 1916, 3876, 295, 3089, 13, 51328, 51328, 1176, 6915, 33808, 13, 15677, 76, 425, 13, 51438, 51438], "temperature": 0.0, "avg_logprob": -0.20778298011192908, "compression_ratio": 1.2792207792207793, "no_speech_prob": 2.769374077615794e-06}, {"id": 23, "seek": 9876, "start": 116.12, "end": 118.04, "text": " just a couple lines of code.", "tokens": [50364, 400, 272, 11, 286, 478, 586, 1228, 4238, 363, 11, 307, 611, 257, 502, 538, 805, 568, 35, 10225, 13, 50874, 50874, 400, 550, 309, 4523, 484, 300, 439, 295, 613, 4439, 11, 341, 337, 6367, 1854, 11, 393, 312, 10772, 365, 51232, 51232, 445, 257, 1916, 3876, 295, 3089, 13, 51328, 51328, 1176, 6915, 33808, 13, 15677, 76, 425, 13, 51438, 51438], "temperature": 0.0, "avg_logprob": -0.20778298011192908, "compression_ratio": 1.2792207792207793, "no_speech_prob": 2.769374077615794e-06}, {"id": 24, "seek": 9876, "start": 118.04, "end": 120.24000000000001, "text": " Z equals np.matmul.", "tokens": [50364, 400, 272, 11, 286, 478, 586, 1228, 4238, 363, 11, 307, 611, 257, 502, 538, 805, 568, 35, 10225, 13, 50874, 50874, 400, 550, 309, 4523, 484, 300, 439, 295, 613, 4439, 11, 341, 337, 6367, 1854, 11, 393, 312, 10772, 365, 51232, 51232, 445, 257, 1916, 3876, 295, 3089, 13, 51328, 51328, 1176, 6915, 33808, 13, 15677, 76, 425, 13, 51438, 51438], "temperature": 0.0, "avg_logprob": -0.20778298011192908, "compression_ratio": 1.2792207792207793, "no_speech_prob": 2.769374077615794e-06}, {"id": 25, "seek": 12024, "start": 120.24, "end": 129.84, "text": " Matmul is how NumPy carries out matrix multiplication, where now x and w are both matrices.", "tokens": [50364, 6789, 76, 425, 307, 577, 22592, 47, 88, 16402, 484, 8141, 27290, 11, 689, 586, 2031, 293, 261, 366, 1293, 32284, 13, 50844, 50844, 400, 370, 291, 445, 12972, 552, 1214, 13, 51010, 51010, 400, 309, 4523, 484, 300, 341, 337, 6367, 11, 439, 295, 613, 3876, 295, 3089, 11, 393, 312, 10772, 365, 51240, 51240, 445, 257, 1916, 3876, 295, 3089, 11, 597, 2709, 257, 8062, 1602, 11420, 295, 341, 2445, 13, 51614, 51614], "temperature": 0.0, "avg_logprob": -0.07565601769979897, "compression_ratio": 1.558974358974359, "no_speech_prob": 5.771840733359568e-06}, {"id": 26, "seek": 12024, "start": 129.84, "end": 133.16, "text": " And so you just multiply them together.", "tokens": [50364, 6789, 76, 425, 307, 577, 22592, 47, 88, 16402, 484, 8141, 27290, 11, 689, 586, 2031, 293, 261, 366, 1293, 32284, 13, 50844, 50844, 400, 370, 291, 445, 12972, 552, 1214, 13, 51010, 51010, 400, 309, 4523, 484, 300, 341, 337, 6367, 11, 439, 295, 613, 3876, 295, 3089, 11, 393, 312, 10772, 365, 51240, 51240, 445, 257, 1916, 3876, 295, 3089, 11, 597, 2709, 257, 8062, 1602, 11420, 295, 341, 2445, 13, 51614, 51614], "temperature": 0.0, "avg_logprob": -0.07565601769979897, "compression_ratio": 1.558974358974359, "no_speech_prob": 5.771840733359568e-06}, {"id": 27, "seek": 12024, "start": 133.16, "end": 137.76, "text": " And it turns out that this for loop, all of these lines of code, can be replaced with", "tokens": [50364, 6789, 76, 425, 307, 577, 22592, 47, 88, 16402, 484, 8141, 27290, 11, 689, 586, 2031, 293, 261, 366, 1293, 32284, 13, 50844, 50844, 400, 370, 291, 445, 12972, 552, 1214, 13, 51010, 51010, 400, 309, 4523, 484, 300, 341, 337, 6367, 11, 439, 295, 613, 3876, 295, 3089, 11, 393, 312, 10772, 365, 51240, 51240, 445, 257, 1916, 3876, 295, 3089, 11, 597, 2709, 257, 8062, 1602, 11420, 295, 341, 2445, 13, 51614, 51614], "temperature": 0.0, "avg_logprob": -0.07565601769979897, "compression_ratio": 1.558974358974359, "no_speech_prob": 5.771840733359568e-06}, {"id": 28, "seek": 12024, "start": 137.76, "end": 145.24, "text": " just a couple lines of code, which gives a vectorized implementation of this function.", "tokens": [50364, 6789, 76, 425, 307, 577, 22592, 47, 88, 16402, 484, 8141, 27290, 11, 689, 586, 2031, 293, 261, 366, 1293, 32284, 13, 50844, 50844, 400, 370, 291, 445, 12972, 552, 1214, 13, 51010, 51010, 400, 309, 4523, 484, 300, 341, 337, 6367, 11, 439, 295, 613, 3876, 295, 3089, 11, 393, 312, 10772, 365, 51240, 51240, 445, 257, 1916, 3876, 295, 3089, 11, 597, 2709, 257, 8062, 1602, 11420, 295, 341, 2445, 13, 51614, 51614], "temperature": 0.0, "avg_logprob": -0.07565601769979897, "compression_ratio": 1.558974358974359, "no_speech_prob": 5.771840733359568e-06}, {"id": 29, "seek": 14524, "start": 145.24, "end": 154.60000000000002, "text": " So you compute z, which is now a matrix again, as NumPy.matmul between a in and w, where", "tokens": [50364, 407, 291, 14722, 710, 11, 597, 307, 586, 257, 8141, 797, 11, 382, 22592, 47, 88, 13, 15677, 76, 425, 1296, 257, 294, 293, 261, 11, 689, 50832, 50832, 510, 257, 294, 293, 261, 366, 1293, 32284, 13, 50990, 50990, 400, 3803, 76, 425, 307, 577, 22592, 47, 88, 16402, 484, 257, 8141, 27290, 13, 51242, 51242, 467, 12788, 530, 732, 32284, 1214, 293, 550, 10860, 264, 8141, 272, 281, 309, 13, 51484, 51484, 400, 550, 257, 510, 11, 420, 257, 484, 11, 307, 2681, 281, 264, 24433, 2445, 290, 11, 300, 307, 257, 4556, 3280, 327, 2445, 11, 51854, 51854], "temperature": 0.0, "avg_logprob": -0.1315584830867434, "compression_ratio": 1.7142857142857142, "no_speech_prob": 1.5056795064083417e-06}, {"id": 30, "seek": 14524, "start": 154.60000000000002, "end": 157.76000000000002, "text": " here a in and w are both matrices.", "tokens": [50364, 407, 291, 14722, 710, 11, 597, 307, 586, 257, 8141, 797, 11, 382, 22592, 47, 88, 13, 15677, 76, 425, 1296, 257, 294, 293, 261, 11, 689, 50832, 50832, 510, 257, 294, 293, 261, 366, 1293, 32284, 13, 50990, 50990, 400, 3803, 76, 425, 307, 577, 22592, 47, 88, 16402, 484, 257, 8141, 27290, 13, 51242, 51242, 467, 12788, 530, 732, 32284, 1214, 293, 550, 10860, 264, 8141, 272, 281, 309, 13, 51484, 51484, 400, 550, 257, 510, 11, 420, 257, 484, 11, 307, 2681, 281, 264, 24433, 2445, 290, 11, 300, 307, 257, 4556, 3280, 327, 2445, 11, 51854, 51854], "temperature": 0.0, "avg_logprob": -0.1315584830867434, "compression_ratio": 1.7142857142857142, "no_speech_prob": 1.5056795064083417e-06}, {"id": 31, "seek": 14524, "start": 157.76000000000002, "end": 162.8, "text": " And matmul is how NumPy carries out a matrix multiplication.", "tokens": [50364, 407, 291, 14722, 710, 11, 597, 307, 586, 257, 8141, 797, 11, 382, 22592, 47, 88, 13, 15677, 76, 425, 1296, 257, 294, 293, 261, 11, 689, 50832, 50832, 510, 257, 294, 293, 261, 366, 1293, 32284, 13, 50990, 50990, 400, 3803, 76, 425, 307, 577, 22592, 47, 88, 16402, 484, 257, 8141, 27290, 13, 51242, 51242, 467, 12788, 530, 732, 32284, 1214, 293, 550, 10860, 264, 8141, 272, 281, 309, 13, 51484, 51484, 400, 550, 257, 510, 11, 420, 257, 484, 11, 307, 2681, 281, 264, 24433, 2445, 290, 11, 300, 307, 257, 4556, 3280, 327, 2445, 11, 51854, 51854], "temperature": 0.0, "avg_logprob": -0.1315584830867434, "compression_ratio": 1.7142857142857142, "no_speech_prob": 1.5056795064083417e-06}, {"id": 32, "seek": 14524, "start": 162.8, "end": 167.64000000000001, "text": " It multiplies two matrices together and then adds the matrix b to it.", "tokens": [50364, 407, 291, 14722, 710, 11, 597, 307, 586, 257, 8141, 797, 11, 382, 22592, 47, 88, 13, 15677, 76, 425, 1296, 257, 294, 293, 261, 11, 689, 50832, 50832, 510, 257, 294, 293, 261, 366, 1293, 32284, 13, 50990, 50990, 400, 3803, 76, 425, 307, 577, 22592, 47, 88, 16402, 484, 257, 8141, 27290, 13, 51242, 51242, 467, 12788, 530, 732, 32284, 1214, 293, 550, 10860, 264, 8141, 272, 281, 309, 13, 51484, 51484, 400, 550, 257, 510, 11, 420, 257, 484, 11, 307, 2681, 281, 264, 24433, 2445, 290, 11, 300, 307, 257, 4556, 3280, 327, 2445, 11, 51854, 51854], "temperature": 0.0, "avg_logprob": -0.1315584830867434, "compression_ratio": 1.7142857142857142, "no_speech_prob": 1.5056795064083417e-06}, {"id": 33, "seek": 14524, "start": 167.64000000000001, "end": 175.04000000000002, "text": " And then a here, or a out, is equal to the activation function g, that is a sigmoid function,", "tokens": [50364, 407, 291, 14722, 710, 11, 597, 307, 586, 257, 8141, 797, 11, 382, 22592, 47, 88, 13, 15677, 76, 425, 1296, 257, 294, 293, 261, 11, 689, 50832, 50832, 510, 257, 294, 293, 261, 366, 1293, 32284, 13, 50990, 50990, 400, 3803, 76, 425, 307, 577, 22592, 47, 88, 16402, 484, 257, 8141, 27290, 13, 51242, 51242, 467, 12788, 530, 732, 32284, 1214, 293, 550, 10860, 264, 8141, 272, 281, 309, 13, 51484, 51484, 400, 550, 257, 510, 11, 420, 257, 484, 11, 307, 2681, 281, 264, 24433, 2445, 290, 11, 300, 307, 257, 4556, 3280, 327, 2445, 11, 51854, 51854], "temperature": 0.0, "avg_logprob": -0.1315584830867434, "compression_ratio": 1.7142857142857142, "no_speech_prob": 1.5056795064083417e-06}, {"id": 34, "seek": 17504, "start": 175.04, "end": 178.72, "text": " multiplied element-wise to this matrix z.", "tokens": [50364, 17207, 4478, 12, 3711, 281, 341, 8141, 710, 13, 50548, 50548, 400, 550, 291, 2721, 2736, 257, 484, 13, 50732, 50732, 407, 341, 307, 437, 264, 3089, 1542, 411, 13, 50908, 50908, 13428, 300, 294, 264, 8062, 1602, 11420, 11, 439, 295, 613, 22927, 11, 2031, 11, 597, 307, 4636, 666, 51174, 51174, 264, 2158, 295, 257, 294, 11, 382, 731, 382, 261, 11, 272, 11, 382, 731, 382, 710, 11, 293, 257, 484, 11, 439, 295, 613, 366, 586, 568, 35, 41011, 13, 51554, 51554, 1057, 295, 613, 366, 32284, 13, 51676, 51676], "temperature": 0.0, "avg_logprob": -0.11546972393989563, "compression_ratio": 1.6169154228855722, "no_speech_prob": 5.422095910034841e-06}, {"id": 35, "seek": 17504, "start": 178.72, "end": 182.4, "text": " And then you finally return a out.", "tokens": [50364, 17207, 4478, 12, 3711, 281, 341, 8141, 710, 13, 50548, 50548, 400, 550, 291, 2721, 2736, 257, 484, 13, 50732, 50732, 407, 341, 307, 437, 264, 3089, 1542, 411, 13, 50908, 50908, 13428, 300, 294, 264, 8062, 1602, 11420, 11, 439, 295, 613, 22927, 11, 2031, 11, 597, 307, 4636, 666, 51174, 51174, 264, 2158, 295, 257, 294, 11, 382, 731, 382, 261, 11, 272, 11, 382, 731, 382, 710, 11, 293, 257, 484, 11, 439, 295, 613, 366, 586, 568, 35, 41011, 13, 51554, 51554, 1057, 295, 613, 366, 32284, 13, 51676, 51676], "temperature": 0.0, "avg_logprob": -0.11546972393989563, "compression_ratio": 1.6169154228855722, "no_speech_prob": 5.422095910034841e-06}, {"id": 36, "seek": 17504, "start": 182.4, "end": 185.92, "text": " So this is what the code looks like.", "tokens": [50364, 17207, 4478, 12, 3711, 281, 341, 8141, 710, 13, 50548, 50548, 400, 550, 291, 2721, 2736, 257, 484, 13, 50732, 50732, 407, 341, 307, 437, 264, 3089, 1542, 411, 13, 50908, 50908, 13428, 300, 294, 264, 8062, 1602, 11420, 11, 439, 295, 613, 22927, 11, 2031, 11, 597, 307, 4636, 666, 51174, 51174, 264, 2158, 295, 257, 294, 11, 382, 731, 382, 261, 11, 272, 11, 382, 731, 382, 710, 11, 293, 257, 484, 11, 439, 295, 613, 366, 586, 568, 35, 41011, 13, 51554, 51554, 1057, 295, 613, 366, 32284, 13, 51676, 51676], "temperature": 0.0, "avg_logprob": -0.11546972393989563, "compression_ratio": 1.6169154228855722, "no_speech_prob": 5.422095910034841e-06}, {"id": 37, "seek": 17504, "start": 185.92, "end": 191.23999999999998, "text": " Notice that in the vectorized implementation, all of these quantities, x, which is fed into", "tokens": [50364, 17207, 4478, 12, 3711, 281, 341, 8141, 710, 13, 50548, 50548, 400, 550, 291, 2721, 2736, 257, 484, 13, 50732, 50732, 407, 341, 307, 437, 264, 3089, 1542, 411, 13, 50908, 50908, 13428, 300, 294, 264, 8062, 1602, 11420, 11, 439, 295, 613, 22927, 11, 2031, 11, 597, 307, 4636, 666, 51174, 51174, 264, 2158, 295, 257, 294, 11, 382, 731, 382, 261, 11, 272, 11, 382, 731, 382, 710, 11, 293, 257, 484, 11, 439, 295, 613, 366, 586, 568, 35, 41011, 13, 51554, 51554, 1057, 295, 613, 366, 32284, 13, 51676, 51676], "temperature": 0.0, "avg_logprob": -0.11546972393989563, "compression_ratio": 1.6169154228855722, "no_speech_prob": 5.422095910034841e-06}, {"id": 38, "seek": 17504, "start": 191.23999999999998, "end": 198.84, "text": " the value of a in, as well as w, b, as well as z, and a out, all of these are now 2D arrays.", "tokens": [50364, 17207, 4478, 12, 3711, 281, 341, 8141, 710, 13, 50548, 50548, 400, 550, 291, 2721, 2736, 257, 484, 13, 50732, 50732, 407, 341, 307, 437, 264, 3089, 1542, 411, 13, 50908, 50908, 13428, 300, 294, 264, 8062, 1602, 11420, 11, 439, 295, 613, 22927, 11, 2031, 11, 597, 307, 4636, 666, 51174, 51174, 264, 2158, 295, 257, 294, 11, 382, 731, 382, 261, 11, 272, 11, 382, 731, 382, 710, 11, 293, 257, 484, 11, 439, 295, 613, 366, 586, 568, 35, 41011, 13, 51554, 51554, 1057, 295, 613, 366, 32284, 13, 51676, 51676], "temperature": 0.0, "avg_logprob": -0.11546972393989563, "compression_ratio": 1.6169154228855722, "no_speech_prob": 5.422095910034841e-06}, {"id": 39, "seek": 17504, "start": 198.84, "end": 201.28, "text": " All of these are matrices.", "tokens": [50364, 17207, 4478, 12, 3711, 281, 341, 8141, 710, 13, 50548, 50548, 400, 550, 291, 2721, 2736, 257, 484, 13, 50732, 50732, 407, 341, 307, 437, 264, 3089, 1542, 411, 13, 50908, 50908, 13428, 300, 294, 264, 8062, 1602, 11420, 11, 439, 295, 613, 22927, 11, 2031, 11, 597, 307, 4636, 666, 51174, 51174, 264, 2158, 295, 257, 294, 11, 382, 731, 382, 261, 11, 272, 11, 382, 731, 382, 710, 11, 293, 257, 484, 11, 439, 295, 613, 366, 586, 568, 35, 41011, 13, 51554, 51554, 1057, 295, 613, 366, 32284, 13, 51676, 51676], "temperature": 0.0, "avg_logprob": -0.11546972393989563, "compression_ratio": 1.6169154228855722, "no_speech_prob": 5.422095910034841e-06}, {"id": 40, "seek": 20128, "start": 201.28, "end": 208.16, "text": " And this turns out to be a very efficient implementation of one step of forward propagation", "tokens": [50364, 400, 341, 4523, 484, 281, 312, 257, 588, 7148, 11420, 295, 472, 1823, 295, 2128, 38377, 50708, 50708, 807, 257, 18011, 4583, 294, 264, 18161, 3209, 13, 50840, 50840, 407, 341, 307, 3089, 337, 257, 8062, 1602, 11420, 295, 2128, 2365, 294, 257, 18161, 3209, 13, 51164, 51164, 583, 437, 307, 341, 3089, 884, 293, 577, 775, 309, 767, 589, 30, 51344, 51344, 400, 437, 307, 341, 3803, 76, 425, 767, 884, 30, 51524, 51524, 682, 264, 958, 732, 2145, 11, 1293, 611, 17312, 11, 321, 603, 352, 670, 8141, 27290, 293, 577, 51834, 51834], "temperature": 0.0, "avg_logprob": -0.11714723921313729, "compression_ratio": 1.7361702127659575, "no_speech_prob": 1.2289132200749009e-06}, {"id": 41, "seek": 20128, "start": 208.16, "end": 210.8, "text": " through a dense layer in the neural network.", "tokens": [50364, 400, 341, 4523, 484, 281, 312, 257, 588, 7148, 11420, 295, 472, 1823, 295, 2128, 38377, 50708, 50708, 807, 257, 18011, 4583, 294, 264, 18161, 3209, 13, 50840, 50840, 407, 341, 307, 3089, 337, 257, 8062, 1602, 11420, 295, 2128, 2365, 294, 257, 18161, 3209, 13, 51164, 51164, 583, 437, 307, 341, 3089, 884, 293, 577, 775, 309, 767, 589, 30, 51344, 51344, 400, 437, 307, 341, 3803, 76, 425, 767, 884, 30, 51524, 51524, 682, 264, 958, 732, 2145, 11, 1293, 611, 17312, 11, 321, 603, 352, 670, 8141, 27290, 293, 577, 51834, 51834], "temperature": 0.0, "avg_logprob": -0.11714723921313729, "compression_ratio": 1.7361702127659575, "no_speech_prob": 1.2289132200749009e-06}, {"id": 42, "seek": 20128, "start": 210.8, "end": 217.28, "text": " So this is code for a vectorized implementation of forward prop in a neural network.", "tokens": [50364, 400, 341, 4523, 484, 281, 312, 257, 588, 7148, 11420, 295, 472, 1823, 295, 2128, 38377, 50708, 50708, 807, 257, 18011, 4583, 294, 264, 18161, 3209, 13, 50840, 50840, 407, 341, 307, 3089, 337, 257, 8062, 1602, 11420, 295, 2128, 2365, 294, 257, 18161, 3209, 13, 51164, 51164, 583, 437, 307, 341, 3089, 884, 293, 577, 775, 309, 767, 589, 30, 51344, 51344, 400, 437, 307, 341, 3803, 76, 425, 767, 884, 30, 51524, 51524, 682, 264, 958, 732, 2145, 11, 1293, 611, 17312, 11, 321, 603, 352, 670, 8141, 27290, 293, 577, 51834, 51834], "temperature": 0.0, "avg_logprob": -0.11714723921313729, "compression_ratio": 1.7361702127659575, "no_speech_prob": 1.2289132200749009e-06}, {"id": 43, "seek": 20128, "start": 217.28, "end": 220.88, "text": " But what is this code doing and how does it actually work?", "tokens": [50364, 400, 341, 4523, 484, 281, 312, 257, 588, 7148, 11420, 295, 472, 1823, 295, 2128, 38377, 50708, 50708, 807, 257, 18011, 4583, 294, 264, 18161, 3209, 13, 50840, 50840, 407, 341, 307, 3089, 337, 257, 8062, 1602, 11420, 295, 2128, 2365, 294, 257, 18161, 3209, 13, 51164, 51164, 583, 437, 307, 341, 3089, 884, 293, 577, 775, 309, 767, 589, 30, 51344, 51344, 400, 437, 307, 341, 3803, 76, 425, 767, 884, 30, 51524, 51524, 682, 264, 958, 732, 2145, 11, 1293, 611, 17312, 11, 321, 603, 352, 670, 8141, 27290, 293, 577, 51834, 51834], "temperature": 0.0, "avg_logprob": -0.11714723921313729, "compression_ratio": 1.7361702127659575, "no_speech_prob": 1.2289132200749009e-06}, {"id": 44, "seek": 20128, "start": 220.88, "end": 224.48, "text": " And what is this matmul actually doing?", "tokens": [50364, 400, 341, 4523, 484, 281, 312, 257, 588, 7148, 11420, 295, 472, 1823, 295, 2128, 38377, 50708, 50708, 807, 257, 18011, 4583, 294, 264, 18161, 3209, 13, 50840, 50840, 407, 341, 307, 3089, 337, 257, 8062, 1602, 11420, 295, 2128, 2365, 294, 257, 18161, 3209, 13, 51164, 51164, 583, 437, 307, 341, 3089, 884, 293, 577, 775, 309, 767, 589, 30, 51344, 51344, 400, 437, 307, 341, 3803, 76, 425, 767, 884, 30, 51524, 51524, 682, 264, 958, 732, 2145, 11, 1293, 611, 17312, 11, 321, 603, 352, 670, 8141, 27290, 293, 577, 51834, 51834], "temperature": 0.0, "avg_logprob": -0.11714723921313729, "compression_ratio": 1.7361702127659575, "no_speech_prob": 1.2289132200749009e-06}, {"id": 45, "seek": 20128, "start": 224.48, "end": 230.68, "text": " In the next two videos, both also optional, we'll go over matrix multiplication and how", "tokens": [50364, 400, 341, 4523, 484, 281, 312, 257, 588, 7148, 11420, 295, 472, 1823, 295, 2128, 38377, 50708, 50708, 807, 257, 18011, 4583, 294, 264, 18161, 3209, 13, 50840, 50840, 407, 341, 307, 3089, 337, 257, 8062, 1602, 11420, 295, 2128, 2365, 294, 257, 18161, 3209, 13, 51164, 51164, 583, 437, 307, 341, 3089, 884, 293, 577, 775, 309, 767, 589, 30, 51344, 51344, 400, 437, 307, 341, 3803, 76, 425, 767, 884, 30, 51524, 51524, 682, 264, 958, 732, 2145, 11, 1293, 611, 17312, 11, 321, 603, 352, 670, 8141, 27290, 293, 577, 51834, 51834], "temperature": 0.0, "avg_logprob": -0.11714723921313729, "compression_ratio": 1.7361702127659575, "no_speech_prob": 1.2289132200749009e-06}, {"id": 46, "seek": 23068, "start": 230.68, "end": 232.36, "text": " that works.", "tokens": [50364, 300, 1985, 13, 50448, 50448, 759, 291, 434, 4963, 365, 8213, 21989, 11, 498, 291, 434, 4963, 365, 18875, 11, 32284, 11, 7132, 4201, 11, 50760, 50760, 293, 8141, 8141, 17596, 763, 11, 291, 393, 11750, 445, 2661, 1110, 332, 670, 613, 732, 2145, 51072, 51072, 293, 3012, 281, 264, 1036, 960, 295, 341, 1243, 13, 51212, 51212, 400, 550, 294, 264, 1036, 960, 295, 341, 1243, 11, 611, 17312, 11, 321, 603, 9192, 666, 544, 2607, 281, 2903, 51472, 51472, 577, 3803, 76, 425, 2709, 291, 341, 8062, 1602, 11420, 13, 51680, 51680], "temperature": 0.0, "avg_logprob": -0.08508919676144917, "compression_ratio": 1.7264573991031391, "no_speech_prob": 2.0145294911344536e-05}, {"id": 47, "seek": 23068, "start": 232.36, "end": 238.6, "text": " If you're familiar with linear algebra, if you're familiar with vectors, matrices, transposes,", "tokens": [50364, 300, 1985, 13, 50448, 50448, 759, 291, 434, 4963, 365, 8213, 21989, 11, 498, 291, 434, 4963, 365, 18875, 11, 32284, 11, 7132, 4201, 11, 50760, 50760, 293, 8141, 8141, 17596, 763, 11, 291, 393, 11750, 445, 2661, 1110, 332, 670, 613, 732, 2145, 51072, 51072, 293, 3012, 281, 264, 1036, 960, 295, 341, 1243, 13, 51212, 51212, 400, 550, 294, 264, 1036, 960, 295, 341, 1243, 11, 611, 17312, 11, 321, 603, 9192, 666, 544, 2607, 281, 2903, 51472, 51472, 577, 3803, 76, 425, 2709, 291, 341, 8062, 1602, 11420, 13, 51680, 51680], "temperature": 0.0, "avg_logprob": -0.08508919676144917, "compression_ratio": 1.7264573991031391, "no_speech_prob": 2.0145294911344536e-05}, {"id": 48, "seek": 23068, "start": 238.6, "end": 244.84, "text": " and matrix matrix multiplications, you can safely just quickly skim over these two videos", "tokens": [50364, 300, 1985, 13, 50448, 50448, 759, 291, 434, 4963, 365, 8213, 21989, 11, 498, 291, 434, 4963, 365, 18875, 11, 32284, 11, 7132, 4201, 11, 50760, 50760, 293, 8141, 8141, 17596, 763, 11, 291, 393, 11750, 445, 2661, 1110, 332, 670, 613, 732, 2145, 51072, 51072, 293, 3012, 281, 264, 1036, 960, 295, 341, 1243, 13, 51212, 51212, 400, 550, 294, 264, 1036, 960, 295, 341, 1243, 11, 611, 17312, 11, 321, 603, 9192, 666, 544, 2607, 281, 2903, 51472, 51472, 577, 3803, 76, 425, 2709, 291, 341, 8062, 1602, 11420, 13, 51680, 51680], "temperature": 0.0, "avg_logprob": -0.08508919676144917, "compression_ratio": 1.7264573991031391, "no_speech_prob": 2.0145294911344536e-05}, {"id": 49, "seek": 23068, "start": 244.84, "end": 247.64000000000001, "text": " and jump to the last video of this week.", "tokens": [50364, 300, 1985, 13, 50448, 50448, 759, 291, 434, 4963, 365, 8213, 21989, 11, 498, 291, 434, 4963, 365, 18875, 11, 32284, 11, 7132, 4201, 11, 50760, 50760, 293, 8141, 8141, 17596, 763, 11, 291, 393, 11750, 445, 2661, 1110, 332, 670, 613, 732, 2145, 51072, 51072, 293, 3012, 281, 264, 1036, 960, 295, 341, 1243, 13, 51212, 51212, 400, 550, 294, 264, 1036, 960, 295, 341, 1243, 11, 611, 17312, 11, 321, 603, 9192, 666, 544, 2607, 281, 2903, 51472, 51472, 577, 3803, 76, 425, 2709, 291, 341, 8062, 1602, 11420, 13, 51680, 51680], "temperature": 0.0, "avg_logprob": -0.08508919676144917, "compression_ratio": 1.7264573991031391, "no_speech_prob": 2.0145294911344536e-05}, {"id": 50, "seek": 23068, "start": 247.64000000000001, "end": 252.84, "text": " And then in the last video of this week, also optional, we'll dive into more detail to explain", "tokens": [50364, 300, 1985, 13, 50448, 50448, 759, 291, 434, 4963, 365, 8213, 21989, 11, 498, 291, 434, 4963, 365, 18875, 11, 32284, 11, 7132, 4201, 11, 50760, 50760, 293, 8141, 8141, 17596, 763, 11, 291, 393, 11750, 445, 2661, 1110, 332, 670, 613, 732, 2145, 51072, 51072, 293, 3012, 281, 264, 1036, 960, 295, 341, 1243, 13, 51212, 51212, 400, 550, 294, 264, 1036, 960, 295, 341, 1243, 11, 611, 17312, 11, 321, 603, 9192, 666, 544, 2607, 281, 2903, 51472, 51472, 577, 3803, 76, 425, 2709, 291, 341, 8062, 1602, 11420, 13, 51680, 51680], "temperature": 0.0, "avg_logprob": -0.08508919676144917, "compression_ratio": 1.7264573991031391, "no_speech_prob": 2.0145294911344536e-05}, {"id": 51, "seek": 23068, "start": 252.84, "end": 257.0, "text": " how matmul gives you this vectorized implementation.", "tokens": [50364, 300, 1985, 13, 50448, 50448, 759, 291, 434, 4963, 365, 8213, 21989, 11, 498, 291, 434, 4963, 365, 18875, 11, 32284, 11, 7132, 4201, 11, 50760, 50760, 293, 8141, 8141, 17596, 763, 11, 291, 393, 11750, 445, 2661, 1110, 332, 670, 613, 732, 2145, 51072, 51072, 293, 3012, 281, 264, 1036, 960, 295, 341, 1243, 13, 51212, 51212, 400, 550, 294, 264, 1036, 960, 295, 341, 1243, 11, 611, 17312, 11, 321, 603, 9192, 666, 544, 2607, 281, 2903, 51472, 51472, 577, 3803, 76, 425, 2709, 291, 341, 8062, 1602, 11420, 13, 51680, 51680], "temperature": 0.0, "avg_logprob": -0.08508919676144917, "compression_ratio": 1.7264573991031391, "no_speech_prob": 2.0145294911344536e-05}, {"id": 52, "seek": 25700, "start": 257.0, "end": 261.32, "text": " And so with that, let's go on to the next video where we'll take a look at what matrix", "tokens": [50364, 400, 370, 365, 300, 11, 718, 311, 352, 322, 281, 264, 958, 960, 689, 321, 603, 747, 257, 574, 412, 437, 8141, 50580, 50580, 27290, 307, 13, 50636], "temperature": 0.0, "avg_logprob": -0.11866850852966308, "compression_ratio": 1.1538461538461537, "no_speech_prob": 5.899723691982217e-05}, {"id": 53, "seek": 26132, "start": 261.32, "end": 288.36, "text": " multiplication is.", "tokens": [50364, 27290, 307, 13, 51716], "temperature": 0.0, "avg_logprob": -0.7246247132619222, "compression_ratio": 0.6923076923076923, "no_speech_prob": 0.00016559948562644422}], "language": "en", "video_id": "3iDMb-EUQPA", "entity": "ML Specialization, Andrew Ng (2022)"}}