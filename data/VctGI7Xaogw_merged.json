{"video_id": "VctGI7Xaogw", "title": "4.8 TensorFlow implementation | Inference in Code --[Machine Learning | Andrew Ng]", "description": "Second Course:\nAdvanced Learning Algorithms.\n\n\nIf you liked the content please subscribe and put a little blue thumb.\nTake heart!", "author": "Machine Learning", "keywords": [], "channel_url": "https://www.youtube.com/channel/UClG5HEAJJFOavT_UolqYROQ", "length": 432, "views": 155, "publish_date": "11/04/2022", "timestamp": 1661385600, "entity": "ML Specialization, Andrew Ng (2022)", "transcript": {"text": " TensorFlow is one of the leading frameworks for implementing deep learning algorithms. When I'm building projects, TensorFlow is actually the tool that I use the most often and the other popular tool is PyTorch. But we're going to focus in this specialization on TensorFlow. In this video, let's take a look at how you can implement inference in code using TensorFlow. Let's dive in. One of the remarkable things about neural networks is the same algorithm can be applied to so many different applications. So in order both for this video and in some of the labs for you to see what a neural network is doing, I'm going to use another example to illustrate inference. So sometimes I do like to roast coffee beans myself at home. My favorite is actually Colombian coffee beans. So kind of learning algorithm help optimize the quality of the beans you get from a roasting process like this. When you're roasting coffee, two parameters you get to control are the temperature at which are heating up the raw coffee beans to turn them into nicely roasted coffee beans, as well as the duration or how long you're going to roast the beans. And in this slightly simplified example, we've created the data sets of different temperatures and different durations, as well as labels showing whether the coffee you roasted is good tasting coffee, where cross here, the positive class, y equals one, corresponds to good coffee, and oh, the negative class corresponds to bad coffee. So it looks like a reasonable way to think of this data set is if you cook it at too low a temperature, it doesn't get roasted and ends up undercooked. If you cook it not for long enough, the duration is too short. There's also not a nicely roasted set of beans. And finally, if you were to cook it either for too long or for too high a temperature, then you end up with overcooked beans, they're a little bit burnt beans. And so that's not good coffee either. There's only points within this little triangle here that corresponds to good coffee. This example is simplified a bit from actual coffee roasting. Even though this example is a simplified one for the purpose of illustration, there have actually been serious projects using machine learning to optimize coffee roasting as well. So the task is given a feature vector x with both temperature and duration, say 200 degrees Celsius for 17 minutes, how can we do inference in a neural network to get it to tell us whether or not this temperature and duration setting will result in good coffee or not? It looks like this. We're going to set x to be an array of two numbers, the input features 200 degrees Celsius and 17 minutes. And this here, layer one equals dense units, three activation equals sigmoid, creates a hidden layer of neurons with three hidden units and using as the activation function, the sigmoid function. And dense here is just the name of this layer. And then finally, to compute the activation values a one, you would write a one equals layer one applied to the input features x. Then you create layer one as this first hidden layer of the neural network as dense, open prints units three, that means three units or three hidden units in this layer using as the activation function, the sigmoid function. And dense is another name for the layers of a neural network that we've learned about so far. And as you learn more about neural networks, you learn about other types of layers as well. But for now, we just use the dense layer, which is the layer type you've learned about in the last few videos for all of our examples. So next, you compute a one by taking layer one, which is actually a function and applying this function layer one to the values of x. So that's how you get a one, which is going to be a list of three numbers because they one had three units. And so a one here may just for the sake of illustration be point 2.7.3. Next, for the second hidden layer, layer two would be dense of. Now this time as one unit and again to signal and activation function. And you can then compute a two by applying this layer two function to the activation values from layer one to a one. And that will give you the value of a two, which for the sake of illustration is maybe zero point eight. Finally, if you wish to threshold is at 0.5, then you can just test if a two is greater than or equal to 0.5 and set y hat equals to one or zero positive or negative class accordingly. So that's how you do inference in the neural network using TensorFlow. There are some additional details that I didn't go over here, such as how to load the TensorFlow library and how to also load the parameters W and B of the neural network. But we'll go over that in the lab. So please be sure to take a look at the lab. But these are the key steps for for propagation and how you compute a one and a two and optionally threshold a two. Let's look at one more example. And we're going to go back to the handwritten digit classification problem. So in this example, X is a list of the pixel intensity values. So X is equal to a non-pi array of this list of pixel intensity values. And then to initialize and carry out one step before propagation, layer one is a dense layer with 25 units and a sigmoid activation function. And you then compute a one equals the layer one function applied to X to build and carry out inference through the second layer. Similarly, you set up layer two as follows and then compute a two as layer two applied to a one. And then finally, layer three is the third and final dense layer. And then finally, you can optionally threshold a three to come up with a binary prediction for Y hat. So that's the syntax for carrying out inference in TensorFlow. One thing I briefly alluded to is the structure of the non-pi arrays. TensorFlow treats data in a certain way that is important to get right. So in the next video, let's take a look at how TensorFlow handles data.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 6.22, "text": " TensorFlow is one of the leading frameworks for implementing deep learning algorithms.", "tokens": [50364, 37624, 307, 472, 295, 264, 5775, 29834, 337, 18114, 2452, 2539, 14642, 13, 50675, 50675, 1133, 286, 478, 2390, 4455, 11, 37624, 307, 767, 264, 2290, 300, 286, 764, 264, 881, 2049, 50907, 50907, 293, 264, 661, 3743, 2290, 307, 9953, 51, 284, 339, 13, 51061, 51061, 583, 321, 434, 516, 281, 1879, 294, 341, 2121, 2144, 322, 37624, 13, 51279, 51279, 682, 341, 960, 11, 718, 311, 747, 257, 574, 412, 577, 291, 393, 4445, 38253, 294, 3089, 1228, 37624, 13, 51569, 51569, 961, 311, 9192, 294, 13, 51619, 51619], "temperature": 0.0, "avg_logprob": -0.15320999391617313, "compression_ratio": 1.5826446280991735, "no_speech_prob": 0.007343058940023184}, {"id": 1, "seek": 0, "start": 6.22, "end": 10.86, "text": " When I'm building projects, TensorFlow is actually the tool that I use the most often", "tokens": [50364, 37624, 307, 472, 295, 264, 5775, 29834, 337, 18114, 2452, 2539, 14642, 13, 50675, 50675, 1133, 286, 478, 2390, 4455, 11, 37624, 307, 767, 264, 2290, 300, 286, 764, 264, 881, 2049, 50907, 50907, 293, 264, 661, 3743, 2290, 307, 9953, 51, 284, 339, 13, 51061, 51061, 583, 321, 434, 516, 281, 1879, 294, 341, 2121, 2144, 322, 37624, 13, 51279, 51279, 682, 341, 960, 11, 718, 311, 747, 257, 574, 412, 577, 291, 393, 4445, 38253, 294, 3089, 1228, 37624, 13, 51569, 51569, 961, 311, 9192, 294, 13, 51619, 51619], "temperature": 0.0, "avg_logprob": -0.15320999391617313, "compression_ratio": 1.5826446280991735, "no_speech_prob": 0.007343058940023184}, {"id": 2, "seek": 0, "start": 10.86, "end": 13.94, "text": " and the other popular tool is PyTorch.", "tokens": [50364, 37624, 307, 472, 295, 264, 5775, 29834, 337, 18114, 2452, 2539, 14642, 13, 50675, 50675, 1133, 286, 478, 2390, 4455, 11, 37624, 307, 767, 264, 2290, 300, 286, 764, 264, 881, 2049, 50907, 50907, 293, 264, 661, 3743, 2290, 307, 9953, 51, 284, 339, 13, 51061, 51061, 583, 321, 434, 516, 281, 1879, 294, 341, 2121, 2144, 322, 37624, 13, 51279, 51279, 682, 341, 960, 11, 718, 311, 747, 257, 574, 412, 577, 291, 393, 4445, 38253, 294, 3089, 1228, 37624, 13, 51569, 51569, 961, 311, 9192, 294, 13, 51619, 51619], "temperature": 0.0, "avg_logprob": -0.15320999391617313, "compression_ratio": 1.5826446280991735, "no_speech_prob": 0.007343058940023184}, {"id": 3, "seek": 0, "start": 13.94, "end": 18.3, "text": " But we're going to focus in this specialization on TensorFlow.", "tokens": [50364, 37624, 307, 472, 295, 264, 5775, 29834, 337, 18114, 2452, 2539, 14642, 13, 50675, 50675, 1133, 286, 478, 2390, 4455, 11, 37624, 307, 767, 264, 2290, 300, 286, 764, 264, 881, 2049, 50907, 50907, 293, 264, 661, 3743, 2290, 307, 9953, 51, 284, 339, 13, 51061, 51061, 583, 321, 434, 516, 281, 1879, 294, 341, 2121, 2144, 322, 37624, 13, 51279, 51279, 682, 341, 960, 11, 718, 311, 747, 257, 574, 412, 577, 291, 393, 4445, 38253, 294, 3089, 1228, 37624, 13, 51569, 51569, 961, 311, 9192, 294, 13, 51619, 51619], "temperature": 0.0, "avg_logprob": -0.15320999391617313, "compression_ratio": 1.5826446280991735, "no_speech_prob": 0.007343058940023184}, {"id": 4, "seek": 0, "start": 18.3, "end": 24.1, "text": " In this video, let's take a look at how you can implement inference in code using TensorFlow.", "tokens": [50364, 37624, 307, 472, 295, 264, 5775, 29834, 337, 18114, 2452, 2539, 14642, 13, 50675, 50675, 1133, 286, 478, 2390, 4455, 11, 37624, 307, 767, 264, 2290, 300, 286, 764, 264, 881, 2049, 50907, 50907, 293, 264, 661, 3743, 2290, 307, 9953, 51, 284, 339, 13, 51061, 51061, 583, 321, 434, 516, 281, 1879, 294, 341, 2121, 2144, 322, 37624, 13, 51279, 51279, 682, 341, 960, 11, 718, 311, 747, 257, 574, 412, 577, 291, 393, 4445, 38253, 294, 3089, 1228, 37624, 13, 51569, 51569, 961, 311, 9192, 294, 13, 51619, 51619], "temperature": 0.0, "avg_logprob": -0.15320999391617313, "compression_ratio": 1.5826446280991735, "no_speech_prob": 0.007343058940023184}, {"id": 5, "seek": 0, "start": 24.1, "end": 25.1, "text": " Let's dive in.", "tokens": [50364, 37624, 307, 472, 295, 264, 5775, 29834, 337, 18114, 2452, 2539, 14642, 13, 50675, 50675, 1133, 286, 478, 2390, 4455, 11, 37624, 307, 767, 264, 2290, 300, 286, 764, 264, 881, 2049, 50907, 50907, 293, 264, 661, 3743, 2290, 307, 9953, 51, 284, 339, 13, 51061, 51061, 583, 321, 434, 516, 281, 1879, 294, 341, 2121, 2144, 322, 37624, 13, 51279, 51279, 682, 341, 960, 11, 718, 311, 747, 257, 574, 412, 577, 291, 393, 4445, 38253, 294, 3089, 1228, 37624, 13, 51569, 51569, 961, 311, 9192, 294, 13, 51619, 51619], "temperature": 0.0, "avg_logprob": -0.15320999391617313, "compression_ratio": 1.5826446280991735, "no_speech_prob": 0.007343058940023184}, {"id": 6, "seek": 2510, "start": 25.1, "end": 30.060000000000002, "text": " One of the remarkable things about neural networks is the same algorithm can be applied", "tokens": [50364, 1485, 295, 264, 12802, 721, 466, 18161, 9590, 307, 264, 912, 9284, 393, 312, 6456, 50612, 50612, 281, 370, 867, 819, 5821, 13, 50777, 50777, 407, 294, 1668, 1293, 337, 341, 960, 293, 294, 512, 295, 264, 20339, 337, 291, 281, 536, 437, 257, 18161, 3209, 51089, 51089, 307, 884, 11, 286, 478, 516, 281, 764, 1071, 1365, 281, 23221, 38253, 13, 51417, 51417, 407, 2171, 286, 360, 411, 281, 12904, 4982, 12010, 2059, 412, 1280, 13, 51636, 51636, 1222, 2954, 307, 767, 18514, 952, 4982, 12010, 13, 51807, 51807], "temperature": 0.0, "avg_logprob": -0.09615099948385487, "compression_ratio": 1.6131687242798354, "no_speech_prob": 3.822037615464069e-05}, {"id": 7, "seek": 2510, "start": 30.060000000000002, "end": 33.36, "text": " to so many different applications.", "tokens": [50364, 1485, 295, 264, 12802, 721, 466, 18161, 9590, 307, 264, 912, 9284, 393, 312, 6456, 50612, 50612, 281, 370, 867, 819, 5821, 13, 50777, 50777, 407, 294, 1668, 1293, 337, 341, 960, 293, 294, 512, 295, 264, 20339, 337, 291, 281, 536, 437, 257, 18161, 3209, 51089, 51089, 307, 884, 11, 286, 478, 516, 281, 764, 1071, 1365, 281, 23221, 38253, 13, 51417, 51417, 407, 2171, 286, 360, 411, 281, 12904, 4982, 12010, 2059, 412, 1280, 13, 51636, 51636, 1222, 2954, 307, 767, 18514, 952, 4982, 12010, 13, 51807, 51807], "temperature": 0.0, "avg_logprob": -0.09615099948385487, "compression_ratio": 1.6131687242798354, "no_speech_prob": 3.822037615464069e-05}, {"id": 8, "seek": 2510, "start": 33.36, "end": 39.6, "text": " So in order both for this video and in some of the labs for you to see what a neural network", "tokens": [50364, 1485, 295, 264, 12802, 721, 466, 18161, 9590, 307, 264, 912, 9284, 393, 312, 6456, 50612, 50612, 281, 370, 867, 819, 5821, 13, 50777, 50777, 407, 294, 1668, 1293, 337, 341, 960, 293, 294, 512, 295, 264, 20339, 337, 291, 281, 536, 437, 257, 18161, 3209, 51089, 51089, 307, 884, 11, 286, 478, 516, 281, 764, 1071, 1365, 281, 23221, 38253, 13, 51417, 51417, 407, 2171, 286, 360, 411, 281, 12904, 4982, 12010, 2059, 412, 1280, 13, 51636, 51636, 1222, 2954, 307, 767, 18514, 952, 4982, 12010, 13, 51807, 51807], "temperature": 0.0, "avg_logprob": -0.09615099948385487, "compression_ratio": 1.6131687242798354, "no_speech_prob": 3.822037615464069e-05}, {"id": 9, "seek": 2510, "start": 39.6, "end": 46.16, "text": " is doing, I'm going to use another example to illustrate inference.", "tokens": [50364, 1485, 295, 264, 12802, 721, 466, 18161, 9590, 307, 264, 912, 9284, 393, 312, 6456, 50612, 50612, 281, 370, 867, 819, 5821, 13, 50777, 50777, 407, 294, 1668, 1293, 337, 341, 960, 293, 294, 512, 295, 264, 20339, 337, 291, 281, 536, 437, 257, 18161, 3209, 51089, 51089, 307, 884, 11, 286, 478, 516, 281, 764, 1071, 1365, 281, 23221, 38253, 13, 51417, 51417, 407, 2171, 286, 360, 411, 281, 12904, 4982, 12010, 2059, 412, 1280, 13, 51636, 51636, 1222, 2954, 307, 767, 18514, 952, 4982, 12010, 13, 51807, 51807], "temperature": 0.0, "avg_logprob": -0.09615099948385487, "compression_ratio": 1.6131687242798354, "no_speech_prob": 3.822037615464069e-05}, {"id": 10, "seek": 2510, "start": 46.16, "end": 50.540000000000006, "text": " So sometimes I do like to roast coffee beans myself at home.", "tokens": [50364, 1485, 295, 264, 12802, 721, 466, 18161, 9590, 307, 264, 912, 9284, 393, 312, 6456, 50612, 50612, 281, 370, 867, 819, 5821, 13, 50777, 50777, 407, 294, 1668, 1293, 337, 341, 960, 293, 294, 512, 295, 264, 20339, 337, 291, 281, 536, 437, 257, 18161, 3209, 51089, 51089, 307, 884, 11, 286, 478, 516, 281, 764, 1071, 1365, 281, 23221, 38253, 13, 51417, 51417, 407, 2171, 286, 360, 411, 281, 12904, 4982, 12010, 2059, 412, 1280, 13, 51636, 51636, 1222, 2954, 307, 767, 18514, 952, 4982, 12010, 13, 51807, 51807], "temperature": 0.0, "avg_logprob": -0.09615099948385487, "compression_ratio": 1.6131687242798354, "no_speech_prob": 3.822037615464069e-05}, {"id": 11, "seek": 2510, "start": 50.540000000000006, "end": 53.96, "text": " My favorite is actually Colombian coffee beans.", "tokens": [50364, 1485, 295, 264, 12802, 721, 466, 18161, 9590, 307, 264, 912, 9284, 393, 312, 6456, 50612, 50612, 281, 370, 867, 819, 5821, 13, 50777, 50777, 407, 294, 1668, 1293, 337, 341, 960, 293, 294, 512, 295, 264, 20339, 337, 291, 281, 536, 437, 257, 18161, 3209, 51089, 51089, 307, 884, 11, 286, 478, 516, 281, 764, 1071, 1365, 281, 23221, 38253, 13, 51417, 51417, 407, 2171, 286, 360, 411, 281, 12904, 4982, 12010, 2059, 412, 1280, 13, 51636, 51636, 1222, 2954, 307, 767, 18514, 952, 4982, 12010, 13, 51807, 51807], "temperature": 0.0, "avg_logprob": -0.09615099948385487, "compression_ratio": 1.6131687242798354, "no_speech_prob": 3.822037615464069e-05}, {"id": 12, "seek": 5396, "start": 53.96, "end": 58.980000000000004, "text": " So kind of learning algorithm help optimize the quality of the beans you get from a roasting", "tokens": [50364, 407, 733, 295, 2539, 9284, 854, 19719, 264, 3125, 295, 264, 12010, 291, 483, 490, 257, 45227, 50615, 50615, 1399, 411, 341, 13, 50719, 50719, 1133, 291, 434, 45227, 4982, 11, 732, 9834, 291, 483, 281, 1969, 366, 264, 4292, 412, 50963, 50963, 597, 366, 15082, 493, 264, 8936, 4982, 12010, 281, 1261, 552, 666, 9594, 24766, 4982, 12010, 11, 51298, 51298, 382, 731, 382, 264, 16365, 420, 577, 938, 291, 434, 516, 281, 12904, 264, 12010, 13, 51501, 51501, 400, 294, 341, 4748, 26335, 1365, 11, 321, 600, 2942, 264, 1412, 6352, 295, 819, 12633, 51827, 51827], "temperature": 0.0, "avg_logprob": -0.12228907585144043, "compression_ratio": 1.7509727626459144, "no_speech_prob": 6.108077650424093e-05}, {"id": 13, "seek": 5396, "start": 58.980000000000004, "end": 61.06, "text": " process like this.", "tokens": [50364, 407, 733, 295, 2539, 9284, 854, 19719, 264, 3125, 295, 264, 12010, 291, 483, 490, 257, 45227, 50615, 50615, 1399, 411, 341, 13, 50719, 50719, 1133, 291, 434, 45227, 4982, 11, 732, 9834, 291, 483, 281, 1969, 366, 264, 4292, 412, 50963, 50963, 597, 366, 15082, 493, 264, 8936, 4982, 12010, 281, 1261, 552, 666, 9594, 24766, 4982, 12010, 11, 51298, 51298, 382, 731, 382, 264, 16365, 420, 577, 938, 291, 434, 516, 281, 12904, 264, 12010, 13, 51501, 51501, 400, 294, 341, 4748, 26335, 1365, 11, 321, 600, 2942, 264, 1412, 6352, 295, 819, 12633, 51827, 51827], "temperature": 0.0, "avg_logprob": -0.12228907585144043, "compression_ratio": 1.7509727626459144, "no_speech_prob": 6.108077650424093e-05}, {"id": 14, "seek": 5396, "start": 61.06, "end": 65.94, "text": " When you're roasting coffee, two parameters you get to control are the temperature at", "tokens": [50364, 407, 733, 295, 2539, 9284, 854, 19719, 264, 3125, 295, 264, 12010, 291, 483, 490, 257, 45227, 50615, 50615, 1399, 411, 341, 13, 50719, 50719, 1133, 291, 434, 45227, 4982, 11, 732, 9834, 291, 483, 281, 1969, 366, 264, 4292, 412, 50963, 50963, 597, 366, 15082, 493, 264, 8936, 4982, 12010, 281, 1261, 552, 666, 9594, 24766, 4982, 12010, 11, 51298, 51298, 382, 731, 382, 264, 16365, 420, 577, 938, 291, 434, 516, 281, 12904, 264, 12010, 13, 51501, 51501, 400, 294, 341, 4748, 26335, 1365, 11, 321, 600, 2942, 264, 1412, 6352, 295, 819, 12633, 51827, 51827], "temperature": 0.0, "avg_logprob": -0.12228907585144043, "compression_ratio": 1.7509727626459144, "no_speech_prob": 6.108077650424093e-05}, {"id": 15, "seek": 5396, "start": 65.94, "end": 72.64, "text": " which are heating up the raw coffee beans to turn them into nicely roasted coffee beans,", "tokens": [50364, 407, 733, 295, 2539, 9284, 854, 19719, 264, 3125, 295, 264, 12010, 291, 483, 490, 257, 45227, 50615, 50615, 1399, 411, 341, 13, 50719, 50719, 1133, 291, 434, 45227, 4982, 11, 732, 9834, 291, 483, 281, 1969, 366, 264, 4292, 412, 50963, 50963, 597, 366, 15082, 493, 264, 8936, 4982, 12010, 281, 1261, 552, 666, 9594, 24766, 4982, 12010, 11, 51298, 51298, 382, 731, 382, 264, 16365, 420, 577, 938, 291, 434, 516, 281, 12904, 264, 12010, 13, 51501, 51501, 400, 294, 341, 4748, 26335, 1365, 11, 321, 600, 2942, 264, 1412, 6352, 295, 819, 12633, 51827, 51827], "temperature": 0.0, "avg_logprob": -0.12228907585144043, "compression_ratio": 1.7509727626459144, "no_speech_prob": 6.108077650424093e-05}, {"id": 16, "seek": 5396, "start": 72.64, "end": 76.7, "text": " as well as the duration or how long you're going to roast the beans.", "tokens": [50364, 407, 733, 295, 2539, 9284, 854, 19719, 264, 3125, 295, 264, 12010, 291, 483, 490, 257, 45227, 50615, 50615, 1399, 411, 341, 13, 50719, 50719, 1133, 291, 434, 45227, 4982, 11, 732, 9834, 291, 483, 281, 1969, 366, 264, 4292, 412, 50963, 50963, 597, 366, 15082, 493, 264, 8936, 4982, 12010, 281, 1261, 552, 666, 9594, 24766, 4982, 12010, 11, 51298, 51298, 382, 731, 382, 264, 16365, 420, 577, 938, 291, 434, 516, 281, 12904, 264, 12010, 13, 51501, 51501, 400, 294, 341, 4748, 26335, 1365, 11, 321, 600, 2942, 264, 1412, 6352, 295, 819, 12633, 51827, 51827], "temperature": 0.0, "avg_logprob": -0.12228907585144043, "compression_ratio": 1.7509727626459144, "no_speech_prob": 6.108077650424093e-05}, {"id": 17, "seek": 5396, "start": 76.7, "end": 83.22, "text": " And in this slightly simplified example, we've created the data sets of different temperatures", "tokens": [50364, 407, 733, 295, 2539, 9284, 854, 19719, 264, 3125, 295, 264, 12010, 291, 483, 490, 257, 45227, 50615, 50615, 1399, 411, 341, 13, 50719, 50719, 1133, 291, 434, 45227, 4982, 11, 732, 9834, 291, 483, 281, 1969, 366, 264, 4292, 412, 50963, 50963, 597, 366, 15082, 493, 264, 8936, 4982, 12010, 281, 1261, 552, 666, 9594, 24766, 4982, 12010, 11, 51298, 51298, 382, 731, 382, 264, 16365, 420, 577, 938, 291, 434, 516, 281, 12904, 264, 12010, 13, 51501, 51501, 400, 294, 341, 4748, 26335, 1365, 11, 321, 600, 2942, 264, 1412, 6352, 295, 819, 12633, 51827, 51827], "temperature": 0.0, "avg_logprob": -0.12228907585144043, "compression_ratio": 1.7509727626459144, "no_speech_prob": 6.108077650424093e-05}, {"id": 18, "seek": 8322, "start": 83.22, "end": 90.38, "text": " and different durations, as well as labels showing whether the coffee you roasted is", "tokens": [50364, 293, 819, 4861, 763, 11, 382, 731, 382, 16949, 4099, 1968, 264, 4982, 291, 24766, 307, 50722, 50722, 665, 26223, 4982, 11, 689, 3278, 510, 11, 264, 3353, 1508, 11, 288, 6915, 472, 11, 23249, 51010, 51010, 281, 665, 4982, 11, 293, 1954, 11, 264, 3671, 1508, 23249, 281, 1578, 4982, 13, 51314, 51314, 407, 309, 1542, 411, 257, 10585, 636, 281, 519, 295, 341, 1412, 992, 307, 498, 291, 2543, 309, 412, 886, 51654, 51654], "temperature": 0.0, "avg_logprob": -0.17097298304239908, "compression_ratio": 1.6875, "no_speech_prob": 9.972614861908369e-06}, {"id": 19, "seek": 8322, "start": 90.38, "end": 96.14, "text": " good tasting coffee, where cross here, the positive class, y equals one, corresponds", "tokens": [50364, 293, 819, 4861, 763, 11, 382, 731, 382, 16949, 4099, 1968, 264, 4982, 291, 24766, 307, 50722, 50722, 665, 26223, 4982, 11, 689, 3278, 510, 11, 264, 3353, 1508, 11, 288, 6915, 472, 11, 23249, 51010, 51010, 281, 665, 4982, 11, 293, 1954, 11, 264, 3671, 1508, 23249, 281, 1578, 4982, 13, 51314, 51314, 407, 309, 1542, 411, 257, 10585, 636, 281, 519, 295, 341, 1412, 992, 307, 498, 291, 2543, 309, 412, 886, 51654, 51654], "temperature": 0.0, "avg_logprob": -0.17097298304239908, "compression_ratio": 1.6875, "no_speech_prob": 9.972614861908369e-06}, {"id": 20, "seek": 8322, "start": 96.14, "end": 102.22, "text": " to good coffee, and oh, the negative class corresponds to bad coffee.", "tokens": [50364, 293, 819, 4861, 763, 11, 382, 731, 382, 16949, 4099, 1968, 264, 4982, 291, 24766, 307, 50722, 50722, 665, 26223, 4982, 11, 689, 3278, 510, 11, 264, 3353, 1508, 11, 288, 6915, 472, 11, 23249, 51010, 51010, 281, 665, 4982, 11, 293, 1954, 11, 264, 3671, 1508, 23249, 281, 1578, 4982, 13, 51314, 51314, 407, 309, 1542, 411, 257, 10585, 636, 281, 519, 295, 341, 1412, 992, 307, 498, 291, 2543, 309, 412, 886, 51654, 51654], "temperature": 0.0, "avg_logprob": -0.17097298304239908, "compression_ratio": 1.6875, "no_speech_prob": 9.972614861908369e-06}, {"id": 21, "seek": 8322, "start": 102.22, "end": 109.02, "text": " So it looks like a reasonable way to think of this data set is if you cook it at too", "tokens": [50364, 293, 819, 4861, 763, 11, 382, 731, 382, 16949, 4099, 1968, 264, 4982, 291, 24766, 307, 50722, 50722, 665, 26223, 4982, 11, 689, 3278, 510, 11, 264, 3353, 1508, 11, 288, 6915, 472, 11, 23249, 51010, 51010, 281, 665, 4982, 11, 293, 1954, 11, 264, 3671, 1508, 23249, 281, 1578, 4982, 13, 51314, 51314, 407, 309, 1542, 411, 257, 10585, 636, 281, 519, 295, 341, 1412, 992, 307, 498, 291, 2543, 309, 412, 886, 51654, 51654], "temperature": 0.0, "avg_logprob": -0.17097298304239908, "compression_ratio": 1.6875, "no_speech_prob": 9.972614861908369e-06}, {"id": 22, "seek": 10902, "start": 109.02, "end": 114.17999999999999, "text": " low a temperature, it doesn't get roasted and ends up undercooked.", "tokens": [50364, 2295, 257, 4292, 11, 309, 1177, 380, 483, 24766, 293, 5314, 493, 833, 66, 29262, 13, 50622, 50622, 759, 291, 2543, 309, 406, 337, 938, 1547, 11, 264, 16365, 307, 886, 2099, 13, 50838, 50838, 821, 311, 611, 406, 257, 9594, 24766, 992, 295, 12010, 13, 50997, 50997, 400, 2721, 11, 498, 291, 645, 281, 2543, 309, 2139, 337, 886, 938, 420, 337, 886, 1090, 257, 4292, 11, 51258, 51258, 550, 291, 917, 493, 365, 40027, 29262, 12010, 11, 436, 434, 257, 707, 857, 18901, 12010, 13, 51430, 51430, 400, 370, 300, 311, 406, 665, 4982, 2139, 13, 51555, 51555], "temperature": 0.0, "avg_logprob": -0.15358943565219058, "compression_ratio": 1.7201834862385321, "no_speech_prob": 3.321276744827628e-05}, {"id": 23, "seek": 10902, "start": 114.17999999999999, "end": 118.5, "text": " If you cook it not for long enough, the duration is too short.", "tokens": [50364, 2295, 257, 4292, 11, 309, 1177, 380, 483, 24766, 293, 5314, 493, 833, 66, 29262, 13, 50622, 50622, 759, 291, 2543, 309, 406, 337, 938, 1547, 11, 264, 16365, 307, 886, 2099, 13, 50838, 50838, 821, 311, 611, 406, 257, 9594, 24766, 992, 295, 12010, 13, 50997, 50997, 400, 2721, 11, 498, 291, 645, 281, 2543, 309, 2139, 337, 886, 938, 420, 337, 886, 1090, 257, 4292, 11, 51258, 51258, 550, 291, 917, 493, 365, 40027, 29262, 12010, 11, 436, 434, 257, 707, 857, 18901, 12010, 13, 51430, 51430, 400, 370, 300, 311, 406, 665, 4982, 2139, 13, 51555, 51555], "temperature": 0.0, "avg_logprob": -0.15358943565219058, "compression_ratio": 1.7201834862385321, "no_speech_prob": 3.321276744827628e-05}, {"id": 24, "seek": 10902, "start": 118.5, "end": 121.67999999999999, "text": " There's also not a nicely roasted set of beans.", "tokens": [50364, 2295, 257, 4292, 11, 309, 1177, 380, 483, 24766, 293, 5314, 493, 833, 66, 29262, 13, 50622, 50622, 759, 291, 2543, 309, 406, 337, 938, 1547, 11, 264, 16365, 307, 886, 2099, 13, 50838, 50838, 821, 311, 611, 406, 257, 9594, 24766, 992, 295, 12010, 13, 50997, 50997, 400, 2721, 11, 498, 291, 645, 281, 2543, 309, 2139, 337, 886, 938, 420, 337, 886, 1090, 257, 4292, 11, 51258, 51258, 550, 291, 917, 493, 365, 40027, 29262, 12010, 11, 436, 434, 257, 707, 857, 18901, 12010, 13, 51430, 51430, 400, 370, 300, 311, 406, 665, 4982, 2139, 13, 51555, 51555], "temperature": 0.0, "avg_logprob": -0.15358943565219058, "compression_ratio": 1.7201834862385321, "no_speech_prob": 3.321276744827628e-05}, {"id": 25, "seek": 10902, "start": 121.67999999999999, "end": 126.89999999999999, "text": " And finally, if you were to cook it either for too long or for too high a temperature,", "tokens": [50364, 2295, 257, 4292, 11, 309, 1177, 380, 483, 24766, 293, 5314, 493, 833, 66, 29262, 13, 50622, 50622, 759, 291, 2543, 309, 406, 337, 938, 1547, 11, 264, 16365, 307, 886, 2099, 13, 50838, 50838, 821, 311, 611, 406, 257, 9594, 24766, 992, 295, 12010, 13, 50997, 50997, 400, 2721, 11, 498, 291, 645, 281, 2543, 309, 2139, 337, 886, 938, 420, 337, 886, 1090, 257, 4292, 11, 51258, 51258, 550, 291, 917, 493, 365, 40027, 29262, 12010, 11, 436, 434, 257, 707, 857, 18901, 12010, 13, 51430, 51430, 400, 370, 300, 311, 406, 665, 4982, 2139, 13, 51555, 51555], "temperature": 0.0, "avg_logprob": -0.15358943565219058, "compression_ratio": 1.7201834862385321, "no_speech_prob": 3.321276744827628e-05}, {"id": 26, "seek": 10902, "start": 126.89999999999999, "end": 130.34, "text": " then you end up with overcooked beans, they're a little bit burnt beans.", "tokens": [50364, 2295, 257, 4292, 11, 309, 1177, 380, 483, 24766, 293, 5314, 493, 833, 66, 29262, 13, 50622, 50622, 759, 291, 2543, 309, 406, 337, 938, 1547, 11, 264, 16365, 307, 886, 2099, 13, 50838, 50838, 821, 311, 611, 406, 257, 9594, 24766, 992, 295, 12010, 13, 50997, 50997, 400, 2721, 11, 498, 291, 645, 281, 2543, 309, 2139, 337, 886, 938, 420, 337, 886, 1090, 257, 4292, 11, 51258, 51258, 550, 291, 917, 493, 365, 40027, 29262, 12010, 11, 436, 434, 257, 707, 857, 18901, 12010, 13, 51430, 51430, 400, 370, 300, 311, 406, 665, 4982, 2139, 13, 51555, 51555], "temperature": 0.0, "avg_logprob": -0.15358943565219058, "compression_ratio": 1.7201834862385321, "no_speech_prob": 3.321276744827628e-05}, {"id": 27, "seek": 10902, "start": 130.34, "end": 132.84, "text": " And so that's not good coffee either.", "tokens": [50364, 2295, 257, 4292, 11, 309, 1177, 380, 483, 24766, 293, 5314, 493, 833, 66, 29262, 13, 50622, 50622, 759, 291, 2543, 309, 406, 337, 938, 1547, 11, 264, 16365, 307, 886, 2099, 13, 50838, 50838, 821, 311, 611, 406, 257, 9594, 24766, 992, 295, 12010, 13, 50997, 50997, 400, 2721, 11, 498, 291, 645, 281, 2543, 309, 2139, 337, 886, 938, 420, 337, 886, 1090, 257, 4292, 11, 51258, 51258, 550, 291, 917, 493, 365, 40027, 29262, 12010, 11, 436, 434, 257, 707, 857, 18901, 12010, 13, 51430, 51430, 400, 370, 300, 311, 406, 665, 4982, 2139, 13, 51555, 51555], "temperature": 0.0, "avg_logprob": -0.15358943565219058, "compression_ratio": 1.7201834862385321, "no_speech_prob": 3.321276744827628e-05}, {"id": 28, "seek": 13284, "start": 132.84, "end": 139.3, "text": " There's only points within this little triangle here that corresponds to good coffee.", "tokens": [50364, 821, 311, 787, 2793, 1951, 341, 707, 13369, 510, 300, 23249, 281, 665, 4982, 13, 50687, 50687, 639, 1365, 307, 26335, 257, 857, 490, 3539, 4982, 45227, 13, 50909, 50909, 2754, 1673, 341, 1365, 307, 257, 26335, 472, 337, 264, 4334, 295, 22645, 11, 456, 362, 51227, 51227, 767, 668, 3156, 4455, 1228, 3479, 2539, 281, 19719, 4982, 45227, 382, 731, 13, 51495, 51495], "temperature": 0.0, "avg_logprob": -0.08175144051060532, "compression_ratio": 1.618811881188119, "no_speech_prob": 1.3709288850805024e-06}, {"id": 29, "seek": 13284, "start": 139.3, "end": 143.74, "text": " This example is simplified a bit from actual coffee roasting.", "tokens": [50364, 821, 311, 787, 2793, 1951, 341, 707, 13369, 510, 300, 23249, 281, 665, 4982, 13, 50687, 50687, 639, 1365, 307, 26335, 257, 857, 490, 3539, 4982, 45227, 13, 50909, 50909, 2754, 1673, 341, 1365, 307, 257, 26335, 472, 337, 264, 4334, 295, 22645, 11, 456, 362, 51227, 51227, 767, 668, 3156, 4455, 1228, 3479, 2539, 281, 19719, 4982, 45227, 382, 731, 13, 51495, 51495], "temperature": 0.0, "avg_logprob": -0.08175144051060532, "compression_ratio": 1.618811881188119, "no_speech_prob": 1.3709288850805024e-06}, {"id": 30, "seek": 13284, "start": 143.74, "end": 150.1, "text": " Even though this example is a simplified one for the purpose of illustration, there have", "tokens": [50364, 821, 311, 787, 2793, 1951, 341, 707, 13369, 510, 300, 23249, 281, 665, 4982, 13, 50687, 50687, 639, 1365, 307, 26335, 257, 857, 490, 3539, 4982, 45227, 13, 50909, 50909, 2754, 1673, 341, 1365, 307, 257, 26335, 472, 337, 264, 4334, 295, 22645, 11, 456, 362, 51227, 51227, 767, 668, 3156, 4455, 1228, 3479, 2539, 281, 19719, 4982, 45227, 382, 731, 13, 51495, 51495], "temperature": 0.0, "avg_logprob": -0.08175144051060532, "compression_ratio": 1.618811881188119, "no_speech_prob": 1.3709288850805024e-06}, {"id": 31, "seek": 13284, "start": 150.1, "end": 155.46, "text": " actually been serious projects using machine learning to optimize coffee roasting as well.", "tokens": [50364, 821, 311, 787, 2793, 1951, 341, 707, 13369, 510, 300, 23249, 281, 665, 4982, 13, 50687, 50687, 639, 1365, 307, 26335, 257, 857, 490, 3539, 4982, 45227, 13, 50909, 50909, 2754, 1673, 341, 1365, 307, 257, 26335, 472, 337, 264, 4334, 295, 22645, 11, 456, 362, 51227, 51227, 767, 668, 3156, 4455, 1228, 3479, 2539, 281, 19719, 4982, 45227, 382, 731, 13, 51495, 51495], "temperature": 0.0, "avg_logprob": -0.08175144051060532, "compression_ratio": 1.618811881188119, "no_speech_prob": 1.3709288850805024e-06}, {"id": 32, "seek": 15546, "start": 155.46, "end": 163.06, "text": " So the task is given a feature vector x with both temperature and duration, say 200 degrees", "tokens": [50364, 407, 264, 5633, 307, 2212, 257, 4111, 8062, 2031, 365, 1293, 4292, 293, 16365, 11, 584, 2331, 5310, 50744, 50744, 22658, 337, 3282, 2077, 11, 577, 393, 321, 360, 38253, 294, 257, 18161, 3209, 281, 483, 309, 281, 980, 505, 1968, 51144, 51144, 420, 406, 341, 4292, 293, 16365, 3287, 486, 1874, 294, 665, 4982, 420, 406, 30, 51436, 51436, 467, 1542, 411, 341, 13, 51570, 51570], "temperature": 0.0, "avg_logprob": -0.10141073448070581, "compression_ratio": 1.5238095238095237, "no_speech_prob": 5.593642981693847e-06}, {"id": 33, "seek": 15546, "start": 163.06, "end": 171.06, "text": " Celsius for 17 minutes, how can we do inference in a neural network to get it to tell us whether", "tokens": [50364, 407, 264, 5633, 307, 2212, 257, 4111, 8062, 2031, 365, 1293, 4292, 293, 16365, 11, 584, 2331, 5310, 50744, 50744, 22658, 337, 3282, 2077, 11, 577, 393, 321, 360, 38253, 294, 257, 18161, 3209, 281, 483, 309, 281, 980, 505, 1968, 51144, 51144, 420, 406, 341, 4292, 293, 16365, 3287, 486, 1874, 294, 665, 4982, 420, 406, 30, 51436, 51436, 467, 1542, 411, 341, 13, 51570, 51570], "temperature": 0.0, "avg_logprob": -0.10141073448070581, "compression_ratio": 1.5238095238095237, "no_speech_prob": 5.593642981693847e-06}, {"id": 34, "seek": 15546, "start": 171.06, "end": 176.9, "text": " or not this temperature and duration setting will result in good coffee or not?", "tokens": [50364, 407, 264, 5633, 307, 2212, 257, 4111, 8062, 2031, 365, 1293, 4292, 293, 16365, 11, 584, 2331, 5310, 50744, 50744, 22658, 337, 3282, 2077, 11, 577, 393, 321, 360, 38253, 294, 257, 18161, 3209, 281, 483, 309, 281, 980, 505, 1968, 51144, 51144, 420, 406, 341, 4292, 293, 16365, 3287, 486, 1874, 294, 665, 4982, 420, 406, 30, 51436, 51436, 467, 1542, 411, 341, 13, 51570, 51570], "temperature": 0.0, "avg_logprob": -0.10141073448070581, "compression_ratio": 1.5238095238095237, "no_speech_prob": 5.593642981693847e-06}, {"id": 35, "seek": 15546, "start": 176.9, "end": 179.58, "text": " It looks like this.", "tokens": [50364, 407, 264, 5633, 307, 2212, 257, 4111, 8062, 2031, 365, 1293, 4292, 293, 16365, 11, 584, 2331, 5310, 50744, 50744, 22658, 337, 3282, 2077, 11, 577, 393, 321, 360, 38253, 294, 257, 18161, 3209, 281, 483, 309, 281, 980, 505, 1968, 51144, 51144, 420, 406, 341, 4292, 293, 16365, 3287, 486, 1874, 294, 665, 4982, 420, 406, 30, 51436, 51436, 467, 1542, 411, 341, 13, 51570, 51570], "temperature": 0.0, "avg_logprob": -0.10141073448070581, "compression_ratio": 1.5238095238095237, "no_speech_prob": 5.593642981693847e-06}, {"id": 36, "seek": 17958, "start": 179.58, "end": 189.82000000000002, "text": " We're going to set x to be an array of two numbers, the input features 200 degrees Celsius", "tokens": [50364, 492, 434, 516, 281, 992, 2031, 281, 312, 364, 10225, 295, 732, 3547, 11, 264, 4846, 4122, 2331, 5310, 22658, 50876, 50876, 293, 3282, 2077, 13, 51002, 51002, 400, 341, 510, 11, 4583, 472, 6915, 18011, 6815, 11, 1045, 24433, 6915, 4556, 3280, 327, 11, 7829, 257, 51376, 51376, 7633, 4583, 295, 22027, 365, 1045, 7633, 6815, 293, 1228, 382, 264, 24433, 2445, 11, 51686, 51686, 264, 4556, 3280, 327, 2445, 13, 51784, 51784], "temperature": 0.0, "avg_logprob": -0.16691288195158305, "compression_ratio": 1.5894736842105264, "no_speech_prob": 1.4508295862469822e-05}, {"id": 37, "seek": 17958, "start": 189.82000000000002, "end": 192.34, "text": " and 17 minutes.", "tokens": [50364, 492, 434, 516, 281, 992, 2031, 281, 312, 364, 10225, 295, 732, 3547, 11, 264, 4846, 4122, 2331, 5310, 22658, 50876, 50876, 293, 3282, 2077, 13, 51002, 51002, 400, 341, 510, 11, 4583, 472, 6915, 18011, 6815, 11, 1045, 24433, 6915, 4556, 3280, 327, 11, 7829, 257, 51376, 51376, 7633, 4583, 295, 22027, 365, 1045, 7633, 6815, 293, 1228, 382, 264, 24433, 2445, 11, 51686, 51686, 264, 4556, 3280, 327, 2445, 13, 51784, 51784], "temperature": 0.0, "avg_logprob": -0.16691288195158305, "compression_ratio": 1.5894736842105264, "no_speech_prob": 1.4508295862469822e-05}, {"id": 38, "seek": 17958, "start": 192.34, "end": 199.82000000000002, "text": " And this here, layer one equals dense units, three activation equals sigmoid, creates a", "tokens": [50364, 492, 434, 516, 281, 992, 2031, 281, 312, 364, 10225, 295, 732, 3547, 11, 264, 4846, 4122, 2331, 5310, 22658, 50876, 50876, 293, 3282, 2077, 13, 51002, 51002, 400, 341, 510, 11, 4583, 472, 6915, 18011, 6815, 11, 1045, 24433, 6915, 4556, 3280, 327, 11, 7829, 257, 51376, 51376, 7633, 4583, 295, 22027, 365, 1045, 7633, 6815, 293, 1228, 382, 264, 24433, 2445, 11, 51686, 51686, 264, 4556, 3280, 327, 2445, 13, 51784, 51784], "temperature": 0.0, "avg_logprob": -0.16691288195158305, "compression_ratio": 1.5894736842105264, "no_speech_prob": 1.4508295862469822e-05}, {"id": 39, "seek": 17958, "start": 199.82000000000002, "end": 206.02, "text": " hidden layer of neurons with three hidden units and using as the activation function,", "tokens": [50364, 492, 434, 516, 281, 992, 2031, 281, 312, 364, 10225, 295, 732, 3547, 11, 264, 4846, 4122, 2331, 5310, 22658, 50876, 50876, 293, 3282, 2077, 13, 51002, 51002, 400, 341, 510, 11, 4583, 472, 6915, 18011, 6815, 11, 1045, 24433, 6915, 4556, 3280, 327, 11, 7829, 257, 51376, 51376, 7633, 4583, 295, 22027, 365, 1045, 7633, 6815, 293, 1228, 382, 264, 24433, 2445, 11, 51686, 51686, 264, 4556, 3280, 327, 2445, 13, 51784, 51784], "temperature": 0.0, "avg_logprob": -0.16691288195158305, "compression_ratio": 1.5894736842105264, "no_speech_prob": 1.4508295862469822e-05}, {"id": 40, "seek": 17958, "start": 206.02, "end": 207.98000000000002, "text": " the sigmoid function.", "tokens": [50364, 492, 434, 516, 281, 992, 2031, 281, 312, 364, 10225, 295, 732, 3547, 11, 264, 4846, 4122, 2331, 5310, 22658, 50876, 50876, 293, 3282, 2077, 13, 51002, 51002, 400, 341, 510, 11, 4583, 472, 6915, 18011, 6815, 11, 1045, 24433, 6915, 4556, 3280, 327, 11, 7829, 257, 51376, 51376, 7633, 4583, 295, 22027, 365, 1045, 7633, 6815, 293, 1228, 382, 264, 24433, 2445, 11, 51686, 51686, 264, 4556, 3280, 327, 2445, 13, 51784, 51784], "temperature": 0.0, "avg_logprob": -0.16691288195158305, "compression_ratio": 1.5894736842105264, "no_speech_prob": 1.4508295862469822e-05}, {"id": 41, "seek": 20798, "start": 207.98, "end": 211.06, "text": " And dense here is just the name of this layer.", "tokens": [50364, 400, 18011, 510, 307, 445, 264, 1315, 295, 341, 4583, 13, 50518, 50518, 400, 550, 2721, 11, 281, 14722, 264, 24433, 4190, 257, 472, 11, 291, 576, 2464, 257, 472, 6915, 50932, 50932, 4583, 472, 6456, 281, 264, 4846, 4122, 2031, 13, 51148, 51148, 1396, 291, 1884, 4583, 472, 382, 341, 700, 7633, 4583, 295, 264, 18161, 3209, 382, 18011, 11, 1269, 51546, 51546], "temperature": 0.0, "avg_logprob": -0.13945468266805014, "compression_ratio": 1.5555555555555556, "no_speech_prob": 7.296035164472414e-06}, {"id": 42, "seek": 20798, "start": 211.06, "end": 219.33999999999997, "text": " And then finally, to compute the activation values a one, you would write a one equals", "tokens": [50364, 400, 18011, 510, 307, 445, 264, 1315, 295, 341, 4583, 13, 50518, 50518, 400, 550, 2721, 11, 281, 14722, 264, 24433, 4190, 257, 472, 11, 291, 576, 2464, 257, 472, 6915, 50932, 50932, 4583, 472, 6456, 281, 264, 4846, 4122, 2031, 13, 51148, 51148, 1396, 291, 1884, 4583, 472, 382, 341, 700, 7633, 4583, 295, 264, 18161, 3209, 382, 18011, 11, 1269, 51546, 51546], "temperature": 0.0, "avg_logprob": -0.13945468266805014, "compression_ratio": 1.5555555555555556, "no_speech_prob": 7.296035164472414e-06}, {"id": 43, "seek": 20798, "start": 219.33999999999997, "end": 223.66, "text": " layer one applied to the input features x.", "tokens": [50364, 400, 18011, 510, 307, 445, 264, 1315, 295, 341, 4583, 13, 50518, 50518, 400, 550, 2721, 11, 281, 14722, 264, 24433, 4190, 257, 472, 11, 291, 576, 2464, 257, 472, 6915, 50932, 50932, 4583, 472, 6456, 281, 264, 4846, 4122, 2031, 13, 51148, 51148, 1396, 291, 1884, 4583, 472, 382, 341, 700, 7633, 4583, 295, 264, 18161, 3209, 382, 18011, 11, 1269, 51546, 51546], "temperature": 0.0, "avg_logprob": -0.13945468266805014, "compression_ratio": 1.5555555555555556, "no_speech_prob": 7.296035164472414e-06}, {"id": 44, "seek": 20798, "start": 223.66, "end": 231.62, "text": " Then you create layer one as this first hidden layer of the neural network as dense, open", "tokens": [50364, 400, 18011, 510, 307, 445, 264, 1315, 295, 341, 4583, 13, 50518, 50518, 400, 550, 2721, 11, 281, 14722, 264, 24433, 4190, 257, 472, 11, 291, 576, 2464, 257, 472, 6915, 50932, 50932, 4583, 472, 6456, 281, 264, 4846, 4122, 2031, 13, 51148, 51148, 1396, 291, 1884, 4583, 472, 382, 341, 700, 7633, 4583, 295, 264, 18161, 3209, 382, 18011, 11, 1269, 51546, 51546], "temperature": 0.0, "avg_logprob": -0.13945468266805014, "compression_ratio": 1.5555555555555556, "no_speech_prob": 7.296035164472414e-06}, {"id": 45, "seek": 23162, "start": 231.62, "end": 237.9, "text": " prints units three, that means three units or three hidden units in this layer using", "tokens": [50364, 22305, 6815, 1045, 11, 300, 1355, 1045, 6815, 420, 1045, 7633, 6815, 294, 341, 4583, 1228, 50678, 50678, 382, 264, 24433, 2445, 11, 264, 4556, 3280, 327, 2445, 13, 50856, 50856, 400, 18011, 307, 1071, 1315, 337, 264, 7914, 295, 257, 18161, 3209, 300, 321, 600, 3264, 466, 51112, 51112, 370, 1400, 13, 51174, 51174, 400, 382, 291, 1466, 544, 466, 18161, 9590, 11, 291, 1466, 466, 661, 3467, 295, 7914, 382, 731, 13, 51450, 51450, 583, 337, 586, 11, 321, 445, 764, 264, 18011, 4583, 11, 597, 307, 264, 4583, 2010, 291, 600, 3264, 466, 51658, 51658, 294, 264, 1036, 1326, 2145, 337, 439, 295, 527, 5110, 13, 51831, 51831], "temperature": 0.0, "avg_logprob": -0.11317188127905922, "compression_ratio": 1.903765690376569, "no_speech_prob": 6.6432353378331754e-06}, {"id": 46, "seek": 23162, "start": 237.9, "end": 241.46, "text": " as the activation function, the sigmoid function.", "tokens": [50364, 22305, 6815, 1045, 11, 300, 1355, 1045, 6815, 420, 1045, 7633, 6815, 294, 341, 4583, 1228, 50678, 50678, 382, 264, 24433, 2445, 11, 264, 4556, 3280, 327, 2445, 13, 50856, 50856, 400, 18011, 307, 1071, 1315, 337, 264, 7914, 295, 257, 18161, 3209, 300, 321, 600, 3264, 466, 51112, 51112, 370, 1400, 13, 51174, 51174, 400, 382, 291, 1466, 544, 466, 18161, 9590, 11, 291, 1466, 466, 661, 3467, 295, 7914, 382, 731, 13, 51450, 51450, 583, 337, 586, 11, 321, 445, 764, 264, 18011, 4583, 11, 597, 307, 264, 4583, 2010, 291, 600, 3264, 466, 51658, 51658, 294, 264, 1036, 1326, 2145, 337, 439, 295, 527, 5110, 13, 51831, 51831], "temperature": 0.0, "avg_logprob": -0.11317188127905922, "compression_ratio": 1.903765690376569, "no_speech_prob": 6.6432353378331754e-06}, {"id": 47, "seek": 23162, "start": 241.46, "end": 246.58, "text": " And dense is another name for the layers of a neural network that we've learned about", "tokens": [50364, 22305, 6815, 1045, 11, 300, 1355, 1045, 6815, 420, 1045, 7633, 6815, 294, 341, 4583, 1228, 50678, 50678, 382, 264, 24433, 2445, 11, 264, 4556, 3280, 327, 2445, 13, 50856, 50856, 400, 18011, 307, 1071, 1315, 337, 264, 7914, 295, 257, 18161, 3209, 300, 321, 600, 3264, 466, 51112, 51112, 370, 1400, 13, 51174, 51174, 400, 382, 291, 1466, 544, 466, 18161, 9590, 11, 291, 1466, 466, 661, 3467, 295, 7914, 382, 731, 13, 51450, 51450, 583, 337, 586, 11, 321, 445, 764, 264, 18011, 4583, 11, 597, 307, 264, 4583, 2010, 291, 600, 3264, 466, 51658, 51658, 294, 264, 1036, 1326, 2145, 337, 439, 295, 527, 5110, 13, 51831, 51831], "temperature": 0.0, "avg_logprob": -0.11317188127905922, "compression_ratio": 1.903765690376569, "no_speech_prob": 6.6432353378331754e-06}, {"id": 48, "seek": 23162, "start": 246.58, "end": 247.82, "text": " so far.", "tokens": [50364, 22305, 6815, 1045, 11, 300, 1355, 1045, 6815, 420, 1045, 7633, 6815, 294, 341, 4583, 1228, 50678, 50678, 382, 264, 24433, 2445, 11, 264, 4556, 3280, 327, 2445, 13, 50856, 50856, 400, 18011, 307, 1071, 1315, 337, 264, 7914, 295, 257, 18161, 3209, 300, 321, 600, 3264, 466, 51112, 51112, 370, 1400, 13, 51174, 51174, 400, 382, 291, 1466, 544, 466, 18161, 9590, 11, 291, 1466, 466, 661, 3467, 295, 7914, 382, 731, 13, 51450, 51450, 583, 337, 586, 11, 321, 445, 764, 264, 18011, 4583, 11, 597, 307, 264, 4583, 2010, 291, 600, 3264, 466, 51658, 51658, 294, 264, 1036, 1326, 2145, 337, 439, 295, 527, 5110, 13, 51831, 51831], "temperature": 0.0, "avg_logprob": -0.11317188127905922, "compression_ratio": 1.903765690376569, "no_speech_prob": 6.6432353378331754e-06}, {"id": 49, "seek": 23162, "start": 247.82, "end": 253.34, "text": " And as you learn more about neural networks, you learn about other types of layers as well.", "tokens": [50364, 22305, 6815, 1045, 11, 300, 1355, 1045, 6815, 420, 1045, 7633, 6815, 294, 341, 4583, 1228, 50678, 50678, 382, 264, 24433, 2445, 11, 264, 4556, 3280, 327, 2445, 13, 50856, 50856, 400, 18011, 307, 1071, 1315, 337, 264, 7914, 295, 257, 18161, 3209, 300, 321, 600, 3264, 466, 51112, 51112, 370, 1400, 13, 51174, 51174, 400, 382, 291, 1466, 544, 466, 18161, 9590, 11, 291, 1466, 466, 661, 3467, 295, 7914, 382, 731, 13, 51450, 51450, 583, 337, 586, 11, 321, 445, 764, 264, 18011, 4583, 11, 597, 307, 264, 4583, 2010, 291, 600, 3264, 466, 51658, 51658, 294, 264, 1036, 1326, 2145, 337, 439, 295, 527, 5110, 13, 51831, 51831], "temperature": 0.0, "avg_logprob": -0.11317188127905922, "compression_ratio": 1.903765690376569, "no_speech_prob": 6.6432353378331754e-06}, {"id": 50, "seek": 23162, "start": 253.34, "end": 257.5, "text": " But for now, we just use the dense layer, which is the layer type you've learned about", "tokens": [50364, 22305, 6815, 1045, 11, 300, 1355, 1045, 6815, 420, 1045, 7633, 6815, 294, 341, 4583, 1228, 50678, 50678, 382, 264, 24433, 2445, 11, 264, 4556, 3280, 327, 2445, 13, 50856, 50856, 400, 18011, 307, 1071, 1315, 337, 264, 7914, 295, 257, 18161, 3209, 300, 321, 600, 3264, 466, 51112, 51112, 370, 1400, 13, 51174, 51174, 400, 382, 291, 1466, 544, 466, 18161, 9590, 11, 291, 1466, 466, 661, 3467, 295, 7914, 382, 731, 13, 51450, 51450, 583, 337, 586, 11, 321, 445, 764, 264, 18011, 4583, 11, 597, 307, 264, 4583, 2010, 291, 600, 3264, 466, 51658, 51658, 294, 264, 1036, 1326, 2145, 337, 439, 295, 527, 5110, 13, 51831, 51831], "temperature": 0.0, "avg_logprob": -0.11317188127905922, "compression_ratio": 1.903765690376569, "no_speech_prob": 6.6432353378331754e-06}, {"id": 51, "seek": 23162, "start": 257.5, "end": 260.96, "text": " in the last few videos for all of our examples.", "tokens": [50364, 22305, 6815, 1045, 11, 300, 1355, 1045, 6815, 420, 1045, 7633, 6815, 294, 341, 4583, 1228, 50678, 50678, 382, 264, 24433, 2445, 11, 264, 4556, 3280, 327, 2445, 13, 50856, 50856, 400, 18011, 307, 1071, 1315, 337, 264, 7914, 295, 257, 18161, 3209, 300, 321, 600, 3264, 466, 51112, 51112, 370, 1400, 13, 51174, 51174, 400, 382, 291, 1466, 544, 466, 18161, 9590, 11, 291, 1466, 466, 661, 3467, 295, 7914, 382, 731, 13, 51450, 51450, 583, 337, 586, 11, 321, 445, 764, 264, 18011, 4583, 11, 597, 307, 264, 4583, 2010, 291, 600, 3264, 466, 51658, 51658, 294, 264, 1036, 1326, 2145, 337, 439, 295, 527, 5110, 13, 51831, 51831], "temperature": 0.0, "avg_logprob": -0.11317188127905922, "compression_ratio": 1.903765690376569, "no_speech_prob": 6.6432353378331754e-06}, {"id": 52, "seek": 26096, "start": 260.96, "end": 268.62, "text": " So next, you compute a one by taking layer one, which is actually a function and applying", "tokens": [50364, 407, 958, 11, 291, 14722, 257, 472, 538, 1940, 4583, 472, 11, 597, 307, 767, 257, 2445, 293, 9275, 50747, 50747, 341, 2445, 4583, 472, 281, 264, 4190, 295, 2031, 13, 50887, 50887, 407, 300, 311, 577, 291, 483, 257, 472, 11, 597, 307, 516, 281, 312, 257, 1329, 295, 1045, 3547, 570, 436, 51179, 51179, 472, 632, 1045, 6815, 13, 51271, 51271, 400, 370, 257, 472, 510, 815, 445, 337, 264, 9717, 295, 22645, 312, 935, 568, 13, 22, 13, 18, 13, 51559, 51559, 3087, 11, 337, 264, 1150, 7633, 4583, 11, 4583, 732, 576, 312, 18011, 295, 13, 51839, 51839], "temperature": 0.0, "avg_logprob": -0.16010073515085074, "compression_ratio": 1.6462882096069869, "no_speech_prob": 5.307070750859566e-05}, {"id": 53, "seek": 26096, "start": 268.62, "end": 271.41999999999996, "text": " this function layer one to the values of x.", "tokens": [50364, 407, 958, 11, 291, 14722, 257, 472, 538, 1940, 4583, 472, 11, 597, 307, 767, 257, 2445, 293, 9275, 50747, 50747, 341, 2445, 4583, 472, 281, 264, 4190, 295, 2031, 13, 50887, 50887, 407, 300, 311, 577, 291, 483, 257, 472, 11, 597, 307, 516, 281, 312, 257, 1329, 295, 1045, 3547, 570, 436, 51179, 51179, 472, 632, 1045, 6815, 13, 51271, 51271, 400, 370, 257, 472, 510, 815, 445, 337, 264, 9717, 295, 22645, 312, 935, 568, 13, 22, 13, 18, 13, 51559, 51559, 3087, 11, 337, 264, 1150, 7633, 4583, 11, 4583, 732, 576, 312, 18011, 295, 13, 51839, 51839], "temperature": 0.0, "avg_logprob": -0.16010073515085074, "compression_ratio": 1.6462882096069869, "no_speech_prob": 5.307070750859566e-05}, {"id": 54, "seek": 26096, "start": 271.41999999999996, "end": 277.26, "text": " So that's how you get a one, which is going to be a list of three numbers because they", "tokens": [50364, 407, 958, 11, 291, 14722, 257, 472, 538, 1940, 4583, 472, 11, 597, 307, 767, 257, 2445, 293, 9275, 50747, 50747, 341, 2445, 4583, 472, 281, 264, 4190, 295, 2031, 13, 50887, 50887, 407, 300, 311, 577, 291, 483, 257, 472, 11, 597, 307, 516, 281, 312, 257, 1329, 295, 1045, 3547, 570, 436, 51179, 51179, 472, 632, 1045, 6815, 13, 51271, 51271, 400, 370, 257, 472, 510, 815, 445, 337, 264, 9717, 295, 22645, 312, 935, 568, 13, 22, 13, 18, 13, 51559, 51559, 3087, 11, 337, 264, 1150, 7633, 4583, 11, 4583, 732, 576, 312, 18011, 295, 13, 51839, 51839], "temperature": 0.0, "avg_logprob": -0.16010073515085074, "compression_ratio": 1.6462882096069869, "no_speech_prob": 5.307070750859566e-05}, {"id": 55, "seek": 26096, "start": 277.26, "end": 279.09999999999997, "text": " one had three units.", "tokens": [50364, 407, 958, 11, 291, 14722, 257, 472, 538, 1940, 4583, 472, 11, 597, 307, 767, 257, 2445, 293, 9275, 50747, 50747, 341, 2445, 4583, 472, 281, 264, 4190, 295, 2031, 13, 50887, 50887, 407, 300, 311, 577, 291, 483, 257, 472, 11, 597, 307, 516, 281, 312, 257, 1329, 295, 1045, 3547, 570, 436, 51179, 51179, 472, 632, 1045, 6815, 13, 51271, 51271, 400, 370, 257, 472, 510, 815, 445, 337, 264, 9717, 295, 22645, 312, 935, 568, 13, 22, 13, 18, 13, 51559, 51559, 3087, 11, 337, 264, 1150, 7633, 4583, 11, 4583, 732, 576, 312, 18011, 295, 13, 51839, 51839], "temperature": 0.0, "avg_logprob": -0.16010073515085074, "compression_ratio": 1.6462882096069869, "no_speech_prob": 5.307070750859566e-05}, {"id": 56, "seek": 26096, "start": 279.09999999999997, "end": 284.85999999999996, "text": " And so a one here may just for the sake of illustration be point 2.7.3.", "tokens": [50364, 407, 958, 11, 291, 14722, 257, 472, 538, 1940, 4583, 472, 11, 597, 307, 767, 257, 2445, 293, 9275, 50747, 50747, 341, 2445, 4583, 472, 281, 264, 4190, 295, 2031, 13, 50887, 50887, 407, 300, 311, 577, 291, 483, 257, 472, 11, 597, 307, 516, 281, 312, 257, 1329, 295, 1045, 3547, 570, 436, 51179, 51179, 472, 632, 1045, 6815, 13, 51271, 51271, 400, 370, 257, 472, 510, 815, 445, 337, 264, 9717, 295, 22645, 312, 935, 568, 13, 22, 13, 18, 13, 51559, 51559, 3087, 11, 337, 264, 1150, 7633, 4583, 11, 4583, 732, 576, 312, 18011, 295, 13, 51839, 51839], "temperature": 0.0, "avg_logprob": -0.16010073515085074, "compression_ratio": 1.6462882096069869, "no_speech_prob": 5.307070750859566e-05}, {"id": 57, "seek": 26096, "start": 284.85999999999996, "end": 290.46, "text": " Next, for the second hidden layer, layer two would be dense of.", "tokens": [50364, 407, 958, 11, 291, 14722, 257, 472, 538, 1940, 4583, 472, 11, 597, 307, 767, 257, 2445, 293, 9275, 50747, 50747, 341, 2445, 4583, 472, 281, 264, 4190, 295, 2031, 13, 50887, 50887, 407, 300, 311, 577, 291, 483, 257, 472, 11, 597, 307, 516, 281, 312, 257, 1329, 295, 1045, 3547, 570, 436, 51179, 51179, 472, 632, 1045, 6815, 13, 51271, 51271, 400, 370, 257, 472, 510, 815, 445, 337, 264, 9717, 295, 22645, 312, 935, 568, 13, 22, 13, 18, 13, 51559, 51559, 3087, 11, 337, 264, 1150, 7633, 4583, 11, 4583, 732, 576, 312, 18011, 295, 13, 51839, 51839], "temperature": 0.0, "avg_logprob": -0.16010073515085074, "compression_ratio": 1.6462882096069869, "no_speech_prob": 5.307070750859566e-05}, {"id": 58, "seek": 29046, "start": 290.46, "end": 295.21999999999997, "text": " Now this time as one unit and again to signal and activation function.", "tokens": [50364, 823, 341, 565, 382, 472, 4985, 293, 797, 281, 6358, 293, 24433, 2445, 13, 50602, 50602, 400, 291, 393, 550, 14722, 257, 732, 538, 9275, 341, 4583, 732, 2445, 281, 264, 24433, 50848, 50848, 4190, 490, 4583, 472, 281, 257, 472, 13, 51016, 51016, 400, 300, 486, 976, 291, 264, 2158, 295, 257, 732, 11, 597, 337, 264, 9717, 295, 22645, 307, 1310, 51202, 51202, 4018, 935, 3180, 13, 51284, 51284, 6288, 11, 498, 291, 3172, 281, 14678, 307, 412, 1958, 13, 20, 11, 550, 291, 393, 445, 1500, 498, 257, 732, 307, 5044, 51645, 51645], "temperature": 0.0, "avg_logprob": -0.21744060516357422, "compression_ratio": 1.6888888888888889, "no_speech_prob": 1.2804719517589547e-05}, {"id": 59, "seek": 29046, "start": 295.21999999999997, "end": 300.14, "text": " And you can then compute a two by applying this layer two function to the activation", "tokens": [50364, 823, 341, 565, 382, 472, 4985, 293, 797, 281, 6358, 293, 24433, 2445, 13, 50602, 50602, 400, 291, 393, 550, 14722, 257, 732, 538, 9275, 341, 4583, 732, 2445, 281, 264, 24433, 50848, 50848, 4190, 490, 4583, 472, 281, 257, 472, 13, 51016, 51016, 400, 300, 486, 976, 291, 264, 2158, 295, 257, 732, 11, 597, 337, 264, 9717, 295, 22645, 307, 1310, 51202, 51202, 4018, 935, 3180, 13, 51284, 51284, 6288, 11, 498, 291, 3172, 281, 14678, 307, 412, 1958, 13, 20, 11, 550, 291, 393, 445, 1500, 498, 257, 732, 307, 5044, 51645, 51645], "temperature": 0.0, "avg_logprob": -0.21744060516357422, "compression_ratio": 1.6888888888888889, "no_speech_prob": 1.2804719517589547e-05}, {"id": 60, "seek": 29046, "start": 300.14, "end": 303.5, "text": " values from layer one to a one.", "tokens": [50364, 823, 341, 565, 382, 472, 4985, 293, 797, 281, 6358, 293, 24433, 2445, 13, 50602, 50602, 400, 291, 393, 550, 14722, 257, 732, 538, 9275, 341, 4583, 732, 2445, 281, 264, 24433, 50848, 50848, 4190, 490, 4583, 472, 281, 257, 472, 13, 51016, 51016, 400, 300, 486, 976, 291, 264, 2158, 295, 257, 732, 11, 597, 337, 264, 9717, 295, 22645, 307, 1310, 51202, 51202, 4018, 935, 3180, 13, 51284, 51284, 6288, 11, 498, 291, 3172, 281, 14678, 307, 412, 1958, 13, 20, 11, 550, 291, 393, 445, 1500, 498, 257, 732, 307, 5044, 51645, 51645], "temperature": 0.0, "avg_logprob": -0.21744060516357422, "compression_ratio": 1.6888888888888889, "no_speech_prob": 1.2804719517589547e-05}, {"id": 61, "seek": 29046, "start": 303.5, "end": 307.21999999999997, "text": " And that will give you the value of a two, which for the sake of illustration is maybe", "tokens": [50364, 823, 341, 565, 382, 472, 4985, 293, 797, 281, 6358, 293, 24433, 2445, 13, 50602, 50602, 400, 291, 393, 550, 14722, 257, 732, 538, 9275, 341, 4583, 732, 2445, 281, 264, 24433, 50848, 50848, 4190, 490, 4583, 472, 281, 257, 472, 13, 51016, 51016, 400, 300, 486, 976, 291, 264, 2158, 295, 257, 732, 11, 597, 337, 264, 9717, 295, 22645, 307, 1310, 51202, 51202, 4018, 935, 3180, 13, 51284, 51284, 6288, 11, 498, 291, 3172, 281, 14678, 307, 412, 1958, 13, 20, 11, 550, 291, 393, 445, 1500, 498, 257, 732, 307, 5044, 51645, 51645], "temperature": 0.0, "avg_logprob": -0.21744060516357422, "compression_ratio": 1.6888888888888889, "no_speech_prob": 1.2804719517589547e-05}, {"id": 62, "seek": 29046, "start": 307.21999999999997, "end": 308.85999999999996, "text": " zero point eight.", "tokens": [50364, 823, 341, 565, 382, 472, 4985, 293, 797, 281, 6358, 293, 24433, 2445, 13, 50602, 50602, 400, 291, 393, 550, 14722, 257, 732, 538, 9275, 341, 4583, 732, 2445, 281, 264, 24433, 50848, 50848, 4190, 490, 4583, 472, 281, 257, 472, 13, 51016, 51016, 400, 300, 486, 976, 291, 264, 2158, 295, 257, 732, 11, 597, 337, 264, 9717, 295, 22645, 307, 1310, 51202, 51202, 4018, 935, 3180, 13, 51284, 51284, 6288, 11, 498, 291, 3172, 281, 14678, 307, 412, 1958, 13, 20, 11, 550, 291, 393, 445, 1500, 498, 257, 732, 307, 5044, 51645, 51645], "temperature": 0.0, "avg_logprob": -0.21744060516357422, "compression_ratio": 1.6888888888888889, "no_speech_prob": 1.2804719517589547e-05}, {"id": 63, "seek": 29046, "start": 308.85999999999996, "end": 316.08, "text": " Finally, if you wish to threshold is at 0.5, then you can just test if a two is greater", "tokens": [50364, 823, 341, 565, 382, 472, 4985, 293, 797, 281, 6358, 293, 24433, 2445, 13, 50602, 50602, 400, 291, 393, 550, 14722, 257, 732, 538, 9275, 341, 4583, 732, 2445, 281, 264, 24433, 50848, 50848, 4190, 490, 4583, 472, 281, 257, 472, 13, 51016, 51016, 400, 300, 486, 976, 291, 264, 2158, 295, 257, 732, 11, 597, 337, 264, 9717, 295, 22645, 307, 1310, 51202, 51202, 4018, 935, 3180, 13, 51284, 51284, 6288, 11, 498, 291, 3172, 281, 14678, 307, 412, 1958, 13, 20, 11, 550, 291, 393, 445, 1500, 498, 257, 732, 307, 5044, 51645, 51645], "temperature": 0.0, "avg_logprob": -0.21744060516357422, "compression_ratio": 1.6888888888888889, "no_speech_prob": 1.2804719517589547e-05}, {"id": 64, "seek": 31608, "start": 316.08, "end": 321.5, "text": " than or equal to 0.5 and set y hat equals to one or zero positive or negative class", "tokens": [50364, 813, 420, 2681, 281, 1958, 13, 20, 293, 992, 288, 2385, 6915, 281, 472, 420, 4018, 3353, 420, 3671, 1508, 50635, 50635, 19717, 13, 50733, 50733, 407, 300, 311, 577, 291, 360, 38253, 294, 264, 18161, 3209, 1228, 37624, 13, 50949, 50949, 821, 366, 512, 4497, 4365, 300, 286, 994, 380, 352, 670, 510, 11, 1270, 382, 577, 281, 3677, 264, 37624, 51191, 51191, 6405, 293, 577, 281, 611, 3677, 264, 9834, 343, 293, 363, 295, 264, 18161, 3209, 13, 51551, 51551, 583, 321, 603, 352, 670, 300, 294, 264, 2715, 13, 51634, 51634, 407, 1767, 312, 988, 281, 747, 257, 574, 412, 264, 2715, 13, 51763, 51763], "temperature": 0.0, "avg_logprob": -0.15242909518155184, "compression_ratio": 1.6693227091633467, "no_speech_prob": 3.237648570575402e-06}, {"id": 65, "seek": 31608, "start": 321.5, "end": 323.46, "text": " accordingly.", "tokens": [50364, 813, 420, 2681, 281, 1958, 13, 20, 293, 992, 288, 2385, 6915, 281, 472, 420, 4018, 3353, 420, 3671, 1508, 50635, 50635, 19717, 13, 50733, 50733, 407, 300, 311, 577, 291, 360, 38253, 294, 264, 18161, 3209, 1228, 37624, 13, 50949, 50949, 821, 366, 512, 4497, 4365, 300, 286, 994, 380, 352, 670, 510, 11, 1270, 382, 577, 281, 3677, 264, 37624, 51191, 51191, 6405, 293, 577, 281, 611, 3677, 264, 9834, 343, 293, 363, 295, 264, 18161, 3209, 13, 51551, 51551, 583, 321, 603, 352, 670, 300, 294, 264, 2715, 13, 51634, 51634, 407, 1767, 312, 988, 281, 747, 257, 574, 412, 264, 2715, 13, 51763, 51763], "temperature": 0.0, "avg_logprob": -0.15242909518155184, "compression_ratio": 1.6693227091633467, "no_speech_prob": 3.237648570575402e-06}, {"id": 66, "seek": 31608, "start": 323.46, "end": 327.78, "text": " So that's how you do inference in the neural network using TensorFlow.", "tokens": [50364, 813, 420, 2681, 281, 1958, 13, 20, 293, 992, 288, 2385, 6915, 281, 472, 420, 4018, 3353, 420, 3671, 1508, 50635, 50635, 19717, 13, 50733, 50733, 407, 300, 311, 577, 291, 360, 38253, 294, 264, 18161, 3209, 1228, 37624, 13, 50949, 50949, 821, 366, 512, 4497, 4365, 300, 286, 994, 380, 352, 670, 510, 11, 1270, 382, 577, 281, 3677, 264, 37624, 51191, 51191, 6405, 293, 577, 281, 611, 3677, 264, 9834, 343, 293, 363, 295, 264, 18161, 3209, 13, 51551, 51551, 583, 321, 603, 352, 670, 300, 294, 264, 2715, 13, 51634, 51634, 407, 1767, 312, 988, 281, 747, 257, 574, 412, 264, 2715, 13, 51763, 51763], "temperature": 0.0, "avg_logprob": -0.15242909518155184, "compression_ratio": 1.6693227091633467, "no_speech_prob": 3.237648570575402e-06}, {"id": 67, "seek": 31608, "start": 327.78, "end": 332.62, "text": " There are some additional details that I didn't go over here, such as how to load the TensorFlow", "tokens": [50364, 813, 420, 2681, 281, 1958, 13, 20, 293, 992, 288, 2385, 6915, 281, 472, 420, 4018, 3353, 420, 3671, 1508, 50635, 50635, 19717, 13, 50733, 50733, 407, 300, 311, 577, 291, 360, 38253, 294, 264, 18161, 3209, 1228, 37624, 13, 50949, 50949, 821, 366, 512, 4497, 4365, 300, 286, 994, 380, 352, 670, 510, 11, 1270, 382, 577, 281, 3677, 264, 37624, 51191, 51191, 6405, 293, 577, 281, 611, 3677, 264, 9834, 343, 293, 363, 295, 264, 18161, 3209, 13, 51551, 51551, 583, 321, 603, 352, 670, 300, 294, 264, 2715, 13, 51634, 51634, 407, 1767, 312, 988, 281, 747, 257, 574, 412, 264, 2715, 13, 51763, 51763], "temperature": 0.0, "avg_logprob": -0.15242909518155184, "compression_ratio": 1.6693227091633467, "no_speech_prob": 3.237648570575402e-06}, {"id": 68, "seek": 31608, "start": 332.62, "end": 339.82, "text": " library and how to also load the parameters W and B of the neural network.", "tokens": [50364, 813, 420, 2681, 281, 1958, 13, 20, 293, 992, 288, 2385, 6915, 281, 472, 420, 4018, 3353, 420, 3671, 1508, 50635, 50635, 19717, 13, 50733, 50733, 407, 300, 311, 577, 291, 360, 38253, 294, 264, 18161, 3209, 1228, 37624, 13, 50949, 50949, 821, 366, 512, 4497, 4365, 300, 286, 994, 380, 352, 670, 510, 11, 1270, 382, 577, 281, 3677, 264, 37624, 51191, 51191, 6405, 293, 577, 281, 611, 3677, 264, 9834, 343, 293, 363, 295, 264, 18161, 3209, 13, 51551, 51551, 583, 321, 603, 352, 670, 300, 294, 264, 2715, 13, 51634, 51634, 407, 1767, 312, 988, 281, 747, 257, 574, 412, 264, 2715, 13, 51763, 51763], "temperature": 0.0, "avg_logprob": -0.15242909518155184, "compression_ratio": 1.6693227091633467, "no_speech_prob": 3.237648570575402e-06}, {"id": 69, "seek": 31608, "start": 339.82, "end": 341.47999999999996, "text": " But we'll go over that in the lab.", "tokens": [50364, 813, 420, 2681, 281, 1958, 13, 20, 293, 992, 288, 2385, 6915, 281, 472, 420, 4018, 3353, 420, 3671, 1508, 50635, 50635, 19717, 13, 50733, 50733, 407, 300, 311, 577, 291, 360, 38253, 294, 264, 18161, 3209, 1228, 37624, 13, 50949, 50949, 821, 366, 512, 4497, 4365, 300, 286, 994, 380, 352, 670, 510, 11, 1270, 382, 577, 281, 3677, 264, 37624, 51191, 51191, 6405, 293, 577, 281, 611, 3677, 264, 9834, 343, 293, 363, 295, 264, 18161, 3209, 13, 51551, 51551, 583, 321, 603, 352, 670, 300, 294, 264, 2715, 13, 51634, 51634, 407, 1767, 312, 988, 281, 747, 257, 574, 412, 264, 2715, 13, 51763, 51763], "temperature": 0.0, "avg_logprob": -0.15242909518155184, "compression_ratio": 1.6693227091633467, "no_speech_prob": 3.237648570575402e-06}, {"id": 70, "seek": 31608, "start": 341.47999999999996, "end": 344.06, "text": " So please be sure to take a look at the lab.", "tokens": [50364, 813, 420, 2681, 281, 1958, 13, 20, 293, 992, 288, 2385, 6915, 281, 472, 420, 4018, 3353, 420, 3671, 1508, 50635, 50635, 19717, 13, 50733, 50733, 407, 300, 311, 577, 291, 360, 38253, 294, 264, 18161, 3209, 1228, 37624, 13, 50949, 50949, 821, 366, 512, 4497, 4365, 300, 286, 994, 380, 352, 670, 510, 11, 1270, 382, 577, 281, 3677, 264, 37624, 51191, 51191, 6405, 293, 577, 281, 611, 3677, 264, 9834, 343, 293, 363, 295, 264, 18161, 3209, 13, 51551, 51551, 583, 321, 603, 352, 670, 300, 294, 264, 2715, 13, 51634, 51634, 407, 1767, 312, 988, 281, 747, 257, 574, 412, 264, 2715, 13, 51763, 51763], "temperature": 0.0, "avg_logprob": -0.15242909518155184, "compression_ratio": 1.6693227091633467, "no_speech_prob": 3.237648570575402e-06}, {"id": 71, "seek": 34406, "start": 344.06, "end": 350.66, "text": " But these are the key steps for for propagation and how you compute a one and a two and optionally", "tokens": [50364, 583, 613, 366, 264, 2141, 4439, 337, 337, 38377, 293, 577, 291, 14722, 257, 472, 293, 257, 732, 293, 3614, 379, 50694, 50694, 14678, 257, 732, 13, 50814, 50814, 961, 311, 574, 412, 472, 544, 1365, 13, 50898, 50898, 400, 321, 434, 516, 281, 352, 646, 281, 264, 1011, 26859, 14293, 21538, 1154, 13, 51174, 51174, 407, 294, 341, 1365, 11, 1783, 307, 257, 1329, 295, 264, 19261, 13749, 4190, 13, 51413, 51413, 407, 1783, 307, 2681, 281, 257, 2107, 12, 22630, 10225, 295, 341, 1329, 295, 19261, 13749, 4190, 13, 51664, 51664], "temperature": 0.0, "avg_logprob": -0.16064829575388054, "compression_ratio": 1.6651162790697673, "no_speech_prob": 6.048546310921665e-06}, {"id": 72, "seek": 34406, "start": 350.66, "end": 353.06, "text": " threshold a two.", "tokens": [50364, 583, 613, 366, 264, 2141, 4439, 337, 337, 38377, 293, 577, 291, 14722, 257, 472, 293, 257, 732, 293, 3614, 379, 50694, 50694, 14678, 257, 732, 13, 50814, 50814, 961, 311, 574, 412, 472, 544, 1365, 13, 50898, 50898, 400, 321, 434, 516, 281, 352, 646, 281, 264, 1011, 26859, 14293, 21538, 1154, 13, 51174, 51174, 407, 294, 341, 1365, 11, 1783, 307, 257, 1329, 295, 264, 19261, 13749, 4190, 13, 51413, 51413, 407, 1783, 307, 2681, 281, 257, 2107, 12, 22630, 10225, 295, 341, 1329, 295, 19261, 13749, 4190, 13, 51664, 51664], "temperature": 0.0, "avg_logprob": -0.16064829575388054, "compression_ratio": 1.6651162790697673, "no_speech_prob": 6.048546310921665e-06}, {"id": 73, "seek": 34406, "start": 353.06, "end": 354.74, "text": " Let's look at one more example.", "tokens": [50364, 583, 613, 366, 264, 2141, 4439, 337, 337, 38377, 293, 577, 291, 14722, 257, 472, 293, 257, 732, 293, 3614, 379, 50694, 50694, 14678, 257, 732, 13, 50814, 50814, 961, 311, 574, 412, 472, 544, 1365, 13, 50898, 50898, 400, 321, 434, 516, 281, 352, 646, 281, 264, 1011, 26859, 14293, 21538, 1154, 13, 51174, 51174, 407, 294, 341, 1365, 11, 1783, 307, 257, 1329, 295, 264, 19261, 13749, 4190, 13, 51413, 51413, 407, 1783, 307, 2681, 281, 257, 2107, 12, 22630, 10225, 295, 341, 1329, 295, 19261, 13749, 4190, 13, 51664, 51664], "temperature": 0.0, "avg_logprob": -0.16064829575388054, "compression_ratio": 1.6651162790697673, "no_speech_prob": 6.048546310921665e-06}, {"id": 74, "seek": 34406, "start": 354.74, "end": 360.26, "text": " And we're going to go back to the handwritten digit classification problem.", "tokens": [50364, 583, 613, 366, 264, 2141, 4439, 337, 337, 38377, 293, 577, 291, 14722, 257, 472, 293, 257, 732, 293, 3614, 379, 50694, 50694, 14678, 257, 732, 13, 50814, 50814, 961, 311, 574, 412, 472, 544, 1365, 13, 50898, 50898, 400, 321, 434, 516, 281, 352, 646, 281, 264, 1011, 26859, 14293, 21538, 1154, 13, 51174, 51174, 407, 294, 341, 1365, 11, 1783, 307, 257, 1329, 295, 264, 19261, 13749, 4190, 13, 51413, 51413, 407, 1783, 307, 2681, 281, 257, 2107, 12, 22630, 10225, 295, 341, 1329, 295, 19261, 13749, 4190, 13, 51664, 51664], "temperature": 0.0, "avg_logprob": -0.16064829575388054, "compression_ratio": 1.6651162790697673, "no_speech_prob": 6.048546310921665e-06}, {"id": 75, "seek": 34406, "start": 360.26, "end": 365.04, "text": " So in this example, X is a list of the pixel intensity values.", "tokens": [50364, 583, 613, 366, 264, 2141, 4439, 337, 337, 38377, 293, 577, 291, 14722, 257, 472, 293, 257, 732, 293, 3614, 379, 50694, 50694, 14678, 257, 732, 13, 50814, 50814, 961, 311, 574, 412, 472, 544, 1365, 13, 50898, 50898, 400, 321, 434, 516, 281, 352, 646, 281, 264, 1011, 26859, 14293, 21538, 1154, 13, 51174, 51174, 407, 294, 341, 1365, 11, 1783, 307, 257, 1329, 295, 264, 19261, 13749, 4190, 13, 51413, 51413, 407, 1783, 307, 2681, 281, 257, 2107, 12, 22630, 10225, 295, 341, 1329, 295, 19261, 13749, 4190, 13, 51664, 51664], "temperature": 0.0, "avg_logprob": -0.16064829575388054, "compression_ratio": 1.6651162790697673, "no_speech_prob": 6.048546310921665e-06}, {"id": 76, "seek": 34406, "start": 365.04, "end": 370.06, "text": " So X is equal to a non-pi array of this list of pixel intensity values.", "tokens": [50364, 583, 613, 366, 264, 2141, 4439, 337, 337, 38377, 293, 577, 291, 14722, 257, 472, 293, 257, 732, 293, 3614, 379, 50694, 50694, 14678, 257, 732, 13, 50814, 50814, 961, 311, 574, 412, 472, 544, 1365, 13, 50898, 50898, 400, 321, 434, 516, 281, 352, 646, 281, 264, 1011, 26859, 14293, 21538, 1154, 13, 51174, 51174, 407, 294, 341, 1365, 11, 1783, 307, 257, 1329, 295, 264, 19261, 13749, 4190, 13, 51413, 51413, 407, 1783, 307, 2681, 281, 257, 2107, 12, 22630, 10225, 295, 341, 1329, 295, 19261, 13749, 4190, 13, 51664, 51664], "temperature": 0.0, "avg_logprob": -0.16064829575388054, "compression_ratio": 1.6651162790697673, "no_speech_prob": 6.048546310921665e-06}, {"id": 77, "seek": 37006, "start": 370.06, "end": 377.98, "text": " And then to initialize and carry out one step before propagation, layer one is a dense layer", "tokens": [50364, 400, 550, 281, 5883, 1125, 293, 3985, 484, 472, 1823, 949, 38377, 11, 4583, 472, 307, 257, 18011, 4583, 50760, 50760, 365, 3552, 6815, 293, 257, 4556, 3280, 327, 24433, 2445, 13, 50966, 50966, 400, 291, 550, 14722, 257, 472, 6915, 264, 4583, 472, 2445, 6456, 281, 1783, 281, 1322, 293, 3985, 51276, 51276, 484, 38253, 807, 264, 1150, 4583, 13, 51450, 51450], "temperature": 0.0, "avg_logprob": -0.1758241506723257, "compression_ratio": 1.569767441860465, "no_speech_prob": 6.4386872509203386e-06}, {"id": 78, "seek": 37006, "start": 377.98, "end": 382.1, "text": " with 25 units and a sigmoid activation function.", "tokens": [50364, 400, 550, 281, 5883, 1125, 293, 3985, 484, 472, 1823, 949, 38377, 11, 4583, 472, 307, 257, 18011, 4583, 50760, 50760, 365, 3552, 6815, 293, 257, 4556, 3280, 327, 24433, 2445, 13, 50966, 50966, 400, 291, 550, 14722, 257, 472, 6915, 264, 4583, 472, 2445, 6456, 281, 1783, 281, 1322, 293, 3985, 51276, 51276, 484, 38253, 807, 264, 1150, 4583, 13, 51450, 51450], "temperature": 0.0, "avg_logprob": -0.1758241506723257, "compression_ratio": 1.569767441860465, "no_speech_prob": 6.4386872509203386e-06}, {"id": 79, "seek": 37006, "start": 382.1, "end": 388.3, "text": " And you then compute a one equals the layer one function applied to X to build and carry", "tokens": [50364, 400, 550, 281, 5883, 1125, 293, 3985, 484, 472, 1823, 949, 38377, 11, 4583, 472, 307, 257, 18011, 4583, 50760, 50760, 365, 3552, 6815, 293, 257, 4556, 3280, 327, 24433, 2445, 13, 50966, 50966, 400, 291, 550, 14722, 257, 472, 6915, 264, 4583, 472, 2445, 6456, 281, 1783, 281, 1322, 293, 3985, 51276, 51276, 484, 38253, 807, 264, 1150, 4583, 13, 51450, 51450], "temperature": 0.0, "avg_logprob": -0.1758241506723257, "compression_ratio": 1.569767441860465, "no_speech_prob": 6.4386872509203386e-06}, {"id": 80, "seek": 37006, "start": 388.3, "end": 391.78, "text": " out inference through the second layer.", "tokens": [50364, 400, 550, 281, 5883, 1125, 293, 3985, 484, 472, 1823, 949, 38377, 11, 4583, 472, 307, 257, 18011, 4583, 50760, 50760, 365, 3552, 6815, 293, 257, 4556, 3280, 327, 24433, 2445, 13, 50966, 50966, 400, 291, 550, 14722, 257, 472, 6915, 264, 4583, 472, 2445, 6456, 281, 1783, 281, 1322, 293, 3985, 51276, 51276, 484, 38253, 807, 264, 1150, 4583, 13, 51450, 51450], "temperature": 0.0, "avg_logprob": -0.1758241506723257, "compression_ratio": 1.569767441860465, "no_speech_prob": 6.4386872509203386e-06}, {"id": 81, "seek": 39178, "start": 391.78, "end": 400.73999999999995, "text": " Similarly, you set up layer two as follows and then compute a two as layer two applied to a one.", "tokens": [50364, 13157, 11, 291, 992, 493, 4583, 732, 382, 10002, 293, 550, 14722, 257, 732, 382, 4583, 732, 6456, 281, 257, 472, 13, 50812, 50812, 400, 550, 2721, 11, 4583, 1045, 307, 264, 2636, 293, 2572, 18011, 4583, 13, 51072, 51072, 400, 550, 2721, 11, 291, 393, 3614, 379, 14678, 257, 1045, 281, 808, 493, 365, 257, 17434, 17630, 51300, 51300, 337, 398, 2385, 13, 51408, 51408, 407, 300, 311, 264, 28431, 337, 9792, 484, 38253, 294, 37624, 13, 51648, 51648], "temperature": 0.0, "avg_logprob": -0.1265942527026665, "compression_ratio": 1.635, "no_speech_prob": 7.112311095625046e-07}, {"id": 82, "seek": 39178, "start": 400.73999999999995, "end": 405.94, "text": " And then finally, layer three is the third and final dense layer.", "tokens": [50364, 13157, 11, 291, 992, 493, 4583, 732, 382, 10002, 293, 550, 14722, 257, 732, 382, 4583, 732, 6456, 281, 257, 472, 13, 50812, 50812, 400, 550, 2721, 11, 4583, 1045, 307, 264, 2636, 293, 2572, 18011, 4583, 13, 51072, 51072, 400, 550, 2721, 11, 291, 393, 3614, 379, 14678, 257, 1045, 281, 808, 493, 365, 257, 17434, 17630, 51300, 51300, 337, 398, 2385, 13, 51408, 51408, 407, 300, 311, 264, 28431, 337, 9792, 484, 38253, 294, 37624, 13, 51648, 51648], "temperature": 0.0, "avg_logprob": -0.1265942527026665, "compression_ratio": 1.635, "no_speech_prob": 7.112311095625046e-07}, {"id": 83, "seek": 39178, "start": 405.94, "end": 410.5, "text": " And then finally, you can optionally threshold a three to come up with a binary prediction", "tokens": [50364, 13157, 11, 291, 992, 493, 4583, 732, 382, 10002, 293, 550, 14722, 257, 732, 382, 4583, 732, 6456, 281, 257, 472, 13, 50812, 50812, 400, 550, 2721, 11, 4583, 1045, 307, 264, 2636, 293, 2572, 18011, 4583, 13, 51072, 51072, 400, 550, 2721, 11, 291, 393, 3614, 379, 14678, 257, 1045, 281, 808, 493, 365, 257, 17434, 17630, 51300, 51300, 337, 398, 2385, 13, 51408, 51408, 407, 300, 311, 264, 28431, 337, 9792, 484, 38253, 294, 37624, 13, 51648, 51648], "temperature": 0.0, "avg_logprob": -0.1265942527026665, "compression_ratio": 1.635, "no_speech_prob": 7.112311095625046e-07}, {"id": 84, "seek": 39178, "start": 410.5, "end": 412.65999999999997, "text": " for Y hat.", "tokens": [50364, 13157, 11, 291, 992, 493, 4583, 732, 382, 10002, 293, 550, 14722, 257, 732, 382, 4583, 732, 6456, 281, 257, 472, 13, 50812, 50812, 400, 550, 2721, 11, 4583, 1045, 307, 264, 2636, 293, 2572, 18011, 4583, 13, 51072, 51072, 400, 550, 2721, 11, 291, 393, 3614, 379, 14678, 257, 1045, 281, 808, 493, 365, 257, 17434, 17630, 51300, 51300, 337, 398, 2385, 13, 51408, 51408, 407, 300, 311, 264, 28431, 337, 9792, 484, 38253, 294, 37624, 13, 51648, 51648], "temperature": 0.0, "avg_logprob": -0.1265942527026665, "compression_ratio": 1.635, "no_speech_prob": 7.112311095625046e-07}, {"id": 85, "seek": 39178, "start": 412.65999999999997, "end": 417.46, "text": " So that's the syntax for carrying out inference in TensorFlow.", "tokens": [50364, 13157, 11, 291, 992, 493, 4583, 732, 382, 10002, 293, 550, 14722, 257, 732, 382, 4583, 732, 6456, 281, 257, 472, 13, 50812, 50812, 400, 550, 2721, 11, 4583, 1045, 307, 264, 2636, 293, 2572, 18011, 4583, 13, 51072, 51072, 400, 550, 2721, 11, 291, 393, 3614, 379, 14678, 257, 1045, 281, 808, 493, 365, 257, 17434, 17630, 51300, 51300, 337, 398, 2385, 13, 51408, 51408, 407, 300, 311, 264, 28431, 337, 9792, 484, 38253, 294, 37624, 13, 51648, 51648], "temperature": 0.0, "avg_logprob": -0.1265942527026665, "compression_ratio": 1.635, "no_speech_prob": 7.112311095625046e-07}, {"id": 86, "seek": 41746, "start": 417.46, "end": 422.58, "text": " One thing I briefly alluded to is the structure of the non-pi arrays.", "tokens": [50364, 1485, 551, 286, 10515, 33919, 281, 307, 264, 3877, 295, 264, 2107, 12, 22630, 41011, 13, 50620, 50620, 37624, 19566, 1412, 294, 257, 1629, 636, 300, 307, 1021, 281, 483, 558, 13, 50859, 50859, 407, 294, 264, 958, 960, 11, 718, 311, 747, 257, 574, 412, 577, 37624, 18722, 1412, 13, 51082], "temperature": 0.0, "avg_logprob": -0.14892828906023944, "compression_ratio": 1.392156862745098, "no_speech_prob": 3.526743239490315e-05}, {"id": 87, "seek": 41746, "start": 422.58, "end": 427.35999999999996, "text": " TensorFlow treats data in a certain way that is important to get right.", "tokens": [50364, 1485, 551, 286, 10515, 33919, 281, 307, 264, 3877, 295, 264, 2107, 12, 22630, 41011, 13, 50620, 50620, 37624, 19566, 1412, 294, 257, 1629, 636, 300, 307, 1021, 281, 483, 558, 13, 50859, 50859, 407, 294, 264, 958, 960, 11, 718, 311, 747, 257, 574, 412, 577, 37624, 18722, 1412, 13, 51082], "temperature": 0.0, "avg_logprob": -0.14892828906023944, "compression_ratio": 1.392156862745098, "no_speech_prob": 3.526743239490315e-05}, {"id": 88, "seek": 42736, "start": 427.36, "end": 448.26, "text": " So in the next video, let's take a look at how TensorFlow handles data.", "tokens": [50364, 407, 294, 264, 958, 960, 11, 718, 311, 747, 257, 574, 412, 577, 37624, 18722, 1412, 13, 51409, 51409], "temperature": 0.0, "avg_logprob": -0.22358283542451404, "compression_ratio": 0.9861111111111112, "no_speech_prob": 0.000140598596772179}], "language": "en", "video_id": "VctGI7Xaogw", "entity": "ML Specialization, Andrew Ng (2022)"}}