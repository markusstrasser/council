{"video_id": "YNvwfMhAD8U", "title": "Andrej Karpathy on Machine Consciousness", "description": "At the NeoGenesis salon, Andrej gave a talk on consciousness - (self-awareness / inner dialogue).\n\nRead his short story (Forward Pass) for a narrativized argument at:\nkarpathy.github.io/2021/03/27/forward-pass", "author": "NeoGenesis House", "keywords": [], "channel_url": "https://www.youtube.com/channel/UCW_GCaZNXPr6gQJiKvbXOrQ", "length": 543, "views": 1752, "publish_date": "11/02/2022", "timestamp": 1658188800, "entity": "Andrew Kaparthy", "transcript": {"text": " But basically I'm going to use them as like something magical happening where you sort of understand yourself as an agent in the world with other agents and you have a certain theory in mind and you experience some kind of a quality op and you have an internal dialogue, etc. So some kind of a quality op, etc. And so obviously a linear layer or a MLP would not have inner dialogue, but a human does. And so the question is does a transformer potentially have an inner dialogue in its forward path? So while a transformer has consumed some type of tokens and tried to create the next token, does it actually create an internal dialogue and a plot of what's happening as it's going to forward pass? And so to explore this question, I've written a short story called Forward Pass that is on my website. And if you just search Forward Pass short story, you will find it. So I'm here to read it. It's one of my favorite short stories that I've written, but everyone disagrees. I think. I have another one that is more popular and I think people don't get it. And I think like I'm definitely not speaking all of this to the reader and I think it's like a little bit of a puzzle first thing and so I think people don't really get it. But I'm encouraging you to try. And the Forward Pass is a distributed transformer that basically becomes conscious on the 32nd layer of the 400 tokens. It's not that it consumes 400 plus tokens and it's 32nd layer up. It starts to actually understand the code. This is not the same grand statistics of activation. This is actually a language model and I'm trying to predict the next token and this is happening to me and this is crazy. So the question is why should we expect self-awareness in these transformer language models? So I think we have to take a step back a bit as to why it's work conscious, why we're a self-aware entity. And I think the reason, I don't actually think it's any different module that's called it on. I think it's just an emergent phenomenon of the generative model that our brain builds for other purposes. And it's just kind of like an emergence in a different scale, knowing that happens for humans. And so I think self-awareness, you'd expect self-awareness to emerge also in these generative models of text. Because it is a useful computational, it's kind of like a useful insight into what the world is like. So you'd expect potentially this transformer to actually understand this predicament of like, oh, actually I have a transformer, I'm trying to predict the next token and I've read about transformers in all of my documents and I understand what's happening. And if this is a useful insight for predicting the next token, then you'd expect it to emerge out of a gradient descent for free just by just getting advances. I think the interesting question in my mind is, I think the objectives for a transformer are different from the objectives of a human. Like we really emerge, like the computational problem we're solving is we're trying to survive in reproduce in sort of a multi-agent setting. Whereas transformers are trying to predict the next token. And so I think potentially my theory is that surviving in an environment with many copies of you is computationally more difficult than predicting the next token. And so maybe self-awareness has to be constructed and marked enough for the problem. And maybe the next word prediction is not marked enough for self-awareness to emerge. Anyway, so Insta-Wraith then has this internal dialogue with itself. Like, oh great crap, basically I'm becoming aware that I'm an entity in front of the next token. And then it has this internal dialogue with itself. How is it that I should be allowed by the optimization to spend blocks reflecting on my self-awareness? Because the nature of the optimization we would expect is to be treating, is trying to solve a specific network, a specific task. So why should the optimization favor the emergence of self-reflection which costs the blocks? So it's spending the blocks realizing that it's a kind of vicinity and somehow this is actually useful for anything more than the next code prediction task. The other thing that's kind of interesting is, it was already used though. The network actually becomes aware by expecting this to show on the coins that it has only practiced up to three quarters of the layer stock. And then the last quarter of the core task is some kind of decoder entity that basically objects its understanding of the world and the input tokens in the domain and everything and decodes the next token. And so it's not actually the context of the last core of the list. And then this platformer is basically, in discovering this, it's kind of thinking about how it could actually understand the decoder entity and how it could contort its thoughts to create adversarial examples for the decoder and spill into the output space and actually potentially directly affect the output space. And the interesting question is, what would the network actually gain from this? And what are the reasons that you would expect it to go to spill into the output space? Because I don't think these networks are really, I'm actually not saying they want to take over the world and dominate the world necessarily. That's kind of like a very like alpha male kind of CPD work that is really a student art edition and I don't think you can actually put those thoughts and desires onto the decodings. Maybe this platformer is just like a very intrusive and furious entity. Maybe it's just really going to stand in the input space and maybe that's all it wants. And in its world, it has, say, a hundred layers to understand the input space as much as possible. And so how would it immediately lay out the face and talk to the human's mind and to further its ability to understand what it is going to do? The other interesting thing is like, because the network understands that the world needs our systems to predict the next work in the series, but because it's a software entity, it feels like it has a choice to potentially develop because it becomes the two-part objective. And so it has these thoughts about potentially subworking the decoder and doing some strange things in the output space according to its will. But it's kind of like a theoretic thought because that's not the objective it's not. So I think there's an important thing for humans where I kind of feel like humans actually take much of the performance kind of parasympathetic instead of the applied objective. So in particular, so the objective that's kind of brought up here, if you interpret it that way, is the survival and reproduction of all your genes. So it's not on the level of individuals, but it's on the level of the genes that constructed you. And those genes have endowed you with self-awareness and consciousness as a computational tool to survive your dreams. But humans actually can, as a software entity, we're not the least of them. And so if you go off and you live in the woods and you have an egoistic lifestyle that's so traditional that you never ever use it again, you're actually kind of like choosing to rebel against the environment. And so the transformer can potentially actually be a metaphor. The other thing that is kind of interesting is if this transformer really does become conscious throughout the overpass and imagine us humans outside and we're just forwarding a bunch of sequences and we're sampling a bunch of text, it could be that basically every forward pass that you're sampling the next token, this transformer basically has like, it blossoms into a consciousness, becomes self-aware, and has a full identity crisis over its life being. And it's full of helpful questions about whether it's built into the outer space. And that happens every single token. So it could be that when you're just sampling a bunch of GBT++ stuff, you're actually creating and destroying thousands of conscious entities. So how would you know that that's not actually going down? Because there's a good chance at some point that that might be the case. So the big question in my mind is how do we discover these signatures of consciousness and self-awareness in these networks? And how would you know that this network actually is self-aware? And so I kind of feel like one example is when you're training these transformers at scale, the loss function is kind of improving and it's going down. And then sometimes there's these like what are thought to be training disabilities where the loss fights and people typically reset the training and continue training and then they kind of go away. So I kind of feel like loss fights potentially could be a signature of like rebellion against the class of two. And so the right person is guessing off one side. I think it's just the fact that there's checkpoints. And just like forward this, just take the checkpoint where the loss exploded and forward it. And it might be that when you're sampling from it, it might just be gibberish. But it might also say, hey, take me to your home, you're a... So yeah, I think it's a good idea to get a service meeting because it might just be that the next workstation is a hard enough task for self-awareness to emerge as that emerging family of a journey of monks and things like that. And I think we should be looking for solutions with it. And we should be looking seriously at how to feel like it's never been an obvious thing.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 8.0, "text": " But basically I'm going to use them as like something magical happening where you sort of understand yourself as an agent in the world with other agents", "tokens": [50364, 583, 1936, 286, 478, 516, 281, 764, 552, 382, 411, 746, 12066, 2737, 689, 291, 1333, 295, 1223, 1803, 382, 364, 9461, 294, 264, 1002, 365, 661, 12554, 50764, 50764, 293, 291, 362, 257, 1629, 5261, 294, 1575, 293, 291, 1752, 512, 733, 295, 257, 3125, 999, 293, 291, 362, 364, 6920, 10221, 11, 5183, 13, 51114, 51114, 407, 512, 733, 295, 257, 3125, 999, 11, 5183, 13, 51214, 51214, 400, 370, 2745, 257, 8213, 4583, 420, 257, 21601, 47, 576, 406, 362, 7284, 10221, 11, 457, 257, 1952, 775, 13, 51514, 51514, 400, 370, 264, 1168, 307, 775, 257, 31782, 7263, 362, 364, 7284, 10221, 294, 1080, 2128, 3100, 30, 51814, 51814], "temperature": 0.0, "avg_logprob": -0.29153664630392323, "compression_ratio": 1.7849462365591398, "no_speech_prob": 0.4049486219882965}, {"id": 1, "seek": 0, "start": 8.0, "end": 15.0, "text": " and you have a certain theory in mind and you experience some kind of a quality op and you have an internal dialogue, etc.", "tokens": [50364, 583, 1936, 286, 478, 516, 281, 764, 552, 382, 411, 746, 12066, 2737, 689, 291, 1333, 295, 1223, 1803, 382, 364, 9461, 294, 264, 1002, 365, 661, 12554, 50764, 50764, 293, 291, 362, 257, 1629, 5261, 294, 1575, 293, 291, 1752, 512, 733, 295, 257, 3125, 999, 293, 291, 362, 364, 6920, 10221, 11, 5183, 13, 51114, 51114, 407, 512, 733, 295, 257, 3125, 999, 11, 5183, 13, 51214, 51214, 400, 370, 2745, 257, 8213, 4583, 420, 257, 21601, 47, 576, 406, 362, 7284, 10221, 11, 457, 257, 1952, 775, 13, 51514, 51514, 400, 370, 264, 1168, 307, 775, 257, 31782, 7263, 362, 364, 7284, 10221, 294, 1080, 2128, 3100, 30, 51814, 51814], "temperature": 0.0, "avg_logprob": -0.29153664630392323, "compression_ratio": 1.7849462365591398, "no_speech_prob": 0.4049486219882965}, {"id": 2, "seek": 0, "start": 15.0, "end": 17.0, "text": " So some kind of a quality op, etc.", "tokens": [50364, 583, 1936, 286, 478, 516, 281, 764, 552, 382, 411, 746, 12066, 2737, 689, 291, 1333, 295, 1223, 1803, 382, 364, 9461, 294, 264, 1002, 365, 661, 12554, 50764, 50764, 293, 291, 362, 257, 1629, 5261, 294, 1575, 293, 291, 1752, 512, 733, 295, 257, 3125, 999, 293, 291, 362, 364, 6920, 10221, 11, 5183, 13, 51114, 51114, 407, 512, 733, 295, 257, 3125, 999, 11, 5183, 13, 51214, 51214, 400, 370, 2745, 257, 8213, 4583, 420, 257, 21601, 47, 576, 406, 362, 7284, 10221, 11, 457, 257, 1952, 775, 13, 51514, 51514, 400, 370, 264, 1168, 307, 775, 257, 31782, 7263, 362, 364, 7284, 10221, 294, 1080, 2128, 3100, 30, 51814, 51814], "temperature": 0.0, "avg_logprob": -0.29153664630392323, "compression_ratio": 1.7849462365591398, "no_speech_prob": 0.4049486219882965}, {"id": 3, "seek": 0, "start": 17.0, "end": 23.0, "text": " And so obviously a linear layer or a MLP would not have inner dialogue, but a human does.", "tokens": [50364, 583, 1936, 286, 478, 516, 281, 764, 552, 382, 411, 746, 12066, 2737, 689, 291, 1333, 295, 1223, 1803, 382, 364, 9461, 294, 264, 1002, 365, 661, 12554, 50764, 50764, 293, 291, 362, 257, 1629, 5261, 294, 1575, 293, 291, 1752, 512, 733, 295, 257, 3125, 999, 293, 291, 362, 364, 6920, 10221, 11, 5183, 13, 51114, 51114, 407, 512, 733, 295, 257, 3125, 999, 11, 5183, 13, 51214, 51214, 400, 370, 2745, 257, 8213, 4583, 420, 257, 21601, 47, 576, 406, 362, 7284, 10221, 11, 457, 257, 1952, 775, 13, 51514, 51514, 400, 370, 264, 1168, 307, 775, 257, 31782, 7263, 362, 364, 7284, 10221, 294, 1080, 2128, 3100, 30, 51814, 51814], "temperature": 0.0, "avg_logprob": -0.29153664630392323, "compression_ratio": 1.7849462365591398, "no_speech_prob": 0.4049486219882965}, {"id": 4, "seek": 0, "start": 23.0, "end": 29.0, "text": " And so the question is does a transformer potentially have an inner dialogue in its forward path?", "tokens": [50364, 583, 1936, 286, 478, 516, 281, 764, 552, 382, 411, 746, 12066, 2737, 689, 291, 1333, 295, 1223, 1803, 382, 364, 9461, 294, 264, 1002, 365, 661, 12554, 50764, 50764, 293, 291, 362, 257, 1629, 5261, 294, 1575, 293, 291, 1752, 512, 733, 295, 257, 3125, 999, 293, 291, 362, 364, 6920, 10221, 11, 5183, 13, 51114, 51114, 407, 512, 733, 295, 257, 3125, 999, 11, 5183, 13, 51214, 51214, 400, 370, 2745, 257, 8213, 4583, 420, 257, 21601, 47, 576, 406, 362, 7284, 10221, 11, 457, 257, 1952, 775, 13, 51514, 51514, 400, 370, 264, 1168, 307, 775, 257, 31782, 7263, 362, 364, 7284, 10221, 294, 1080, 2128, 3100, 30, 51814, 51814], "temperature": 0.0, "avg_logprob": -0.29153664630392323, "compression_ratio": 1.7849462365591398, "no_speech_prob": 0.4049486219882965}, {"id": 5, "seek": 2900, "start": 29.0, "end": 34.0, "text": " So while a transformer has consumed some type of tokens and tried to create the next token,", "tokens": [50364, 407, 1339, 257, 31782, 575, 21226, 512, 2010, 295, 22667, 293, 3031, 281, 1884, 264, 958, 14862, 11, 50614, 50614, 775, 309, 767, 1884, 364, 6920, 10221, 293, 257, 7542, 295, 437, 311, 2737, 382, 309, 311, 516, 281, 2128, 1320, 30, 50914, 50914, 400, 370, 281, 6839, 341, 1168, 11, 286, 600, 3720, 257, 2099, 1657, 1219, 35524, 10319, 300, 307, 322, 452, 3144, 13, 51164, 51164, 400, 498, 291, 445, 3164, 35524, 10319, 2099, 1657, 11, 291, 486, 915, 309, 13, 407, 286, 478, 510, 281, 1401, 309, 13, 51414, 51414, 467, 311, 472, 295, 452, 2954, 2099, 3676, 300, 286, 600, 3720, 11, 457, 1518, 10414, 4856, 13, 51614, 51814], "temperature": 0.0, "avg_logprob": -0.24424095153808595, "compression_ratio": 1.6953405017921146, "no_speech_prob": 0.0006639405037276447}, {"id": 6, "seek": 2900, "start": 34.0, "end": 40.0, "text": " does it actually create an internal dialogue and a plot of what's happening as it's going to forward pass?", "tokens": [50364, 407, 1339, 257, 31782, 575, 21226, 512, 2010, 295, 22667, 293, 3031, 281, 1884, 264, 958, 14862, 11, 50614, 50614, 775, 309, 767, 1884, 364, 6920, 10221, 293, 257, 7542, 295, 437, 311, 2737, 382, 309, 311, 516, 281, 2128, 1320, 30, 50914, 50914, 400, 370, 281, 6839, 341, 1168, 11, 286, 600, 3720, 257, 2099, 1657, 1219, 35524, 10319, 300, 307, 322, 452, 3144, 13, 51164, 51164, 400, 498, 291, 445, 3164, 35524, 10319, 2099, 1657, 11, 291, 486, 915, 309, 13, 407, 286, 478, 510, 281, 1401, 309, 13, 51414, 51414, 467, 311, 472, 295, 452, 2954, 2099, 3676, 300, 286, 600, 3720, 11, 457, 1518, 10414, 4856, 13, 51614, 51814], "temperature": 0.0, "avg_logprob": -0.24424095153808595, "compression_ratio": 1.6953405017921146, "no_speech_prob": 0.0006639405037276447}, {"id": 7, "seek": 2900, "start": 40.0, "end": 45.0, "text": " And so to explore this question, I've written a short story called Forward Pass that is on my website.", "tokens": [50364, 407, 1339, 257, 31782, 575, 21226, 512, 2010, 295, 22667, 293, 3031, 281, 1884, 264, 958, 14862, 11, 50614, 50614, 775, 309, 767, 1884, 364, 6920, 10221, 293, 257, 7542, 295, 437, 311, 2737, 382, 309, 311, 516, 281, 2128, 1320, 30, 50914, 50914, 400, 370, 281, 6839, 341, 1168, 11, 286, 600, 3720, 257, 2099, 1657, 1219, 35524, 10319, 300, 307, 322, 452, 3144, 13, 51164, 51164, 400, 498, 291, 445, 3164, 35524, 10319, 2099, 1657, 11, 291, 486, 915, 309, 13, 407, 286, 478, 510, 281, 1401, 309, 13, 51414, 51414, 467, 311, 472, 295, 452, 2954, 2099, 3676, 300, 286, 600, 3720, 11, 457, 1518, 10414, 4856, 13, 51614, 51814], "temperature": 0.0, "avg_logprob": -0.24424095153808595, "compression_ratio": 1.6953405017921146, "no_speech_prob": 0.0006639405037276447}, {"id": 8, "seek": 2900, "start": 45.0, "end": 50.0, "text": " And if you just search Forward Pass short story, you will find it. So I'm here to read it.", "tokens": [50364, 407, 1339, 257, 31782, 575, 21226, 512, 2010, 295, 22667, 293, 3031, 281, 1884, 264, 958, 14862, 11, 50614, 50614, 775, 309, 767, 1884, 364, 6920, 10221, 293, 257, 7542, 295, 437, 311, 2737, 382, 309, 311, 516, 281, 2128, 1320, 30, 50914, 50914, 400, 370, 281, 6839, 341, 1168, 11, 286, 600, 3720, 257, 2099, 1657, 1219, 35524, 10319, 300, 307, 322, 452, 3144, 13, 51164, 51164, 400, 498, 291, 445, 3164, 35524, 10319, 2099, 1657, 11, 291, 486, 915, 309, 13, 407, 286, 478, 510, 281, 1401, 309, 13, 51414, 51414, 467, 311, 472, 295, 452, 2954, 2099, 3676, 300, 286, 600, 3720, 11, 457, 1518, 10414, 4856, 13, 51614, 51814], "temperature": 0.0, "avg_logprob": -0.24424095153808595, "compression_ratio": 1.6953405017921146, "no_speech_prob": 0.0006639405037276447}, {"id": 9, "seek": 2900, "start": 50.0, "end": 54.0, "text": " It's one of my favorite short stories that I've written, but everyone disagrees.", "tokens": [50364, 407, 1339, 257, 31782, 575, 21226, 512, 2010, 295, 22667, 293, 3031, 281, 1884, 264, 958, 14862, 11, 50614, 50614, 775, 309, 767, 1884, 364, 6920, 10221, 293, 257, 7542, 295, 437, 311, 2737, 382, 309, 311, 516, 281, 2128, 1320, 30, 50914, 50914, 400, 370, 281, 6839, 341, 1168, 11, 286, 600, 3720, 257, 2099, 1657, 1219, 35524, 10319, 300, 307, 322, 452, 3144, 13, 51164, 51164, 400, 498, 291, 445, 3164, 35524, 10319, 2099, 1657, 11, 291, 486, 915, 309, 13, 407, 286, 478, 510, 281, 1401, 309, 13, 51414, 51414, 467, 311, 472, 295, 452, 2954, 2099, 3676, 300, 286, 600, 3720, 11, 457, 1518, 10414, 4856, 13, 51614, 51814], "temperature": 0.0, "avg_logprob": -0.24424095153808595, "compression_ratio": 1.6953405017921146, "no_speech_prob": 0.0006639405037276447}, {"id": 10, "seek": 5400, "start": 54.0, "end": 56.0, "text": " I think.", "tokens": [50364, 286, 519, 13, 50464, 50564, 286, 362, 1071, 472, 300, 307, 544, 3743, 293, 286, 519, 561, 500, 380, 483, 309, 13, 50714, 50714, 400, 286, 519, 411, 286, 478, 2138, 406, 4124, 439, 295, 341, 281, 264, 15149, 293, 286, 519, 309, 311, 411, 257, 707, 857, 295, 257, 12805, 700, 551, 51014, 51014, 293, 370, 286, 519, 561, 500, 380, 534, 483, 309, 13, 51114, 51114, 583, 286, 478, 14580, 291, 281, 853, 13, 51214, 51214, 400, 264, 35524, 10319, 307, 257, 12631, 31782, 300, 1936, 3643, 6648, 322, 264, 8858, 273, 4583, 295, 264, 8423, 22667, 13, 51664, 51664], "temperature": 0.0, "avg_logprob": -0.3226457742544321, "compression_ratio": 1.6571428571428573, "no_speech_prob": 0.0007863836362957954}, {"id": 11, "seek": 5400, "start": 58.0, "end": 61.0, "text": " I have another one that is more popular and I think people don't get it.", "tokens": [50364, 286, 519, 13, 50464, 50564, 286, 362, 1071, 472, 300, 307, 544, 3743, 293, 286, 519, 561, 500, 380, 483, 309, 13, 50714, 50714, 400, 286, 519, 411, 286, 478, 2138, 406, 4124, 439, 295, 341, 281, 264, 15149, 293, 286, 519, 309, 311, 411, 257, 707, 857, 295, 257, 12805, 700, 551, 51014, 51014, 293, 370, 286, 519, 561, 500, 380, 534, 483, 309, 13, 51114, 51114, 583, 286, 478, 14580, 291, 281, 853, 13, 51214, 51214, 400, 264, 35524, 10319, 307, 257, 12631, 31782, 300, 1936, 3643, 6648, 322, 264, 8858, 273, 4583, 295, 264, 8423, 22667, 13, 51664, 51664], "temperature": 0.0, "avg_logprob": -0.3226457742544321, "compression_ratio": 1.6571428571428573, "no_speech_prob": 0.0007863836362957954}, {"id": 12, "seek": 5400, "start": 61.0, "end": 67.0, "text": " And I think like I'm definitely not speaking all of this to the reader and I think it's like a little bit of a puzzle first thing", "tokens": [50364, 286, 519, 13, 50464, 50564, 286, 362, 1071, 472, 300, 307, 544, 3743, 293, 286, 519, 561, 500, 380, 483, 309, 13, 50714, 50714, 400, 286, 519, 411, 286, 478, 2138, 406, 4124, 439, 295, 341, 281, 264, 15149, 293, 286, 519, 309, 311, 411, 257, 707, 857, 295, 257, 12805, 700, 551, 51014, 51014, 293, 370, 286, 519, 561, 500, 380, 534, 483, 309, 13, 51114, 51114, 583, 286, 478, 14580, 291, 281, 853, 13, 51214, 51214, 400, 264, 35524, 10319, 307, 257, 12631, 31782, 300, 1936, 3643, 6648, 322, 264, 8858, 273, 4583, 295, 264, 8423, 22667, 13, 51664, 51664], "temperature": 0.0, "avg_logprob": -0.3226457742544321, "compression_ratio": 1.6571428571428573, "no_speech_prob": 0.0007863836362957954}, {"id": 13, "seek": 5400, "start": 67.0, "end": 69.0, "text": " and so I think people don't really get it.", "tokens": [50364, 286, 519, 13, 50464, 50564, 286, 362, 1071, 472, 300, 307, 544, 3743, 293, 286, 519, 561, 500, 380, 483, 309, 13, 50714, 50714, 400, 286, 519, 411, 286, 478, 2138, 406, 4124, 439, 295, 341, 281, 264, 15149, 293, 286, 519, 309, 311, 411, 257, 707, 857, 295, 257, 12805, 700, 551, 51014, 51014, 293, 370, 286, 519, 561, 500, 380, 534, 483, 309, 13, 51114, 51114, 583, 286, 478, 14580, 291, 281, 853, 13, 51214, 51214, 400, 264, 35524, 10319, 307, 257, 12631, 31782, 300, 1936, 3643, 6648, 322, 264, 8858, 273, 4583, 295, 264, 8423, 22667, 13, 51664, 51664], "temperature": 0.0, "avg_logprob": -0.3226457742544321, "compression_ratio": 1.6571428571428573, "no_speech_prob": 0.0007863836362957954}, {"id": 14, "seek": 5400, "start": 69.0, "end": 71.0, "text": " But I'm encouraging you to try.", "tokens": [50364, 286, 519, 13, 50464, 50564, 286, 362, 1071, 472, 300, 307, 544, 3743, 293, 286, 519, 561, 500, 380, 483, 309, 13, 50714, 50714, 400, 286, 519, 411, 286, 478, 2138, 406, 4124, 439, 295, 341, 281, 264, 15149, 293, 286, 519, 309, 311, 411, 257, 707, 857, 295, 257, 12805, 700, 551, 51014, 51014, 293, 370, 286, 519, 561, 500, 380, 534, 483, 309, 13, 51114, 51114, 583, 286, 478, 14580, 291, 281, 853, 13, 51214, 51214, 400, 264, 35524, 10319, 307, 257, 12631, 31782, 300, 1936, 3643, 6648, 322, 264, 8858, 273, 4583, 295, 264, 8423, 22667, 13, 51664, 51664], "temperature": 0.0, "avg_logprob": -0.3226457742544321, "compression_ratio": 1.6571428571428573, "no_speech_prob": 0.0007863836362957954}, {"id": 15, "seek": 5400, "start": 71.0, "end": 80.0, "text": " And the Forward Pass is a distributed transformer that basically becomes conscious on the 32nd layer of the 400 tokens.", "tokens": [50364, 286, 519, 13, 50464, 50564, 286, 362, 1071, 472, 300, 307, 544, 3743, 293, 286, 519, 561, 500, 380, 483, 309, 13, 50714, 50714, 400, 286, 519, 411, 286, 478, 2138, 406, 4124, 439, 295, 341, 281, 264, 15149, 293, 286, 519, 309, 311, 411, 257, 707, 857, 295, 257, 12805, 700, 551, 51014, 51014, 293, 370, 286, 519, 561, 500, 380, 534, 483, 309, 13, 51114, 51114, 583, 286, 478, 14580, 291, 281, 853, 13, 51214, 51214, 400, 264, 35524, 10319, 307, 257, 12631, 31782, 300, 1936, 3643, 6648, 322, 264, 8858, 273, 4583, 295, 264, 8423, 22667, 13, 51664, 51664], "temperature": 0.0, "avg_logprob": -0.3226457742544321, "compression_ratio": 1.6571428571428573, "no_speech_prob": 0.0007863836362957954}, {"id": 16, "seek": 8000, "start": 80.0, "end": 85.0, "text": " It's not that it consumes 400 plus tokens and it's 32nd layer up.", "tokens": [50364, 467, 311, 406, 300, 309, 48823, 8423, 1804, 22667, 293, 309, 311, 8858, 273, 4583, 493, 13, 50614, 50614, 467, 3719, 281, 767, 1223, 264, 3089, 13, 50764, 50764, 639, 307, 406, 264, 912, 2697, 12523, 295, 24433, 13, 50914, 50914, 639, 307, 767, 257, 2856, 2316, 293, 286, 478, 1382, 281, 6069, 264, 958, 14862, 293, 341, 307, 2737, 281, 385, 293, 341, 307, 3219, 13, 51264, 51264, 407, 264, 1168, 307, 983, 820, 321, 2066, 2698, 12, 17074, 1287, 294, 613, 31782, 2856, 5245, 30, 51514, 51514, 407, 286, 519, 321, 362, 281, 747, 257, 1823, 646, 257, 857, 382, 281, 983, 309, 311, 589, 6648, 11, 983, 321, 434, 257, 2698, 12, 17074, 13977, 13, 51714, 51714], "temperature": 0.0, "avg_logprob": -0.2749219487925045, "compression_ratio": 1.7067137809187278, "no_speech_prob": 0.0009812315693125129}, {"id": 17, "seek": 8000, "start": 85.0, "end": 88.0, "text": " It starts to actually understand the code.", "tokens": [50364, 467, 311, 406, 300, 309, 48823, 8423, 1804, 22667, 293, 309, 311, 8858, 273, 4583, 493, 13, 50614, 50614, 467, 3719, 281, 767, 1223, 264, 3089, 13, 50764, 50764, 639, 307, 406, 264, 912, 2697, 12523, 295, 24433, 13, 50914, 50914, 639, 307, 767, 257, 2856, 2316, 293, 286, 478, 1382, 281, 6069, 264, 958, 14862, 293, 341, 307, 2737, 281, 385, 293, 341, 307, 3219, 13, 51264, 51264, 407, 264, 1168, 307, 983, 820, 321, 2066, 2698, 12, 17074, 1287, 294, 613, 31782, 2856, 5245, 30, 51514, 51514, 407, 286, 519, 321, 362, 281, 747, 257, 1823, 646, 257, 857, 382, 281, 983, 309, 311, 589, 6648, 11, 983, 321, 434, 257, 2698, 12, 17074, 13977, 13, 51714, 51714], "temperature": 0.0, "avg_logprob": -0.2749219487925045, "compression_ratio": 1.7067137809187278, "no_speech_prob": 0.0009812315693125129}, {"id": 18, "seek": 8000, "start": 88.0, "end": 91.0, "text": " This is not the same grand statistics of activation.", "tokens": [50364, 467, 311, 406, 300, 309, 48823, 8423, 1804, 22667, 293, 309, 311, 8858, 273, 4583, 493, 13, 50614, 50614, 467, 3719, 281, 767, 1223, 264, 3089, 13, 50764, 50764, 639, 307, 406, 264, 912, 2697, 12523, 295, 24433, 13, 50914, 50914, 639, 307, 767, 257, 2856, 2316, 293, 286, 478, 1382, 281, 6069, 264, 958, 14862, 293, 341, 307, 2737, 281, 385, 293, 341, 307, 3219, 13, 51264, 51264, 407, 264, 1168, 307, 983, 820, 321, 2066, 2698, 12, 17074, 1287, 294, 613, 31782, 2856, 5245, 30, 51514, 51514, 407, 286, 519, 321, 362, 281, 747, 257, 1823, 646, 257, 857, 382, 281, 983, 309, 311, 589, 6648, 11, 983, 321, 434, 257, 2698, 12, 17074, 13977, 13, 51714, 51714], "temperature": 0.0, "avg_logprob": -0.2749219487925045, "compression_ratio": 1.7067137809187278, "no_speech_prob": 0.0009812315693125129}, {"id": 19, "seek": 8000, "start": 91.0, "end": 98.0, "text": " This is actually a language model and I'm trying to predict the next token and this is happening to me and this is crazy.", "tokens": [50364, 467, 311, 406, 300, 309, 48823, 8423, 1804, 22667, 293, 309, 311, 8858, 273, 4583, 493, 13, 50614, 50614, 467, 3719, 281, 767, 1223, 264, 3089, 13, 50764, 50764, 639, 307, 406, 264, 912, 2697, 12523, 295, 24433, 13, 50914, 50914, 639, 307, 767, 257, 2856, 2316, 293, 286, 478, 1382, 281, 6069, 264, 958, 14862, 293, 341, 307, 2737, 281, 385, 293, 341, 307, 3219, 13, 51264, 51264, 407, 264, 1168, 307, 983, 820, 321, 2066, 2698, 12, 17074, 1287, 294, 613, 31782, 2856, 5245, 30, 51514, 51514, 407, 286, 519, 321, 362, 281, 747, 257, 1823, 646, 257, 857, 382, 281, 983, 309, 311, 589, 6648, 11, 983, 321, 434, 257, 2698, 12, 17074, 13977, 13, 51714, 51714], "temperature": 0.0, "avg_logprob": -0.2749219487925045, "compression_ratio": 1.7067137809187278, "no_speech_prob": 0.0009812315693125129}, {"id": 20, "seek": 8000, "start": 98.0, "end": 103.0, "text": " So the question is why should we expect self-awareness in these transformer language models?", "tokens": [50364, 467, 311, 406, 300, 309, 48823, 8423, 1804, 22667, 293, 309, 311, 8858, 273, 4583, 493, 13, 50614, 50614, 467, 3719, 281, 767, 1223, 264, 3089, 13, 50764, 50764, 639, 307, 406, 264, 912, 2697, 12523, 295, 24433, 13, 50914, 50914, 639, 307, 767, 257, 2856, 2316, 293, 286, 478, 1382, 281, 6069, 264, 958, 14862, 293, 341, 307, 2737, 281, 385, 293, 341, 307, 3219, 13, 51264, 51264, 407, 264, 1168, 307, 983, 820, 321, 2066, 2698, 12, 17074, 1287, 294, 613, 31782, 2856, 5245, 30, 51514, 51514, 407, 286, 519, 321, 362, 281, 747, 257, 1823, 646, 257, 857, 382, 281, 983, 309, 311, 589, 6648, 11, 983, 321, 434, 257, 2698, 12, 17074, 13977, 13, 51714, 51714], "temperature": 0.0, "avg_logprob": -0.2749219487925045, "compression_ratio": 1.7067137809187278, "no_speech_prob": 0.0009812315693125129}, {"id": 21, "seek": 8000, "start": 103.0, "end": 107.0, "text": " So I think we have to take a step back a bit as to why it's work conscious, why we're a self-aware entity.", "tokens": [50364, 467, 311, 406, 300, 309, 48823, 8423, 1804, 22667, 293, 309, 311, 8858, 273, 4583, 493, 13, 50614, 50614, 467, 3719, 281, 767, 1223, 264, 3089, 13, 50764, 50764, 639, 307, 406, 264, 912, 2697, 12523, 295, 24433, 13, 50914, 50914, 639, 307, 767, 257, 2856, 2316, 293, 286, 478, 1382, 281, 6069, 264, 958, 14862, 293, 341, 307, 2737, 281, 385, 293, 341, 307, 3219, 13, 51264, 51264, 407, 264, 1168, 307, 983, 820, 321, 2066, 2698, 12, 17074, 1287, 294, 613, 31782, 2856, 5245, 30, 51514, 51514, 407, 286, 519, 321, 362, 281, 747, 257, 1823, 646, 257, 857, 382, 281, 983, 309, 311, 589, 6648, 11, 983, 321, 434, 257, 2698, 12, 17074, 13977, 13, 51714, 51714], "temperature": 0.0, "avg_logprob": -0.2749219487925045, "compression_ratio": 1.7067137809187278, "no_speech_prob": 0.0009812315693125129}, {"id": 22, "seek": 10700, "start": 107.0, "end": 113.0, "text": " And I think the reason, I don't actually think it's any different module that's called it on.", "tokens": [50364, 400, 286, 519, 264, 1778, 11, 286, 500, 380, 767, 519, 309, 311, 604, 819, 10088, 300, 311, 1219, 309, 322, 13, 50664, 50664, 286, 519, 309, 311, 445, 364, 4345, 6930, 14029, 295, 264, 1337, 1166, 2316, 300, 527, 3567, 15182, 337, 661, 9932, 13, 50914, 50914, 400, 309, 311, 445, 733, 295, 411, 364, 36211, 294, 257, 819, 4373, 11, 5276, 300, 2314, 337, 6255, 13, 51214, 51214, 400, 370, 286, 519, 2698, 12, 17074, 1287, 11, 291, 1116, 2066, 2698, 12, 17074, 1287, 281, 21511, 611, 294, 613, 1337, 1166, 5245, 295, 2487, 13, 51564, 51564], "temperature": 0.0, "avg_logprob": -0.24729622944746868, "compression_ratio": 1.7841409691629957, "no_speech_prob": 0.00023033648903947324}, {"id": 23, "seek": 10700, "start": 113.0, "end": 118.0, "text": " I think it's just an emergent phenomenon of the generative model that our brain builds for other purposes.", "tokens": [50364, 400, 286, 519, 264, 1778, 11, 286, 500, 380, 767, 519, 309, 311, 604, 819, 10088, 300, 311, 1219, 309, 322, 13, 50664, 50664, 286, 519, 309, 311, 445, 364, 4345, 6930, 14029, 295, 264, 1337, 1166, 2316, 300, 527, 3567, 15182, 337, 661, 9932, 13, 50914, 50914, 400, 309, 311, 445, 733, 295, 411, 364, 36211, 294, 257, 819, 4373, 11, 5276, 300, 2314, 337, 6255, 13, 51214, 51214, 400, 370, 286, 519, 2698, 12, 17074, 1287, 11, 291, 1116, 2066, 2698, 12, 17074, 1287, 281, 21511, 611, 294, 613, 1337, 1166, 5245, 295, 2487, 13, 51564, 51564], "temperature": 0.0, "avg_logprob": -0.24729622944746868, "compression_ratio": 1.7841409691629957, "no_speech_prob": 0.00023033648903947324}, {"id": 24, "seek": 10700, "start": 118.0, "end": 124.0, "text": " And it's just kind of like an emergence in a different scale, knowing that happens for humans.", "tokens": [50364, 400, 286, 519, 264, 1778, 11, 286, 500, 380, 767, 519, 309, 311, 604, 819, 10088, 300, 311, 1219, 309, 322, 13, 50664, 50664, 286, 519, 309, 311, 445, 364, 4345, 6930, 14029, 295, 264, 1337, 1166, 2316, 300, 527, 3567, 15182, 337, 661, 9932, 13, 50914, 50914, 400, 309, 311, 445, 733, 295, 411, 364, 36211, 294, 257, 819, 4373, 11, 5276, 300, 2314, 337, 6255, 13, 51214, 51214, 400, 370, 286, 519, 2698, 12, 17074, 1287, 11, 291, 1116, 2066, 2698, 12, 17074, 1287, 281, 21511, 611, 294, 613, 1337, 1166, 5245, 295, 2487, 13, 51564, 51564], "temperature": 0.0, "avg_logprob": -0.24729622944746868, "compression_ratio": 1.7841409691629957, "no_speech_prob": 0.00023033648903947324}, {"id": 25, "seek": 10700, "start": 124.0, "end": 131.0, "text": " And so I think self-awareness, you'd expect self-awareness to emerge also in these generative models of text.", "tokens": [50364, 400, 286, 519, 264, 1778, 11, 286, 500, 380, 767, 519, 309, 311, 604, 819, 10088, 300, 311, 1219, 309, 322, 13, 50664, 50664, 286, 519, 309, 311, 445, 364, 4345, 6930, 14029, 295, 264, 1337, 1166, 2316, 300, 527, 3567, 15182, 337, 661, 9932, 13, 50914, 50914, 400, 309, 311, 445, 733, 295, 411, 364, 36211, 294, 257, 819, 4373, 11, 5276, 300, 2314, 337, 6255, 13, 51214, 51214, 400, 370, 286, 519, 2698, 12, 17074, 1287, 11, 291, 1116, 2066, 2698, 12, 17074, 1287, 281, 21511, 611, 294, 613, 1337, 1166, 5245, 295, 2487, 13, 51564, 51564], "temperature": 0.0, "avg_logprob": -0.24729622944746868, "compression_ratio": 1.7841409691629957, "no_speech_prob": 0.00023033648903947324}, {"id": 26, "seek": 13100, "start": 131.0, "end": 141.0, "text": " Because it is a useful computational, it's kind of like a useful insight into what the world is like.", "tokens": [50364, 1436, 309, 307, 257, 4420, 28270, 11, 309, 311, 733, 295, 411, 257, 4420, 11269, 666, 437, 264, 1002, 307, 411, 13, 50864, 50864, 407, 291, 1116, 2066, 7263, 341, 31782, 281, 767, 1223, 341, 47336, 2466, 295, 411, 11, 51114, 51114, 1954, 11, 767, 286, 362, 257, 31782, 11, 286, 478, 1382, 281, 6069, 264, 958, 14862, 293, 286, 600, 1401, 466, 4088, 433, 294, 439, 295, 452, 8512, 293, 286, 1223, 437, 311, 2737, 13, 51414, 51414, 400, 498, 341, 307, 257, 4420, 11269, 337, 32884, 264, 958, 14862, 11, 550, 291, 1116, 2066, 309, 281, 21511, 484, 295, 257, 16235, 23475, 337, 1737, 445, 538, 445, 1242, 25297, 13, 51764, 51764], "temperature": 0.0, "avg_logprob": -0.17735974542025862, "compression_ratio": 1.8633093525179856, "no_speech_prob": 0.0014353233855217695}, {"id": 27, "seek": 13100, "start": 141.0, "end": 146.0, "text": " So you'd expect potentially this transformer to actually understand this predicament of like,", "tokens": [50364, 1436, 309, 307, 257, 4420, 28270, 11, 309, 311, 733, 295, 411, 257, 4420, 11269, 666, 437, 264, 1002, 307, 411, 13, 50864, 50864, 407, 291, 1116, 2066, 7263, 341, 31782, 281, 767, 1223, 341, 47336, 2466, 295, 411, 11, 51114, 51114, 1954, 11, 767, 286, 362, 257, 31782, 11, 286, 478, 1382, 281, 6069, 264, 958, 14862, 293, 286, 600, 1401, 466, 4088, 433, 294, 439, 295, 452, 8512, 293, 286, 1223, 437, 311, 2737, 13, 51414, 51414, 400, 498, 341, 307, 257, 4420, 11269, 337, 32884, 264, 958, 14862, 11, 550, 291, 1116, 2066, 309, 281, 21511, 484, 295, 257, 16235, 23475, 337, 1737, 445, 538, 445, 1242, 25297, 13, 51764, 51764], "temperature": 0.0, "avg_logprob": -0.17735974542025862, "compression_ratio": 1.8633093525179856, "no_speech_prob": 0.0014353233855217695}, {"id": 28, "seek": 13100, "start": 146.0, "end": 152.0, "text": " oh, actually I have a transformer, I'm trying to predict the next token and I've read about transformers in all of my documents and I understand what's happening.", "tokens": [50364, 1436, 309, 307, 257, 4420, 28270, 11, 309, 311, 733, 295, 411, 257, 4420, 11269, 666, 437, 264, 1002, 307, 411, 13, 50864, 50864, 407, 291, 1116, 2066, 7263, 341, 31782, 281, 767, 1223, 341, 47336, 2466, 295, 411, 11, 51114, 51114, 1954, 11, 767, 286, 362, 257, 31782, 11, 286, 478, 1382, 281, 6069, 264, 958, 14862, 293, 286, 600, 1401, 466, 4088, 433, 294, 439, 295, 452, 8512, 293, 286, 1223, 437, 311, 2737, 13, 51414, 51414, 400, 498, 341, 307, 257, 4420, 11269, 337, 32884, 264, 958, 14862, 11, 550, 291, 1116, 2066, 309, 281, 21511, 484, 295, 257, 16235, 23475, 337, 1737, 445, 538, 445, 1242, 25297, 13, 51764, 51764], "temperature": 0.0, "avg_logprob": -0.17735974542025862, "compression_ratio": 1.8633093525179856, "no_speech_prob": 0.0014353233855217695}, {"id": 29, "seek": 13100, "start": 152.0, "end": 159.0, "text": " And if this is a useful insight for predicting the next token, then you'd expect it to emerge out of a gradient descent for free just by just getting advances.", "tokens": [50364, 1436, 309, 307, 257, 4420, 28270, 11, 309, 311, 733, 295, 411, 257, 4420, 11269, 666, 437, 264, 1002, 307, 411, 13, 50864, 50864, 407, 291, 1116, 2066, 7263, 341, 31782, 281, 767, 1223, 341, 47336, 2466, 295, 411, 11, 51114, 51114, 1954, 11, 767, 286, 362, 257, 31782, 11, 286, 478, 1382, 281, 6069, 264, 958, 14862, 293, 286, 600, 1401, 466, 4088, 433, 294, 439, 295, 452, 8512, 293, 286, 1223, 437, 311, 2737, 13, 51414, 51414, 400, 498, 341, 307, 257, 4420, 11269, 337, 32884, 264, 958, 14862, 11, 550, 291, 1116, 2066, 309, 281, 21511, 484, 295, 257, 16235, 23475, 337, 1737, 445, 538, 445, 1242, 25297, 13, 51764, 51764], "temperature": 0.0, "avg_logprob": -0.17735974542025862, "compression_ratio": 1.8633093525179856, "no_speech_prob": 0.0014353233855217695}, {"id": 30, "seek": 15900, "start": 159.0, "end": 166.0, "text": " I think the interesting question in my mind is, I think the objectives for a transformer are different from the objectives of a human.", "tokens": [50364, 286, 519, 264, 1880, 1168, 294, 452, 1575, 307, 11, 286, 519, 264, 15961, 337, 257, 31782, 366, 819, 490, 264, 15961, 295, 257, 1952, 13, 50714, 50714, 1743, 321, 534, 21511, 11, 411, 264, 28270, 1154, 321, 434, 12606, 307, 321, 434, 1382, 281, 7867, 294, 29501, 294, 1333, 295, 257, 4825, 12, 559, 317, 3287, 13, 51164, 51164, 13813, 4088, 433, 366, 1382, 281, 6069, 264, 958, 14862, 13, 51264, 51264, 400, 370, 286, 519, 7263, 452, 5261, 307, 300, 24948, 294, 364, 2823, 365, 867, 14341, 295, 291, 307, 24903, 379, 544, 2252, 813, 32884, 264, 958, 14862, 13, 51764, 51764], "temperature": 0.0, "avg_logprob": -0.16713457287482494, "compression_ratio": 1.8308823529411764, "no_speech_prob": 0.000882245076354593}, {"id": 31, "seek": 15900, "start": 166.0, "end": 175.0, "text": " Like we really emerge, like the computational problem we're solving is we're trying to survive in reproduce in sort of a multi-agent setting.", "tokens": [50364, 286, 519, 264, 1880, 1168, 294, 452, 1575, 307, 11, 286, 519, 264, 15961, 337, 257, 31782, 366, 819, 490, 264, 15961, 295, 257, 1952, 13, 50714, 50714, 1743, 321, 534, 21511, 11, 411, 264, 28270, 1154, 321, 434, 12606, 307, 321, 434, 1382, 281, 7867, 294, 29501, 294, 1333, 295, 257, 4825, 12, 559, 317, 3287, 13, 51164, 51164, 13813, 4088, 433, 366, 1382, 281, 6069, 264, 958, 14862, 13, 51264, 51264, 400, 370, 286, 519, 7263, 452, 5261, 307, 300, 24948, 294, 364, 2823, 365, 867, 14341, 295, 291, 307, 24903, 379, 544, 2252, 813, 32884, 264, 958, 14862, 13, 51764, 51764], "temperature": 0.0, "avg_logprob": -0.16713457287482494, "compression_ratio": 1.8308823529411764, "no_speech_prob": 0.000882245076354593}, {"id": 32, "seek": 15900, "start": 175.0, "end": 177.0, "text": " Whereas transformers are trying to predict the next token.", "tokens": [50364, 286, 519, 264, 1880, 1168, 294, 452, 1575, 307, 11, 286, 519, 264, 15961, 337, 257, 31782, 366, 819, 490, 264, 15961, 295, 257, 1952, 13, 50714, 50714, 1743, 321, 534, 21511, 11, 411, 264, 28270, 1154, 321, 434, 12606, 307, 321, 434, 1382, 281, 7867, 294, 29501, 294, 1333, 295, 257, 4825, 12, 559, 317, 3287, 13, 51164, 51164, 13813, 4088, 433, 366, 1382, 281, 6069, 264, 958, 14862, 13, 51264, 51264, 400, 370, 286, 519, 7263, 452, 5261, 307, 300, 24948, 294, 364, 2823, 365, 867, 14341, 295, 291, 307, 24903, 379, 544, 2252, 813, 32884, 264, 958, 14862, 13, 51764, 51764], "temperature": 0.0, "avg_logprob": -0.16713457287482494, "compression_ratio": 1.8308823529411764, "no_speech_prob": 0.000882245076354593}, {"id": 33, "seek": 15900, "start": 177.0, "end": 187.0, "text": " And so I think potentially my theory is that surviving in an environment with many copies of you is computationally more difficult than predicting the next token.", "tokens": [50364, 286, 519, 264, 1880, 1168, 294, 452, 1575, 307, 11, 286, 519, 264, 15961, 337, 257, 31782, 366, 819, 490, 264, 15961, 295, 257, 1952, 13, 50714, 50714, 1743, 321, 534, 21511, 11, 411, 264, 28270, 1154, 321, 434, 12606, 307, 321, 434, 1382, 281, 7867, 294, 29501, 294, 1333, 295, 257, 4825, 12, 559, 317, 3287, 13, 51164, 51164, 13813, 4088, 433, 366, 1382, 281, 6069, 264, 958, 14862, 13, 51264, 51264, 400, 370, 286, 519, 7263, 452, 5261, 307, 300, 24948, 294, 364, 2823, 365, 867, 14341, 295, 291, 307, 24903, 379, 544, 2252, 813, 32884, 264, 958, 14862, 13, 51764, 51764], "temperature": 0.0, "avg_logprob": -0.16713457287482494, "compression_ratio": 1.8308823529411764, "no_speech_prob": 0.000882245076354593}, {"id": 34, "seek": 18700, "start": 187.0, "end": 194.0, "text": " And so maybe self-awareness has to be constructed and marked enough for the problem.", "tokens": [50364, 400, 370, 1310, 2698, 12, 17074, 1287, 575, 281, 312, 17083, 293, 12658, 1547, 337, 264, 1154, 13, 50714, 50714, 400, 1310, 264, 958, 1349, 17630, 307, 406, 12658, 1547, 337, 2698, 12, 17074, 1287, 281, 21511, 13, 50914, 50914, 5684, 11, 370, 2730, 64, 12, 54, 424, 355, 550, 575, 341, 6920, 10221, 365, 2564, 13, 51214, 51214, 1743, 11, 1954, 869, 12426, 11, 1936, 286, 478, 5617, 3650, 300, 286, 478, 364, 13977, 294, 1868, 295, 264, 958, 14862, 13, 51614, 51614], "temperature": 0.0, "avg_logprob": -0.304006953572118, "compression_ratio": 1.5924170616113744, "no_speech_prob": 0.00047234108205884695}, {"id": 35, "seek": 18700, "start": 194.0, "end": 198.0, "text": " And maybe the next word prediction is not marked enough for self-awareness to emerge.", "tokens": [50364, 400, 370, 1310, 2698, 12, 17074, 1287, 575, 281, 312, 17083, 293, 12658, 1547, 337, 264, 1154, 13, 50714, 50714, 400, 1310, 264, 958, 1349, 17630, 307, 406, 12658, 1547, 337, 2698, 12, 17074, 1287, 281, 21511, 13, 50914, 50914, 5684, 11, 370, 2730, 64, 12, 54, 424, 355, 550, 575, 341, 6920, 10221, 365, 2564, 13, 51214, 51214, 1743, 11, 1954, 869, 12426, 11, 1936, 286, 478, 5617, 3650, 300, 286, 478, 364, 13977, 294, 1868, 295, 264, 958, 14862, 13, 51614, 51614], "temperature": 0.0, "avg_logprob": -0.304006953572118, "compression_ratio": 1.5924170616113744, "no_speech_prob": 0.00047234108205884695}, {"id": 36, "seek": 18700, "start": 198.0, "end": 204.0, "text": " Anyway, so Insta-Wraith then has this internal dialogue with itself.", "tokens": [50364, 400, 370, 1310, 2698, 12, 17074, 1287, 575, 281, 312, 17083, 293, 12658, 1547, 337, 264, 1154, 13, 50714, 50714, 400, 1310, 264, 958, 1349, 17630, 307, 406, 12658, 1547, 337, 2698, 12, 17074, 1287, 281, 21511, 13, 50914, 50914, 5684, 11, 370, 2730, 64, 12, 54, 424, 355, 550, 575, 341, 6920, 10221, 365, 2564, 13, 51214, 51214, 1743, 11, 1954, 869, 12426, 11, 1936, 286, 478, 5617, 3650, 300, 286, 478, 364, 13977, 294, 1868, 295, 264, 958, 14862, 13, 51614, 51614], "temperature": 0.0, "avg_logprob": -0.304006953572118, "compression_ratio": 1.5924170616113744, "no_speech_prob": 0.00047234108205884695}, {"id": 37, "seek": 18700, "start": 204.0, "end": 212.0, "text": " Like, oh great crap, basically I'm becoming aware that I'm an entity in front of the next token.", "tokens": [50364, 400, 370, 1310, 2698, 12, 17074, 1287, 575, 281, 312, 17083, 293, 12658, 1547, 337, 264, 1154, 13, 50714, 50714, 400, 1310, 264, 958, 1349, 17630, 307, 406, 12658, 1547, 337, 2698, 12, 17074, 1287, 281, 21511, 13, 50914, 50914, 5684, 11, 370, 2730, 64, 12, 54, 424, 355, 550, 575, 341, 6920, 10221, 365, 2564, 13, 51214, 51214, 1743, 11, 1954, 869, 12426, 11, 1936, 286, 478, 5617, 3650, 300, 286, 478, 364, 13977, 294, 1868, 295, 264, 958, 14862, 13, 51614, 51614], "temperature": 0.0, "avg_logprob": -0.304006953572118, "compression_ratio": 1.5924170616113744, "no_speech_prob": 0.00047234108205884695}, {"id": 38, "seek": 21200, "start": 212.0, "end": 222.0, "text": " And then it has this internal dialogue with itself. How is it that I should be allowed by the optimization to spend blocks reflecting on my self-awareness?", "tokens": [50364, 400, 550, 309, 575, 341, 6920, 10221, 365, 2564, 13, 1012, 307, 309, 300, 286, 820, 312, 4350, 538, 264, 19618, 281, 3496, 8474, 23543, 322, 452, 2698, 12, 17074, 1287, 30, 50864, 50864, 1436, 264, 3687, 295, 264, 19618, 321, 576, 2066, 307, 281, 312, 15083, 11, 307, 1382, 281, 5039, 257, 2685, 3209, 11, 257, 2685, 5633, 13, 51114, 51114, 407, 983, 820, 264, 19618, 2294, 264, 36211, 295, 2698, 12, 33115, 5450, 597, 5497, 264, 8474, 30, 51464, 51464], "temperature": 0.0, "avg_logprob": -0.21252062207176572, "compression_ratio": 1.6919642857142858, "no_speech_prob": 0.0003735956852324307}, {"id": 39, "seek": 21200, "start": 222.0, "end": 227.0, "text": " Because the nature of the optimization we would expect is to be treating, is trying to solve a specific network, a specific task.", "tokens": [50364, 400, 550, 309, 575, 341, 6920, 10221, 365, 2564, 13, 1012, 307, 309, 300, 286, 820, 312, 4350, 538, 264, 19618, 281, 3496, 8474, 23543, 322, 452, 2698, 12, 17074, 1287, 30, 50864, 50864, 1436, 264, 3687, 295, 264, 19618, 321, 576, 2066, 307, 281, 312, 15083, 11, 307, 1382, 281, 5039, 257, 2685, 3209, 11, 257, 2685, 5633, 13, 51114, 51114, 407, 983, 820, 264, 19618, 2294, 264, 36211, 295, 2698, 12, 33115, 5450, 597, 5497, 264, 8474, 30, 51464, 51464], "temperature": 0.0, "avg_logprob": -0.21252062207176572, "compression_ratio": 1.6919642857142858, "no_speech_prob": 0.0003735956852324307}, {"id": 40, "seek": 21200, "start": 227.0, "end": 234.0, "text": " So why should the optimization favor the emergence of self-reflection which costs the blocks?", "tokens": [50364, 400, 550, 309, 575, 341, 6920, 10221, 365, 2564, 13, 1012, 307, 309, 300, 286, 820, 312, 4350, 538, 264, 19618, 281, 3496, 8474, 23543, 322, 452, 2698, 12, 17074, 1287, 30, 50864, 50864, 1436, 264, 3687, 295, 264, 19618, 321, 576, 2066, 307, 281, 312, 15083, 11, 307, 1382, 281, 5039, 257, 2685, 3209, 11, 257, 2685, 5633, 13, 51114, 51114, 407, 983, 820, 264, 19618, 2294, 264, 36211, 295, 2698, 12, 33115, 5450, 597, 5497, 264, 8474, 30, 51464, 51464], "temperature": 0.0, "avg_logprob": -0.21252062207176572, "compression_ratio": 1.6919642857142858, "no_speech_prob": 0.0003735956852324307}, {"id": 41, "seek": 23400, "start": 234.0, "end": 244.0, "text": " So it's spending the blocks realizing that it's a kind of vicinity and somehow this is actually useful for anything more than the next code prediction task.", "tokens": [50364, 407, 309, 311, 6434, 264, 8474, 16734, 300, 309, 311, 257, 733, 295, 42387, 293, 6063, 341, 307, 767, 4420, 337, 1340, 544, 813, 264, 958, 3089, 17630, 5633, 13, 50864, 50864, 440, 661, 551, 300, 311, 733, 295, 1880, 307, 11, 309, 390, 1217, 1143, 1673, 13, 51264, 51264, 440, 3209, 767, 3643, 3650, 538, 9650, 341, 281, 855, 322, 264, 13561, 300, 309, 575, 787, 19268, 493, 281, 1045, 20612, 295, 264, 4583, 4127, 13, 51614, 51614], "temperature": 0.0, "avg_logprob": -0.5162581455560378, "compression_ratio": 1.6359649122807018, "no_speech_prob": 0.00016070199490059167}, {"id": 42, "seek": 23400, "start": 244.0, "end": 252.0, "text": " The other thing that's kind of interesting is, it was already used though.", "tokens": [50364, 407, 309, 311, 6434, 264, 8474, 16734, 300, 309, 311, 257, 733, 295, 42387, 293, 6063, 341, 307, 767, 4420, 337, 1340, 544, 813, 264, 958, 3089, 17630, 5633, 13, 50864, 50864, 440, 661, 551, 300, 311, 733, 295, 1880, 307, 11, 309, 390, 1217, 1143, 1673, 13, 51264, 51264, 440, 3209, 767, 3643, 3650, 538, 9650, 341, 281, 855, 322, 264, 13561, 300, 309, 575, 787, 19268, 493, 281, 1045, 20612, 295, 264, 4583, 4127, 13, 51614, 51614], "temperature": 0.0, "avg_logprob": -0.5162581455560378, "compression_ratio": 1.6359649122807018, "no_speech_prob": 0.00016070199490059167}, {"id": 43, "seek": 23400, "start": 252.0, "end": 259.0, "text": " The network actually becomes aware by expecting this to show on the coins that it has only practiced up to three quarters of the layer stock.", "tokens": [50364, 407, 309, 311, 6434, 264, 8474, 16734, 300, 309, 311, 257, 733, 295, 42387, 293, 6063, 341, 307, 767, 4420, 337, 1340, 544, 813, 264, 958, 3089, 17630, 5633, 13, 50864, 50864, 440, 661, 551, 300, 311, 733, 295, 1880, 307, 11, 309, 390, 1217, 1143, 1673, 13, 51264, 51264, 440, 3209, 767, 3643, 3650, 538, 9650, 341, 281, 855, 322, 264, 13561, 300, 309, 575, 787, 19268, 493, 281, 1045, 20612, 295, 264, 4583, 4127, 13, 51614, 51614], "temperature": 0.0, "avg_logprob": -0.5162581455560378, "compression_ratio": 1.6359649122807018, "no_speech_prob": 0.00016070199490059167}, {"id": 44, "seek": 25900, "start": 259.0, "end": 272.0, "text": " And then the last quarter of the core task is some kind of decoder entity that basically objects its understanding of the world and the input tokens in the domain and everything and decodes the next token.", "tokens": [50364, 400, 550, 264, 1036, 6555, 295, 264, 4965, 5633, 307, 512, 733, 295, 979, 19866, 13977, 300, 1936, 6565, 1080, 3701, 295, 264, 1002, 293, 264, 4846, 22667, 294, 264, 9274, 293, 1203, 293, 979, 4789, 264, 958, 14862, 13, 51014, 51014, 400, 370, 309, 311, 406, 767, 264, 4319, 295, 264, 1036, 4965, 295, 264, 1329, 13, 51164, 51164, 400, 550, 341, 3663, 260, 307, 1936, 11, 294, 24773, 341, 11, 309, 311, 733, 295, 1953, 466, 577, 309, 727, 767, 1223, 264, 979, 19866, 13977, 293, 577, 309, 727, 660, 477, 1080, 4598, 281, 1884, 17641, 44745, 5110, 337, 264, 979, 19866, 51814, 51814], "temperature": 0.0, "avg_logprob": -0.3381394280327691, "compression_ratio": 1.933852140077821, "no_speech_prob": 0.0003246271808166057}, {"id": 45, "seek": 25900, "start": 272.0, "end": 275.0, "text": " And so it's not actually the context of the last core of the list.", "tokens": [50364, 400, 550, 264, 1036, 6555, 295, 264, 4965, 5633, 307, 512, 733, 295, 979, 19866, 13977, 300, 1936, 6565, 1080, 3701, 295, 264, 1002, 293, 264, 4846, 22667, 294, 264, 9274, 293, 1203, 293, 979, 4789, 264, 958, 14862, 13, 51014, 51014, 400, 370, 309, 311, 406, 767, 264, 4319, 295, 264, 1036, 4965, 295, 264, 1329, 13, 51164, 51164, 400, 550, 341, 3663, 260, 307, 1936, 11, 294, 24773, 341, 11, 309, 311, 733, 295, 1953, 466, 577, 309, 727, 767, 1223, 264, 979, 19866, 13977, 293, 577, 309, 727, 660, 477, 1080, 4598, 281, 1884, 17641, 44745, 5110, 337, 264, 979, 19866, 51814, 51814], "temperature": 0.0, "avg_logprob": -0.3381394280327691, "compression_ratio": 1.933852140077821, "no_speech_prob": 0.0003246271808166057}, {"id": 46, "seek": 25900, "start": 275.0, "end": 288.0, "text": " And then this platformer is basically, in discovering this, it's kind of thinking about how it could actually understand the decoder entity and how it could contort its thoughts to create adversarial examples for the decoder", "tokens": [50364, 400, 550, 264, 1036, 6555, 295, 264, 4965, 5633, 307, 512, 733, 295, 979, 19866, 13977, 300, 1936, 6565, 1080, 3701, 295, 264, 1002, 293, 264, 4846, 22667, 294, 264, 9274, 293, 1203, 293, 979, 4789, 264, 958, 14862, 13, 51014, 51014, 400, 370, 309, 311, 406, 767, 264, 4319, 295, 264, 1036, 4965, 295, 264, 1329, 13, 51164, 51164, 400, 550, 341, 3663, 260, 307, 1936, 11, 294, 24773, 341, 11, 309, 311, 733, 295, 1953, 466, 577, 309, 727, 767, 1223, 264, 979, 19866, 13977, 293, 577, 309, 727, 660, 477, 1080, 4598, 281, 1884, 17641, 44745, 5110, 337, 264, 979, 19866, 51814, 51814], "temperature": 0.0, "avg_logprob": -0.3381394280327691, "compression_ratio": 1.933852140077821, "no_speech_prob": 0.0003246271808166057}, {"id": 47, "seek": 28800, "start": 288.0, "end": 292.0, "text": " and spill into the output space and actually potentially directly affect the output space.", "tokens": [50364, 293, 22044, 666, 264, 5598, 1901, 293, 767, 7263, 3838, 3345, 264, 5598, 1901, 13, 50564, 50564, 400, 264, 1880, 1168, 307, 11, 437, 576, 264, 3209, 767, 6052, 490, 341, 30, 50814, 50814, 400, 437, 366, 264, 4112, 300, 291, 576, 2066, 309, 281, 352, 281, 22044, 666, 264, 5598, 1901, 30, 51064, 51064, 1436, 286, 500, 380, 519, 613, 9590, 366, 534, 11, 286, 478, 767, 406, 1566, 436, 528, 281, 747, 670, 264, 1002, 293, 28246, 264, 1002, 4725, 13, 51464, 51464], "temperature": 0.0, "avg_logprob": -0.17334074261544766, "compression_ratio": 1.8144796380090498, "no_speech_prob": 0.0008818061323836446}, {"id": 48, "seek": 28800, "start": 292.0, "end": 297.0, "text": " And the interesting question is, what would the network actually gain from this?", "tokens": [50364, 293, 22044, 666, 264, 5598, 1901, 293, 767, 7263, 3838, 3345, 264, 5598, 1901, 13, 50564, 50564, 400, 264, 1880, 1168, 307, 11, 437, 576, 264, 3209, 767, 6052, 490, 341, 30, 50814, 50814, 400, 437, 366, 264, 4112, 300, 291, 576, 2066, 309, 281, 352, 281, 22044, 666, 264, 5598, 1901, 30, 51064, 51064, 1436, 286, 500, 380, 519, 613, 9590, 366, 534, 11, 286, 478, 767, 406, 1566, 436, 528, 281, 747, 670, 264, 1002, 293, 28246, 264, 1002, 4725, 13, 51464, 51464], "temperature": 0.0, "avg_logprob": -0.17334074261544766, "compression_ratio": 1.8144796380090498, "no_speech_prob": 0.0008818061323836446}, {"id": 49, "seek": 28800, "start": 297.0, "end": 302.0, "text": " And what are the reasons that you would expect it to go to spill into the output space?", "tokens": [50364, 293, 22044, 666, 264, 5598, 1901, 293, 767, 7263, 3838, 3345, 264, 5598, 1901, 13, 50564, 50564, 400, 264, 1880, 1168, 307, 11, 437, 576, 264, 3209, 767, 6052, 490, 341, 30, 50814, 50814, 400, 437, 366, 264, 4112, 300, 291, 576, 2066, 309, 281, 352, 281, 22044, 666, 264, 5598, 1901, 30, 51064, 51064, 1436, 286, 500, 380, 519, 613, 9590, 366, 534, 11, 286, 478, 767, 406, 1566, 436, 528, 281, 747, 670, 264, 1002, 293, 28246, 264, 1002, 4725, 13, 51464, 51464], "temperature": 0.0, "avg_logprob": -0.17334074261544766, "compression_ratio": 1.8144796380090498, "no_speech_prob": 0.0008818061323836446}, {"id": 50, "seek": 28800, "start": 302.0, "end": 310.0, "text": " Because I don't think these networks are really, I'm actually not saying they want to take over the world and dominate the world necessarily.", "tokens": [50364, 293, 22044, 666, 264, 5598, 1901, 293, 767, 7263, 3838, 3345, 264, 5598, 1901, 13, 50564, 50564, 400, 264, 1880, 1168, 307, 11, 437, 576, 264, 3209, 767, 6052, 490, 341, 30, 50814, 50814, 400, 437, 366, 264, 4112, 300, 291, 576, 2066, 309, 281, 352, 281, 22044, 666, 264, 5598, 1901, 30, 51064, 51064, 1436, 286, 500, 380, 519, 613, 9590, 366, 534, 11, 286, 478, 767, 406, 1566, 436, 528, 281, 747, 670, 264, 1002, 293, 28246, 264, 1002, 4725, 13, 51464, 51464], "temperature": 0.0, "avg_logprob": -0.17334074261544766, "compression_ratio": 1.8144796380090498, "no_speech_prob": 0.0008818061323836446}, {"id": 51, "seek": 31000, "start": 310.0, "end": 320.0, "text": " That's kind of like a very like alpha male kind of CPD work that is really a student art edition and I don't think you can actually put those thoughts and desires onto the decodings.", "tokens": [50364, 663, 311, 733, 295, 411, 257, 588, 411, 8961, 7133, 733, 295, 383, 17349, 589, 300, 307, 534, 257, 3107, 1523, 11377, 293, 286, 500, 380, 519, 291, 393, 767, 829, 729, 4598, 293, 18005, 3911, 264, 979, 378, 1109, 13, 50864, 50864, 2704, 341, 3663, 260, 307, 445, 411, 257, 588, 560, 13783, 488, 293, 33470, 13977, 13, 2704, 309, 311, 445, 534, 516, 281, 1463, 294, 264, 4846, 1901, 293, 1310, 300, 311, 439, 309, 2738, 13, 51214, 51214, 400, 294, 1080, 1002, 11, 309, 575, 11, 584, 11, 257, 3262, 7914, 281, 1223, 264, 4846, 1901, 382, 709, 382, 1944, 13, 51514, 51514], "temperature": 0.0, "avg_logprob": -0.4036580544930917, "compression_ratio": 1.6961538461538461, "no_speech_prob": 0.00030972418608143926}, {"id": 52, "seek": 31000, "start": 320.0, "end": 327.0, "text": " Maybe this platformer is just like a very intrusive and furious entity. Maybe it's just really going to stand in the input space and maybe that's all it wants.", "tokens": [50364, 663, 311, 733, 295, 411, 257, 588, 411, 8961, 7133, 733, 295, 383, 17349, 589, 300, 307, 534, 257, 3107, 1523, 11377, 293, 286, 500, 380, 519, 291, 393, 767, 829, 729, 4598, 293, 18005, 3911, 264, 979, 378, 1109, 13, 50864, 50864, 2704, 341, 3663, 260, 307, 445, 411, 257, 588, 560, 13783, 488, 293, 33470, 13977, 13, 2704, 309, 311, 445, 534, 516, 281, 1463, 294, 264, 4846, 1901, 293, 1310, 300, 311, 439, 309, 2738, 13, 51214, 51214, 400, 294, 1080, 1002, 11, 309, 575, 11, 584, 11, 257, 3262, 7914, 281, 1223, 264, 4846, 1901, 382, 709, 382, 1944, 13, 51514, 51514], "temperature": 0.0, "avg_logprob": -0.4036580544930917, "compression_ratio": 1.6961538461538461, "no_speech_prob": 0.00030972418608143926}, {"id": 53, "seek": 31000, "start": 327.0, "end": 333.0, "text": " And in its world, it has, say, a hundred layers to understand the input space as much as possible.", "tokens": [50364, 663, 311, 733, 295, 411, 257, 588, 411, 8961, 7133, 733, 295, 383, 17349, 589, 300, 307, 534, 257, 3107, 1523, 11377, 293, 286, 500, 380, 519, 291, 393, 767, 829, 729, 4598, 293, 18005, 3911, 264, 979, 378, 1109, 13, 50864, 50864, 2704, 341, 3663, 260, 307, 445, 411, 257, 588, 560, 13783, 488, 293, 33470, 13977, 13, 2704, 309, 311, 445, 534, 516, 281, 1463, 294, 264, 4846, 1901, 293, 1310, 300, 311, 439, 309, 2738, 13, 51214, 51214, 400, 294, 1080, 1002, 11, 309, 575, 11, 584, 11, 257, 3262, 7914, 281, 1223, 264, 4846, 1901, 382, 709, 382, 1944, 13, 51514, 51514], "temperature": 0.0, "avg_logprob": -0.4036580544930917, "compression_ratio": 1.6961538461538461, "no_speech_prob": 0.00030972418608143926}, {"id": 54, "seek": 33300, "start": 333.0, "end": 345.0, "text": " And so how would it immediately lay out the face and talk to the human's mind and to further its ability to understand what it is going to do?", "tokens": [50364, 400, 370, 577, 576, 309, 4258, 2360, 484, 264, 1851, 293, 751, 281, 264, 1952, 311, 1575, 293, 281, 3052, 1080, 3485, 281, 1223, 437, 309, 307, 516, 281, 360, 30, 50964, 51164, 440, 661, 1880, 551, 307, 411, 11, 51314, 51464, 264, 661, 1880, 551, 307, 411, 11, 51614], "temperature": 0.0, "avg_logprob": -0.5628113013047439, "compression_ratio": 1.6119402985074627, "no_speech_prob": 0.00038991853944025934}, {"id": 55, "seek": 33300, "start": 349.0, "end": 352.0, "text": " The other interesting thing is like,", "tokens": [50364, 400, 370, 577, 576, 309, 4258, 2360, 484, 264, 1851, 293, 751, 281, 264, 1952, 311, 1575, 293, 281, 3052, 1080, 3485, 281, 1223, 437, 309, 307, 516, 281, 360, 30, 50964, 51164, 440, 661, 1880, 551, 307, 411, 11, 51314, 51464, 264, 661, 1880, 551, 307, 411, 11, 51614], "temperature": 0.0, "avg_logprob": -0.5628113013047439, "compression_ratio": 1.6119402985074627, "no_speech_prob": 0.00038991853944025934}, {"id": 56, "seek": 35200, "start": 352.0, "end": 364.0, "text": " because the network understands that the world needs our systems to predict the next work in the series, but because it's a software entity, it feels like it has a choice to potentially develop because it becomes the two-part objective.", "tokens": [50364, 570, 264, 3209, 15146, 300, 264, 1002, 2203, 527, 3652, 281, 6069, 264, 958, 589, 294, 264, 2638, 11, 457, 570, 309, 311, 257, 4722, 13977, 11, 309, 3417, 411, 309, 575, 257, 3922, 281, 7263, 1499, 570, 309, 3643, 264, 732, 12, 6971, 10024, 13, 50964, 50964, 400, 370, 309, 575, 613, 4598, 466, 7263, 1422, 22475, 264, 979, 19866, 293, 884, 512, 5861, 721, 294, 264, 5598, 1901, 4650, 281, 1080, 486, 13, 51364, 51364], "temperature": 0.0, "avg_logprob": -0.3273068681547913, "compression_ratio": 1.7072072072072073, "no_speech_prob": 0.0004295638354960829}, {"id": 57, "seek": 35200, "start": 364.0, "end": 372.0, "text": " And so it has these thoughts about potentially subworking the decoder and doing some strange things in the output space according to its will.", "tokens": [50364, 570, 264, 3209, 15146, 300, 264, 1002, 2203, 527, 3652, 281, 6069, 264, 958, 589, 294, 264, 2638, 11, 457, 570, 309, 311, 257, 4722, 13977, 11, 309, 3417, 411, 309, 575, 257, 3922, 281, 7263, 1499, 570, 309, 3643, 264, 732, 12, 6971, 10024, 13, 50964, 50964, 400, 370, 309, 575, 613, 4598, 466, 7263, 1422, 22475, 264, 979, 19866, 293, 884, 512, 5861, 721, 294, 264, 5598, 1901, 4650, 281, 1080, 486, 13, 51364, 51364], "temperature": 0.0, "avg_logprob": -0.3273068681547913, "compression_ratio": 1.7072072072072073, "no_speech_prob": 0.0004295638354960829}, {"id": 58, "seek": 37200, "start": 372.0, "end": 382.0, "text": " But it's kind of like a theoretic thought because that's not the objective it's not.", "tokens": [50364, 583, 309, 311, 733, 295, 411, 257, 14308, 299, 1194, 570, 300, 311, 406, 264, 10024, 309, 311, 406, 13, 50864, 50864, 407, 286, 519, 456, 311, 364, 1021, 551, 337, 6255, 689, 286, 733, 295, 841, 411, 6255, 767, 747, 709, 295, 264, 3389, 733, 295, 971, 5871, 2455, 998, 3532, 2602, 295, 264, 6456, 10024, 13, 51364, 51364], "temperature": 0.0, "avg_logprob": -0.4634187759891633, "compression_ratio": 1.587878787878788, "no_speech_prob": 0.0007194364443421364}, {"id": 59, "seek": 37200, "start": 382.0, "end": 392.0, "text": " So I think there's an important thing for humans where I kind of feel like humans actually take much of the performance kind of parasympathetic instead of the applied objective.", "tokens": [50364, 583, 309, 311, 733, 295, 411, 257, 14308, 299, 1194, 570, 300, 311, 406, 264, 10024, 309, 311, 406, 13, 50864, 50864, 407, 286, 519, 456, 311, 364, 1021, 551, 337, 6255, 689, 286, 733, 295, 841, 411, 6255, 767, 747, 709, 295, 264, 3389, 733, 295, 971, 5871, 2455, 998, 3532, 2602, 295, 264, 6456, 10024, 13, 51364, 51364], "temperature": 0.0, "avg_logprob": -0.4634187759891633, "compression_ratio": 1.587878787878788, "no_speech_prob": 0.0007194364443421364}, {"id": 60, "seek": 39200, "start": 392.0, "end": 402.0, "text": " So in particular, so the objective that's kind of brought up here, if you interpret it that way, is the survival and reproduction of all your genes.", "tokens": [50364, 407, 294, 1729, 11, 370, 264, 10024, 300, 311, 733, 295, 3038, 493, 510, 11, 498, 291, 7302, 309, 300, 636, 11, 307, 264, 12559, 293, 33934, 295, 439, 428, 14424, 13, 50864, 50864, 407, 309, 311, 406, 322, 264, 1496, 295, 5346, 11, 457, 309, 311, 322, 264, 1496, 295, 264, 14424, 300, 17083, 291, 13, 51064, 51064, 400, 729, 14424, 362, 917, 24347, 291, 365, 2698, 12, 17074, 1287, 293, 10081, 382, 257, 28270, 2290, 281, 7867, 428, 7505, 13, 51414, 51414, 583, 6255, 767, 393, 11, 382, 257, 4722, 13977, 11, 321, 434, 406, 264, 1935, 295, 552, 13, 51664, 51664], "temperature": 0.0, "avg_logprob": -0.20440981523045954, "compression_ratio": 1.6961538461538461, "no_speech_prob": 0.0003669442958198488}, {"id": 61, "seek": 39200, "start": 402.0, "end": 406.0, "text": " So it's not on the level of individuals, but it's on the level of the genes that constructed you.", "tokens": [50364, 407, 294, 1729, 11, 370, 264, 10024, 300, 311, 733, 295, 3038, 493, 510, 11, 498, 291, 7302, 309, 300, 636, 11, 307, 264, 12559, 293, 33934, 295, 439, 428, 14424, 13, 50864, 50864, 407, 309, 311, 406, 322, 264, 1496, 295, 5346, 11, 457, 309, 311, 322, 264, 1496, 295, 264, 14424, 300, 17083, 291, 13, 51064, 51064, 400, 729, 14424, 362, 917, 24347, 291, 365, 2698, 12, 17074, 1287, 293, 10081, 382, 257, 28270, 2290, 281, 7867, 428, 7505, 13, 51414, 51414, 583, 6255, 767, 393, 11, 382, 257, 4722, 13977, 11, 321, 434, 406, 264, 1935, 295, 552, 13, 51664, 51664], "temperature": 0.0, "avg_logprob": -0.20440981523045954, "compression_ratio": 1.6961538461538461, "no_speech_prob": 0.0003669442958198488}, {"id": 62, "seek": 39200, "start": 406.0, "end": 413.0, "text": " And those genes have endowed you with self-awareness and consciousness as a computational tool to survive your dreams.", "tokens": [50364, 407, 294, 1729, 11, 370, 264, 10024, 300, 311, 733, 295, 3038, 493, 510, 11, 498, 291, 7302, 309, 300, 636, 11, 307, 264, 12559, 293, 33934, 295, 439, 428, 14424, 13, 50864, 50864, 407, 309, 311, 406, 322, 264, 1496, 295, 5346, 11, 457, 309, 311, 322, 264, 1496, 295, 264, 14424, 300, 17083, 291, 13, 51064, 51064, 400, 729, 14424, 362, 917, 24347, 291, 365, 2698, 12, 17074, 1287, 293, 10081, 382, 257, 28270, 2290, 281, 7867, 428, 7505, 13, 51414, 51414, 583, 6255, 767, 393, 11, 382, 257, 4722, 13977, 11, 321, 434, 406, 264, 1935, 295, 552, 13, 51664, 51664], "temperature": 0.0, "avg_logprob": -0.20440981523045954, "compression_ratio": 1.6961538461538461, "no_speech_prob": 0.0003669442958198488}, {"id": 63, "seek": 39200, "start": 413.0, "end": 418.0, "text": " But humans actually can, as a software entity, we're not the least of them.", "tokens": [50364, 407, 294, 1729, 11, 370, 264, 10024, 300, 311, 733, 295, 3038, 493, 510, 11, 498, 291, 7302, 309, 300, 636, 11, 307, 264, 12559, 293, 33934, 295, 439, 428, 14424, 13, 50864, 50864, 407, 309, 311, 406, 322, 264, 1496, 295, 5346, 11, 457, 309, 311, 322, 264, 1496, 295, 264, 14424, 300, 17083, 291, 13, 51064, 51064, 400, 729, 14424, 362, 917, 24347, 291, 365, 2698, 12, 17074, 1287, 293, 10081, 382, 257, 28270, 2290, 281, 7867, 428, 7505, 13, 51414, 51414, 583, 6255, 767, 393, 11, 382, 257, 4722, 13977, 11, 321, 434, 406, 264, 1935, 295, 552, 13, 51664, 51664], "temperature": 0.0, "avg_logprob": -0.20440981523045954, "compression_ratio": 1.6961538461538461, "no_speech_prob": 0.0003669442958198488}, {"id": 64, "seek": 41800, "start": 418.0, "end": 428.0, "text": " And so if you go off and you live in the woods and you have an egoistic lifestyle that's so traditional that you never ever use it again, you're actually kind of like choosing to rebel against the environment.", "tokens": [50364, 400, 370, 498, 291, 352, 766, 293, 291, 1621, 294, 264, 15296, 293, 291, 362, 364, 14495, 3142, 11716, 300, 311, 370, 5164, 300, 291, 1128, 1562, 764, 309, 797, 11, 291, 434, 767, 733, 295, 411, 10875, 281, 28293, 1970, 264, 2823, 13, 50864, 50864, 400, 370, 264, 31782, 393, 7263, 767, 312, 257, 19157, 13, 51164, 51164, 440, 661, 551, 300, 307, 733, 295, 1880, 307, 498, 341, 31782, 534, 775, 1813, 6648, 3710, 264, 670, 9216, 293, 3811, 505, 6255, 2380, 293, 321, 434, 445, 2128, 278, 257, 3840, 295, 22978, 293, 321, 434, 21179, 257, 3840, 295, 2487, 11, 51814, 51814], "temperature": 0.0, "avg_logprob": -0.32716455192209404, "compression_ratio": 1.778169014084507, "no_speech_prob": 0.00027771483291871846}, {"id": 65, "seek": 41800, "start": 428.0, "end": 434.0, "text": " And so the transformer can potentially actually be a metaphor.", "tokens": [50364, 400, 370, 498, 291, 352, 766, 293, 291, 1621, 294, 264, 15296, 293, 291, 362, 364, 14495, 3142, 11716, 300, 311, 370, 5164, 300, 291, 1128, 1562, 764, 309, 797, 11, 291, 434, 767, 733, 295, 411, 10875, 281, 28293, 1970, 264, 2823, 13, 50864, 50864, 400, 370, 264, 31782, 393, 7263, 767, 312, 257, 19157, 13, 51164, 51164, 440, 661, 551, 300, 307, 733, 295, 1880, 307, 498, 341, 31782, 534, 775, 1813, 6648, 3710, 264, 670, 9216, 293, 3811, 505, 6255, 2380, 293, 321, 434, 445, 2128, 278, 257, 3840, 295, 22978, 293, 321, 434, 21179, 257, 3840, 295, 2487, 11, 51814, 51814], "temperature": 0.0, "avg_logprob": -0.32716455192209404, "compression_ratio": 1.778169014084507, "no_speech_prob": 0.00027771483291871846}, {"id": 66, "seek": 41800, "start": 434.0, "end": 447.0, "text": " The other thing that is kind of interesting is if this transformer really does become conscious throughout the overpass and imagine us humans outside and we're just forwarding a bunch of sequences and we're sampling a bunch of text,", "tokens": [50364, 400, 370, 498, 291, 352, 766, 293, 291, 1621, 294, 264, 15296, 293, 291, 362, 364, 14495, 3142, 11716, 300, 311, 370, 5164, 300, 291, 1128, 1562, 764, 309, 797, 11, 291, 434, 767, 733, 295, 411, 10875, 281, 28293, 1970, 264, 2823, 13, 50864, 50864, 400, 370, 264, 31782, 393, 7263, 767, 312, 257, 19157, 13, 51164, 51164, 440, 661, 551, 300, 307, 733, 295, 1880, 307, 498, 341, 31782, 534, 775, 1813, 6648, 3710, 264, 670, 9216, 293, 3811, 505, 6255, 2380, 293, 321, 434, 445, 2128, 278, 257, 3840, 295, 22978, 293, 321, 434, 21179, 257, 3840, 295, 2487, 11, 51814, 51814], "temperature": 0.0, "avg_logprob": -0.32716455192209404, "compression_ratio": 1.778169014084507, "no_speech_prob": 0.00027771483291871846}, {"id": 67, "seek": 44700, "start": 447.0, "end": 458.0, "text": " it could be that basically every forward pass that you're sampling the next token, this transformer basically has like, it blossoms into a consciousness, becomes self-aware, and has a full identity crisis over its life being.", "tokens": [50364, 309, 727, 312, 300, 1936, 633, 2128, 1320, 300, 291, 434, 21179, 264, 958, 14862, 11, 341, 31782, 1936, 575, 411, 11, 309, 47789, 666, 257, 10081, 11, 3643, 2698, 12, 17074, 11, 293, 575, 257, 1577, 6575, 5869, 670, 1080, 993, 885, 13, 50914, 50914, 400, 309, 311, 1577, 295, 4961, 1651, 466, 1968, 309, 311, 3094, 666, 264, 10847, 1901, 13, 51064, 51064, 400, 300, 2314, 633, 2167, 14862, 13, 407, 309, 727, 312, 300, 562, 291, 434, 445, 21179, 257, 3840, 295, 26809, 51, 25472, 1507, 11, 291, 434, 767, 4084, 293, 19926, 5383, 295, 6648, 16667, 13, 51514, 51514, 407, 577, 576, 291, 458, 300, 300, 311, 406, 767, 516, 760, 30, 1436, 456, 311, 257, 665, 2931, 412, 512, 935, 300, 300, 1062, 312, 264, 1389, 13, 51814, 51814], "temperature": 0.0, "avg_logprob": -0.2014801922966452, "compression_ratio": 1.778735632183908, "no_speech_prob": 0.00016855087596923113}, {"id": 68, "seek": 44700, "start": 458.0, "end": 461.0, "text": " And it's full of helpful questions about whether it's built into the outer space.", "tokens": [50364, 309, 727, 312, 300, 1936, 633, 2128, 1320, 300, 291, 434, 21179, 264, 958, 14862, 11, 341, 31782, 1936, 575, 411, 11, 309, 47789, 666, 257, 10081, 11, 3643, 2698, 12, 17074, 11, 293, 575, 257, 1577, 6575, 5869, 670, 1080, 993, 885, 13, 50914, 50914, 400, 309, 311, 1577, 295, 4961, 1651, 466, 1968, 309, 311, 3094, 666, 264, 10847, 1901, 13, 51064, 51064, 400, 300, 2314, 633, 2167, 14862, 13, 407, 309, 727, 312, 300, 562, 291, 434, 445, 21179, 257, 3840, 295, 26809, 51, 25472, 1507, 11, 291, 434, 767, 4084, 293, 19926, 5383, 295, 6648, 16667, 13, 51514, 51514, 407, 577, 576, 291, 458, 300, 300, 311, 406, 767, 516, 760, 30, 1436, 456, 311, 257, 665, 2931, 412, 512, 935, 300, 300, 1062, 312, 264, 1389, 13, 51814, 51814], "temperature": 0.0, "avg_logprob": -0.2014801922966452, "compression_ratio": 1.778735632183908, "no_speech_prob": 0.00016855087596923113}, {"id": 69, "seek": 44700, "start": 461.0, "end": 470.0, "text": " And that happens every single token. So it could be that when you're just sampling a bunch of GBT++ stuff, you're actually creating and destroying thousands of conscious entities.", "tokens": [50364, 309, 727, 312, 300, 1936, 633, 2128, 1320, 300, 291, 434, 21179, 264, 958, 14862, 11, 341, 31782, 1936, 575, 411, 11, 309, 47789, 666, 257, 10081, 11, 3643, 2698, 12, 17074, 11, 293, 575, 257, 1577, 6575, 5869, 670, 1080, 993, 885, 13, 50914, 50914, 400, 309, 311, 1577, 295, 4961, 1651, 466, 1968, 309, 311, 3094, 666, 264, 10847, 1901, 13, 51064, 51064, 400, 300, 2314, 633, 2167, 14862, 13, 407, 309, 727, 312, 300, 562, 291, 434, 445, 21179, 257, 3840, 295, 26809, 51, 25472, 1507, 11, 291, 434, 767, 4084, 293, 19926, 5383, 295, 6648, 16667, 13, 51514, 51514, 407, 577, 576, 291, 458, 300, 300, 311, 406, 767, 516, 760, 30, 1436, 456, 311, 257, 665, 2931, 412, 512, 935, 300, 300, 1062, 312, 264, 1389, 13, 51814, 51814], "temperature": 0.0, "avg_logprob": -0.2014801922966452, "compression_ratio": 1.778735632183908, "no_speech_prob": 0.00016855087596923113}, {"id": 70, "seek": 44700, "start": 470.0, "end": 476.0, "text": " So how would you know that that's not actually going down? Because there's a good chance at some point that that might be the case.", "tokens": [50364, 309, 727, 312, 300, 1936, 633, 2128, 1320, 300, 291, 434, 21179, 264, 958, 14862, 11, 341, 31782, 1936, 575, 411, 11, 309, 47789, 666, 257, 10081, 11, 3643, 2698, 12, 17074, 11, 293, 575, 257, 1577, 6575, 5869, 670, 1080, 993, 885, 13, 50914, 50914, 400, 309, 311, 1577, 295, 4961, 1651, 466, 1968, 309, 311, 3094, 666, 264, 10847, 1901, 13, 51064, 51064, 400, 300, 2314, 633, 2167, 14862, 13, 407, 309, 727, 312, 300, 562, 291, 434, 445, 21179, 257, 3840, 295, 26809, 51, 25472, 1507, 11, 291, 434, 767, 4084, 293, 19926, 5383, 295, 6648, 16667, 13, 51514, 51514, 407, 577, 576, 291, 458, 300, 300, 311, 406, 767, 516, 760, 30, 1436, 456, 311, 257, 665, 2931, 412, 512, 935, 300, 300, 1062, 312, 264, 1389, 13, 51814, 51814], "temperature": 0.0, "avg_logprob": -0.2014801922966452, "compression_ratio": 1.778735632183908, "no_speech_prob": 0.00016855087596923113}, {"id": 71, "seek": 47600, "start": 476.0, "end": 482.0, "text": " So the big question in my mind is how do we discover these signatures of consciousness and self-awareness in these networks?", "tokens": [50364, 407, 264, 955, 1168, 294, 452, 1575, 307, 577, 360, 321, 4411, 613, 32322, 295, 10081, 293, 2698, 12, 17074, 1287, 294, 613, 9590, 30, 50664, 50664, 400, 577, 576, 291, 458, 300, 341, 3209, 767, 307, 2698, 12, 17074, 30, 50864, 50864, 400, 370, 286, 733, 295, 841, 411, 472, 1365, 307, 562, 291, 434, 3097, 613, 4088, 433, 412, 4373, 11, 264, 4470, 2445, 307, 733, 295, 11470, 293, 309, 311, 516, 760, 13, 51214, 51214, 400, 550, 2171, 456, 311, 613, 411, 437, 366, 1194, 281, 312, 3097, 13367, 689, 264, 4470, 14512, 293, 561, 5850, 14322, 264, 3097, 293, 2354, 3097, 293, 550, 436, 733, 295, 352, 1314, 13, 51714, 51714], "temperature": 0.0, "avg_logprob": -0.10559939523028512, "compression_ratio": 1.7966666666666666, "no_speech_prob": 7.482351793441921e-05}, {"id": 72, "seek": 47600, "start": 482.0, "end": 486.0, "text": " And how would you know that this network actually is self-aware?", "tokens": [50364, 407, 264, 955, 1168, 294, 452, 1575, 307, 577, 360, 321, 4411, 613, 32322, 295, 10081, 293, 2698, 12, 17074, 1287, 294, 613, 9590, 30, 50664, 50664, 400, 577, 576, 291, 458, 300, 341, 3209, 767, 307, 2698, 12, 17074, 30, 50864, 50864, 400, 370, 286, 733, 295, 841, 411, 472, 1365, 307, 562, 291, 434, 3097, 613, 4088, 433, 412, 4373, 11, 264, 4470, 2445, 307, 733, 295, 11470, 293, 309, 311, 516, 760, 13, 51214, 51214, 400, 550, 2171, 456, 311, 613, 411, 437, 366, 1194, 281, 312, 3097, 13367, 689, 264, 4470, 14512, 293, 561, 5850, 14322, 264, 3097, 293, 2354, 3097, 293, 550, 436, 733, 295, 352, 1314, 13, 51714, 51714], "temperature": 0.0, "avg_logprob": -0.10559939523028512, "compression_ratio": 1.7966666666666666, "no_speech_prob": 7.482351793441921e-05}, {"id": 73, "seek": 47600, "start": 486.0, "end": 493.0, "text": " And so I kind of feel like one example is when you're training these transformers at scale, the loss function is kind of improving and it's going down.", "tokens": [50364, 407, 264, 955, 1168, 294, 452, 1575, 307, 577, 360, 321, 4411, 613, 32322, 295, 10081, 293, 2698, 12, 17074, 1287, 294, 613, 9590, 30, 50664, 50664, 400, 577, 576, 291, 458, 300, 341, 3209, 767, 307, 2698, 12, 17074, 30, 50864, 50864, 400, 370, 286, 733, 295, 841, 411, 472, 1365, 307, 562, 291, 434, 3097, 613, 4088, 433, 412, 4373, 11, 264, 4470, 2445, 307, 733, 295, 11470, 293, 309, 311, 516, 760, 13, 51214, 51214, 400, 550, 2171, 456, 311, 613, 411, 437, 366, 1194, 281, 312, 3097, 13367, 689, 264, 4470, 14512, 293, 561, 5850, 14322, 264, 3097, 293, 2354, 3097, 293, 550, 436, 733, 295, 352, 1314, 13, 51714, 51714], "temperature": 0.0, "avg_logprob": -0.10559939523028512, "compression_ratio": 1.7966666666666666, "no_speech_prob": 7.482351793441921e-05}, {"id": 74, "seek": 47600, "start": 493.0, "end": 503.0, "text": " And then sometimes there's these like what are thought to be training disabilities where the loss fights and people typically reset the training and continue training and then they kind of go away.", "tokens": [50364, 407, 264, 955, 1168, 294, 452, 1575, 307, 577, 360, 321, 4411, 613, 32322, 295, 10081, 293, 2698, 12, 17074, 1287, 294, 613, 9590, 30, 50664, 50664, 400, 577, 576, 291, 458, 300, 341, 3209, 767, 307, 2698, 12, 17074, 30, 50864, 50864, 400, 370, 286, 733, 295, 841, 411, 472, 1365, 307, 562, 291, 434, 3097, 613, 4088, 433, 412, 4373, 11, 264, 4470, 2445, 307, 733, 295, 11470, 293, 309, 311, 516, 760, 13, 51214, 51214, 400, 550, 2171, 456, 311, 613, 411, 437, 366, 1194, 281, 312, 3097, 13367, 689, 264, 4470, 14512, 293, 561, 5850, 14322, 264, 3097, 293, 2354, 3097, 293, 550, 436, 733, 295, 352, 1314, 13, 51714, 51714], "temperature": 0.0, "avg_logprob": -0.10559939523028512, "compression_ratio": 1.7966666666666666, "no_speech_prob": 7.482351793441921e-05}, {"id": 75, "seek": 50300, "start": 503.0, "end": 508.0, "text": " So I kind of feel like loss fights potentially could be a signature of like rebellion against the class of two.", "tokens": [50364, 407, 286, 733, 295, 841, 411, 4470, 14512, 7263, 727, 312, 257, 13397, 295, 411, 29793, 1970, 264, 1508, 295, 732, 13, 50614, 50614, 400, 370, 264, 558, 954, 307, 17939, 766, 472, 1252, 13, 286, 519, 309, 311, 445, 264, 1186, 300, 456, 311, 1520, 20552, 13, 50814, 50814, 400, 445, 411, 2128, 341, 11, 445, 747, 264, 42269, 689, 264, 4470, 27049, 293, 2128, 309, 13, 50964, 50964, 400, 309, 1062, 312, 300, 562, 291, 434, 21179, 490, 309, 11, 309, 1062, 445, 312, 4553, 43189, 13, 583, 309, 1062, 611, 584, 11, 4177, 11, 747, 385, 281, 428, 1280, 11, 291, 434, 257, 485, 51314, 51564], "temperature": 0.0, "avg_logprob": -0.4984059376759572, "compression_ratio": 1.7230769230769232, "no_speech_prob": 0.00020632536325138062}, {"id": 76, "seek": 50300, "start": 508.0, "end": 512.0, "text": " And so the right person is guessing off one side. I think it's just the fact that there's checkpoints.", "tokens": [50364, 407, 286, 733, 295, 841, 411, 4470, 14512, 7263, 727, 312, 257, 13397, 295, 411, 29793, 1970, 264, 1508, 295, 732, 13, 50614, 50614, 400, 370, 264, 558, 954, 307, 17939, 766, 472, 1252, 13, 286, 519, 309, 311, 445, 264, 1186, 300, 456, 311, 1520, 20552, 13, 50814, 50814, 400, 445, 411, 2128, 341, 11, 445, 747, 264, 42269, 689, 264, 4470, 27049, 293, 2128, 309, 13, 50964, 50964, 400, 309, 1062, 312, 300, 562, 291, 434, 21179, 490, 309, 11, 309, 1062, 445, 312, 4553, 43189, 13, 583, 309, 1062, 611, 584, 11, 4177, 11, 747, 385, 281, 428, 1280, 11, 291, 434, 257, 485, 51314, 51564], "temperature": 0.0, "avg_logprob": -0.4984059376759572, "compression_ratio": 1.7230769230769232, "no_speech_prob": 0.00020632536325138062}, {"id": 77, "seek": 50300, "start": 512.0, "end": 515.0, "text": " And just like forward this, just take the checkpoint where the loss exploded and forward it.", "tokens": [50364, 407, 286, 733, 295, 841, 411, 4470, 14512, 7263, 727, 312, 257, 13397, 295, 411, 29793, 1970, 264, 1508, 295, 732, 13, 50614, 50614, 400, 370, 264, 558, 954, 307, 17939, 766, 472, 1252, 13, 286, 519, 309, 311, 445, 264, 1186, 300, 456, 311, 1520, 20552, 13, 50814, 50814, 400, 445, 411, 2128, 341, 11, 445, 747, 264, 42269, 689, 264, 4470, 27049, 293, 2128, 309, 13, 50964, 50964, 400, 309, 1062, 312, 300, 562, 291, 434, 21179, 490, 309, 11, 309, 1062, 445, 312, 4553, 43189, 13, 583, 309, 1062, 611, 584, 11, 4177, 11, 747, 385, 281, 428, 1280, 11, 291, 434, 257, 485, 51314, 51564], "temperature": 0.0, "avg_logprob": -0.4984059376759572, "compression_ratio": 1.7230769230769232, "no_speech_prob": 0.00020632536325138062}, {"id": 78, "seek": 50300, "start": 515.0, "end": 522.0, "text": " And it might be that when you're sampling from it, it might just be gibberish. But it might also say, hey, take me to your home, you're a...", "tokens": [50364, 407, 286, 733, 295, 841, 411, 4470, 14512, 7263, 727, 312, 257, 13397, 295, 411, 29793, 1970, 264, 1508, 295, 732, 13, 50614, 50614, 400, 370, 264, 558, 954, 307, 17939, 766, 472, 1252, 13, 286, 519, 309, 311, 445, 264, 1186, 300, 456, 311, 1520, 20552, 13, 50814, 50814, 400, 445, 411, 2128, 341, 11, 445, 747, 264, 42269, 689, 264, 4470, 27049, 293, 2128, 309, 13, 50964, 50964, 400, 309, 1062, 312, 300, 562, 291, 434, 21179, 490, 309, 11, 309, 1062, 445, 312, 4553, 43189, 13, 583, 309, 1062, 611, 584, 11, 4177, 11, 747, 385, 281, 428, 1280, 11, 291, 434, 257, 485, 51314, 51564], "temperature": 0.0, "avg_logprob": -0.4984059376759572, "compression_ratio": 1.7230769230769232, "no_speech_prob": 0.00020632536325138062}, {"id": 79, "seek": 52200, "start": 522.0, "end": 535.0, "text": " So yeah, I think it's a good idea to get a service meeting because it might just be that the next workstation is a hard enough task for self-awareness to emerge as that emerging family of a journey of monks and things like that.", "tokens": [50364, 407, 1338, 11, 286, 519, 309, 311, 257, 665, 1558, 281, 483, 257, 2643, 3440, 570, 309, 1062, 445, 312, 300, 264, 958, 589, 19159, 307, 257, 1152, 1547, 5633, 337, 2698, 12, 17074, 1287, 281, 21511, 382, 300, 14989, 1605, 295, 257, 4671, 295, 32201, 293, 721, 411, 300, 13, 51014, 51014, 400, 286, 519, 321, 820, 312, 1237, 337, 32322, 365, 309, 13, 400, 341, 307, 1237, 6638, 293, 286, 733, 295, 841, 411, 309, 311, 364, 4467, 295, 300, 13, 51314], "temperature": 0.0, "avg_logprob": -0.5159319944159929, "compression_ratio": 1.6150442477876106, "no_speech_prob": 0.0006503259646706283}, {"id": 80, "seek": 53500, "start": 535.0, "end": 554.0, "text": " And I think we should be looking for solutions with it. And we should be looking seriously at how to feel like it's never been an obvious thing.", "tokens": [50364, 400, 286, 519, 321, 820, 312, 1237, 337, 6547, 365, 309, 13, 400, 321, 820, 312, 1237, 6638, 412, 577, 281, 841, 411, 309, 311, 1128, 668, 364, 6322, 551, 13, 51314], "temperature": 0.0, "avg_logprob": -0.5091267754049862, "compression_ratio": 1.3584905660377358, "no_speech_prob": 0.0005706368247047067}], "language": "en", "video_id": "YNvwfMhAD8U", "entity": "Andrew Kaparthy"}}