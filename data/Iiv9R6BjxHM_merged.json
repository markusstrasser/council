{"video_id": "Iiv9R6BjxHM", "title": "Week 13 \u2013 Lecture: Graph Convolutional Networks (GCNs)", "description": "Course website: http://bit.ly/pDL-home\nPlaylist: http://bit.ly/pDL-YouTube\nSpeaker: Xavier Bresson\nWeek 13: http://bit.ly/pDL-en-13\n\n0:00:00 \u2013 Week 13 \u2013 Lecture\n\nLECTURE Part A: http://bit.ly/pDL-en-13-1\nIn this section, we discuss the architecture and convolution of traditional convolutional neural networks. Then we extend to the graph domain. We understand the characteristics of graph and define the graph convolution. Finally, we introduce spectral graph convolutional neural networks and discuss how to perform spectral convolution.\n0:00:50 \u2013 Architecture of Traditional ConvNets\n0:13:11 \u2013 Convolution of Traditional ConvNets\n0:25:29 \u2013 Spectral Convolution\n\nLECTURE Part B: http://bit.ly/pDL-en-13-2\nThis section covers the complete spectrum of Graph Convolutional Networks (GCNs), starting with the implementation of Spectral Convolution through Spectral Networks. It then provides insights on applicability of the other convolutional definition of Template Matching to graphs, leading to Spatial networks. Various architectures employing the two approaches are detailed out with their corresponding pros & cons, experiments, benchmarks and applications.\n0:44:30 \u2013 Spectral GCNs\n1:06:04 \u2013 Template Matching, Isotropic GCNs and Benchmarking GNNs\n1:33:06 \u2013 Anisotropic GCNs and Conclusion", "author": "Alfredo Canziani", "keywords": ["Yann LeCun", "Deep Learning", "PyTorch", "NYU", "transformer", "attention", "Xavier Bresson", "Graph Convolutional Networks", "graph", "Graph Laplacian", "Spectral Graph ConvNets", "SplineGCNs", "LapGCNs", "ChebNets", "Isotropic GCNs", "GraphSage", "Anisotropic GCNs", "MoNets", "Graph Attention Networks", "GAT", "Gated Graph ConvNets", "Graph Transformers", "Benchmarking GNNs"], "channel_url": "https://www.youtube.com/channel/UCupQLyNchb9-2Z5lmUOIijw", "length": 7222, "views": 43994, "publish_date": "11/02/2022", "timestamp": 1598745600, "entity": "Yann LeCun", "transcript": {"text": " So welcome everyone to this lecture on graph convolutional networks. Okay so this is the outline of the lecture. So first I will go quickly on the traditional coordinates and the architecture and then I will introduce graphs and I will also remind definitions of convolutions to extend it to graphs. Then I will present two classes of graph convenants. The first one is what I call spectral graph convenants and the second one is the spatial graph convenants. I will talk a little bit about benchmarking graph neural networks and finally I will conclude. Okay so let's start with the traditional coordinates. So we all know coordinates are a breakthrough in computer vision. So when for the image net competition you know for the image classification task when the coordinate was used they decreased by almost a factor two the error of classification. It was in 2012 and it was basically the end of encrafting features and we shift the paradigm to and crafting learning systems. And now for this very specific task we all know that we go to superhuman performance. Convnets are also a breakthrough in speech and natural language processing so at Facebook when you want to translate you are also using coordinates. So coordinates are powerful architectures to actually solve high dimensional learning problems. So we all know about the curse of dimensionality. So if you have an image let's say by 1000 pixels so you have 1 million variables so an image can be seen as a point in a space of 1 million dimensions and for each dimension if you sample by using by using 10 samples then you have 10 to the power 1 million possible images. So these pieces are really huge and of course this is the question how do you find the needle of information in this big haystack. So coordinates are really powerful to extract basically this information the best possible representation of your image data to solve problems. Of course we don't know yet everything about yeah we don't know yet everything about Convnets so it's a kind of a miracle how powerful how good they are and it's also quite exciting because this opens many research areas to understand better and to develop new architectures. Okay so when you use Convnets you are doing an assumption and the main assumption that you are using is that your data so images videos speech is compositional. It means that it is form of patterns that are local so you know this is the contribution of urban and visual so if you are on this layer for this neuron this neuron is going to be connected to a few neurons in the previous layer and not all neurons okay so this is the local reception field assumption. Then you have also the property of stationary stationarity so basically you have some patterns that are similar and that are shared across your image domain okay so like the yellow patches and the blue patches so they are they are all similar to each other. The last property is hierarchical so you make the assumption that your data is hierarchical in the sense that your low level features are going to be combined together to form medium level features and then this medium feature are going to be again combined to each other to form higher and higher abstract features. So any Convnet work the same way so the first part of the architecture is to extract these conversional features and then the second part will be to solve your specific task you know like classification, recommendation and so on and this is what we call you know end-to-end systems and the first part is to learn the features the second part is to solve your task. Okay let's see more precisely what is the data domain so if you have images, images, volumes or videos basically so for example you can see this image and if you zoom in this image what you have is a 2D grid okay you have a 2D grid this is the structure of the domain of this image and on the top of this grid you have some features so for example in the case of color image you will have three features which are red, green and blue okay now if I'm looking at natural language processing so like sentences you will have a sequence of words and basically you can see that you know as a 1D grid and on the top of this grid for each node of the grid you will have a word okay so a word can be represented by just an integer for example the same also for speech so what you see here is the variation of the air pressure and it's the same you know it's like you have the support is a 1D grid and for each node of the grid you will have the the air pressure value okay which is a real number so I think it's clear we all use all the time grids and grids are you know as very strong regular spatial structure and for this for this for this structure this is good because we mathematically we can define the convenient operations like convolution and pulling and also in practice it's very fast to do it so everything is good now let's look at you know new data so for example social networks okay so you want you want to do your task for example would be to do advertisement or to also make recommendation so for a social network I'm going to it's going to be clear but I'm going to show you that if you take two nodes so for example you know you have this user let's say this user i and user j and all the others you see that this is not a grid okay so the connection the pairwise connection between all users they do not form a grid they have a very special pattern of connections and this is basically a graph okay so how do you define your graph you're going to see the connection between users so if i user i user j are friends you're going to have your no connection and then for this you are going to use what we call an adjacent c matrix which is just going to record all the connection or non-connection between nodes in your in your social networks okay and on the top of your network for each user you will have features so for example you have you know messages you have images you have videos so they form you know some feature in a d-dimensional space in in neuroscience in brain analysis for example we are really interesting to understand you know the fundamental relation relationship between structure and function of the brain so they are really connected to each other and it's very fundamental to understand that we also want for example to predict a neuro generative disease different stages of this disease so then this is very important for this we need to understand the brain and the brain if you look at the brain the brain is composed of what we call a region of interest okay and this region of interest if you take one region of interest this region is not connected to all other regions in the brain actually they are only connected to a few other regions so it's it's and again you can see nothing to do with the grid okay so this spatial connection between different region of the brains they can be measured by the structural MRI signal and then you also have an adjacent c matrix between region i and region j and and here you have a strength of connection which depends how many connection how many fibers do you have to connect region i and region j okay and then on the top of this graph so if you look at the region i then you will have activations you know functional activation which is basically a time series that you can see here and also we can record this activation of the brain with functional MRI okay the last example i want to show you is in quantum chemistry so for example the task would be to design new molecules for drugs and materials so so you see again the connection between atoms has nothing to do with the grid okay it really depends how you're going to connect your atoms and then you will have you know molecules so so the connection between atoms they are called bonds and you have you know different kind of bonds they can be single bond double bond aromatic bond and you have and you have also different features like energy and many other features that you can use from from chemistry for the node of the graph so there are atoms and again you you you may have different features like the type of atom if it is you know hydrogen if it is azot all these all these types you have also the 3d coordinates you have the charge and so on you may have multiple features okay so and it's not the list actually goes on to give you example of graph to give you example of graph domains so you also have you know computer graphics with 3d meshes you also want maybe to analyze transportation network and the dynamic of of cars or maybe i don't know trains you have also you know gene regulatory network you have knowledge graphs world relationships you know users products where you want to do recommendation you have also seen understanding you want to give more common sense to your computer vision machine so you want to understand the relationship between you between your objects you also have a lot of information about the high energy physics particles so you have captors and the captors are not you know structure as a regular grid so for all this you see that there is a denominator which is basically you can represent all these problems as graphs okay and and here is the common sense of the graph okay and and here is the command setting i would say the mathematical command setting for all these problems so the graphs let's let's call it g okay they are defined by three entities so the first entity is going to be the set of vertices so usually you are going to index the set of vertices from one to n and is is the number of nodes in your in your graph okay so for example this will be the index one two three and so on then you will have you know the set of edges basically they are the connections between them between the nodes and finally you will have the adjacency matrix a which will give you the strength of the connection of your of your edge okay okay then you have graph features so for example for each node node i or node j you will have some some node features so it's basically a vector of dimensionality dv okay the same also it's possible that you can get you can get h features and it's going to be a vector of dimensionality d e so for example for molecules the node feature maybe you know the atom type and the edge feature maybe the bond type to give you an example and finally you can have also some graph feature okay for all for the whole graph you can have some feature so again it's a it's a vector of dimensionality dj and and in this case and and in the case of of of chemistry that that might be the molecule energy okay so this is um i would say the general definition of of graphs okay so now what i'm going to do is that i'm going to talk about convolution and the question how do we extend convolution to graphs okay so first let me remind you the classical way to use convolutional layer for grids when we use confnet for computer vision so let's say i have this image and or maybe this is some you know hidden feature at layer l okay and i'm going to do the convolution with some pattern or curve with some pattern or kernel that of course i will learn by back propagation and then i will get some activation okay so this is the the features at the next layer so to give you maybe some dimensionality so for example n1 and 2 is going to be the number of pixels in the x and y direction and d is the dimensionality of of each pixel so if this is a color image the dimensionality is going to be 3 for the three colors and if this is like intermediate hidden feature maybe you have 100 you know dimensions for the kernel usually you take small kernels because you want to know the local reception field so that might be you know 3 by 3 pixels kernel or 5 by 5 and of course you have d because you need to to respect the dimensionality of your input features okay so maybe for this one so you see that so you are going to convert this image with this feature which is oriented in this direction so you will basically identify you know lines in in in this direction of the image so that was just an example and we use padding right right now right so we had the same dimensionality of the yes yes absolutely again just padding so you basically you don't reduce the size of your image right yeah okay so so how do we mathematically define convolution so the first definition is to do is to see convolution as a template matching okay so so template matching so here is the definition the mathematical definition of convolution so what you're going to do is that you're going to take your template you're going to take your image and then you are going to sum over the index in the whole image domain omega okay of wj and this is going to be a product between vector wj and vector hi minus j okay so this is the pure definition of convolution and what we do usually in in computer vision is that we don't take minus we take plus okay and we call that because when we when we do that we have the definition of correlation and this is this is you know because it's more like it's exactly like template matching okay so it doesn't change anything if you if you do i minus j or i plus j in the learning sense because the only thing that you do is that you flip up and down and left and right your your your your your kernel and when you learn it doesn't change anything basically okay but this is the definition of correlation so it's it's really a template matching and then I'm going to take for the notation ij okay so basically and yeah and something very important that you have here is that you when when we do convolutional layers we are using kernel with compact support you know like a tree by tree it's very small support when we do that we don't do the sum over the whole domain the whole image domain we just do the sum over the neighborhood of the node i okay and this is very important it's very important because suddenly the sum is not over the whole pixel it's just you know in the neighborhood and then the complexity of doing convolution is actually to the order of the number of nodes so the number of pixels in your in your image so so the the complexity is quite easy to to compute so what you're going to do is that you're going to take your your pattern you're going to slice your pattern so it's going to be n slicing because n number of locations and then you're going to do you know a scalar product of three by three elements and and you're going to do you know um the vector product of vectors of dimension 18d so you see the complexity of doing this operation is just n times three times three times d so the complexity is n and and again everything can be done in parallel if you have a gpu the computation that you are doing in this in this location is independent to the competition that you are doing in this location so everything is is linear complexity okay so doing that um okay so so at the end of the day if you want to do convolution with template matching you're just going to compute this um scalar product between your template and between uh your uh your image um i would say your image patch okay um okay so something that is very important to see in the case of the graph being grid so this is for standard convolution in computer vision if you look at if you are looking at you know your template which is here okay so you see that i'm going to give some node ordering uh j1 j2 j3 and so on to j9 and this node ordering is actually very important okay because for for all time i mean this not i mean this this node so for example the node j3 will always be positioned at the same location so it's always going to be at the top right corner of of the pattern okay so that's that's very important why it's very important so let me go to the next slide so why it's very important is so when i will do the convolution so the pattern matching again i will take my uh my pattern and i will slice the pattern over my image domain okay so that will be maybe here and i put it here and and also this is position i position i prime that i put here i put here so when i'm going to do the template matching between the kernel and the image what i will do is that for this index so the index j3 it will always match you know the information in the image at at this uh index here okay so this is very important so you when you have a grid the node ordering the node positioning is always the same whatever the position in your image so when you do the template matching between index j3 and this index here in the image you always compare the same information you always compare the feature at the top right corner of your pattern and the type of corner of the image patch okay so this um this uh you see these matching scores they are for the same information okay so that's very important now let's look at what happened for graphs okay so the question is can we extend this definition of template matching for graphs and there are too many issues so the first issue is basically on a graph you don't have any uh ordering of your notes okay so on the graph you you have no given position uh for your notes so let's say for example i have this uh graph template okay so there are like four nodes with this connection and i have this uh vertex here the thing is for this vertex i know nothing about the position the only thing that i know is the index okay so maybe this is the index number three for this one and then when when if i want to use the template matching definition what i'm going to do is that i need to match you know this uh index with other index uh in the graph domain so this is my graph and let's say this is for the node i and they are the neighbors of the node i so for this label this is the index the same index j3 but here i mean how can i match you know this information with this information when i do not know if they match to each they match with to each other because on the graph you don't have any ordering of your notes you don't know uh if these nodes it's for the top right corner of any information you don't know that so on the graph you have no notion of where is the up where is the down where is the right where is the left okay so when you do this matching between uh this feature vector and this feature vector actually this matching usually in general has no meaning okay you you don't know what you compare to each other okay and again the index is completely arbitrary okay so you can have the value three here but it can be here the value number two or value number 12 you you don't have this is this is not uh you know any uh good information so basically because you don't have any uh ordering of your notes on graphs you cannot use the definition of template matching you cannot use that directly so we will need to do something else okay the second issue with template matching for graphs is what happens if the number of nodes in your template does not match the number of nodes you know uh in your in your graph so for example here i have four nodes here i have four nodes fine maybe i can find a way to compare um the two the two sets of of nodes but here i have uh i have seven nodes so how i'm going to compare seven nodes to four nodes so that's also you know an open issue okay so the third mathematical definition was to use template matching to define convolution now the second definition is to use the convolution the convolution theorem so the convolution theorem from um from Fourier is basically the Fourier transform of the convolution of two functions is the pointwise product of their Fourier transform this is what you see here okay so the Fourier transform of the convolution of function w and function h is the Fourier transform of f and pointwise multiplication the Fourier transform of h then if you do the inverse Fourier transform you go back to your um to your convolution so nice okay we have a very um nice formula to do the convolution of w and h and but the thing is in a general case doing the Fourier transform is n square complexity we come back to that however if you if your domain uh like uh like the image grid has some very particular structure then you can reduce the complexity to n log n uh by using you know uh fast Fourier transform okay so the question is can we extend this definition of uh of convolution uh theorem to graphs so the question is how do we redefine a Fourier transform for for graphs okay and and the thing is how to make it fast okay so remember that in the case of uh of template matching and we have linear complexity so how do we have a fast spectral convolution in linear time for compact kernels so that's that's the open question okay so basically we are going to use these two definitions of convolution to design two classes of graph neural network so the this would be the template machine will be for the spatial graph coordinates and the convolutional theorem i'm going to use that for the spectral graph coordinate and this is the next uh the next part that i'm going to talk about now okay so let's talk about uh how we do spectral convolution okay so i i there is a book that i like very much uh which is the book of fanchime which is uh spectral graph theory so there is everything nice like harmonic analysis graph theory combinatorial problems and optimization so i really recommend uh you know people to read the books if they want to know more and a lot more about about these these questions so how do we perform spectral convolution so we are going to use four steps so the first step will be to do will be to define graph laplation second step will be to define four functions then we will do four transform and eventually uh convolution theorem okay so the what is the graph laplation so the graph laplation this is the core operator in spectral graph theory okay so remember how we define a graph we have a set of vertices a set of edges and then we have the adjacency matrix so is the graph as n vertices the adjacency matrix is an n by n uh matrix so we are going simply to define the laplation which is also going to be an n by n matrix to be the identity minus the adjacency matrix and we are going to normalize the adjacency matrix by using um the degree of each node so d is basically a diagonal matrix and the diagonal each element of the diagonal is basically the degree of the node okay so we are doing and this is called the normalized laplation okay so this is i would say this is by default the definition of uh laplation that we use for for graphs so we can interpret uh this uh this operator so the the laplation is the question so the a was that matrix with basically all the zeros and the one was representing the connection between edges right um yes so uh for facebook for example i would say that this is exactly the definition so if uh node i user i is a friend with a user j then you will have uh adjacency matrix value will be i j equal to one and if two users are not friends then you will get the value zero but sometimes you have a real value for a for example for the for the brain connectivity graph um the value of a i j is um the degree of connection between the two regions so basically what we say the number of fibers that connect uh region i and region j so that can be binary that can be also a continuous value and also this is symmetric if it's non oriented graph otherwise yes so yeah for um usually it is symmetric uh and you want you want the symmetry for for mathematical reasons um but you may have some not so here this is the normal elevation but if you have the random walk laplation and then this is non-symmetric okay so it's um it's a different definition of the laplation so in the case of laplation is very interesting so in the continuous setting you have only one definition for the laplation this is called the laplace beltrami operator in the discrete setting you have multiple definitions you can do your own definition of the laplation depending on on the assumptions that that you are going to use i understand thank you um okay so we can interpret the laplation so the laplation is nothing else than a measure of smoothness of a function on a on a graph so this is nothing else than you see so i'm doing the laplation that i apply to a function h okay on the graph and i'm looking at what happened at the vertex i and if i expand this definition i will have the value of hi minus the mean value of the neighborhood okay so basically if your signal is smooth you know if it doesn't very much then this difference will be very small but if your signal you know varies a lot it oscillates a lot then the difference will be very high so the laplation is nothing else than a measure of smoothness of function on a on a on a graph okay all right so um now let's define Fourier functions so let's let's take the laplation matrix and let's do a little bit of linear algebra let's do eigen decomposition of the graph laplation so when you do eigen decomposition you will have the you are going to factorize your laplation matrix into three matrices so you have a phi transpose lambda and phi so this matrix phi of the size n by n actually have the what and the laplation again vectors okay for each colon and the laplation again vectors they are called the Fourier functions okay the famous Fourier functions and of course this is an orthonormal basis um so when you do the the product between two bases you will get one if they are the same and then you get zero if they are orthogonal if they are different uh you this is also an invertible uh matrix this guy so this matrix this is the uh diagonal matrix of the laplation eigenvalues so lambda one to lambda n and and and we know that for the normalized application that these values are bounded between zero and between two so this is the maximum value that you can get this guy the laplation eigenvalues they are known as the spectrum of the graph okay so if you take a graph here you have 27 nodes if i compute the laplation eigenvalues and if i put them i have a signature of the graph which is called the spectrum of the graph okay that which will be different for each each graph okay and here you have okay this is what i say so this is doing again decomposition so if you take your laplation matrix and you apply to a vector phi of k then you will get the eigenvalue lambda k times the same vector phi of k okay so this is the definition of the eigen decomposition okay so you see that for functions there are nothing else than the laplation eigenvectors okay let me illustrate these fourier functions so we actually we already know fourier functions if you if you take the grid so for example you take here a one degree and you compute the fourier functions so you so you will get phi zero okay then you will get phi one which is this one which is smooth phi two which is less a little less smooth and phi three and so on and so on so this is when known this is the cosine function and the simulzoids and we use that you know for for image compression so if we take an image and we project the image on the fourier functions then the image is going to be the the the transformation is going to be sparse so you only keep you know the highest coefficient and you can do compression so this is something that is very important for the graph domain this is this is quite interesting so you see that and this is a graph and i'm computing here the the first four you know fourier function of the graphs so you see for phi one you still have oscillations you know between positive and negative value the same if you positive and negative value and and here as well what is interesting is that the oscillation depends on the topology of the graph okay so so it's related to the to the geometry of the graph like communities like hubs and so on and we know that so for example if you want to capture k communities on graph a very good algorithm is to apply k-means on the first k fourier functions if you do that you have something that we call spectrograph theory and it's a it's a it's a huge literature and and if you want to know more about this there is this very nice tutorial by van loomsbroe about about spectrograph clustering and using all these notions of fourier functions okay okay now let me introduce you fourier transform okay so for this i'm going to do the fourier series for your series is nothing else then you take a function h defined on your graph and then you are going to decompose this function using the fourier function okay so i take my function h i project my function h on each fourier function phi of k and i will get you know this coefficient of this fourier series it's going to be a scalar multiplied by my function phi of k okay of the time and n by one of the size and n by one okay so and doing that you know just projecting my function on the fourier functions just projecting my function on the fourier functions give me the fourier transform okay so the fourier transform is is just you know the coefficient of the fourier series nothing else okay then h you know is a basically a linear combination of the fourier transform times the the fourier functions okay i can rewrite everything in matrix vector representation and this guy so doing the phi times the the fourier transform this is actually the inverse fourier transform okay so let me summarize this if i do if i project h on the fourier functions i will have the fourier transform okay so i'm taking the matrix of the fourier functions and i'm multiplied by h so this is n by n by n this is n by one so this is n by one okay and now if i do inverse fourier transform of the fourier transform okay so i would have phi of fourier transform of h and this guy is here okay so i just put phi transpose h and we know that the the basis is normal so this guy is actually identity function the identity i'm sorry identity matrix okay so this is an entity matrix so i come back to to h so so the inverse fourier transform is is of of the fourier transform is h obviously okay so one thing that you can observe is that the fourier transform and the inverse fourier transform can be done in one line of code okay you just take your vector h you multiply by this matrix and that's it and the same also to do the inverse fourier transform you take your your signal and you multiply by this matrix so it's basically just linear operations just multiplying a matrix by a vector and this is how you do fourier transform an inverse fourier transform on graphs okay now let's let's do the convolution theorem so again the convolution theorem the fourier transform the fourier transform of your um the fourier transform of the convolution is is going to be the pointwise product of the fourier transform of each signal okay so let's say i have w convolution h so i'm going first to do the fourier transform of w then this is going to be a vector of the size n by one then i'm going to multiply pointwise by another vector which is the fourier transform of h okay so how do we get the three transform you just by doing phi transpose w and phi transpose h and then i'm going to do the inverse three transform to come to go back to the spatial domain so i'm just multiplied by the matrix phi okay n by n so this is what i write here okay i have phi i have um w hat which is a fourier transform and i have this this i'm going to change it i'm going to change it to this line what is this line um shouldn't there be a phi transpose before w hat sorry shouldn't there be a phi transpose before w hat no the inverse fourier transform is phi okay so you do phi and you multiply by the fourier transform which is a phi transpose w which i call uh hat uh w so i'm going i'm going to use that a lot uh i will come back to this and then here you have the fourier transform of h which is just phi transpose h which is here okay so this guy okay this guy is actually what we call the spectral function okay the spectral filter so this guy is a vector of n by one okay and i'm writing i'm writing here uh this vector here so you see this is a vector of n elements and this is actually the spectral function which is um evaluated at the at the uh at the eigenvalue lambda one which is here so this is this point here then you have uh w hat lambda two which is this this value here and so on and so on okay and then i'm going to rewrite this you know i'm going to put this uh in a diagonal okay so i will do diagonal of this vector so this will create a matrix of the size n by n okay and i'm putting this guy back here so i'm going to change the uh the pointwise multiplication of this vector n by one and this vector n by one by the matrix vector multiplication and it's going to be the same right this is a diagonal matrix which contains this guy this guy multiply multiply by this by this vector so this is exactly the same these two lines but what i want to do that because i want to get rid of the parentheses okay so i don't have the parentheses anymore and i have just you know matrix matrix multiplication okay so this is this is what i get um then when i'm going to do something is that we know that when you apply a function on the eigenvalues okay if you have some orthogonal basis then you can put it inside you can put it inside and this is what i do here i put uh phi and phi transpose inside and this guy is precisely the definition of the relation okay the relation uh when i do the eigen decomposition is phi lambda phi transpose okay um then so what i have is basically the spectral function that i applied to the laplacian uh operator and this is an n by n matrix and apply to the vector n by one so at the end i will get n by one vector okay so you see that if you want to do so it's it's important now so if you want to do a convolution of two functions on graph w and h what you're going to do is that you're going to take the spectral function of w you will apply it to the to the to the laplacian and then you multiply by h okay this is the definition of uh of spectral convolution okay and and the thing is this is very expensive uh in practice to do it why it is expensive it's because the matrix phi is a full matrix okay it contains uh the n uh the n um Fourier functions and they are not zero okay so it's a dense matrix and you are going to pay the price of n square and you don't have any FFT because the thing you don't have any FFT for uh for general graph okay so this is a this is a lot and why it is a lot because n remember and this is the number of nodes in your domain so if you have um if you have a big graph for example if you have uh the web the web has you know billions of nodes n is equal to the billions so you need to do billion square which is going to be a huge computation to do so you you cannot really do it can i summarize so h is going to be a function defined over every vertex in your graph right and w instead is going to be like a kernel as well or is he but in this case w is going to be a function like this so w is a spectral function w hat is a spectral function so you are walking in the frequency space in the frequency space you are working with this what this is this is a spectral function so for example if you if you know image processing a little bit so for example if you want to do image denoising if you want to do image denoising what you what you know is that you know that the noise is usually in the high frequency part of your image of your signal. So what you can do is that you can design a spectral filter which is going to be zero for the high frequency and you are going to preserve the low frequency to preserve your geometry. So this is just doing filtering of the frequencies contained in your signal. Okay, but the W without the hat would be still a small guy, right? Would be a small filter. So W without hat is the spatial filter. Yeah, the small one, right? Which is exactly so. Exactly. So if you have the grid, W will be a tree by tree patch, for example. I see. Okay. Okay. Thanks. Yeah, sure. So in the context of graph, it's a small property to know is that you don't have any shifting variance. So if you have a grid and if you are using the convolutional theorem to move around your function, for example, the function is a Gaussian here. On the grid, you are not going to change the shape of your function. But on a graph, because you have a regular structure, if you move around your Gaussian, then you will have different shapes. Okay. So this is something that you lose when you go to graphs. But in practice, actually, it has absolutely no effect. So it's not really important. It's just a mathematical property that you lose when you go to graphs. Okay. There is another question. There is another question I got here. So can you remind us what is actually the overall goal here? What is the goal of defining these convolutions or the spectral correspondence over these graphs? I think maybe it's not... Yeah, if we can remind everyone, it's going to be... Yeah. So what I'm trying... The goal of the lecture is to define graph convolutional nets. Okay. So I need to redefine convolution in the case of graphs. And there are two ways to define convolutions. You can do convolution with stamp-like matching, or you can do convolution with graph spectral theory. So what I'm doing here, I'm redefining convolution in the case of spectral theory. And then I'm going to use this definition of convolution to define graph convolutional nets. So my goal is just to define convolution in the case of graphs so I can design graph convolutional nets. Yeah. Sounds great. Okay. So let's go to... Okay. So now the first part was, okay, I define spectral convolution. Now I'm going to use spectral convolution to define GCN. Okay. So the first model, what I call Vanilla Spectral GCN, was introduced actually by Yann Lecain and his collaborators, so Johan Bruner, Zahran Bah and Arshur Slam in 2014. I think it was for the first ICLR conference. And what they did, they did the simple idea to do, okay, let's define a graph spectral convolutional layer. So we know what is a standard convolutional layer. So this is the activation at the next layer, 8 plus 1. This is your nonlinear activation. So this is, for example, the redo. And then I'm going to do the spatial filter. So the template WL, convolution by HM. Okay. So this is in the spatial domain, the graph domain. And then I'm going to do that. And remember that what I just defined, so doing this convolution in the spectral domain, it's just doing that. Okay. So this is the spectral filter applied to the laplation and then you multiply by HM. Okay. So this guy is, I can decompose this guy. I will get the Fourier matrix times the spectral function that I applied to the eigenvalues, phi transpose HM. Okay. And this is my spectral filter. Okay. So I do not work directly here. Okay. I work directly here. And here, the thing that I'm going to learn, I'm going actually to learn this function, W hat, non-linear one. So I'm going to learn the spectral filter and I'm going to learn it by back propagation. Okay. So I don't need to, you know, handcraft the spectral filter. I don't need to do that. This will be learned by back propagation. So that was really a great idea to do it. And this was the first spectral technique, but it has some limitations. So the first limitation is that you don't have any guarantee of special localization of filters. So remember that what we want, we want to have the local reception field because it's a very good property to be able to extract, you know, multi-scale feature, multi-scale patterns from your signal. So you don't have this guarantee. The second thing is that how many parameters do you need to learn? So you need to learn you need to learn N parameters. Okay. You need to learn this W hat non-linear one to W hat non-linear N. So it's N parameters. So again, if the graph is large, like the web, you know, or Facebook, then this is going to be billions of parameters to learn. And this is for each layer. So it's going to be really huge. And again, the learning complicity is going to be N square because your file is a dense matrix. So we need to improve this. Okay. So Yan and his collaborators, so they improve the two properties. So the first property was, okay, how do we get localized spatial filters? Okay. So for this, what they propose is to get localized spatial filter. So you want something which is localized. What you need to do is to compute smooth spectral filters, something very smooth like this. Okay. So why do you, why do you want smooth spectral filter? It's because if you are smooth in the frequency space, then you are going to be localized in the space domain. Okay. So this is in physics, you know, the Isenberg's entity principle. And you can see that, you know, with the possible identity, if let's, let's say that K is equal to one, if K is equal to one, you have the first derivative of, of the spectral function. So if you want this to be small, okay. So you're going to have a smooth function. And for K equal to one, you see here is this is going to be the variance of your spatial filter. So if this is small, if the variance is small, it means that you're going to have a small, you're going to have a spatial filter with a small compact support. Okay. So if you are smooth in the frequency space, you're going to be localized in the spatial space. Okay. So you need smoothness. How do you get smoothness for spectral filter? So you can also think about the, the transform of the data of the Iraq, right? So we have, if we have a data in the Iraq in the, in the time domain, then in the frequency, we're going to have basically a flat, a completely flat transform, right? So there's another maybe way to see if someone doesn't quite know the parcel identity. Yeah, exactly. Right. And so, so how do you get a smooth spectral filter? So the idea is, okay, we can simply decompose, you know, the spectral filter to be a linear combination of smooth kernels. Okay. So the smooth kernel was chosen to be splines because splines are nice. They are, you know, with compact support and they are smooth. And basically the idea is, okay, now let's learn a vector of K coefficient. And this is a K smooth kernel. Okay. And you learn this coefficient by back propagation. But suddenly, you know, everything is nice because you have localization in space and the number of parameters that you're going to learn is going to be K parameters. So K for example, let's say it's nine. Okay. Remember that before in the case of, of convolution. So you have the tree by tree, which is nine parameters. So that can be the same. You can have nine parameters to learn. You're going to, you're going to learn a combination of nine spline functions. And, and that's it. So you can have a constant number of parameters to learn per layer. So this is nice, but we still have, you know, the, the five matrix. So the learning complexity is still quadratic. Okay. Okay. So, so the question is, how do we learn in linear time? Okay. So how do we learn with respect to the, to the graph size and so the problem of the quadratic complexity comes from directly from the use of the Laplacian again, vectors. Okay. So you see that the thing that is, that is annoying in this spectral convolution is not this diagonal matrix. It's not this vector. It's this guy. Okay. This is, this is the five matrix because it's a full matrix, right? It's a dense matrix. And, and then, and then it's an N square number of elements. So this is the price that we need to pay. So we know that if we want to avoid the quadratic complexity, we need to avoid the again, the composition. Okay. And, and, and okay. So we can avoid again, the position by simply directly learn function of the Laplacian. Okay. So this is what we propose in 2000, 2016. So the spectral function is just going to be, you know, a monomial function of the Laplacian. That's it. So we just have a sum of some parameters that we learn by back propagation WK and Laplacian to the power of K. Okay. So, so when we do that, first there is something which is, which is good is that we're going to have features that are exactly localized in a key hop support. Okay. So if we have the application to the power of K, the spectral, I mean, the special features will be exactly localized in the support of key hop. So what is, what is the one hop neighbor neighborhood? So let's say, for example, you have this graph and here I'm going to put a hit source. So the value is going to be one at this node and zero for all other nodes. If I apply the Laplacian to this hit source, then the signal, the support of the signal is going to be increased by one hop. So every basically every nodes that can be reached by one job. Okay. That you do that. And, and if you do two jumps from this, you will, you will reach the, the second hop neighborhood, which is your range, the orange nodes here. Okay. So if you apply the Laplacian two times, this is going to be the support. Okay. If you apply the Laplacian K times, then you will have a support of K hops. So you, you exactly control the, the size of your spatial filters. Okay. So that, that was the first point. The second point, let me show you that you get learning complexity. Okay. So, so again, you have your convolution, W H you have your spectral convolution definition. I'm using here as a spectral convolution monomials of the, of the Laplacian. And then I'm going to replace this guy. So the Laplacian power of K times the vector H by the vector X K. Okay. And X K is actually given by your recursive equation. Okay. So recursive is always good. Right. So it's going to be this recursive equation, which is the Laplacian times the vector X K minus one and the X K equal to zero is simply the original function H. Okay. So, so when I do that, you see that this sequence X of K is generated by multiplying a matrix. So the Laplacian and the vector X K minus one. So the complexity of doing that is the number of edges. Okay. And you do it that, you know, K times. So number of edges times K. And the thing is for real graph, real world graphs, basically they are all sparse. Okay. Because sparsity is structure. So remember, for example, for, for, for the web, the web has billions of, of web pages, but for each web page, it is an average connected to 50 other web page. So comparing 50 to one billion is nothing. So usually, and the same also for the brain, the brain, it's very high sparse. The same also for transport networks. So everything, every natural graph is usually sparse because sparsity is structure. Okay. So, so the number of edges is, you know, some value times N. So at the end of the day, you have linear complexity because for sparse real world graphs. Okay. Okay. So, and you see here is that I'm using the Laplacian and I never do any identity composition of the Laplacian. Okay. And there is, so there is a bit of, of confusion that sometimes I see is that, so I call this spectral, you know, GCN, but this is, this might be misguided because I don't do any spectral operations. Like, you know, I don't use any identity composition with the Laplacian. I don't have any eigenvectors, eigenvalues. So, so at the end of the day, even if I use, you know, the spectral theory to define this GCN, at the end of the day, the computation are all done in the special domain using the Laplacian. Okay. I don't use any, I don't use the spectral domain for the computation. I use, I do everything in the special domain. So even if we call that spectral GCN, we don't use, you know, in practice, the spectral decomposition. So just, just one, one, one comment. Okay. And the last, the last comment I want to do is that, so graph convolutional layers, again, this is just linear operations. So you just multiply a vector, a matrix by a vector. So we're just doing an operation. So this is GPU friendly. The issue is that here you are doing sparse linear algebra and the existing GPU are not optimized for that. So this is, I think, one of the limitations today for graph neural networks. We need to have specialized hardware for graph neural networks. We need to have hardware that adapt to the sparsity of these operations. And we don't have this today. So if we want this to get far, very far with graph neural network, we need to have this specialized hardware. What about TPUs? Do you know whether TPUs can handle this? That's the same. That's the same. They are optimized for full, you know, linear operations, like full matrices. They are specialized for that. But if you want to do sparse linear algebra, you need specialized hardware to do that. Gotcha. Thanks. Yeah. Okay. So how do we implement, how do we implement this? So for example, we have a signal. We have a function defined on the graph. So n is the number of vertices of your graph. And d is the dimensionality of of the feature. So for each node, you have a feature or vector of the dimension. So how do we do that? So we have xk. And what we do is that we are just going to shape stuff to do just linear operations. So xk are going to be arranged in a matrix, you know, x bar, which is of the size of k times nd. Okay, so we just reshape, you know, this xk to be 1 times nd. And then we have k times nd. And then we multiply this by the vector that we will learn by back propagation, which is of the size k by 1. Okay, we do that. The operation would give you 1 times nd, you reshape and you get n times d. So this is how I implemented, you know, with PyTorch or TensorFlow, they will be the same. And this is how you do this spectral convolution. So again, the properties is that filters are exactly localized. You have a constant number of parameters to learn. So this is a k, you know, this is this is this k parameters that you need to learn by back propagation, you have a learning complexity, a linear learning complexity. But the thing which, which is not good is that here I'm using monomial basis. Okay, so I'm using LePlace shunt to the power zero, LePlace shunt to the power one, power two, power three, and so on. Okay, this is what I use here. And the thing is monomial basis are unstable for optimization, because this basis, you know, is not orthogonal. So if you change one coefficient, then you are going to change the approximation of your function. So you need orthogonality, if you want to learn with stability. Okay, so then you can use your favorite, you know, orthonormal basis, but your favorite orthonormal basis must have a recursive equation. Okay, so this is the only thing that that that you that you need. You need your orthonormal basis to have a recursive equation, because this is the key to have the linear complexity. So we use a Chebyshev polynomials. So this is something very well known in signal processing. So we're going to approximate, you know, the spectral convolution with a Chebyshev function. The Chebyshev functions apply to H again can be represented by xk, and xk is given by this recursive equation. Okay, so it's a little more complex than before. But in practice, this is just doing again, multiplication of your laplacian times the vector one vector. Okay, at the end of the day, the complexity is still linear, you don't change anything. And this time you have stability during your during the learning process. Okay, so what we did, we did the sanity check with MNIST. So and you see that so this is the number of vertices. So for MNIST, the graph is the standard grid. Okay, we use a K-Niris neighbor grid to do that. And you see that you have linear complexity. Okay, this is the number of vertices. And you have this number of you have the linear complexity. So this is good for the accuracy of the accuracy, we get to see 99% of accuracy compared to the standard learning five. Okay, so ChebNet So ChebNet is basically coordinates for arbitrary graph, and we have the same linear learning complexity. Of course, the complexity constant is much larger than than the standard than the standard coordinate. So it's something like 20 or 30. So it's much, much smaller to learn on this, but you get, you know, a coordinate for any arbitrary graph. So that's, that's, that's what you mean. Another limitation is, it's an isotropic model. So, so let me talk a little bit about isotropy versus anisotropy. So if you look at, you know, the standard coordinates, then you are going to produce anisotropic filters like this one. Okay, so you see that this filter is an isotropic, it goes in this direction. Okay, and we can get anisotropic filters with standard coordinates, because we are using a grid. And on a grid, we have, you know, directional, we have directions, we know where is the up, where is down, where is left, where is right, right, remember that we know the ordering of of the nodes on the grid, we know that. But this is different for graphs, we don't have any notion of direction, we don't know where is the where is up, where is down, where is left, where is right. So the thing, the only thing that we can do at this point, is that we can only compute isotropic filters. Isotropic filters means that the value of the filter will be the same, you know, for in all directions, for, for, for, for cycles, okay, for the four cycles of the same radius. Okay, so this is, this is what we can get, we can only get isotropic filters when we use a chipnet, because we have no notion of direction on arbitrary graphs. And we come back to that, we come back to the isotropy versus anisotropy a bit later. Okay, so what we what we did also is to very quickly, I don't, I don't have the time. Oh, wow, the time is up. So I need to speed up a little bit. So we did we did extend also this spectral convolution from one graph to multiple graphs. So you can do that, you know, it's like extending from 1D signal processing to 2D image processing. So extension is mathematically straightforward to do. And we did that, you know, for for example, for recommender systems, because we have users of movies and users of graphs. So that we also, as I said before, is that you can use your favorite, you know, orthogonal polynomial basis. So we use k-inets, because Chebyshev are unstable to localize frequency bands of interest, which are basically the graph communities. We use that something more powerful, you know, more powerful spectral functions. Okay, which is going in it. Okay, so now let me go to the to the to this class of graph coordinates that I call special graph coordinates. And then for this class, I'm going back to the template matching, you know, definition of convolution. So how we do template matching for graphs. So remember that the main issue, the main issue when you want to do template matching for graph is that you don't have any node ordering or positioning for your template. Okay, we don't have any positioning. So basically, the only thing that we have, we have the index of the nodes, and that's it. But the index is not enough to match, you know, information between nodes. So how can we design template matching to be invariant to node parameterization? Okay, so you have a graph, this index of the node is maybe, let's say, six, but it's completely arbitrary. I can have an index with the number 122, for example. So I want to be able to do template matching independently of the index of this node. Okay, so how I do that. So the simplest thing you can do is actually to have only one template vector to do the matching. So you don't have, you know, WG1, WG2, WG3, you don't have this, you just have one vector W, and you are doing the matching of this vector with all other features on your graph. Okay, this is the simplest template feature matching you can do, which is invariant by node parameterization. And actually, this property is going to be used for most graph neural networks today. Okay, so here is the mathematical definition. So I'm just going to do the product between the template vector W at layer L, so this is a D by one, and I have the vector at node J, which is also the dimensionality D by one. Okay, I will get a scalar. So here this is only for one feature. Of course, you will have to get more features. So instead of having a vector D by one, you're going to use a matrix D by D. So this way you can get, you know, D features for each node I. Okay, and then so this is the representation at node I. I can put everything in vector representation. Okay, this is my activation at layer L plus one. It is defined on the graph of n vertices, and it has D dimensions. Okay, and this can be rewritten as the adjacency matrix A. So this is an n by n matrix. This is my activation at the layer L. So this is n by d, you know, matrix. And this is the template that I'm going to learn by backpropagation of the size D by D. Okay, so you do this product, you get n by D. Okay, so based on this template matching of graph, now I'm going to define two classes of spatial GCN, which are the isotropic GCN and the anisotropic GCN. So let's start with the isotropic GCN. So this is actually quite some history. Okay, so the simplest formulation of spatial GCN was introduced by Skarsily and his co-author. So he was in 2009 before the deep learning revolution, and then more recently by Thomas Keith, Max Willing, and also Sian Sukubata and Arshur Slam and Rob Fergus in 2016. So this is actually this graph neural network, so what I call the Vanina graph computational nets. Okay, this is exactly the same definition that I had before. Just here I put the GV matrix in such a way that I have the mean value. Okay, I just do the mean value over the neighborhood. Okay, but this is exactly the equation that I used before. Okay, and you see that so this equation is, it can handle absence of node ordering. So this is completely invariant to node parameterization. So again, if this index is maybe six and I change to be 122, it's not going to change anything in the computation of the of H at the next layer. It's not going to change anything. You can also deal with a neighborhood of different sizes. Okay, you don't care if you have a neighborhood of four nodes or a neighborhood of 10 nodes, it's not going to change or one node, it's not going to change anything. You have the local reception field by design with graph neural network, you just need to look at the neighbors and that's it. So it's given to you. You have weight sharing. Okay, you have weight sharing means that for all features, you are going to use the same W, whatever the position on the graph. Okay, so this is a convolution property. This formulation is also independent of the graph size, because all operations are done locally. Okay, you just use local information for the next for the next layer. So you can have a graph of 10 nodes or you can have a graph of 10 billion nodes. It doesn't care. So you can do also everything in parallel. And but this is limited to isotropic capability. So the W is the same for all neighbors. So it's again, it's an isotropic model is going to give the same value for all neighbors. Okay, but at the end of the day, this model can be represented by this figure. So this, so the activation at the next layer is basically a function of the activation of the activation at the current layer at index at the node i and the neighborhood of the node i. Okay. And the only thing that we're going to do basically is to change the function, the instantiation of the function. And then you will get all family of graph neural network by just, you know, deciding a different function here, but everything is based on this equation. So again, you have your core node and then you have your neighborhood to decide what will be the activation at the next layer. Okay, so I'm running out of time. So I'm not going to take too much time on this. But what you can show is that this previews Vanilla GCN I just show you is actually a simplification of chain net. So if you truncate the expansion of chain net by using the first two chain net function, that at the end, you end up with the same equation. So, so this is this is the relationship. Okay, so one interesting GCN is graph sage that was introduced by William Hamilton, Lee and Yuri Leskovic. So let's say for let's go back to the Vanilla GCN. So and let's suppose that the adjacency matrix as a value one for the edges. Okay, so I have this equation. So the thing is, for this equation, I'm going to treat, you know, the central vertex i and the neighborhood with the same template weight. Okay, but I can differentiate that, you know, I can have a template for the central node, the body one, and I can have a template for the one hope neighborhood. Okay, by doing that, you improve already a lot, you know, your the performance of your of your graph neural networks. So you go from here to here. So you have again, some template for the central node and the template for the neighborhood. Okay, but this is still an isotropic, isotropic GCN. Okay, because you are treating all the neighbors with the same weight. Here, this is the mean, but you can change you can take the sum, you can also take the max, you can take also something more elaborated like LSTM. Okay, now more simply people try to improve the theoretical understanding of GCN. So there was the graph isomorphism, I see isomorphism networks are introduced by Yuri Leskovic in 2018. So the idea is, can we design an architecture that can differentiate graphs that are not isomorphic? So you know isomorphic is basically a measure of equivalence between between graphs. So these two graphs are isomorphic to each other. And of course, you want to treat them the same way. But if you are not isomorphic, you want especially to treat them in a different way. Okay, so there was a graph neural network based on this one, on this definition, but this is still an isotropic GCN. Okay, so now I'm going to talk about anisotropic GCN. So again, again, so I go back to what I said before is that standard coordinate can produce anisotropic filters, because there is a notion of directions on grids. Okay, so you have this anisotropic filter in this direction. GCN like a ChemNet, KaliNet, Vanilla GCN, GraphSAGE, and GIN, they compute isotropic filters. So you have this kind of filters that you learn during the process, but they are isotropic. But we know that anisotropy is very powerful, right? So how do we get back anisotropy in graph neural networks? So you can get anisotropy naturally. For example, if you have H features for like, if you take in chemistry molecules, you know that the bond features can be different. They can be, you know, single, double, aromatic bonds. So naturally you would get anisotropic GCN. And again, if we want to design a mechanism for anisotropy, we want this mechanism to be independent with respect to the null parametrization. So to do that, we can use, for example, H degrees. And so that was proposed by Monet, Hgate that we propose in GAT GCN or attention mechanism in GAT. And the idea is what I put here as an illustration. Okay. So here you're going to treat your neighbors in the same way. Okay. So with the same template, but you want to treat your neighbors in a different way, right? If this is J1, you want a different weight than if it was for J2. What do you want that is, for example, if you want to analyze graphs, you know that you have communities of people which are different. For example, I don't know if it is politics, you have Republicans and Democrats. So you don't want, you know, to have the same analysis for the same group of people. So you want anisotropy for graph. That's quite important. Okay. So the first model who deal with anisotropy was Monet. So he was introduced by Federico Monti, Michael Bronstain, and their co-author. And the idea was to use GMM, so Gaussian mixture model, and to learn the parameters of the Gaussian mixture. So here they have K Gaussian mixture model, and then learn the parameters by using the degree of the graph. Then there is also GAT. So it was developed by Peter Velikovic and Yoshua Benjo and their co-author. It was basically to use the attention mechanism developed by Jimmy Badano, Yoshua Benjo, and Cho to introduce anisotropy in the neighborhood regression function. Okay. And so this is what you see here. So you have, you're going to concatenate, so it's a multi-head architecture. And here you have this weight, which are basically the softmax on the neighborhood. Okay. You do the softmax on the neighborhood. So some nodes will be more important than the others, given by softmax. What we use with Thomas Laurent and me in 2017, we use a simple age-getting mechanism, which is a soft attention process compared to the sparse attention mechanism of Yoshua Benjo. And here what we did also, we use H feature explicitly. And this actually, recently we discovered that this is very important for H prediction task. If you have explicit expedition task, this is important to keep it. Okay. So this is the model that we used. Okay. So if I take transformer, and if I write down the equation of the graph version of transformer, this is the data we get. Okay. So you recognize here the value, here you have the query, here you have the key, and here you have the softmax, but the softmax is done in the neighborhood, the one-hawk neighborhood. Okay. That would be this. And here I'm going to make a connection with a transformer of Vasmohany and his collaborators. So what is a transformer? So a standard transformer is actually a special case of graph conventional nets when the graph is fully connected. Okay. So this is a fully connected graph. So you take any node, i, and this node is going to be connected to all other nodes in the graph. And it's included itself. Okay. So if you look at this equation, the equation I just wrote before, if the neighborhood is this time not the one-hawk neighborhood, but the whole graph, then you will get the standard equation that if you do an LP and transformer, you will recognize directly. Okay. We saw this last week. So just... Exactly. So that's a nice transition. So you see, you have the computation. So this is multi-head, you have the softmax, the query, the key, and the value, and then you have the weight for the multi-head. So the only thing that I do here mathematically, just having the neighborhood that use all connection. And when I do that, so there is the question. So what does it mean to do graph conventional nets for fully connected graphs? And I think in this case, it becomes less useful to talk about graphs, because when you have each data connected to all other data, then you don't have any more specific graph structure. Because a graph, what is really interesting with graph is the sparsity structure, right? Like the brain connectivity, like the social networks. What is interesting is not everything to be connected to each other. It's only to have a sparse connection between the nodes. So I think in this case, it would be better to talk about sets than to talk about graphs. And we know that. We know that transformer are set neural networks. So in some sense, instead of looking at a fully connected graphs with feature, the thing that we should look at is more a set of features. And transformers are really good to process sets of feature vectors. OK. So there is a lab that I put here. So the lab is based on, so this is the GATGCN, the model I proposed. And this is with GGL. So this is the deep graph library. So it was developed by NYU Shanghai by Professor Zheng Zheng. And here, this is the link to the lab. So if you click on this link, you will go directly to the lab. And this is using Google collapse. So you will just need a Gmail account to access to this. And you will be able to run it on the Google Cloud. And what I put here, I put really the most interesting functions that you need to develop a Gcm. So maybe tomorrow. Yeah, tomorrow we're going to be going over everything. OK, perfect. You will do that. OK. So and here, I gave you know, I put some comments on the code. And also, yeah, also understand DGL, how DGL works. So probably you'll do that tomorrow. Yes, yes, yes. Nice. OK. So let me now, I'm going to the end. So let me talk a little bit about benchmarking graph neural networks. So recently, we have this paper of benchmarking graph neural networks. So why we did this benchmark? Because if you look at the most published Gcm papers, most of the work actually use small data set like Cora or TU data set and only one task, like classification. And when I started doing some experiments on that, I just realized that if you use Gcm or if you don't use any Gcm, you will get statistically the same performance because the standard deviation is very high for the small data sets. So the thing is, we cannot identify good Gcm. We need something else. And also, recently, so there has been a new theoretical development for Gcm. And the question is, how good they are in practice. It's important to have some good mathematical justification of Gcm. But we need to be able to prove that this is something that is useful. And I think also benchmark has been very essential to make progress in many fields, like, of course, deep learning with ImageNet by Fei-Fei Li. But the thing is, what I observe is actually people are quite reluctant to give credit to benchmarks. Anyway, so we introduced this open benchmark infrastructure. So it's on GitHub. It's based on PyTorch and DGL. And we introduced six new medium scale data sets for the four fundamental graph problems, like graph classification, graph regression, node classification, and edge classification, which I think if you cover these four fundamental graph problems, you already know quite a lot about the performance of your Gcm. Can you spend a few words more about these four fundamental graph problems? I think we haven't mentioned them so far, I think. Yeah, exactly. But what I mentioned is basically the first part of any convolutional nets is how do you extract a powerful feature. The rest is quite easy. If you want to do regression, you just use an MLP. If you want to do classification, you should use MLP, with cross entropy. I can take more time to do that. But what I present is more interesting than doing just these guys. But if you give me another hour, we could do that. I was making the point that I think I understand now how we can build a representation of a graph. But then so you would have this feature per node. But then how would you go from this feature per node to the final task? Maybe we can mention this such that we can give some more. Sure. What you do basically, for example, you have feature exactly. You extract convolutional feature per node. Then suddenly, if you want to do, for example, graph classification, what you will do, you will do some kind of aggregation function on this feature node. For example, the most common one is to do the average. You do the average of all feature nodes. Then on the top of that, you use an MLP. Then you will do classification of your graph. This would be for always the same kind of structure of the graph or you have different structures, like different numbers of nodes? If you use the mean, it's completely independent of the number of nodes. If you do the sum, if you do the max, you have many operators which are independent of the number of nodes. We have this. This medium size actually enough to statistically separate the performance of graph neural networks. We make easy for new users to add new graph models and also new data sets. This is the link to the repo. Let me now explain the graph neural network pipeline. A standard graph neural network pipeline is composed of three layers. The first layer is going to be an input layer and is going to make an embedding of the input node and edge features. Then you will have a series of graph neural network layers. Finally, you will have a task layer. There will be a prediction layer for graph node and edge task. Let me now describe in details each of these three layers. For the input layer, again, we will have the input node and edge features. This comes from the application. That can be a node feature, for example, for recommender system, for products. It will give you some feature of your product. What you will do is that you will take this whole feature and you will make an embedding, a linear embedding, and you will get a vector of d dimensions. We can do the same if we have some edge feature. We can do an embedding of the input edge feature and we will get a vector of d dimension. Basically, the output of the embedding layer will be for h, it's going to be a matrix of n nodes and d dimension for the features. For the edge is going to be a matrix of e, the number of edges times the number of features. We will give that. We will give this output of the embedding layer is going to be the input of the graph neural network layers, which is here. Then what we will do is that we will apply our favorite graph neural layer a number of L times. We have the node and the edge representation at layer L. It will go through the G and N layer and it will give you node representation of h and e at the next layer. We will do that N number of times. This will give us the output of the graph neural network layers. Again, it's going to be a matrix of n nodes and d dimensions for the nodes and for the edges. It's going to be a matrix of e, which is the number of edges times the dimensionality. This is the output of our graph neural network layers. Finally, for the last layer, this is a task-based layer. If we are doing some prediction at the graph labels, what happens is that we are going to take the output of the graph neural network layers and we're going to make a mean with respect to all nodes of the graph. This will give us a representation of the graph of d dimension. Then we will give that to an MLP, a multi-layer perceptron, and it will give us a score which can be a scalar if we are doing some graph regression like chemical property estimation, or it can be classification if we are trying to classify molecules to some classes. We can also have a node-level prediction. What we will do is that we will take the node representation at the output of the graph neural network and we will give that to an MLP and we will get a score for the node i, which can be a scalar for regression or can be a k-dimensional vector for classification. We can also do edge-level prediction. We have a link between node i and node j. It's going to be a concatenation of the graph neural network representation for node i and node j. We give that to an MLP and again, we'd have a score for the link between node i and node j and it can be regression or classification. Quickly, because I'm running out of time, you have the graph classification task, the graph regression task, sorry. This is for molecules. Here we want to predict the molecular solubility. Here you have the table. This is agnostic GCN. We don't use any graph structure. The lower, the better. Here this is isotropic GCN and this is anisotropic GCN. Usually you will see that for most experiments, anisotropic GCN do better job than isotropic GCN because you use some directional property. This is for graph regression. This is for graph classification. You have supernodes of images and you want to classify the image to belong to one of the classes. You also have edge classification. This is here the combinatorial optimization problem of TSP, so the traveling salesman problem. You have a graph and then you want to know if this edge belongs to the solution. If it belongs to a solution, this is a class one. If it doesn't belong, this is class zero. We see that here you need explicit edge feature. You see that the only model that does a good job compared to the naive heuristic is by using explicit edge feature. Here I'm using this combinatorial example to make a workshop announcement. This is also what we are organizing next year with Yan and also Peter, Stephanie, Andrea, Stan, and Max. We're organizing a workshop on combining deep learning and combinatorial optimization, which I think is a very interesting direction of research. Okay, conclusion. We generalized the conv net to data on graphs. For this, we needed to redesign a convolution operator on graphs. We do that for template matching, which lead to the class of spatial GCN. We also did that with spectral convolution, which lead to the class of spectral convolution, spectral GCN. We have linear complexity for real world graphs. We have GPU implementation, but yet it's not optimized for the GPU that we have today. We have universal learning capacity, so this is the recent theoretical works. We can do that for multiple graphs and also for graphs that can change dynamically. Application, so I'm happy now that I don't need to justify anymore why we are doing graph convolution on nets to anybody, so it's getting more and more application. We see that at the last, actually this week, ICLR conference. The key word that gets the most improvement was graph neural networks. You have now a workshop and tutorials on graph neural networks at many of the top deep learning and AI conferences. This is the first probably tutorials on graph deep learning that we organized at the Norelips in 2017 and CDPR. Also, if you want some materials to look more, we have this iPad workshop organized in 2018 and also a follow-up in 2019. For this, we have the video talks, so if you want to know more about this. We have a framework for writers, so Joshua Benjo, Michael Bronstein, Federico Monti, Chaitaina Joshi, Vijay Diwili, Leo, Thomas Lorenz, Arshur Slam, Ron Levy, Michael De Fiora, Pierre Mandela, Eli Sampath, and Patrick Aigman. Thank you. Thank you. It was really impressive and I think everyone here was stunned by the quality of the slides and your explanations. We really, really enjoyed it. I'm getting so many private messages here. Everyone's pretty excited. I have actually a few questions if you have some time left. We haven't talked about generative models. Do you have any words about how we can, for example, generate new proteins for figuring out whether we can find a cure for this COVID right now? Actually, how do you say, current question for the current world. Yeah, absolutely. The community is also working on the graph generative models. You have two directions. The first direction, you can do it in a recursive way. What you're going to do is that you are creating your molecule atom after atom. You start with an atom, then you will have a candidate for the next atom and also the next bound between the two atoms. You can do that. It's a LSTM style. The second direction is to do it in one shot. You need a network that can predict what is the length or the size of your molecule and then what are the connections. You have these two directions. You can do it in a recursive way or you can do it in one shot. The community is more interested in the recursive way today. I have a paper on the one shot. Basically, they are performing the same. I don't see any difference, but you can do it. The only thing is how do you treat? The question is your molecule can have different size. This is the key. I would say the challenge here. How do you deal with different sizes? We have different options to do that. What is very interesting related to the chemistry of that is that what I want to make is that graph neural networks in some sense are too much flexible. When you go from the standard ConvNet, the grid is very structured. You can get a lot of information for the structure of the grid, but you don't have this in graph. Again, you lose the node ordering and everything. We need to find a way to have more and more structure inside the graph neural networks. One way to do that is the architecture. For example, you would like to combine, for example, if you do chemistry, you would like to combine Schrodinger equation, like Hamilton energy. People are doing that to constrain better your graph neural networks. Again, graph neural networks are in some sense too much flexible. You need to find a way to add more universal constraints. Actually, about the universal constraints, I got here a question. What do you mean by universal learning capacity? Yes. This is the recent works on graph neural networks. In some sense, you're trying to classify your neural networks. There are many publications on neural networks. How do you classify them? You need to find mathematical properties like isotropic properties, anisotropic properties. More recently, there are theoretical work on isomorphism and expressibility of graph neural network depending on some class of theoretical graphs. Graphs are starting by earlier, like 200 years ago. We know a lot about graphs and we want to classify graphs according to some mathematical property. This is what I was trying to mention that you can design graph neural networks for some special mathematical properties. I see. Thank you. Okay. Guys, feel free to ask questions. You can also write to me if you're too shy. I'm not shy. I can just read. I have a question. Thank you so much for this great lecture. You mentioned that you created a benchmark data set so people can benchmark their different graph neural networks. I feel like a lot of those networks also learn some representation in the graph. A lot of downstream tasks could be like an unsupervised setting where I think in the benchmarking data sets, you're all just using accuracy more or less. It's like you have labels, ground truth labels. It's more in the supervised setting. Do you have any thoughts on how we could benchmark the graph network's performance in an unsupervised setting or semi-supervised setting or by measuring their performance in some common downstream tasks or application? I would like to hear your thoughts on that. Thank you. I think this is one of the most favorite topics of Jan, the self-supervised. Yeah, that's right. As you can tell, I brainwashed the students in the class very well. Yes, so that's why I'm asking. Of course, one important question is you want to learn efficiently. You don't want to have too much labels to be able to predict well. Self-supervised learning is one way to do that. You can do that also with graph. You can hide some part of the information of your graph and then you can predict this hidden information to get your representation. I guess now it's out for me to follow all the recent GCN work, but I guess if you Google it, there will probably already be one or two papers on this idea. There is nothing special with GCN. You can apply the same ideas like self-supervised learning to GCN. We don't put that in the benchmark yet. It's a good idea. That's something maybe we could do. Actually, arguably, all of self-supervised learning actually exploits some sort of graph structure. When you do self-supervised learning in text, for example, you take a sequence of words and you learn to predict a word in the middle or missing words, whatever they are. There is a graph structure and that graph structure is how many times a word appears some distance away from another word. Imagine you have all the words and then you say within this context, make a graph between words. This would be a very simplified version of it, but make a graph that indicates how many times this word appears a distance three from that other word. Then you have another graph for distance one, another one for distance two, etc. That constitutes a graph and it's a graph that indicates in what context two words simultaneously appear. You can think of a text as basically a linear graph and the neighbors that you take. When you train a transformer, basically, it's taking a neighborhood in this graph. When you do metric learning, the type of stuff that Isha Mishra talked about, using contrastive training where you have two samples that you know are similar and two samples you know are dissimilar, this basically is a graph. It's a similarity graph that you're using. You're telling the system, here are two samples that are linked because I know they are similar and here are two samples that I know are not linked because I know they're dissimilar. I'm trying to find a graph embedding, essentially. You can think of those neural nets are learning a graph embedding for nodes so that nodes that are linked in the graph have similar vectors and nodes that are not are dissimilar vectors. There is a very, very strong connection between self-supervised learning and the graph view of a training set. I don't think it's been exploited or realized yet by a lot of people, so there might be really interesting stuff to do there. I don't know what you think about this, Xavier. Yeah, exactly. This is completely related to the graph. You don't have any known positioning. What you are seeing is exactly that. How do we get positioning between nodes that are relevant to your particular application? You want to do it in a self-supervised way because then you will learn all possible configurations and you don't need to have labels to do that. This is the point. If you know how to compare nodes, so basically how do you extract positional encoding, then you will do a great job. That's one of the most important questions in graph neural networks and also for NLP and many other applications. Great. Thank you. A question just arrived here. Could you possibly highlight the most important parts of graph with attention? I think we maybe have gone a little faster and someone got a little bit lost. Graph attention network, the first technique was developed by Yoshua Benjo, Peter, and so it's probably the first work you would like to see. You can also take the transformer, the standard transformer, and then you can make it a graph version. It's quite straightforward to do it. Just by multiplying with the agency matrix, right? Yeah, exactly. You can already do it with PyTorch transformer. There is a mask. Exactly, with a minus infinity. Yeah, a mask. Exactly. If you put minus infinity with softmax, you will get zero. Exactly. I think I'm going to show this tomorrow. Yeah, exactly. You can already do graph transformer very easily with PyTorch. But the thing is, it's going to be a full matrix. It's going to use a lot of your GME memory because there are many values that you don't need. If you want to scale to larger graphs, then you need something that explores the sparsity like DGL or PyTorch geometric, for example. Last week, we coded from scratch. We actually see all the operations inside, and then maybe we can just add one additional matrix there just to make this masked part such that we can retrieve the graph convolutional net from the code that we already have written. So that would be, I think, a connection for tomorrow. Hold on. There are more questions coming. Is there any application where using CHEPnet might be better than spatial GCN? So I would say they are part of the isotropic. This is the class I call isotropic GCN. So for me, of course, it will depend on your data, and it will depend on your task. If you have some task where your data is isotropic, this kind of information, then CHEPnet will do a very good job for sure. Now, if you have information where isotropic is important, for example, for social networks, you don't want to treat the neighbors the same way, then it's not going to do a good job. So it really depends on your task where isotropy is very important. If isotropy is very important, then you should use CHEPnet because CHEPnet is using all bit of information about your graph in an isotropic way. And if you are using GCN, the Vanilla GCN, you are just using the first two terms of approximation of CHEPnet. Yes, yes, yes. There we can learn the edges, right? We can learn the representation for the edges such that they are discriminated between neighbors, right? No, no, no, this one is an isotropic. You are talking about isotropic. What I mean by isotropic is that if you have a pure isotropic graph problems, then you should use CHEPnet. CHEPnet, otherwise, yeah. But otherwise, yeah, it's better to use an isotropic GCN. Of course. More questions, guys? Hey, I have a question. Thanks for the talk. I was wondering, a lot of these methods require an existing adjacency matrix and for some problems. For example, you know that there is a graph structure, but you don't know the underlying connections. Do you know of any work that addresses this problem? Yeah, absolutely. So far, most works focus on having already the graph structure. And of course, sometimes you just have data. For example, you just have a set of features, and you want to learn some graph structure. It's very hard, very, very hard. So there are some works doing that. So they are trying to learn some graph structure, and at the same time, they are trying to learn another representation. So that's promising, that's interesting. And this is also some work that I'm trying to do now. But I can tell you it's very hard to do. And especially because if you let the adjacency matrix to be a variable, then you are n squared. You have n squared unknown parameters to learn. So it's not easy. But yeah, this is a So I would say that these techniques, there are many natural data coming with graphs. You don't need to build any graphs. And this is already giving you a lot of good tools. Now, if you can give me maybe what you have in mind, what kind of application you have in mind, what you want to use, when you want to learn graphs, at the same time, maybe we can talk about it. So I can tell you Xavier, of course, Ziming will correct me. But Ziming is actually working on predicting protein function prediction, basically. And so the undating graph would be the, for example, a contact map or the kind of proximity graph of different sites on a protein. And you don't have that. I mean, in most cases, you don't. That's kind of what the things you have to predict. So you could use this as some sort of latent, you know, graph variable. I see your model. Ziming, maybe you had some other idea in mind. Yeah, I think actually, so the more specific problem is that some of these graphs, you know, the edges and you, you know, some of the edges, but you don't know the other ones. For example, in protein function prediction, you can imagine like two proteins that have similar functions as having an edge between them. But they might not have the same function. So you don't know sort of the edge weights and you kind of have like a human labels that are inaccurate. So you know that they're connected in some way, but you don't know the edge weights and you know that there are other proteins that should be connected, but you don't have labels for. So I guess this is more of a graph completion problem. Yeah. And this one is easy. This one, if you have, it's like the semi, you know, the semi graph clustering problem. So if you already have some label, just a few labels, and you have some structure around this, that's something you can, you can live with. If you absolutely know structure on the edge and then you need to learn the graph, that is very hard. I see. Okay. Thank you. Hey, I have a question about splits of the data when it actually training a neural network. Because it's like, can you talk about some of the things that you would want to consider when actually splitting the data into say training and validation? Like you might want to have all of the nodes in the training data for it to actually be exposed to everything that's in the graph data. And you might have a case where different types of edges are in balance in the data set. Can you talk about when that would be important? What are some of the considerations in splitting the data in training? Sorry, I'm not sure I understand the question. So you are talking about unbalanced training sets? Yes. And also like, so if you have like a huge relational data set, right? You can talk about some of the considerations for splitting the data when you're trying to train a graph network. So for relational data sets, so you may have millions of small graphs. And it is fine. I mean, because this graph neural network, they are independent of the size of your graph. So this is not an issue to learn some good graph learning representation. There is no issue with that. Now, if you have unbalanced data set, I don't know. So that's maybe you can maybe apply some standard techniques to do that. So you can also, for cross entropy, for example, you can weight your cross entropy depending on the size of each class. So that may be something you can do. But I never thought too much about this. Okay, thank you. Any more questions? I'm still getting things written here, but you can voice yourself if you are Yeah, I have a question actually. First of all, thanks a lot for the lecture at this time, especially for you. So how do you deal with cases where the nodes do not have the same dimension? Like if I want to run a small, simple vanilla graph count relieving network, but my nodes are something like even for Facebook, people and then pages, and I want different dimensions. So how do you think about graph, like very, very simple graph neural network in that? Nothing has nothing to do with graph neural networks. If you have different dimensions for your vector, so probably you need to put everything on the same dimension, and then you need to use some indicator function, like one when you have the information and zero when you don't have any information. And this will be used during the computation of the loss. And then when you back propagate, if you don't have any feature information, you will not use it. But nothing has anything to do with graph neural networks. Okay, thank you. Hold on, you're writing, I'm reading so much. So maybe I don't understand the question, but I will read it out loud anyway. Is there any GCN which can work on multiple agency matrices together? For example, a bidirectional graph. I don't know what this means. So, I think that's a good question. So, I think that's a good question. So, I think that's a good agency matrices together. For example, a bidirectional graph. I don't know what this means. So, if the question is about hypergraph, so you know you may have more than one age connecting your nodes. Yes, there are some work about this. It's an extension, it's a natural extension mathematically. So, you can do that. There is no limitation to go to hypergraph. It's fine. And there are now some data sets for this task. So, if there is an application, so students would be trusting to do, there is already a data set and papers about this. Okay, another question would be, does it make sense to have nodes that are features of a person and do graph classification or have nodes as person and do node classification? I don't know. I don't know. So, often people ask me the question, can I do a graph given this data? So, it's really task dependent. I think it's really, when is going to be useful or not, when you get some good relationships. Because what is a graph? It's just a collection of pairwise, you know, pairwise connections. So, that's it. So, the question is when it is relevant to solve your task. Sometimes it is relevant, sometimes it's not. So, it really depends on the, yeah, it's obvious, but it really depends on the data and the task you want to solve. So, yeah. Yeah, the student is satisfied with your answer. I think we ran out of questions, unless there are more coming my way. No, it starts getting bright outside there. Exactly. I was noticing. The sun is rising. That's nice. Okay. I think that was it. Thank you so, so much. It was like, I mean, really, those were so pretty. These slides were so pretty. I had to learn so much from the way you teach. Yeah. Thank you again for waking us early. I mean, I think this is a fascinating topic. As you know, I've been involved in this at the beginning, and I think it opens a completely new door to applications of machine learning and neural nets. It's a new world. It's a completely different world. I know your PhD advisor had been working on graph six, but I'm not sure if that's the right word. I know your PhD advisor had been working on graph signal processing for a long time. So this was kind of a natural transition for him and for you, I guess. But I think we haven't seen the end of this. We're going to be surprised by what's going to come out of this. I mean, there's really already sort of fascinating work in that area, in high energy physics, in computational chemistry, in social network applications. And you kind of cited all the big names in the, you know, if you're interested in this topic, if you're listening to this, Yuri Leskovic is one of the big names, in addition to Xavier, obviously. And Joanne Brunard, whom you know, because he's a professor here, and he talks about it in this course. Michael Bronstein is also a big contributor. He's made some really interesting contributions to the topic, also on sort of slightly different methods than the one that you talked about today, on like, you know, using graph neural nets for like 3D meshes and for computer graphics and things like that. So I agree. I think this is also a field, you know, where there is a back and forth between, you know, mathematics and also applications. So if you look at, for example, this protein stuff, it's very, very hard. But at the same time, we can learn a lot, you know, from the mathematical side, we can, we can, and it's very exciting, right? Because you want both, if you want to be able to make scientific discovery, you need to be, you know, driven by some real world very hard problem. And then at the same time, you have these new tools, you know, coming up with graph theory, neural networks, and it's a way also for us to better understand, you know, why neural networks work so well. And this is, you know, a direction where it looks like, you know, each day, they are like a new problem in this direction. So the pie is big, and for everyone, for the young students to come and to enjoy, you know, this area of research. Great. Well, thank you again, and enjoy your day. Yeah, thanks again. Thank you so much, guys. All right. Bye bye. Bye. Guys, see you tomorrow.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 4.88, "text": " So welcome everyone to this lecture on graph convolutional networks.", "tokens": [50364, 407, 2928, 1518, 281, 341, 7991, 322, 4295, 45216, 304, 9590, 13, 50608, 50768, 1033, 370, 341, 307, 264, 16387, 295, 264, 7991, 13, 407, 700, 286, 486, 352, 2661, 322, 264, 5164, 51104, 51104, 21056, 293, 264, 9482, 293, 550, 286, 486, 5366, 24877, 293, 286, 486, 611, 4160, 51532, 51532], "temperature": 0.0, "avg_logprob": -0.20997725592719185, "compression_ratio": 1.5732484076433122, "no_speech_prob": 0.004175633192062378}, {"id": 1, "seek": 0, "start": 8.08, "end": 14.8, "text": " Okay so this is the outline of the lecture. So first I will go quickly on the traditional", "tokens": [50364, 407, 2928, 1518, 281, 341, 7991, 322, 4295, 45216, 304, 9590, 13, 50608, 50768, 1033, 370, 341, 307, 264, 16387, 295, 264, 7991, 13, 407, 700, 286, 486, 352, 2661, 322, 264, 5164, 51104, 51104, 21056, 293, 264, 9482, 293, 550, 286, 486, 5366, 24877, 293, 286, 486, 611, 4160, 51532, 51532], "temperature": 0.0, "avg_logprob": -0.20997725592719185, "compression_ratio": 1.5732484076433122, "no_speech_prob": 0.004175633192062378}, {"id": 2, "seek": 0, "start": 14.8, "end": 23.36, "text": " coordinates and the architecture and then I will introduce graphs and I will also remind", "tokens": [50364, 407, 2928, 1518, 281, 341, 7991, 322, 4295, 45216, 304, 9590, 13, 50608, 50768, 1033, 370, 341, 307, 264, 16387, 295, 264, 7991, 13, 407, 700, 286, 486, 352, 2661, 322, 264, 5164, 51104, 51104, 21056, 293, 264, 9482, 293, 550, 286, 486, 5366, 24877, 293, 286, 486, 611, 4160, 51532, 51532], "temperature": 0.0, "avg_logprob": -0.20997725592719185, "compression_ratio": 1.5732484076433122, "no_speech_prob": 0.004175633192062378}, {"id": 3, "seek": 2336, "start": 23.36, "end": 32.08, "text": " definitions of convolutions to extend it to graphs. Then I will present two classes of graph", "tokens": [50364, 21988, 295, 3754, 15892, 281, 10101, 309, 281, 24877, 13, 1396, 286, 486, 1974, 732, 5359, 295, 4295, 50800, 50800, 7158, 1719, 13, 440, 700, 472, 307, 437, 286, 818, 42761, 4295, 7158, 1719, 293, 264, 1150, 472, 307, 264, 23598, 51064, 51064, 4295, 7158, 1719, 13, 286, 486, 751, 257, 707, 857, 466, 18927, 278, 4295, 18161, 9590, 51320, 51320, 293, 2721, 286, 486, 16886, 13, 51376, 51568], "temperature": 0.0, "avg_logprob": -0.182083183610943, "compression_ratio": 1.7586206896551724, "no_speech_prob": 0.00024005674640648067}, {"id": 4, "seek": 2336, "start": 32.08, "end": 37.36, "text": " convenants. The first one is what I call spectral graph convenants and the second one is the spatial", "tokens": [50364, 21988, 295, 3754, 15892, 281, 10101, 309, 281, 24877, 13, 1396, 286, 486, 1974, 732, 5359, 295, 4295, 50800, 50800, 7158, 1719, 13, 440, 700, 472, 307, 437, 286, 818, 42761, 4295, 7158, 1719, 293, 264, 1150, 472, 307, 264, 23598, 51064, 51064, 4295, 7158, 1719, 13, 286, 486, 751, 257, 707, 857, 466, 18927, 278, 4295, 18161, 9590, 51320, 51320, 293, 2721, 286, 486, 16886, 13, 51376, 51568], "temperature": 0.0, "avg_logprob": -0.182083183610943, "compression_ratio": 1.7586206896551724, "no_speech_prob": 0.00024005674640648067}, {"id": 5, "seek": 2336, "start": 37.36, "end": 42.480000000000004, "text": " graph convenants. I will talk a little bit about benchmarking graph neural networks", "tokens": [50364, 21988, 295, 3754, 15892, 281, 10101, 309, 281, 24877, 13, 1396, 286, 486, 1974, 732, 5359, 295, 4295, 50800, 50800, 7158, 1719, 13, 440, 700, 472, 307, 437, 286, 818, 42761, 4295, 7158, 1719, 293, 264, 1150, 472, 307, 264, 23598, 51064, 51064, 4295, 7158, 1719, 13, 286, 486, 751, 257, 707, 857, 466, 18927, 278, 4295, 18161, 9590, 51320, 51320, 293, 2721, 286, 486, 16886, 13, 51376, 51568], "temperature": 0.0, "avg_logprob": -0.182083183610943, "compression_ratio": 1.7586206896551724, "no_speech_prob": 0.00024005674640648067}, {"id": 6, "seek": 2336, "start": 42.480000000000004, "end": 43.6, "text": " and finally I will conclude.", "tokens": [50364, 21988, 295, 3754, 15892, 281, 10101, 309, 281, 24877, 13, 1396, 286, 486, 1974, 732, 5359, 295, 4295, 50800, 50800, 7158, 1719, 13, 440, 700, 472, 307, 437, 286, 818, 42761, 4295, 7158, 1719, 293, 264, 1150, 472, 307, 264, 23598, 51064, 51064, 4295, 7158, 1719, 13, 286, 486, 751, 257, 707, 857, 466, 18927, 278, 4295, 18161, 9590, 51320, 51320, 293, 2721, 286, 486, 16886, 13, 51376, 51568], "temperature": 0.0, "avg_logprob": -0.182083183610943, "compression_ratio": 1.7586206896551724, "no_speech_prob": 0.00024005674640648067}, {"id": 7, "seek": 4360, "start": 43.6, "end": 52.0, "text": " Okay so let's start with the traditional coordinates. So we all know", "tokens": [50364, 1033, 370, 718, 311, 722, 365, 264, 5164, 21056, 13, 407, 321, 439, 458, 50784, 50784, 21056, 366, 257, 22397, 294, 3820, 5201, 13, 407, 562, 337, 264, 3256, 2533, 6211, 51156, 51156, 291, 458, 337, 264, 3256, 21538, 5633, 562, 264, 15670, 390, 1143, 436, 24436, 538, 1920, 51476, 51476, 257, 5952, 732, 264, 6713, 295, 21538, 13, 467, 390, 294, 9125, 293, 309, 390, 1936, 264, 917, 295, 51784, 51812], "temperature": 0.0, "avg_logprob": -0.2157768558811497, "compression_ratio": 1.7064676616915422, "no_speech_prob": 0.0001626823504921049}, {"id": 8, "seek": 4360, "start": 52.0, "end": 59.44, "text": " coordinates are a breakthrough in computer vision. So when for the image net competition", "tokens": [50364, 1033, 370, 718, 311, 722, 365, 264, 5164, 21056, 13, 407, 321, 439, 458, 50784, 50784, 21056, 366, 257, 22397, 294, 3820, 5201, 13, 407, 562, 337, 264, 3256, 2533, 6211, 51156, 51156, 291, 458, 337, 264, 3256, 21538, 5633, 562, 264, 15670, 390, 1143, 436, 24436, 538, 1920, 51476, 51476, 257, 5952, 732, 264, 6713, 295, 21538, 13, 467, 390, 294, 9125, 293, 309, 390, 1936, 264, 917, 295, 51784, 51812], "temperature": 0.0, "avg_logprob": -0.2157768558811497, "compression_ratio": 1.7064676616915422, "no_speech_prob": 0.0001626823504921049}, {"id": 9, "seek": 4360, "start": 59.44, "end": 65.84, "text": " you know for the image classification task when the coordinate was used they decreased by almost", "tokens": [50364, 1033, 370, 718, 311, 722, 365, 264, 5164, 21056, 13, 407, 321, 439, 458, 50784, 50784, 21056, 366, 257, 22397, 294, 3820, 5201, 13, 407, 562, 337, 264, 3256, 2533, 6211, 51156, 51156, 291, 458, 337, 264, 3256, 21538, 5633, 562, 264, 15670, 390, 1143, 436, 24436, 538, 1920, 51476, 51476, 257, 5952, 732, 264, 6713, 295, 21538, 13, 467, 390, 294, 9125, 293, 309, 390, 1936, 264, 917, 295, 51784, 51812], "temperature": 0.0, "avg_logprob": -0.2157768558811497, "compression_ratio": 1.7064676616915422, "no_speech_prob": 0.0001626823504921049}, {"id": 10, "seek": 4360, "start": 65.84, "end": 72.0, "text": " a factor two the error of classification. It was in 2012 and it was basically the end of", "tokens": [50364, 1033, 370, 718, 311, 722, 365, 264, 5164, 21056, 13, 407, 321, 439, 458, 50784, 50784, 21056, 366, 257, 22397, 294, 3820, 5201, 13, 407, 562, 337, 264, 3256, 2533, 6211, 51156, 51156, 291, 458, 337, 264, 3256, 21538, 5633, 562, 264, 15670, 390, 1143, 436, 24436, 538, 1920, 51476, 51476, 257, 5952, 732, 264, 6713, 295, 21538, 13, 467, 390, 294, 9125, 293, 309, 390, 1936, 264, 917, 295, 51784, 51812], "temperature": 0.0, "avg_logprob": -0.2157768558811497, "compression_ratio": 1.7064676616915422, "no_speech_prob": 0.0001626823504921049}, {"id": 11, "seek": 7200, "start": 72.0, "end": 78.96, "text": " encrafting features and we shift the paradigm to and crafting learning systems. And now for this", "tokens": [50364, 2058, 10437, 783, 4122, 293, 321, 5513, 264, 24709, 281, 293, 29048, 2539, 3652, 13, 400, 586, 337, 341, 50712, 50712, 588, 2685, 5633, 321, 439, 458, 300, 321, 352, 281, 1687, 18796, 3389, 13, 2656, 85, 77, 1385, 366, 611, 51108, 51180, 257, 22397, 294, 6218, 293, 3303, 2856, 9007, 370, 412, 4384, 562, 291, 528, 281, 51376, 51376, 13799, 291, 366, 611, 1228, 21056, 13, 407, 21056, 366, 4005, 6331, 1303, 281, 51804, 51804], "temperature": 0.0, "avg_logprob": -0.2509263601058569, "compression_ratio": 1.6318181818181818, "no_speech_prob": 5.018887895857915e-05}, {"id": 12, "seek": 7200, "start": 78.96, "end": 86.88, "text": " very specific task we all know that we go to superhuman performance. Convnets are also", "tokens": [50364, 2058, 10437, 783, 4122, 293, 321, 5513, 264, 24709, 281, 293, 29048, 2539, 3652, 13, 400, 586, 337, 341, 50712, 50712, 588, 2685, 5633, 321, 439, 458, 300, 321, 352, 281, 1687, 18796, 3389, 13, 2656, 85, 77, 1385, 366, 611, 51108, 51180, 257, 22397, 294, 6218, 293, 3303, 2856, 9007, 370, 412, 4384, 562, 291, 528, 281, 51376, 51376, 13799, 291, 366, 611, 1228, 21056, 13, 407, 21056, 366, 4005, 6331, 1303, 281, 51804, 51804], "temperature": 0.0, "avg_logprob": -0.2509263601058569, "compression_ratio": 1.6318181818181818, "no_speech_prob": 5.018887895857915e-05}, {"id": 13, "seek": 7200, "start": 88.32, "end": 92.24000000000001, "text": " a breakthrough in speech and natural language processing so at Facebook when you want to", "tokens": [50364, 2058, 10437, 783, 4122, 293, 321, 5513, 264, 24709, 281, 293, 29048, 2539, 3652, 13, 400, 586, 337, 341, 50712, 50712, 588, 2685, 5633, 321, 439, 458, 300, 321, 352, 281, 1687, 18796, 3389, 13, 2656, 85, 77, 1385, 366, 611, 51108, 51180, 257, 22397, 294, 6218, 293, 3303, 2856, 9007, 370, 412, 4384, 562, 291, 528, 281, 51376, 51376, 13799, 291, 366, 611, 1228, 21056, 13, 407, 21056, 366, 4005, 6331, 1303, 281, 51804, 51804], "temperature": 0.0, "avg_logprob": -0.2509263601058569, "compression_ratio": 1.6318181818181818, "no_speech_prob": 5.018887895857915e-05}, {"id": 14, "seek": 7200, "start": 92.24000000000001, "end": 100.8, "text": " translate you are also using coordinates. So coordinates are powerful architectures to", "tokens": [50364, 2058, 10437, 783, 4122, 293, 321, 5513, 264, 24709, 281, 293, 29048, 2539, 3652, 13, 400, 586, 337, 341, 50712, 50712, 588, 2685, 5633, 321, 439, 458, 300, 321, 352, 281, 1687, 18796, 3389, 13, 2656, 85, 77, 1385, 366, 611, 51108, 51180, 257, 22397, 294, 6218, 293, 3303, 2856, 9007, 370, 412, 4384, 562, 291, 528, 281, 51376, 51376, 13799, 291, 366, 611, 1228, 21056, 13, 407, 21056, 366, 4005, 6331, 1303, 281, 51804, 51804], "temperature": 0.0, "avg_logprob": -0.2509263601058569, "compression_ratio": 1.6318181818181818, "no_speech_prob": 5.018887895857915e-05}, {"id": 15, "seek": 10080, "start": 100.8, "end": 105.92, "text": " actually solve high dimensional learning problems. So we all know about the curse of dimensionality.", "tokens": [50364, 767, 5039, 1090, 18795, 2539, 2740, 13, 407, 321, 439, 458, 466, 264, 17139, 295, 10139, 1860, 13, 50620, 50620, 407, 498, 291, 362, 364, 3256, 718, 311, 584, 538, 9714, 18668, 370, 291, 362, 502, 2459, 9102, 370, 364, 3256, 393, 312, 51020, 51020, 1612, 382, 257, 935, 294, 257, 1901, 295, 502, 2459, 12819, 293, 337, 1184, 10139, 498, 291, 6889, 538, 1228, 51352, 51412, 538, 1228, 1266, 10938, 550, 291, 362, 1266, 281, 264, 1347, 502, 2459, 1944, 5267, 13, 407, 613, 3755, 366, 51740, 51740], "temperature": 0.0, "avg_logprob": -0.20025760524875516, "compression_ratio": 1.8156682027649769, "no_speech_prob": 3.7388668715720996e-05}, {"id": 16, "seek": 10080, "start": 105.92, "end": 113.92, "text": " So if you have an image let's say by 1000 pixels so you have 1 million variables so an image can be", "tokens": [50364, 767, 5039, 1090, 18795, 2539, 2740, 13, 407, 321, 439, 458, 466, 264, 17139, 295, 10139, 1860, 13, 50620, 50620, 407, 498, 291, 362, 364, 3256, 718, 311, 584, 538, 9714, 18668, 370, 291, 362, 502, 2459, 9102, 370, 364, 3256, 393, 312, 51020, 51020, 1612, 382, 257, 935, 294, 257, 1901, 295, 502, 2459, 12819, 293, 337, 1184, 10139, 498, 291, 6889, 538, 1228, 51352, 51412, 538, 1228, 1266, 10938, 550, 291, 362, 1266, 281, 264, 1347, 502, 2459, 1944, 5267, 13, 407, 613, 3755, 366, 51740, 51740], "temperature": 0.0, "avg_logprob": -0.20025760524875516, "compression_ratio": 1.8156682027649769, "no_speech_prob": 3.7388668715720996e-05}, {"id": 17, "seek": 10080, "start": 113.92, "end": 120.56, "text": " seen as a point in a space of 1 million dimensions and for each dimension if you sample by using", "tokens": [50364, 767, 5039, 1090, 18795, 2539, 2740, 13, 407, 321, 439, 458, 466, 264, 17139, 295, 10139, 1860, 13, 50620, 50620, 407, 498, 291, 362, 364, 3256, 718, 311, 584, 538, 9714, 18668, 370, 291, 362, 502, 2459, 9102, 370, 364, 3256, 393, 312, 51020, 51020, 1612, 382, 257, 935, 294, 257, 1901, 295, 502, 2459, 12819, 293, 337, 1184, 10139, 498, 291, 6889, 538, 1228, 51352, 51412, 538, 1228, 1266, 10938, 550, 291, 362, 1266, 281, 264, 1347, 502, 2459, 1944, 5267, 13, 407, 613, 3755, 366, 51740, 51740], "temperature": 0.0, "avg_logprob": -0.20025760524875516, "compression_ratio": 1.8156682027649769, "no_speech_prob": 3.7388668715720996e-05}, {"id": 18, "seek": 10080, "start": 121.75999999999999, "end": 128.32, "text": " by using 10 samples then you have 10 to the power 1 million possible images. So these pieces are", "tokens": [50364, 767, 5039, 1090, 18795, 2539, 2740, 13, 407, 321, 439, 458, 466, 264, 17139, 295, 10139, 1860, 13, 50620, 50620, 407, 498, 291, 362, 364, 3256, 718, 311, 584, 538, 9714, 18668, 370, 291, 362, 502, 2459, 9102, 370, 364, 3256, 393, 312, 51020, 51020, 1612, 382, 257, 935, 294, 257, 1901, 295, 502, 2459, 12819, 293, 337, 1184, 10139, 498, 291, 6889, 538, 1228, 51352, 51412, 538, 1228, 1266, 10938, 550, 291, 362, 1266, 281, 264, 1347, 502, 2459, 1944, 5267, 13, 407, 613, 3755, 366, 51740, 51740], "temperature": 0.0, "avg_logprob": -0.20025760524875516, "compression_ratio": 1.8156682027649769, "no_speech_prob": 3.7388668715720996e-05}, {"id": 19, "seek": 12832, "start": 128.32, "end": 134.64, "text": " really huge and of course this is the question how do you find the needle of information in this big", "tokens": [50364, 534, 2603, 293, 295, 1164, 341, 307, 264, 1168, 577, 360, 291, 915, 264, 11037, 295, 1589, 294, 341, 955, 50680, 50680, 4842, 372, 501, 13, 407, 21056, 366, 534, 4005, 281, 8947, 1936, 341, 1589, 264, 51000, 51000, 1151, 1944, 10290, 295, 428, 3256, 1412, 281, 5039, 2740, 13, 2720, 1164, 321, 500, 380, 458, 1939, 51428, 51428, 1203, 466, 1338, 321, 500, 380, 458, 1939, 1203, 466, 21056, 370, 309, 311, 257, 733, 295, 257, 14660, 577, 51820], "temperature": 0.0, "avg_logprob": -0.11584873897273366, "compression_ratio": 1.7568807339449541, "no_speech_prob": 1.9286961105535738e-05}, {"id": 20, "seek": 12832, "start": 134.64, "end": 141.04, "text": " haystack. So coordinates are really powerful to extract basically this information the", "tokens": [50364, 534, 2603, 293, 295, 1164, 341, 307, 264, 1168, 577, 360, 291, 915, 264, 11037, 295, 1589, 294, 341, 955, 50680, 50680, 4842, 372, 501, 13, 407, 21056, 366, 534, 4005, 281, 8947, 1936, 341, 1589, 264, 51000, 51000, 1151, 1944, 10290, 295, 428, 3256, 1412, 281, 5039, 2740, 13, 2720, 1164, 321, 500, 380, 458, 1939, 51428, 51428, 1203, 466, 1338, 321, 500, 380, 458, 1939, 1203, 466, 21056, 370, 309, 311, 257, 733, 295, 257, 14660, 577, 51820], "temperature": 0.0, "avg_logprob": -0.11584873897273366, "compression_ratio": 1.7568807339449541, "no_speech_prob": 1.9286961105535738e-05}, {"id": 21, "seek": 12832, "start": 141.04, "end": 149.6, "text": " best possible representation of your image data to solve problems. Of course we don't know yet", "tokens": [50364, 534, 2603, 293, 295, 1164, 341, 307, 264, 1168, 577, 360, 291, 915, 264, 11037, 295, 1589, 294, 341, 955, 50680, 50680, 4842, 372, 501, 13, 407, 21056, 366, 534, 4005, 281, 8947, 1936, 341, 1589, 264, 51000, 51000, 1151, 1944, 10290, 295, 428, 3256, 1412, 281, 5039, 2740, 13, 2720, 1164, 321, 500, 380, 458, 1939, 51428, 51428, 1203, 466, 1338, 321, 500, 380, 458, 1939, 1203, 466, 21056, 370, 309, 311, 257, 733, 295, 257, 14660, 577, 51820], "temperature": 0.0, "avg_logprob": -0.11584873897273366, "compression_ratio": 1.7568807339449541, "no_speech_prob": 1.9286961105535738e-05}, {"id": 22, "seek": 14960, "start": 149.6, "end": 158.64, "text": " everything about yeah we don't know yet everything about Convnets so it's a kind of a miracle how", "tokens": [50364, 1203, 466, 1338, 321, 500, 380, 458, 1939, 1203, 466, 2656, 85, 77, 1385, 370, 309, 311, 257, 733, 295, 257, 14660, 577, 50816, 50816, 4005, 577, 665, 436, 366, 293, 309, 311, 611, 1596, 4670, 570, 341, 9870, 867, 2132, 3179, 51156, 51156, 281, 1223, 1101, 293, 281, 1499, 777, 6331, 1303, 13, 1033, 370, 562, 291, 764, 2656, 85, 77, 1385, 291, 366, 884, 364, 51608, 51608], "temperature": 0.0, "avg_logprob": -0.11975484498789613, "compression_ratio": 1.5638297872340425, "no_speech_prob": 2.0691661120508797e-05}, {"id": 23, "seek": 14960, "start": 158.64, "end": 165.44, "text": " powerful how good they are and it's also quite exciting because this opens many research areas", "tokens": [50364, 1203, 466, 1338, 321, 500, 380, 458, 1939, 1203, 466, 2656, 85, 77, 1385, 370, 309, 311, 257, 733, 295, 257, 14660, 577, 50816, 50816, 4005, 577, 665, 436, 366, 293, 309, 311, 611, 1596, 4670, 570, 341, 9870, 867, 2132, 3179, 51156, 51156, 281, 1223, 1101, 293, 281, 1499, 777, 6331, 1303, 13, 1033, 370, 562, 291, 764, 2656, 85, 77, 1385, 291, 366, 884, 364, 51608, 51608], "temperature": 0.0, "avg_logprob": -0.11975484498789613, "compression_ratio": 1.5638297872340425, "no_speech_prob": 2.0691661120508797e-05}, {"id": 24, "seek": 14960, "start": 165.44, "end": 174.48, "text": " to understand better and to develop new architectures. Okay so when you use Convnets you are doing an", "tokens": [50364, 1203, 466, 1338, 321, 500, 380, 458, 1939, 1203, 466, 2656, 85, 77, 1385, 370, 309, 311, 257, 733, 295, 257, 14660, 577, 50816, 50816, 4005, 577, 665, 436, 366, 293, 309, 311, 611, 1596, 4670, 570, 341, 9870, 867, 2132, 3179, 51156, 51156, 281, 1223, 1101, 293, 281, 1499, 777, 6331, 1303, 13, 1033, 370, 562, 291, 764, 2656, 85, 77, 1385, 291, 366, 884, 364, 51608, 51608], "temperature": 0.0, "avg_logprob": -0.11975484498789613, "compression_ratio": 1.5638297872340425, "no_speech_prob": 2.0691661120508797e-05}, {"id": 25, "seek": 17448, "start": 174.48, "end": 181.51999999999998, "text": " assumption and the main assumption that you are using is that your data so images videos speech", "tokens": [50364, 15302, 293, 264, 2135, 15302, 300, 291, 366, 1228, 307, 300, 428, 1412, 370, 5267, 2145, 6218, 50716, 50716, 307, 10199, 2628, 13, 467, 1355, 300, 309, 307, 1254, 295, 8294, 300, 366, 2654, 370, 291, 458, 341, 307, 264, 51048, 51048, 13150, 295, 9681, 293, 5056, 370, 498, 291, 366, 322, 341, 4583, 337, 341, 34090, 341, 34090, 307, 516, 51308, 51308, 281, 312, 4582, 281, 257, 1326, 22027, 294, 264, 3894, 4583, 293, 406, 439, 22027, 1392, 370, 341, 307, 264, 2654, 51580, 51580], "temperature": 0.0, "avg_logprob": -0.09863621538335626, "compression_ratio": 1.883495145631068, "no_speech_prob": 0.00010580600792309269}, {"id": 26, "seek": 17448, "start": 181.51999999999998, "end": 188.16, "text": " is compositional. It means that it is form of patterns that are local so you know this is the", "tokens": [50364, 15302, 293, 264, 2135, 15302, 300, 291, 366, 1228, 307, 300, 428, 1412, 370, 5267, 2145, 6218, 50716, 50716, 307, 10199, 2628, 13, 467, 1355, 300, 309, 307, 1254, 295, 8294, 300, 366, 2654, 370, 291, 458, 341, 307, 264, 51048, 51048, 13150, 295, 9681, 293, 5056, 370, 498, 291, 366, 322, 341, 4583, 337, 341, 34090, 341, 34090, 307, 516, 51308, 51308, 281, 312, 4582, 281, 257, 1326, 22027, 294, 264, 3894, 4583, 293, 406, 439, 22027, 1392, 370, 341, 307, 264, 2654, 51580, 51580], "temperature": 0.0, "avg_logprob": -0.09863621538335626, "compression_ratio": 1.883495145631068, "no_speech_prob": 0.00010580600792309269}, {"id": 27, "seek": 17448, "start": 188.16, "end": 193.35999999999999, "text": " contribution of urban and visual so if you are on this layer for this neuron this neuron is going", "tokens": [50364, 15302, 293, 264, 2135, 15302, 300, 291, 366, 1228, 307, 300, 428, 1412, 370, 5267, 2145, 6218, 50716, 50716, 307, 10199, 2628, 13, 467, 1355, 300, 309, 307, 1254, 295, 8294, 300, 366, 2654, 370, 291, 458, 341, 307, 264, 51048, 51048, 13150, 295, 9681, 293, 5056, 370, 498, 291, 366, 322, 341, 4583, 337, 341, 34090, 341, 34090, 307, 516, 51308, 51308, 281, 312, 4582, 281, 257, 1326, 22027, 294, 264, 3894, 4583, 293, 406, 439, 22027, 1392, 370, 341, 307, 264, 2654, 51580, 51580], "temperature": 0.0, "avg_logprob": -0.09863621538335626, "compression_ratio": 1.883495145631068, "no_speech_prob": 0.00010580600792309269}, {"id": 28, "seek": 17448, "start": 193.35999999999999, "end": 198.79999999999998, "text": " to be connected to a few neurons in the previous layer and not all neurons okay so this is the local", "tokens": [50364, 15302, 293, 264, 2135, 15302, 300, 291, 366, 1228, 307, 300, 428, 1412, 370, 5267, 2145, 6218, 50716, 50716, 307, 10199, 2628, 13, 467, 1355, 300, 309, 307, 1254, 295, 8294, 300, 366, 2654, 370, 291, 458, 341, 307, 264, 51048, 51048, 13150, 295, 9681, 293, 5056, 370, 498, 291, 366, 322, 341, 4583, 337, 341, 34090, 341, 34090, 307, 516, 51308, 51308, 281, 312, 4582, 281, 257, 1326, 22027, 294, 264, 3894, 4583, 293, 406, 439, 22027, 1392, 370, 341, 307, 264, 2654, 51580, 51580], "temperature": 0.0, "avg_logprob": -0.09863621538335626, "compression_ratio": 1.883495145631068, "no_speech_prob": 0.00010580600792309269}, {"id": 29, "seek": 19880, "start": 198.8, "end": 206.48000000000002, "text": " reception field assumption. Then you have also the property of stationary stationarity so basically", "tokens": [50364, 21682, 2519, 15302, 13, 1396, 291, 362, 611, 264, 4707, 295, 30452, 5214, 17409, 370, 1936, 50748, 50748, 291, 362, 512, 8294, 300, 366, 2531, 293, 300, 366, 5507, 2108, 428, 3256, 9274, 1392, 370, 411, 51156, 51156, 264, 5566, 26531, 293, 264, 3344, 26531, 370, 436, 366, 436, 366, 439, 2531, 281, 1184, 661, 13, 51432, 51472, 440, 1036, 4707, 307, 35250, 804, 370, 291, 652, 264, 15302, 300, 428, 1412, 307, 35250, 804, 294, 264, 51800, 51800], "temperature": 0.0, "avg_logprob": -0.09600791224726925, "compression_ratio": 1.9104477611940298, "no_speech_prob": 3.155973899993114e-05}, {"id": 30, "seek": 19880, "start": 206.48000000000002, "end": 214.64000000000001, "text": " you have some patterns that are similar and that are shared across your image domain okay so like", "tokens": [50364, 21682, 2519, 15302, 13, 1396, 291, 362, 611, 264, 4707, 295, 30452, 5214, 17409, 370, 1936, 50748, 50748, 291, 362, 512, 8294, 300, 366, 2531, 293, 300, 366, 5507, 2108, 428, 3256, 9274, 1392, 370, 411, 51156, 51156, 264, 5566, 26531, 293, 264, 3344, 26531, 370, 436, 366, 436, 366, 439, 2531, 281, 1184, 661, 13, 51432, 51472, 440, 1036, 4707, 307, 35250, 804, 370, 291, 652, 264, 15302, 300, 428, 1412, 307, 35250, 804, 294, 264, 51800, 51800], "temperature": 0.0, "avg_logprob": -0.09600791224726925, "compression_ratio": 1.9104477611940298, "no_speech_prob": 3.155973899993114e-05}, {"id": 31, "seek": 19880, "start": 214.64000000000001, "end": 220.16000000000003, "text": " the yellow patches and the blue patches so they are they are all similar to each other.", "tokens": [50364, 21682, 2519, 15302, 13, 1396, 291, 362, 611, 264, 4707, 295, 30452, 5214, 17409, 370, 1936, 50748, 50748, 291, 362, 512, 8294, 300, 366, 2531, 293, 300, 366, 5507, 2108, 428, 3256, 9274, 1392, 370, 411, 51156, 51156, 264, 5566, 26531, 293, 264, 3344, 26531, 370, 436, 366, 436, 366, 439, 2531, 281, 1184, 661, 13, 51432, 51472, 440, 1036, 4707, 307, 35250, 804, 370, 291, 652, 264, 15302, 300, 428, 1412, 307, 35250, 804, 294, 264, 51800, 51800], "temperature": 0.0, "avg_logprob": -0.09600791224726925, "compression_ratio": 1.9104477611940298, "no_speech_prob": 3.155973899993114e-05}, {"id": 32, "seek": 19880, "start": 220.96, "end": 227.52, "text": " The last property is hierarchical so you make the assumption that your data is hierarchical in the", "tokens": [50364, 21682, 2519, 15302, 13, 1396, 291, 362, 611, 264, 4707, 295, 30452, 5214, 17409, 370, 1936, 50748, 50748, 291, 362, 512, 8294, 300, 366, 2531, 293, 300, 366, 5507, 2108, 428, 3256, 9274, 1392, 370, 411, 51156, 51156, 264, 5566, 26531, 293, 264, 3344, 26531, 370, 436, 366, 436, 366, 439, 2531, 281, 1184, 661, 13, 51432, 51472, 440, 1036, 4707, 307, 35250, 804, 370, 291, 652, 264, 15302, 300, 428, 1412, 307, 35250, 804, 294, 264, 51800, 51800], "temperature": 0.0, "avg_logprob": -0.09600791224726925, "compression_ratio": 1.9104477611940298, "no_speech_prob": 3.155973899993114e-05}, {"id": 33, "seek": 22752, "start": 227.52, "end": 234.48000000000002, "text": " sense that your low level features are going to be combined together to form medium level", "tokens": [50364, 2020, 300, 428, 2295, 1496, 4122, 366, 516, 281, 312, 9354, 1214, 281, 1254, 6399, 1496, 50712, 50752, 4122, 293, 550, 341, 6399, 4111, 366, 516, 281, 312, 797, 9354, 281, 1184, 661, 281, 1254, 2946, 51068, 51068, 293, 2946, 12649, 4122, 13, 407, 604, 2656, 85, 7129, 589, 264, 912, 636, 370, 264, 700, 644, 295, 264, 51500, 51500, 9482, 307, 281, 8947, 613, 2615, 1966, 4122, 293, 550, 264, 1150, 644, 486, 312, 281, 51764, 51764], "temperature": 0.0, "avg_logprob": -0.09108308553695679, "compression_ratio": 1.8963730569948187, "no_speech_prob": 3.415144237806089e-05}, {"id": 34, "seek": 22752, "start": 235.28, "end": 241.60000000000002, "text": " features and then this medium feature are going to be again combined to each other to form higher", "tokens": [50364, 2020, 300, 428, 2295, 1496, 4122, 366, 516, 281, 312, 9354, 1214, 281, 1254, 6399, 1496, 50712, 50752, 4122, 293, 550, 341, 6399, 4111, 366, 516, 281, 312, 797, 9354, 281, 1184, 661, 281, 1254, 2946, 51068, 51068, 293, 2946, 12649, 4122, 13, 407, 604, 2656, 85, 7129, 589, 264, 912, 636, 370, 264, 700, 644, 295, 264, 51500, 51500, 9482, 307, 281, 8947, 613, 2615, 1966, 4122, 293, 550, 264, 1150, 644, 486, 312, 281, 51764, 51764], "temperature": 0.0, "avg_logprob": -0.09108308553695679, "compression_ratio": 1.8963730569948187, "no_speech_prob": 3.415144237806089e-05}, {"id": 35, "seek": 22752, "start": 241.60000000000002, "end": 250.24, "text": " and higher abstract features. So any Convnet work the same way so the first part of the", "tokens": [50364, 2020, 300, 428, 2295, 1496, 4122, 366, 516, 281, 312, 9354, 1214, 281, 1254, 6399, 1496, 50712, 50752, 4122, 293, 550, 341, 6399, 4111, 366, 516, 281, 312, 797, 9354, 281, 1184, 661, 281, 1254, 2946, 51068, 51068, 293, 2946, 12649, 4122, 13, 407, 604, 2656, 85, 7129, 589, 264, 912, 636, 370, 264, 700, 644, 295, 264, 51500, 51500, 9482, 307, 281, 8947, 613, 2615, 1966, 4122, 293, 550, 264, 1150, 644, 486, 312, 281, 51764, 51764], "temperature": 0.0, "avg_logprob": -0.09108308553695679, "compression_ratio": 1.8963730569948187, "no_speech_prob": 3.415144237806089e-05}, {"id": 36, "seek": 22752, "start": 250.24, "end": 255.52, "text": " architecture is to extract these conversional features and then the second part will be to", "tokens": [50364, 2020, 300, 428, 2295, 1496, 4122, 366, 516, 281, 312, 9354, 1214, 281, 1254, 6399, 1496, 50712, 50752, 4122, 293, 550, 341, 6399, 4111, 366, 516, 281, 312, 797, 9354, 281, 1184, 661, 281, 1254, 2946, 51068, 51068, 293, 2946, 12649, 4122, 13, 407, 604, 2656, 85, 7129, 589, 264, 912, 636, 370, 264, 700, 644, 295, 264, 51500, 51500, 9482, 307, 281, 8947, 613, 2615, 1966, 4122, 293, 550, 264, 1150, 644, 486, 312, 281, 51764, 51764], "temperature": 0.0, "avg_logprob": -0.09108308553695679, "compression_ratio": 1.8963730569948187, "no_speech_prob": 3.415144237806089e-05}, {"id": 37, "seek": 25552, "start": 255.52, "end": 262.48, "text": " solve your specific task you know like classification, recommendation and so on and this is what we call", "tokens": [50364, 5039, 428, 2685, 5633, 291, 458, 411, 21538, 11, 11879, 293, 370, 322, 293, 341, 307, 437, 321, 818, 50712, 50712, 291, 458, 917, 12, 1353, 12, 521, 3652, 293, 264, 700, 644, 307, 281, 1466, 264, 4122, 264, 1150, 644, 307, 281, 5039, 428, 5633, 13, 50960, 51148, 1033, 718, 311, 536, 544, 13402, 437, 307, 264, 1412, 9274, 370, 498, 291, 362, 5267, 11, 51556, 51584], "temperature": 0.0, "avg_logprob": -0.17201187951224192, "compression_ratio": 1.6590909090909092, "no_speech_prob": 7.095744877005927e-06}, {"id": 38, "seek": 25552, "start": 262.48, "end": 267.44, "text": " you know end-to-end systems and the first part is to learn the features the second part is to solve your task.", "tokens": [50364, 5039, 428, 2685, 5633, 291, 458, 411, 21538, 11, 11879, 293, 370, 322, 293, 341, 307, 437, 321, 818, 50712, 50712, 291, 458, 917, 12, 1353, 12, 521, 3652, 293, 264, 700, 644, 307, 281, 1466, 264, 4122, 264, 1150, 644, 307, 281, 5039, 428, 5633, 13, 50960, 51148, 1033, 718, 311, 536, 544, 13402, 437, 307, 264, 1412, 9274, 370, 498, 291, 362, 5267, 11, 51556, 51584], "temperature": 0.0, "avg_logprob": -0.17201187951224192, "compression_ratio": 1.6590909090909092, "no_speech_prob": 7.095744877005927e-06}, {"id": 39, "seek": 25552, "start": 271.2, "end": 279.36, "text": " Okay let's see more precisely what is the data domain so if you have images,", "tokens": [50364, 5039, 428, 2685, 5633, 291, 458, 411, 21538, 11, 11879, 293, 370, 322, 293, 341, 307, 437, 321, 818, 50712, 50712, 291, 458, 917, 12, 1353, 12, 521, 3652, 293, 264, 700, 644, 307, 281, 1466, 264, 4122, 264, 1150, 644, 307, 281, 5039, 428, 5633, 13, 50960, 51148, 1033, 718, 311, 536, 544, 13402, 437, 307, 264, 1412, 9274, 370, 498, 291, 362, 5267, 11, 51556, 51584], "temperature": 0.0, "avg_logprob": -0.17201187951224192, "compression_ratio": 1.6590909090909092, "no_speech_prob": 7.095744877005927e-06}, {"id": 40, "seek": 27936, "start": 279.36, "end": 286.40000000000003, "text": " images, volumes or videos basically so for example you can see this image and if you zoom in this image", "tokens": [50364, 5267, 11, 22219, 420, 2145, 1936, 370, 337, 1365, 291, 393, 536, 341, 3256, 293, 498, 291, 8863, 294, 341, 3256, 50716, 50716, 437, 291, 362, 307, 257, 568, 35, 10748, 1392, 291, 362, 257, 568, 35, 10748, 341, 307, 264, 3877, 295, 264, 9274, 295, 341, 3256, 51156, 51156, 293, 322, 264, 1192, 295, 341, 10748, 291, 362, 512, 4122, 370, 337, 1365, 294, 264, 1389, 295, 2017, 3256, 291, 486, 51476, 51476], "temperature": 0.0, "avg_logprob": -0.13849248384174548, "compression_ratio": 1.8545454545454545, "no_speech_prob": 1.3159681657270994e-05}, {"id": 41, "seek": 27936, "start": 286.40000000000003, "end": 295.2, "text": " what you have is a 2D grid okay you have a 2D grid this is the structure of the domain of this image", "tokens": [50364, 5267, 11, 22219, 420, 2145, 1936, 370, 337, 1365, 291, 393, 536, 341, 3256, 293, 498, 291, 8863, 294, 341, 3256, 50716, 50716, 437, 291, 362, 307, 257, 568, 35, 10748, 1392, 291, 362, 257, 568, 35, 10748, 341, 307, 264, 3877, 295, 264, 9274, 295, 341, 3256, 51156, 51156, 293, 322, 264, 1192, 295, 341, 10748, 291, 362, 512, 4122, 370, 337, 1365, 294, 264, 1389, 295, 2017, 3256, 291, 486, 51476, 51476], "temperature": 0.0, "avg_logprob": -0.13849248384174548, "compression_ratio": 1.8545454545454545, "no_speech_prob": 1.3159681657270994e-05}, {"id": 42, "seek": 27936, "start": 295.2, "end": 301.6, "text": " and on the top of this grid you have some features so for example in the case of color image you will", "tokens": [50364, 5267, 11, 22219, 420, 2145, 1936, 370, 337, 1365, 291, 393, 536, 341, 3256, 293, 498, 291, 8863, 294, 341, 3256, 50716, 50716, 437, 291, 362, 307, 257, 568, 35, 10748, 1392, 291, 362, 257, 568, 35, 10748, 341, 307, 264, 3877, 295, 264, 9274, 295, 341, 3256, 51156, 51156, 293, 322, 264, 1192, 295, 341, 10748, 291, 362, 512, 4122, 370, 337, 1365, 294, 264, 1389, 295, 2017, 3256, 291, 486, 51476, 51476], "temperature": 0.0, "avg_logprob": -0.13849248384174548, "compression_ratio": 1.8545454545454545, "no_speech_prob": 1.3159681657270994e-05}, {"id": 43, "seek": 30160, "start": 301.6, "end": 311.68, "text": " have three features which are red, green and blue okay now if I'm looking at natural language", "tokens": [50364, 362, 1045, 4122, 597, 366, 2182, 11, 3092, 293, 3344, 1392, 586, 498, 286, 478, 1237, 412, 3303, 2856, 50868, 50868, 9007, 370, 411, 16579, 291, 486, 362, 257, 8310, 295, 2283, 293, 1936, 291, 393, 536, 300, 51168, 51168, 291, 458, 382, 257, 502, 35, 10748, 293, 322, 264, 1192, 295, 341, 10748, 337, 1184, 9984, 295, 264, 10748, 291, 486, 362, 257, 1349, 51504, 51504, 1392, 370, 257, 1349, 393, 312, 10379, 538, 445, 364, 24922, 337, 1365, 264, 912, 611, 337, 6218, 51844], "temperature": 0.0, "avg_logprob": -0.07736480236053467, "compression_ratio": 1.6846846846846846, "no_speech_prob": 1.1279557838861365e-05}, {"id": 44, "seek": 30160, "start": 311.68, "end": 317.68, "text": " processing so like sentences you will have a sequence of words and basically you can see that", "tokens": [50364, 362, 1045, 4122, 597, 366, 2182, 11, 3092, 293, 3344, 1392, 586, 498, 286, 478, 1237, 412, 3303, 2856, 50868, 50868, 9007, 370, 411, 16579, 291, 486, 362, 257, 8310, 295, 2283, 293, 1936, 291, 393, 536, 300, 51168, 51168, 291, 458, 382, 257, 502, 35, 10748, 293, 322, 264, 1192, 295, 341, 10748, 337, 1184, 9984, 295, 264, 10748, 291, 486, 362, 257, 1349, 51504, 51504, 1392, 370, 257, 1349, 393, 312, 10379, 538, 445, 364, 24922, 337, 1365, 264, 912, 611, 337, 6218, 51844], "temperature": 0.0, "avg_logprob": -0.07736480236053467, "compression_ratio": 1.6846846846846846, "no_speech_prob": 1.1279557838861365e-05}, {"id": 45, "seek": 30160, "start": 317.68, "end": 324.40000000000003, "text": " you know as a 1D grid and on the top of this grid for each node of the grid you will have a word", "tokens": [50364, 362, 1045, 4122, 597, 366, 2182, 11, 3092, 293, 3344, 1392, 586, 498, 286, 478, 1237, 412, 3303, 2856, 50868, 50868, 9007, 370, 411, 16579, 291, 486, 362, 257, 8310, 295, 2283, 293, 1936, 291, 393, 536, 300, 51168, 51168, 291, 458, 382, 257, 502, 35, 10748, 293, 322, 264, 1192, 295, 341, 10748, 337, 1184, 9984, 295, 264, 10748, 291, 486, 362, 257, 1349, 51504, 51504, 1392, 370, 257, 1349, 393, 312, 10379, 538, 445, 364, 24922, 337, 1365, 264, 912, 611, 337, 6218, 51844], "temperature": 0.0, "avg_logprob": -0.07736480236053467, "compression_ratio": 1.6846846846846846, "no_speech_prob": 1.1279557838861365e-05}, {"id": 46, "seek": 32440, "start": 324.4, "end": 331.59999999999997, "text": " okay so a word can be represented by just an integer for example the same also for speech", "tokens": [50364, 1392, 370, 257, 1349, 393, 312, 10379, 538, 445, 364, 24922, 337, 1365, 264, 912, 611, 337, 6218, 50724, 50724, 370, 437, 291, 536, 510, 307, 264, 12990, 295, 264, 1988, 3321, 293, 309, 311, 264, 912, 291, 458, 309, 311, 411, 51020, 51020, 291, 362, 264, 1406, 307, 257, 502, 35, 10748, 293, 337, 1184, 9984, 295, 264, 10748, 291, 486, 362, 264, 51376, 51376, 264, 1988, 3321, 2158, 1392, 597, 307, 257, 957, 1230, 370, 286, 519, 309, 311, 1850, 321, 439, 764, 439, 264, 565, 51804, 51804], "temperature": 0.0, "avg_logprob": -0.09118975763735564, "compression_ratio": 1.7285714285714286, "no_speech_prob": 5.0973078032257035e-05}, {"id": 47, "seek": 32440, "start": 331.59999999999997, "end": 337.52, "text": " so what you see here is the variation of the air pressure and it's the same you know it's like", "tokens": [50364, 1392, 370, 257, 1349, 393, 312, 10379, 538, 445, 364, 24922, 337, 1365, 264, 912, 611, 337, 6218, 50724, 50724, 370, 437, 291, 536, 510, 307, 264, 12990, 295, 264, 1988, 3321, 293, 309, 311, 264, 912, 291, 458, 309, 311, 411, 51020, 51020, 291, 362, 264, 1406, 307, 257, 502, 35, 10748, 293, 337, 1184, 9984, 295, 264, 10748, 291, 486, 362, 264, 51376, 51376, 264, 1988, 3321, 2158, 1392, 597, 307, 257, 957, 1230, 370, 286, 519, 309, 311, 1850, 321, 439, 764, 439, 264, 565, 51804, 51804], "temperature": 0.0, "avg_logprob": -0.09118975763735564, "compression_ratio": 1.7285714285714286, "no_speech_prob": 5.0973078032257035e-05}, {"id": 48, "seek": 32440, "start": 337.52, "end": 344.64, "text": " you have the support is a 1D grid and for each node of the grid you will have the", "tokens": [50364, 1392, 370, 257, 1349, 393, 312, 10379, 538, 445, 364, 24922, 337, 1365, 264, 912, 611, 337, 6218, 50724, 50724, 370, 437, 291, 536, 510, 307, 264, 12990, 295, 264, 1988, 3321, 293, 309, 311, 264, 912, 291, 458, 309, 311, 411, 51020, 51020, 291, 362, 264, 1406, 307, 257, 502, 35, 10748, 293, 337, 1184, 9984, 295, 264, 10748, 291, 486, 362, 264, 51376, 51376, 264, 1988, 3321, 2158, 1392, 597, 307, 257, 957, 1230, 370, 286, 519, 309, 311, 1850, 321, 439, 764, 439, 264, 565, 51804, 51804], "temperature": 0.0, "avg_logprob": -0.09118975763735564, "compression_ratio": 1.7285714285714286, "no_speech_prob": 5.0973078032257035e-05}, {"id": 49, "seek": 32440, "start": 344.64, "end": 353.2, "text": " the air pressure value okay which is a real number so I think it's clear we all use all the time", "tokens": [50364, 1392, 370, 257, 1349, 393, 312, 10379, 538, 445, 364, 24922, 337, 1365, 264, 912, 611, 337, 6218, 50724, 50724, 370, 437, 291, 536, 510, 307, 264, 12990, 295, 264, 1988, 3321, 293, 309, 311, 264, 912, 291, 458, 309, 311, 411, 51020, 51020, 291, 362, 264, 1406, 307, 257, 502, 35, 10748, 293, 337, 1184, 9984, 295, 264, 10748, 291, 486, 362, 264, 51376, 51376, 264, 1988, 3321, 2158, 1392, 597, 307, 257, 957, 1230, 370, 286, 519, 309, 311, 1850, 321, 439, 764, 439, 264, 565, 51804, 51804], "temperature": 0.0, "avg_logprob": -0.09118975763735564, "compression_ratio": 1.7285714285714286, "no_speech_prob": 5.0973078032257035e-05}, {"id": 50, "seek": 35320, "start": 353.2, "end": 359.12, "text": " grids and grids are you know as very strong regular spatial structure and for this for this", "tokens": [50364, 677, 3742, 293, 677, 3742, 366, 291, 458, 382, 588, 2068, 3890, 23598, 3877, 293, 337, 341, 337, 341, 50660, 50660, 337, 341, 3877, 341, 307, 665, 570, 321, 44003, 321, 393, 6964, 264, 10851, 51020, 51020, 7705, 411, 45216, 293, 8407, 293, 611, 294, 3124, 309, 311, 588, 2370, 281, 360, 309, 51240, 51312, 370, 1203, 307, 665, 586, 718, 311, 574, 412, 291, 458, 777, 1412, 370, 337, 1365, 2093, 9590, 51732, 51732], "temperature": 0.0, "avg_logprob": -0.1322861337042474, "compression_ratio": 1.76, "no_speech_prob": 1.8556527720647864e-05}, {"id": 51, "seek": 35320, "start": 359.12, "end": 366.32, "text": " for this structure this is good because we mathematically we can define the convenient", "tokens": [50364, 677, 3742, 293, 677, 3742, 366, 291, 458, 382, 588, 2068, 3890, 23598, 3877, 293, 337, 341, 337, 341, 50660, 50660, 337, 341, 3877, 341, 307, 665, 570, 321, 44003, 321, 393, 6964, 264, 10851, 51020, 51020, 7705, 411, 45216, 293, 8407, 293, 611, 294, 3124, 309, 311, 588, 2370, 281, 360, 309, 51240, 51312, 370, 1203, 307, 665, 586, 718, 311, 574, 412, 291, 458, 777, 1412, 370, 337, 1365, 2093, 9590, 51732, 51732], "temperature": 0.0, "avg_logprob": -0.1322861337042474, "compression_ratio": 1.76, "no_speech_prob": 1.8556527720647864e-05}, {"id": 52, "seek": 35320, "start": 366.32, "end": 370.71999999999997, "text": " operations like convolution and pulling and also in practice it's very fast to do it", "tokens": [50364, 677, 3742, 293, 677, 3742, 366, 291, 458, 382, 588, 2068, 3890, 23598, 3877, 293, 337, 341, 337, 341, 50660, 50660, 337, 341, 3877, 341, 307, 665, 570, 321, 44003, 321, 393, 6964, 264, 10851, 51020, 51020, 7705, 411, 45216, 293, 8407, 293, 611, 294, 3124, 309, 311, 588, 2370, 281, 360, 309, 51240, 51312, 370, 1203, 307, 665, 586, 718, 311, 574, 412, 291, 458, 777, 1412, 370, 337, 1365, 2093, 9590, 51732, 51732], "temperature": 0.0, "avg_logprob": -0.1322861337042474, "compression_ratio": 1.76, "no_speech_prob": 1.8556527720647864e-05}, {"id": 53, "seek": 35320, "start": 372.15999999999997, "end": 380.56, "text": " so everything is good now let's look at you know new data so for example social networks", "tokens": [50364, 677, 3742, 293, 677, 3742, 366, 291, 458, 382, 588, 2068, 3890, 23598, 3877, 293, 337, 341, 337, 341, 50660, 50660, 337, 341, 3877, 341, 307, 665, 570, 321, 44003, 321, 393, 6964, 264, 10851, 51020, 51020, 7705, 411, 45216, 293, 8407, 293, 611, 294, 3124, 309, 311, 588, 2370, 281, 360, 309, 51240, 51312, 370, 1203, 307, 665, 586, 718, 311, 574, 412, 291, 458, 777, 1412, 370, 337, 1365, 2093, 9590, 51732, 51732], "temperature": 0.0, "avg_logprob": -0.1322861337042474, "compression_ratio": 1.76, "no_speech_prob": 1.8556527720647864e-05}, {"id": 54, "seek": 38056, "start": 380.56, "end": 385.12, "text": " okay so you want you want to do your task for example would be to do advertisement or to", "tokens": [50364, 1392, 370, 291, 528, 291, 528, 281, 360, 428, 5633, 337, 1365, 576, 312, 281, 360, 31370, 420, 281, 50592, 50632, 611, 652, 11879, 370, 337, 257, 2093, 3209, 286, 478, 516, 281, 309, 311, 516, 281, 312, 1850, 457, 286, 478, 516, 50892, 50892, 281, 855, 291, 300, 498, 291, 747, 732, 13891, 370, 337, 1365, 291, 458, 291, 362, 341, 4195, 718, 311, 584, 51180, 51180, 341, 4195, 741, 293, 4195, 361, 293, 439, 264, 2357, 291, 536, 300, 341, 307, 406, 257, 10748, 1392, 370, 264, 4984, 51524, 51524, 264, 6119, 3711, 4984, 1296, 439, 5022, 436, 360, 406, 1254, 257, 10748, 436, 362, 257, 588, 2121, 5102, 51796, 51796], "temperature": 0.0, "avg_logprob": -0.08024700828220534, "compression_ratio": 1.9230769230769231, "no_speech_prob": 1.1409848411858547e-05}, {"id": 55, "seek": 38056, "start": 385.92, "end": 391.12, "text": " also make recommendation so for a social network I'm going to it's going to be clear but I'm going", "tokens": [50364, 1392, 370, 291, 528, 291, 528, 281, 360, 428, 5633, 337, 1365, 576, 312, 281, 360, 31370, 420, 281, 50592, 50632, 611, 652, 11879, 370, 337, 257, 2093, 3209, 286, 478, 516, 281, 309, 311, 516, 281, 312, 1850, 457, 286, 478, 516, 50892, 50892, 281, 855, 291, 300, 498, 291, 747, 732, 13891, 370, 337, 1365, 291, 458, 291, 362, 341, 4195, 718, 311, 584, 51180, 51180, 341, 4195, 741, 293, 4195, 361, 293, 439, 264, 2357, 291, 536, 300, 341, 307, 406, 257, 10748, 1392, 370, 264, 4984, 51524, 51524, 264, 6119, 3711, 4984, 1296, 439, 5022, 436, 360, 406, 1254, 257, 10748, 436, 362, 257, 588, 2121, 5102, 51796, 51796], "temperature": 0.0, "avg_logprob": -0.08024700828220534, "compression_ratio": 1.9230769230769231, "no_speech_prob": 1.1409848411858547e-05}, {"id": 56, "seek": 38056, "start": 391.12, "end": 396.88, "text": " to show you that if you take two nodes so for example you know you have this user let's say", "tokens": [50364, 1392, 370, 291, 528, 291, 528, 281, 360, 428, 5633, 337, 1365, 576, 312, 281, 360, 31370, 420, 281, 50592, 50632, 611, 652, 11879, 370, 337, 257, 2093, 3209, 286, 478, 516, 281, 309, 311, 516, 281, 312, 1850, 457, 286, 478, 516, 50892, 50892, 281, 855, 291, 300, 498, 291, 747, 732, 13891, 370, 337, 1365, 291, 458, 291, 362, 341, 4195, 718, 311, 584, 51180, 51180, 341, 4195, 741, 293, 4195, 361, 293, 439, 264, 2357, 291, 536, 300, 341, 307, 406, 257, 10748, 1392, 370, 264, 4984, 51524, 51524, 264, 6119, 3711, 4984, 1296, 439, 5022, 436, 360, 406, 1254, 257, 10748, 436, 362, 257, 588, 2121, 5102, 51796, 51796], "temperature": 0.0, "avg_logprob": -0.08024700828220534, "compression_ratio": 1.9230769230769231, "no_speech_prob": 1.1409848411858547e-05}, {"id": 57, "seek": 38056, "start": 396.88, "end": 403.76, "text": " this user i and user j and all the others you see that this is not a grid okay so the connection", "tokens": [50364, 1392, 370, 291, 528, 291, 528, 281, 360, 428, 5633, 337, 1365, 576, 312, 281, 360, 31370, 420, 281, 50592, 50632, 611, 652, 11879, 370, 337, 257, 2093, 3209, 286, 478, 516, 281, 309, 311, 516, 281, 312, 1850, 457, 286, 478, 516, 50892, 50892, 281, 855, 291, 300, 498, 291, 747, 732, 13891, 370, 337, 1365, 291, 458, 291, 362, 341, 4195, 718, 311, 584, 51180, 51180, 341, 4195, 741, 293, 4195, 361, 293, 439, 264, 2357, 291, 536, 300, 341, 307, 406, 257, 10748, 1392, 370, 264, 4984, 51524, 51524, 264, 6119, 3711, 4984, 1296, 439, 5022, 436, 360, 406, 1254, 257, 10748, 436, 362, 257, 588, 2121, 5102, 51796, 51796], "temperature": 0.0, "avg_logprob": -0.08024700828220534, "compression_ratio": 1.9230769230769231, "no_speech_prob": 1.1409848411858547e-05}, {"id": 58, "seek": 38056, "start": 403.76, "end": 409.2, "text": " the pairwise connection between all users they do not form a grid they have a very special pattern", "tokens": [50364, 1392, 370, 291, 528, 291, 528, 281, 360, 428, 5633, 337, 1365, 576, 312, 281, 360, 31370, 420, 281, 50592, 50632, 611, 652, 11879, 370, 337, 257, 2093, 3209, 286, 478, 516, 281, 309, 311, 516, 281, 312, 1850, 457, 286, 478, 516, 50892, 50892, 281, 855, 291, 300, 498, 291, 747, 732, 13891, 370, 337, 1365, 291, 458, 291, 362, 341, 4195, 718, 311, 584, 51180, 51180, 341, 4195, 741, 293, 4195, 361, 293, 439, 264, 2357, 291, 536, 300, 341, 307, 406, 257, 10748, 1392, 370, 264, 4984, 51524, 51524, 264, 6119, 3711, 4984, 1296, 439, 5022, 436, 360, 406, 1254, 257, 10748, 436, 362, 257, 588, 2121, 5102, 51796, 51796], "temperature": 0.0, "avg_logprob": -0.08024700828220534, "compression_ratio": 1.9230769230769231, "no_speech_prob": 1.1409848411858547e-05}, {"id": 59, "seek": 40920, "start": 409.2, "end": 416.4, "text": " of connections and this is basically a graph okay so how do you define your graph you're going to", "tokens": [50364, 295, 9271, 293, 341, 307, 1936, 257, 4295, 1392, 370, 577, 360, 291, 6964, 428, 4295, 291, 434, 516, 281, 50724, 50724, 536, 264, 4984, 1296, 5022, 370, 498, 741, 4195, 741, 4195, 361, 366, 1855, 291, 434, 516, 281, 362, 428, 51024, 51024, 572, 4984, 293, 550, 337, 341, 291, 366, 516, 281, 764, 437, 321, 818, 364, 24441, 269, 8141, 597, 307, 51272, 51272, 445, 516, 281, 2136, 439, 264, 4984, 420, 2107, 12, 9826, 313, 1296, 13891, 294, 428, 294, 428, 51664, 51664], "temperature": 0.0, "avg_logprob": -0.07319932634180243, "compression_ratio": 1.9378238341968912, "no_speech_prob": 4.771251951751765e-06}, {"id": 60, "seek": 40920, "start": 416.4, "end": 422.4, "text": " see the connection between users so if i user i user j are friends you're going to have your", "tokens": [50364, 295, 9271, 293, 341, 307, 1936, 257, 4295, 1392, 370, 577, 360, 291, 6964, 428, 4295, 291, 434, 516, 281, 50724, 50724, 536, 264, 4984, 1296, 5022, 370, 498, 741, 4195, 741, 4195, 361, 366, 1855, 291, 434, 516, 281, 362, 428, 51024, 51024, 572, 4984, 293, 550, 337, 341, 291, 366, 516, 281, 764, 437, 321, 818, 364, 24441, 269, 8141, 597, 307, 51272, 51272, 445, 516, 281, 2136, 439, 264, 4984, 420, 2107, 12, 9826, 313, 1296, 13891, 294, 428, 294, 428, 51664, 51664], "temperature": 0.0, "avg_logprob": -0.07319932634180243, "compression_ratio": 1.9378238341968912, "no_speech_prob": 4.771251951751765e-06}, {"id": 61, "seek": 40920, "start": 422.4, "end": 427.36, "text": " no connection and then for this you are going to use what we call an adjacent c matrix which is", "tokens": [50364, 295, 9271, 293, 341, 307, 1936, 257, 4295, 1392, 370, 577, 360, 291, 6964, 428, 4295, 291, 434, 516, 281, 50724, 50724, 536, 264, 4984, 1296, 5022, 370, 498, 741, 4195, 741, 4195, 361, 366, 1855, 291, 434, 516, 281, 362, 428, 51024, 51024, 572, 4984, 293, 550, 337, 341, 291, 366, 516, 281, 764, 437, 321, 818, 364, 24441, 269, 8141, 597, 307, 51272, 51272, 445, 516, 281, 2136, 439, 264, 4984, 420, 2107, 12, 9826, 313, 1296, 13891, 294, 428, 294, 428, 51664, 51664], "temperature": 0.0, "avg_logprob": -0.07319932634180243, "compression_ratio": 1.9378238341968912, "no_speech_prob": 4.771251951751765e-06}, {"id": 62, "seek": 40920, "start": 427.36, "end": 435.2, "text": " just going to record all the connection or non-connection between nodes in your in your", "tokens": [50364, 295, 9271, 293, 341, 307, 1936, 257, 4295, 1392, 370, 577, 360, 291, 6964, 428, 4295, 291, 434, 516, 281, 50724, 50724, 536, 264, 4984, 1296, 5022, 370, 498, 741, 4195, 741, 4195, 361, 366, 1855, 291, 434, 516, 281, 362, 428, 51024, 51024, 572, 4984, 293, 550, 337, 341, 291, 366, 516, 281, 764, 437, 321, 818, 364, 24441, 269, 8141, 597, 307, 51272, 51272, 445, 516, 281, 2136, 439, 264, 4984, 420, 2107, 12, 9826, 313, 1296, 13891, 294, 428, 294, 428, 51664, 51664], "temperature": 0.0, "avg_logprob": -0.07319932634180243, "compression_ratio": 1.9378238341968912, "no_speech_prob": 4.771251951751765e-06}, {"id": 63, "seek": 43520, "start": 435.2, "end": 441.59999999999997, "text": " social networks okay and on the top of your network for each user you will have features", "tokens": [50364, 2093, 9590, 1392, 293, 322, 264, 1192, 295, 428, 3209, 337, 1184, 4195, 291, 486, 362, 4122, 50684, 50684, 370, 337, 1365, 291, 362, 291, 458, 7897, 291, 362, 5267, 291, 362, 2145, 370, 436, 1254, 291, 458, 512, 51020, 51020, 4111, 294, 257, 274, 12, 18759, 1901, 294, 294, 42762, 294, 3567, 5215, 337, 1365, 321, 366, 534, 51480, 51480, 1880, 281, 1223, 291, 458, 264, 8088, 9721, 2480, 1296, 3877, 293, 51828, 51828], "temperature": 0.0, "avg_logprob": -0.05885570699518377, "compression_ratio": 1.8269230769230769, "no_speech_prob": 1.259109649254242e-05}, {"id": 64, "seek": 43520, "start": 441.59999999999997, "end": 448.32, "text": " so for example you have you know messages you have images you have videos so they form you know some", "tokens": [50364, 2093, 9590, 1392, 293, 322, 264, 1192, 295, 428, 3209, 337, 1184, 4195, 291, 486, 362, 4122, 50684, 50684, 370, 337, 1365, 291, 362, 291, 458, 7897, 291, 362, 5267, 291, 362, 2145, 370, 436, 1254, 291, 458, 512, 51020, 51020, 4111, 294, 257, 274, 12, 18759, 1901, 294, 294, 42762, 294, 3567, 5215, 337, 1365, 321, 366, 534, 51480, 51480, 1880, 281, 1223, 291, 458, 264, 8088, 9721, 2480, 1296, 3877, 293, 51828, 51828], "temperature": 0.0, "avg_logprob": -0.05885570699518377, "compression_ratio": 1.8269230769230769, "no_speech_prob": 1.259109649254242e-05}, {"id": 65, "seek": 43520, "start": 448.32, "end": 457.52, "text": " feature in a d-dimensional space in in neuroscience in brain analysis for example we are really", "tokens": [50364, 2093, 9590, 1392, 293, 322, 264, 1192, 295, 428, 3209, 337, 1184, 4195, 291, 486, 362, 4122, 50684, 50684, 370, 337, 1365, 291, 362, 291, 458, 7897, 291, 362, 5267, 291, 362, 2145, 370, 436, 1254, 291, 458, 512, 51020, 51020, 4111, 294, 257, 274, 12, 18759, 1901, 294, 294, 42762, 294, 3567, 5215, 337, 1365, 321, 366, 534, 51480, 51480, 1880, 281, 1223, 291, 458, 264, 8088, 9721, 2480, 1296, 3877, 293, 51828, 51828], "temperature": 0.0, "avg_logprob": -0.05885570699518377, "compression_ratio": 1.8269230769230769, "no_speech_prob": 1.259109649254242e-05}, {"id": 66, "seek": 43520, "start": 457.52, "end": 464.48, "text": " interesting to understand you know the fundamental relation relationship between structure and", "tokens": [50364, 2093, 9590, 1392, 293, 322, 264, 1192, 295, 428, 3209, 337, 1184, 4195, 291, 486, 362, 4122, 50684, 50684, 370, 337, 1365, 291, 362, 291, 458, 7897, 291, 362, 5267, 291, 362, 2145, 370, 436, 1254, 291, 458, 512, 51020, 51020, 4111, 294, 257, 274, 12, 18759, 1901, 294, 294, 42762, 294, 3567, 5215, 337, 1365, 321, 366, 534, 51480, 51480, 1880, 281, 1223, 291, 458, 264, 8088, 9721, 2480, 1296, 3877, 293, 51828, 51828], "temperature": 0.0, "avg_logprob": -0.05885570699518377, "compression_ratio": 1.8269230769230769, "no_speech_prob": 1.259109649254242e-05}, {"id": 67, "seek": 46448, "start": 464.48, "end": 469.36, "text": " function of the brain so they are really connected to each other and it's very fundamental to", "tokens": [50364, 2445, 295, 264, 3567, 370, 436, 366, 534, 4582, 281, 1184, 661, 293, 309, 311, 588, 8088, 281, 50608, 50608, 1223, 300, 321, 611, 528, 337, 1365, 281, 6069, 257, 16499, 1337, 1166, 4752, 819, 10232, 295, 50884, 50884, 341, 4752, 370, 550, 341, 307, 588, 1021, 337, 341, 321, 643, 281, 1223, 264, 3567, 293, 264, 3567, 51156, 51156, 498, 291, 574, 412, 264, 3567, 264, 3567, 307, 18204, 295, 437, 321, 818, 257, 4458, 295, 1179, 1392, 293, 341, 51512, 51512, 4458, 295, 1179, 498, 291, 747, 472, 4458, 295, 1179, 341, 4458, 307, 406, 4582, 281, 439, 661, 51760, 51760], "temperature": 0.0, "avg_logprob": -0.06028941926502046, "compression_ratio": 2.0995670995670994, "no_speech_prob": 2.304735426150728e-05}, {"id": 68, "seek": 46448, "start": 469.36, "end": 474.88, "text": " understand that we also want for example to predict a neuro generative disease different stages of", "tokens": [50364, 2445, 295, 264, 3567, 370, 436, 366, 534, 4582, 281, 1184, 661, 293, 309, 311, 588, 8088, 281, 50608, 50608, 1223, 300, 321, 611, 528, 337, 1365, 281, 6069, 257, 16499, 1337, 1166, 4752, 819, 10232, 295, 50884, 50884, 341, 4752, 370, 550, 341, 307, 588, 1021, 337, 341, 321, 643, 281, 1223, 264, 3567, 293, 264, 3567, 51156, 51156, 498, 291, 574, 412, 264, 3567, 264, 3567, 307, 18204, 295, 437, 321, 818, 257, 4458, 295, 1179, 1392, 293, 341, 51512, 51512, 4458, 295, 1179, 498, 291, 747, 472, 4458, 295, 1179, 341, 4458, 307, 406, 4582, 281, 439, 661, 51760, 51760], "temperature": 0.0, "avg_logprob": -0.06028941926502046, "compression_ratio": 2.0995670995670994, "no_speech_prob": 2.304735426150728e-05}, {"id": 69, "seek": 46448, "start": 474.88, "end": 480.32, "text": " this disease so then this is very important for this we need to understand the brain and the brain", "tokens": [50364, 2445, 295, 264, 3567, 370, 436, 366, 534, 4582, 281, 1184, 661, 293, 309, 311, 588, 8088, 281, 50608, 50608, 1223, 300, 321, 611, 528, 337, 1365, 281, 6069, 257, 16499, 1337, 1166, 4752, 819, 10232, 295, 50884, 50884, 341, 4752, 370, 550, 341, 307, 588, 1021, 337, 341, 321, 643, 281, 1223, 264, 3567, 293, 264, 3567, 51156, 51156, 498, 291, 574, 412, 264, 3567, 264, 3567, 307, 18204, 295, 437, 321, 818, 257, 4458, 295, 1179, 1392, 293, 341, 51512, 51512, 4458, 295, 1179, 498, 291, 747, 472, 4458, 295, 1179, 341, 4458, 307, 406, 4582, 281, 439, 661, 51760, 51760], "temperature": 0.0, "avg_logprob": -0.06028941926502046, "compression_ratio": 2.0995670995670994, "no_speech_prob": 2.304735426150728e-05}, {"id": 70, "seek": 46448, "start": 480.32, "end": 487.44, "text": " if you look at the brain the brain is composed of what we call a region of interest okay and this", "tokens": [50364, 2445, 295, 264, 3567, 370, 436, 366, 534, 4582, 281, 1184, 661, 293, 309, 311, 588, 8088, 281, 50608, 50608, 1223, 300, 321, 611, 528, 337, 1365, 281, 6069, 257, 16499, 1337, 1166, 4752, 819, 10232, 295, 50884, 50884, 341, 4752, 370, 550, 341, 307, 588, 1021, 337, 341, 321, 643, 281, 1223, 264, 3567, 293, 264, 3567, 51156, 51156, 498, 291, 574, 412, 264, 3567, 264, 3567, 307, 18204, 295, 437, 321, 818, 257, 4458, 295, 1179, 1392, 293, 341, 51512, 51512, 4458, 295, 1179, 498, 291, 747, 472, 4458, 295, 1179, 341, 4458, 307, 406, 4582, 281, 439, 661, 51760, 51760], "temperature": 0.0, "avg_logprob": -0.06028941926502046, "compression_ratio": 2.0995670995670994, "no_speech_prob": 2.304735426150728e-05}, {"id": 71, "seek": 46448, "start": 487.44, "end": 492.40000000000003, "text": " region of interest if you take one region of interest this region is not connected to all other", "tokens": [50364, 2445, 295, 264, 3567, 370, 436, 366, 534, 4582, 281, 1184, 661, 293, 309, 311, 588, 8088, 281, 50608, 50608, 1223, 300, 321, 611, 528, 337, 1365, 281, 6069, 257, 16499, 1337, 1166, 4752, 819, 10232, 295, 50884, 50884, 341, 4752, 370, 550, 341, 307, 588, 1021, 337, 341, 321, 643, 281, 1223, 264, 3567, 293, 264, 3567, 51156, 51156, 498, 291, 574, 412, 264, 3567, 264, 3567, 307, 18204, 295, 437, 321, 818, 257, 4458, 295, 1179, 1392, 293, 341, 51512, 51512, 4458, 295, 1179, 498, 291, 747, 472, 4458, 295, 1179, 341, 4458, 307, 406, 4582, 281, 439, 661, 51760, 51760], "temperature": 0.0, "avg_logprob": -0.06028941926502046, "compression_ratio": 2.0995670995670994, "no_speech_prob": 2.304735426150728e-05}, {"id": 72, "seek": 49240, "start": 492.4, "end": 497.52, "text": " regions in the brain actually they are only connected to a few other regions so it's it's", "tokens": [50364, 10682, 294, 264, 3567, 767, 436, 366, 787, 4582, 281, 257, 1326, 661, 10682, 370, 309, 311, 309, 311, 50620, 50620, 293, 797, 291, 393, 536, 1825, 281, 360, 365, 264, 10748, 1392, 370, 341, 23598, 4984, 1296, 819, 51000, 51000, 4458, 295, 264, 15442, 436, 393, 312, 12690, 538, 264, 15067, 32812, 6358, 293, 550, 291, 611, 362, 364, 51308, 51308, 24441, 269, 8141, 1296, 4458, 741, 293, 4458, 361, 293, 293, 510, 291, 362, 257, 3800, 295, 4984, 51624, 51624], "temperature": 0.0, "avg_logprob": -0.07557259287152972, "compression_ratio": 1.7557603686635945, "no_speech_prob": 1.3411227882897947e-05}, {"id": 73, "seek": 49240, "start": 497.52, "end": 505.12, "text": " and again you can see nothing to do with the grid okay so this spatial connection between different", "tokens": [50364, 10682, 294, 264, 3567, 767, 436, 366, 787, 4582, 281, 257, 1326, 661, 10682, 370, 309, 311, 309, 311, 50620, 50620, 293, 797, 291, 393, 536, 1825, 281, 360, 365, 264, 10748, 1392, 370, 341, 23598, 4984, 1296, 819, 51000, 51000, 4458, 295, 264, 15442, 436, 393, 312, 12690, 538, 264, 15067, 32812, 6358, 293, 550, 291, 611, 362, 364, 51308, 51308, 24441, 269, 8141, 1296, 4458, 741, 293, 4458, 361, 293, 293, 510, 291, 362, 257, 3800, 295, 4984, 51624, 51624], "temperature": 0.0, "avg_logprob": -0.07557259287152972, "compression_ratio": 1.7557603686635945, "no_speech_prob": 1.3411227882897947e-05}, {"id": 74, "seek": 49240, "start": 505.12, "end": 511.28, "text": " region of the brains they can be measured by the structural MRI signal and then you also have an", "tokens": [50364, 10682, 294, 264, 3567, 767, 436, 366, 787, 4582, 281, 257, 1326, 661, 10682, 370, 309, 311, 309, 311, 50620, 50620, 293, 797, 291, 393, 536, 1825, 281, 360, 365, 264, 10748, 1392, 370, 341, 23598, 4984, 1296, 819, 51000, 51000, 4458, 295, 264, 15442, 436, 393, 312, 12690, 538, 264, 15067, 32812, 6358, 293, 550, 291, 611, 362, 364, 51308, 51308, 24441, 269, 8141, 1296, 4458, 741, 293, 4458, 361, 293, 293, 510, 291, 362, 257, 3800, 295, 4984, 51624, 51624], "temperature": 0.0, "avg_logprob": -0.07557259287152972, "compression_ratio": 1.7557603686635945, "no_speech_prob": 1.3411227882897947e-05}, {"id": 75, "seek": 49240, "start": 511.28, "end": 517.6, "text": " adjacent c matrix between region i and region j and and here you have a strength of connection", "tokens": [50364, 10682, 294, 264, 3567, 767, 436, 366, 787, 4582, 281, 257, 1326, 661, 10682, 370, 309, 311, 309, 311, 50620, 50620, 293, 797, 291, 393, 536, 1825, 281, 360, 365, 264, 10748, 1392, 370, 341, 23598, 4984, 1296, 819, 51000, 51000, 4458, 295, 264, 15442, 436, 393, 312, 12690, 538, 264, 15067, 32812, 6358, 293, 550, 291, 611, 362, 364, 51308, 51308, 24441, 269, 8141, 1296, 4458, 741, 293, 4458, 361, 293, 293, 510, 291, 362, 257, 3800, 295, 4984, 51624, 51624], "temperature": 0.0, "avg_logprob": -0.07557259287152972, "compression_ratio": 1.7557603686635945, "no_speech_prob": 1.3411227882897947e-05}, {"id": 76, "seek": 51760, "start": 517.6, "end": 523.44, "text": " which depends how many connection how many fibers do you have to connect region i and region j", "tokens": [50364, 597, 5946, 577, 867, 4984, 577, 867, 25252, 360, 291, 362, 281, 1745, 4458, 741, 293, 4458, 361, 50656, 50656, 1392, 293, 550, 322, 264, 1192, 295, 341, 4295, 370, 498, 291, 574, 412, 264, 4458, 741, 550, 291, 486, 362, 50980, 50980, 2430, 763, 291, 458, 11745, 24433, 597, 307, 1936, 257, 565, 2638, 300, 291, 393, 536, 510, 51316, 51316, 293, 611, 321, 393, 2136, 341, 24433, 295, 264, 3567, 365, 11745, 32812, 51520, 51636], "temperature": 0.0, "avg_logprob": -0.053170771538456785, "compression_ratio": 1.8010204081632653, "no_speech_prob": 1.7478145309723914e-05}, {"id": 77, "seek": 51760, "start": 523.44, "end": 529.9200000000001, "text": " okay and then on the top of this graph so if you look at the region i then you will have", "tokens": [50364, 597, 5946, 577, 867, 4984, 577, 867, 25252, 360, 291, 362, 281, 1745, 4458, 741, 293, 4458, 361, 50656, 50656, 1392, 293, 550, 322, 264, 1192, 295, 341, 4295, 370, 498, 291, 574, 412, 264, 4458, 741, 550, 291, 486, 362, 50980, 50980, 2430, 763, 291, 458, 11745, 24433, 597, 307, 1936, 257, 565, 2638, 300, 291, 393, 536, 510, 51316, 51316, 293, 611, 321, 393, 2136, 341, 24433, 295, 264, 3567, 365, 11745, 32812, 51520, 51636], "temperature": 0.0, "avg_logprob": -0.053170771538456785, "compression_ratio": 1.8010204081632653, "no_speech_prob": 1.7478145309723914e-05}, {"id": 78, "seek": 51760, "start": 529.9200000000001, "end": 536.64, "text": " activations you know functional activation which is basically a time series that you can see here", "tokens": [50364, 597, 5946, 577, 867, 4984, 577, 867, 25252, 360, 291, 362, 281, 1745, 4458, 741, 293, 4458, 361, 50656, 50656, 1392, 293, 550, 322, 264, 1192, 295, 341, 4295, 370, 498, 291, 574, 412, 264, 4458, 741, 550, 291, 486, 362, 50980, 50980, 2430, 763, 291, 458, 11745, 24433, 597, 307, 1936, 257, 565, 2638, 300, 291, 393, 536, 510, 51316, 51316, 293, 611, 321, 393, 2136, 341, 24433, 295, 264, 3567, 365, 11745, 32812, 51520, 51636], "temperature": 0.0, "avg_logprob": -0.053170771538456785, "compression_ratio": 1.8010204081632653, "no_speech_prob": 1.7478145309723914e-05}, {"id": 79, "seek": 51760, "start": 536.64, "end": 540.72, "text": " and also we can record this activation of the brain with functional MRI", "tokens": [50364, 597, 5946, 577, 867, 4984, 577, 867, 25252, 360, 291, 362, 281, 1745, 4458, 741, 293, 4458, 361, 50656, 50656, 1392, 293, 550, 322, 264, 1192, 295, 341, 4295, 370, 498, 291, 574, 412, 264, 4458, 741, 550, 291, 486, 362, 50980, 50980, 2430, 763, 291, 458, 11745, 24433, 597, 307, 1936, 257, 565, 2638, 300, 291, 393, 536, 510, 51316, 51316, 293, 611, 321, 393, 2136, 341, 24433, 295, 264, 3567, 365, 11745, 32812, 51520, 51636], "temperature": 0.0, "avg_logprob": -0.053170771538456785, "compression_ratio": 1.8010204081632653, "no_speech_prob": 1.7478145309723914e-05}, {"id": 80, "seek": 54072, "start": 540.72, "end": 546.48, "text": " okay the last example i want to show you is in quantum chemistry so for example the task would", "tokens": [50364, 1392, 264, 1036, 1365, 741, 528, 281, 855, 291, 307, 294, 13018, 12558, 370, 337, 1365, 264, 5633, 576, 50652, 50652, 312, 281, 1715, 777, 13093, 337, 7766, 293, 5319, 370, 370, 291, 536, 797, 264, 4984, 1296, 16871, 51076, 51076, 575, 1825, 281, 360, 365, 264, 10748, 1392, 309, 534, 5946, 577, 291, 434, 516, 281, 1745, 428, 16871, 51428, 51428, 293, 550, 291, 486, 362, 291, 458, 13093, 370, 370, 264, 4984, 1296, 16871, 436, 366, 1219, 14713, 51772, 51772], "temperature": 0.0, "avg_logprob": -0.14638118516831172, "compression_ratio": 1.808411214953271, "no_speech_prob": 4.782923042512266e-06}, {"id": 81, "seek": 54072, "start": 546.48, "end": 554.96, "text": " be to design new molecules for drugs and materials so so you see again the connection between atoms", "tokens": [50364, 1392, 264, 1036, 1365, 741, 528, 281, 855, 291, 307, 294, 13018, 12558, 370, 337, 1365, 264, 5633, 576, 50652, 50652, 312, 281, 1715, 777, 13093, 337, 7766, 293, 5319, 370, 370, 291, 536, 797, 264, 4984, 1296, 16871, 51076, 51076, 575, 1825, 281, 360, 365, 264, 10748, 1392, 309, 534, 5946, 577, 291, 434, 516, 281, 1745, 428, 16871, 51428, 51428, 293, 550, 291, 486, 362, 291, 458, 13093, 370, 370, 264, 4984, 1296, 16871, 436, 366, 1219, 14713, 51772, 51772], "temperature": 0.0, "avg_logprob": -0.14638118516831172, "compression_ratio": 1.808411214953271, "no_speech_prob": 4.782923042512266e-06}, {"id": 82, "seek": 54072, "start": 554.96, "end": 562.0, "text": " has nothing to do with the grid okay it really depends how you're going to connect your atoms", "tokens": [50364, 1392, 264, 1036, 1365, 741, 528, 281, 855, 291, 307, 294, 13018, 12558, 370, 337, 1365, 264, 5633, 576, 50652, 50652, 312, 281, 1715, 777, 13093, 337, 7766, 293, 5319, 370, 370, 291, 536, 797, 264, 4984, 1296, 16871, 51076, 51076, 575, 1825, 281, 360, 365, 264, 10748, 1392, 309, 534, 5946, 577, 291, 434, 516, 281, 1745, 428, 16871, 51428, 51428, 293, 550, 291, 486, 362, 291, 458, 13093, 370, 370, 264, 4984, 1296, 16871, 436, 366, 1219, 14713, 51772, 51772], "temperature": 0.0, "avg_logprob": -0.14638118516831172, "compression_ratio": 1.808411214953271, "no_speech_prob": 4.782923042512266e-06}, {"id": 83, "seek": 54072, "start": 562.0, "end": 568.88, "text": " and then you will have you know molecules so so the connection between atoms they are called bonds", "tokens": [50364, 1392, 264, 1036, 1365, 741, 528, 281, 855, 291, 307, 294, 13018, 12558, 370, 337, 1365, 264, 5633, 576, 50652, 50652, 312, 281, 1715, 777, 13093, 337, 7766, 293, 5319, 370, 370, 291, 536, 797, 264, 4984, 1296, 16871, 51076, 51076, 575, 1825, 281, 360, 365, 264, 10748, 1392, 309, 534, 5946, 577, 291, 434, 516, 281, 1745, 428, 16871, 51428, 51428, 293, 550, 291, 486, 362, 291, 458, 13093, 370, 370, 264, 4984, 1296, 16871, 436, 366, 1219, 14713, 51772, 51772], "temperature": 0.0, "avg_logprob": -0.14638118516831172, "compression_ratio": 1.808411214953271, "no_speech_prob": 4.782923042512266e-06}, {"id": 84, "seek": 56888, "start": 568.88, "end": 575.4399999999999, "text": " and you have you know different kind of bonds they can be single bond double bond aromatic bond", "tokens": [50364, 293, 291, 362, 291, 458, 819, 733, 295, 14713, 436, 393, 312, 2167, 6086, 3834, 6086, 45831, 6086, 50692, 50692, 293, 291, 362, 293, 291, 362, 611, 819, 4122, 411, 2281, 293, 867, 661, 4122, 300, 291, 393, 50960, 50960, 764, 490, 490, 12558, 337, 264, 9984, 295, 264, 4295, 370, 456, 366, 16871, 293, 797, 291, 291, 291, 815, 362, 51332, 51332, 819, 4122, 411, 264, 2010, 295, 12018, 498, 309, 307, 291, 458, 12697, 498, 309, 307, 7883, 310, 439, 613, 439, 613, 51652, 51652], "temperature": 0.0, "avg_logprob": -0.17878655637248178, "compression_ratio": 2.020408163265306, "no_speech_prob": 1.776762837835122e-05}, {"id": 85, "seek": 56888, "start": 575.4399999999999, "end": 580.8, "text": " and you have and you have also different features like energy and many other features that you can", "tokens": [50364, 293, 291, 362, 291, 458, 819, 733, 295, 14713, 436, 393, 312, 2167, 6086, 3834, 6086, 45831, 6086, 50692, 50692, 293, 291, 362, 293, 291, 362, 611, 819, 4122, 411, 2281, 293, 867, 661, 4122, 300, 291, 393, 50960, 50960, 764, 490, 490, 12558, 337, 264, 9984, 295, 264, 4295, 370, 456, 366, 16871, 293, 797, 291, 291, 291, 815, 362, 51332, 51332, 819, 4122, 411, 264, 2010, 295, 12018, 498, 309, 307, 291, 458, 12697, 498, 309, 307, 7883, 310, 439, 613, 439, 613, 51652, 51652], "temperature": 0.0, "avg_logprob": -0.17878655637248178, "compression_ratio": 2.020408163265306, "no_speech_prob": 1.776762837835122e-05}, {"id": 86, "seek": 56888, "start": 580.8, "end": 588.24, "text": " use from from chemistry for the node of the graph so there are atoms and again you you you may have", "tokens": [50364, 293, 291, 362, 291, 458, 819, 733, 295, 14713, 436, 393, 312, 2167, 6086, 3834, 6086, 45831, 6086, 50692, 50692, 293, 291, 362, 293, 291, 362, 611, 819, 4122, 411, 2281, 293, 867, 661, 4122, 300, 291, 393, 50960, 50960, 764, 490, 490, 12558, 337, 264, 9984, 295, 264, 4295, 370, 456, 366, 16871, 293, 797, 291, 291, 291, 815, 362, 51332, 51332, 819, 4122, 411, 264, 2010, 295, 12018, 498, 309, 307, 291, 458, 12697, 498, 309, 307, 7883, 310, 439, 613, 439, 613, 51652, 51652], "temperature": 0.0, "avg_logprob": -0.17878655637248178, "compression_ratio": 2.020408163265306, "no_speech_prob": 1.776762837835122e-05}, {"id": 87, "seek": 56888, "start": 588.24, "end": 594.64, "text": " different features like the type of atom if it is you know hydrogen if it is azot all these all these", "tokens": [50364, 293, 291, 362, 291, 458, 819, 733, 295, 14713, 436, 393, 312, 2167, 6086, 3834, 6086, 45831, 6086, 50692, 50692, 293, 291, 362, 293, 291, 362, 611, 819, 4122, 411, 2281, 293, 867, 661, 4122, 300, 291, 393, 50960, 50960, 764, 490, 490, 12558, 337, 264, 9984, 295, 264, 4295, 370, 456, 366, 16871, 293, 797, 291, 291, 291, 815, 362, 51332, 51332, 819, 4122, 411, 264, 2010, 295, 12018, 498, 309, 307, 291, 458, 12697, 498, 309, 307, 7883, 310, 439, 613, 439, 613, 51652, 51652], "temperature": 0.0, "avg_logprob": -0.17878655637248178, "compression_ratio": 2.020408163265306, "no_speech_prob": 1.776762837835122e-05}, {"id": 88, "seek": 59464, "start": 594.64, "end": 600.4, "text": " types you have also the 3d coordinates you have the charge and so on you may have multiple features", "tokens": [50364, 3467, 291, 362, 611, 264, 805, 67, 21056, 291, 362, 264, 4602, 293, 370, 322, 291, 815, 362, 3866, 4122, 50652, 50732, 1392, 370, 293, 309, 311, 406, 264, 1329, 767, 1709, 322, 281, 976, 291, 1365, 295, 4295, 51136, 51172, 281, 976, 291, 1365, 295, 4295, 25514, 370, 291, 611, 362, 291, 458, 3820, 11837, 365, 805, 67, 3813, 8076, 51404, 51404, 291, 611, 528, 1310, 281, 12477, 11328, 3209, 293, 264, 8546, 51640, 51640], "temperature": 0.0, "avg_logprob": -0.29256131098820615, "compression_ratio": 1.7760416666666667, "no_speech_prob": 2.6587116735754535e-05}, {"id": 89, "seek": 59464, "start": 602.0, "end": 610.08, "text": " okay so and it's not the list actually goes on to give you example of graph", "tokens": [50364, 3467, 291, 362, 611, 264, 805, 67, 21056, 291, 362, 264, 4602, 293, 370, 322, 291, 815, 362, 3866, 4122, 50652, 50732, 1392, 370, 293, 309, 311, 406, 264, 1329, 767, 1709, 322, 281, 976, 291, 1365, 295, 4295, 51136, 51172, 281, 976, 291, 1365, 295, 4295, 25514, 370, 291, 611, 362, 291, 458, 3820, 11837, 365, 805, 67, 3813, 8076, 51404, 51404, 291, 611, 528, 1310, 281, 12477, 11328, 3209, 293, 264, 8546, 51640, 51640], "temperature": 0.0, "avg_logprob": -0.29256131098820615, "compression_ratio": 1.7760416666666667, "no_speech_prob": 2.6587116735754535e-05}, {"id": 90, "seek": 59464, "start": 610.8, "end": 615.4399999999999, "text": " to give you example of graph domains so you also have you know computer graphics with 3d meshes", "tokens": [50364, 3467, 291, 362, 611, 264, 805, 67, 21056, 291, 362, 264, 4602, 293, 370, 322, 291, 815, 362, 3866, 4122, 50652, 50732, 1392, 370, 293, 309, 311, 406, 264, 1329, 767, 1709, 322, 281, 976, 291, 1365, 295, 4295, 51136, 51172, 281, 976, 291, 1365, 295, 4295, 25514, 370, 291, 611, 362, 291, 458, 3820, 11837, 365, 805, 67, 3813, 8076, 51404, 51404, 291, 611, 528, 1310, 281, 12477, 11328, 3209, 293, 264, 8546, 51640, 51640], "temperature": 0.0, "avg_logprob": -0.29256131098820615, "compression_ratio": 1.7760416666666667, "no_speech_prob": 2.6587116735754535e-05}, {"id": 91, "seek": 59464, "start": 615.4399999999999, "end": 620.16, "text": " you also want maybe to analyze transportation network and the dynamic", "tokens": [50364, 3467, 291, 362, 611, 264, 805, 67, 21056, 291, 362, 264, 4602, 293, 370, 322, 291, 815, 362, 3866, 4122, 50652, 50732, 1392, 370, 293, 309, 311, 406, 264, 1329, 767, 1709, 322, 281, 976, 291, 1365, 295, 4295, 51136, 51172, 281, 976, 291, 1365, 295, 4295, 25514, 370, 291, 611, 362, 291, 458, 3820, 11837, 365, 805, 67, 3813, 8076, 51404, 51404, 291, 611, 528, 1310, 281, 12477, 11328, 3209, 293, 264, 8546, 51640, 51640], "temperature": 0.0, "avg_logprob": -0.29256131098820615, "compression_ratio": 1.7760416666666667, "no_speech_prob": 2.6587116735754535e-05}, {"id": 92, "seek": 62016, "start": 620.16, "end": 626.7199999999999, "text": " of of cars or maybe i don't know trains you have also you know gene regulatory network", "tokens": [50364, 295, 295, 5163, 420, 1310, 741, 500, 380, 458, 16329, 291, 362, 611, 291, 458, 12186, 18260, 3209, 50692, 50692, 291, 362, 3601, 24877, 1002, 6159, 291, 458, 5022, 3383, 689, 291, 528, 281, 360, 51076, 51076, 11879, 291, 362, 611, 1612, 3701, 291, 528, 281, 976, 544, 2689, 2020, 281, 428, 3820, 51316, 51316, 5201, 3479, 370, 291, 528, 281, 1223, 264, 2480, 1296, 291, 1296, 428, 6565, 51520, 51520, 291, 611, 362, 257, 688, 295, 1589, 466, 264, 51674, 51674], "temperature": 0.0, "avg_logprob": -0.3278212093171619, "compression_ratio": 1.8944954128440368, "no_speech_prob": 5.125344614498317e-05}, {"id": 93, "seek": 62016, "start": 626.7199999999999, "end": 634.4, "text": " you have knowledge graphs world relationships you know users products where you want to do", "tokens": [50364, 295, 295, 5163, 420, 1310, 741, 500, 380, 458, 16329, 291, 362, 611, 291, 458, 12186, 18260, 3209, 50692, 50692, 291, 362, 3601, 24877, 1002, 6159, 291, 458, 5022, 3383, 689, 291, 528, 281, 360, 51076, 51076, 11879, 291, 362, 611, 1612, 3701, 291, 528, 281, 976, 544, 2689, 2020, 281, 428, 3820, 51316, 51316, 5201, 3479, 370, 291, 528, 281, 1223, 264, 2480, 1296, 291, 1296, 428, 6565, 51520, 51520, 291, 611, 362, 257, 688, 295, 1589, 466, 264, 51674, 51674], "temperature": 0.0, "avg_logprob": -0.3278212093171619, "compression_ratio": 1.8944954128440368, "no_speech_prob": 5.125344614498317e-05}, {"id": 94, "seek": 62016, "start": 634.4, "end": 639.1999999999999, "text": " recommendation you have also seen understanding you want to give more common sense to your computer", "tokens": [50364, 295, 295, 5163, 420, 1310, 741, 500, 380, 458, 16329, 291, 362, 611, 291, 458, 12186, 18260, 3209, 50692, 50692, 291, 362, 3601, 24877, 1002, 6159, 291, 458, 5022, 3383, 689, 291, 528, 281, 360, 51076, 51076, 11879, 291, 362, 611, 1612, 3701, 291, 528, 281, 976, 544, 2689, 2020, 281, 428, 3820, 51316, 51316, 5201, 3479, 370, 291, 528, 281, 1223, 264, 2480, 1296, 291, 1296, 428, 6565, 51520, 51520, 291, 611, 362, 257, 688, 295, 1589, 466, 264, 51674, 51674], "temperature": 0.0, "avg_logprob": -0.3278212093171619, "compression_ratio": 1.8944954128440368, "no_speech_prob": 5.125344614498317e-05}, {"id": 95, "seek": 62016, "start": 639.1999999999999, "end": 643.28, "text": " vision machine so you want to understand the relationship between you between your objects", "tokens": [50364, 295, 295, 5163, 420, 1310, 741, 500, 380, 458, 16329, 291, 362, 611, 291, 458, 12186, 18260, 3209, 50692, 50692, 291, 362, 3601, 24877, 1002, 6159, 291, 458, 5022, 3383, 689, 291, 528, 281, 360, 51076, 51076, 11879, 291, 362, 611, 1612, 3701, 291, 528, 281, 976, 544, 2689, 2020, 281, 428, 3820, 51316, 51316, 5201, 3479, 370, 291, 528, 281, 1223, 264, 2480, 1296, 291, 1296, 428, 6565, 51520, 51520, 291, 611, 362, 257, 688, 295, 1589, 466, 264, 51674, 51674], "temperature": 0.0, "avg_logprob": -0.3278212093171619, "compression_ratio": 1.8944954128440368, "no_speech_prob": 5.125344614498317e-05}, {"id": 96, "seek": 62016, "start": 643.28, "end": 646.36, "text": " you also have a lot of information about the", "tokens": [50364, 295, 295, 5163, 420, 1310, 741, 500, 380, 458, 16329, 291, 362, 611, 291, 458, 12186, 18260, 3209, 50692, 50692, 291, 362, 3601, 24877, 1002, 6159, 291, 458, 5022, 3383, 689, 291, 528, 281, 360, 51076, 51076, 11879, 291, 362, 611, 1612, 3701, 291, 528, 281, 976, 544, 2689, 2020, 281, 428, 3820, 51316, 51316, 5201, 3479, 370, 291, 528, 281, 1223, 264, 2480, 1296, 291, 1296, 428, 6565, 51520, 51520, 291, 611, 362, 257, 688, 295, 1589, 466, 264, 51674, 51674], "temperature": 0.0, "avg_logprob": -0.3278212093171619, "compression_ratio": 1.8944954128440368, "no_speech_prob": 5.125344614498317e-05}, {"id": 97, "seek": 64636, "start": 646.36, "end": 652.72, "text": " high energy physics particles so you have captors and the captors are not you know structure as a", "tokens": [50364, 1090, 2281, 10649, 10007, 370, 291, 362, 3770, 830, 293, 264, 3770, 830, 366, 406, 291, 458, 3877, 382, 257, 50682, 50682, 3890, 10748, 370, 337, 439, 341, 291, 536, 300, 456, 307, 257, 20687, 597, 307, 1936, 291, 393, 2906, 51030, 51030, 439, 613, 2740, 382, 24877, 1392, 293, 51382, 51454, 293, 510, 307, 264, 2689, 2020, 295, 264, 4295, 51606, 51606], "temperature": 0.0, "avg_logprob": -0.4431616856501653, "compression_ratio": 1.650887573964497, "no_speech_prob": 7.572905451525003e-05}, {"id": 98, "seek": 64636, "start": 652.72, "end": 659.6800000000001, "text": " regular grid so for all this you see that there is a denominator which is basically you can represent", "tokens": [50364, 1090, 2281, 10649, 10007, 370, 291, 362, 3770, 830, 293, 264, 3770, 830, 366, 406, 291, 458, 3877, 382, 257, 50682, 50682, 3890, 10748, 370, 337, 439, 341, 291, 536, 300, 456, 307, 257, 20687, 597, 307, 1936, 291, 393, 2906, 51030, 51030, 439, 613, 2740, 382, 24877, 1392, 293, 51382, 51454, 293, 510, 307, 264, 2689, 2020, 295, 264, 4295, 51606, 51606], "temperature": 0.0, "avg_logprob": -0.4431616856501653, "compression_ratio": 1.650887573964497, "no_speech_prob": 7.572905451525003e-05}, {"id": 99, "seek": 64636, "start": 659.6800000000001, "end": 666.72, "text": " all these problems as graphs okay and", "tokens": [50364, 1090, 2281, 10649, 10007, 370, 291, 362, 3770, 830, 293, 264, 3770, 830, 366, 406, 291, 458, 3877, 382, 257, 50682, 50682, 3890, 10748, 370, 337, 439, 341, 291, 536, 300, 456, 307, 257, 20687, 597, 307, 1936, 291, 393, 2906, 51030, 51030, 439, 613, 2740, 382, 24877, 1392, 293, 51382, 51454, 293, 510, 307, 264, 2689, 2020, 295, 264, 4295, 51606, 51606], "temperature": 0.0, "avg_logprob": -0.4431616856501653, "compression_ratio": 1.650887573964497, "no_speech_prob": 7.572905451525003e-05}, {"id": 100, "seek": 64636, "start": 668.16, "end": 671.2, "text": " and here is the common sense of the graph", "tokens": [50364, 1090, 2281, 10649, 10007, 370, 291, 362, 3770, 830, 293, 264, 3770, 830, 366, 406, 291, 458, 3877, 382, 257, 50682, 50682, 3890, 10748, 370, 337, 439, 341, 291, 536, 300, 456, 307, 257, 20687, 597, 307, 1936, 291, 393, 2906, 51030, 51030, 439, 613, 2740, 382, 24877, 1392, 293, 51382, 51454, 293, 510, 307, 264, 2689, 2020, 295, 264, 4295, 51606, 51606], "temperature": 0.0, "avg_logprob": -0.4431616856501653, "compression_ratio": 1.650887573964497, "no_speech_prob": 7.572905451525003e-05}, {"id": 101, "seek": 67120, "start": 671.2, "end": 681.08, "text": " okay and and here is the command setting i would say the mathematical command setting for all these", "tokens": [50364, 1392, 293, 293, 510, 307, 264, 5622, 3287, 741, 576, 584, 264, 18894, 5622, 3287, 337, 439, 613, 50858, 50858, 2740, 370, 264, 24877, 718, 311, 718, 311, 818, 309, 290, 1392, 436, 366, 7642, 538, 1045, 16667, 370, 264, 700, 51362, 51362, 13977, 307, 516, 281, 312, 264, 992, 295, 32053, 370, 2673, 291, 366, 516, 281, 8186, 264, 992, 295, 32053, 51642, 51642], "temperature": 0.0, "avg_logprob": -0.1194055898865657, "compression_ratio": 1.8427672955974843, "no_speech_prob": 3.76626594515983e-05}, {"id": 102, "seek": 67120, "start": 681.08, "end": 691.1600000000001, "text": " problems so the graphs let's let's call it g okay they are defined by three entities so the first", "tokens": [50364, 1392, 293, 293, 510, 307, 264, 5622, 3287, 741, 576, 584, 264, 18894, 5622, 3287, 337, 439, 613, 50858, 50858, 2740, 370, 264, 24877, 718, 311, 718, 311, 818, 309, 290, 1392, 436, 366, 7642, 538, 1045, 16667, 370, 264, 700, 51362, 51362, 13977, 307, 516, 281, 312, 264, 992, 295, 32053, 370, 2673, 291, 366, 516, 281, 8186, 264, 992, 295, 32053, 51642, 51642], "temperature": 0.0, "avg_logprob": -0.1194055898865657, "compression_ratio": 1.8427672955974843, "no_speech_prob": 3.76626594515983e-05}, {"id": 103, "seek": 67120, "start": 691.1600000000001, "end": 696.76, "text": " entity is going to be the set of vertices so usually you are going to index the set of vertices", "tokens": [50364, 1392, 293, 293, 510, 307, 264, 5622, 3287, 741, 576, 584, 264, 18894, 5622, 3287, 337, 439, 613, 50858, 50858, 2740, 370, 264, 24877, 718, 311, 718, 311, 818, 309, 290, 1392, 436, 366, 7642, 538, 1045, 16667, 370, 264, 700, 51362, 51362, 13977, 307, 516, 281, 312, 264, 992, 295, 32053, 370, 2673, 291, 366, 516, 281, 8186, 264, 992, 295, 32053, 51642, 51642], "temperature": 0.0, "avg_logprob": -0.1194055898865657, "compression_ratio": 1.8427672955974843, "no_speech_prob": 3.76626594515983e-05}, {"id": 104, "seek": 69676, "start": 696.76, "end": 704.04, "text": " from one to n and is is the number of nodes in your in your graph okay so for example this will be", "tokens": [50364, 490, 472, 281, 297, 293, 307, 307, 264, 1230, 295, 13891, 294, 428, 294, 428, 4295, 1392, 370, 337, 1365, 341, 486, 312, 50728, 50728, 264, 8186, 472, 732, 1045, 293, 370, 322, 550, 291, 486, 362, 291, 458, 264, 992, 295, 8819, 1936, 436, 366, 51068, 51068, 264, 9271, 1296, 552, 1296, 264, 13891, 293, 2721, 291, 486, 362, 264, 22940, 3020, 8141, 51388, 51388], "temperature": 0.0, "avg_logprob": -0.08362803739659927, "compression_ratio": 1.7469879518072289, "no_speech_prob": 1.5165354852797464e-05}, {"id": 105, "seek": 69676, "start": 704.04, "end": 710.84, "text": " the index one two three and so on then you will have you know the set of edges basically they are", "tokens": [50364, 490, 472, 281, 297, 293, 307, 307, 264, 1230, 295, 13891, 294, 428, 294, 428, 4295, 1392, 370, 337, 1365, 341, 486, 312, 50728, 50728, 264, 8186, 472, 732, 1045, 293, 370, 322, 550, 291, 486, 362, 291, 458, 264, 992, 295, 8819, 1936, 436, 366, 51068, 51068, 264, 9271, 1296, 552, 1296, 264, 13891, 293, 2721, 291, 486, 362, 264, 22940, 3020, 8141, 51388, 51388], "temperature": 0.0, "avg_logprob": -0.08362803739659927, "compression_ratio": 1.7469879518072289, "no_speech_prob": 1.5165354852797464e-05}, {"id": 106, "seek": 69676, "start": 710.84, "end": 717.24, "text": " the connections between them between the nodes and finally you will have the adjacency matrix", "tokens": [50364, 490, 472, 281, 297, 293, 307, 307, 264, 1230, 295, 13891, 294, 428, 294, 428, 4295, 1392, 370, 337, 1365, 341, 486, 312, 50728, 50728, 264, 8186, 472, 732, 1045, 293, 370, 322, 550, 291, 486, 362, 291, 458, 264, 992, 295, 8819, 1936, 436, 366, 51068, 51068, 264, 9271, 1296, 552, 1296, 264, 13891, 293, 2721, 291, 486, 362, 264, 22940, 3020, 8141, 51388, 51388], "temperature": 0.0, "avg_logprob": -0.08362803739659927, "compression_ratio": 1.7469879518072289, "no_speech_prob": 1.5165354852797464e-05}, {"id": 107, "seek": 71724, "start": 717.24, "end": 726.92, "text": " a which will give you the strength of the connection of your of your edge okay okay then you have graph", "tokens": [50364, 257, 597, 486, 976, 291, 264, 3800, 295, 264, 4984, 295, 428, 295, 428, 4691, 1392, 1392, 550, 291, 362, 4295, 50848, 50848, 4122, 370, 337, 1365, 337, 1184, 9984, 9984, 741, 420, 9984, 361, 291, 486, 362, 512, 512, 9984, 4122, 370, 51296, 51296, 309, 311, 1936, 257, 8062, 295, 10139, 1860, 274, 85, 1392, 264, 912, 611, 309, 311, 1944, 300, 291, 393, 483, 51656, 51784], "temperature": 0.0, "avg_logprob": -0.08384207316807338, "compression_ratio": 1.75, "no_speech_prob": 3.0036591851967387e-05}, {"id": 108, "seek": 71724, "start": 726.92, "end": 735.88, "text": " features so for example for each node node i or node j you will have some some node features so", "tokens": [50364, 257, 597, 486, 976, 291, 264, 3800, 295, 264, 4984, 295, 428, 295, 428, 4691, 1392, 1392, 550, 291, 362, 4295, 50848, 50848, 4122, 370, 337, 1365, 337, 1184, 9984, 9984, 741, 420, 9984, 361, 291, 486, 362, 512, 512, 9984, 4122, 370, 51296, 51296, 309, 311, 1936, 257, 8062, 295, 10139, 1860, 274, 85, 1392, 264, 912, 611, 309, 311, 1944, 300, 291, 393, 483, 51656, 51784], "temperature": 0.0, "avg_logprob": -0.08384207316807338, "compression_ratio": 1.75, "no_speech_prob": 3.0036591851967387e-05}, {"id": 109, "seek": 71724, "start": 735.88, "end": 743.08, "text": " it's basically a vector of dimensionality dv okay the same also it's possible that you can get", "tokens": [50364, 257, 597, 486, 976, 291, 264, 3800, 295, 264, 4984, 295, 428, 295, 428, 4691, 1392, 1392, 550, 291, 362, 4295, 50848, 50848, 4122, 370, 337, 1365, 337, 1184, 9984, 9984, 741, 420, 9984, 361, 291, 486, 362, 512, 512, 9984, 4122, 370, 51296, 51296, 309, 311, 1936, 257, 8062, 295, 10139, 1860, 274, 85, 1392, 264, 912, 611, 309, 311, 1944, 300, 291, 393, 483, 51656, 51784], "temperature": 0.0, "avg_logprob": -0.08384207316807338, "compression_ratio": 1.75, "no_speech_prob": 3.0036591851967387e-05}, {"id": 110, "seek": 74308, "start": 743.08, "end": 752.6, "text": " you can get h features and it's going to be a vector of dimensionality d e so for example for", "tokens": [50364, 291, 393, 483, 276, 4122, 293, 309, 311, 516, 281, 312, 257, 8062, 295, 10139, 1860, 274, 308, 370, 337, 1365, 337, 50840, 50840, 13093, 264, 9984, 4111, 1310, 291, 458, 264, 12018, 2010, 293, 264, 4691, 4111, 1310, 264, 6086, 2010, 281, 51128, 51128, 976, 291, 364, 1365, 293, 2721, 291, 393, 362, 611, 512, 4295, 4111, 1392, 337, 439, 337, 264, 1379, 4295, 51428, 51428, 291, 393, 362, 512, 4111, 370, 797, 309, 311, 257, 309, 311, 257, 8062, 295, 10139, 1860, 274, 73, 293, 293, 294, 341, 1389, 51832, 51832], "temperature": 0.0, "avg_logprob": -0.21548046312834088, "compression_ratio": 1.955223880597015, "no_speech_prob": 3.003488563990686e-05}, {"id": 111, "seek": 74308, "start": 752.6, "end": 758.36, "text": " molecules the node feature maybe you know the atom type and the edge feature maybe the bond type to", "tokens": [50364, 291, 393, 483, 276, 4122, 293, 309, 311, 516, 281, 312, 257, 8062, 295, 10139, 1860, 274, 308, 370, 337, 1365, 337, 50840, 50840, 13093, 264, 9984, 4111, 1310, 291, 458, 264, 12018, 2010, 293, 264, 4691, 4111, 1310, 264, 6086, 2010, 281, 51128, 51128, 976, 291, 364, 1365, 293, 2721, 291, 393, 362, 611, 512, 4295, 4111, 1392, 337, 439, 337, 264, 1379, 4295, 51428, 51428, 291, 393, 362, 512, 4111, 370, 797, 309, 311, 257, 309, 311, 257, 8062, 295, 10139, 1860, 274, 73, 293, 293, 294, 341, 1389, 51832, 51832], "temperature": 0.0, "avg_logprob": -0.21548046312834088, "compression_ratio": 1.955223880597015, "no_speech_prob": 3.003488563990686e-05}, {"id": 112, "seek": 74308, "start": 758.36, "end": 764.36, "text": " give you an example and finally you can have also some graph feature okay for all for the whole graph", "tokens": [50364, 291, 393, 483, 276, 4122, 293, 309, 311, 516, 281, 312, 257, 8062, 295, 10139, 1860, 274, 308, 370, 337, 1365, 337, 50840, 50840, 13093, 264, 9984, 4111, 1310, 291, 458, 264, 12018, 2010, 293, 264, 4691, 4111, 1310, 264, 6086, 2010, 281, 51128, 51128, 976, 291, 364, 1365, 293, 2721, 291, 393, 362, 611, 512, 4295, 4111, 1392, 337, 439, 337, 264, 1379, 4295, 51428, 51428, 291, 393, 362, 512, 4111, 370, 797, 309, 311, 257, 309, 311, 257, 8062, 295, 10139, 1860, 274, 73, 293, 293, 294, 341, 1389, 51832, 51832], "temperature": 0.0, "avg_logprob": -0.21548046312834088, "compression_ratio": 1.955223880597015, "no_speech_prob": 3.003488563990686e-05}, {"id": 113, "seek": 74308, "start": 764.36, "end": 772.44, "text": " you can have some feature so again it's a it's a vector of dimensionality dj and and in this case", "tokens": [50364, 291, 393, 483, 276, 4122, 293, 309, 311, 516, 281, 312, 257, 8062, 295, 10139, 1860, 274, 308, 370, 337, 1365, 337, 50840, 50840, 13093, 264, 9984, 4111, 1310, 291, 458, 264, 12018, 2010, 293, 264, 4691, 4111, 1310, 264, 6086, 2010, 281, 51128, 51128, 976, 291, 364, 1365, 293, 2721, 291, 393, 362, 611, 512, 4295, 4111, 1392, 337, 439, 337, 264, 1379, 4295, 51428, 51428, 291, 393, 362, 512, 4111, 370, 797, 309, 311, 257, 309, 311, 257, 8062, 295, 10139, 1860, 274, 73, 293, 293, 294, 341, 1389, 51832, 51832], "temperature": 0.0, "avg_logprob": -0.21548046312834088, "compression_ratio": 1.955223880597015, "no_speech_prob": 3.003488563990686e-05}, {"id": 114, "seek": 77244, "start": 772.44, "end": 777.6400000000001, "text": " and and in the case of of of chemistry that that might be the molecule energy", "tokens": [50364, 293, 293, 294, 264, 1389, 295, 295, 295, 12558, 300, 300, 1062, 312, 264, 15582, 2281, 50624, 50696, 1392, 370, 341, 307, 1105, 741, 576, 584, 264, 2674, 7123, 295, 295, 24877, 50912, 51064, 1392, 370, 586, 437, 741, 478, 516, 281, 360, 307, 300, 741, 478, 516, 281, 751, 466, 51232, 51232, 45216, 293, 264, 1168, 577, 360, 321, 10101, 45216, 281, 24877, 51448, 51616], "temperature": 0.0, "avg_logprob": -0.08170181863448199, "compression_ratio": 1.6993865030674846, "no_speech_prob": 1.1255636309215333e-05}, {"id": 115, "seek": 77244, "start": 779.08, "end": 783.4000000000001, "text": " okay so this is um i would say the general definition of of graphs", "tokens": [50364, 293, 293, 294, 264, 1389, 295, 295, 295, 12558, 300, 300, 1062, 312, 264, 15582, 2281, 50624, 50696, 1392, 370, 341, 307, 1105, 741, 576, 584, 264, 2674, 7123, 295, 295, 24877, 50912, 51064, 1392, 370, 586, 437, 741, 478, 516, 281, 360, 307, 300, 741, 478, 516, 281, 751, 466, 51232, 51232, 45216, 293, 264, 1168, 577, 360, 321, 10101, 45216, 281, 24877, 51448, 51616], "temperature": 0.0, "avg_logprob": -0.08170181863448199, "compression_ratio": 1.6993865030674846, "no_speech_prob": 1.1255636309215333e-05}, {"id": 116, "seek": 77244, "start": 786.44, "end": 789.8000000000001, "text": " okay so now what i'm going to do is that i'm going to talk about", "tokens": [50364, 293, 293, 294, 264, 1389, 295, 295, 295, 12558, 300, 300, 1062, 312, 264, 15582, 2281, 50624, 50696, 1392, 370, 341, 307, 1105, 741, 576, 584, 264, 2674, 7123, 295, 295, 24877, 50912, 51064, 1392, 370, 586, 437, 741, 478, 516, 281, 360, 307, 300, 741, 478, 516, 281, 751, 466, 51232, 51232, 45216, 293, 264, 1168, 577, 360, 321, 10101, 45216, 281, 24877, 51448, 51616], "temperature": 0.0, "avg_logprob": -0.08170181863448199, "compression_ratio": 1.6993865030674846, "no_speech_prob": 1.1255636309215333e-05}, {"id": 117, "seek": 77244, "start": 789.8000000000001, "end": 794.12, "text": " convolution and the question how do we extend convolution to graphs", "tokens": [50364, 293, 293, 294, 264, 1389, 295, 295, 295, 12558, 300, 300, 1062, 312, 264, 15582, 2281, 50624, 50696, 1392, 370, 341, 307, 1105, 741, 576, 584, 264, 2674, 7123, 295, 295, 24877, 50912, 51064, 1392, 370, 586, 437, 741, 478, 516, 281, 360, 307, 300, 741, 478, 516, 281, 751, 466, 51232, 51232, 45216, 293, 264, 1168, 577, 360, 321, 10101, 45216, 281, 24877, 51448, 51616], "temperature": 0.0, "avg_logprob": -0.08170181863448199, "compression_ratio": 1.6993865030674846, "no_speech_prob": 1.1255636309215333e-05}, {"id": 118, "seek": 79412, "start": 794.12, "end": 801.72, "text": " okay so first let me remind you the classical way to use convolutional layer for grids when we use", "tokens": [50364, 1392, 370, 700, 718, 385, 4160, 291, 264, 13735, 636, 281, 764, 45216, 304, 4583, 337, 677, 3742, 562, 321, 764, 50744, 50744, 1497, 7129, 337, 3820, 5201, 370, 718, 311, 584, 741, 362, 341, 3256, 293, 420, 1310, 341, 307, 512, 291, 458, 51244, 51288, 7633, 4111, 412, 4583, 287, 1392, 293, 741, 478, 516, 281, 360, 264, 45216, 365, 512, 5102, 420, 7605, 51708, 51708], "temperature": 0.0, "avg_logprob": -0.25799754046011664, "compression_ratio": 1.625, "no_speech_prob": 1.4857704627502244e-05}, {"id": 119, "seek": 79412, "start": 801.72, "end": 811.72, "text": " confnet for computer vision so let's say i have this image and or maybe this is some you know", "tokens": [50364, 1392, 370, 700, 718, 385, 4160, 291, 264, 13735, 636, 281, 764, 45216, 304, 4583, 337, 677, 3742, 562, 321, 764, 50744, 50744, 1497, 7129, 337, 3820, 5201, 370, 718, 311, 584, 741, 362, 341, 3256, 293, 420, 1310, 341, 307, 512, 291, 458, 51244, 51288, 7633, 4111, 412, 4583, 287, 1392, 293, 741, 478, 516, 281, 360, 264, 45216, 365, 512, 5102, 420, 7605, 51708, 51708], "temperature": 0.0, "avg_logprob": -0.25799754046011664, "compression_ratio": 1.625, "no_speech_prob": 1.4857704627502244e-05}, {"id": 120, "seek": 79412, "start": 812.6, "end": 821.0, "text": " hidden feature at layer l okay and i'm going to do the convolution with some pattern or curve", "tokens": [50364, 1392, 370, 700, 718, 385, 4160, 291, 264, 13735, 636, 281, 764, 45216, 304, 4583, 337, 677, 3742, 562, 321, 764, 50744, 50744, 1497, 7129, 337, 3820, 5201, 370, 718, 311, 584, 741, 362, 341, 3256, 293, 420, 1310, 341, 307, 512, 291, 458, 51244, 51288, 7633, 4111, 412, 4583, 287, 1392, 293, 741, 478, 516, 281, 360, 264, 45216, 365, 512, 5102, 420, 7605, 51708, 51708], "temperature": 0.0, "avg_logprob": -0.25799754046011664, "compression_ratio": 1.625, "no_speech_prob": 1.4857704627502244e-05}, {"id": 121, "seek": 82100, "start": 821.0, "end": 828.68, "text": " with some pattern or kernel that of course i will learn by back propagation and then i will get", "tokens": [50364, 365, 512, 5102, 420, 28256, 300, 295, 1164, 741, 486, 1466, 538, 646, 38377, 293, 550, 741, 486, 483, 50748, 50748, 512, 24433, 1392, 370, 341, 307, 264, 264, 4122, 412, 264, 958, 4583, 370, 281, 976, 291, 1310, 512, 51116, 51116, 10139, 1860, 370, 337, 1365, 297, 16, 293, 568, 307, 516, 281, 312, 264, 1230, 295, 18668, 294, 264, 2031, 293, 288, 3513, 51408, 51408, 293, 274, 307, 264, 10139, 1860, 295, 295, 1184, 19261, 370, 498, 341, 307, 257, 2017, 3256, 264, 10139, 1860, 307, 51756, 51756], "temperature": 0.0, "avg_logprob": -0.0655157877051312, "compression_ratio": 1.8238095238095238, "no_speech_prob": 8.450269888271578e-06}, {"id": 122, "seek": 82100, "start": 828.68, "end": 836.04, "text": " some activation okay so this is the the features at the next layer so to give you maybe some", "tokens": [50364, 365, 512, 5102, 420, 28256, 300, 295, 1164, 741, 486, 1466, 538, 646, 38377, 293, 550, 741, 486, 483, 50748, 50748, 512, 24433, 1392, 370, 341, 307, 264, 264, 4122, 412, 264, 958, 4583, 370, 281, 976, 291, 1310, 512, 51116, 51116, 10139, 1860, 370, 337, 1365, 297, 16, 293, 568, 307, 516, 281, 312, 264, 1230, 295, 18668, 294, 264, 2031, 293, 288, 3513, 51408, 51408, 293, 274, 307, 264, 10139, 1860, 295, 295, 1184, 19261, 370, 498, 341, 307, 257, 2017, 3256, 264, 10139, 1860, 307, 51756, 51756], "temperature": 0.0, "avg_logprob": -0.0655157877051312, "compression_ratio": 1.8238095238095238, "no_speech_prob": 8.450269888271578e-06}, {"id": 123, "seek": 82100, "start": 836.04, "end": 841.88, "text": " dimensionality so for example n1 and 2 is going to be the number of pixels in the x and y direction", "tokens": [50364, 365, 512, 5102, 420, 28256, 300, 295, 1164, 741, 486, 1466, 538, 646, 38377, 293, 550, 741, 486, 483, 50748, 50748, 512, 24433, 1392, 370, 341, 307, 264, 264, 4122, 412, 264, 958, 4583, 370, 281, 976, 291, 1310, 512, 51116, 51116, 10139, 1860, 370, 337, 1365, 297, 16, 293, 568, 307, 516, 281, 312, 264, 1230, 295, 18668, 294, 264, 2031, 293, 288, 3513, 51408, 51408, 293, 274, 307, 264, 10139, 1860, 295, 295, 1184, 19261, 370, 498, 341, 307, 257, 2017, 3256, 264, 10139, 1860, 307, 51756, 51756], "temperature": 0.0, "avg_logprob": -0.0655157877051312, "compression_ratio": 1.8238095238095238, "no_speech_prob": 8.450269888271578e-06}, {"id": 124, "seek": 82100, "start": 841.88, "end": 848.84, "text": " and d is the dimensionality of of each pixel so if this is a color image the dimensionality is", "tokens": [50364, 365, 512, 5102, 420, 28256, 300, 295, 1164, 741, 486, 1466, 538, 646, 38377, 293, 550, 741, 486, 483, 50748, 50748, 512, 24433, 1392, 370, 341, 307, 264, 264, 4122, 412, 264, 958, 4583, 370, 281, 976, 291, 1310, 512, 51116, 51116, 10139, 1860, 370, 337, 1365, 297, 16, 293, 568, 307, 516, 281, 312, 264, 1230, 295, 18668, 294, 264, 2031, 293, 288, 3513, 51408, 51408, 293, 274, 307, 264, 10139, 1860, 295, 295, 1184, 19261, 370, 498, 341, 307, 257, 2017, 3256, 264, 10139, 1860, 307, 51756, 51756], "temperature": 0.0, "avg_logprob": -0.0655157877051312, "compression_ratio": 1.8238095238095238, "no_speech_prob": 8.450269888271578e-06}, {"id": 125, "seek": 84884, "start": 848.84, "end": 855.1600000000001, "text": " going to be 3 for the three colors and if this is like intermediate hidden feature maybe you have", "tokens": [50364, 516, 281, 312, 805, 337, 264, 1045, 4577, 293, 498, 341, 307, 411, 19376, 7633, 4111, 1310, 291, 362, 50680, 50680, 2319, 291, 458, 12819, 337, 264, 28256, 2673, 291, 747, 1359, 23434, 1625, 570, 291, 528, 281, 458, 264, 51000, 51036, 2654, 21682, 2519, 370, 300, 1062, 312, 291, 458, 805, 538, 805, 18668, 28256, 420, 1025, 538, 1025, 293, 295, 1164, 291, 51424, 51424, 362, 274, 570, 291, 643, 281, 281, 3104, 264, 10139, 1860, 295, 428, 4846, 295, 428, 4846, 4122, 51728], "temperature": 0.0, "avg_logprob": -0.10361795315797302, "compression_ratio": 1.7671232876712328, "no_speech_prob": 4.4186917875777e-06}, {"id": 126, "seek": 84884, "start": 855.1600000000001, "end": 861.5600000000001, "text": " 100 you know dimensions for the kernel usually you take small kernels because you want to know the", "tokens": [50364, 516, 281, 312, 805, 337, 264, 1045, 4577, 293, 498, 341, 307, 411, 19376, 7633, 4111, 1310, 291, 362, 50680, 50680, 2319, 291, 458, 12819, 337, 264, 28256, 2673, 291, 747, 1359, 23434, 1625, 570, 291, 528, 281, 458, 264, 51000, 51036, 2654, 21682, 2519, 370, 300, 1062, 312, 291, 458, 805, 538, 805, 18668, 28256, 420, 1025, 538, 1025, 293, 295, 1164, 291, 51424, 51424, 362, 274, 570, 291, 643, 281, 281, 3104, 264, 10139, 1860, 295, 428, 4846, 295, 428, 4846, 4122, 51728], "temperature": 0.0, "avg_logprob": -0.10361795315797302, "compression_ratio": 1.7671232876712328, "no_speech_prob": 4.4186917875777e-06}, {"id": 127, "seek": 84884, "start": 862.2800000000001, "end": 870.0400000000001, "text": " local reception field so that might be you know 3 by 3 pixels kernel or 5 by 5 and of course you", "tokens": [50364, 516, 281, 312, 805, 337, 264, 1045, 4577, 293, 498, 341, 307, 411, 19376, 7633, 4111, 1310, 291, 362, 50680, 50680, 2319, 291, 458, 12819, 337, 264, 28256, 2673, 291, 747, 1359, 23434, 1625, 570, 291, 528, 281, 458, 264, 51000, 51036, 2654, 21682, 2519, 370, 300, 1062, 312, 291, 458, 805, 538, 805, 18668, 28256, 420, 1025, 538, 1025, 293, 295, 1164, 291, 51424, 51424, 362, 274, 570, 291, 643, 281, 281, 3104, 264, 10139, 1860, 295, 428, 4846, 295, 428, 4846, 4122, 51728], "temperature": 0.0, "avg_logprob": -0.10361795315797302, "compression_ratio": 1.7671232876712328, "no_speech_prob": 4.4186917875777e-06}, {"id": 128, "seek": 87004, "start": 870.04, "end": 879.3199999999999, "text": " have d because you need to to respect the dimensionality of your input features okay", "tokens": [50364, 362, 274, 570, 291, 643, 281, 281, 3104, 264, 10139, 1860, 295, 428, 4846, 4122, 1392, 50828, 50828, 370, 1310, 337, 341, 472, 370, 291, 536, 300, 370, 291, 366, 516, 281, 7620, 341, 3256, 365, 341, 4111, 51100, 51100, 597, 307, 21841, 294, 341, 3513, 370, 291, 486, 1936, 5876, 291, 458, 3876, 294, 294, 294, 341, 51532, 51532, 3513, 295, 264, 3256, 370, 300, 390, 445, 364, 1365, 293, 321, 764, 39562, 558, 558, 586, 558, 370, 321, 51848, 51848], "temperature": 0.0, "avg_logprob": -0.06285959766024635, "compression_ratio": 1.776190476190476, "no_speech_prob": 1.9097493350272998e-05}, {"id": 129, "seek": 87004, "start": 879.3199999999999, "end": 884.76, "text": " so maybe for this one so you see that so you are going to convert this image with this feature", "tokens": [50364, 362, 274, 570, 291, 643, 281, 281, 3104, 264, 10139, 1860, 295, 428, 4846, 4122, 1392, 50828, 50828, 370, 1310, 337, 341, 472, 370, 291, 536, 300, 370, 291, 366, 516, 281, 7620, 341, 3256, 365, 341, 4111, 51100, 51100, 597, 307, 21841, 294, 341, 3513, 370, 291, 486, 1936, 5876, 291, 458, 3876, 294, 294, 294, 341, 51532, 51532, 3513, 295, 264, 3256, 370, 300, 390, 445, 364, 1365, 293, 321, 764, 39562, 558, 558, 586, 558, 370, 321, 51848, 51848], "temperature": 0.0, "avg_logprob": -0.06285959766024635, "compression_ratio": 1.776190476190476, "no_speech_prob": 1.9097493350272998e-05}, {"id": 130, "seek": 87004, "start": 884.76, "end": 893.4, "text": " which is oriented in this direction so you will basically identify you know lines in in in this", "tokens": [50364, 362, 274, 570, 291, 643, 281, 281, 3104, 264, 10139, 1860, 295, 428, 4846, 4122, 1392, 50828, 50828, 370, 1310, 337, 341, 472, 370, 291, 536, 300, 370, 291, 366, 516, 281, 7620, 341, 3256, 365, 341, 4111, 51100, 51100, 597, 307, 21841, 294, 341, 3513, 370, 291, 486, 1936, 5876, 291, 458, 3876, 294, 294, 294, 341, 51532, 51532, 3513, 295, 264, 3256, 370, 300, 390, 445, 364, 1365, 293, 321, 764, 39562, 558, 558, 586, 558, 370, 321, 51848, 51848], "temperature": 0.0, "avg_logprob": -0.06285959766024635, "compression_ratio": 1.776190476190476, "no_speech_prob": 1.9097493350272998e-05}, {"id": 131, "seek": 87004, "start": 893.4, "end": 899.7199999999999, "text": " direction of the image so that was just an example and we use padding right right now right so we", "tokens": [50364, 362, 274, 570, 291, 643, 281, 281, 3104, 264, 10139, 1860, 295, 428, 4846, 4122, 1392, 50828, 50828, 370, 1310, 337, 341, 472, 370, 291, 536, 300, 370, 291, 366, 516, 281, 7620, 341, 3256, 365, 341, 4111, 51100, 51100, 597, 307, 21841, 294, 341, 3513, 370, 291, 486, 1936, 5876, 291, 458, 3876, 294, 294, 294, 341, 51532, 51532, 3513, 295, 264, 3256, 370, 300, 390, 445, 364, 1365, 293, 321, 764, 39562, 558, 558, 586, 558, 370, 321, 51848, 51848], "temperature": 0.0, "avg_logprob": -0.06285959766024635, "compression_ratio": 1.776190476190476, "no_speech_prob": 1.9097493350272998e-05}, {"id": 132, "seek": 89972, "start": 899.72, "end": 905.08, "text": " had the same dimensionality of the yes yes absolutely again just padding so you basically", "tokens": [50364, 632, 264, 912, 10139, 1860, 295, 264, 2086, 2086, 3122, 797, 445, 39562, 370, 291, 1936, 50632, 50632, 291, 500, 380, 5407, 264, 2744, 295, 428, 3256, 558, 1338, 1392, 370, 370, 577, 360, 321, 44003, 6964, 51036, 51036, 45216, 370, 264, 700, 7123, 307, 281, 360, 307, 281, 536, 45216, 382, 257, 12379, 14324, 1392, 370, 51500, 51528], "temperature": 0.0, "avg_logprob": -0.09690827228983895, "compression_ratio": 1.6627218934911243, "no_speech_prob": 3.799611295107752e-05}, {"id": 133, "seek": 89972, "start": 905.08, "end": 913.1600000000001, "text": " you don't reduce the size of your image right yeah okay so so how do we mathematically define", "tokens": [50364, 632, 264, 912, 10139, 1860, 295, 264, 2086, 2086, 3122, 797, 445, 39562, 370, 291, 1936, 50632, 50632, 291, 500, 380, 5407, 264, 2744, 295, 428, 3256, 558, 1338, 1392, 370, 370, 577, 360, 321, 44003, 6964, 51036, 51036, 45216, 370, 264, 700, 7123, 307, 281, 360, 307, 281, 536, 45216, 382, 257, 12379, 14324, 1392, 370, 51500, 51528], "temperature": 0.0, "avg_logprob": -0.09690827228983895, "compression_ratio": 1.6627218934911243, "no_speech_prob": 3.799611295107752e-05}, {"id": 134, "seek": 89972, "start": 913.1600000000001, "end": 922.44, "text": " convolution so the first definition is to do is to see convolution as a template matching okay so", "tokens": [50364, 632, 264, 912, 10139, 1860, 295, 264, 2086, 2086, 3122, 797, 445, 39562, 370, 291, 1936, 50632, 50632, 291, 500, 380, 5407, 264, 2744, 295, 428, 3256, 558, 1338, 1392, 370, 370, 577, 360, 321, 44003, 6964, 51036, 51036, 45216, 370, 264, 700, 7123, 307, 281, 360, 307, 281, 536, 45216, 382, 257, 12379, 14324, 1392, 370, 51500, 51528], "temperature": 0.0, "avg_logprob": -0.09690827228983895, "compression_ratio": 1.6627218934911243, "no_speech_prob": 3.799611295107752e-05}, {"id": 135, "seek": 92244, "start": 922.44, "end": 929.8000000000001, "text": " so template matching so here is the definition the mathematical definition of convolution so what", "tokens": [50364, 370, 12379, 14324, 370, 510, 307, 264, 7123, 264, 18894, 7123, 295, 45216, 370, 437, 50732, 50732, 291, 434, 516, 281, 360, 307, 300, 291, 434, 516, 281, 747, 428, 12379, 291, 434, 516, 281, 747, 428, 3256, 50956, 50956, 293, 550, 291, 366, 516, 281, 2408, 670, 264, 8186, 294, 264, 1379, 3256, 9274, 10498, 1392, 295, 261, 73, 293, 341, 51556, 51556], "temperature": 0.0, "avg_logprob": -0.11708797108043324, "compression_ratio": 1.9072847682119205, "no_speech_prob": 9.952949767466635e-06}, {"id": 136, "seek": 92244, "start": 929.8000000000001, "end": 934.2800000000001, "text": " you're going to do is that you're going to take your template you're going to take your image", "tokens": [50364, 370, 12379, 14324, 370, 510, 307, 264, 7123, 264, 18894, 7123, 295, 45216, 370, 437, 50732, 50732, 291, 434, 516, 281, 360, 307, 300, 291, 434, 516, 281, 747, 428, 12379, 291, 434, 516, 281, 747, 428, 3256, 50956, 50956, 293, 550, 291, 366, 516, 281, 2408, 670, 264, 8186, 294, 264, 1379, 3256, 9274, 10498, 1392, 295, 261, 73, 293, 341, 51556, 51556], "temperature": 0.0, "avg_logprob": -0.11708797108043324, "compression_ratio": 1.9072847682119205, "no_speech_prob": 9.952949767466635e-06}, {"id": 137, "seek": 92244, "start": 934.2800000000001, "end": 946.2800000000001, "text": " and then you are going to sum over the index in the whole image domain omega okay of wj and this", "tokens": [50364, 370, 12379, 14324, 370, 510, 307, 264, 7123, 264, 18894, 7123, 295, 45216, 370, 437, 50732, 50732, 291, 434, 516, 281, 360, 307, 300, 291, 434, 516, 281, 747, 428, 12379, 291, 434, 516, 281, 747, 428, 3256, 50956, 50956, 293, 550, 291, 366, 516, 281, 2408, 670, 264, 8186, 294, 264, 1379, 3256, 9274, 10498, 1392, 295, 261, 73, 293, 341, 51556, 51556], "temperature": 0.0, "avg_logprob": -0.11708797108043324, "compression_ratio": 1.9072847682119205, "no_speech_prob": 9.952949767466635e-06}, {"id": 138, "seek": 94628, "start": 946.28, "end": 953.88, "text": " is going to be a product between vector wj and vector hi minus j okay so this is the pure", "tokens": [50364, 307, 516, 281, 312, 257, 1674, 1296, 8062, 261, 73, 293, 8062, 4879, 3175, 361, 1392, 370, 341, 307, 264, 6075, 50744, 50744, 7123, 295, 45216, 293, 437, 321, 360, 2673, 294, 294, 3820, 5201, 307, 300, 321, 500, 380, 747, 3175, 51040, 51040, 321, 747, 1804, 1392, 293, 321, 818, 300, 570, 562, 321, 562, 321, 360, 300, 321, 362, 264, 7123, 295, 51296, 51296, 20009, 293, 341, 307, 341, 307, 291, 458, 570, 309, 311, 544, 411, 309, 311, 2293, 411, 12379, 14324, 51596, 51596], "temperature": 0.0, "avg_logprob": -0.12836058755938926, "compression_ratio": 1.8676470588235294, "no_speech_prob": 6.678935733361868e-07}, {"id": 139, "seek": 94628, "start": 953.88, "end": 959.8, "text": " definition of convolution and what we do usually in in computer vision is that we don't take minus", "tokens": [50364, 307, 516, 281, 312, 257, 1674, 1296, 8062, 261, 73, 293, 8062, 4879, 3175, 361, 1392, 370, 341, 307, 264, 6075, 50744, 50744, 7123, 295, 45216, 293, 437, 321, 360, 2673, 294, 294, 3820, 5201, 307, 300, 321, 500, 380, 747, 3175, 51040, 51040, 321, 747, 1804, 1392, 293, 321, 818, 300, 570, 562, 321, 562, 321, 360, 300, 321, 362, 264, 7123, 295, 51296, 51296, 20009, 293, 341, 307, 341, 307, 291, 458, 570, 309, 311, 544, 411, 309, 311, 2293, 411, 12379, 14324, 51596, 51596], "temperature": 0.0, "avg_logprob": -0.12836058755938926, "compression_ratio": 1.8676470588235294, "no_speech_prob": 6.678935733361868e-07}, {"id": 140, "seek": 94628, "start": 959.8, "end": 964.92, "text": " we take plus okay and we call that because when we when we do that we have the definition of", "tokens": [50364, 307, 516, 281, 312, 257, 1674, 1296, 8062, 261, 73, 293, 8062, 4879, 3175, 361, 1392, 370, 341, 307, 264, 6075, 50744, 50744, 7123, 295, 45216, 293, 437, 321, 360, 2673, 294, 294, 3820, 5201, 307, 300, 321, 500, 380, 747, 3175, 51040, 51040, 321, 747, 1804, 1392, 293, 321, 818, 300, 570, 562, 321, 562, 321, 360, 300, 321, 362, 264, 7123, 295, 51296, 51296, 20009, 293, 341, 307, 341, 307, 291, 458, 570, 309, 311, 544, 411, 309, 311, 2293, 411, 12379, 14324, 51596, 51596], "temperature": 0.0, "avg_logprob": -0.12836058755938926, "compression_ratio": 1.8676470588235294, "no_speech_prob": 6.678935733361868e-07}, {"id": 141, "seek": 94628, "start": 964.92, "end": 970.92, "text": " correlation and this is this is you know because it's more like it's exactly like template matching", "tokens": [50364, 307, 516, 281, 312, 257, 1674, 1296, 8062, 261, 73, 293, 8062, 4879, 3175, 361, 1392, 370, 341, 307, 264, 6075, 50744, 50744, 7123, 295, 45216, 293, 437, 321, 360, 2673, 294, 294, 3820, 5201, 307, 300, 321, 500, 380, 747, 3175, 51040, 51040, 321, 747, 1804, 1392, 293, 321, 818, 300, 570, 562, 321, 562, 321, 360, 300, 321, 362, 264, 7123, 295, 51296, 51296, 20009, 293, 341, 307, 341, 307, 291, 458, 570, 309, 311, 544, 411, 309, 311, 2293, 411, 12379, 14324, 51596, 51596], "temperature": 0.0, "avg_logprob": -0.12836058755938926, "compression_ratio": 1.8676470588235294, "no_speech_prob": 6.678935733361868e-07}, {"id": 142, "seek": 97092, "start": 970.92, "end": 977.7199999999999, "text": " okay so it doesn't change anything if you if you do i minus j or i plus j in the learning sense", "tokens": [50364, 1392, 370, 309, 1177, 380, 1319, 1340, 498, 291, 498, 291, 360, 741, 3175, 361, 420, 741, 1804, 361, 294, 264, 2539, 2020, 50704, 50704, 570, 264, 787, 551, 300, 291, 360, 307, 300, 291, 7929, 493, 293, 760, 293, 1411, 293, 558, 428, 428, 51000, 51000, 428, 428, 428, 28256, 293, 562, 291, 1466, 309, 1177, 380, 1319, 1340, 1936, 1392, 457, 341, 307, 264, 51272, 51272, 7123, 295, 20009, 370, 309, 311, 309, 311, 534, 257, 12379, 14324, 293, 550, 286, 478, 516, 281, 747, 337, 51512, 51512, 264, 24657, 741, 73, 1392, 370, 1936, 293, 1338, 293, 746, 588, 1021, 300, 291, 362, 510, 307, 51772, 51772], "temperature": 0.0, "avg_logprob": -0.13246499640601023, "compression_ratio": 1.983402489626556, "no_speech_prob": 3.6103001548326574e-06}, {"id": 143, "seek": 97092, "start": 977.7199999999999, "end": 983.64, "text": " because the only thing that you do is that you flip up and down and left and right your your", "tokens": [50364, 1392, 370, 309, 1177, 380, 1319, 1340, 498, 291, 498, 291, 360, 741, 3175, 361, 420, 741, 1804, 361, 294, 264, 2539, 2020, 50704, 50704, 570, 264, 787, 551, 300, 291, 360, 307, 300, 291, 7929, 493, 293, 760, 293, 1411, 293, 558, 428, 428, 51000, 51000, 428, 428, 428, 28256, 293, 562, 291, 1466, 309, 1177, 380, 1319, 1340, 1936, 1392, 457, 341, 307, 264, 51272, 51272, 7123, 295, 20009, 370, 309, 311, 309, 311, 534, 257, 12379, 14324, 293, 550, 286, 478, 516, 281, 747, 337, 51512, 51512, 264, 24657, 741, 73, 1392, 370, 1936, 293, 1338, 293, 746, 588, 1021, 300, 291, 362, 510, 307, 51772, 51772], "temperature": 0.0, "avg_logprob": -0.13246499640601023, "compression_ratio": 1.983402489626556, "no_speech_prob": 3.6103001548326574e-06}, {"id": 144, "seek": 97092, "start": 983.64, "end": 989.0799999999999, "text": " your your your kernel and when you learn it doesn't change anything basically okay but this is the", "tokens": [50364, 1392, 370, 309, 1177, 380, 1319, 1340, 498, 291, 498, 291, 360, 741, 3175, 361, 420, 741, 1804, 361, 294, 264, 2539, 2020, 50704, 50704, 570, 264, 787, 551, 300, 291, 360, 307, 300, 291, 7929, 493, 293, 760, 293, 1411, 293, 558, 428, 428, 51000, 51000, 428, 428, 428, 28256, 293, 562, 291, 1466, 309, 1177, 380, 1319, 1340, 1936, 1392, 457, 341, 307, 264, 51272, 51272, 7123, 295, 20009, 370, 309, 311, 309, 311, 534, 257, 12379, 14324, 293, 550, 286, 478, 516, 281, 747, 337, 51512, 51512, 264, 24657, 741, 73, 1392, 370, 1936, 293, 1338, 293, 746, 588, 1021, 300, 291, 362, 510, 307, 51772, 51772], "temperature": 0.0, "avg_logprob": -0.13246499640601023, "compression_ratio": 1.983402489626556, "no_speech_prob": 3.6103001548326574e-06}, {"id": 145, "seek": 97092, "start": 989.0799999999999, "end": 993.88, "text": " definition of correlation so it's it's really a template matching and then I'm going to take for", "tokens": [50364, 1392, 370, 309, 1177, 380, 1319, 1340, 498, 291, 498, 291, 360, 741, 3175, 361, 420, 741, 1804, 361, 294, 264, 2539, 2020, 50704, 50704, 570, 264, 787, 551, 300, 291, 360, 307, 300, 291, 7929, 493, 293, 760, 293, 1411, 293, 558, 428, 428, 51000, 51000, 428, 428, 428, 28256, 293, 562, 291, 1466, 309, 1177, 380, 1319, 1340, 1936, 1392, 457, 341, 307, 264, 51272, 51272, 7123, 295, 20009, 370, 309, 311, 309, 311, 534, 257, 12379, 14324, 293, 550, 286, 478, 516, 281, 747, 337, 51512, 51512, 264, 24657, 741, 73, 1392, 370, 1936, 293, 1338, 293, 746, 588, 1021, 300, 291, 362, 510, 307, 51772, 51772], "temperature": 0.0, "avg_logprob": -0.13246499640601023, "compression_ratio": 1.983402489626556, "no_speech_prob": 3.6103001548326574e-06}, {"id": 146, "seek": 97092, "start": 993.88, "end": 999.0799999999999, "text": " the notation ij okay so basically and yeah and something very important that you have here is", "tokens": [50364, 1392, 370, 309, 1177, 380, 1319, 1340, 498, 291, 498, 291, 360, 741, 3175, 361, 420, 741, 1804, 361, 294, 264, 2539, 2020, 50704, 50704, 570, 264, 787, 551, 300, 291, 360, 307, 300, 291, 7929, 493, 293, 760, 293, 1411, 293, 558, 428, 428, 51000, 51000, 428, 428, 428, 28256, 293, 562, 291, 1466, 309, 1177, 380, 1319, 1340, 1936, 1392, 457, 341, 307, 264, 51272, 51272, 7123, 295, 20009, 370, 309, 311, 309, 311, 534, 257, 12379, 14324, 293, 550, 286, 478, 516, 281, 747, 337, 51512, 51512, 264, 24657, 741, 73, 1392, 370, 1936, 293, 1338, 293, 746, 588, 1021, 300, 291, 362, 510, 307, 51772, 51772], "temperature": 0.0, "avg_logprob": -0.13246499640601023, "compression_ratio": 1.983402489626556, "no_speech_prob": 3.6103001548326574e-06}, {"id": 147, "seek": 99908, "start": 999.08, "end": 1007.64, "text": " that you when when we do convolutional layers we are using kernel with compact support you know", "tokens": [50364, 300, 291, 562, 562, 321, 360, 45216, 304, 7914, 321, 366, 1228, 28256, 365, 14679, 1406, 291, 458, 50792, 50792, 411, 257, 4230, 538, 4230, 309, 311, 588, 1359, 1406, 562, 321, 360, 300, 321, 500, 380, 360, 264, 2408, 670, 264, 1379, 51096, 51096, 9274, 264, 1379, 3256, 9274, 321, 445, 360, 264, 2408, 670, 264, 7630, 295, 264, 9984, 741, 1392, 51408, 51452, 293, 341, 307, 588, 1021, 309, 311, 588, 1021, 570, 5800, 264, 2408, 307, 406, 670, 264, 1379, 51696, 51696], "temperature": 0.0, "avg_logprob": -0.09098257415596096, "compression_ratio": 1.9684210526315788, "no_speech_prob": 2.7459214834379964e-05}, {"id": 148, "seek": 99908, "start": 1007.64, "end": 1013.72, "text": " like a tree by tree it's very small support when we do that we don't do the sum over the whole", "tokens": [50364, 300, 291, 562, 562, 321, 360, 45216, 304, 7914, 321, 366, 1228, 28256, 365, 14679, 1406, 291, 458, 50792, 50792, 411, 257, 4230, 538, 4230, 309, 311, 588, 1359, 1406, 562, 321, 360, 300, 321, 500, 380, 360, 264, 2408, 670, 264, 1379, 51096, 51096, 9274, 264, 1379, 3256, 9274, 321, 445, 360, 264, 2408, 670, 264, 7630, 295, 264, 9984, 741, 1392, 51408, 51452, 293, 341, 307, 588, 1021, 309, 311, 588, 1021, 570, 5800, 264, 2408, 307, 406, 670, 264, 1379, 51696, 51696], "temperature": 0.0, "avg_logprob": -0.09098257415596096, "compression_ratio": 1.9684210526315788, "no_speech_prob": 2.7459214834379964e-05}, {"id": 149, "seek": 99908, "start": 1013.72, "end": 1019.96, "text": " domain the whole image domain we just do the sum over the neighborhood of the node i okay", "tokens": [50364, 300, 291, 562, 562, 321, 360, 45216, 304, 7914, 321, 366, 1228, 28256, 365, 14679, 1406, 291, 458, 50792, 50792, 411, 257, 4230, 538, 4230, 309, 311, 588, 1359, 1406, 562, 321, 360, 300, 321, 500, 380, 360, 264, 2408, 670, 264, 1379, 51096, 51096, 9274, 264, 1379, 3256, 9274, 321, 445, 360, 264, 2408, 670, 264, 7630, 295, 264, 9984, 741, 1392, 51408, 51452, 293, 341, 307, 588, 1021, 309, 311, 588, 1021, 570, 5800, 264, 2408, 307, 406, 670, 264, 1379, 51696, 51696], "temperature": 0.0, "avg_logprob": -0.09098257415596096, "compression_ratio": 1.9684210526315788, "no_speech_prob": 2.7459214834379964e-05}, {"id": 150, "seek": 99908, "start": 1020.84, "end": 1025.72, "text": " and this is very important it's very important because suddenly the sum is not over the whole", "tokens": [50364, 300, 291, 562, 562, 321, 360, 45216, 304, 7914, 321, 366, 1228, 28256, 365, 14679, 1406, 291, 458, 50792, 50792, 411, 257, 4230, 538, 4230, 309, 311, 588, 1359, 1406, 562, 321, 360, 300, 321, 500, 380, 360, 264, 2408, 670, 264, 1379, 51096, 51096, 9274, 264, 1379, 3256, 9274, 321, 445, 360, 264, 2408, 670, 264, 7630, 295, 264, 9984, 741, 1392, 51408, 51452, 293, 341, 307, 588, 1021, 309, 311, 588, 1021, 570, 5800, 264, 2408, 307, 406, 670, 264, 1379, 51696, 51696], "temperature": 0.0, "avg_logprob": -0.09098257415596096, "compression_ratio": 1.9684210526315788, "no_speech_prob": 2.7459214834379964e-05}, {"id": 151, "seek": 102572, "start": 1025.72, "end": 1032.84, "text": " pixel it's just you know in the neighborhood and then the complexity of doing convolution is actually", "tokens": [50364, 19261, 309, 311, 445, 291, 458, 294, 264, 7630, 293, 550, 264, 14024, 295, 884, 45216, 307, 767, 50720, 50768, 281, 264, 1668, 295, 264, 1230, 295, 13891, 370, 264, 1230, 295, 18668, 294, 428, 294, 428, 3256, 370, 370, 264, 264, 51120, 51120, 14024, 307, 1596, 1858, 281, 281, 14722, 370, 437, 291, 434, 516, 281, 360, 307, 300, 291, 434, 516, 281, 747, 51324, 51324, 428, 428, 5102, 291, 434, 516, 281, 13153, 428, 5102, 370, 309, 311, 516, 281, 312, 297, 46586, 570, 51604, 51604], "temperature": 0.0, "avg_logprob": -0.04667887157864041, "compression_ratio": 2.0372340425531914, "no_speech_prob": 8.612072633695789e-06}, {"id": 152, "seek": 102572, "start": 1033.8, "end": 1040.84, "text": " to the order of the number of nodes so the number of pixels in your in your image so so the the", "tokens": [50364, 19261, 309, 311, 445, 291, 458, 294, 264, 7630, 293, 550, 264, 14024, 295, 884, 45216, 307, 767, 50720, 50768, 281, 264, 1668, 295, 264, 1230, 295, 13891, 370, 264, 1230, 295, 18668, 294, 428, 294, 428, 3256, 370, 370, 264, 264, 51120, 51120, 14024, 307, 1596, 1858, 281, 281, 14722, 370, 437, 291, 434, 516, 281, 360, 307, 300, 291, 434, 516, 281, 747, 51324, 51324, 428, 428, 5102, 291, 434, 516, 281, 13153, 428, 5102, 370, 309, 311, 516, 281, 312, 297, 46586, 570, 51604, 51604], "temperature": 0.0, "avg_logprob": -0.04667887157864041, "compression_ratio": 2.0372340425531914, "no_speech_prob": 8.612072633695789e-06}, {"id": 153, "seek": 102572, "start": 1040.84, "end": 1044.92, "text": " complexity is quite easy to to compute so what you're going to do is that you're going to take", "tokens": [50364, 19261, 309, 311, 445, 291, 458, 294, 264, 7630, 293, 550, 264, 14024, 295, 884, 45216, 307, 767, 50720, 50768, 281, 264, 1668, 295, 264, 1230, 295, 13891, 370, 264, 1230, 295, 18668, 294, 428, 294, 428, 3256, 370, 370, 264, 264, 51120, 51120, 14024, 307, 1596, 1858, 281, 281, 14722, 370, 437, 291, 434, 516, 281, 360, 307, 300, 291, 434, 516, 281, 747, 51324, 51324, 428, 428, 5102, 291, 434, 516, 281, 13153, 428, 5102, 370, 309, 311, 516, 281, 312, 297, 46586, 570, 51604, 51604], "temperature": 0.0, "avg_logprob": -0.04667887157864041, "compression_ratio": 2.0372340425531914, "no_speech_prob": 8.612072633695789e-06}, {"id": 154, "seek": 102572, "start": 1044.92, "end": 1050.52, "text": " your your pattern you're going to slice your pattern so it's going to be n slicing because", "tokens": [50364, 19261, 309, 311, 445, 291, 458, 294, 264, 7630, 293, 550, 264, 14024, 295, 884, 45216, 307, 767, 50720, 50768, 281, 264, 1668, 295, 264, 1230, 295, 13891, 370, 264, 1230, 295, 18668, 294, 428, 294, 428, 3256, 370, 370, 264, 264, 51120, 51120, 14024, 307, 1596, 1858, 281, 281, 14722, 370, 437, 291, 434, 516, 281, 360, 307, 300, 291, 434, 516, 281, 747, 51324, 51324, 428, 428, 5102, 291, 434, 516, 281, 13153, 428, 5102, 370, 309, 311, 516, 281, 312, 297, 46586, 570, 51604, 51604], "temperature": 0.0, "avg_logprob": -0.04667887157864041, "compression_ratio": 2.0372340425531914, "no_speech_prob": 8.612072633695789e-06}, {"id": 155, "seek": 105052, "start": 1050.52, "end": 1056.76, "text": " n number of locations and then you're going to do you know a scalar product of three by three", "tokens": [50364, 297, 1230, 295, 9253, 293, 550, 291, 434, 516, 281, 360, 291, 458, 257, 39684, 1674, 295, 1045, 538, 1045, 50676, 50676, 4959, 293, 293, 291, 434, 516, 281, 360, 291, 458, 1105, 264, 8062, 1674, 295, 18875, 295, 10139, 2443, 67, 51108, 51108, 370, 291, 536, 264, 14024, 295, 884, 341, 6916, 307, 445, 297, 1413, 1045, 1413, 1045, 1413, 274, 370, 264, 51388, 51388, 14024, 307, 297, 293, 293, 797, 1203, 393, 312, 1096, 294, 8952, 498, 291, 362, 257, 290, 34859, 264, 24903, 51620, 51620, 300, 291, 366, 884, 294, 341, 294, 341, 4914, 307, 6695, 281, 264, 6211, 300, 291, 366, 884, 51848, 51848], "temperature": 0.0, "avg_logprob": -0.11819426796653054, "compression_ratio": 2.1, "no_speech_prob": 1.2395325938996393e-05}, {"id": 156, "seek": 105052, "start": 1056.76, "end": 1065.4, "text": " elements and and you're going to do you know um the vector product of vectors of dimension 18d", "tokens": [50364, 297, 1230, 295, 9253, 293, 550, 291, 434, 516, 281, 360, 291, 458, 257, 39684, 1674, 295, 1045, 538, 1045, 50676, 50676, 4959, 293, 293, 291, 434, 516, 281, 360, 291, 458, 1105, 264, 8062, 1674, 295, 18875, 295, 10139, 2443, 67, 51108, 51108, 370, 291, 536, 264, 14024, 295, 884, 341, 6916, 307, 445, 297, 1413, 1045, 1413, 1045, 1413, 274, 370, 264, 51388, 51388, 14024, 307, 297, 293, 293, 797, 1203, 393, 312, 1096, 294, 8952, 498, 291, 362, 257, 290, 34859, 264, 24903, 51620, 51620, 300, 291, 366, 884, 294, 341, 294, 341, 4914, 307, 6695, 281, 264, 6211, 300, 291, 366, 884, 51848, 51848], "temperature": 0.0, "avg_logprob": -0.11819426796653054, "compression_ratio": 2.1, "no_speech_prob": 1.2395325938996393e-05}, {"id": 157, "seek": 105052, "start": 1065.4, "end": 1071.0, "text": " so you see the complexity of doing this operation is just n times three times three times d so the", "tokens": [50364, 297, 1230, 295, 9253, 293, 550, 291, 434, 516, 281, 360, 291, 458, 257, 39684, 1674, 295, 1045, 538, 1045, 50676, 50676, 4959, 293, 293, 291, 434, 516, 281, 360, 291, 458, 1105, 264, 8062, 1674, 295, 18875, 295, 10139, 2443, 67, 51108, 51108, 370, 291, 536, 264, 14024, 295, 884, 341, 6916, 307, 445, 297, 1413, 1045, 1413, 1045, 1413, 274, 370, 264, 51388, 51388, 14024, 307, 297, 293, 293, 797, 1203, 393, 312, 1096, 294, 8952, 498, 291, 362, 257, 290, 34859, 264, 24903, 51620, 51620, 300, 291, 366, 884, 294, 341, 294, 341, 4914, 307, 6695, 281, 264, 6211, 300, 291, 366, 884, 51848, 51848], "temperature": 0.0, "avg_logprob": -0.11819426796653054, "compression_ratio": 2.1, "no_speech_prob": 1.2395325938996393e-05}, {"id": 158, "seek": 105052, "start": 1071.0, "end": 1075.6399999999999, "text": " complexity is n and and again everything can be done in parallel if you have a gpu the computation", "tokens": [50364, 297, 1230, 295, 9253, 293, 550, 291, 434, 516, 281, 360, 291, 458, 257, 39684, 1674, 295, 1045, 538, 1045, 50676, 50676, 4959, 293, 293, 291, 434, 516, 281, 360, 291, 458, 1105, 264, 8062, 1674, 295, 18875, 295, 10139, 2443, 67, 51108, 51108, 370, 291, 536, 264, 14024, 295, 884, 341, 6916, 307, 445, 297, 1413, 1045, 1413, 1045, 1413, 274, 370, 264, 51388, 51388, 14024, 307, 297, 293, 293, 797, 1203, 393, 312, 1096, 294, 8952, 498, 291, 362, 257, 290, 34859, 264, 24903, 51620, 51620, 300, 291, 366, 884, 294, 341, 294, 341, 4914, 307, 6695, 281, 264, 6211, 300, 291, 366, 884, 51848, 51848], "temperature": 0.0, "avg_logprob": -0.11819426796653054, "compression_ratio": 2.1, "no_speech_prob": 1.2395325938996393e-05}, {"id": 159, "seek": 105052, "start": 1075.6399999999999, "end": 1080.2, "text": " that you are doing in this in this location is independent to the competition that you are doing", "tokens": [50364, 297, 1230, 295, 9253, 293, 550, 291, 434, 516, 281, 360, 291, 458, 257, 39684, 1674, 295, 1045, 538, 1045, 50676, 50676, 4959, 293, 293, 291, 434, 516, 281, 360, 291, 458, 1105, 264, 8062, 1674, 295, 18875, 295, 10139, 2443, 67, 51108, 51108, 370, 291, 536, 264, 14024, 295, 884, 341, 6916, 307, 445, 297, 1413, 1045, 1413, 1045, 1413, 274, 370, 264, 51388, 51388, 14024, 307, 297, 293, 293, 797, 1203, 393, 312, 1096, 294, 8952, 498, 291, 362, 257, 290, 34859, 264, 24903, 51620, 51620, 300, 291, 366, 884, 294, 341, 294, 341, 4914, 307, 6695, 281, 264, 6211, 300, 291, 366, 884, 51848, 51848], "temperature": 0.0, "avg_logprob": -0.11819426796653054, "compression_ratio": 2.1, "no_speech_prob": 1.2395325938996393e-05}, {"id": 160, "seek": 108020, "start": 1080.2, "end": 1089.16, "text": " in this location so everything is is linear complexity okay so doing that um okay so so at", "tokens": [50364, 294, 341, 4914, 370, 1203, 307, 307, 8213, 14024, 1392, 370, 884, 300, 1105, 1392, 370, 370, 412, 50812, 50812, 264, 917, 295, 264, 786, 498, 291, 528, 281, 360, 45216, 365, 12379, 14324, 291, 434, 445, 516, 281, 14722, 51052, 51052, 341, 1105, 39684, 1674, 1296, 428, 12379, 293, 1296, 2232, 428, 2232, 428, 3256, 1105, 741, 576, 584, 428, 51508, 51508], "temperature": 0.0, "avg_logprob": -0.08741968595064603, "compression_ratio": 1.695906432748538, "no_speech_prob": 4.7791841097932775e-06}, {"id": 161, "seek": 108020, "start": 1089.16, "end": 1093.96, "text": " the end of the day if you want to do convolution with template matching you're just going to compute", "tokens": [50364, 294, 341, 4914, 370, 1203, 307, 307, 8213, 14024, 1392, 370, 884, 300, 1105, 1392, 370, 370, 412, 50812, 50812, 264, 917, 295, 264, 786, 498, 291, 528, 281, 360, 45216, 365, 12379, 14324, 291, 434, 445, 516, 281, 14722, 51052, 51052, 341, 1105, 39684, 1674, 1296, 428, 12379, 293, 1296, 2232, 428, 2232, 428, 3256, 1105, 741, 576, 584, 428, 51508, 51508], "temperature": 0.0, "avg_logprob": -0.08741968595064603, "compression_ratio": 1.695906432748538, "no_speech_prob": 4.7791841097932775e-06}, {"id": 162, "seek": 108020, "start": 1093.96, "end": 1103.0800000000002, "text": " this um scalar product between your template and between uh your uh your image um i would say your", "tokens": [50364, 294, 341, 4914, 370, 1203, 307, 307, 8213, 14024, 1392, 370, 884, 300, 1105, 1392, 370, 370, 412, 50812, 50812, 264, 917, 295, 264, 786, 498, 291, 528, 281, 360, 45216, 365, 12379, 14324, 291, 434, 445, 516, 281, 14722, 51052, 51052, 341, 1105, 39684, 1674, 1296, 428, 12379, 293, 1296, 2232, 428, 2232, 428, 3256, 1105, 741, 576, 584, 428, 51508, 51508], "temperature": 0.0, "avg_logprob": -0.08741968595064603, "compression_ratio": 1.695906432748538, "no_speech_prob": 4.7791841097932775e-06}, {"id": 163, "seek": 110308, "start": 1103.08, "end": 1112.28, "text": " image patch okay um okay so something that is very important to see in the case of the graph being", "tokens": [50364, 3256, 9972, 1392, 1105, 1392, 370, 746, 300, 307, 588, 1021, 281, 536, 294, 264, 1389, 295, 264, 4295, 885, 50824, 50824, 10748, 370, 341, 307, 337, 3832, 45216, 294, 3820, 5201, 498, 291, 574, 412, 498, 291, 366, 1237, 412, 51116, 51116, 291, 458, 428, 12379, 597, 307, 510, 1392, 370, 291, 536, 300, 741, 478, 516, 281, 976, 512, 9984, 21739, 51428, 51464], "temperature": 0.0, "avg_logprob": -0.08806210845264036, "compression_ratio": 1.6477272727272727, "no_speech_prob": 2.599248773549334e-06}, {"id": 164, "seek": 110308, "start": 1112.28, "end": 1118.12, "text": " grid so this is for standard convolution in computer vision if you look at if you are looking at", "tokens": [50364, 3256, 9972, 1392, 1105, 1392, 370, 746, 300, 307, 588, 1021, 281, 536, 294, 264, 1389, 295, 264, 4295, 885, 50824, 50824, 10748, 370, 341, 307, 337, 3832, 45216, 294, 3820, 5201, 498, 291, 574, 412, 498, 291, 366, 1237, 412, 51116, 51116, 291, 458, 428, 12379, 597, 307, 510, 1392, 370, 291, 536, 300, 741, 478, 516, 281, 976, 512, 9984, 21739, 51428, 51464], "temperature": 0.0, "avg_logprob": -0.08806210845264036, "compression_ratio": 1.6477272727272727, "no_speech_prob": 2.599248773549334e-06}, {"id": 165, "seek": 110308, "start": 1118.12, "end": 1124.36, "text": " you know your template which is here okay so you see that i'm going to give some node ordering", "tokens": [50364, 3256, 9972, 1392, 1105, 1392, 370, 746, 300, 307, 588, 1021, 281, 536, 294, 264, 1389, 295, 264, 4295, 885, 50824, 50824, 10748, 370, 341, 307, 337, 3832, 45216, 294, 3820, 5201, 498, 291, 574, 412, 498, 291, 366, 1237, 412, 51116, 51116, 291, 458, 428, 12379, 597, 307, 510, 1392, 370, 291, 536, 300, 741, 478, 516, 281, 976, 512, 9984, 21739, 51428, 51464], "temperature": 0.0, "avg_logprob": -0.08806210845264036, "compression_ratio": 1.6477272727272727, "no_speech_prob": 2.599248773549334e-06}, {"id": 166, "seek": 112436, "start": 1124.36, "end": 1134.6799999999998, "text": " uh j1 j2 j3 and so on to j9 and this node ordering is actually very important okay because for for", "tokens": [50364, 2232, 361, 16, 361, 17, 361, 18, 293, 370, 322, 281, 361, 24, 293, 341, 9984, 21739, 307, 767, 588, 1021, 1392, 570, 337, 337, 50880, 50880, 439, 565, 741, 914, 341, 406, 741, 914, 341, 341, 9984, 370, 337, 1365, 264, 9984, 361, 18, 486, 1009, 312, 24889, 51276, 51276, 412, 264, 912, 4914, 370, 309, 311, 1009, 516, 281, 312, 412, 264, 1192, 558, 4538, 295, 295, 264, 5102, 1392, 370, 51600, 51600], "temperature": 0.0, "avg_logprob": -0.15505507085230444, "compression_ratio": 1.6444444444444444, "no_speech_prob": 5.766543836216442e-06}, {"id": 167, "seek": 112436, "start": 1134.6799999999998, "end": 1142.6, "text": " all time i mean this not i mean this this node so for example the node j3 will always be positioned", "tokens": [50364, 2232, 361, 16, 361, 17, 361, 18, 293, 370, 322, 281, 361, 24, 293, 341, 9984, 21739, 307, 767, 588, 1021, 1392, 570, 337, 337, 50880, 50880, 439, 565, 741, 914, 341, 406, 741, 914, 341, 341, 9984, 370, 337, 1365, 264, 9984, 361, 18, 486, 1009, 312, 24889, 51276, 51276, 412, 264, 912, 4914, 370, 309, 311, 1009, 516, 281, 312, 412, 264, 1192, 558, 4538, 295, 295, 264, 5102, 1392, 370, 51600, 51600], "temperature": 0.0, "avg_logprob": -0.15505507085230444, "compression_ratio": 1.6444444444444444, "no_speech_prob": 5.766543836216442e-06}, {"id": 168, "seek": 112436, "start": 1142.6, "end": 1149.08, "text": " at the same location so it's always going to be at the top right corner of of the pattern okay so", "tokens": [50364, 2232, 361, 16, 361, 17, 361, 18, 293, 370, 322, 281, 361, 24, 293, 341, 9984, 21739, 307, 767, 588, 1021, 1392, 570, 337, 337, 50880, 50880, 439, 565, 741, 914, 341, 406, 741, 914, 341, 341, 9984, 370, 337, 1365, 264, 9984, 361, 18, 486, 1009, 312, 24889, 51276, 51276, 412, 264, 912, 4914, 370, 309, 311, 1009, 516, 281, 312, 412, 264, 1192, 558, 4538, 295, 295, 264, 5102, 1392, 370, 51600, 51600], "temperature": 0.0, "avg_logprob": -0.15505507085230444, "compression_ratio": 1.6444444444444444, "no_speech_prob": 5.766543836216442e-06}, {"id": 169, "seek": 114908, "start": 1149.08, "end": 1155.24, "text": " that's that's very important why it's very important so let me go to the next slide so why", "tokens": [50364, 300, 311, 300, 311, 588, 1021, 983, 309, 311, 588, 1021, 370, 718, 385, 352, 281, 264, 958, 4137, 370, 983, 50672, 50672, 309, 311, 588, 1021, 307, 370, 562, 741, 486, 360, 264, 45216, 370, 264, 5102, 14324, 797, 741, 486, 50904, 50904, 747, 452, 2232, 452, 5102, 293, 741, 486, 13153, 264, 5102, 670, 452, 3256, 9274, 1392, 370, 300, 486, 312, 1310, 51228, 51228, 510, 293, 741, 829, 309, 510, 293, 293, 611, 341, 307, 2535, 741, 2535, 741, 5835, 300, 741, 829, 510, 51536, 51564], "temperature": 0.0, "avg_logprob": -0.12053537892771292, "compression_ratio": 2.0726256983240225, "no_speech_prob": 5.0136991376348305e-06}, {"id": 170, "seek": 114908, "start": 1155.24, "end": 1159.8799999999999, "text": " it's very important is so when i will do the convolution so the pattern matching again i will", "tokens": [50364, 300, 311, 300, 311, 588, 1021, 983, 309, 311, 588, 1021, 370, 718, 385, 352, 281, 264, 958, 4137, 370, 983, 50672, 50672, 309, 311, 588, 1021, 307, 370, 562, 741, 486, 360, 264, 45216, 370, 264, 5102, 14324, 797, 741, 486, 50904, 50904, 747, 452, 2232, 452, 5102, 293, 741, 486, 13153, 264, 5102, 670, 452, 3256, 9274, 1392, 370, 300, 486, 312, 1310, 51228, 51228, 510, 293, 741, 829, 309, 510, 293, 293, 611, 341, 307, 2535, 741, 2535, 741, 5835, 300, 741, 829, 510, 51536, 51564], "temperature": 0.0, "avg_logprob": -0.12053537892771292, "compression_ratio": 2.0726256983240225, "no_speech_prob": 5.0136991376348305e-06}, {"id": 171, "seek": 114908, "start": 1159.8799999999999, "end": 1166.36, "text": " take my uh my pattern and i will slice the pattern over my image domain okay so that will be maybe", "tokens": [50364, 300, 311, 300, 311, 588, 1021, 983, 309, 311, 588, 1021, 370, 718, 385, 352, 281, 264, 958, 4137, 370, 983, 50672, 50672, 309, 311, 588, 1021, 307, 370, 562, 741, 486, 360, 264, 45216, 370, 264, 5102, 14324, 797, 741, 486, 50904, 50904, 747, 452, 2232, 452, 5102, 293, 741, 486, 13153, 264, 5102, 670, 452, 3256, 9274, 1392, 370, 300, 486, 312, 1310, 51228, 51228, 510, 293, 741, 829, 309, 510, 293, 293, 611, 341, 307, 2535, 741, 2535, 741, 5835, 300, 741, 829, 510, 51536, 51564], "temperature": 0.0, "avg_logprob": -0.12053537892771292, "compression_ratio": 2.0726256983240225, "no_speech_prob": 5.0136991376348305e-06}, {"id": 172, "seek": 114908, "start": 1166.36, "end": 1172.52, "text": " here and i put it here and and also this is position i position i prime that i put here", "tokens": [50364, 300, 311, 300, 311, 588, 1021, 983, 309, 311, 588, 1021, 370, 718, 385, 352, 281, 264, 958, 4137, 370, 983, 50672, 50672, 309, 311, 588, 1021, 307, 370, 562, 741, 486, 360, 264, 45216, 370, 264, 5102, 14324, 797, 741, 486, 50904, 50904, 747, 452, 2232, 452, 5102, 293, 741, 486, 13153, 264, 5102, 670, 452, 3256, 9274, 1392, 370, 300, 486, 312, 1310, 51228, 51228, 510, 293, 741, 829, 309, 510, 293, 293, 611, 341, 307, 2535, 741, 2535, 741, 5835, 300, 741, 829, 510, 51536, 51564], "temperature": 0.0, "avg_logprob": -0.12053537892771292, "compression_ratio": 2.0726256983240225, "no_speech_prob": 5.0136991376348305e-06}, {"id": 173, "seek": 117252, "start": 1172.52, "end": 1179.96, "text": " i put here so when i'm going to do the template matching between the kernel and the image what", "tokens": [50364, 741, 829, 510, 370, 562, 741, 478, 516, 281, 360, 264, 12379, 14324, 1296, 264, 28256, 293, 264, 3256, 437, 50736, 50736, 741, 486, 360, 307, 300, 337, 341, 8186, 370, 264, 8186, 361, 18, 309, 486, 1009, 2995, 291, 458, 264, 1589, 294, 51132, 51132, 264, 3256, 412, 412, 341, 2232, 8186, 510, 1392, 370, 341, 307, 588, 1021, 370, 291, 562, 291, 362, 257, 10748, 264, 51568, 51568, 9984, 21739, 264, 9984, 26381, 307, 1009, 264, 912, 2035, 264, 2535, 294, 428, 3256, 370, 562, 51840, 51840], "temperature": 0.0, "avg_logprob": -0.06741222444471422, "compression_ratio": 1.8476190476190477, "no_speech_prob": 5.590430646407185e-06}, {"id": 174, "seek": 117252, "start": 1179.96, "end": 1187.8799999999999, "text": " i will do is that for this index so the index j3 it will always match you know the information in", "tokens": [50364, 741, 829, 510, 370, 562, 741, 478, 516, 281, 360, 264, 12379, 14324, 1296, 264, 28256, 293, 264, 3256, 437, 50736, 50736, 741, 486, 360, 307, 300, 337, 341, 8186, 370, 264, 8186, 361, 18, 309, 486, 1009, 2995, 291, 458, 264, 1589, 294, 51132, 51132, 264, 3256, 412, 412, 341, 2232, 8186, 510, 1392, 370, 341, 307, 588, 1021, 370, 291, 562, 291, 362, 257, 10748, 264, 51568, 51568, 9984, 21739, 264, 9984, 26381, 307, 1009, 264, 912, 2035, 264, 2535, 294, 428, 3256, 370, 562, 51840, 51840], "temperature": 0.0, "avg_logprob": -0.06741222444471422, "compression_ratio": 1.8476190476190477, "no_speech_prob": 5.590430646407185e-06}, {"id": 175, "seek": 117252, "start": 1187.8799999999999, "end": 1196.6, "text": " the image at at this uh index here okay so this is very important so you when you have a grid the", "tokens": [50364, 741, 829, 510, 370, 562, 741, 478, 516, 281, 360, 264, 12379, 14324, 1296, 264, 28256, 293, 264, 3256, 437, 50736, 50736, 741, 486, 360, 307, 300, 337, 341, 8186, 370, 264, 8186, 361, 18, 309, 486, 1009, 2995, 291, 458, 264, 1589, 294, 51132, 51132, 264, 3256, 412, 412, 341, 2232, 8186, 510, 1392, 370, 341, 307, 588, 1021, 370, 291, 562, 291, 362, 257, 10748, 264, 51568, 51568, 9984, 21739, 264, 9984, 26381, 307, 1009, 264, 912, 2035, 264, 2535, 294, 428, 3256, 370, 562, 51840, 51840], "temperature": 0.0, "avg_logprob": -0.06741222444471422, "compression_ratio": 1.8476190476190477, "no_speech_prob": 5.590430646407185e-06}, {"id": 176, "seek": 117252, "start": 1196.6, "end": 1202.04, "text": " node ordering the node positioning is always the same whatever the position in your image so when", "tokens": [50364, 741, 829, 510, 370, 562, 741, 478, 516, 281, 360, 264, 12379, 14324, 1296, 264, 28256, 293, 264, 3256, 437, 50736, 50736, 741, 486, 360, 307, 300, 337, 341, 8186, 370, 264, 8186, 361, 18, 309, 486, 1009, 2995, 291, 458, 264, 1589, 294, 51132, 51132, 264, 3256, 412, 412, 341, 2232, 8186, 510, 1392, 370, 341, 307, 588, 1021, 370, 291, 562, 291, 362, 257, 10748, 264, 51568, 51568, 9984, 21739, 264, 9984, 26381, 307, 1009, 264, 912, 2035, 264, 2535, 294, 428, 3256, 370, 562, 51840, 51840], "temperature": 0.0, "avg_logprob": -0.06741222444471422, "compression_ratio": 1.8476190476190477, "no_speech_prob": 5.590430646407185e-06}, {"id": 177, "seek": 120204, "start": 1202.04, "end": 1207.72, "text": " you do the template matching between index j3 and this index here in the image you always compare", "tokens": [50364, 291, 360, 264, 12379, 14324, 1296, 8186, 361, 18, 293, 341, 8186, 510, 294, 264, 3256, 291, 1009, 6794, 50648, 50648, 264, 912, 1589, 291, 1009, 6794, 264, 4111, 412, 264, 1192, 558, 4538, 295, 428, 5102, 51000, 51000, 293, 264, 2010, 295, 4538, 295, 264, 3256, 9972, 1392, 370, 341, 1105, 341, 2232, 291, 536, 613, 14324, 13444, 51404, 51404, 436, 366, 337, 264, 912, 1589, 1392, 370, 300, 311, 588, 1021, 586, 718, 311, 574, 412, 437, 2011, 337, 51688, 51688], "temperature": 0.0, "avg_logprob": -0.07952653660493739, "compression_ratio": 1.9154228855721394, "no_speech_prob": 1.306335320805374e-06}, {"id": 178, "seek": 120204, "start": 1207.72, "end": 1214.76, "text": " the same information you always compare the feature at the top right corner of your pattern", "tokens": [50364, 291, 360, 264, 12379, 14324, 1296, 8186, 361, 18, 293, 341, 8186, 510, 294, 264, 3256, 291, 1009, 6794, 50648, 50648, 264, 912, 1589, 291, 1009, 6794, 264, 4111, 412, 264, 1192, 558, 4538, 295, 428, 5102, 51000, 51000, 293, 264, 2010, 295, 4538, 295, 264, 3256, 9972, 1392, 370, 341, 1105, 341, 2232, 291, 536, 613, 14324, 13444, 51404, 51404, 436, 366, 337, 264, 912, 1589, 1392, 370, 300, 311, 588, 1021, 586, 718, 311, 574, 412, 437, 2011, 337, 51688, 51688], "temperature": 0.0, "avg_logprob": -0.07952653660493739, "compression_ratio": 1.9154228855721394, "no_speech_prob": 1.306335320805374e-06}, {"id": 179, "seek": 120204, "start": 1214.76, "end": 1222.84, "text": " and the type of corner of the image patch okay so this um this uh you see these matching scores", "tokens": [50364, 291, 360, 264, 12379, 14324, 1296, 8186, 361, 18, 293, 341, 8186, 510, 294, 264, 3256, 291, 1009, 6794, 50648, 50648, 264, 912, 1589, 291, 1009, 6794, 264, 4111, 412, 264, 1192, 558, 4538, 295, 428, 5102, 51000, 51000, 293, 264, 2010, 295, 4538, 295, 264, 3256, 9972, 1392, 370, 341, 1105, 341, 2232, 291, 536, 613, 14324, 13444, 51404, 51404, 436, 366, 337, 264, 912, 1589, 1392, 370, 300, 311, 588, 1021, 586, 718, 311, 574, 412, 437, 2011, 337, 51688, 51688], "temperature": 0.0, "avg_logprob": -0.07952653660493739, "compression_ratio": 1.9154228855721394, "no_speech_prob": 1.306335320805374e-06}, {"id": 180, "seek": 120204, "start": 1222.84, "end": 1228.52, "text": " they are for the same information okay so that's very important now let's look at what happened for", "tokens": [50364, 291, 360, 264, 12379, 14324, 1296, 8186, 361, 18, 293, 341, 8186, 510, 294, 264, 3256, 291, 1009, 6794, 50648, 50648, 264, 912, 1589, 291, 1009, 6794, 264, 4111, 412, 264, 1192, 558, 4538, 295, 428, 5102, 51000, 51000, 293, 264, 2010, 295, 4538, 295, 264, 3256, 9972, 1392, 370, 341, 1105, 341, 2232, 291, 536, 613, 14324, 13444, 51404, 51404, 436, 366, 337, 264, 912, 1589, 1392, 370, 300, 311, 588, 1021, 586, 718, 311, 574, 412, 437, 2011, 337, 51688, 51688], "temperature": 0.0, "avg_logprob": -0.07952653660493739, "compression_ratio": 1.9154228855721394, "no_speech_prob": 1.306335320805374e-06}, {"id": 181, "seek": 122852, "start": 1228.52, "end": 1237.4, "text": " graphs okay so the question is can we extend this definition of template matching for graphs", "tokens": [50364, 24877, 1392, 370, 264, 1168, 307, 393, 321, 10101, 341, 7123, 295, 12379, 14324, 337, 24877, 50808, 50844, 293, 456, 366, 886, 867, 2663, 370, 264, 700, 2734, 307, 1936, 322, 257, 4295, 291, 500, 380, 362, 604, 2232, 51224, 51224, 21739, 295, 428, 5570, 1392, 370, 322, 264, 4295, 291, 291, 362, 572, 2212, 2535, 2232, 337, 428, 5570, 370, 51688, 51688], "temperature": 0.0, "avg_logprob": -0.09155394480778621, "compression_ratio": 1.715151515151515, "no_speech_prob": 1.4714779354108032e-05}, {"id": 182, "seek": 122852, "start": 1238.12, "end": 1245.72, "text": " and there are too many issues so the first issue is basically on a graph you don't have any uh", "tokens": [50364, 24877, 1392, 370, 264, 1168, 307, 393, 321, 10101, 341, 7123, 295, 12379, 14324, 337, 24877, 50808, 50844, 293, 456, 366, 886, 867, 2663, 370, 264, 700, 2734, 307, 1936, 322, 257, 4295, 291, 500, 380, 362, 604, 2232, 51224, 51224, 21739, 295, 428, 5570, 1392, 370, 322, 264, 4295, 291, 291, 362, 572, 2212, 2535, 2232, 337, 428, 5570, 370, 51688, 51688], "temperature": 0.0, "avg_logprob": -0.09155394480778621, "compression_ratio": 1.715151515151515, "no_speech_prob": 1.4714779354108032e-05}, {"id": 183, "seek": 122852, "start": 1245.72, "end": 1255.0, "text": " ordering of your notes okay so on the graph you you have no given position uh for your notes so", "tokens": [50364, 24877, 1392, 370, 264, 1168, 307, 393, 321, 10101, 341, 7123, 295, 12379, 14324, 337, 24877, 50808, 50844, 293, 456, 366, 886, 867, 2663, 370, 264, 700, 2734, 307, 1936, 322, 257, 4295, 291, 500, 380, 362, 604, 2232, 51224, 51224, 21739, 295, 428, 5570, 1392, 370, 322, 264, 4295, 291, 291, 362, 572, 2212, 2535, 2232, 337, 428, 5570, 370, 51688, 51688], "temperature": 0.0, "avg_logprob": -0.09155394480778621, "compression_ratio": 1.715151515151515, "no_speech_prob": 1.4714779354108032e-05}, {"id": 184, "seek": 125500, "start": 1255.0, "end": 1262.12, "text": " let's say for example i have this uh graph template okay so there are like four nodes", "tokens": [50364, 718, 311, 584, 337, 1365, 741, 362, 341, 2232, 4295, 12379, 1392, 370, 456, 366, 411, 1451, 13891, 50720, 50720, 365, 341, 4984, 293, 741, 362, 341, 2232, 28162, 510, 264, 551, 307, 337, 341, 28162, 741, 458, 1825, 51072, 51072, 466, 264, 2535, 264, 787, 551, 300, 741, 458, 307, 264, 8186, 1392, 370, 1310, 341, 307, 264, 8186, 1230, 51364, 51364, 1045, 337, 341, 472, 293, 550, 562, 562, 498, 741, 528, 281, 764, 264, 12379, 14324, 7123, 437, 741, 478, 51612, 51612], "temperature": 0.0, "avg_logprob": -0.047942950807768725, "compression_ratio": 1.9086294416243654, "no_speech_prob": 7.15880833013216e-06}, {"id": 185, "seek": 125500, "start": 1262.12, "end": 1269.16, "text": " with this connection and i have this uh vertex here the thing is for this vertex i know nothing", "tokens": [50364, 718, 311, 584, 337, 1365, 741, 362, 341, 2232, 4295, 12379, 1392, 370, 456, 366, 411, 1451, 13891, 50720, 50720, 365, 341, 4984, 293, 741, 362, 341, 2232, 28162, 510, 264, 551, 307, 337, 341, 28162, 741, 458, 1825, 51072, 51072, 466, 264, 2535, 264, 787, 551, 300, 741, 458, 307, 264, 8186, 1392, 370, 1310, 341, 307, 264, 8186, 1230, 51364, 51364, 1045, 337, 341, 472, 293, 550, 562, 562, 498, 741, 528, 281, 764, 264, 12379, 14324, 7123, 437, 741, 478, 51612, 51612], "temperature": 0.0, "avg_logprob": -0.047942950807768725, "compression_ratio": 1.9086294416243654, "no_speech_prob": 7.15880833013216e-06}, {"id": 186, "seek": 125500, "start": 1269.16, "end": 1275.0, "text": " about the position the only thing that i know is the index okay so maybe this is the index number", "tokens": [50364, 718, 311, 584, 337, 1365, 741, 362, 341, 2232, 4295, 12379, 1392, 370, 456, 366, 411, 1451, 13891, 50720, 50720, 365, 341, 4984, 293, 741, 362, 341, 2232, 28162, 510, 264, 551, 307, 337, 341, 28162, 741, 458, 1825, 51072, 51072, 466, 264, 2535, 264, 787, 551, 300, 741, 458, 307, 264, 8186, 1392, 370, 1310, 341, 307, 264, 8186, 1230, 51364, 51364, 1045, 337, 341, 472, 293, 550, 562, 562, 498, 741, 528, 281, 764, 264, 12379, 14324, 7123, 437, 741, 478, 51612, 51612], "temperature": 0.0, "avg_logprob": -0.047942950807768725, "compression_ratio": 1.9086294416243654, "no_speech_prob": 7.15880833013216e-06}, {"id": 187, "seek": 125500, "start": 1275.0, "end": 1279.96, "text": " three for this one and then when when if i want to use the template matching definition what i'm", "tokens": [50364, 718, 311, 584, 337, 1365, 741, 362, 341, 2232, 4295, 12379, 1392, 370, 456, 366, 411, 1451, 13891, 50720, 50720, 365, 341, 4984, 293, 741, 362, 341, 2232, 28162, 510, 264, 551, 307, 337, 341, 28162, 741, 458, 1825, 51072, 51072, 466, 264, 2535, 264, 787, 551, 300, 741, 458, 307, 264, 8186, 1392, 370, 1310, 341, 307, 264, 8186, 1230, 51364, 51364, 1045, 337, 341, 472, 293, 550, 562, 562, 498, 741, 528, 281, 764, 264, 12379, 14324, 7123, 437, 741, 478, 51612, 51612], "temperature": 0.0, "avg_logprob": -0.047942950807768725, "compression_ratio": 1.9086294416243654, "no_speech_prob": 7.15880833013216e-06}, {"id": 188, "seek": 127996, "start": 1279.96, "end": 1287.96, "text": " going to do is that i need to match you know this uh index with other index uh in the graph domain", "tokens": [50364, 516, 281, 360, 307, 300, 741, 643, 281, 2995, 291, 458, 341, 2232, 8186, 365, 661, 8186, 2232, 294, 264, 4295, 9274, 50764, 50764, 370, 341, 307, 452, 4295, 293, 718, 311, 584, 341, 307, 337, 264, 9984, 741, 293, 436, 366, 264, 12512, 295, 264, 9984, 741, 51032, 51032, 370, 337, 341, 7645, 341, 307, 264, 8186, 264, 912, 8186, 361, 18, 457, 510, 741, 914, 577, 393, 741, 2995, 291, 458, 341, 51452, 51452, 1589, 365, 341, 1589, 562, 741, 360, 406, 458, 498, 436, 2995, 281, 1184, 436, 2995, 365, 281, 1184, 51732, 51732], "temperature": 0.0, "avg_logprob": -0.06498853124753394, "compression_ratio": 2.0153061224489797, "no_speech_prob": 2.769016646197997e-06}, {"id": 189, "seek": 127996, "start": 1287.96, "end": 1293.32, "text": " so this is my graph and let's say this is for the node i and they are the neighbors of the node i", "tokens": [50364, 516, 281, 360, 307, 300, 741, 643, 281, 2995, 291, 458, 341, 2232, 8186, 365, 661, 8186, 2232, 294, 264, 4295, 9274, 50764, 50764, 370, 341, 307, 452, 4295, 293, 718, 311, 584, 341, 307, 337, 264, 9984, 741, 293, 436, 366, 264, 12512, 295, 264, 9984, 741, 51032, 51032, 370, 337, 341, 7645, 341, 307, 264, 8186, 264, 912, 8186, 361, 18, 457, 510, 741, 914, 577, 393, 741, 2995, 291, 458, 341, 51452, 51452, 1589, 365, 341, 1589, 562, 741, 360, 406, 458, 498, 436, 2995, 281, 1184, 436, 2995, 365, 281, 1184, 51732, 51732], "temperature": 0.0, "avg_logprob": -0.06498853124753394, "compression_ratio": 2.0153061224489797, "no_speech_prob": 2.769016646197997e-06}, {"id": 190, "seek": 127996, "start": 1293.32, "end": 1301.72, "text": " so for this label this is the index the same index j3 but here i mean how can i match you know this", "tokens": [50364, 516, 281, 360, 307, 300, 741, 643, 281, 2995, 291, 458, 341, 2232, 8186, 365, 661, 8186, 2232, 294, 264, 4295, 9274, 50764, 50764, 370, 341, 307, 452, 4295, 293, 718, 311, 584, 341, 307, 337, 264, 9984, 741, 293, 436, 366, 264, 12512, 295, 264, 9984, 741, 51032, 51032, 370, 337, 341, 7645, 341, 307, 264, 8186, 264, 912, 8186, 361, 18, 457, 510, 741, 914, 577, 393, 741, 2995, 291, 458, 341, 51452, 51452, 1589, 365, 341, 1589, 562, 741, 360, 406, 458, 498, 436, 2995, 281, 1184, 436, 2995, 365, 281, 1184, 51732, 51732], "temperature": 0.0, "avg_logprob": -0.06498853124753394, "compression_ratio": 2.0153061224489797, "no_speech_prob": 2.769016646197997e-06}, {"id": 191, "seek": 127996, "start": 1301.72, "end": 1307.32, "text": " information with this information when i do not know if they match to each they match with to each", "tokens": [50364, 516, 281, 360, 307, 300, 741, 643, 281, 2995, 291, 458, 341, 2232, 8186, 365, 661, 8186, 2232, 294, 264, 4295, 9274, 50764, 50764, 370, 341, 307, 452, 4295, 293, 718, 311, 584, 341, 307, 337, 264, 9984, 741, 293, 436, 366, 264, 12512, 295, 264, 9984, 741, 51032, 51032, 370, 337, 341, 7645, 341, 307, 264, 8186, 264, 912, 8186, 361, 18, 457, 510, 741, 914, 577, 393, 741, 2995, 291, 458, 341, 51452, 51452, 1589, 365, 341, 1589, 562, 741, 360, 406, 458, 498, 436, 2995, 281, 1184, 436, 2995, 365, 281, 1184, 51732, 51732], "temperature": 0.0, "avg_logprob": -0.06498853124753394, "compression_ratio": 2.0153061224489797, "no_speech_prob": 2.769016646197997e-06}, {"id": 192, "seek": 130732, "start": 1307.32, "end": 1313.56, "text": " other because on the graph you don't have any ordering of your notes you don't know uh if these", "tokens": [50364, 661, 570, 322, 264, 4295, 291, 500, 380, 362, 604, 21739, 295, 428, 5570, 291, 500, 380, 458, 2232, 498, 613, 50676, 50676, 13891, 309, 311, 337, 264, 1192, 558, 4538, 295, 604, 1589, 291, 500, 380, 458, 300, 370, 322, 264, 4295, 50984, 50984, 291, 362, 572, 10710, 295, 689, 307, 264, 493, 689, 307, 264, 760, 689, 307, 264, 558, 689, 307, 264, 1411, 51240, 51240, 1392, 370, 562, 291, 360, 341, 14324, 1296, 2232, 341, 4111, 8062, 293, 341, 4111, 8062, 767, 51612, 51612], "temperature": 0.0, "avg_logprob": -0.053585615050926634, "compression_ratio": 1.9947089947089947, "no_speech_prob": 1.643527502892539e-05}, {"id": 193, "seek": 130732, "start": 1313.56, "end": 1319.72, "text": " nodes it's for the top right corner of any information you don't know that so on the graph", "tokens": [50364, 661, 570, 322, 264, 4295, 291, 500, 380, 362, 604, 21739, 295, 428, 5570, 291, 500, 380, 458, 2232, 498, 613, 50676, 50676, 13891, 309, 311, 337, 264, 1192, 558, 4538, 295, 604, 1589, 291, 500, 380, 458, 300, 370, 322, 264, 4295, 50984, 50984, 291, 362, 572, 10710, 295, 689, 307, 264, 493, 689, 307, 264, 760, 689, 307, 264, 558, 689, 307, 264, 1411, 51240, 51240, 1392, 370, 562, 291, 360, 341, 14324, 1296, 2232, 341, 4111, 8062, 293, 341, 4111, 8062, 767, 51612, 51612], "temperature": 0.0, "avg_logprob": -0.053585615050926634, "compression_ratio": 1.9947089947089947, "no_speech_prob": 1.643527502892539e-05}, {"id": 194, "seek": 130732, "start": 1319.72, "end": 1324.84, "text": " you have no notion of where is the up where is the down where is the right where is the left", "tokens": [50364, 661, 570, 322, 264, 4295, 291, 500, 380, 362, 604, 21739, 295, 428, 5570, 291, 500, 380, 458, 2232, 498, 613, 50676, 50676, 13891, 309, 311, 337, 264, 1192, 558, 4538, 295, 604, 1589, 291, 500, 380, 458, 300, 370, 322, 264, 4295, 50984, 50984, 291, 362, 572, 10710, 295, 689, 307, 264, 493, 689, 307, 264, 760, 689, 307, 264, 558, 689, 307, 264, 1411, 51240, 51240, 1392, 370, 562, 291, 360, 341, 14324, 1296, 2232, 341, 4111, 8062, 293, 341, 4111, 8062, 767, 51612, 51612], "temperature": 0.0, "avg_logprob": -0.053585615050926634, "compression_ratio": 1.9947089947089947, "no_speech_prob": 1.643527502892539e-05}, {"id": 195, "seek": 130732, "start": 1324.84, "end": 1332.28, "text": " okay so when you do this matching between uh this feature vector and this feature vector actually", "tokens": [50364, 661, 570, 322, 264, 4295, 291, 500, 380, 362, 604, 21739, 295, 428, 5570, 291, 500, 380, 458, 2232, 498, 613, 50676, 50676, 13891, 309, 311, 337, 264, 1192, 558, 4538, 295, 604, 1589, 291, 500, 380, 458, 300, 370, 322, 264, 4295, 50984, 50984, 291, 362, 572, 10710, 295, 689, 307, 264, 493, 689, 307, 264, 760, 689, 307, 264, 558, 689, 307, 264, 1411, 51240, 51240, 1392, 370, 562, 291, 360, 341, 14324, 1296, 2232, 341, 4111, 8062, 293, 341, 4111, 8062, 767, 51612, 51612], "temperature": 0.0, "avg_logprob": -0.053585615050926634, "compression_ratio": 1.9947089947089947, "no_speech_prob": 1.643527502892539e-05}, {"id": 196, "seek": 133228, "start": 1332.28, "end": 1338.52, "text": " this matching usually in general has no meaning okay you you don't know what you compare to each", "tokens": [50364, 341, 14324, 2673, 294, 2674, 575, 572, 3620, 1392, 291, 291, 500, 380, 458, 437, 291, 6794, 281, 1184, 50676, 50676, 661, 1392, 293, 797, 264, 8186, 307, 2584, 23211, 1392, 370, 291, 393, 362, 264, 2158, 1045, 51004, 51004, 510, 457, 309, 393, 312, 510, 264, 2158, 1230, 732, 420, 2158, 1230, 2272, 291, 291, 500, 380, 362, 341, 307, 341, 51288, 51288, 307, 406, 2232, 291, 458, 604, 2232, 665, 1589, 370, 1936, 570, 291, 500, 380, 362, 604, 2232, 21739, 51648, 51648], "temperature": 0.0, "avg_logprob": -0.06410757152513526, "compression_ratio": 1.8487804878048781, "no_speech_prob": 1.0902270332735498e-05}, {"id": 197, "seek": 133228, "start": 1338.52, "end": 1345.08, "text": " other okay and again the index is completely arbitrary okay so you can have the value three", "tokens": [50364, 341, 14324, 2673, 294, 2674, 575, 572, 3620, 1392, 291, 291, 500, 380, 458, 437, 291, 6794, 281, 1184, 50676, 50676, 661, 1392, 293, 797, 264, 8186, 307, 2584, 23211, 1392, 370, 291, 393, 362, 264, 2158, 1045, 51004, 51004, 510, 457, 309, 393, 312, 510, 264, 2158, 1230, 732, 420, 2158, 1230, 2272, 291, 291, 500, 380, 362, 341, 307, 341, 51288, 51288, 307, 406, 2232, 291, 458, 604, 2232, 665, 1589, 370, 1936, 570, 291, 500, 380, 362, 604, 2232, 21739, 51648, 51648], "temperature": 0.0, "avg_logprob": -0.06410757152513526, "compression_ratio": 1.8487804878048781, "no_speech_prob": 1.0902270332735498e-05}, {"id": 198, "seek": 133228, "start": 1345.08, "end": 1350.76, "text": " here but it can be here the value number two or value number 12 you you don't have this is this", "tokens": [50364, 341, 14324, 2673, 294, 2674, 575, 572, 3620, 1392, 291, 291, 500, 380, 458, 437, 291, 6794, 281, 1184, 50676, 50676, 661, 1392, 293, 797, 264, 8186, 307, 2584, 23211, 1392, 370, 291, 393, 362, 264, 2158, 1045, 51004, 51004, 510, 457, 309, 393, 312, 510, 264, 2158, 1230, 732, 420, 2158, 1230, 2272, 291, 291, 500, 380, 362, 341, 307, 341, 51288, 51288, 307, 406, 2232, 291, 458, 604, 2232, 665, 1589, 370, 1936, 570, 291, 500, 380, 362, 604, 2232, 21739, 51648, 51648], "temperature": 0.0, "avg_logprob": -0.06410757152513526, "compression_ratio": 1.8487804878048781, "no_speech_prob": 1.0902270332735498e-05}, {"id": 199, "seek": 133228, "start": 1350.76, "end": 1357.96, "text": " is not uh you know any uh good information so basically because you don't have any uh ordering", "tokens": [50364, 341, 14324, 2673, 294, 2674, 575, 572, 3620, 1392, 291, 291, 500, 380, 458, 437, 291, 6794, 281, 1184, 50676, 50676, 661, 1392, 293, 797, 264, 8186, 307, 2584, 23211, 1392, 370, 291, 393, 362, 264, 2158, 1045, 51004, 51004, 510, 457, 309, 393, 312, 510, 264, 2158, 1230, 732, 420, 2158, 1230, 2272, 291, 291, 500, 380, 362, 341, 307, 341, 51288, 51288, 307, 406, 2232, 291, 458, 604, 2232, 665, 1589, 370, 1936, 570, 291, 500, 380, 362, 604, 2232, 21739, 51648, 51648], "temperature": 0.0, "avg_logprob": -0.06410757152513526, "compression_ratio": 1.8487804878048781, "no_speech_prob": 1.0902270332735498e-05}, {"id": 200, "seek": 135796, "start": 1357.96, "end": 1363.08, "text": " of your notes on graphs you cannot use the definition of template matching you cannot", "tokens": [50364, 295, 428, 5570, 322, 24877, 291, 2644, 764, 264, 7123, 295, 12379, 14324, 291, 2644, 50620, 50620, 764, 300, 3838, 370, 321, 486, 643, 281, 360, 746, 1646, 1392, 264, 1150, 2734, 365, 12379, 14324, 51104, 51104, 337, 24877, 307, 437, 2314, 498, 264, 1230, 295, 13891, 294, 428, 12379, 775, 406, 2995, 264, 1230, 295, 13891, 51500, 51500, 291, 458, 2232, 294, 428, 294, 428, 4295, 370, 337, 1365, 510, 741, 362, 1451, 13891, 510, 741, 362, 1451, 13891, 2489, 51832], "temperature": 0.0, "avg_logprob": -0.08692131723676409, "compression_ratio": 2.036842105263158, "no_speech_prob": 3.390954589121975e-06}, {"id": 201, "seek": 135796, "start": 1363.08, "end": 1372.76, "text": " use that directly so we will need to do something else okay the second issue with template matching", "tokens": [50364, 295, 428, 5570, 322, 24877, 291, 2644, 764, 264, 7123, 295, 12379, 14324, 291, 2644, 50620, 50620, 764, 300, 3838, 370, 321, 486, 643, 281, 360, 746, 1646, 1392, 264, 1150, 2734, 365, 12379, 14324, 51104, 51104, 337, 24877, 307, 437, 2314, 498, 264, 1230, 295, 13891, 294, 428, 12379, 775, 406, 2995, 264, 1230, 295, 13891, 51500, 51500, 291, 458, 2232, 294, 428, 294, 428, 4295, 370, 337, 1365, 510, 741, 362, 1451, 13891, 510, 741, 362, 1451, 13891, 2489, 51832], "temperature": 0.0, "avg_logprob": -0.08692131723676409, "compression_ratio": 2.036842105263158, "no_speech_prob": 3.390954589121975e-06}, {"id": 202, "seek": 135796, "start": 1372.76, "end": 1380.68, "text": " for graphs is what happens if the number of nodes in your template does not match the number of nodes", "tokens": [50364, 295, 428, 5570, 322, 24877, 291, 2644, 764, 264, 7123, 295, 12379, 14324, 291, 2644, 50620, 50620, 764, 300, 3838, 370, 321, 486, 643, 281, 360, 746, 1646, 1392, 264, 1150, 2734, 365, 12379, 14324, 51104, 51104, 337, 24877, 307, 437, 2314, 498, 264, 1230, 295, 13891, 294, 428, 12379, 775, 406, 2995, 264, 1230, 295, 13891, 51500, 51500, 291, 458, 2232, 294, 428, 294, 428, 4295, 370, 337, 1365, 510, 741, 362, 1451, 13891, 510, 741, 362, 1451, 13891, 2489, 51832], "temperature": 0.0, "avg_logprob": -0.08692131723676409, "compression_ratio": 2.036842105263158, "no_speech_prob": 3.390954589121975e-06}, {"id": 203, "seek": 138068, "start": 1380.68, "end": 1387.96, "text": " you know uh in your in your graph so for example here i have four nodes here i have four nodes fine", "tokens": [50364, 291, 458, 2232, 294, 428, 294, 428, 4295, 370, 337, 1365, 510, 741, 362, 1451, 13891, 510, 741, 362, 1451, 13891, 2489, 50728, 50728, 1310, 741, 393, 915, 257, 636, 281, 6794, 1105, 264, 732, 264, 732, 6352, 295, 295, 13891, 457, 510, 741, 362, 2232, 741, 362, 51092, 51092, 3407, 13891, 370, 577, 741, 478, 516, 281, 6794, 3407, 13891, 281, 1451, 13891, 370, 300, 311, 611, 291, 458, 364, 1269, 2734, 51356, 51560, 1392, 370, 264, 2636, 18894, 7123, 390, 281, 764, 12379, 14324, 281, 6964, 45216, 51812, 51848], "temperature": 0.0, "avg_logprob": -0.0707205085344212, "compression_ratio": 1.9215686274509804, "no_speech_prob": 4.559957687888527e-06}, {"id": 204, "seek": 138068, "start": 1387.96, "end": 1395.24, "text": " maybe i can find a way to compare um the two the two sets of of nodes but here i have uh i have", "tokens": [50364, 291, 458, 2232, 294, 428, 294, 428, 4295, 370, 337, 1365, 510, 741, 362, 1451, 13891, 510, 741, 362, 1451, 13891, 2489, 50728, 50728, 1310, 741, 393, 915, 257, 636, 281, 6794, 1105, 264, 732, 264, 732, 6352, 295, 295, 13891, 457, 510, 741, 362, 2232, 741, 362, 51092, 51092, 3407, 13891, 370, 577, 741, 478, 516, 281, 6794, 3407, 13891, 281, 1451, 13891, 370, 300, 311, 611, 291, 458, 364, 1269, 2734, 51356, 51560, 1392, 370, 264, 2636, 18894, 7123, 390, 281, 764, 12379, 14324, 281, 6964, 45216, 51812, 51848], "temperature": 0.0, "avg_logprob": -0.0707205085344212, "compression_ratio": 1.9215686274509804, "no_speech_prob": 4.559957687888527e-06}, {"id": 205, "seek": 138068, "start": 1395.24, "end": 1400.52, "text": " seven nodes so how i'm going to compare seven nodes to four nodes so that's also you know an open issue", "tokens": [50364, 291, 458, 2232, 294, 428, 294, 428, 4295, 370, 337, 1365, 510, 741, 362, 1451, 13891, 510, 741, 362, 1451, 13891, 2489, 50728, 50728, 1310, 741, 393, 915, 257, 636, 281, 6794, 1105, 264, 732, 264, 732, 6352, 295, 295, 13891, 457, 510, 741, 362, 2232, 741, 362, 51092, 51092, 3407, 13891, 370, 577, 741, 478, 516, 281, 6794, 3407, 13891, 281, 1451, 13891, 370, 300, 311, 611, 291, 458, 364, 1269, 2734, 51356, 51560, 1392, 370, 264, 2636, 18894, 7123, 390, 281, 764, 12379, 14324, 281, 6964, 45216, 51812, 51848], "temperature": 0.0, "avg_logprob": -0.0707205085344212, "compression_ratio": 1.9215686274509804, "no_speech_prob": 4.559957687888527e-06}, {"id": 206, "seek": 138068, "start": 1404.6000000000001, "end": 1409.64, "text": " okay so the third mathematical definition was to use template matching to define convolution", "tokens": [50364, 291, 458, 2232, 294, 428, 294, 428, 4295, 370, 337, 1365, 510, 741, 362, 1451, 13891, 510, 741, 362, 1451, 13891, 2489, 50728, 50728, 1310, 741, 393, 915, 257, 636, 281, 6794, 1105, 264, 732, 264, 732, 6352, 295, 295, 13891, 457, 510, 741, 362, 2232, 741, 362, 51092, 51092, 3407, 13891, 370, 577, 741, 478, 516, 281, 6794, 3407, 13891, 281, 1451, 13891, 370, 300, 311, 611, 291, 458, 364, 1269, 2734, 51356, 51560, 1392, 370, 264, 2636, 18894, 7123, 390, 281, 764, 12379, 14324, 281, 6964, 45216, 51812, 51848], "temperature": 0.0, "avg_logprob": -0.0707205085344212, "compression_ratio": 1.9215686274509804, "no_speech_prob": 4.559957687888527e-06}, {"id": 207, "seek": 140964, "start": 1409.64, "end": 1415.16, "text": " now the second definition is to use the convolution the convolution theorem so the convolution theorem", "tokens": [50364, 586, 264, 1150, 7123, 307, 281, 764, 264, 45216, 264, 45216, 20904, 370, 264, 45216, 20904, 50640, 50640, 490, 1105, 490, 36810, 307, 1936, 264, 36810, 4088, 295, 264, 45216, 295, 732, 6828, 50940, 50968, 307, 264, 935, 3711, 1674, 295, 641, 36810, 4088, 341, 307, 437, 291, 536, 510, 1392, 370, 264, 36810, 51240, 51240, 4088, 295, 264, 45216, 295, 2445, 261, 293, 2445, 276, 307, 264, 36810, 4088, 295, 283, 293, 51604, 51604], "temperature": 0.0, "avg_logprob": -0.2002155130559748, "compression_ratio": 2.3850931677018634, "no_speech_prob": 1.8536973584559746e-05}, {"id": 208, "seek": 140964, "start": 1415.16, "end": 1421.16, "text": " from um from Fourier is basically the Fourier transform of the convolution of two functions", "tokens": [50364, 586, 264, 1150, 7123, 307, 281, 764, 264, 45216, 264, 45216, 20904, 370, 264, 45216, 20904, 50640, 50640, 490, 1105, 490, 36810, 307, 1936, 264, 36810, 4088, 295, 264, 45216, 295, 732, 6828, 50940, 50968, 307, 264, 935, 3711, 1674, 295, 641, 36810, 4088, 341, 307, 437, 291, 536, 510, 1392, 370, 264, 36810, 51240, 51240, 4088, 295, 264, 45216, 295, 2445, 261, 293, 2445, 276, 307, 264, 36810, 4088, 295, 283, 293, 51604, 51604], "temperature": 0.0, "avg_logprob": -0.2002155130559748, "compression_ratio": 2.3850931677018634, "no_speech_prob": 1.8536973584559746e-05}, {"id": 209, "seek": 140964, "start": 1421.72, "end": 1427.16, "text": " is the pointwise product of their Fourier transform this is what you see here okay so the Fourier", "tokens": [50364, 586, 264, 1150, 7123, 307, 281, 764, 264, 45216, 264, 45216, 20904, 370, 264, 45216, 20904, 50640, 50640, 490, 1105, 490, 36810, 307, 1936, 264, 36810, 4088, 295, 264, 45216, 295, 732, 6828, 50940, 50968, 307, 264, 935, 3711, 1674, 295, 641, 36810, 4088, 341, 307, 437, 291, 536, 510, 1392, 370, 264, 36810, 51240, 51240, 4088, 295, 264, 45216, 295, 2445, 261, 293, 2445, 276, 307, 264, 36810, 4088, 295, 283, 293, 51604, 51604], "temperature": 0.0, "avg_logprob": -0.2002155130559748, "compression_ratio": 2.3850931677018634, "no_speech_prob": 1.8536973584559746e-05}, {"id": 210, "seek": 140964, "start": 1427.16, "end": 1434.44, "text": " transform of the convolution of function w and function h is the Fourier transform of f and", "tokens": [50364, 586, 264, 1150, 7123, 307, 281, 764, 264, 45216, 264, 45216, 20904, 370, 264, 45216, 20904, 50640, 50640, 490, 1105, 490, 36810, 307, 1936, 264, 36810, 4088, 295, 264, 45216, 295, 732, 6828, 50940, 50968, 307, 264, 935, 3711, 1674, 295, 641, 36810, 4088, 341, 307, 437, 291, 536, 510, 1392, 370, 264, 36810, 51240, 51240, 4088, 295, 264, 45216, 295, 2445, 261, 293, 2445, 276, 307, 264, 36810, 4088, 295, 283, 293, 51604, 51604], "temperature": 0.0, "avg_logprob": -0.2002155130559748, "compression_ratio": 2.3850931677018634, "no_speech_prob": 1.8536973584559746e-05}, {"id": 211, "seek": 143444, "start": 1434.44, "end": 1439.64, "text": " pointwise multiplication the Fourier transform of h then if you do the inverse Fourier transform you", "tokens": [50364, 935, 3711, 27290, 264, 36810, 4088, 295, 276, 550, 498, 291, 360, 264, 17340, 36810, 4088, 291, 50624, 50624, 352, 646, 281, 428, 1105, 281, 428, 45216, 370, 1481, 1392, 321, 362, 257, 588, 1105, 1481, 8513, 281, 360, 264, 50944, 50944, 45216, 295, 261, 293, 276, 293, 457, 264, 551, 307, 294, 257, 2674, 1389, 884, 264, 36810, 4088, 307, 297, 51260, 51260, 3732, 14024, 321, 808, 646, 281, 300, 4461, 498, 291, 498, 428, 9274, 2232, 411, 2232, 411, 264, 3256, 10748, 51700, 51700], "temperature": 0.0, "avg_logprob": -0.1056930043480613, "compression_ratio": 1.8926829268292682, "no_speech_prob": 5.076646175439237e-06}, {"id": 212, "seek": 143444, "start": 1439.64, "end": 1446.04, "text": " go back to your um to your convolution so nice okay we have a very um nice formula to do the", "tokens": [50364, 935, 3711, 27290, 264, 36810, 4088, 295, 276, 550, 498, 291, 360, 264, 17340, 36810, 4088, 291, 50624, 50624, 352, 646, 281, 428, 1105, 281, 428, 45216, 370, 1481, 1392, 321, 362, 257, 588, 1105, 1481, 8513, 281, 360, 264, 50944, 50944, 45216, 295, 261, 293, 276, 293, 457, 264, 551, 307, 294, 257, 2674, 1389, 884, 264, 36810, 4088, 307, 297, 51260, 51260, 3732, 14024, 321, 808, 646, 281, 300, 4461, 498, 291, 498, 428, 9274, 2232, 411, 2232, 411, 264, 3256, 10748, 51700, 51700], "temperature": 0.0, "avg_logprob": -0.1056930043480613, "compression_ratio": 1.8926829268292682, "no_speech_prob": 5.076646175439237e-06}, {"id": 213, "seek": 143444, "start": 1446.04, "end": 1452.3600000000001, "text": " convolution of w and h and but the thing is in a general case doing the Fourier transform is n", "tokens": [50364, 935, 3711, 27290, 264, 36810, 4088, 295, 276, 550, 498, 291, 360, 264, 17340, 36810, 4088, 291, 50624, 50624, 352, 646, 281, 428, 1105, 281, 428, 45216, 370, 1481, 1392, 321, 362, 257, 588, 1105, 1481, 8513, 281, 360, 264, 50944, 50944, 45216, 295, 261, 293, 276, 293, 457, 264, 551, 307, 294, 257, 2674, 1389, 884, 264, 36810, 4088, 307, 297, 51260, 51260, 3732, 14024, 321, 808, 646, 281, 300, 4461, 498, 291, 498, 428, 9274, 2232, 411, 2232, 411, 264, 3256, 10748, 51700, 51700], "temperature": 0.0, "avg_logprob": -0.1056930043480613, "compression_ratio": 1.8926829268292682, "no_speech_prob": 5.076646175439237e-06}, {"id": 214, "seek": 143444, "start": 1452.3600000000001, "end": 1461.16, "text": " square complexity we come back to that however if you if your domain uh like uh like the image grid", "tokens": [50364, 935, 3711, 27290, 264, 36810, 4088, 295, 276, 550, 498, 291, 360, 264, 17340, 36810, 4088, 291, 50624, 50624, 352, 646, 281, 428, 1105, 281, 428, 45216, 370, 1481, 1392, 321, 362, 257, 588, 1105, 1481, 8513, 281, 360, 264, 50944, 50944, 45216, 295, 261, 293, 276, 293, 457, 264, 551, 307, 294, 257, 2674, 1389, 884, 264, 36810, 4088, 307, 297, 51260, 51260, 3732, 14024, 321, 808, 646, 281, 300, 4461, 498, 291, 498, 428, 9274, 2232, 411, 2232, 411, 264, 3256, 10748, 51700, 51700], "temperature": 0.0, "avg_logprob": -0.1056930043480613, "compression_ratio": 1.8926829268292682, "no_speech_prob": 5.076646175439237e-06}, {"id": 215, "seek": 146116, "start": 1461.16, "end": 1466.92, "text": " has some very particular structure then you can reduce the complexity to n log n uh by using you", "tokens": [50364, 575, 512, 588, 1729, 3877, 550, 291, 393, 5407, 264, 14024, 281, 297, 3565, 297, 2232, 538, 1228, 291, 50652, 50652, 458, 2232, 2370, 36810, 4088, 1392, 370, 264, 1168, 307, 393, 321, 10101, 341, 7123, 295, 2232, 295, 45216, 51088, 51116, 2232, 20904, 281, 24877, 370, 264, 1168, 307, 577, 360, 321, 38818, 533, 257, 36810, 4088, 337, 337, 24877, 1392, 51476, 51512, 293, 293, 264, 551, 307, 577, 281, 652, 309, 2370, 1392, 370, 1604, 300, 294, 264, 1389, 295, 2232, 295, 12379, 51832, 51832], "temperature": 0.0, "avg_logprob": -0.1362974831227506, "compression_ratio": 1.8325581395348838, "no_speech_prob": 7.6068063208367676e-06}, {"id": 216, "seek": 146116, "start": 1466.92, "end": 1475.64, "text": " know uh fast Fourier transform okay so the question is can we extend this definition of uh of convolution", "tokens": [50364, 575, 512, 588, 1729, 3877, 550, 291, 393, 5407, 264, 14024, 281, 297, 3565, 297, 2232, 538, 1228, 291, 50652, 50652, 458, 2232, 2370, 36810, 4088, 1392, 370, 264, 1168, 307, 393, 321, 10101, 341, 7123, 295, 2232, 295, 45216, 51088, 51116, 2232, 20904, 281, 24877, 370, 264, 1168, 307, 577, 360, 321, 38818, 533, 257, 36810, 4088, 337, 337, 24877, 1392, 51476, 51512, 293, 293, 264, 551, 307, 577, 281, 652, 309, 2370, 1392, 370, 1604, 300, 294, 264, 1389, 295, 2232, 295, 12379, 51832, 51832], "temperature": 0.0, "avg_logprob": -0.1362974831227506, "compression_ratio": 1.8325581395348838, "no_speech_prob": 7.6068063208367676e-06}, {"id": 217, "seek": 146116, "start": 1476.2, "end": 1483.4, "text": " uh theorem to graphs so the question is how do we redefine a Fourier transform for for graphs okay", "tokens": [50364, 575, 512, 588, 1729, 3877, 550, 291, 393, 5407, 264, 14024, 281, 297, 3565, 297, 2232, 538, 1228, 291, 50652, 50652, 458, 2232, 2370, 36810, 4088, 1392, 370, 264, 1168, 307, 393, 321, 10101, 341, 7123, 295, 2232, 295, 45216, 51088, 51116, 2232, 20904, 281, 24877, 370, 264, 1168, 307, 577, 360, 321, 38818, 533, 257, 36810, 4088, 337, 337, 24877, 1392, 51476, 51512, 293, 293, 264, 551, 307, 577, 281, 652, 309, 2370, 1392, 370, 1604, 300, 294, 264, 1389, 295, 2232, 295, 12379, 51832, 51832], "temperature": 0.0, "avg_logprob": -0.1362974831227506, "compression_ratio": 1.8325581395348838, "no_speech_prob": 7.6068063208367676e-06}, {"id": 218, "seek": 146116, "start": 1484.1200000000001, "end": 1490.52, "text": " and and the thing is how to make it fast okay so remember that in the case of uh of template", "tokens": [50364, 575, 512, 588, 1729, 3877, 550, 291, 393, 5407, 264, 14024, 281, 297, 3565, 297, 2232, 538, 1228, 291, 50652, 50652, 458, 2232, 2370, 36810, 4088, 1392, 370, 264, 1168, 307, 393, 321, 10101, 341, 7123, 295, 2232, 295, 45216, 51088, 51116, 2232, 20904, 281, 24877, 370, 264, 1168, 307, 577, 360, 321, 38818, 533, 257, 36810, 4088, 337, 337, 24877, 1392, 51476, 51512, 293, 293, 264, 551, 307, 577, 281, 652, 309, 2370, 1392, 370, 1604, 300, 294, 264, 1389, 295, 2232, 295, 12379, 51832, 51832], "temperature": 0.0, "avg_logprob": -0.1362974831227506, "compression_ratio": 1.8325581395348838, "no_speech_prob": 7.6068063208367676e-06}, {"id": 219, "seek": 149052, "start": 1490.52, "end": 1497.48, "text": " matching and we have linear complexity so how do we have a fast spectral convolution in linear time", "tokens": [50364, 14324, 293, 321, 362, 8213, 14024, 370, 577, 360, 321, 362, 257, 2370, 42761, 45216, 294, 8213, 565, 50712, 50740, 337, 14679, 23434, 1625, 370, 300, 311, 300, 311, 264, 1269, 1168, 1392, 370, 1936, 321, 366, 516, 281, 764, 50996, 50996, 613, 732, 21988, 295, 45216, 281, 1715, 732, 5359, 295, 4295, 18161, 3209, 370, 264, 341, 51424, 51424, 576, 312, 264, 12379, 3479, 486, 312, 337, 264, 23598, 4295, 21056, 293, 264, 45216, 304, 51660, 51660], "temperature": 0.0, "avg_logprob": -0.13901805877685547, "compression_ratio": 1.7971698113207548, "no_speech_prob": 1.4614470273954794e-05}, {"id": 220, "seek": 149052, "start": 1498.04, "end": 1503.16, "text": " for compact kernels so that's that's the open question okay so basically we are going to use", "tokens": [50364, 14324, 293, 321, 362, 8213, 14024, 370, 577, 360, 321, 362, 257, 2370, 42761, 45216, 294, 8213, 565, 50712, 50740, 337, 14679, 23434, 1625, 370, 300, 311, 300, 311, 264, 1269, 1168, 1392, 370, 1936, 321, 366, 516, 281, 764, 50996, 50996, 613, 732, 21988, 295, 45216, 281, 1715, 732, 5359, 295, 4295, 18161, 3209, 370, 264, 341, 51424, 51424, 576, 312, 264, 12379, 3479, 486, 312, 337, 264, 23598, 4295, 21056, 293, 264, 45216, 304, 51660, 51660], "temperature": 0.0, "avg_logprob": -0.13901805877685547, "compression_ratio": 1.7971698113207548, "no_speech_prob": 1.4614470273954794e-05}, {"id": 221, "seek": 149052, "start": 1503.16, "end": 1511.72, "text": " these two definitions of convolution to design two classes of graph neural network so the this", "tokens": [50364, 14324, 293, 321, 362, 8213, 14024, 370, 577, 360, 321, 362, 257, 2370, 42761, 45216, 294, 8213, 565, 50712, 50740, 337, 14679, 23434, 1625, 370, 300, 311, 300, 311, 264, 1269, 1168, 1392, 370, 1936, 321, 366, 516, 281, 764, 50996, 50996, 613, 732, 21988, 295, 45216, 281, 1715, 732, 5359, 295, 4295, 18161, 3209, 370, 264, 341, 51424, 51424, 576, 312, 264, 12379, 3479, 486, 312, 337, 264, 23598, 4295, 21056, 293, 264, 45216, 304, 51660, 51660], "temperature": 0.0, "avg_logprob": -0.13901805877685547, "compression_ratio": 1.7971698113207548, "no_speech_prob": 1.4614470273954794e-05}, {"id": 222, "seek": 149052, "start": 1511.72, "end": 1516.44, "text": " would be the template machine will be for the spatial graph coordinates and the convolutional", "tokens": [50364, 14324, 293, 321, 362, 8213, 14024, 370, 577, 360, 321, 362, 257, 2370, 42761, 45216, 294, 8213, 565, 50712, 50740, 337, 14679, 23434, 1625, 370, 300, 311, 300, 311, 264, 1269, 1168, 1392, 370, 1936, 321, 366, 516, 281, 764, 50996, 50996, 613, 732, 21988, 295, 45216, 281, 1715, 732, 5359, 295, 4295, 18161, 3209, 370, 264, 341, 51424, 51424, 576, 312, 264, 12379, 3479, 486, 312, 337, 264, 23598, 4295, 21056, 293, 264, 45216, 304, 51660, 51660], "temperature": 0.0, "avg_logprob": -0.13901805877685547, "compression_ratio": 1.7971698113207548, "no_speech_prob": 1.4614470273954794e-05}, {"id": 223, "seek": 151644, "start": 1516.44, "end": 1522.04, "text": " theorem i'm going to use that for the spectral graph coordinate and this is the next uh the next", "tokens": [50364, 20904, 741, 478, 516, 281, 764, 300, 337, 264, 42761, 4295, 15670, 293, 341, 307, 264, 958, 2232, 264, 958, 50644, 50644, 644, 300, 741, 478, 516, 281, 751, 466, 586, 1392, 370, 718, 311, 751, 466, 2232, 577, 321, 360, 42761, 45216, 1392, 51284, 51520, 370, 741, 741, 456, 307, 257, 1446, 300, 741, 411, 588, 709, 2232, 597, 307, 264, 1446, 295, 3429, 339, 1312, 597, 307, 51840, 51840], "temperature": 0.0, "avg_logprob": -0.16423655209476, "compression_ratio": 1.7592592592592593, "no_speech_prob": 6.2271706156025175e-06}, {"id": 224, "seek": 151644, "start": 1522.04, "end": 1534.8400000000001, "text": " part that i'm going to talk about now okay so let's talk about uh how we do spectral convolution okay", "tokens": [50364, 20904, 741, 478, 516, 281, 764, 300, 337, 264, 42761, 4295, 15670, 293, 341, 307, 264, 958, 2232, 264, 958, 50644, 50644, 644, 300, 741, 478, 516, 281, 751, 466, 586, 1392, 370, 718, 311, 751, 466, 2232, 577, 321, 360, 42761, 45216, 1392, 51284, 51520, 370, 741, 741, 456, 307, 257, 1446, 300, 741, 411, 588, 709, 2232, 597, 307, 264, 1446, 295, 3429, 339, 1312, 597, 307, 51840, 51840], "temperature": 0.0, "avg_logprob": -0.16423655209476, "compression_ratio": 1.7592592592592593, "no_speech_prob": 6.2271706156025175e-06}, {"id": 225, "seek": 151644, "start": 1539.56, "end": 1545.96, "text": " so i i there is a book that i like very much uh which is the book of fanchime which is", "tokens": [50364, 20904, 741, 478, 516, 281, 764, 300, 337, 264, 42761, 4295, 15670, 293, 341, 307, 264, 958, 2232, 264, 958, 50644, 50644, 644, 300, 741, 478, 516, 281, 751, 466, 586, 1392, 370, 718, 311, 751, 466, 2232, 577, 321, 360, 42761, 45216, 1392, 51284, 51520, 370, 741, 741, 456, 307, 257, 1446, 300, 741, 411, 588, 709, 2232, 597, 307, 264, 1446, 295, 3429, 339, 1312, 597, 307, 51840, 51840], "temperature": 0.0, "avg_logprob": -0.16423655209476, "compression_ratio": 1.7592592592592593, "no_speech_prob": 6.2271706156025175e-06}, {"id": 226, "seek": 154596, "start": 1545.96, "end": 1551.96, "text": " uh spectral graph theory so there is everything nice like harmonic analysis graph theory combinatorial", "tokens": [50364, 2232, 42761, 4295, 5261, 370, 456, 307, 1203, 1481, 411, 32270, 5215, 4295, 5261, 2512, 31927, 831, 50664, 50664, 2740, 293, 19618, 370, 741, 534, 2748, 2232, 291, 458, 561, 281, 1401, 264, 3642, 498, 436, 528, 50960, 50960, 281, 458, 544, 293, 257, 688, 544, 466, 466, 613, 613, 1651, 370, 577, 360, 321, 2042, 42761, 51268, 51268, 45216, 370, 321, 366, 516, 281, 764, 1451, 4439, 370, 264, 700, 1823, 486, 312, 281, 360, 486, 312, 281, 6964, 51556, 51556], "temperature": 0.0, "avg_logprob": -0.055494643393017, "compression_ratio": 1.7798165137614679, "no_speech_prob": 2.7872245482285507e-05}, {"id": 227, "seek": 154596, "start": 1551.96, "end": 1557.88, "text": " problems and optimization so i really recommend uh you know people to read the books if they want", "tokens": [50364, 2232, 42761, 4295, 5261, 370, 456, 307, 1203, 1481, 411, 32270, 5215, 4295, 5261, 2512, 31927, 831, 50664, 50664, 2740, 293, 19618, 370, 741, 534, 2748, 2232, 291, 458, 561, 281, 1401, 264, 3642, 498, 436, 528, 50960, 50960, 281, 458, 544, 293, 257, 688, 544, 466, 466, 613, 613, 1651, 370, 577, 360, 321, 2042, 42761, 51268, 51268, 45216, 370, 321, 366, 516, 281, 764, 1451, 4439, 370, 264, 700, 1823, 486, 312, 281, 360, 486, 312, 281, 6964, 51556, 51556], "temperature": 0.0, "avg_logprob": -0.055494643393017, "compression_ratio": 1.7798165137614679, "no_speech_prob": 2.7872245482285507e-05}, {"id": 228, "seek": 154596, "start": 1557.88, "end": 1564.04, "text": " to know more and a lot more about about these these questions so how do we perform spectral", "tokens": [50364, 2232, 42761, 4295, 5261, 370, 456, 307, 1203, 1481, 411, 32270, 5215, 4295, 5261, 2512, 31927, 831, 50664, 50664, 2740, 293, 19618, 370, 741, 534, 2748, 2232, 291, 458, 561, 281, 1401, 264, 3642, 498, 436, 528, 50960, 50960, 281, 458, 544, 293, 257, 688, 544, 466, 466, 613, 613, 1651, 370, 577, 360, 321, 2042, 42761, 51268, 51268, 45216, 370, 321, 366, 516, 281, 764, 1451, 4439, 370, 264, 700, 1823, 486, 312, 281, 360, 486, 312, 281, 6964, 51556, 51556], "temperature": 0.0, "avg_logprob": -0.055494643393017, "compression_ratio": 1.7798165137614679, "no_speech_prob": 2.7872245482285507e-05}, {"id": 229, "seek": 154596, "start": 1564.04, "end": 1569.8, "text": " convolution so we are going to use four steps so the first step will be to do will be to define", "tokens": [50364, 2232, 42761, 4295, 5261, 370, 456, 307, 1203, 1481, 411, 32270, 5215, 4295, 5261, 2512, 31927, 831, 50664, 50664, 2740, 293, 19618, 370, 741, 534, 2748, 2232, 291, 458, 561, 281, 1401, 264, 3642, 498, 436, 528, 50960, 50960, 281, 458, 544, 293, 257, 688, 544, 466, 466, 613, 613, 1651, 370, 577, 360, 321, 2042, 42761, 51268, 51268, 45216, 370, 321, 366, 516, 281, 764, 1451, 4439, 370, 264, 700, 1823, 486, 312, 281, 360, 486, 312, 281, 6964, 51556, 51556], "temperature": 0.0, "avg_logprob": -0.055494643393017, "compression_ratio": 1.7798165137614679, "no_speech_prob": 2.7872245482285507e-05}, {"id": 230, "seek": 156980, "start": 1569.8, "end": 1576.6, "text": " graph laplation second step will be to define four functions then we will do four transform", "tokens": [50364, 4295, 635, 564, 399, 1150, 1823, 486, 312, 281, 6964, 1451, 6828, 550, 321, 486, 360, 1451, 4088, 50704, 50704, 293, 4728, 2232, 45216, 20904, 1392, 370, 264, 437, 307, 264, 4295, 635, 564, 399, 51060, 51108, 370, 264, 4295, 635, 564, 399, 341, 307, 264, 4965, 12973, 294, 42761, 4295, 5261, 51320, 51320, 1392, 370, 1604, 577, 321, 6964, 257, 4295, 321, 362, 257, 992, 295, 32053, 257, 992, 295, 8819, 293, 550, 321, 362, 51644, 51644], "temperature": 0.0, "avg_logprob": -0.1042443037033081, "compression_ratio": 1.8784530386740332, "no_speech_prob": 7.996758540684823e-06}, {"id": 231, "seek": 156980, "start": 1576.6, "end": 1583.72, "text": " and eventually uh convolution theorem okay so the what is the graph laplation", "tokens": [50364, 4295, 635, 564, 399, 1150, 1823, 486, 312, 281, 6964, 1451, 6828, 550, 321, 486, 360, 1451, 4088, 50704, 50704, 293, 4728, 2232, 45216, 20904, 1392, 370, 264, 437, 307, 264, 4295, 635, 564, 399, 51060, 51108, 370, 264, 4295, 635, 564, 399, 341, 307, 264, 4965, 12973, 294, 42761, 4295, 5261, 51320, 51320, 1392, 370, 1604, 577, 321, 6964, 257, 4295, 321, 362, 257, 992, 295, 32053, 257, 992, 295, 8819, 293, 550, 321, 362, 51644, 51644], "temperature": 0.0, "avg_logprob": -0.1042443037033081, "compression_ratio": 1.8784530386740332, "no_speech_prob": 7.996758540684823e-06}, {"id": 232, "seek": 156980, "start": 1584.68, "end": 1588.9199999999998, "text": " so the graph laplation this is the core operator in spectral graph theory", "tokens": [50364, 4295, 635, 564, 399, 1150, 1823, 486, 312, 281, 6964, 1451, 6828, 550, 321, 486, 360, 1451, 4088, 50704, 50704, 293, 4728, 2232, 45216, 20904, 1392, 370, 264, 437, 307, 264, 4295, 635, 564, 399, 51060, 51108, 370, 264, 4295, 635, 564, 399, 341, 307, 264, 4965, 12973, 294, 42761, 4295, 5261, 51320, 51320, 1392, 370, 1604, 577, 321, 6964, 257, 4295, 321, 362, 257, 992, 295, 32053, 257, 992, 295, 8819, 293, 550, 321, 362, 51644, 51644], "temperature": 0.0, "avg_logprob": -0.1042443037033081, "compression_ratio": 1.8784530386740332, "no_speech_prob": 7.996758540684823e-06}, {"id": 233, "seek": 156980, "start": 1588.9199999999998, "end": 1595.3999999999999, "text": " okay so remember how we define a graph we have a set of vertices a set of edges and then we have", "tokens": [50364, 4295, 635, 564, 399, 1150, 1823, 486, 312, 281, 6964, 1451, 6828, 550, 321, 486, 360, 1451, 4088, 50704, 50704, 293, 4728, 2232, 45216, 20904, 1392, 370, 264, 437, 307, 264, 4295, 635, 564, 399, 51060, 51108, 370, 264, 4295, 635, 564, 399, 341, 307, 264, 4965, 12973, 294, 42761, 4295, 5261, 51320, 51320, 1392, 370, 1604, 577, 321, 6964, 257, 4295, 321, 362, 257, 992, 295, 32053, 257, 992, 295, 8819, 293, 550, 321, 362, 51644, 51644], "temperature": 0.0, "avg_logprob": -0.1042443037033081, "compression_ratio": 1.8784530386740332, "no_speech_prob": 7.996758540684823e-06}, {"id": 234, "seek": 159540, "start": 1595.4, "end": 1604.6000000000001, "text": " the adjacency matrix so is the graph as n vertices the adjacency matrix is an n by n uh matrix so we", "tokens": [50364, 264, 22940, 3020, 8141, 370, 307, 264, 4295, 382, 297, 32053, 264, 22940, 3020, 8141, 307, 364, 297, 538, 297, 2232, 8141, 370, 321, 50824, 50824, 366, 516, 2935, 281, 6964, 264, 635, 564, 399, 597, 307, 611, 516, 281, 312, 364, 297, 538, 297, 8141, 281, 312, 264, 51104, 51104, 6575, 3175, 264, 22940, 3020, 8141, 293, 321, 366, 516, 281, 2710, 1125, 264, 22940, 3020, 8141, 538, 1228, 51528, 51608], "temperature": 0.0, "avg_logprob": -0.10208939861606907, "compression_ratio": 2.0, "no_speech_prob": 6.027371000527637e-06}, {"id": 235, "seek": 159540, "start": 1604.6000000000001, "end": 1610.2, "text": " are going simply to define the laplation which is also going to be an n by n matrix to be the", "tokens": [50364, 264, 22940, 3020, 8141, 370, 307, 264, 4295, 382, 297, 32053, 264, 22940, 3020, 8141, 307, 364, 297, 538, 297, 2232, 8141, 370, 321, 50824, 50824, 366, 516, 2935, 281, 6964, 264, 635, 564, 399, 597, 307, 611, 516, 281, 312, 364, 297, 538, 297, 8141, 281, 312, 264, 51104, 51104, 6575, 3175, 264, 22940, 3020, 8141, 293, 321, 366, 516, 281, 2710, 1125, 264, 22940, 3020, 8141, 538, 1228, 51528, 51608], "temperature": 0.0, "avg_logprob": -0.10208939861606907, "compression_ratio": 2.0, "no_speech_prob": 6.027371000527637e-06}, {"id": 236, "seek": 159540, "start": 1610.2, "end": 1618.68, "text": " identity minus the adjacency matrix and we are going to normalize the adjacency matrix by using", "tokens": [50364, 264, 22940, 3020, 8141, 370, 307, 264, 4295, 382, 297, 32053, 264, 22940, 3020, 8141, 307, 364, 297, 538, 297, 2232, 8141, 370, 321, 50824, 50824, 366, 516, 2935, 281, 6964, 264, 635, 564, 399, 597, 307, 611, 516, 281, 312, 364, 297, 538, 297, 8141, 281, 312, 264, 51104, 51104, 6575, 3175, 264, 22940, 3020, 8141, 293, 321, 366, 516, 281, 2710, 1125, 264, 22940, 3020, 8141, 538, 1228, 51528, 51608], "temperature": 0.0, "avg_logprob": -0.10208939861606907, "compression_ratio": 2.0, "no_speech_prob": 6.027371000527637e-06}, {"id": 237, "seek": 161868, "start": 1618.68, "end": 1626.6000000000001, "text": " um the degree of each node so d is basically a diagonal matrix and the diagonal each element", "tokens": [50364, 1105, 264, 4314, 295, 1184, 9984, 370, 274, 307, 1936, 257, 21539, 8141, 293, 264, 21539, 1184, 4478, 50760, 50760, 295, 264, 21539, 307, 1936, 264, 4314, 295, 264, 9984, 1392, 370, 321, 366, 884, 293, 341, 307, 1219, 264, 51020, 51020, 48704, 635, 564, 399, 1392, 370, 341, 307, 741, 576, 584, 341, 307, 538, 7576, 264, 7123, 295, 2232, 51324, 51324, 635, 564, 399, 300, 321, 764, 337, 337, 24877, 370, 321, 393, 7302, 2232, 341, 2232, 341, 12973, 370, 264, 51724, 51724], "temperature": 0.0, "avg_logprob": -0.11423696320632408, "compression_ratio": 1.9891304347826086, "no_speech_prob": 2.257884625578299e-05}, {"id": 238, "seek": 161868, "start": 1626.6000000000001, "end": 1631.8, "text": " of the diagonal is basically the degree of the node okay so we are doing and this is called the", "tokens": [50364, 1105, 264, 4314, 295, 1184, 9984, 370, 274, 307, 1936, 257, 21539, 8141, 293, 264, 21539, 1184, 4478, 50760, 50760, 295, 264, 21539, 307, 1936, 264, 4314, 295, 264, 9984, 1392, 370, 321, 366, 884, 293, 341, 307, 1219, 264, 51020, 51020, 48704, 635, 564, 399, 1392, 370, 341, 307, 741, 576, 584, 341, 307, 538, 7576, 264, 7123, 295, 2232, 51324, 51324, 635, 564, 399, 300, 321, 764, 337, 337, 24877, 370, 321, 393, 7302, 2232, 341, 2232, 341, 12973, 370, 264, 51724, 51724], "temperature": 0.0, "avg_logprob": -0.11423696320632408, "compression_ratio": 1.9891304347826086, "no_speech_prob": 2.257884625578299e-05}, {"id": 239, "seek": 161868, "start": 1631.8, "end": 1637.88, "text": " normalized laplation okay so this is i would say this is by default the definition of uh", "tokens": [50364, 1105, 264, 4314, 295, 1184, 9984, 370, 274, 307, 1936, 257, 21539, 8141, 293, 264, 21539, 1184, 4478, 50760, 50760, 295, 264, 21539, 307, 1936, 264, 4314, 295, 264, 9984, 1392, 370, 321, 366, 884, 293, 341, 307, 1219, 264, 51020, 51020, 48704, 635, 564, 399, 1392, 370, 341, 307, 741, 576, 584, 341, 307, 538, 7576, 264, 7123, 295, 2232, 51324, 51324, 635, 564, 399, 300, 321, 764, 337, 337, 24877, 370, 321, 393, 7302, 2232, 341, 2232, 341, 12973, 370, 264, 51724, 51724], "temperature": 0.0, "avg_logprob": -0.11423696320632408, "compression_ratio": 1.9891304347826086, "no_speech_prob": 2.257884625578299e-05}, {"id": 240, "seek": 161868, "start": 1637.88, "end": 1645.88, "text": " laplation that we use for for graphs so we can interpret uh this uh this operator so the", "tokens": [50364, 1105, 264, 4314, 295, 1184, 9984, 370, 274, 307, 1936, 257, 21539, 8141, 293, 264, 21539, 1184, 4478, 50760, 50760, 295, 264, 21539, 307, 1936, 264, 4314, 295, 264, 9984, 1392, 370, 321, 366, 884, 293, 341, 307, 1219, 264, 51020, 51020, 48704, 635, 564, 399, 1392, 370, 341, 307, 741, 576, 584, 341, 307, 538, 7576, 264, 7123, 295, 2232, 51324, 51324, 635, 564, 399, 300, 321, 764, 337, 337, 24877, 370, 321, 393, 7302, 2232, 341, 2232, 341, 12973, 370, 264, 51724, 51724], "temperature": 0.0, "avg_logprob": -0.11423696320632408, "compression_ratio": 1.9891304347826086, "no_speech_prob": 2.257884625578299e-05}, {"id": 241, "seek": 164588, "start": 1645.88, "end": 1652.5200000000002, "text": " the laplation is the question so the a was that matrix with basically all the zeros and the one", "tokens": [50364, 264, 635, 564, 399, 307, 264, 1168, 370, 264, 257, 390, 300, 8141, 365, 1936, 439, 264, 35193, 293, 264, 472, 50696, 50696, 390, 13460, 264, 4984, 1296, 8819, 558, 1105, 2086, 370, 2232, 337, 23372, 337, 1365, 741, 51088, 51088, 576, 584, 300, 341, 307, 2293, 264, 7123, 370, 498, 2232, 9984, 741, 4195, 741, 307, 257, 1277, 365, 257, 4195, 361, 550, 51488, 51488], "temperature": 0.0, "avg_logprob": -0.17641340985017664, "compression_ratio": 1.6494252873563218, "no_speech_prob": 1.8903294403571635e-05}, {"id": 242, "seek": 164588, "start": 1652.5200000000002, "end": 1660.3600000000001, "text": " was representing the connection between edges right um yes so uh for facebook for example i", "tokens": [50364, 264, 635, 564, 399, 307, 264, 1168, 370, 264, 257, 390, 300, 8141, 365, 1936, 439, 264, 35193, 293, 264, 472, 50696, 50696, 390, 13460, 264, 4984, 1296, 8819, 558, 1105, 2086, 370, 2232, 337, 23372, 337, 1365, 741, 51088, 51088, 576, 584, 300, 341, 307, 2293, 264, 7123, 370, 498, 2232, 9984, 741, 4195, 741, 307, 257, 1277, 365, 257, 4195, 361, 550, 51488, 51488], "temperature": 0.0, "avg_logprob": -0.17641340985017664, "compression_ratio": 1.6494252873563218, "no_speech_prob": 1.8903294403571635e-05}, {"id": 243, "seek": 164588, "start": 1660.3600000000001, "end": 1668.3600000000001, "text": " would say that this is exactly the definition so if uh node i user i is a friend with a user j then", "tokens": [50364, 264, 635, 564, 399, 307, 264, 1168, 370, 264, 257, 390, 300, 8141, 365, 1936, 439, 264, 35193, 293, 264, 472, 50696, 50696, 390, 13460, 264, 4984, 1296, 8819, 558, 1105, 2086, 370, 2232, 337, 23372, 337, 1365, 741, 51088, 51088, 576, 584, 300, 341, 307, 2293, 264, 7123, 370, 498, 2232, 9984, 741, 4195, 741, 307, 257, 1277, 365, 257, 4195, 361, 550, 51488, 51488], "temperature": 0.0, "avg_logprob": -0.17641340985017664, "compression_ratio": 1.6494252873563218, "no_speech_prob": 1.8903294403571635e-05}, {"id": 244, "seek": 166836, "start": 1668.36, "end": 1676.12, "text": " you will have uh adjacency matrix value will be i j equal to one and if two users are not friends", "tokens": [50364, 291, 486, 362, 2232, 22940, 3020, 8141, 2158, 486, 312, 741, 361, 2681, 281, 472, 293, 498, 732, 5022, 366, 406, 1855, 50752, 50752, 550, 291, 486, 483, 264, 2158, 4018, 457, 2171, 291, 362, 257, 957, 2158, 337, 257, 337, 1365, 337, 264, 51052, 51052, 337, 264, 3567, 21095, 4295, 1105, 264, 2158, 295, 257, 741, 361, 307, 1105, 264, 4314, 295, 4984, 1296, 264, 51432, 51432, 732, 10682, 370, 1936, 437, 321, 584, 264, 1230, 295, 25252, 300, 1745, 2232, 4458, 741, 293, 4458, 361, 51792, 51792], "temperature": 0.0, "avg_logprob": -0.06222305717049064, "compression_ratio": 1.7953488372093023, "no_speech_prob": 1.5174295185715891e-05}, {"id": 245, "seek": 166836, "start": 1676.12, "end": 1682.12, "text": " then you will get the value zero but sometimes you have a real value for a for example for the", "tokens": [50364, 291, 486, 362, 2232, 22940, 3020, 8141, 2158, 486, 312, 741, 361, 2681, 281, 472, 293, 498, 732, 5022, 366, 406, 1855, 50752, 50752, 550, 291, 486, 483, 264, 2158, 4018, 457, 2171, 291, 362, 257, 957, 2158, 337, 257, 337, 1365, 337, 264, 51052, 51052, 337, 264, 3567, 21095, 4295, 1105, 264, 2158, 295, 257, 741, 361, 307, 1105, 264, 4314, 295, 4984, 1296, 264, 51432, 51432, 732, 10682, 370, 1936, 437, 321, 584, 264, 1230, 295, 25252, 300, 1745, 2232, 4458, 741, 293, 4458, 361, 51792, 51792], "temperature": 0.0, "avg_logprob": -0.06222305717049064, "compression_ratio": 1.7953488372093023, "no_speech_prob": 1.5174295185715891e-05}, {"id": 246, "seek": 166836, "start": 1682.12, "end": 1689.7199999999998, "text": " for the brain connectivity graph um the value of a i j is um the degree of connection between the", "tokens": [50364, 291, 486, 362, 2232, 22940, 3020, 8141, 2158, 486, 312, 741, 361, 2681, 281, 472, 293, 498, 732, 5022, 366, 406, 1855, 50752, 50752, 550, 291, 486, 483, 264, 2158, 4018, 457, 2171, 291, 362, 257, 957, 2158, 337, 257, 337, 1365, 337, 264, 51052, 51052, 337, 264, 3567, 21095, 4295, 1105, 264, 2158, 295, 257, 741, 361, 307, 1105, 264, 4314, 295, 4984, 1296, 264, 51432, 51432, 732, 10682, 370, 1936, 437, 321, 584, 264, 1230, 295, 25252, 300, 1745, 2232, 4458, 741, 293, 4458, 361, 51792, 51792], "temperature": 0.0, "avg_logprob": -0.06222305717049064, "compression_ratio": 1.7953488372093023, "no_speech_prob": 1.5174295185715891e-05}, {"id": 247, "seek": 166836, "start": 1689.7199999999998, "end": 1696.9199999999998, "text": " two regions so basically what we say the number of fibers that connect uh region i and region j", "tokens": [50364, 291, 486, 362, 2232, 22940, 3020, 8141, 2158, 486, 312, 741, 361, 2681, 281, 472, 293, 498, 732, 5022, 366, 406, 1855, 50752, 50752, 550, 291, 486, 483, 264, 2158, 4018, 457, 2171, 291, 362, 257, 957, 2158, 337, 257, 337, 1365, 337, 264, 51052, 51052, 337, 264, 3567, 21095, 4295, 1105, 264, 2158, 295, 257, 741, 361, 307, 1105, 264, 4314, 295, 4984, 1296, 264, 51432, 51432, 732, 10682, 370, 1936, 437, 321, 584, 264, 1230, 295, 25252, 300, 1745, 2232, 4458, 741, 293, 4458, 361, 51792, 51792], "temperature": 0.0, "avg_logprob": -0.06222305717049064, "compression_ratio": 1.7953488372093023, "no_speech_prob": 1.5174295185715891e-05}, {"id": 248, "seek": 169692, "start": 1696.92, "end": 1703.24, "text": " so that can be binary that can be also a continuous value and also this is symmetric if it's non", "tokens": [50364, 370, 300, 393, 312, 17434, 300, 393, 312, 611, 257, 10957, 2158, 293, 611, 341, 307, 32330, 498, 309, 311, 2107, 50680, 50680, 21841, 4295, 5911, 2086, 370, 1338, 337, 1105, 2673, 309, 307, 32330, 2232, 293, 291, 528, 291, 528, 264, 51084, 51084, 25440, 337, 337, 18894, 4112, 1105, 457, 291, 815, 362, 512, 406, 370, 510, 341, 307, 264, 2710, 51376, 51376, 25827, 457, 498, 291, 362, 264, 4974, 1792, 635, 564, 399, 293, 550, 341, 307, 2107, 12, 3187, 2174, 17475, 1392, 370, 309, 311, 1105, 51728, 51728], "temperature": 0.0, "avg_logprob": -0.09533002299647178, "compression_ratio": 1.812206572769953, "no_speech_prob": 4.3891192035516724e-05}, {"id": 249, "seek": 169692, "start": 1703.24, "end": 1711.3200000000002, "text": " oriented graph otherwise yes so yeah for um usually it is symmetric uh and you want you want the", "tokens": [50364, 370, 300, 393, 312, 17434, 300, 393, 312, 611, 257, 10957, 2158, 293, 611, 341, 307, 32330, 498, 309, 311, 2107, 50680, 50680, 21841, 4295, 5911, 2086, 370, 1338, 337, 1105, 2673, 309, 307, 32330, 2232, 293, 291, 528, 291, 528, 264, 51084, 51084, 25440, 337, 337, 18894, 4112, 1105, 457, 291, 815, 362, 512, 406, 370, 510, 341, 307, 264, 2710, 51376, 51376, 25827, 457, 498, 291, 362, 264, 4974, 1792, 635, 564, 399, 293, 550, 341, 307, 2107, 12, 3187, 2174, 17475, 1392, 370, 309, 311, 1105, 51728, 51728], "temperature": 0.0, "avg_logprob": -0.09533002299647178, "compression_ratio": 1.812206572769953, "no_speech_prob": 4.3891192035516724e-05}, {"id": 250, "seek": 169692, "start": 1711.3200000000002, "end": 1717.16, "text": " symmetry for for mathematical reasons um but you may have some not so here this is the normal", "tokens": [50364, 370, 300, 393, 312, 17434, 300, 393, 312, 611, 257, 10957, 2158, 293, 611, 341, 307, 32330, 498, 309, 311, 2107, 50680, 50680, 21841, 4295, 5911, 2086, 370, 1338, 337, 1105, 2673, 309, 307, 32330, 2232, 293, 291, 528, 291, 528, 264, 51084, 51084, 25440, 337, 337, 18894, 4112, 1105, 457, 291, 815, 362, 512, 406, 370, 510, 341, 307, 264, 2710, 51376, 51376, 25827, 457, 498, 291, 362, 264, 4974, 1792, 635, 564, 399, 293, 550, 341, 307, 2107, 12, 3187, 2174, 17475, 1392, 370, 309, 311, 1105, 51728, 51728], "temperature": 0.0, "avg_logprob": -0.09533002299647178, "compression_ratio": 1.812206572769953, "no_speech_prob": 4.3891192035516724e-05}, {"id": 251, "seek": 169692, "start": 1717.16, "end": 1724.2, "text": " elevation but if you have the random walk laplation and then this is non-symmetric okay so it's um", "tokens": [50364, 370, 300, 393, 312, 17434, 300, 393, 312, 611, 257, 10957, 2158, 293, 611, 341, 307, 32330, 498, 309, 311, 2107, 50680, 50680, 21841, 4295, 5911, 2086, 370, 1338, 337, 1105, 2673, 309, 307, 32330, 2232, 293, 291, 528, 291, 528, 264, 51084, 51084, 25440, 337, 337, 18894, 4112, 1105, 457, 291, 815, 362, 512, 406, 370, 510, 341, 307, 264, 2710, 51376, 51376, 25827, 457, 498, 291, 362, 264, 4974, 1792, 635, 564, 399, 293, 550, 341, 307, 2107, 12, 3187, 2174, 17475, 1392, 370, 309, 311, 1105, 51728, 51728], "temperature": 0.0, "avg_logprob": -0.09533002299647178, "compression_ratio": 1.812206572769953, "no_speech_prob": 4.3891192035516724e-05}, {"id": 252, "seek": 172420, "start": 1724.2, "end": 1728.76, "text": " it's a different definition of the laplation so in the case of laplation is very interesting so in", "tokens": [50364, 309, 311, 257, 819, 7123, 295, 264, 635, 564, 399, 370, 294, 264, 1389, 295, 635, 564, 399, 307, 588, 1880, 370, 294, 50592, 50592, 264, 10957, 3287, 291, 362, 787, 472, 7123, 337, 264, 635, 564, 399, 341, 307, 1219, 264, 635, 6742, 50796, 50796, 10750, 2356, 72, 12973, 294, 264, 27706, 3287, 291, 362, 3866, 21988, 291, 393, 360, 428, 1065, 51036, 51036, 7123, 295, 264, 635, 564, 399, 5413, 322, 322, 264, 17695, 300, 300, 291, 366, 516, 281, 764, 741, 51316, 51316, 1223, 1309, 291, 1105, 1392, 370, 321, 393, 7302, 264, 635, 564, 399, 370, 264, 635, 564, 399, 307, 1825, 1646, 51636, 51636], "temperature": 0.0, "avg_logprob": -0.124399657721992, "compression_ratio": 2.1345291479820627, "no_speech_prob": 2.7936279366258532e-05}, {"id": 253, "seek": 172420, "start": 1728.76, "end": 1732.8400000000001, "text": " the continuous setting you have only one definition for the laplation this is called the laplace", "tokens": [50364, 309, 311, 257, 819, 7123, 295, 264, 635, 564, 399, 370, 294, 264, 1389, 295, 635, 564, 399, 307, 588, 1880, 370, 294, 50592, 50592, 264, 10957, 3287, 291, 362, 787, 472, 7123, 337, 264, 635, 564, 399, 341, 307, 1219, 264, 635, 6742, 50796, 50796, 10750, 2356, 72, 12973, 294, 264, 27706, 3287, 291, 362, 3866, 21988, 291, 393, 360, 428, 1065, 51036, 51036, 7123, 295, 264, 635, 564, 399, 5413, 322, 322, 264, 17695, 300, 300, 291, 366, 516, 281, 764, 741, 51316, 51316, 1223, 1309, 291, 1105, 1392, 370, 321, 393, 7302, 264, 635, 564, 399, 370, 264, 635, 564, 399, 307, 1825, 1646, 51636, 51636], "temperature": 0.0, "avg_logprob": -0.124399657721992, "compression_ratio": 2.1345291479820627, "no_speech_prob": 2.7936279366258532e-05}, {"id": 254, "seek": 172420, "start": 1732.8400000000001, "end": 1737.64, "text": " beltrami operator in the discrete setting you have multiple definitions you can do your own", "tokens": [50364, 309, 311, 257, 819, 7123, 295, 264, 635, 564, 399, 370, 294, 264, 1389, 295, 635, 564, 399, 307, 588, 1880, 370, 294, 50592, 50592, 264, 10957, 3287, 291, 362, 787, 472, 7123, 337, 264, 635, 564, 399, 341, 307, 1219, 264, 635, 6742, 50796, 50796, 10750, 2356, 72, 12973, 294, 264, 27706, 3287, 291, 362, 3866, 21988, 291, 393, 360, 428, 1065, 51036, 51036, 7123, 295, 264, 635, 564, 399, 5413, 322, 322, 264, 17695, 300, 300, 291, 366, 516, 281, 764, 741, 51316, 51316, 1223, 1309, 291, 1105, 1392, 370, 321, 393, 7302, 264, 635, 564, 399, 370, 264, 635, 564, 399, 307, 1825, 1646, 51636, 51636], "temperature": 0.0, "avg_logprob": -0.124399657721992, "compression_ratio": 2.1345291479820627, "no_speech_prob": 2.7936279366258532e-05}, {"id": 255, "seek": 172420, "start": 1737.64, "end": 1743.24, "text": " definition of the laplation depending on on the assumptions that that you are going to use i", "tokens": [50364, 309, 311, 257, 819, 7123, 295, 264, 635, 564, 399, 370, 294, 264, 1389, 295, 635, 564, 399, 307, 588, 1880, 370, 294, 50592, 50592, 264, 10957, 3287, 291, 362, 787, 472, 7123, 337, 264, 635, 564, 399, 341, 307, 1219, 264, 635, 6742, 50796, 50796, 10750, 2356, 72, 12973, 294, 264, 27706, 3287, 291, 362, 3866, 21988, 291, 393, 360, 428, 1065, 51036, 51036, 7123, 295, 264, 635, 564, 399, 5413, 322, 322, 264, 17695, 300, 300, 291, 366, 516, 281, 764, 741, 51316, 51316, 1223, 1309, 291, 1105, 1392, 370, 321, 393, 7302, 264, 635, 564, 399, 370, 264, 635, 564, 399, 307, 1825, 1646, 51636, 51636], "temperature": 0.0, "avg_logprob": -0.124399657721992, "compression_ratio": 2.1345291479820627, "no_speech_prob": 2.7936279366258532e-05}, {"id": 256, "seek": 172420, "start": 1743.24, "end": 1749.64, "text": " understand thank you um okay so we can interpret the laplation so the laplation is nothing else", "tokens": [50364, 309, 311, 257, 819, 7123, 295, 264, 635, 564, 399, 370, 294, 264, 1389, 295, 635, 564, 399, 307, 588, 1880, 370, 294, 50592, 50592, 264, 10957, 3287, 291, 362, 787, 472, 7123, 337, 264, 635, 564, 399, 341, 307, 1219, 264, 635, 6742, 50796, 50796, 10750, 2356, 72, 12973, 294, 264, 27706, 3287, 291, 362, 3866, 21988, 291, 393, 360, 428, 1065, 51036, 51036, 7123, 295, 264, 635, 564, 399, 5413, 322, 322, 264, 17695, 300, 300, 291, 366, 516, 281, 764, 741, 51316, 51316, 1223, 1309, 291, 1105, 1392, 370, 321, 393, 7302, 264, 635, 564, 399, 370, 264, 635, 564, 399, 307, 1825, 1646, 51636, 51636], "temperature": 0.0, "avg_logprob": -0.124399657721992, "compression_ratio": 2.1345291479820627, "no_speech_prob": 2.7936279366258532e-05}, {"id": 257, "seek": 174964, "start": 1749.64, "end": 1757.3200000000002, "text": " than a measure of smoothness of a function on a on a graph so this is nothing else than you see so", "tokens": [50364, 813, 257, 3481, 295, 5508, 1287, 295, 257, 2445, 322, 257, 322, 257, 4295, 370, 341, 307, 1825, 1646, 813, 291, 536, 370, 50748, 50748, 741, 478, 884, 264, 635, 564, 399, 300, 741, 3079, 281, 257, 2445, 276, 1392, 322, 264, 4295, 293, 741, 478, 1237, 412, 437, 2011, 51040, 51040, 412, 264, 28162, 741, 293, 498, 741, 5268, 341, 7123, 741, 486, 362, 264, 2158, 295, 4879, 3175, 264, 914, 2158, 51464, 51464, 295, 264, 7630, 1392, 370, 1936, 498, 428, 6358, 307, 5508, 291, 458, 498, 309, 1177, 380, 588, 709, 51760, 51792], "temperature": 0.0, "avg_logprob": -0.07278807309209084, "compression_ratio": 1.7633928571428572, "no_speech_prob": 1.1093777175119612e-05}, {"id": 258, "seek": 174964, "start": 1757.3200000000002, "end": 1763.16, "text": " i'm doing the laplation that i apply to a function h okay on the graph and i'm looking at what happened", "tokens": [50364, 813, 257, 3481, 295, 5508, 1287, 295, 257, 2445, 322, 257, 322, 257, 4295, 370, 341, 307, 1825, 1646, 813, 291, 536, 370, 50748, 50748, 741, 478, 884, 264, 635, 564, 399, 300, 741, 3079, 281, 257, 2445, 276, 1392, 322, 264, 4295, 293, 741, 478, 1237, 412, 437, 2011, 51040, 51040, 412, 264, 28162, 741, 293, 498, 741, 5268, 341, 7123, 741, 486, 362, 264, 2158, 295, 4879, 3175, 264, 914, 2158, 51464, 51464, 295, 264, 7630, 1392, 370, 1936, 498, 428, 6358, 307, 5508, 291, 458, 498, 309, 1177, 380, 588, 709, 51760, 51792], "temperature": 0.0, "avg_logprob": -0.07278807309209084, "compression_ratio": 1.7633928571428572, "no_speech_prob": 1.1093777175119612e-05}, {"id": 259, "seek": 174964, "start": 1763.16, "end": 1771.64, "text": " at the vertex i and if i expand this definition i will have the value of hi minus the mean value", "tokens": [50364, 813, 257, 3481, 295, 5508, 1287, 295, 257, 2445, 322, 257, 322, 257, 4295, 370, 341, 307, 1825, 1646, 813, 291, 536, 370, 50748, 50748, 741, 478, 884, 264, 635, 564, 399, 300, 741, 3079, 281, 257, 2445, 276, 1392, 322, 264, 4295, 293, 741, 478, 1237, 412, 437, 2011, 51040, 51040, 412, 264, 28162, 741, 293, 498, 741, 5268, 341, 7123, 741, 486, 362, 264, 2158, 295, 4879, 3175, 264, 914, 2158, 51464, 51464, 295, 264, 7630, 1392, 370, 1936, 498, 428, 6358, 307, 5508, 291, 458, 498, 309, 1177, 380, 588, 709, 51760, 51792], "temperature": 0.0, "avg_logprob": -0.07278807309209084, "compression_ratio": 1.7633928571428572, "no_speech_prob": 1.1093777175119612e-05}, {"id": 260, "seek": 174964, "start": 1771.64, "end": 1777.5600000000002, "text": " of the neighborhood okay so basically if your signal is smooth you know if it doesn't very much", "tokens": [50364, 813, 257, 3481, 295, 5508, 1287, 295, 257, 2445, 322, 257, 322, 257, 4295, 370, 341, 307, 1825, 1646, 813, 291, 536, 370, 50748, 50748, 741, 478, 884, 264, 635, 564, 399, 300, 741, 3079, 281, 257, 2445, 276, 1392, 322, 264, 4295, 293, 741, 478, 1237, 412, 437, 2011, 51040, 51040, 412, 264, 28162, 741, 293, 498, 741, 5268, 341, 7123, 741, 486, 362, 264, 2158, 295, 4879, 3175, 264, 914, 2158, 51464, 51464, 295, 264, 7630, 1392, 370, 1936, 498, 428, 6358, 307, 5508, 291, 458, 498, 309, 1177, 380, 588, 709, 51760, 51792], "temperature": 0.0, "avg_logprob": -0.07278807309209084, "compression_ratio": 1.7633928571428572, "no_speech_prob": 1.1093777175119612e-05}, {"id": 261, "seek": 177756, "start": 1777.56, "end": 1783.96, "text": " then this difference will be very small but if your signal you know varies a lot it oscillates", "tokens": [50364, 550, 341, 2649, 486, 312, 588, 1359, 457, 498, 428, 6358, 291, 458, 21716, 257, 688, 309, 18225, 1024, 50684, 50684, 257, 688, 550, 264, 2649, 486, 312, 588, 1090, 370, 264, 635, 564, 399, 307, 1825, 1646, 813, 257, 3481, 295, 50900, 50900, 5508, 1287, 295, 2445, 322, 257, 322, 257, 322, 257, 4295, 1392, 439, 558, 370, 1105, 586, 718, 311, 6964, 36810, 6828, 51624, 51624], "temperature": 0.0, "avg_logprob": -0.12580506461007254, "compression_ratio": 1.7100591715976332, "no_speech_prob": 1.2025283467664849e-05}, {"id": 262, "seek": 177756, "start": 1783.96, "end": 1788.28, "text": " a lot then the difference will be very high so the laplation is nothing else than a measure of", "tokens": [50364, 550, 341, 2649, 486, 312, 588, 1359, 457, 498, 428, 6358, 291, 458, 21716, 257, 688, 309, 18225, 1024, 50684, 50684, 257, 688, 550, 264, 2649, 486, 312, 588, 1090, 370, 264, 635, 564, 399, 307, 1825, 1646, 813, 257, 3481, 295, 50900, 50900, 5508, 1287, 295, 2445, 322, 257, 322, 257, 322, 257, 4295, 1392, 439, 558, 370, 1105, 586, 718, 311, 6964, 36810, 6828, 51624, 51624], "temperature": 0.0, "avg_logprob": -0.12580506461007254, "compression_ratio": 1.7100591715976332, "no_speech_prob": 1.2025283467664849e-05}, {"id": 263, "seek": 177756, "start": 1788.28, "end": 1802.76, "text": " smoothness of function on a on a on a graph okay all right so um now let's define Fourier functions", "tokens": [50364, 550, 341, 2649, 486, 312, 588, 1359, 457, 498, 428, 6358, 291, 458, 21716, 257, 688, 309, 18225, 1024, 50684, 50684, 257, 688, 550, 264, 2649, 486, 312, 588, 1090, 370, 264, 635, 564, 399, 307, 1825, 1646, 813, 257, 3481, 295, 50900, 50900, 5508, 1287, 295, 2445, 322, 257, 322, 257, 322, 257, 4295, 1392, 439, 558, 370, 1105, 586, 718, 311, 6964, 36810, 6828, 51624, 51624], "temperature": 0.0, "avg_logprob": -0.12580506461007254, "compression_ratio": 1.7100591715976332, "no_speech_prob": 1.2025283467664849e-05}, {"id": 264, "seek": 180276, "start": 1802.76, "end": 1809.56, "text": " so let's let's take the laplation matrix and let's do a little bit of linear algebra let's do", "tokens": [50364, 370, 718, 311, 718, 311, 747, 264, 635, 564, 399, 8141, 293, 718, 311, 360, 257, 707, 857, 295, 8213, 21989, 718, 311, 360, 50704, 50704, 10446, 48356, 295, 264, 4295, 635, 564, 399, 370, 562, 291, 360, 10446, 48356, 291, 486, 362, 264, 291, 51008, 51008, 366, 516, 281, 5952, 1125, 428, 635, 564, 399, 8141, 666, 1045, 32284, 370, 291, 362, 257, 13107, 25167, 13607, 51384, 51384, 293, 13107, 370, 341, 8141, 13107, 295, 264, 2744, 297, 538, 297, 767, 362, 264, 437, 293, 264, 635, 564, 399, 797, 51828, 51828], "temperature": 0.0, "avg_logprob": -0.17668981050190172, "compression_ratio": 1.969387755102041, "no_speech_prob": 2.7816973670269363e-05}, {"id": 265, "seek": 180276, "start": 1809.56, "end": 1815.64, "text": " eigen decomposition of the graph laplation so when you do eigen decomposition you will have the you", "tokens": [50364, 370, 718, 311, 718, 311, 747, 264, 635, 564, 399, 8141, 293, 718, 311, 360, 257, 707, 857, 295, 8213, 21989, 718, 311, 360, 50704, 50704, 10446, 48356, 295, 264, 4295, 635, 564, 399, 370, 562, 291, 360, 10446, 48356, 291, 486, 362, 264, 291, 51008, 51008, 366, 516, 281, 5952, 1125, 428, 635, 564, 399, 8141, 666, 1045, 32284, 370, 291, 362, 257, 13107, 25167, 13607, 51384, 51384, 293, 13107, 370, 341, 8141, 13107, 295, 264, 2744, 297, 538, 297, 767, 362, 264, 437, 293, 264, 635, 564, 399, 797, 51828, 51828], "temperature": 0.0, "avg_logprob": -0.17668981050190172, "compression_ratio": 1.969387755102041, "no_speech_prob": 2.7816973670269363e-05}, {"id": 266, "seek": 180276, "start": 1815.64, "end": 1823.16, "text": " are going to factorize your laplation matrix into three matrices so you have a phi transpose lambda", "tokens": [50364, 370, 718, 311, 718, 311, 747, 264, 635, 564, 399, 8141, 293, 718, 311, 360, 257, 707, 857, 295, 8213, 21989, 718, 311, 360, 50704, 50704, 10446, 48356, 295, 264, 4295, 635, 564, 399, 370, 562, 291, 360, 10446, 48356, 291, 486, 362, 264, 291, 51008, 51008, 366, 516, 281, 5952, 1125, 428, 635, 564, 399, 8141, 666, 1045, 32284, 370, 291, 362, 257, 13107, 25167, 13607, 51384, 51384, 293, 13107, 370, 341, 8141, 13107, 295, 264, 2744, 297, 538, 297, 767, 362, 264, 437, 293, 264, 635, 564, 399, 797, 51828, 51828], "temperature": 0.0, "avg_logprob": -0.17668981050190172, "compression_ratio": 1.969387755102041, "no_speech_prob": 2.7816973670269363e-05}, {"id": 267, "seek": 180276, "start": 1823.16, "end": 1832.04, "text": " and phi so this matrix phi of the size n by n actually have the what and the laplation again", "tokens": [50364, 370, 718, 311, 718, 311, 747, 264, 635, 564, 399, 8141, 293, 718, 311, 360, 257, 707, 857, 295, 8213, 21989, 718, 311, 360, 50704, 50704, 10446, 48356, 295, 264, 4295, 635, 564, 399, 370, 562, 291, 360, 10446, 48356, 291, 486, 362, 264, 291, 51008, 51008, 366, 516, 281, 5952, 1125, 428, 635, 564, 399, 8141, 666, 1045, 32284, 370, 291, 362, 257, 13107, 25167, 13607, 51384, 51384, 293, 13107, 370, 341, 8141, 13107, 295, 264, 2744, 297, 538, 297, 767, 362, 264, 437, 293, 264, 635, 564, 399, 797, 51828, 51828], "temperature": 0.0, "avg_logprob": -0.17668981050190172, "compression_ratio": 1.969387755102041, "no_speech_prob": 2.7816973670269363e-05}, {"id": 268, "seek": 183204, "start": 1832.04, "end": 1838.04, "text": " vectors okay for each colon and the laplation again vectors they are called the Fourier functions", "tokens": [50364, 18875, 1392, 337, 1184, 8255, 293, 264, 635, 564, 399, 797, 18875, 436, 366, 1219, 264, 36810, 6828, 50664, 50696, 1392, 264, 4618, 36810, 6828, 293, 295, 1164, 341, 307, 364, 420, 11943, 24440, 5143, 50940, 50964, 1105, 370, 562, 291, 360, 264, 264, 1674, 1296, 732, 17949, 291, 486, 483, 472, 498, 436, 366, 264, 912, 293, 51264, 51264, 550, 291, 483, 4018, 498, 436, 366, 41488, 498, 436, 366, 819, 2232, 291, 341, 307, 611, 364, 33966, 964, 51584, 51584], "temperature": 0.0, "avg_logprob": -0.14315304302033924, "compression_ratio": 1.8527918781725887, "no_speech_prob": 8.76078411238268e-06}, {"id": 269, "seek": 183204, "start": 1838.68, "end": 1843.56, "text": " okay the famous Fourier functions and of course this is an orthonormal basis", "tokens": [50364, 18875, 1392, 337, 1184, 8255, 293, 264, 635, 564, 399, 797, 18875, 436, 366, 1219, 264, 36810, 6828, 50664, 50696, 1392, 264, 4618, 36810, 6828, 293, 295, 1164, 341, 307, 364, 420, 11943, 24440, 5143, 50940, 50964, 1105, 370, 562, 291, 360, 264, 264, 1674, 1296, 732, 17949, 291, 486, 483, 472, 498, 436, 366, 264, 912, 293, 51264, 51264, 550, 291, 483, 4018, 498, 436, 366, 41488, 498, 436, 366, 819, 2232, 291, 341, 307, 611, 364, 33966, 964, 51584, 51584], "temperature": 0.0, "avg_logprob": -0.14315304302033924, "compression_ratio": 1.8527918781725887, "no_speech_prob": 8.76078411238268e-06}, {"id": 270, "seek": 183204, "start": 1844.04, "end": 1850.04, "text": " um so when you do the the product between two bases you will get one if they are the same and", "tokens": [50364, 18875, 1392, 337, 1184, 8255, 293, 264, 635, 564, 399, 797, 18875, 436, 366, 1219, 264, 36810, 6828, 50664, 50696, 1392, 264, 4618, 36810, 6828, 293, 295, 1164, 341, 307, 364, 420, 11943, 24440, 5143, 50940, 50964, 1105, 370, 562, 291, 360, 264, 264, 1674, 1296, 732, 17949, 291, 486, 483, 472, 498, 436, 366, 264, 912, 293, 51264, 51264, 550, 291, 483, 4018, 498, 436, 366, 41488, 498, 436, 366, 819, 2232, 291, 341, 307, 611, 364, 33966, 964, 51584, 51584], "temperature": 0.0, "avg_logprob": -0.14315304302033924, "compression_ratio": 1.8527918781725887, "no_speech_prob": 8.76078411238268e-06}, {"id": 271, "seek": 183204, "start": 1850.04, "end": 1856.44, "text": " then you get zero if they are orthogonal if they are different uh you this is also an invertible", "tokens": [50364, 18875, 1392, 337, 1184, 8255, 293, 264, 635, 564, 399, 797, 18875, 436, 366, 1219, 264, 36810, 6828, 50664, 50696, 1392, 264, 4618, 36810, 6828, 293, 295, 1164, 341, 307, 364, 420, 11943, 24440, 5143, 50940, 50964, 1105, 370, 562, 291, 360, 264, 264, 1674, 1296, 732, 17949, 291, 486, 483, 472, 498, 436, 366, 264, 912, 293, 51264, 51264, 550, 291, 483, 4018, 498, 436, 366, 41488, 498, 436, 366, 819, 2232, 291, 341, 307, 611, 364, 33966, 964, 51584, 51584], "temperature": 0.0, "avg_logprob": -0.14315304302033924, "compression_ratio": 1.8527918781725887, "no_speech_prob": 8.76078411238268e-06}, {"id": 272, "seek": 185644, "start": 1856.44, "end": 1866.2, "text": " uh matrix this guy so this matrix this is the uh diagonal matrix of the laplation eigenvalues", "tokens": [50364, 2232, 8141, 341, 2146, 370, 341, 8141, 341, 307, 264, 2232, 21539, 8141, 295, 264, 635, 564, 399, 10446, 46033, 50852, 50852, 370, 13607, 472, 281, 13607, 297, 293, 293, 293, 321, 458, 300, 337, 264, 48704, 3861, 300, 613, 4190, 51240, 51240, 366, 37498, 1296, 4018, 293, 1296, 732, 370, 341, 307, 264, 6674, 2158, 300, 291, 393, 483, 51460, 51492, 341, 2146, 264, 635, 564, 399, 10446, 46033, 436, 366, 2570, 382, 264, 11143, 295, 264, 4295, 1392, 370, 498, 291, 747, 51808, 51808], "temperature": 0.0, "avg_logprob": -0.09562401338057085, "compression_ratio": 1.9739583333333333, "no_speech_prob": 2.8532760552479886e-05}, {"id": 273, "seek": 185644, "start": 1866.2, "end": 1873.96, "text": " so lambda one to lambda n and and and we know that for the normalized application that these values", "tokens": [50364, 2232, 8141, 341, 2146, 370, 341, 8141, 341, 307, 264, 2232, 21539, 8141, 295, 264, 635, 564, 399, 10446, 46033, 50852, 50852, 370, 13607, 472, 281, 13607, 297, 293, 293, 293, 321, 458, 300, 337, 264, 48704, 3861, 300, 613, 4190, 51240, 51240, 366, 37498, 1296, 4018, 293, 1296, 732, 370, 341, 307, 264, 6674, 2158, 300, 291, 393, 483, 51460, 51492, 341, 2146, 264, 635, 564, 399, 10446, 46033, 436, 366, 2570, 382, 264, 11143, 295, 264, 4295, 1392, 370, 498, 291, 747, 51808, 51808], "temperature": 0.0, "avg_logprob": -0.09562401338057085, "compression_ratio": 1.9739583333333333, "no_speech_prob": 2.8532760552479886e-05}, {"id": 274, "seek": 185644, "start": 1873.96, "end": 1878.3600000000001, "text": " are bounded between zero and between two so this is the maximum value that you can get", "tokens": [50364, 2232, 8141, 341, 2146, 370, 341, 8141, 341, 307, 264, 2232, 21539, 8141, 295, 264, 635, 564, 399, 10446, 46033, 50852, 50852, 370, 13607, 472, 281, 13607, 297, 293, 293, 293, 321, 458, 300, 337, 264, 48704, 3861, 300, 613, 4190, 51240, 51240, 366, 37498, 1296, 4018, 293, 1296, 732, 370, 341, 307, 264, 6674, 2158, 300, 291, 393, 483, 51460, 51492, 341, 2146, 264, 635, 564, 399, 10446, 46033, 436, 366, 2570, 382, 264, 11143, 295, 264, 4295, 1392, 370, 498, 291, 747, 51808, 51808], "temperature": 0.0, "avg_logprob": -0.09562401338057085, "compression_ratio": 1.9739583333333333, "no_speech_prob": 2.8532760552479886e-05}, {"id": 275, "seek": 185644, "start": 1879.0, "end": 1885.3200000000002, "text": " this guy the laplation eigenvalues they are known as the spectrum of the graph okay so if you take", "tokens": [50364, 2232, 8141, 341, 2146, 370, 341, 8141, 341, 307, 264, 2232, 21539, 8141, 295, 264, 635, 564, 399, 10446, 46033, 50852, 50852, 370, 13607, 472, 281, 13607, 297, 293, 293, 293, 321, 458, 300, 337, 264, 48704, 3861, 300, 613, 4190, 51240, 51240, 366, 37498, 1296, 4018, 293, 1296, 732, 370, 341, 307, 264, 6674, 2158, 300, 291, 393, 483, 51460, 51492, 341, 2146, 264, 635, 564, 399, 10446, 46033, 436, 366, 2570, 382, 264, 11143, 295, 264, 4295, 1392, 370, 498, 291, 747, 51808, 51808], "temperature": 0.0, "avg_logprob": -0.09562401338057085, "compression_ratio": 1.9739583333333333, "no_speech_prob": 2.8532760552479886e-05}, {"id": 276, "seek": 188532, "start": 1885.32, "end": 1892.12, "text": " a graph here you have 27 nodes if i compute the laplation eigenvalues and if i put them", "tokens": [50364, 257, 4295, 510, 291, 362, 7634, 13891, 498, 741, 14722, 264, 635, 564, 399, 10446, 46033, 293, 498, 741, 829, 552, 50704, 50704, 741, 362, 257, 13397, 295, 264, 4295, 597, 307, 1219, 264, 11143, 295, 264, 4295, 1392, 300, 597, 486, 312, 50980, 50980, 819, 337, 1184, 1184, 4295, 1392, 293, 510, 291, 362, 1392, 341, 307, 437, 741, 584, 370, 341, 307, 884, 51292, 51320, 797, 48356, 370, 498, 291, 747, 428, 635, 564, 399, 8141, 293, 291, 3079, 281, 257, 8062, 13107, 295, 350, 550, 51724, 51724], "temperature": 0.0, "avg_logprob": -0.11512795738551927, "compression_ratio": 1.8076923076923077, "no_speech_prob": 9.788096576812677e-06}, {"id": 277, "seek": 188532, "start": 1892.12, "end": 1897.6399999999999, "text": " i have a signature of the graph which is called the spectrum of the graph okay that which will be", "tokens": [50364, 257, 4295, 510, 291, 362, 7634, 13891, 498, 741, 14722, 264, 635, 564, 399, 10446, 46033, 293, 498, 741, 829, 552, 50704, 50704, 741, 362, 257, 13397, 295, 264, 4295, 597, 307, 1219, 264, 11143, 295, 264, 4295, 1392, 300, 597, 486, 312, 50980, 50980, 819, 337, 1184, 1184, 4295, 1392, 293, 510, 291, 362, 1392, 341, 307, 437, 741, 584, 370, 341, 307, 884, 51292, 51320, 797, 48356, 370, 498, 291, 747, 428, 635, 564, 399, 8141, 293, 291, 3079, 281, 257, 8062, 13107, 295, 350, 550, 51724, 51724], "temperature": 0.0, "avg_logprob": -0.11512795738551927, "compression_ratio": 1.8076923076923077, "no_speech_prob": 9.788096576812677e-06}, {"id": 278, "seek": 188532, "start": 1897.6399999999999, "end": 1903.8799999999999, "text": " different for each each graph okay and here you have okay this is what i say so this is doing", "tokens": [50364, 257, 4295, 510, 291, 362, 7634, 13891, 498, 741, 14722, 264, 635, 564, 399, 10446, 46033, 293, 498, 741, 829, 552, 50704, 50704, 741, 362, 257, 13397, 295, 264, 4295, 597, 307, 1219, 264, 11143, 295, 264, 4295, 1392, 300, 597, 486, 312, 50980, 50980, 819, 337, 1184, 1184, 4295, 1392, 293, 510, 291, 362, 1392, 341, 307, 437, 741, 584, 370, 341, 307, 884, 51292, 51320, 797, 48356, 370, 498, 291, 747, 428, 635, 564, 399, 8141, 293, 291, 3079, 281, 257, 8062, 13107, 295, 350, 550, 51724, 51724], "temperature": 0.0, "avg_logprob": -0.11512795738551927, "compression_ratio": 1.8076923076923077, "no_speech_prob": 9.788096576812677e-06}, {"id": 279, "seek": 188532, "start": 1904.4399999999998, "end": 1912.52, "text": " again decomposition so if you take your laplation matrix and you apply to a vector phi of k then", "tokens": [50364, 257, 4295, 510, 291, 362, 7634, 13891, 498, 741, 14722, 264, 635, 564, 399, 10446, 46033, 293, 498, 741, 829, 552, 50704, 50704, 741, 362, 257, 13397, 295, 264, 4295, 597, 307, 1219, 264, 11143, 295, 264, 4295, 1392, 300, 597, 486, 312, 50980, 50980, 819, 337, 1184, 1184, 4295, 1392, 293, 510, 291, 362, 1392, 341, 307, 437, 741, 584, 370, 341, 307, 884, 51292, 51320, 797, 48356, 370, 498, 291, 747, 428, 635, 564, 399, 8141, 293, 291, 3079, 281, 257, 8062, 13107, 295, 350, 550, 51724, 51724], "temperature": 0.0, "avg_logprob": -0.11512795738551927, "compression_ratio": 1.8076923076923077, "no_speech_prob": 9.788096576812677e-06}, {"id": 280, "seek": 191252, "start": 1912.52, "end": 1920.44, "text": " you will get the eigenvalue lambda k times the same vector phi of k okay so this is the definition", "tokens": [50364, 291, 486, 483, 264, 10446, 29155, 13607, 350, 1413, 264, 912, 8062, 13107, 295, 350, 1392, 370, 341, 307, 264, 7123, 50760, 50760, 295, 264, 10446, 48356, 1392, 370, 291, 536, 300, 337, 6828, 456, 366, 1825, 1646, 813, 264, 51204, 51204, 635, 564, 399, 10446, 303, 5547, 51292, 51580], "temperature": 0.0, "avg_logprob": -0.10705394928271954, "compression_ratio": 1.628787878787879, "no_speech_prob": 3.2318562261934858e-06}, {"id": 281, "seek": 191252, "start": 1920.44, "end": 1929.32, "text": " of the eigen decomposition okay so you see that for functions there are nothing else than the", "tokens": [50364, 291, 486, 483, 264, 10446, 29155, 13607, 350, 1413, 264, 912, 8062, 13107, 295, 350, 1392, 370, 341, 307, 264, 7123, 50760, 50760, 295, 264, 10446, 48356, 1392, 370, 291, 536, 300, 337, 6828, 456, 366, 1825, 1646, 813, 264, 51204, 51204, 635, 564, 399, 10446, 303, 5547, 51292, 51580], "temperature": 0.0, "avg_logprob": -0.10705394928271954, "compression_ratio": 1.628787878787879, "no_speech_prob": 3.2318562261934858e-06}, {"id": 282, "seek": 191252, "start": 1929.32, "end": 1931.08, "text": " laplation eigenvectors", "tokens": [50364, 291, 486, 483, 264, 10446, 29155, 13607, 350, 1413, 264, 912, 8062, 13107, 295, 350, 1392, 370, 341, 307, 264, 7123, 50760, 50760, 295, 264, 10446, 48356, 1392, 370, 291, 536, 300, 337, 6828, 456, 366, 1825, 1646, 813, 264, 51204, 51204, 635, 564, 399, 10446, 303, 5547, 51292, 51580], "temperature": 0.0, "avg_logprob": -0.10705394928271954, "compression_ratio": 1.628787878787879, "no_speech_prob": 3.2318562261934858e-06}, {"id": 283, "seek": 193108, "start": 1931.08, "end": 1940.9199999999998, "text": " okay let me illustrate these fourier functions so we actually we already know fourier functions", "tokens": [50364, 1392, 718, 385, 23221, 613, 1451, 811, 6828, 370, 321, 767, 321, 1217, 458, 1451, 811, 6828, 50856, 50888, 498, 291, 498, 291, 747, 264, 10748, 370, 337, 1365, 291, 747, 510, 257, 472, 4314, 293, 291, 14722, 264, 1451, 811, 51112, 51112, 6828, 370, 291, 370, 291, 486, 483, 13107, 4018, 1392, 550, 291, 486, 483, 13107, 472, 597, 307, 341, 472, 597, 307, 51504, 51504], "temperature": 0.0, "avg_logprob": -0.26730548471644305, "compression_ratio": 1.9276315789473684, "no_speech_prob": 4.493461801757803e-06}, {"id": 284, "seek": 193108, "start": 1941.56, "end": 1946.04, "text": " if you if you take the grid so for example you take here a one degree and you compute the fourier", "tokens": [50364, 1392, 718, 385, 23221, 613, 1451, 811, 6828, 370, 321, 767, 321, 1217, 458, 1451, 811, 6828, 50856, 50888, 498, 291, 498, 291, 747, 264, 10748, 370, 337, 1365, 291, 747, 510, 257, 472, 4314, 293, 291, 14722, 264, 1451, 811, 51112, 51112, 6828, 370, 291, 370, 291, 486, 483, 13107, 4018, 1392, 550, 291, 486, 483, 13107, 472, 597, 307, 341, 472, 597, 307, 51504, 51504], "temperature": 0.0, "avg_logprob": -0.26730548471644305, "compression_ratio": 1.9276315789473684, "no_speech_prob": 4.493461801757803e-06}, {"id": 285, "seek": 193108, "start": 1946.04, "end": 1953.8799999999999, "text": " functions so you so you will get phi zero okay then you will get phi one which is this one which is", "tokens": [50364, 1392, 718, 385, 23221, 613, 1451, 811, 6828, 370, 321, 767, 321, 1217, 458, 1451, 811, 6828, 50856, 50888, 498, 291, 498, 291, 747, 264, 10748, 370, 337, 1365, 291, 747, 510, 257, 472, 4314, 293, 291, 14722, 264, 1451, 811, 51112, 51112, 6828, 370, 291, 370, 291, 486, 483, 13107, 4018, 1392, 550, 291, 486, 483, 13107, 472, 597, 307, 341, 472, 597, 307, 51504, 51504], "temperature": 0.0, "avg_logprob": -0.26730548471644305, "compression_ratio": 1.9276315789473684, "no_speech_prob": 4.493461801757803e-06}, {"id": 286, "seek": 195388, "start": 1953.88, "end": 1961.72, "text": " smooth phi two which is less a little less smooth and phi three and so on and so on so this is when", "tokens": [50364, 5508, 13107, 732, 597, 307, 1570, 257, 707, 1570, 5508, 293, 13107, 1045, 293, 370, 322, 293, 370, 322, 370, 341, 307, 562, 50756, 50756, 2570, 341, 307, 264, 23565, 2445, 293, 264, 1034, 425, 4765, 3742, 293, 321, 764, 300, 291, 458, 337, 337, 3256, 51052, 51052, 19355, 370, 498, 321, 747, 364, 3256, 293, 321, 1716, 264, 3256, 322, 264, 1451, 811, 6828, 550, 264, 3256, 51328, 51328, 307, 516, 281, 312, 264, 264, 264, 9887, 307, 516, 281, 312, 637, 11668, 370, 291, 787, 1066, 291, 458, 264, 6343, 51544, 51544, 17619, 293, 291, 393, 360, 19355, 370, 341, 307, 746, 300, 307, 588, 1021, 337, 264, 51740, 51740], "temperature": 0.0, "avg_logprob": -0.22624044251023678, "compression_ratio": 2.0166666666666666, "no_speech_prob": 2.3547794626210816e-05}, {"id": 287, "seek": 195388, "start": 1961.72, "end": 1967.64, "text": " known this is the cosine function and the simulzoids and we use that you know for for image", "tokens": [50364, 5508, 13107, 732, 597, 307, 1570, 257, 707, 1570, 5508, 293, 13107, 1045, 293, 370, 322, 293, 370, 322, 370, 341, 307, 562, 50756, 50756, 2570, 341, 307, 264, 23565, 2445, 293, 264, 1034, 425, 4765, 3742, 293, 321, 764, 300, 291, 458, 337, 337, 3256, 51052, 51052, 19355, 370, 498, 321, 747, 364, 3256, 293, 321, 1716, 264, 3256, 322, 264, 1451, 811, 6828, 550, 264, 3256, 51328, 51328, 307, 516, 281, 312, 264, 264, 264, 9887, 307, 516, 281, 312, 637, 11668, 370, 291, 787, 1066, 291, 458, 264, 6343, 51544, 51544, 17619, 293, 291, 393, 360, 19355, 370, 341, 307, 746, 300, 307, 588, 1021, 337, 264, 51740, 51740], "temperature": 0.0, "avg_logprob": -0.22624044251023678, "compression_ratio": 2.0166666666666666, "no_speech_prob": 2.3547794626210816e-05}, {"id": 288, "seek": 195388, "start": 1967.64, "end": 1973.16, "text": " compression so if we take an image and we project the image on the fourier functions then the image", "tokens": [50364, 5508, 13107, 732, 597, 307, 1570, 257, 707, 1570, 5508, 293, 13107, 1045, 293, 370, 322, 293, 370, 322, 370, 341, 307, 562, 50756, 50756, 2570, 341, 307, 264, 23565, 2445, 293, 264, 1034, 425, 4765, 3742, 293, 321, 764, 300, 291, 458, 337, 337, 3256, 51052, 51052, 19355, 370, 498, 321, 747, 364, 3256, 293, 321, 1716, 264, 3256, 322, 264, 1451, 811, 6828, 550, 264, 3256, 51328, 51328, 307, 516, 281, 312, 264, 264, 264, 9887, 307, 516, 281, 312, 637, 11668, 370, 291, 787, 1066, 291, 458, 264, 6343, 51544, 51544, 17619, 293, 291, 393, 360, 19355, 370, 341, 307, 746, 300, 307, 588, 1021, 337, 264, 51740, 51740], "temperature": 0.0, "avg_logprob": -0.22624044251023678, "compression_ratio": 2.0166666666666666, "no_speech_prob": 2.3547794626210816e-05}, {"id": 289, "seek": 195388, "start": 1973.16, "end": 1977.48, "text": " is going to be the the the transformation is going to be sparse so you only keep you know the highest", "tokens": [50364, 5508, 13107, 732, 597, 307, 1570, 257, 707, 1570, 5508, 293, 13107, 1045, 293, 370, 322, 293, 370, 322, 370, 341, 307, 562, 50756, 50756, 2570, 341, 307, 264, 23565, 2445, 293, 264, 1034, 425, 4765, 3742, 293, 321, 764, 300, 291, 458, 337, 337, 3256, 51052, 51052, 19355, 370, 498, 321, 747, 364, 3256, 293, 321, 1716, 264, 3256, 322, 264, 1451, 811, 6828, 550, 264, 3256, 51328, 51328, 307, 516, 281, 312, 264, 264, 264, 9887, 307, 516, 281, 312, 637, 11668, 370, 291, 787, 1066, 291, 458, 264, 6343, 51544, 51544, 17619, 293, 291, 393, 360, 19355, 370, 341, 307, 746, 300, 307, 588, 1021, 337, 264, 51740, 51740], "temperature": 0.0, "avg_logprob": -0.22624044251023678, "compression_ratio": 2.0166666666666666, "no_speech_prob": 2.3547794626210816e-05}, {"id": 290, "seek": 195388, "start": 1977.48, "end": 1981.4, "text": " coefficient and you can do compression so this is something that is very important for the", "tokens": [50364, 5508, 13107, 732, 597, 307, 1570, 257, 707, 1570, 5508, 293, 13107, 1045, 293, 370, 322, 293, 370, 322, 370, 341, 307, 562, 50756, 50756, 2570, 341, 307, 264, 23565, 2445, 293, 264, 1034, 425, 4765, 3742, 293, 321, 764, 300, 291, 458, 337, 337, 3256, 51052, 51052, 19355, 370, 498, 321, 747, 364, 3256, 293, 321, 1716, 264, 3256, 322, 264, 1451, 811, 6828, 550, 264, 3256, 51328, 51328, 307, 516, 281, 312, 264, 264, 264, 9887, 307, 516, 281, 312, 637, 11668, 370, 291, 787, 1066, 291, 458, 264, 6343, 51544, 51544, 17619, 293, 291, 393, 360, 19355, 370, 341, 307, 746, 300, 307, 588, 1021, 337, 264, 51740, 51740], "temperature": 0.0, "avg_logprob": -0.22624044251023678, "compression_ratio": 2.0166666666666666, "no_speech_prob": 2.3547794626210816e-05}, {"id": 291, "seek": 198140, "start": 1981.4, "end": 1987.16, "text": " graph domain this is this is quite interesting so you see that and this is a graph and i'm computing", "tokens": [50364, 4295, 9274, 341, 307, 341, 307, 1596, 1880, 370, 291, 536, 300, 293, 341, 307, 257, 4295, 293, 741, 478, 15866, 50652, 50652, 510, 264, 264, 700, 1451, 291, 458, 1451, 811, 2445, 295, 264, 24877, 370, 291, 536, 337, 13107, 472, 291, 920, 51052, 51052, 362, 18225, 763, 291, 458, 1296, 3353, 293, 3671, 2158, 264, 912, 498, 291, 3353, 293, 3671, 51292, 51292, 2158, 293, 293, 510, 382, 731, 437, 307, 1880, 307, 300, 264, 51569, 51569], "temperature": 0.0, "avg_logprob": -0.26657179844232254, "compression_ratio": 1.9297297297297298, "no_speech_prob": 1.044541841110913e-05}, {"id": 292, "seek": 198140, "start": 1987.16, "end": 1995.16, "text": " here the the first four you know fourier function of the graphs so you see for phi one you still", "tokens": [50364, 4295, 9274, 341, 307, 341, 307, 1596, 1880, 370, 291, 536, 300, 293, 341, 307, 257, 4295, 293, 741, 478, 15866, 50652, 50652, 510, 264, 264, 700, 1451, 291, 458, 1451, 811, 2445, 295, 264, 24877, 370, 291, 536, 337, 13107, 472, 291, 920, 51052, 51052, 362, 18225, 763, 291, 458, 1296, 3353, 293, 3671, 2158, 264, 912, 498, 291, 3353, 293, 3671, 51292, 51292, 2158, 293, 293, 510, 382, 731, 437, 307, 1880, 307, 300, 264, 51569, 51569], "temperature": 0.0, "avg_logprob": -0.26657179844232254, "compression_ratio": 1.9297297297297298, "no_speech_prob": 1.044541841110913e-05}, {"id": 293, "seek": 198140, "start": 1995.16, "end": 1999.96, "text": " have oscillations you know between positive and negative value the same if you positive and negative", "tokens": [50364, 4295, 9274, 341, 307, 341, 307, 1596, 1880, 370, 291, 536, 300, 293, 341, 307, 257, 4295, 293, 741, 478, 15866, 50652, 50652, 510, 264, 264, 700, 1451, 291, 458, 1451, 811, 2445, 295, 264, 24877, 370, 291, 536, 337, 13107, 472, 291, 920, 51052, 51052, 362, 18225, 763, 291, 458, 1296, 3353, 293, 3671, 2158, 264, 912, 498, 291, 3353, 293, 3671, 51292, 51292, 2158, 293, 293, 510, 382, 731, 437, 307, 1880, 307, 300, 264, 51569, 51569], "temperature": 0.0, "avg_logprob": -0.26657179844232254, "compression_ratio": 1.9297297297297298, "no_speech_prob": 1.044541841110913e-05}, {"id": 294, "seek": 198140, "start": 1999.96, "end": 2005.5, "text": " value and and here as well what is interesting is that the", "tokens": [50364, 4295, 9274, 341, 307, 341, 307, 1596, 1880, 370, 291, 536, 300, 293, 341, 307, 257, 4295, 293, 741, 478, 15866, 50652, 50652, 510, 264, 264, 700, 1451, 291, 458, 1451, 811, 2445, 295, 264, 24877, 370, 291, 536, 337, 13107, 472, 291, 920, 51052, 51052, 362, 18225, 763, 291, 458, 1296, 3353, 293, 3671, 2158, 264, 912, 498, 291, 3353, 293, 3671, 51292, 51292, 2158, 293, 293, 510, 382, 731, 437, 307, 1880, 307, 300, 264, 51569, 51569], "temperature": 0.0, "avg_logprob": -0.26657179844232254, "compression_ratio": 1.9297297297297298, "no_speech_prob": 1.044541841110913e-05}, {"id": 295, "seek": 200550, "start": 2005.5, "end": 2012.52, "text": " oscillation depends on the topology of the graph okay so so it's related to the to the geometry of", "tokens": [50364, 18225, 399, 5946, 322, 264, 1192, 1793, 295, 264, 4295, 1392, 370, 370, 309, 311, 4077, 281, 264, 281, 264, 18426, 295, 50715, 50715, 264, 4295, 411, 4456, 411, 46870, 293, 370, 322, 293, 321, 458, 300, 370, 337, 1365, 498, 291, 528, 281, 7983, 51015, 51015, 350, 4456, 322, 4295, 257, 588, 665, 9284, 307, 281, 3079, 350, 12, 1398, 599, 322, 264, 700, 350, 1451, 811, 6828, 51539, 51539], "temperature": 0.0, "avg_logprob": -0.1515870159619475, "compression_ratio": 1.6464088397790055, "no_speech_prob": 5.4046386139816605e-06}, {"id": 296, "seek": 200550, "start": 2012.52, "end": 2018.52, "text": " the graph like communities like hubs and so on and we know that so for example if you want to capture", "tokens": [50364, 18225, 399, 5946, 322, 264, 1192, 1793, 295, 264, 4295, 1392, 370, 370, 309, 311, 4077, 281, 264, 281, 264, 18426, 295, 50715, 50715, 264, 4295, 411, 4456, 411, 46870, 293, 370, 322, 293, 321, 458, 300, 370, 337, 1365, 498, 291, 528, 281, 7983, 51015, 51015, 350, 4456, 322, 4295, 257, 588, 665, 9284, 307, 281, 3079, 350, 12, 1398, 599, 322, 264, 700, 350, 1451, 811, 6828, 51539, 51539], "temperature": 0.0, "avg_logprob": -0.1515870159619475, "compression_ratio": 1.6464088397790055, "no_speech_prob": 5.4046386139816605e-06}, {"id": 297, "seek": 200550, "start": 2018.52, "end": 2029.0, "text": " k communities on graph a very good algorithm is to apply k-means on the first k fourier functions", "tokens": [50364, 18225, 399, 5946, 322, 264, 1192, 1793, 295, 264, 4295, 1392, 370, 370, 309, 311, 4077, 281, 264, 281, 264, 18426, 295, 50715, 50715, 264, 4295, 411, 4456, 411, 46870, 293, 370, 322, 293, 321, 458, 300, 370, 337, 1365, 498, 291, 528, 281, 7983, 51015, 51015, 350, 4456, 322, 4295, 257, 588, 665, 9284, 307, 281, 3079, 350, 12, 1398, 599, 322, 264, 700, 350, 1451, 811, 6828, 51539, 51539], "temperature": 0.0, "avg_logprob": -0.1515870159619475, "compression_ratio": 1.6464088397790055, "no_speech_prob": 5.4046386139816605e-06}, {"id": 298, "seek": 202900, "start": 2029.0, "end": 2034.92, "text": " if you do that you have something that we call spectrograph theory and it's a it's a it's a huge", "tokens": [50364, 498, 291, 360, 300, 291, 362, 746, 300, 321, 818, 6177, 6675, 2662, 5261, 293, 309, 311, 257, 309, 311, 257, 309, 311, 257, 2603, 50660, 50660, 10394, 293, 293, 498, 291, 528, 281, 458, 544, 466, 341, 456, 307, 341, 588, 1481, 7073, 538, 3161, 50936, 50936, 450, 4785, 9120, 68, 466, 466, 6177, 6675, 2662, 596, 48673, 293, 1228, 439, 613, 35799, 295, 1451, 811, 6828, 51228, 51356, 1392, 1392, 586, 718, 385, 5366, 291, 1451, 811, 51580, 51580], "temperature": 0.0, "avg_logprob": -0.3059530602880271, "compression_ratio": 1.7688172043010753, "no_speech_prob": 9.492422577750403e-06}, {"id": 299, "seek": 202900, "start": 2034.92, "end": 2040.44, "text": " literature and and if you want to know more about this there is this very nice tutorial by van", "tokens": [50364, 498, 291, 360, 300, 291, 362, 746, 300, 321, 818, 6177, 6675, 2662, 5261, 293, 309, 311, 257, 309, 311, 257, 309, 311, 257, 2603, 50660, 50660, 10394, 293, 293, 498, 291, 528, 281, 458, 544, 466, 341, 456, 307, 341, 588, 1481, 7073, 538, 3161, 50936, 50936, 450, 4785, 9120, 68, 466, 466, 6177, 6675, 2662, 596, 48673, 293, 1228, 439, 613, 35799, 295, 1451, 811, 6828, 51228, 51356, 1392, 1392, 586, 718, 385, 5366, 291, 1451, 811, 51580, 51580], "temperature": 0.0, "avg_logprob": -0.3059530602880271, "compression_ratio": 1.7688172043010753, "no_speech_prob": 9.492422577750403e-06}, {"id": 300, "seek": 202900, "start": 2040.44, "end": 2046.28, "text": " loomsbroe about about spectrograph clustering and using all these notions of fourier functions", "tokens": [50364, 498, 291, 360, 300, 291, 362, 746, 300, 321, 818, 6177, 6675, 2662, 5261, 293, 309, 311, 257, 309, 311, 257, 309, 311, 257, 2603, 50660, 50660, 10394, 293, 293, 498, 291, 528, 281, 458, 544, 466, 341, 456, 307, 341, 588, 1481, 7073, 538, 3161, 50936, 50936, 450, 4785, 9120, 68, 466, 466, 6177, 6675, 2662, 596, 48673, 293, 1228, 439, 613, 35799, 295, 1451, 811, 6828, 51228, 51356, 1392, 1392, 586, 718, 385, 5366, 291, 1451, 811, 51580, 51580], "temperature": 0.0, "avg_logprob": -0.3059530602880271, "compression_ratio": 1.7688172043010753, "no_speech_prob": 9.492422577750403e-06}, {"id": 301, "seek": 202900, "start": 2048.84, "end": 2053.32, "text": " okay okay now let me introduce you fourier", "tokens": [50364, 498, 291, 360, 300, 291, 362, 746, 300, 321, 818, 6177, 6675, 2662, 5261, 293, 309, 311, 257, 309, 311, 257, 309, 311, 257, 2603, 50660, 50660, 10394, 293, 293, 498, 291, 528, 281, 458, 544, 466, 341, 456, 307, 341, 588, 1481, 7073, 538, 3161, 50936, 50936, 450, 4785, 9120, 68, 466, 466, 6177, 6675, 2662, 596, 48673, 293, 1228, 439, 613, 35799, 295, 1451, 811, 6828, 51228, 51356, 1392, 1392, 586, 718, 385, 5366, 291, 1451, 811, 51580, 51580], "temperature": 0.0, "avg_logprob": -0.3059530602880271, "compression_ratio": 1.7688172043010753, "no_speech_prob": 9.492422577750403e-06}, {"id": 302, "seek": 205332, "start": 2053.32, "end": 2060.28, "text": " transform okay so for this i'm going to do the fourier series for your series is nothing else", "tokens": [50364, 4088, 1392, 370, 337, 341, 741, 478, 516, 281, 360, 264, 1451, 811, 2638, 337, 428, 2638, 307, 1825, 1646, 50712, 50712, 550, 291, 747, 257, 2445, 276, 7642, 322, 428, 4295, 293, 550, 291, 366, 516, 281, 22867, 541, 341, 2445, 51028, 51028, 1228, 264, 1451, 811, 2445, 1392, 370, 741, 747, 452, 2445, 276, 741, 1716, 452, 2445, 276, 322, 1184, 51412, 51412], "temperature": 0.0, "avg_logprob": -0.16598227486681583, "compression_ratio": 1.917808219178082, "no_speech_prob": 1.9138935385853983e-05}, {"id": 303, "seek": 205332, "start": 2060.28, "end": 2066.6000000000004, "text": " then you take a function h defined on your graph and then you are going to decompose this function", "tokens": [50364, 4088, 1392, 370, 337, 341, 741, 478, 516, 281, 360, 264, 1451, 811, 2638, 337, 428, 2638, 307, 1825, 1646, 50712, 50712, 550, 291, 747, 257, 2445, 276, 7642, 322, 428, 4295, 293, 550, 291, 366, 516, 281, 22867, 541, 341, 2445, 51028, 51028, 1228, 264, 1451, 811, 2445, 1392, 370, 741, 747, 452, 2445, 276, 741, 1716, 452, 2445, 276, 322, 1184, 51412, 51412], "temperature": 0.0, "avg_logprob": -0.16598227486681583, "compression_ratio": 1.917808219178082, "no_speech_prob": 1.9138935385853983e-05}, {"id": 304, "seek": 205332, "start": 2066.6000000000004, "end": 2074.28, "text": " using the fourier function okay so i take my function h i project my function h on each", "tokens": [50364, 4088, 1392, 370, 337, 341, 741, 478, 516, 281, 360, 264, 1451, 811, 2638, 337, 428, 2638, 307, 1825, 1646, 50712, 50712, 550, 291, 747, 257, 2445, 276, 7642, 322, 428, 4295, 293, 550, 291, 366, 516, 281, 22867, 541, 341, 2445, 51028, 51028, 1228, 264, 1451, 811, 2445, 1392, 370, 741, 747, 452, 2445, 276, 741, 1716, 452, 2445, 276, 322, 1184, 51412, 51412], "temperature": 0.0, "avg_logprob": -0.16598227486681583, "compression_ratio": 1.917808219178082, "no_speech_prob": 1.9138935385853983e-05}, {"id": 305, "seek": 207428, "start": 2074.28, "end": 2084.44, "text": " fourier function phi of k and i will get you know this coefficient of this fourier series it's going", "tokens": [50364, 1451, 811, 2445, 13107, 295, 350, 293, 741, 486, 483, 291, 458, 341, 17619, 295, 341, 1451, 811, 2638, 309, 311, 516, 50872, 50872, 281, 312, 257, 39684, 17207, 538, 452, 2445, 13107, 295, 350, 1392, 295, 264, 565, 293, 297, 538, 472, 295, 264, 2744, 293, 51280, 51280, 297, 538, 472, 1392, 370, 293, 884, 300, 291, 458, 445, 43001, 452, 2445, 322, 264, 1451, 811, 6828, 51608, 51608], "temperature": 0.0, "avg_logprob": -0.16408965322706434, "compression_ratio": 1.858974358974359, "no_speech_prob": 1.9327173959027277e-06}, {"id": 306, "seek": 207428, "start": 2084.44, "end": 2092.6000000000004, "text": " to be a scalar multiplied by my function phi of k okay of the time and n by one of the size and", "tokens": [50364, 1451, 811, 2445, 13107, 295, 350, 293, 741, 486, 483, 291, 458, 341, 17619, 295, 341, 1451, 811, 2638, 309, 311, 516, 50872, 50872, 281, 312, 257, 39684, 17207, 538, 452, 2445, 13107, 295, 350, 1392, 295, 264, 565, 293, 297, 538, 472, 295, 264, 2744, 293, 51280, 51280, 297, 538, 472, 1392, 370, 293, 884, 300, 291, 458, 445, 43001, 452, 2445, 322, 264, 1451, 811, 6828, 51608, 51608], "temperature": 0.0, "avg_logprob": -0.16408965322706434, "compression_ratio": 1.858974358974359, "no_speech_prob": 1.9327173959027277e-06}, {"id": 307, "seek": 207428, "start": 2092.6000000000004, "end": 2099.1600000000003, "text": " n by one okay so and doing that you know just projecting my function on the fourier functions", "tokens": [50364, 1451, 811, 2445, 13107, 295, 350, 293, 741, 486, 483, 291, 458, 341, 17619, 295, 341, 1451, 811, 2638, 309, 311, 516, 50872, 50872, 281, 312, 257, 39684, 17207, 538, 452, 2445, 13107, 295, 350, 1392, 295, 264, 565, 293, 297, 538, 472, 295, 264, 2744, 293, 51280, 51280, 297, 538, 472, 1392, 370, 293, 884, 300, 291, 458, 445, 43001, 452, 2445, 322, 264, 1451, 811, 6828, 51608, 51608], "temperature": 0.0, "avg_logprob": -0.16408965322706434, "compression_ratio": 1.858974358974359, "no_speech_prob": 1.9327173959027277e-06}, {"id": 308, "seek": 209916, "start": 2099.16, "end": 2104.68, "text": " just projecting my function on the fourier functions give me the fourier transform okay so", "tokens": [50364, 445, 43001, 452, 2445, 322, 264, 1451, 811, 6828, 976, 385, 264, 1451, 811, 4088, 1392, 370, 50640, 50640, 264, 1451, 811, 4088, 307, 307, 445, 291, 458, 264, 17619, 295, 264, 1451, 811, 2638, 1825, 1646, 50864, 50892, 1392, 550, 276, 291, 458, 307, 257, 1936, 257, 8213, 6562, 295, 264, 1451, 811, 4088, 1413, 51232, 51232, 264, 264, 1451, 811, 6828, 1392, 741, 393, 28132, 1203, 294, 8141, 8062, 10290, 51616, 51616], "temperature": 0.0, "avg_logprob": -0.07844227238705284, "compression_ratio": 2.0282485875706215, "no_speech_prob": 1.338743732048897e-05}, {"id": 309, "seek": 209916, "start": 2104.68, "end": 2109.16, "text": " the fourier transform is is just you know the coefficient of the fourier series nothing else", "tokens": [50364, 445, 43001, 452, 2445, 322, 264, 1451, 811, 6828, 976, 385, 264, 1451, 811, 4088, 1392, 370, 50640, 50640, 264, 1451, 811, 4088, 307, 307, 445, 291, 458, 264, 17619, 295, 264, 1451, 811, 2638, 1825, 1646, 50864, 50892, 1392, 550, 276, 291, 458, 307, 257, 1936, 257, 8213, 6562, 295, 264, 1451, 811, 4088, 1413, 51232, 51232, 264, 264, 1451, 811, 6828, 1392, 741, 393, 28132, 1203, 294, 8141, 8062, 10290, 51616, 51616], "temperature": 0.0, "avg_logprob": -0.07844227238705284, "compression_ratio": 2.0282485875706215, "no_speech_prob": 1.338743732048897e-05}, {"id": 310, "seek": 209916, "start": 2109.72, "end": 2116.52, "text": " okay then h you know is a basically a linear combination of the fourier transform times", "tokens": [50364, 445, 43001, 452, 2445, 322, 264, 1451, 811, 6828, 976, 385, 264, 1451, 811, 4088, 1392, 370, 50640, 50640, 264, 1451, 811, 4088, 307, 307, 445, 291, 458, 264, 17619, 295, 264, 1451, 811, 2638, 1825, 1646, 50864, 50892, 1392, 550, 276, 291, 458, 307, 257, 1936, 257, 8213, 6562, 295, 264, 1451, 811, 4088, 1413, 51232, 51232, 264, 264, 1451, 811, 6828, 1392, 741, 393, 28132, 1203, 294, 8141, 8062, 10290, 51616, 51616], "temperature": 0.0, "avg_logprob": -0.07844227238705284, "compression_ratio": 2.0282485875706215, "no_speech_prob": 1.338743732048897e-05}, {"id": 311, "seek": 209916, "start": 2116.52, "end": 2124.2, "text": " the the fourier functions okay i can rewrite everything in matrix vector representation", "tokens": [50364, 445, 43001, 452, 2445, 322, 264, 1451, 811, 6828, 976, 385, 264, 1451, 811, 4088, 1392, 370, 50640, 50640, 264, 1451, 811, 4088, 307, 307, 445, 291, 458, 264, 17619, 295, 264, 1451, 811, 2638, 1825, 1646, 50864, 50892, 1392, 550, 276, 291, 458, 307, 257, 1936, 257, 8213, 6562, 295, 264, 1451, 811, 4088, 1413, 51232, 51232, 264, 264, 1451, 811, 6828, 1392, 741, 393, 28132, 1203, 294, 8141, 8062, 10290, 51616, 51616], "temperature": 0.0, "avg_logprob": -0.07844227238705284, "compression_ratio": 2.0282485875706215, "no_speech_prob": 1.338743732048897e-05}, {"id": 312, "seek": 212420, "start": 2124.2, "end": 2131.8799999999997, "text": " and this guy so doing the phi times the the fourier transform this is actually the inverse fourier", "tokens": [50364, 293, 341, 2146, 370, 884, 264, 13107, 1413, 264, 264, 1451, 811, 4088, 341, 307, 767, 264, 17340, 1451, 811, 50748, 50748, 4088, 1392, 370, 718, 385, 20858, 341, 498, 741, 360, 498, 741, 1716, 276, 322, 264, 1451, 811, 6828, 741, 486, 362, 51176, 51176, 264, 1451, 811, 4088, 1392, 370, 741, 478, 1940, 264, 8141, 295, 264, 1451, 811, 6828, 293, 741, 478, 17207, 538, 276, 51508, 51508], "temperature": 0.0, "avg_logprob": -0.10588568449020386, "compression_ratio": 1.9166666666666667, "no_speech_prob": 8.262454684881959e-06}, {"id": 313, "seek": 212420, "start": 2131.8799999999997, "end": 2140.4399999999996, "text": " transform okay so let me summarize this if i do if i project h on the fourier functions i will have", "tokens": [50364, 293, 341, 2146, 370, 884, 264, 13107, 1413, 264, 264, 1451, 811, 4088, 341, 307, 767, 264, 17340, 1451, 811, 50748, 50748, 4088, 1392, 370, 718, 385, 20858, 341, 498, 741, 360, 498, 741, 1716, 276, 322, 264, 1451, 811, 6828, 741, 486, 362, 51176, 51176, 264, 1451, 811, 4088, 1392, 370, 741, 478, 1940, 264, 8141, 295, 264, 1451, 811, 6828, 293, 741, 478, 17207, 538, 276, 51508, 51508], "temperature": 0.0, "avg_logprob": -0.10588568449020386, "compression_ratio": 1.9166666666666667, "no_speech_prob": 8.262454684881959e-06}, {"id": 314, "seek": 212420, "start": 2140.4399999999996, "end": 2147.08, "text": " the fourier transform okay so i'm taking the matrix of the fourier functions and i'm multiplied by h", "tokens": [50364, 293, 341, 2146, 370, 884, 264, 13107, 1413, 264, 264, 1451, 811, 4088, 341, 307, 767, 264, 17340, 1451, 811, 50748, 50748, 4088, 1392, 370, 718, 385, 20858, 341, 498, 741, 360, 498, 741, 1716, 276, 322, 264, 1451, 811, 6828, 741, 486, 362, 51176, 51176, 264, 1451, 811, 4088, 1392, 370, 741, 478, 1940, 264, 8141, 295, 264, 1451, 811, 6828, 293, 741, 478, 17207, 538, 276, 51508, 51508], "temperature": 0.0, "avg_logprob": -0.10588568449020386, "compression_ratio": 1.9166666666666667, "no_speech_prob": 8.262454684881959e-06}, {"id": 315, "seek": 214708, "start": 2147.08, "end": 2155.7999999999997, "text": " so this is n by n by n this is n by one so this is n by one okay and now if i do inverse fourier", "tokens": [50364, 370, 341, 307, 297, 538, 297, 538, 297, 341, 307, 297, 538, 472, 370, 341, 307, 297, 538, 472, 1392, 293, 586, 498, 741, 360, 17340, 1451, 811, 50800, 50800, 4088, 295, 264, 1451, 811, 4088, 1392, 370, 741, 576, 362, 13107, 295, 1451, 811, 4088, 295, 276, 293, 341, 2146, 307, 51280, 51280, 510, 1392, 370, 741, 445, 829, 13107, 25167, 276, 293, 321, 458, 300, 264, 264, 5143, 307, 2710, 370, 341, 2146, 307, 51780, 51780], "temperature": 0.0, "avg_logprob": -0.09446452260017395, "compression_ratio": 2.0416666666666665, "no_speech_prob": 7.166822797444183e-06}, {"id": 316, "seek": 214708, "start": 2155.7999999999997, "end": 2165.4, "text": " transform of the fourier transform okay so i would have phi of fourier transform of h and this guy is", "tokens": [50364, 370, 341, 307, 297, 538, 297, 538, 297, 341, 307, 297, 538, 472, 370, 341, 307, 297, 538, 472, 1392, 293, 586, 498, 741, 360, 17340, 1451, 811, 50800, 50800, 4088, 295, 264, 1451, 811, 4088, 1392, 370, 741, 576, 362, 13107, 295, 1451, 811, 4088, 295, 276, 293, 341, 2146, 307, 51280, 51280, 510, 1392, 370, 741, 445, 829, 13107, 25167, 276, 293, 321, 458, 300, 264, 264, 5143, 307, 2710, 370, 341, 2146, 307, 51780, 51780], "temperature": 0.0, "avg_logprob": -0.09446452260017395, "compression_ratio": 2.0416666666666665, "no_speech_prob": 7.166822797444183e-06}, {"id": 317, "seek": 214708, "start": 2165.4, "end": 2175.4, "text": " here okay so i just put phi transpose h and we know that the the basis is normal so this guy is", "tokens": [50364, 370, 341, 307, 297, 538, 297, 538, 297, 341, 307, 297, 538, 472, 370, 341, 307, 297, 538, 472, 1392, 293, 586, 498, 741, 360, 17340, 1451, 811, 50800, 50800, 4088, 295, 264, 1451, 811, 4088, 1392, 370, 741, 576, 362, 13107, 295, 1451, 811, 4088, 295, 276, 293, 341, 2146, 307, 51280, 51280, 510, 1392, 370, 741, 445, 829, 13107, 25167, 276, 293, 321, 458, 300, 264, 264, 5143, 307, 2710, 370, 341, 2146, 307, 51780, 51780], "temperature": 0.0, "avg_logprob": -0.09446452260017395, "compression_ratio": 2.0416666666666665, "no_speech_prob": 7.166822797444183e-06}, {"id": 318, "seek": 217540, "start": 2175.4, "end": 2180.92, "text": " actually identity function the identity i'm sorry identity matrix okay so this is an entity matrix", "tokens": [50364, 767, 6575, 2445, 264, 6575, 741, 478, 2597, 6575, 8141, 1392, 370, 341, 307, 364, 13977, 8141, 50640, 50640, 370, 741, 808, 646, 281, 281, 276, 370, 370, 264, 17340, 1451, 811, 4088, 307, 307, 295, 295, 264, 1451, 811, 4088, 307, 276, 51024, 51052, 2745, 1392, 370, 472, 551, 300, 291, 393, 11441, 307, 300, 264, 1451, 811, 4088, 293, 264, 17340, 51352, 51352, 1451, 811, 4088, 393, 312, 1096, 294, 472, 1622, 295, 3089, 1392, 291, 445, 747, 428, 8062, 276, 291, 12972, 538, 51676, 51676], "temperature": 0.0, "avg_logprob": -0.11679907904730903, "compression_ratio": 2.03125, "no_speech_prob": 3.1369802400149638e-06}, {"id": 319, "seek": 217540, "start": 2180.92, "end": 2188.6, "text": " so i come back to to h so so the inverse fourier transform is is of of the fourier transform is h", "tokens": [50364, 767, 6575, 2445, 264, 6575, 741, 478, 2597, 6575, 8141, 1392, 370, 341, 307, 364, 13977, 8141, 50640, 50640, 370, 741, 808, 646, 281, 281, 276, 370, 370, 264, 17340, 1451, 811, 4088, 307, 307, 295, 295, 264, 1451, 811, 4088, 307, 276, 51024, 51052, 2745, 1392, 370, 472, 551, 300, 291, 393, 11441, 307, 300, 264, 1451, 811, 4088, 293, 264, 17340, 51352, 51352, 1451, 811, 4088, 393, 312, 1096, 294, 472, 1622, 295, 3089, 1392, 291, 445, 747, 428, 8062, 276, 291, 12972, 538, 51676, 51676], "temperature": 0.0, "avg_logprob": -0.11679907904730903, "compression_ratio": 2.03125, "no_speech_prob": 3.1369802400149638e-06}, {"id": 320, "seek": 217540, "start": 2189.1600000000003, "end": 2195.1600000000003, "text": " obviously okay so one thing that you can observe is that the fourier transform and the inverse", "tokens": [50364, 767, 6575, 2445, 264, 6575, 741, 478, 2597, 6575, 8141, 1392, 370, 341, 307, 364, 13977, 8141, 50640, 50640, 370, 741, 808, 646, 281, 281, 276, 370, 370, 264, 17340, 1451, 811, 4088, 307, 307, 295, 295, 264, 1451, 811, 4088, 307, 276, 51024, 51052, 2745, 1392, 370, 472, 551, 300, 291, 393, 11441, 307, 300, 264, 1451, 811, 4088, 293, 264, 17340, 51352, 51352, 1451, 811, 4088, 393, 312, 1096, 294, 472, 1622, 295, 3089, 1392, 291, 445, 747, 428, 8062, 276, 291, 12972, 538, 51676, 51676], "temperature": 0.0, "avg_logprob": -0.11679907904730903, "compression_ratio": 2.03125, "no_speech_prob": 3.1369802400149638e-06}, {"id": 321, "seek": 217540, "start": 2195.1600000000003, "end": 2201.64, "text": " fourier transform can be done in one line of code okay you just take your vector h you multiply by", "tokens": [50364, 767, 6575, 2445, 264, 6575, 741, 478, 2597, 6575, 8141, 1392, 370, 341, 307, 364, 13977, 8141, 50640, 50640, 370, 741, 808, 646, 281, 281, 276, 370, 370, 264, 17340, 1451, 811, 4088, 307, 307, 295, 295, 264, 1451, 811, 4088, 307, 276, 51024, 51052, 2745, 1392, 370, 472, 551, 300, 291, 393, 11441, 307, 300, 264, 1451, 811, 4088, 293, 264, 17340, 51352, 51352, 1451, 811, 4088, 393, 312, 1096, 294, 472, 1622, 295, 3089, 1392, 291, 445, 747, 428, 8062, 276, 291, 12972, 538, 51676, 51676], "temperature": 0.0, "avg_logprob": -0.11679907904730903, "compression_ratio": 2.03125, "no_speech_prob": 3.1369802400149638e-06}, {"id": 322, "seek": 220164, "start": 2201.64, "end": 2207.0, "text": " this matrix and that's it and the same also to do the inverse fourier transform you take your your", "tokens": [50364, 341, 8141, 293, 300, 311, 309, 293, 264, 912, 611, 281, 360, 264, 17340, 1451, 811, 4088, 291, 747, 428, 428, 50632, 50632, 6358, 293, 291, 12972, 538, 341, 8141, 370, 309, 311, 1936, 445, 8213, 7705, 445, 30955, 50984, 50984, 257, 8141, 538, 257, 8062, 293, 341, 307, 577, 291, 360, 1451, 811, 4088, 364, 17340, 1451, 811, 4088, 322, 24877, 51204, 51460, 1392, 586, 718, 311, 718, 311, 360, 264, 45216, 20904, 370, 797, 264, 45216, 20904, 264, 1451, 811, 4088, 51792, 51852], "temperature": 0.0, "avg_logprob": -0.08560245886616323, "compression_ratio": 2.046153846153846, "no_speech_prob": 6.717732503602747e-06}, {"id": 323, "seek": 220164, "start": 2207.0, "end": 2214.04, "text": " signal and you multiply by this matrix so it's basically just linear operations just multiplying", "tokens": [50364, 341, 8141, 293, 300, 311, 309, 293, 264, 912, 611, 281, 360, 264, 17340, 1451, 811, 4088, 291, 747, 428, 428, 50632, 50632, 6358, 293, 291, 12972, 538, 341, 8141, 370, 309, 311, 1936, 445, 8213, 7705, 445, 30955, 50984, 50984, 257, 8141, 538, 257, 8062, 293, 341, 307, 577, 291, 360, 1451, 811, 4088, 364, 17340, 1451, 811, 4088, 322, 24877, 51204, 51460, 1392, 586, 718, 311, 718, 311, 360, 264, 45216, 20904, 370, 797, 264, 45216, 20904, 264, 1451, 811, 4088, 51792, 51852], "temperature": 0.0, "avg_logprob": -0.08560245886616323, "compression_ratio": 2.046153846153846, "no_speech_prob": 6.717732503602747e-06}, {"id": 324, "seek": 220164, "start": 2214.04, "end": 2218.44, "text": " a matrix by a vector and this is how you do fourier transform an inverse fourier transform on graphs", "tokens": [50364, 341, 8141, 293, 300, 311, 309, 293, 264, 912, 611, 281, 360, 264, 17340, 1451, 811, 4088, 291, 747, 428, 428, 50632, 50632, 6358, 293, 291, 12972, 538, 341, 8141, 370, 309, 311, 1936, 445, 8213, 7705, 445, 30955, 50984, 50984, 257, 8141, 538, 257, 8062, 293, 341, 307, 577, 291, 360, 1451, 811, 4088, 364, 17340, 1451, 811, 4088, 322, 24877, 51204, 51460, 1392, 586, 718, 311, 718, 311, 360, 264, 45216, 20904, 370, 797, 264, 45216, 20904, 264, 1451, 811, 4088, 51792, 51852], "temperature": 0.0, "avg_logprob": -0.08560245886616323, "compression_ratio": 2.046153846153846, "no_speech_prob": 6.717732503602747e-06}, {"id": 325, "seek": 220164, "start": 2223.56, "end": 2230.2, "text": " okay now let's let's do the convolution theorem so again the convolution theorem the fourier transform", "tokens": [50364, 341, 8141, 293, 300, 311, 309, 293, 264, 912, 611, 281, 360, 264, 17340, 1451, 811, 4088, 291, 747, 428, 428, 50632, 50632, 6358, 293, 291, 12972, 538, 341, 8141, 370, 309, 311, 1936, 445, 8213, 7705, 445, 30955, 50984, 50984, 257, 8141, 538, 257, 8062, 293, 341, 307, 577, 291, 360, 1451, 811, 4088, 364, 17340, 1451, 811, 4088, 322, 24877, 51204, 51460, 1392, 586, 718, 311, 718, 311, 360, 264, 45216, 20904, 370, 797, 264, 45216, 20904, 264, 1451, 811, 4088, 51792, 51852], "temperature": 0.0, "avg_logprob": -0.08560245886616323, "compression_ratio": 2.046153846153846, "no_speech_prob": 6.717732503602747e-06}, {"id": 326, "seek": 223020, "start": 2230.2, "end": 2237.24, "text": " the fourier transform of your um the fourier transform of the convolution is is going to be", "tokens": [50364, 264, 1451, 811, 4088, 295, 428, 1105, 264, 1451, 811, 4088, 295, 264, 45216, 307, 307, 516, 281, 312, 50716, 50716, 264, 935, 3711, 1674, 295, 264, 1451, 811, 4088, 295, 1184, 6358, 1392, 370, 718, 311, 584, 741, 362, 261, 45216, 51104, 51104, 276, 370, 741, 478, 516, 700, 281, 360, 264, 1451, 811, 4088, 295, 261, 550, 341, 307, 516, 281, 312, 257, 8062, 295, 264, 2744, 297, 51480, 51480, 538, 472, 550, 741, 478, 516, 281, 12972, 935, 3711, 538, 1071, 8062, 597, 307, 264, 1451, 811, 4088, 295, 51780, 51780], "temperature": 0.0, "avg_logprob": -0.07107234001159668, "compression_ratio": 2.191011235955056, "no_speech_prob": 2.89657309622271e-05}, {"id": 327, "seek": 223020, "start": 2237.24, "end": 2245.0, "text": " the pointwise product of the fourier transform of each signal okay so let's say i have w convolution", "tokens": [50364, 264, 1451, 811, 4088, 295, 428, 1105, 264, 1451, 811, 4088, 295, 264, 45216, 307, 307, 516, 281, 312, 50716, 50716, 264, 935, 3711, 1674, 295, 264, 1451, 811, 4088, 295, 1184, 6358, 1392, 370, 718, 311, 584, 741, 362, 261, 45216, 51104, 51104, 276, 370, 741, 478, 516, 700, 281, 360, 264, 1451, 811, 4088, 295, 261, 550, 341, 307, 516, 281, 312, 257, 8062, 295, 264, 2744, 297, 51480, 51480, 538, 472, 550, 741, 478, 516, 281, 12972, 935, 3711, 538, 1071, 8062, 597, 307, 264, 1451, 811, 4088, 295, 51780, 51780], "temperature": 0.0, "avg_logprob": -0.07107234001159668, "compression_ratio": 2.191011235955056, "no_speech_prob": 2.89657309622271e-05}, {"id": 328, "seek": 223020, "start": 2245.0, "end": 2252.52, "text": " h so i'm going first to do the fourier transform of w then this is going to be a vector of the size n", "tokens": [50364, 264, 1451, 811, 4088, 295, 428, 1105, 264, 1451, 811, 4088, 295, 264, 45216, 307, 307, 516, 281, 312, 50716, 50716, 264, 935, 3711, 1674, 295, 264, 1451, 811, 4088, 295, 1184, 6358, 1392, 370, 718, 311, 584, 741, 362, 261, 45216, 51104, 51104, 276, 370, 741, 478, 516, 700, 281, 360, 264, 1451, 811, 4088, 295, 261, 550, 341, 307, 516, 281, 312, 257, 8062, 295, 264, 2744, 297, 51480, 51480, 538, 472, 550, 741, 478, 516, 281, 12972, 935, 3711, 538, 1071, 8062, 597, 307, 264, 1451, 811, 4088, 295, 51780, 51780], "temperature": 0.0, "avg_logprob": -0.07107234001159668, "compression_ratio": 2.191011235955056, "no_speech_prob": 2.89657309622271e-05}, {"id": 329, "seek": 223020, "start": 2252.52, "end": 2258.52, "text": " by one then i'm going to multiply pointwise by another vector which is the fourier transform of", "tokens": [50364, 264, 1451, 811, 4088, 295, 428, 1105, 264, 1451, 811, 4088, 295, 264, 45216, 307, 307, 516, 281, 312, 50716, 50716, 264, 935, 3711, 1674, 295, 264, 1451, 811, 4088, 295, 1184, 6358, 1392, 370, 718, 311, 584, 741, 362, 261, 45216, 51104, 51104, 276, 370, 741, 478, 516, 700, 281, 360, 264, 1451, 811, 4088, 295, 261, 550, 341, 307, 516, 281, 312, 257, 8062, 295, 264, 2744, 297, 51480, 51480, 538, 472, 550, 741, 478, 516, 281, 12972, 935, 3711, 538, 1071, 8062, 597, 307, 264, 1451, 811, 4088, 295, 51780, 51780], "temperature": 0.0, "avg_logprob": -0.07107234001159668, "compression_ratio": 2.191011235955056, "no_speech_prob": 2.89657309622271e-05}, {"id": 330, "seek": 225852, "start": 2258.52, "end": 2264.6, "text": " h okay so how do we get the three transform you just by doing phi transpose w and phi transpose h", "tokens": [50364, 276, 1392, 370, 577, 360, 321, 483, 264, 1045, 4088, 291, 445, 538, 884, 13107, 25167, 261, 293, 13107, 25167, 276, 50668, 50708, 293, 550, 741, 478, 516, 281, 360, 264, 17340, 1045, 4088, 281, 808, 281, 352, 646, 281, 264, 23598, 9274, 50920, 50920, 370, 741, 478, 445, 17207, 538, 264, 8141, 13107, 1392, 297, 538, 297, 370, 341, 307, 437, 741, 2464, 510, 1392, 741, 362, 13107, 51288, 51324, 741, 362, 1105, 261, 2385, 597, 307, 257, 1451, 811, 4088, 293, 741, 362, 341, 341, 741, 478, 516, 281, 1319, 309, 51612, 51612], "temperature": 0.0, "avg_logprob": -0.09102904919496517, "compression_ratio": 1.8805970149253732, "no_speech_prob": 9.972218322218396e-06}, {"id": 331, "seek": 225852, "start": 2265.4, "end": 2269.64, "text": " and then i'm going to do the inverse three transform to come to go back to the spatial domain", "tokens": [50364, 276, 1392, 370, 577, 360, 321, 483, 264, 1045, 4088, 291, 445, 538, 884, 13107, 25167, 261, 293, 13107, 25167, 276, 50668, 50708, 293, 550, 741, 478, 516, 281, 360, 264, 17340, 1045, 4088, 281, 808, 281, 352, 646, 281, 264, 23598, 9274, 50920, 50920, 370, 741, 478, 445, 17207, 538, 264, 8141, 13107, 1392, 297, 538, 297, 370, 341, 307, 437, 741, 2464, 510, 1392, 741, 362, 13107, 51288, 51324, 741, 362, 1105, 261, 2385, 597, 307, 257, 1451, 811, 4088, 293, 741, 362, 341, 341, 741, 478, 516, 281, 1319, 309, 51612, 51612], "temperature": 0.0, "avg_logprob": -0.09102904919496517, "compression_ratio": 1.8805970149253732, "no_speech_prob": 9.972218322218396e-06}, {"id": 332, "seek": 225852, "start": 2269.64, "end": 2277.0, "text": " so i'm just multiplied by the matrix phi okay n by n so this is what i write here okay i have phi", "tokens": [50364, 276, 1392, 370, 577, 360, 321, 483, 264, 1045, 4088, 291, 445, 538, 884, 13107, 25167, 261, 293, 13107, 25167, 276, 50668, 50708, 293, 550, 741, 478, 516, 281, 360, 264, 17340, 1045, 4088, 281, 808, 281, 352, 646, 281, 264, 23598, 9274, 50920, 50920, 370, 741, 478, 445, 17207, 538, 264, 8141, 13107, 1392, 297, 538, 297, 370, 341, 307, 437, 741, 2464, 510, 1392, 741, 362, 13107, 51288, 51324, 741, 362, 1105, 261, 2385, 597, 307, 257, 1451, 811, 4088, 293, 741, 362, 341, 341, 741, 478, 516, 281, 1319, 309, 51612, 51612], "temperature": 0.0, "avg_logprob": -0.09102904919496517, "compression_ratio": 1.8805970149253732, "no_speech_prob": 9.972218322218396e-06}, {"id": 333, "seek": 225852, "start": 2277.72, "end": 2283.48, "text": " i have um w hat which is a fourier transform and i have this this i'm going to change it", "tokens": [50364, 276, 1392, 370, 577, 360, 321, 483, 264, 1045, 4088, 291, 445, 538, 884, 13107, 25167, 261, 293, 13107, 25167, 276, 50668, 50708, 293, 550, 741, 478, 516, 281, 360, 264, 17340, 1045, 4088, 281, 808, 281, 352, 646, 281, 264, 23598, 9274, 50920, 50920, 370, 741, 478, 445, 17207, 538, 264, 8141, 13107, 1392, 297, 538, 297, 370, 341, 307, 437, 741, 2464, 510, 1392, 741, 362, 13107, 51288, 51324, 741, 362, 1105, 261, 2385, 597, 307, 257, 1451, 811, 4088, 293, 741, 362, 341, 341, 741, 478, 516, 281, 1319, 309, 51612, 51612], "temperature": 0.0, "avg_logprob": -0.09102904919496517, "compression_ratio": 1.8805970149253732, "no_speech_prob": 9.972218322218396e-06}, {"id": 334, "seek": 228348, "start": 2283.48, "end": 2288.84, "text": " i'm going to change it to this line what is this line um shouldn't there be a phi transpose before", "tokens": [50364, 741, 478, 516, 281, 1319, 309, 281, 341, 1622, 437, 307, 341, 1622, 1105, 4659, 380, 456, 312, 257, 13107, 25167, 949, 50632, 50632, 261, 2385, 2597, 4659, 380, 456, 312, 257, 13107, 25167, 949, 261, 2385, 572, 264, 17340, 1451, 811, 4088, 307, 13107, 51176, 51216, 1392, 370, 291, 360, 13107, 293, 291, 12972, 538, 264, 1451, 811, 4088, 597, 307, 257, 13107, 25167, 261, 51516, 51516], "temperature": 0.0, "avg_logprob": -0.09216103553771973, "compression_ratio": 2.0, "no_speech_prob": 1.2798335774277803e-05}, {"id": 335, "seek": 228348, "start": 2288.84, "end": 2299.72, "text": " w hat sorry shouldn't there be a phi transpose before w hat no the inverse fourier transform is phi", "tokens": [50364, 741, 478, 516, 281, 1319, 309, 281, 341, 1622, 437, 307, 341, 1622, 1105, 4659, 380, 456, 312, 257, 13107, 25167, 949, 50632, 50632, 261, 2385, 2597, 4659, 380, 456, 312, 257, 13107, 25167, 949, 261, 2385, 572, 264, 17340, 1451, 811, 4088, 307, 13107, 51176, 51216, 1392, 370, 291, 360, 13107, 293, 291, 12972, 538, 264, 1451, 811, 4088, 597, 307, 257, 13107, 25167, 261, 51516, 51516], "temperature": 0.0, "avg_logprob": -0.09216103553771973, "compression_ratio": 2.0, "no_speech_prob": 1.2798335774277803e-05}, {"id": 336, "seek": 228348, "start": 2300.52, "end": 2306.52, "text": " okay so you do phi and you multiply by the fourier transform which is a phi transpose w", "tokens": [50364, 741, 478, 516, 281, 1319, 309, 281, 341, 1622, 437, 307, 341, 1622, 1105, 4659, 380, 456, 312, 257, 13107, 25167, 949, 50632, 50632, 261, 2385, 2597, 4659, 380, 456, 312, 257, 13107, 25167, 949, 261, 2385, 572, 264, 17340, 1451, 811, 4088, 307, 13107, 51176, 51216, 1392, 370, 291, 360, 13107, 293, 291, 12972, 538, 264, 1451, 811, 4088, 597, 307, 257, 13107, 25167, 261, 51516, 51516], "temperature": 0.0, "avg_logprob": -0.09216103553771973, "compression_ratio": 2.0, "no_speech_prob": 1.2798335774277803e-05}, {"id": 337, "seek": 230652, "start": 2306.52, "end": 2313.72, "text": " which i call uh hat uh w so i'm going i'm going to use that a lot uh i will come back to this and then", "tokens": [50364, 597, 741, 818, 2232, 2385, 2232, 261, 370, 741, 478, 516, 741, 478, 516, 281, 764, 300, 257, 688, 2232, 741, 486, 808, 646, 281, 341, 293, 550, 50724, 50724, 510, 291, 362, 264, 1451, 811, 4088, 295, 276, 597, 307, 445, 13107, 25167, 276, 597, 307, 510, 1392, 370, 341, 2146, 51064, 51140, 1392, 341, 2146, 307, 767, 437, 321, 818, 264, 42761, 2445, 1392, 264, 42761, 6608, 370, 51472, 51472, 341, 2146, 307, 257, 8062, 295, 297, 538, 472, 1392, 293, 741, 478, 3579, 741, 478, 3579, 510, 2232, 341, 8062, 510, 370, 51764, 51764], "temperature": 0.0, "avg_logprob": -0.08160925393152718, "compression_ratio": 1.9447236180904524, "no_speech_prob": 5.770412826677784e-06}, {"id": 338, "seek": 230652, "start": 2313.72, "end": 2320.52, "text": " here you have the fourier transform of h which is just phi transpose h which is here okay so this guy", "tokens": [50364, 597, 741, 818, 2232, 2385, 2232, 261, 370, 741, 478, 516, 741, 478, 516, 281, 764, 300, 257, 688, 2232, 741, 486, 808, 646, 281, 341, 293, 550, 50724, 50724, 510, 291, 362, 264, 1451, 811, 4088, 295, 276, 597, 307, 445, 13107, 25167, 276, 597, 307, 510, 1392, 370, 341, 2146, 51064, 51140, 1392, 341, 2146, 307, 767, 437, 321, 818, 264, 42761, 2445, 1392, 264, 42761, 6608, 370, 51472, 51472, 341, 2146, 307, 257, 8062, 295, 297, 538, 472, 1392, 293, 741, 478, 3579, 741, 478, 3579, 510, 2232, 341, 8062, 510, 370, 51764, 51764], "temperature": 0.0, "avg_logprob": -0.08160925393152718, "compression_ratio": 1.9447236180904524, "no_speech_prob": 5.770412826677784e-06}, {"id": 339, "seek": 230652, "start": 2322.04, "end": 2328.68, "text": " okay this guy is actually what we call the spectral function okay the spectral filter so", "tokens": [50364, 597, 741, 818, 2232, 2385, 2232, 261, 370, 741, 478, 516, 741, 478, 516, 281, 764, 300, 257, 688, 2232, 741, 486, 808, 646, 281, 341, 293, 550, 50724, 50724, 510, 291, 362, 264, 1451, 811, 4088, 295, 276, 597, 307, 445, 13107, 25167, 276, 597, 307, 510, 1392, 370, 341, 2146, 51064, 51140, 1392, 341, 2146, 307, 767, 437, 321, 818, 264, 42761, 2445, 1392, 264, 42761, 6608, 370, 51472, 51472, 341, 2146, 307, 257, 8062, 295, 297, 538, 472, 1392, 293, 741, 478, 3579, 741, 478, 3579, 510, 2232, 341, 8062, 510, 370, 51764, 51764], "temperature": 0.0, "avg_logprob": -0.08160925393152718, "compression_ratio": 1.9447236180904524, "no_speech_prob": 5.770412826677784e-06}, {"id": 340, "seek": 230652, "start": 2328.68, "end": 2334.52, "text": " this guy is a vector of n by one okay and i'm writing i'm writing here uh this vector here so", "tokens": [50364, 597, 741, 818, 2232, 2385, 2232, 261, 370, 741, 478, 516, 741, 478, 516, 281, 764, 300, 257, 688, 2232, 741, 486, 808, 646, 281, 341, 293, 550, 50724, 50724, 510, 291, 362, 264, 1451, 811, 4088, 295, 276, 597, 307, 445, 13107, 25167, 276, 597, 307, 510, 1392, 370, 341, 2146, 51064, 51140, 1392, 341, 2146, 307, 767, 437, 321, 818, 264, 42761, 2445, 1392, 264, 42761, 6608, 370, 51472, 51472, 341, 2146, 307, 257, 8062, 295, 297, 538, 472, 1392, 293, 741, 478, 3579, 741, 478, 3579, 510, 2232, 341, 8062, 510, 370, 51764, 51764], "temperature": 0.0, "avg_logprob": -0.08160925393152718, "compression_ratio": 1.9447236180904524, "no_speech_prob": 5.770412826677784e-06}, {"id": 341, "seek": 233452, "start": 2334.52, "end": 2342.04, "text": " you see this is a vector of n elements and this is actually the spectral function which is um", "tokens": [50364, 291, 536, 341, 307, 257, 8062, 295, 297, 4959, 293, 341, 307, 767, 264, 42761, 2445, 597, 307, 1105, 50740, 50808, 25509, 412, 264, 412, 264, 2232, 412, 264, 10446, 29155, 13607, 472, 597, 307, 510, 370, 341, 307, 341, 935, 510, 51180, 51180, 550, 291, 362, 2232, 261, 2385, 13607, 732, 597, 307, 341, 341, 2158, 510, 293, 370, 322, 293, 370, 322, 1392, 51508, 51588, 293, 550, 741, 478, 516, 281, 28132, 341, 291, 458, 741, 478, 516, 281, 829, 341, 51736, 51772], "temperature": 0.0, "avg_logprob": -0.07455768256351866, "compression_ratio": 1.9166666666666667, "no_speech_prob": 2.9005348096688977e-06}, {"id": 342, "seek": 233452, "start": 2343.4, "end": 2350.84, "text": " evaluated at the at the uh at the eigenvalue lambda one which is here so this is this point here", "tokens": [50364, 291, 536, 341, 307, 257, 8062, 295, 297, 4959, 293, 341, 307, 767, 264, 42761, 2445, 597, 307, 1105, 50740, 50808, 25509, 412, 264, 412, 264, 2232, 412, 264, 10446, 29155, 13607, 472, 597, 307, 510, 370, 341, 307, 341, 935, 510, 51180, 51180, 550, 291, 362, 2232, 261, 2385, 13607, 732, 597, 307, 341, 341, 2158, 510, 293, 370, 322, 293, 370, 322, 1392, 51508, 51588, 293, 550, 741, 478, 516, 281, 28132, 341, 291, 458, 741, 478, 516, 281, 829, 341, 51736, 51772], "temperature": 0.0, "avg_logprob": -0.07455768256351866, "compression_ratio": 1.9166666666666667, "no_speech_prob": 2.9005348096688977e-06}, {"id": 343, "seek": 233452, "start": 2350.84, "end": 2357.4, "text": " then you have uh w hat lambda two which is this this value here and so on and so on okay", "tokens": [50364, 291, 536, 341, 307, 257, 8062, 295, 297, 4959, 293, 341, 307, 767, 264, 42761, 2445, 597, 307, 1105, 50740, 50808, 25509, 412, 264, 412, 264, 2232, 412, 264, 10446, 29155, 13607, 472, 597, 307, 510, 370, 341, 307, 341, 935, 510, 51180, 51180, 550, 291, 362, 2232, 261, 2385, 13607, 732, 597, 307, 341, 341, 2158, 510, 293, 370, 322, 293, 370, 322, 1392, 51508, 51588, 293, 550, 741, 478, 516, 281, 28132, 341, 291, 458, 741, 478, 516, 281, 829, 341, 51736, 51772], "temperature": 0.0, "avg_logprob": -0.07455768256351866, "compression_ratio": 1.9166666666666667, "no_speech_prob": 2.9005348096688977e-06}, {"id": 344, "seek": 233452, "start": 2359.0, "end": 2361.96, "text": " and then i'm going to rewrite this you know i'm going to put this", "tokens": [50364, 291, 536, 341, 307, 257, 8062, 295, 297, 4959, 293, 341, 307, 767, 264, 42761, 2445, 597, 307, 1105, 50740, 50808, 25509, 412, 264, 412, 264, 2232, 412, 264, 10446, 29155, 13607, 472, 597, 307, 510, 370, 341, 307, 341, 935, 510, 51180, 51180, 550, 291, 362, 2232, 261, 2385, 13607, 732, 597, 307, 341, 341, 2158, 510, 293, 370, 322, 293, 370, 322, 1392, 51508, 51588, 293, 550, 741, 478, 516, 281, 28132, 341, 291, 458, 741, 478, 516, 281, 829, 341, 51736, 51772], "temperature": 0.0, "avg_logprob": -0.07455768256351866, "compression_ratio": 1.9166666666666667, "no_speech_prob": 2.9005348096688977e-06}, {"id": 345, "seek": 236196, "start": 2361.96, "end": 2368.12, "text": " uh in a diagonal okay so i will do diagonal of this vector so this will create a matrix of the", "tokens": [50364, 2232, 294, 257, 21539, 1392, 370, 741, 486, 360, 21539, 295, 341, 8062, 370, 341, 486, 1884, 257, 8141, 295, 264, 50672, 50672, 2744, 297, 538, 297, 1392, 293, 741, 478, 3372, 341, 2146, 646, 510, 370, 741, 478, 516, 281, 1319, 264, 2232, 264, 935, 3711, 51052, 51052, 27290, 295, 341, 8062, 297, 538, 472, 293, 341, 8062, 297, 538, 472, 538, 264, 8141, 8062, 27290, 51364, 51364, 293, 309, 311, 516, 281, 312, 264, 912, 558, 341, 307, 257, 21539, 8141, 597, 8306, 341, 2146, 51592, 51592], "temperature": 0.0, "avg_logprob": -0.13156411935994913, "compression_ratio": 2.0106951871657754, "no_speech_prob": 1.2397696082189213e-05}, {"id": 346, "seek": 236196, "start": 2368.12, "end": 2375.7200000000003, "text": " size n by n okay and i'm putting this guy back here so i'm going to change the uh the pointwise", "tokens": [50364, 2232, 294, 257, 21539, 1392, 370, 741, 486, 360, 21539, 295, 341, 8062, 370, 341, 486, 1884, 257, 8141, 295, 264, 50672, 50672, 2744, 297, 538, 297, 1392, 293, 741, 478, 3372, 341, 2146, 646, 510, 370, 741, 478, 516, 281, 1319, 264, 2232, 264, 935, 3711, 51052, 51052, 27290, 295, 341, 8062, 297, 538, 472, 293, 341, 8062, 297, 538, 472, 538, 264, 8141, 8062, 27290, 51364, 51364, 293, 309, 311, 516, 281, 312, 264, 912, 558, 341, 307, 257, 21539, 8141, 597, 8306, 341, 2146, 51592, 51592], "temperature": 0.0, "avg_logprob": -0.13156411935994913, "compression_ratio": 2.0106951871657754, "no_speech_prob": 1.2397696082189213e-05}, {"id": 347, "seek": 236196, "start": 2375.7200000000003, "end": 2381.96, "text": " multiplication of this vector n by one and this vector n by one by the matrix vector multiplication", "tokens": [50364, 2232, 294, 257, 21539, 1392, 370, 741, 486, 360, 21539, 295, 341, 8062, 370, 341, 486, 1884, 257, 8141, 295, 264, 50672, 50672, 2744, 297, 538, 297, 1392, 293, 741, 478, 3372, 341, 2146, 646, 510, 370, 741, 478, 516, 281, 1319, 264, 2232, 264, 935, 3711, 51052, 51052, 27290, 295, 341, 8062, 297, 538, 472, 293, 341, 8062, 297, 538, 472, 538, 264, 8141, 8062, 27290, 51364, 51364, 293, 309, 311, 516, 281, 312, 264, 912, 558, 341, 307, 257, 21539, 8141, 597, 8306, 341, 2146, 51592, 51592], "temperature": 0.0, "avg_logprob": -0.13156411935994913, "compression_ratio": 2.0106951871657754, "no_speech_prob": 1.2397696082189213e-05}, {"id": 348, "seek": 236196, "start": 2381.96, "end": 2386.52, "text": " and it's going to be the same right this is a diagonal matrix which contains this guy", "tokens": [50364, 2232, 294, 257, 21539, 1392, 370, 741, 486, 360, 21539, 295, 341, 8062, 370, 341, 486, 1884, 257, 8141, 295, 264, 50672, 50672, 2744, 297, 538, 297, 1392, 293, 741, 478, 3372, 341, 2146, 646, 510, 370, 741, 478, 516, 281, 1319, 264, 2232, 264, 935, 3711, 51052, 51052, 27290, 295, 341, 8062, 297, 538, 472, 293, 341, 8062, 297, 538, 472, 538, 264, 8141, 8062, 27290, 51364, 51364, 293, 309, 311, 516, 281, 312, 264, 912, 558, 341, 307, 257, 21539, 8141, 597, 8306, 341, 2146, 51592, 51592], "temperature": 0.0, "avg_logprob": -0.13156411935994913, "compression_ratio": 2.0106951871657754, "no_speech_prob": 1.2397696082189213e-05}, {"id": 349, "seek": 238652, "start": 2386.52, "end": 2392.6, "text": " this guy multiply multiply by this by this vector so this is exactly the same these two lines", "tokens": [50364, 341, 2146, 12972, 12972, 538, 341, 538, 341, 8062, 370, 341, 307, 2293, 264, 912, 613, 732, 3876, 50668, 50668, 457, 437, 741, 528, 281, 360, 300, 570, 741, 528, 281, 483, 3973, 295, 264, 34153, 1392, 370, 741, 500, 380, 362, 264, 50892, 50892, 34153, 3602, 293, 741, 362, 445, 291, 458, 8141, 8141, 27290, 1392, 370, 341, 307, 341, 307, 437, 51276, 51276, 741, 483, 1105, 550, 562, 741, 478, 516, 281, 360, 746, 307, 300, 321, 458, 300, 562, 291, 3079, 257, 2445, 51616, 51616], "temperature": 0.0, "avg_logprob": -0.09454143312242295, "compression_ratio": 1.9154228855721394, "no_speech_prob": 8.573780178267043e-06}, {"id": 350, "seek": 238652, "start": 2392.6, "end": 2397.08, "text": " but what i want to do that because i want to get rid of the parentheses okay so i don't have the", "tokens": [50364, 341, 2146, 12972, 12972, 538, 341, 538, 341, 8062, 370, 341, 307, 2293, 264, 912, 613, 732, 3876, 50668, 50668, 457, 437, 741, 528, 281, 360, 300, 570, 741, 528, 281, 483, 3973, 295, 264, 34153, 1392, 370, 741, 500, 380, 362, 264, 50892, 50892, 34153, 3602, 293, 741, 362, 445, 291, 458, 8141, 8141, 27290, 1392, 370, 341, 307, 341, 307, 437, 51276, 51276, 741, 483, 1105, 550, 562, 741, 478, 516, 281, 360, 746, 307, 300, 321, 458, 300, 562, 291, 3079, 257, 2445, 51616, 51616], "temperature": 0.0, "avg_logprob": -0.09454143312242295, "compression_ratio": 1.9154228855721394, "no_speech_prob": 8.573780178267043e-06}, {"id": 351, "seek": 238652, "start": 2397.08, "end": 2404.7599999999998, "text": " parentheses anymore and i have just you know matrix matrix multiplication okay so this is this is what", "tokens": [50364, 341, 2146, 12972, 12972, 538, 341, 538, 341, 8062, 370, 341, 307, 2293, 264, 912, 613, 732, 3876, 50668, 50668, 457, 437, 741, 528, 281, 360, 300, 570, 741, 528, 281, 483, 3973, 295, 264, 34153, 1392, 370, 741, 500, 380, 362, 264, 50892, 50892, 34153, 3602, 293, 741, 362, 445, 291, 458, 8141, 8141, 27290, 1392, 370, 341, 307, 341, 307, 437, 51276, 51276, 741, 483, 1105, 550, 562, 741, 478, 516, 281, 360, 746, 307, 300, 321, 458, 300, 562, 291, 3079, 257, 2445, 51616, 51616], "temperature": 0.0, "avg_logprob": -0.09454143312242295, "compression_ratio": 1.9154228855721394, "no_speech_prob": 8.573780178267043e-06}, {"id": 352, "seek": 238652, "start": 2404.7599999999998, "end": 2411.56, "text": " i get um then when i'm going to do something is that we know that when you apply a function", "tokens": [50364, 341, 2146, 12972, 12972, 538, 341, 538, 341, 8062, 370, 341, 307, 2293, 264, 912, 613, 732, 3876, 50668, 50668, 457, 437, 741, 528, 281, 360, 300, 570, 741, 528, 281, 483, 3973, 295, 264, 34153, 1392, 370, 741, 500, 380, 362, 264, 50892, 50892, 34153, 3602, 293, 741, 362, 445, 291, 458, 8141, 8141, 27290, 1392, 370, 341, 307, 341, 307, 437, 51276, 51276, 741, 483, 1105, 550, 562, 741, 478, 516, 281, 360, 746, 307, 300, 321, 458, 300, 562, 291, 3079, 257, 2445, 51616, 51616], "temperature": 0.0, "avg_logprob": -0.09454143312242295, "compression_ratio": 1.9154228855721394, "no_speech_prob": 8.573780178267043e-06}, {"id": 353, "seek": 241156, "start": 2411.56, "end": 2416.7599999999998, "text": " on the eigenvalues okay if you have some orthogonal basis then you can put it inside", "tokens": [50364, 322, 264, 10446, 46033, 1392, 498, 291, 362, 512, 41488, 5143, 550, 291, 393, 829, 309, 1854, 50624, 50624, 291, 393, 829, 309, 1854, 293, 341, 307, 437, 741, 360, 510, 741, 829, 2232, 13107, 293, 13107, 25167, 1854, 293, 341, 50908, 50908, 2146, 307, 13402, 264, 7123, 295, 264, 9721, 1392, 264, 9721, 2232, 562, 741, 360, 264, 10446, 48356, 51300, 51300, 307, 13107, 13607, 13107, 25167, 1392, 1105, 550, 370, 437, 741, 362, 307, 1936, 264, 42761, 2445, 51780, 51808], "temperature": 0.0, "avg_logprob": -0.07729469594501313, "compression_ratio": 1.9479166666666667, "no_speech_prob": 5.399951078288723e-06}, {"id": 354, "seek": 241156, "start": 2416.7599999999998, "end": 2422.44, "text": " you can put it inside and this is what i do here i put uh phi and phi transpose inside and this", "tokens": [50364, 322, 264, 10446, 46033, 1392, 498, 291, 362, 512, 41488, 5143, 550, 291, 393, 829, 309, 1854, 50624, 50624, 291, 393, 829, 309, 1854, 293, 341, 307, 437, 741, 360, 510, 741, 829, 2232, 13107, 293, 13107, 25167, 1854, 293, 341, 50908, 50908, 2146, 307, 13402, 264, 7123, 295, 264, 9721, 1392, 264, 9721, 2232, 562, 741, 360, 264, 10446, 48356, 51300, 51300, 307, 13107, 13607, 13107, 25167, 1392, 1105, 550, 370, 437, 741, 362, 307, 1936, 264, 42761, 2445, 51780, 51808], "temperature": 0.0, "avg_logprob": -0.07729469594501313, "compression_ratio": 1.9479166666666667, "no_speech_prob": 5.399951078288723e-06}, {"id": 355, "seek": 241156, "start": 2422.44, "end": 2430.2799999999997, "text": " guy is precisely the definition of the relation okay the relation uh when i do the eigen decomposition", "tokens": [50364, 322, 264, 10446, 46033, 1392, 498, 291, 362, 512, 41488, 5143, 550, 291, 393, 829, 309, 1854, 50624, 50624, 291, 393, 829, 309, 1854, 293, 341, 307, 437, 741, 360, 510, 741, 829, 2232, 13107, 293, 13107, 25167, 1854, 293, 341, 50908, 50908, 2146, 307, 13402, 264, 7123, 295, 264, 9721, 1392, 264, 9721, 2232, 562, 741, 360, 264, 10446, 48356, 51300, 51300, 307, 13107, 13607, 13107, 25167, 1392, 1105, 550, 370, 437, 741, 362, 307, 1936, 264, 42761, 2445, 51780, 51808], "temperature": 0.0, "avg_logprob": -0.07729469594501313, "compression_ratio": 1.9479166666666667, "no_speech_prob": 5.399951078288723e-06}, {"id": 356, "seek": 241156, "start": 2430.2799999999997, "end": 2439.88, "text": " is phi lambda phi transpose okay um then so what i have is basically the spectral function", "tokens": [50364, 322, 264, 10446, 46033, 1392, 498, 291, 362, 512, 41488, 5143, 550, 291, 393, 829, 309, 1854, 50624, 50624, 291, 393, 829, 309, 1854, 293, 341, 307, 437, 741, 360, 510, 741, 829, 2232, 13107, 293, 13107, 25167, 1854, 293, 341, 50908, 50908, 2146, 307, 13402, 264, 7123, 295, 264, 9721, 1392, 264, 9721, 2232, 562, 741, 360, 264, 10446, 48356, 51300, 51300, 307, 13107, 13607, 13107, 25167, 1392, 1105, 550, 370, 437, 741, 362, 307, 1936, 264, 42761, 2445, 51780, 51808], "temperature": 0.0, "avg_logprob": -0.07729469594501313, "compression_ratio": 1.9479166666666667, "no_speech_prob": 5.399951078288723e-06}, {"id": 357, "seek": 243988, "start": 2439.88, "end": 2448.52, "text": " that i applied to the laplacian uh operator and this is an n by n matrix and apply to the vector", "tokens": [50364, 300, 741, 6456, 281, 264, 635, 564, 326, 952, 2232, 12973, 293, 341, 307, 364, 297, 538, 297, 8141, 293, 3079, 281, 264, 8062, 50796, 50796, 297, 538, 472, 370, 412, 264, 917, 741, 486, 483, 297, 538, 472, 8062, 1392, 370, 291, 536, 300, 498, 291, 528, 281, 360, 370, 309, 311, 51176, 51176, 309, 311, 1021, 586, 370, 498, 291, 528, 281, 360, 257, 45216, 295, 732, 6828, 322, 4295, 261, 293, 276, 437, 291, 434, 51512, 51512, 516, 281, 360, 307, 300, 291, 434, 516, 281, 747, 264, 42761, 2445, 295, 261, 291, 486, 3079, 309, 281, 264, 51860, 51860], "temperature": 0.0, "avg_logprob": -0.15451859973725818, "compression_ratio": 1.9108910891089108, "no_speech_prob": 5.172971668798709e-06}, {"id": 358, "seek": 243988, "start": 2448.52, "end": 2456.12, "text": " n by one so at the end i will get n by one vector okay so you see that if you want to do so it's", "tokens": [50364, 300, 741, 6456, 281, 264, 635, 564, 326, 952, 2232, 12973, 293, 341, 307, 364, 297, 538, 297, 8141, 293, 3079, 281, 264, 8062, 50796, 50796, 297, 538, 472, 370, 412, 264, 917, 741, 486, 483, 297, 538, 472, 8062, 1392, 370, 291, 536, 300, 498, 291, 528, 281, 360, 370, 309, 311, 51176, 51176, 309, 311, 1021, 586, 370, 498, 291, 528, 281, 360, 257, 45216, 295, 732, 6828, 322, 4295, 261, 293, 276, 437, 291, 434, 51512, 51512, 516, 281, 360, 307, 300, 291, 434, 516, 281, 747, 264, 42761, 2445, 295, 261, 291, 486, 3079, 309, 281, 264, 51860, 51860], "temperature": 0.0, "avg_logprob": -0.15451859973725818, "compression_ratio": 1.9108910891089108, "no_speech_prob": 5.172971668798709e-06}, {"id": 359, "seek": 243988, "start": 2456.12, "end": 2462.84, "text": " it's important now so if you want to do a convolution of two functions on graph w and h what you're", "tokens": [50364, 300, 741, 6456, 281, 264, 635, 564, 326, 952, 2232, 12973, 293, 341, 307, 364, 297, 538, 297, 8141, 293, 3079, 281, 264, 8062, 50796, 50796, 297, 538, 472, 370, 412, 264, 917, 741, 486, 483, 297, 538, 472, 8062, 1392, 370, 291, 536, 300, 498, 291, 528, 281, 360, 370, 309, 311, 51176, 51176, 309, 311, 1021, 586, 370, 498, 291, 528, 281, 360, 257, 45216, 295, 732, 6828, 322, 4295, 261, 293, 276, 437, 291, 434, 51512, 51512, 516, 281, 360, 307, 300, 291, 434, 516, 281, 747, 264, 42761, 2445, 295, 261, 291, 486, 3079, 309, 281, 264, 51860, 51860], "temperature": 0.0, "avg_logprob": -0.15451859973725818, "compression_ratio": 1.9108910891089108, "no_speech_prob": 5.172971668798709e-06}, {"id": 360, "seek": 243988, "start": 2462.84, "end": 2469.8, "text": " going to do is that you're going to take the spectral function of w you will apply it to the", "tokens": [50364, 300, 741, 6456, 281, 264, 635, 564, 326, 952, 2232, 12973, 293, 341, 307, 364, 297, 538, 297, 8141, 293, 3079, 281, 264, 8062, 50796, 50796, 297, 538, 472, 370, 412, 264, 917, 741, 486, 483, 297, 538, 472, 8062, 1392, 370, 291, 536, 300, 498, 291, 528, 281, 360, 370, 309, 311, 51176, 51176, 309, 311, 1021, 586, 370, 498, 291, 528, 281, 360, 257, 45216, 295, 732, 6828, 322, 4295, 261, 293, 276, 437, 291, 434, 51512, 51512, 516, 281, 360, 307, 300, 291, 434, 516, 281, 747, 264, 42761, 2445, 295, 261, 291, 486, 3079, 309, 281, 264, 51860, 51860], "temperature": 0.0, "avg_logprob": -0.15451859973725818, "compression_ratio": 1.9108910891089108, "no_speech_prob": 5.172971668798709e-06}, {"id": 361, "seek": 246980, "start": 2469.8, "end": 2477.6400000000003, "text": " to the to the laplacian and then you multiply by h okay this is the definition of uh of spectral", "tokens": [50364, 281, 264, 281, 264, 635, 564, 326, 952, 293, 550, 291, 12972, 538, 276, 1392, 341, 307, 264, 7123, 295, 2232, 295, 42761, 50756, 50756, 45216, 1392, 293, 293, 264, 551, 307, 341, 307, 588, 5124, 2232, 294, 3124, 281, 360, 309, 983, 309, 307, 51100, 51100, 5124, 309, 311, 570, 264, 8141, 13107, 307, 257, 1577, 8141, 1392, 309, 8306, 2232, 264, 297, 2232, 264, 297, 1105, 51596, 51596], "temperature": 0.0, "avg_logprob": -0.10029202037387425, "compression_ratio": 1.7212121212121212, "no_speech_prob": 3.1377032883028733e-06}, {"id": 362, "seek": 246980, "start": 2477.6400000000003, "end": 2484.52, "text": " convolution okay and and the thing is this is very expensive uh in practice to do it why it is", "tokens": [50364, 281, 264, 281, 264, 635, 564, 326, 952, 293, 550, 291, 12972, 538, 276, 1392, 341, 307, 264, 7123, 295, 2232, 295, 42761, 50756, 50756, 45216, 1392, 293, 293, 264, 551, 307, 341, 307, 588, 5124, 2232, 294, 3124, 281, 360, 309, 983, 309, 307, 51100, 51100, 5124, 309, 311, 570, 264, 8141, 13107, 307, 257, 1577, 8141, 1392, 309, 8306, 2232, 264, 297, 2232, 264, 297, 1105, 51596, 51596], "temperature": 0.0, "avg_logprob": -0.10029202037387425, "compression_ratio": 1.7212121212121212, "no_speech_prob": 3.1377032883028733e-06}, {"id": 363, "seek": 246980, "start": 2484.52, "end": 2494.44, "text": " expensive it's because the matrix phi is a full matrix okay it contains uh the n uh the n um", "tokens": [50364, 281, 264, 281, 264, 635, 564, 326, 952, 293, 550, 291, 12972, 538, 276, 1392, 341, 307, 264, 7123, 295, 2232, 295, 42761, 50756, 50756, 45216, 1392, 293, 293, 264, 551, 307, 341, 307, 588, 5124, 2232, 294, 3124, 281, 360, 309, 983, 309, 307, 51100, 51100, 5124, 309, 311, 570, 264, 8141, 13107, 307, 257, 1577, 8141, 1392, 309, 8306, 2232, 264, 297, 2232, 264, 297, 1105, 51596, 51596], "temperature": 0.0, "avg_logprob": -0.10029202037387425, "compression_ratio": 1.7212121212121212, "no_speech_prob": 3.1377032883028733e-06}, {"id": 364, "seek": 249444, "start": 2494.44, "end": 2499.56, "text": " Fourier functions and they are not zero okay so it's a dense matrix and you are going to pay the", "tokens": [50364, 36810, 6828, 293, 436, 366, 406, 4018, 1392, 370, 309, 311, 257, 18011, 8141, 293, 291, 366, 516, 281, 1689, 264, 50620, 50620, 3218, 295, 297, 3732, 293, 291, 500, 380, 362, 604, 479, 25469, 570, 264, 551, 291, 500, 380, 362, 604, 479, 25469, 337, 2232, 50884, 50884, 337, 2674, 4295, 1392, 370, 341, 307, 257, 341, 307, 257, 688, 293, 983, 309, 307, 257, 688, 570, 297, 1604, 293, 341, 51212, 51212, 307, 264, 1230, 295, 13891, 294, 428, 9274, 370, 498, 291, 362, 1105, 498, 291, 362, 257, 955, 4295, 337, 1365, 498, 291, 51564, 51564], "temperature": 0.0, "avg_logprob": -0.08117976047024869, "compression_ratio": 1.838095238095238, "no_speech_prob": 1.947391137946397e-05}, {"id": 365, "seek": 249444, "start": 2499.56, "end": 2504.84, "text": " price of n square and you don't have any FFT because the thing you don't have any FFT for uh", "tokens": [50364, 36810, 6828, 293, 436, 366, 406, 4018, 1392, 370, 309, 311, 257, 18011, 8141, 293, 291, 366, 516, 281, 1689, 264, 50620, 50620, 3218, 295, 297, 3732, 293, 291, 500, 380, 362, 604, 479, 25469, 570, 264, 551, 291, 500, 380, 362, 604, 479, 25469, 337, 2232, 50884, 50884, 337, 2674, 4295, 1392, 370, 341, 307, 257, 341, 307, 257, 688, 293, 983, 309, 307, 257, 688, 570, 297, 1604, 293, 341, 51212, 51212, 307, 264, 1230, 295, 13891, 294, 428, 9274, 370, 498, 291, 362, 1105, 498, 291, 362, 257, 955, 4295, 337, 1365, 498, 291, 51564, 51564], "temperature": 0.0, "avg_logprob": -0.08117976047024869, "compression_ratio": 1.838095238095238, "no_speech_prob": 1.947391137946397e-05}, {"id": 366, "seek": 249444, "start": 2504.84, "end": 2511.4, "text": " for general graph okay so this is a this is a lot and why it is a lot because n remember and this", "tokens": [50364, 36810, 6828, 293, 436, 366, 406, 4018, 1392, 370, 309, 311, 257, 18011, 8141, 293, 291, 366, 516, 281, 1689, 264, 50620, 50620, 3218, 295, 297, 3732, 293, 291, 500, 380, 362, 604, 479, 25469, 570, 264, 551, 291, 500, 380, 362, 604, 479, 25469, 337, 2232, 50884, 50884, 337, 2674, 4295, 1392, 370, 341, 307, 257, 341, 307, 257, 688, 293, 983, 309, 307, 257, 688, 570, 297, 1604, 293, 341, 51212, 51212, 307, 264, 1230, 295, 13891, 294, 428, 9274, 370, 498, 291, 362, 1105, 498, 291, 362, 257, 955, 4295, 337, 1365, 498, 291, 51564, 51564], "temperature": 0.0, "avg_logprob": -0.08117976047024869, "compression_ratio": 1.838095238095238, "no_speech_prob": 1.947391137946397e-05}, {"id": 367, "seek": 249444, "start": 2511.4, "end": 2518.44, "text": " is the number of nodes in your domain so if you have um if you have a big graph for example if you", "tokens": [50364, 36810, 6828, 293, 436, 366, 406, 4018, 1392, 370, 309, 311, 257, 18011, 8141, 293, 291, 366, 516, 281, 1689, 264, 50620, 50620, 3218, 295, 297, 3732, 293, 291, 500, 380, 362, 604, 479, 25469, 570, 264, 551, 291, 500, 380, 362, 604, 479, 25469, 337, 2232, 50884, 50884, 337, 2674, 4295, 1392, 370, 341, 307, 257, 341, 307, 257, 688, 293, 983, 309, 307, 257, 688, 570, 297, 1604, 293, 341, 51212, 51212, 307, 264, 1230, 295, 13891, 294, 428, 9274, 370, 498, 291, 362, 1105, 498, 291, 362, 257, 955, 4295, 337, 1365, 498, 291, 51564, 51564], "temperature": 0.0, "avg_logprob": -0.08117976047024869, "compression_ratio": 1.838095238095238, "no_speech_prob": 1.947391137946397e-05}, {"id": 368, "seek": 251844, "start": 2518.44, "end": 2525.48, "text": " have uh the web the web has you know billions of nodes n is equal to the billions so you need to", "tokens": [50364, 362, 2232, 264, 3670, 264, 3670, 575, 291, 458, 17375, 295, 13891, 297, 307, 2681, 281, 264, 17375, 370, 291, 643, 281, 50716, 50716, 360, 5218, 3732, 597, 307, 516, 281, 312, 257, 2603, 24903, 281, 360, 370, 291, 291, 2644, 534, 360, 309, 50972, 51076, 393, 741, 20858, 370, 276, 307, 516, 281, 312, 257, 2445, 7642, 670, 633, 28162, 294, 428, 4295, 558, 51384, 51428, 293, 261, 2602, 307, 516, 281, 312, 411, 257, 28256, 382, 731, 420, 307, 415, 457, 294, 341, 1389, 261, 307, 516, 281, 312, 257, 51756, 51756], "temperature": 0.0, "avg_logprob": -0.11763644218444824, "compression_ratio": 1.8719211822660098, "no_speech_prob": 2.4437169940938475e-06}, {"id": 369, "seek": 251844, "start": 2525.48, "end": 2530.6, "text": " do billion square which is going to be a huge computation to do so you you cannot really do it", "tokens": [50364, 362, 2232, 264, 3670, 264, 3670, 575, 291, 458, 17375, 295, 13891, 297, 307, 2681, 281, 264, 17375, 370, 291, 643, 281, 50716, 50716, 360, 5218, 3732, 597, 307, 516, 281, 312, 257, 2603, 24903, 281, 360, 370, 291, 291, 2644, 534, 360, 309, 50972, 51076, 393, 741, 20858, 370, 276, 307, 516, 281, 312, 257, 2445, 7642, 670, 633, 28162, 294, 428, 4295, 558, 51384, 51428, 293, 261, 2602, 307, 516, 281, 312, 411, 257, 28256, 382, 731, 420, 307, 415, 457, 294, 341, 1389, 261, 307, 516, 281, 312, 257, 51756, 51756], "temperature": 0.0, "avg_logprob": -0.11763644218444824, "compression_ratio": 1.8719211822660098, "no_speech_prob": 2.4437169940938475e-06}, {"id": 370, "seek": 251844, "start": 2532.68, "end": 2538.84, "text": " can i summarize so h is going to be a function defined over every vertex in your graph right", "tokens": [50364, 362, 2232, 264, 3670, 264, 3670, 575, 291, 458, 17375, 295, 13891, 297, 307, 2681, 281, 264, 17375, 370, 291, 643, 281, 50716, 50716, 360, 5218, 3732, 597, 307, 516, 281, 312, 257, 2603, 24903, 281, 360, 370, 291, 291, 2644, 534, 360, 309, 50972, 51076, 393, 741, 20858, 370, 276, 307, 516, 281, 312, 257, 2445, 7642, 670, 633, 28162, 294, 428, 4295, 558, 51384, 51428, 293, 261, 2602, 307, 516, 281, 312, 411, 257, 28256, 382, 731, 420, 307, 415, 457, 294, 341, 1389, 261, 307, 516, 281, 312, 257, 51756, 51756], "temperature": 0.0, "avg_logprob": -0.11763644218444824, "compression_ratio": 1.8719211822660098, "no_speech_prob": 2.4437169940938475e-06}, {"id": 371, "seek": 251844, "start": 2539.7200000000003, "end": 2546.28, "text": " and w instead is going to be like a kernel as well or is he but in this case w is going to be a", "tokens": [50364, 362, 2232, 264, 3670, 264, 3670, 575, 291, 458, 17375, 295, 13891, 297, 307, 2681, 281, 264, 17375, 370, 291, 643, 281, 50716, 50716, 360, 5218, 3732, 597, 307, 516, 281, 312, 257, 2603, 24903, 281, 360, 370, 291, 291, 2644, 534, 360, 309, 50972, 51076, 393, 741, 20858, 370, 276, 307, 516, 281, 312, 257, 2445, 7642, 670, 633, 28162, 294, 428, 4295, 558, 51384, 51428, 293, 261, 2602, 307, 516, 281, 312, 411, 257, 28256, 382, 731, 420, 307, 415, 457, 294, 341, 1389, 261, 307, 516, 281, 312, 257, 51756, 51756], "temperature": 0.0, "avg_logprob": -0.11763644218444824, "compression_ratio": 1.8719211822660098, "no_speech_prob": 2.4437169940938475e-06}, {"id": 372, "seek": 254628, "start": 2546.28, "end": 2554.2000000000003, "text": " function like this so w is a spectral function w hat is a spectral function so you are walking", "tokens": [50364, 2445, 411, 341, 370, 261, 307, 257, 42761, 2445, 261, 2385, 307, 257, 42761, 2445, 370, 291, 366, 4494, 50760, 50760, 294, 264, 7893, 1901, 294, 264, 7893, 1901, 291, 366, 1364, 365, 341, 437, 341, 307, 341, 307, 50992, 50992, 257, 42761, 2445, 370, 337, 1365, 498, 291, 498, 291, 458, 3256, 9007, 257, 707, 857, 51256, 51256, 370, 337, 1365, 498, 291, 528, 281, 360, 3256, 1441, 78, 3436, 498, 291, 528, 281, 360, 3256, 1441, 78, 3436, 51484, 51512, 437, 291, 437, 291, 458, 307, 300, 291, 458, 300, 264, 5658, 307, 2673, 294, 264, 1090, 7893, 51772, 51772], "temperature": 1.0, "avg_logprob": -0.1300020951491136, "compression_ratio": 2.4153005464480874, "no_speech_prob": 1.591168256709352e-05}, {"id": 373, "seek": 254628, "start": 2554.2000000000003, "end": 2558.84, "text": " in the frequency space in the frequency space you are working with this what this is this is", "tokens": [50364, 2445, 411, 341, 370, 261, 307, 257, 42761, 2445, 261, 2385, 307, 257, 42761, 2445, 370, 291, 366, 4494, 50760, 50760, 294, 264, 7893, 1901, 294, 264, 7893, 1901, 291, 366, 1364, 365, 341, 437, 341, 307, 341, 307, 50992, 50992, 257, 42761, 2445, 370, 337, 1365, 498, 291, 498, 291, 458, 3256, 9007, 257, 707, 857, 51256, 51256, 370, 337, 1365, 498, 291, 528, 281, 360, 3256, 1441, 78, 3436, 498, 291, 528, 281, 360, 3256, 1441, 78, 3436, 51484, 51512, 437, 291, 437, 291, 458, 307, 300, 291, 458, 300, 264, 5658, 307, 2673, 294, 264, 1090, 7893, 51772, 51772], "temperature": 1.0, "avg_logprob": -0.1300020951491136, "compression_ratio": 2.4153005464480874, "no_speech_prob": 1.591168256709352e-05}, {"id": 374, "seek": 254628, "start": 2558.84, "end": 2564.1200000000003, "text": " a spectral function so for example if you if you know image processing a little bit", "tokens": [50364, 2445, 411, 341, 370, 261, 307, 257, 42761, 2445, 261, 2385, 307, 257, 42761, 2445, 370, 291, 366, 4494, 50760, 50760, 294, 264, 7893, 1901, 294, 264, 7893, 1901, 291, 366, 1364, 365, 341, 437, 341, 307, 341, 307, 50992, 50992, 257, 42761, 2445, 370, 337, 1365, 498, 291, 498, 291, 458, 3256, 9007, 257, 707, 857, 51256, 51256, 370, 337, 1365, 498, 291, 528, 281, 360, 3256, 1441, 78, 3436, 498, 291, 528, 281, 360, 3256, 1441, 78, 3436, 51484, 51512, 437, 291, 437, 291, 458, 307, 300, 291, 458, 300, 264, 5658, 307, 2673, 294, 264, 1090, 7893, 51772, 51772], "temperature": 1.0, "avg_logprob": -0.1300020951491136, "compression_ratio": 2.4153005464480874, "no_speech_prob": 1.591168256709352e-05}, {"id": 375, "seek": 254628, "start": 2564.1200000000003, "end": 2568.6800000000003, "text": " so for example if you want to do image denoising if you want to do image denoising", "tokens": [50364, 2445, 411, 341, 370, 261, 307, 257, 42761, 2445, 261, 2385, 307, 257, 42761, 2445, 370, 291, 366, 4494, 50760, 50760, 294, 264, 7893, 1901, 294, 264, 7893, 1901, 291, 366, 1364, 365, 341, 437, 341, 307, 341, 307, 50992, 50992, 257, 42761, 2445, 370, 337, 1365, 498, 291, 498, 291, 458, 3256, 9007, 257, 707, 857, 51256, 51256, 370, 337, 1365, 498, 291, 528, 281, 360, 3256, 1441, 78, 3436, 498, 291, 528, 281, 360, 3256, 1441, 78, 3436, 51484, 51512, 437, 291, 437, 291, 458, 307, 300, 291, 458, 300, 264, 5658, 307, 2673, 294, 264, 1090, 7893, 51772, 51772], "temperature": 1.0, "avg_logprob": -0.1300020951491136, "compression_ratio": 2.4153005464480874, "no_speech_prob": 1.591168256709352e-05}, {"id": 376, "seek": 254628, "start": 2569.2400000000002, "end": 2574.44, "text": " what you what you know is that you know that the noise is usually in the high frequency", "tokens": [50364, 2445, 411, 341, 370, 261, 307, 257, 42761, 2445, 261, 2385, 307, 257, 42761, 2445, 370, 291, 366, 4494, 50760, 50760, 294, 264, 7893, 1901, 294, 264, 7893, 1901, 291, 366, 1364, 365, 341, 437, 341, 307, 341, 307, 50992, 50992, 257, 42761, 2445, 370, 337, 1365, 498, 291, 498, 291, 458, 3256, 9007, 257, 707, 857, 51256, 51256, 370, 337, 1365, 498, 291, 528, 281, 360, 3256, 1441, 78, 3436, 498, 291, 528, 281, 360, 3256, 1441, 78, 3436, 51484, 51512, 437, 291, 437, 291, 458, 307, 300, 291, 458, 300, 264, 5658, 307, 2673, 294, 264, 1090, 7893, 51772, 51772], "temperature": 1.0, "avg_logprob": -0.1300020951491136, "compression_ratio": 2.4153005464480874, "no_speech_prob": 1.591168256709352e-05}, {"id": 377, "seek": 257444, "start": 2574.44, "end": 2580.36, "text": " part of your image of your signal. So what you can do is that you can design a spectral filter", "tokens": [50364, 644, 295, 428, 3256, 295, 428, 6358, 13, 407, 437, 291, 393, 360, 307, 300, 291, 393, 1715, 257, 42761, 6608, 50660, 50660, 597, 307, 516, 281, 312, 4018, 337, 264, 1090, 7893, 293, 291, 366, 516, 281, 15665, 264, 2295, 7893, 50948, 50948, 281, 15665, 428, 18426, 13, 407, 341, 307, 445, 884, 30822, 295, 264, 20250, 51272, 51316, 16212, 294, 428, 6358, 13, 1033, 11, 457, 264, 343, 1553, 264, 2385, 576, 312, 920, 257, 1359, 2146, 11, 558, 30, 6068, 51596, 51596], "temperature": 0.0, "avg_logprob": -0.15678062658200317, "compression_ratio": 1.7440758293838863, "no_speech_prob": 0.20750416815280914}, {"id": 378, "seek": 257444, "start": 2580.36, "end": 2586.12, "text": " which is going to be zero for the high frequency and you are going to preserve the low frequency", "tokens": [50364, 644, 295, 428, 3256, 295, 428, 6358, 13, 407, 437, 291, 393, 360, 307, 300, 291, 393, 1715, 257, 42761, 6608, 50660, 50660, 597, 307, 516, 281, 312, 4018, 337, 264, 1090, 7893, 293, 291, 366, 516, 281, 15665, 264, 2295, 7893, 50948, 50948, 281, 15665, 428, 18426, 13, 407, 341, 307, 445, 884, 30822, 295, 264, 20250, 51272, 51316, 16212, 294, 428, 6358, 13, 1033, 11, 457, 264, 343, 1553, 264, 2385, 576, 312, 920, 257, 1359, 2146, 11, 558, 30, 6068, 51596, 51596], "temperature": 0.0, "avg_logprob": -0.15678062658200317, "compression_ratio": 1.7440758293838863, "no_speech_prob": 0.20750416815280914}, {"id": 379, "seek": 257444, "start": 2586.12, "end": 2592.6, "text": " to preserve your geometry. So this is just doing filtering of the frequencies", "tokens": [50364, 644, 295, 428, 3256, 295, 428, 6358, 13, 407, 437, 291, 393, 360, 307, 300, 291, 393, 1715, 257, 42761, 6608, 50660, 50660, 597, 307, 516, 281, 312, 4018, 337, 264, 1090, 7893, 293, 291, 366, 516, 281, 15665, 264, 2295, 7893, 50948, 50948, 281, 15665, 428, 18426, 13, 407, 341, 307, 445, 884, 30822, 295, 264, 20250, 51272, 51316, 16212, 294, 428, 6358, 13, 1033, 11, 457, 264, 343, 1553, 264, 2385, 576, 312, 920, 257, 1359, 2146, 11, 558, 30, 6068, 51596, 51596], "temperature": 0.0, "avg_logprob": -0.15678062658200317, "compression_ratio": 1.7440758293838863, "no_speech_prob": 0.20750416815280914}, {"id": 380, "seek": 257444, "start": 2593.48, "end": 2599.08, "text": " contained in your signal. Okay, but the W without the hat would be still a small guy, right? Would", "tokens": [50364, 644, 295, 428, 3256, 295, 428, 6358, 13, 407, 437, 291, 393, 360, 307, 300, 291, 393, 1715, 257, 42761, 6608, 50660, 50660, 597, 307, 516, 281, 312, 4018, 337, 264, 1090, 7893, 293, 291, 366, 516, 281, 15665, 264, 2295, 7893, 50948, 50948, 281, 15665, 428, 18426, 13, 407, 341, 307, 445, 884, 30822, 295, 264, 20250, 51272, 51316, 16212, 294, 428, 6358, 13, 1033, 11, 457, 264, 343, 1553, 264, 2385, 576, 312, 920, 257, 1359, 2146, 11, 558, 30, 6068, 51596, 51596], "temperature": 0.0, "avg_logprob": -0.15678062658200317, "compression_ratio": 1.7440758293838863, "no_speech_prob": 0.20750416815280914}, {"id": 381, "seek": 259908, "start": 2599.08, "end": 2606.12, "text": " be a small filter. So W without hat is the spatial filter. Yeah, the small one, right? Which is", "tokens": [50364, 312, 257, 1359, 6608, 13, 407, 343, 1553, 2385, 307, 264, 23598, 6608, 13, 865, 11, 264, 1359, 472, 11, 558, 30, 3013, 307, 50716, 50716, 2293, 370, 13, 7587, 13, 407, 498, 291, 362, 264, 10748, 11, 343, 486, 312, 257, 4230, 538, 4230, 9972, 11, 337, 1365, 13, 51200, 51324, 286, 536, 13, 1033, 13, 1033, 13, 2561, 13, 865, 11, 988, 13, 407, 294, 264, 4319, 295, 4295, 11, 370, 309, 311, 257, 1359, 4707, 51808], "temperature": 0.0, "avg_logprob": -0.2536338523582176, "compression_ratio": 1.5274725274725274, "no_speech_prob": 2.7869167752214707e-05}, {"id": 382, "seek": 259908, "start": 2606.12, "end": 2615.7999999999997, "text": " exactly so. Exactly. So if you have the grid, W will be a tree by tree patch, for example.", "tokens": [50364, 312, 257, 1359, 6608, 13, 407, 343, 1553, 2385, 307, 264, 23598, 6608, 13, 865, 11, 264, 1359, 472, 11, 558, 30, 3013, 307, 50716, 50716, 2293, 370, 13, 7587, 13, 407, 498, 291, 362, 264, 10748, 11, 343, 486, 312, 257, 4230, 538, 4230, 9972, 11, 337, 1365, 13, 51200, 51324, 286, 536, 13, 1033, 13, 1033, 13, 2561, 13, 865, 11, 988, 13, 407, 294, 264, 4319, 295, 4295, 11, 370, 309, 311, 257, 1359, 4707, 51808], "temperature": 0.0, "avg_logprob": -0.2536338523582176, "compression_ratio": 1.5274725274725274, "no_speech_prob": 2.7869167752214707e-05}, {"id": 383, "seek": 261580, "start": 2615.8, "end": 2627.96, "text": " I see. Okay. Okay. Thanks. Yeah, sure. So in the context of graph, it's a small property", "tokens": [50364, 286, 536, 13, 1033, 13, 1033, 13, 2561, 13, 865, 11, 988, 13, 407, 294, 264, 4319, 295, 4295, 11, 309, 311, 257, 1359, 4707, 50972, 51048, 281, 458, 307, 300, 291, 500, 380, 362, 604, 17573, 21977, 13, 407, 498, 291, 362, 257, 10748, 293, 498, 291, 366, 51308, 51308, 1228, 264, 45216, 304, 20904, 281, 1286, 926, 428, 2445, 11, 337, 1365, 11, 264, 2445, 307, 257, 51640, 51640], "temperature": 0.0, "avg_logprob": -0.17662977192499865, "compression_ratio": 1.5454545454545454, "no_speech_prob": 4.799592716153711e-05}, {"id": 384, "seek": 261580, "start": 2629.48, "end": 2634.6800000000003, "text": " to know is that you don't have any shifting variance. So if you have a grid and if you are", "tokens": [50364, 286, 536, 13, 1033, 13, 1033, 13, 2561, 13, 865, 11, 988, 13, 407, 294, 264, 4319, 295, 4295, 11, 309, 311, 257, 1359, 4707, 50972, 51048, 281, 458, 307, 300, 291, 500, 380, 362, 604, 17573, 21977, 13, 407, 498, 291, 362, 257, 10748, 293, 498, 291, 366, 51308, 51308, 1228, 264, 45216, 304, 20904, 281, 1286, 926, 428, 2445, 11, 337, 1365, 11, 264, 2445, 307, 257, 51640, 51640], "temperature": 0.0, "avg_logprob": -0.17662977192499865, "compression_ratio": 1.5454545454545454, "no_speech_prob": 4.799592716153711e-05}, {"id": 385, "seek": 261580, "start": 2634.6800000000003, "end": 2641.32, "text": " using the convolutional theorem to move around your function, for example, the function is a", "tokens": [50364, 286, 536, 13, 1033, 13, 1033, 13, 2561, 13, 865, 11, 988, 13, 407, 294, 264, 4319, 295, 4295, 11, 309, 311, 257, 1359, 4707, 50972, 51048, 281, 458, 307, 300, 291, 500, 380, 362, 604, 17573, 21977, 13, 407, 498, 291, 362, 257, 10748, 293, 498, 291, 366, 51308, 51308, 1228, 264, 45216, 304, 20904, 281, 1286, 926, 428, 2445, 11, 337, 1365, 11, 264, 2445, 307, 257, 51640, 51640], "temperature": 0.0, "avg_logprob": -0.17662977192499865, "compression_ratio": 1.5454545454545454, "no_speech_prob": 4.799592716153711e-05}, {"id": 386, "seek": 264132, "start": 2641.32, "end": 2646.92, "text": " Gaussian here. On the grid, you are not going to change the shape of your function. But on a graph,", "tokens": [50364, 39148, 510, 13, 1282, 264, 10748, 11, 291, 366, 406, 516, 281, 1319, 264, 3909, 295, 428, 2445, 13, 583, 322, 257, 4295, 11, 50644, 50644, 570, 291, 362, 257, 3890, 3877, 11, 498, 291, 1286, 926, 428, 39148, 11, 550, 291, 486, 362, 50956, 50956, 819, 10854, 13, 1033, 13, 407, 341, 307, 746, 300, 291, 3624, 562, 291, 352, 281, 24877, 13, 583, 294, 3124, 11, 51272, 51272, 767, 11, 309, 575, 3122, 572, 1802, 13, 407, 309, 311, 406, 534, 1021, 13, 467, 311, 445, 257, 18894, 51508, 51508, 4707, 300, 291, 3624, 562, 291, 352, 281, 24877, 13, 1033, 13, 821, 307, 1071, 1168, 13, 821, 307, 1071, 51840, 51840], "temperature": 0.0, "avg_logprob": -0.12222795650876801, "compression_ratio": 1.7740740740740741, "no_speech_prob": 5.140604844200425e-05}, {"id": 387, "seek": 264132, "start": 2646.92, "end": 2653.1600000000003, "text": " because you have a regular structure, if you move around your Gaussian, then you will have", "tokens": [50364, 39148, 510, 13, 1282, 264, 10748, 11, 291, 366, 406, 516, 281, 1319, 264, 3909, 295, 428, 2445, 13, 583, 322, 257, 4295, 11, 50644, 50644, 570, 291, 362, 257, 3890, 3877, 11, 498, 291, 1286, 926, 428, 39148, 11, 550, 291, 486, 362, 50956, 50956, 819, 10854, 13, 1033, 13, 407, 341, 307, 746, 300, 291, 3624, 562, 291, 352, 281, 24877, 13, 583, 294, 3124, 11, 51272, 51272, 767, 11, 309, 575, 3122, 572, 1802, 13, 407, 309, 311, 406, 534, 1021, 13, 467, 311, 445, 257, 18894, 51508, 51508, 4707, 300, 291, 3624, 562, 291, 352, 281, 24877, 13, 1033, 13, 821, 307, 1071, 1168, 13, 821, 307, 1071, 51840, 51840], "temperature": 0.0, "avg_logprob": -0.12222795650876801, "compression_ratio": 1.7740740740740741, "no_speech_prob": 5.140604844200425e-05}, {"id": 388, "seek": 264132, "start": 2653.1600000000003, "end": 2659.48, "text": " different shapes. Okay. So this is something that you lose when you go to graphs. But in practice,", "tokens": [50364, 39148, 510, 13, 1282, 264, 10748, 11, 291, 366, 406, 516, 281, 1319, 264, 3909, 295, 428, 2445, 13, 583, 322, 257, 4295, 11, 50644, 50644, 570, 291, 362, 257, 3890, 3877, 11, 498, 291, 1286, 926, 428, 39148, 11, 550, 291, 486, 362, 50956, 50956, 819, 10854, 13, 1033, 13, 407, 341, 307, 746, 300, 291, 3624, 562, 291, 352, 281, 24877, 13, 583, 294, 3124, 11, 51272, 51272, 767, 11, 309, 575, 3122, 572, 1802, 13, 407, 309, 311, 406, 534, 1021, 13, 467, 311, 445, 257, 18894, 51508, 51508, 4707, 300, 291, 3624, 562, 291, 352, 281, 24877, 13, 1033, 13, 821, 307, 1071, 1168, 13, 821, 307, 1071, 51840, 51840], "temperature": 0.0, "avg_logprob": -0.12222795650876801, "compression_ratio": 1.7740740740740741, "no_speech_prob": 5.140604844200425e-05}, {"id": 389, "seek": 264132, "start": 2659.48, "end": 2664.2000000000003, "text": " actually, it has absolutely no effect. So it's not really important. It's just a mathematical", "tokens": [50364, 39148, 510, 13, 1282, 264, 10748, 11, 291, 366, 406, 516, 281, 1319, 264, 3909, 295, 428, 2445, 13, 583, 322, 257, 4295, 11, 50644, 50644, 570, 291, 362, 257, 3890, 3877, 11, 498, 291, 1286, 926, 428, 39148, 11, 550, 291, 486, 362, 50956, 50956, 819, 10854, 13, 1033, 13, 407, 341, 307, 746, 300, 291, 3624, 562, 291, 352, 281, 24877, 13, 583, 294, 3124, 11, 51272, 51272, 767, 11, 309, 575, 3122, 572, 1802, 13, 407, 309, 311, 406, 534, 1021, 13, 467, 311, 445, 257, 18894, 51508, 51508, 4707, 300, 291, 3624, 562, 291, 352, 281, 24877, 13, 1033, 13, 821, 307, 1071, 1168, 13, 821, 307, 1071, 51840, 51840], "temperature": 0.0, "avg_logprob": -0.12222795650876801, "compression_ratio": 1.7740740740740741, "no_speech_prob": 5.140604844200425e-05}, {"id": 390, "seek": 264132, "start": 2664.2000000000003, "end": 2670.84, "text": " property that you lose when you go to graphs. Okay. There is another question. There is another", "tokens": [50364, 39148, 510, 13, 1282, 264, 10748, 11, 291, 366, 406, 516, 281, 1319, 264, 3909, 295, 428, 2445, 13, 583, 322, 257, 4295, 11, 50644, 50644, 570, 291, 362, 257, 3890, 3877, 11, 498, 291, 1286, 926, 428, 39148, 11, 550, 291, 486, 362, 50956, 50956, 819, 10854, 13, 1033, 13, 407, 341, 307, 746, 300, 291, 3624, 562, 291, 352, 281, 24877, 13, 583, 294, 3124, 11, 51272, 51272, 767, 11, 309, 575, 3122, 572, 1802, 13, 407, 309, 311, 406, 534, 1021, 13, 467, 311, 445, 257, 18894, 51508, 51508, 4707, 300, 291, 3624, 562, 291, 352, 281, 24877, 13, 1033, 13, 821, 307, 1071, 1168, 13, 821, 307, 1071, 51840, 51840], "temperature": 0.0, "avg_logprob": -0.12222795650876801, "compression_ratio": 1.7740740740740741, "no_speech_prob": 5.140604844200425e-05}, {"id": 391, "seek": 267084, "start": 2670.84, "end": 2676.84, "text": " question I got here. So can you remind us what is actually the overall goal here? What is the goal", "tokens": [50364, 1168, 286, 658, 510, 13, 407, 393, 291, 4160, 505, 437, 307, 767, 264, 4787, 3387, 510, 30, 708, 307, 264, 3387, 50664, 50664, 295, 17827, 613, 3754, 15892, 420, 264, 42761, 38135, 670, 613, 24877, 30, 286, 519, 1310, 50964, 50964, 309, 311, 406, 485, 865, 11, 498, 321, 393, 4160, 1518, 11, 309, 311, 516, 281, 312, 485, 865, 13, 407, 437, 286, 478, 1382, 485, 440, 3387, 51260, 51260, 295, 264, 7991, 307, 281, 6964, 4295, 45216, 304, 36170, 13, 1033, 13, 407, 286, 643, 281, 38818, 533, 45216, 51792, 51792], "temperature": 0.0, "avg_logprob": -0.12248322367668152, "compression_ratio": 1.7212389380530972, "no_speech_prob": 4.262751463102177e-05}, {"id": 392, "seek": 267084, "start": 2676.84, "end": 2682.84, "text": " of defining these convolutions or the spectral correspondence over these graphs? I think maybe", "tokens": [50364, 1168, 286, 658, 510, 13, 407, 393, 291, 4160, 505, 437, 307, 767, 264, 4787, 3387, 510, 30, 708, 307, 264, 3387, 50664, 50664, 295, 17827, 613, 3754, 15892, 420, 264, 42761, 38135, 670, 613, 24877, 30, 286, 519, 1310, 50964, 50964, 309, 311, 406, 485, 865, 11, 498, 321, 393, 4160, 1518, 11, 309, 311, 516, 281, 312, 485, 865, 13, 407, 437, 286, 478, 1382, 485, 440, 3387, 51260, 51260, 295, 264, 7991, 307, 281, 6964, 4295, 45216, 304, 36170, 13, 1033, 13, 407, 286, 643, 281, 38818, 533, 45216, 51792, 51792], "temperature": 0.0, "avg_logprob": -0.12248322367668152, "compression_ratio": 1.7212389380530972, "no_speech_prob": 4.262751463102177e-05}, {"id": 393, "seek": 267084, "start": 2682.84, "end": 2688.76, "text": " it's not... Yeah, if we can remind everyone, it's going to be... Yeah. So what I'm trying... The goal", "tokens": [50364, 1168, 286, 658, 510, 13, 407, 393, 291, 4160, 505, 437, 307, 767, 264, 4787, 3387, 510, 30, 708, 307, 264, 3387, 50664, 50664, 295, 17827, 613, 3754, 15892, 420, 264, 42761, 38135, 670, 613, 24877, 30, 286, 519, 1310, 50964, 50964, 309, 311, 406, 485, 865, 11, 498, 321, 393, 4160, 1518, 11, 309, 311, 516, 281, 312, 485, 865, 13, 407, 437, 286, 478, 1382, 485, 440, 3387, 51260, 51260, 295, 264, 7991, 307, 281, 6964, 4295, 45216, 304, 36170, 13, 1033, 13, 407, 286, 643, 281, 38818, 533, 45216, 51792, 51792], "temperature": 0.0, "avg_logprob": -0.12248322367668152, "compression_ratio": 1.7212389380530972, "no_speech_prob": 4.262751463102177e-05}, {"id": 394, "seek": 267084, "start": 2688.76, "end": 2699.4, "text": " of the lecture is to define graph convolutional nets. Okay. So I need to redefine convolution", "tokens": [50364, 1168, 286, 658, 510, 13, 407, 393, 291, 4160, 505, 437, 307, 767, 264, 4787, 3387, 510, 30, 708, 307, 264, 3387, 50664, 50664, 295, 17827, 613, 3754, 15892, 420, 264, 42761, 38135, 670, 613, 24877, 30, 286, 519, 1310, 50964, 50964, 309, 311, 406, 485, 865, 11, 498, 321, 393, 4160, 1518, 11, 309, 311, 516, 281, 312, 485, 865, 13, 407, 437, 286, 478, 1382, 485, 440, 3387, 51260, 51260, 295, 264, 7991, 307, 281, 6964, 4295, 45216, 304, 36170, 13, 1033, 13, 407, 286, 643, 281, 38818, 533, 45216, 51792, 51792], "temperature": 0.0, "avg_logprob": -0.12248322367668152, "compression_ratio": 1.7212389380530972, "no_speech_prob": 4.262751463102177e-05}, {"id": 395, "seek": 269940, "start": 2699.4, "end": 2705.96, "text": " in the case of graphs. And there are two ways to define convolutions. You can do convolution with", "tokens": [50364, 294, 264, 1389, 295, 24877, 13, 400, 456, 366, 732, 2098, 281, 6964, 3754, 15892, 13, 509, 393, 360, 45216, 365, 50692, 50692, 9921, 12, 4092, 14324, 11, 420, 291, 393, 360, 45216, 365, 4295, 42761, 5261, 13, 407, 437, 286, 478, 884, 510, 11, 51020, 51104, 286, 478, 38818, 1760, 45216, 294, 264, 1389, 295, 42761, 5261, 13, 400, 550, 286, 478, 516, 281, 764, 341, 7123, 51428, 51428, 295, 45216, 281, 6964, 4295, 45216, 304, 36170, 13, 407, 452, 3387, 307, 445, 281, 6964, 45216, 294, 264, 51780, 51780], "temperature": 0.0, "avg_logprob": -0.10462191797071888, "compression_ratio": 2.0307692307692307, "no_speech_prob": 1.0780340744531713e-05}, {"id": 396, "seek": 269940, "start": 2705.96, "end": 2712.52, "text": " stamp-like matching, or you can do convolution with graph spectral theory. So what I'm doing here,", "tokens": [50364, 294, 264, 1389, 295, 24877, 13, 400, 456, 366, 732, 2098, 281, 6964, 3754, 15892, 13, 509, 393, 360, 45216, 365, 50692, 50692, 9921, 12, 4092, 14324, 11, 420, 291, 393, 360, 45216, 365, 4295, 42761, 5261, 13, 407, 437, 286, 478, 884, 510, 11, 51020, 51104, 286, 478, 38818, 1760, 45216, 294, 264, 1389, 295, 42761, 5261, 13, 400, 550, 286, 478, 516, 281, 764, 341, 7123, 51428, 51428, 295, 45216, 281, 6964, 4295, 45216, 304, 36170, 13, 407, 452, 3387, 307, 445, 281, 6964, 45216, 294, 264, 51780, 51780], "temperature": 0.0, "avg_logprob": -0.10462191797071888, "compression_ratio": 2.0307692307692307, "no_speech_prob": 1.0780340744531713e-05}, {"id": 397, "seek": 269940, "start": 2714.2000000000003, "end": 2720.6800000000003, "text": " I'm redefining convolution in the case of spectral theory. And then I'm going to use this definition", "tokens": [50364, 294, 264, 1389, 295, 24877, 13, 400, 456, 366, 732, 2098, 281, 6964, 3754, 15892, 13, 509, 393, 360, 45216, 365, 50692, 50692, 9921, 12, 4092, 14324, 11, 420, 291, 393, 360, 45216, 365, 4295, 42761, 5261, 13, 407, 437, 286, 478, 884, 510, 11, 51020, 51104, 286, 478, 38818, 1760, 45216, 294, 264, 1389, 295, 42761, 5261, 13, 400, 550, 286, 478, 516, 281, 764, 341, 7123, 51428, 51428, 295, 45216, 281, 6964, 4295, 45216, 304, 36170, 13, 407, 452, 3387, 307, 445, 281, 6964, 45216, 294, 264, 51780, 51780], "temperature": 0.0, "avg_logprob": -0.10462191797071888, "compression_ratio": 2.0307692307692307, "no_speech_prob": 1.0780340744531713e-05}, {"id": 398, "seek": 269940, "start": 2720.6800000000003, "end": 2727.7200000000003, "text": " of convolution to define graph convolutional nets. So my goal is just to define convolution in the", "tokens": [50364, 294, 264, 1389, 295, 24877, 13, 400, 456, 366, 732, 2098, 281, 6964, 3754, 15892, 13, 509, 393, 360, 45216, 365, 50692, 50692, 9921, 12, 4092, 14324, 11, 420, 291, 393, 360, 45216, 365, 4295, 42761, 5261, 13, 407, 437, 286, 478, 884, 510, 11, 51020, 51104, 286, 478, 38818, 1760, 45216, 294, 264, 1389, 295, 42761, 5261, 13, 400, 550, 286, 478, 516, 281, 764, 341, 7123, 51428, 51428, 295, 45216, 281, 6964, 4295, 45216, 304, 36170, 13, 407, 452, 3387, 307, 445, 281, 6964, 45216, 294, 264, 51780, 51780], "temperature": 0.0, "avg_logprob": -0.10462191797071888, "compression_ratio": 2.0307692307692307, "no_speech_prob": 1.0780340744531713e-05}, {"id": 399, "seek": 272772, "start": 2727.72, "end": 2734.7599999999998, "text": " case of graphs so I can design graph convolutional nets. Yeah. Sounds great.", "tokens": [50364, 1389, 295, 24877, 370, 286, 393, 1715, 4295, 45216, 304, 36170, 13, 865, 13, 14576, 869, 13, 50716, 50840, 1033, 13, 407, 718, 311, 352, 281, 485, 1033, 13, 407, 586, 264, 700, 644, 390, 11, 1392, 11, 286, 6964, 42761, 45216, 13, 51164, 51164, 823, 286, 478, 516, 281, 764, 42761, 45216, 281, 6964, 29435, 45, 13, 1033, 13, 407, 264, 700, 2316, 11, 51608, 51648], "temperature": 0.0, "avg_logprob": -0.12244534146958504, "compression_ratio": 1.6217948717948718, "no_speech_prob": 2.60741089732619e-05}, {"id": 400, "seek": 272772, "start": 2737.24, "end": 2743.72, "text": " Okay. So let's go to... Okay. So now the first part was, okay, I define spectral convolution.", "tokens": [50364, 1389, 295, 24877, 370, 286, 393, 1715, 4295, 45216, 304, 36170, 13, 865, 13, 14576, 869, 13, 50716, 50840, 1033, 13, 407, 718, 311, 352, 281, 485, 1033, 13, 407, 586, 264, 700, 644, 390, 11, 1392, 11, 286, 6964, 42761, 45216, 13, 51164, 51164, 823, 286, 478, 516, 281, 764, 42761, 45216, 281, 6964, 29435, 45, 13, 1033, 13, 407, 264, 700, 2316, 11, 51608, 51648], "temperature": 0.0, "avg_logprob": -0.12244534146958504, "compression_ratio": 1.6217948717948718, "no_speech_prob": 2.60741089732619e-05}, {"id": 401, "seek": 272772, "start": 2743.72, "end": 2752.6, "text": " Now I'm going to use spectral convolution to define GCN. Okay. So the first model,", "tokens": [50364, 1389, 295, 24877, 370, 286, 393, 1715, 4295, 45216, 304, 36170, 13, 865, 13, 14576, 869, 13, 50716, 50840, 1033, 13, 407, 718, 311, 352, 281, 485, 1033, 13, 407, 586, 264, 700, 644, 390, 11, 1392, 11, 286, 6964, 42761, 45216, 13, 51164, 51164, 823, 286, 478, 516, 281, 764, 42761, 45216, 281, 6964, 29435, 45, 13, 1033, 13, 407, 264, 700, 2316, 11, 51608, 51648], "temperature": 0.0, "avg_logprob": -0.12244534146958504, "compression_ratio": 1.6217948717948718, "no_speech_prob": 2.60741089732619e-05}, {"id": 402, "seek": 275260, "start": 2752.6, "end": 2760.12, "text": " what I call Vanilla Spectral GCN, was introduced actually by Yann Lecain and his collaborators,", "tokens": [50364, 437, 286, 818, 8979, 5291, 27078, 2155, 29435, 45, 11, 390, 7268, 767, 538, 398, 969, 1456, 66, 491, 293, 702, 39789, 11, 50740, 50740, 370, 19180, 282, 1603, 409, 260, 11, 1176, 545, 4257, 14782, 293, 1587, 2716, 374, 318, 4326, 294, 8227, 13, 286, 519, 309, 390, 337, 264, 700, 14360, 31722, 7586, 13, 51180, 51272, 400, 437, 436, 630, 11, 436, 630, 264, 2199, 1558, 281, 360, 11, 1392, 11, 718, 311, 6964, 257, 4295, 42761, 51724, 51724], "temperature": 0.0, "avg_logprob": -0.26187080934823276, "compression_ratio": 1.3707317073170733, "no_speech_prob": 0.00010447374370414764}, {"id": 403, "seek": 275260, "start": 2760.12, "end": 2768.92, "text": " so Johan Bruner, Zahran Bah and Arshur Slam in 2014. I think it was for the first ICLR conference.", "tokens": [50364, 437, 286, 818, 8979, 5291, 27078, 2155, 29435, 45, 11, 390, 7268, 767, 538, 398, 969, 1456, 66, 491, 293, 702, 39789, 11, 50740, 50740, 370, 19180, 282, 1603, 409, 260, 11, 1176, 545, 4257, 14782, 293, 1587, 2716, 374, 318, 4326, 294, 8227, 13, 286, 519, 309, 390, 337, 264, 700, 14360, 31722, 7586, 13, 51180, 51272, 400, 437, 436, 630, 11, 436, 630, 264, 2199, 1558, 281, 360, 11, 1392, 11, 718, 311, 6964, 257, 4295, 42761, 51724, 51724], "temperature": 0.0, "avg_logprob": -0.26187080934823276, "compression_ratio": 1.3707317073170733, "no_speech_prob": 0.00010447374370414764}, {"id": 404, "seek": 275260, "start": 2770.7599999999998, "end": 2779.7999999999997, "text": " And what they did, they did the simple idea to do, okay, let's define a graph spectral", "tokens": [50364, 437, 286, 818, 8979, 5291, 27078, 2155, 29435, 45, 11, 390, 7268, 767, 538, 398, 969, 1456, 66, 491, 293, 702, 39789, 11, 50740, 50740, 370, 19180, 282, 1603, 409, 260, 11, 1176, 545, 4257, 14782, 293, 1587, 2716, 374, 318, 4326, 294, 8227, 13, 286, 519, 309, 390, 337, 264, 700, 14360, 31722, 7586, 13, 51180, 51272, 400, 437, 436, 630, 11, 436, 630, 264, 2199, 1558, 281, 360, 11, 1392, 11, 718, 311, 6964, 257, 4295, 42761, 51724, 51724], "temperature": 0.0, "avg_logprob": -0.26187080934823276, "compression_ratio": 1.3707317073170733, "no_speech_prob": 0.00010447374370414764}, {"id": 405, "seek": 277980, "start": 2779.8, "end": 2787.48, "text": " convolutional layer. So we know what is a standard convolutional layer. So this is the activation at", "tokens": [50364, 45216, 304, 4583, 13, 407, 321, 458, 437, 307, 257, 3832, 45216, 304, 4583, 13, 407, 341, 307, 264, 24433, 412, 50748, 50748, 264, 958, 4583, 11, 1649, 1804, 502, 13, 639, 307, 428, 2107, 28263, 24433, 13, 407, 341, 307, 11, 337, 1365, 11, 264, 29956, 13, 51004, 51072, 400, 550, 286, 478, 516, 281, 360, 264, 23598, 6608, 13, 407, 264, 12379, 343, 43, 11, 45216, 538, 389, 44, 13, 1033, 13, 407, 341, 51388, 51388, 307, 294, 264, 23598, 9274, 11, 264, 4295, 9274, 13, 400, 550, 286, 478, 516, 281, 360, 300, 13, 400, 1604, 300, 437, 51692, 51692], "temperature": 0.0, "avg_logprob": -0.1678464617047991, "compression_ratio": 1.849056603773585, "no_speech_prob": 3.2045260013546795e-05}, {"id": 406, "seek": 277980, "start": 2787.48, "end": 2792.6000000000004, "text": " the next layer, 8 plus 1. This is your nonlinear activation. So this is, for example, the redo.", "tokens": [50364, 45216, 304, 4583, 13, 407, 321, 458, 437, 307, 257, 3832, 45216, 304, 4583, 13, 407, 341, 307, 264, 24433, 412, 50748, 50748, 264, 958, 4583, 11, 1649, 1804, 502, 13, 639, 307, 428, 2107, 28263, 24433, 13, 407, 341, 307, 11, 337, 1365, 11, 264, 29956, 13, 51004, 51072, 400, 550, 286, 478, 516, 281, 360, 264, 23598, 6608, 13, 407, 264, 12379, 343, 43, 11, 45216, 538, 389, 44, 13, 1033, 13, 407, 341, 51388, 51388, 307, 294, 264, 23598, 9274, 11, 264, 4295, 9274, 13, 400, 550, 286, 478, 516, 281, 360, 300, 13, 400, 1604, 300, 437, 51692, 51692], "temperature": 0.0, "avg_logprob": -0.1678464617047991, "compression_ratio": 1.849056603773585, "no_speech_prob": 3.2045260013546795e-05}, {"id": 407, "seek": 277980, "start": 2793.96, "end": 2800.28, "text": " And then I'm going to do the spatial filter. So the template WL, convolution by HM. Okay. So this", "tokens": [50364, 45216, 304, 4583, 13, 407, 321, 458, 437, 307, 257, 3832, 45216, 304, 4583, 13, 407, 341, 307, 264, 24433, 412, 50748, 50748, 264, 958, 4583, 11, 1649, 1804, 502, 13, 639, 307, 428, 2107, 28263, 24433, 13, 407, 341, 307, 11, 337, 1365, 11, 264, 29956, 13, 51004, 51072, 400, 550, 286, 478, 516, 281, 360, 264, 23598, 6608, 13, 407, 264, 12379, 343, 43, 11, 45216, 538, 389, 44, 13, 1033, 13, 407, 341, 51388, 51388, 307, 294, 264, 23598, 9274, 11, 264, 4295, 9274, 13, 400, 550, 286, 478, 516, 281, 360, 300, 13, 400, 1604, 300, 437, 51692, 51692], "temperature": 0.0, "avg_logprob": -0.1678464617047991, "compression_ratio": 1.849056603773585, "no_speech_prob": 3.2045260013546795e-05}, {"id": 408, "seek": 277980, "start": 2800.28, "end": 2806.36, "text": " is in the spatial domain, the graph domain. And then I'm going to do that. And remember that what", "tokens": [50364, 45216, 304, 4583, 13, 407, 321, 458, 437, 307, 257, 3832, 45216, 304, 4583, 13, 407, 341, 307, 264, 24433, 412, 50748, 50748, 264, 958, 4583, 11, 1649, 1804, 502, 13, 639, 307, 428, 2107, 28263, 24433, 13, 407, 341, 307, 11, 337, 1365, 11, 264, 29956, 13, 51004, 51072, 400, 550, 286, 478, 516, 281, 360, 264, 23598, 6608, 13, 407, 264, 12379, 343, 43, 11, 45216, 538, 389, 44, 13, 1033, 13, 407, 341, 51388, 51388, 307, 294, 264, 23598, 9274, 11, 264, 4295, 9274, 13, 400, 550, 286, 478, 516, 281, 360, 300, 13, 400, 1604, 300, 437, 51692, 51692], "temperature": 0.0, "avg_logprob": -0.1678464617047991, "compression_ratio": 1.849056603773585, "no_speech_prob": 3.2045260013546795e-05}, {"id": 409, "seek": 280636, "start": 2806.36, "end": 2811.96, "text": " I just defined, so doing this convolution in the spectral domain, it's just doing that. Okay. So", "tokens": [50364, 286, 445, 7642, 11, 370, 884, 341, 45216, 294, 264, 42761, 9274, 11, 309, 311, 445, 884, 300, 13, 1033, 13, 407, 50644, 50644, 341, 307, 264, 42761, 6608, 6456, 281, 264, 635, 564, 399, 293, 550, 291, 12972, 538, 389, 44, 13, 1033, 13, 51016, 51016, 407, 341, 2146, 307, 11, 286, 393, 22867, 541, 341, 2146, 13, 286, 486, 483, 264, 36810, 8141, 1413, 264, 42761, 2445, 51436, 51436], "temperature": 0.0, "avg_logprob": -0.1491554077357462, "compression_ratio": 1.6045197740112995, "no_speech_prob": 1.2730684829875827e-05}, {"id": 410, "seek": 280636, "start": 2811.96, "end": 2819.4, "text": " this is the spectral filter applied to the laplation and then you multiply by HM. Okay.", "tokens": [50364, 286, 445, 7642, 11, 370, 884, 341, 45216, 294, 264, 42761, 9274, 11, 309, 311, 445, 884, 300, 13, 1033, 13, 407, 50644, 50644, 341, 307, 264, 42761, 6608, 6456, 281, 264, 635, 564, 399, 293, 550, 291, 12972, 538, 389, 44, 13, 1033, 13, 51016, 51016, 407, 341, 2146, 307, 11, 286, 393, 22867, 541, 341, 2146, 13, 286, 486, 483, 264, 36810, 8141, 1413, 264, 42761, 2445, 51436, 51436], "temperature": 0.0, "avg_logprob": -0.1491554077357462, "compression_ratio": 1.6045197740112995, "no_speech_prob": 1.2730684829875827e-05}, {"id": 411, "seek": 280636, "start": 2819.4, "end": 2827.8, "text": " So this guy is, I can decompose this guy. I will get the Fourier matrix times the spectral function", "tokens": [50364, 286, 445, 7642, 11, 370, 884, 341, 45216, 294, 264, 42761, 9274, 11, 309, 311, 445, 884, 300, 13, 1033, 13, 407, 50644, 50644, 341, 307, 264, 42761, 6608, 6456, 281, 264, 635, 564, 399, 293, 550, 291, 12972, 538, 389, 44, 13, 1033, 13, 51016, 51016, 407, 341, 2146, 307, 11, 286, 393, 22867, 541, 341, 2146, 13, 286, 486, 483, 264, 36810, 8141, 1413, 264, 42761, 2445, 51436, 51436], "temperature": 0.0, "avg_logprob": -0.1491554077357462, "compression_ratio": 1.6045197740112995, "no_speech_prob": 1.2730684829875827e-05}, {"id": 412, "seek": 282780, "start": 2827.8, "end": 2837.88, "text": " that I applied to the eigenvalues, phi transpose HM. Okay. And this is my spectral filter. Okay.", "tokens": [50364, 300, 286, 6456, 281, 264, 10446, 46033, 11, 13107, 25167, 389, 44, 13, 1033, 13, 400, 341, 307, 452, 42761, 6608, 13, 1033, 13, 50868, 50868, 407, 286, 360, 406, 589, 3838, 510, 13, 1033, 13, 286, 589, 3838, 510, 13, 400, 510, 11, 264, 551, 300, 286, 478, 516, 51224, 51224, 281, 1466, 11, 286, 478, 516, 767, 281, 1466, 341, 2445, 11, 343, 2385, 11, 2107, 12, 28263, 472, 13, 407, 286, 478, 516, 281, 1466, 51572, 51628], "temperature": 0.0, "avg_logprob": -0.1623383731376834, "compression_ratio": 1.6514285714285715, "no_speech_prob": 1.4056323379918467e-05}, {"id": 413, "seek": 282780, "start": 2837.88, "end": 2845.0, "text": " So I do not work directly here. Okay. I work directly here. And here, the thing that I'm going", "tokens": [50364, 300, 286, 6456, 281, 264, 10446, 46033, 11, 13107, 25167, 389, 44, 13, 1033, 13, 400, 341, 307, 452, 42761, 6608, 13, 1033, 13, 50868, 50868, 407, 286, 360, 406, 589, 3838, 510, 13, 1033, 13, 286, 589, 3838, 510, 13, 400, 510, 11, 264, 551, 300, 286, 478, 516, 51224, 51224, 281, 1466, 11, 286, 478, 516, 767, 281, 1466, 341, 2445, 11, 343, 2385, 11, 2107, 12, 28263, 472, 13, 407, 286, 478, 516, 281, 1466, 51572, 51628], "temperature": 0.0, "avg_logprob": -0.1623383731376834, "compression_ratio": 1.6514285714285715, "no_speech_prob": 1.4056323379918467e-05}, {"id": 414, "seek": 282780, "start": 2845.0, "end": 2851.96, "text": " to learn, I'm going actually to learn this function, W hat, non-linear one. So I'm going to learn", "tokens": [50364, 300, 286, 6456, 281, 264, 10446, 46033, 11, 13107, 25167, 389, 44, 13, 1033, 13, 400, 341, 307, 452, 42761, 6608, 13, 1033, 13, 50868, 50868, 407, 286, 360, 406, 589, 3838, 510, 13, 1033, 13, 286, 589, 3838, 510, 13, 400, 510, 11, 264, 551, 300, 286, 478, 516, 51224, 51224, 281, 1466, 11, 286, 478, 516, 767, 281, 1466, 341, 2445, 11, 343, 2385, 11, 2107, 12, 28263, 472, 13, 407, 286, 478, 516, 281, 1466, 51572, 51628], "temperature": 0.0, "avg_logprob": -0.1623383731376834, "compression_ratio": 1.6514285714285715, "no_speech_prob": 1.4056323379918467e-05}, {"id": 415, "seek": 285196, "start": 2851.96, "end": 2858.2, "text": " the spectral filter and I'm going to learn it by back propagation. Okay. So I don't need to,", "tokens": [50364, 264, 42761, 6608, 293, 286, 478, 516, 281, 1466, 309, 538, 646, 38377, 13, 1033, 13, 407, 286, 500, 380, 643, 281, 11, 50676, 50736, 291, 458, 11, 1011, 5611, 264, 42761, 6608, 13, 286, 500, 380, 643, 281, 360, 300, 13, 639, 486, 312, 3264, 538, 51044, 51044, 646, 38377, 13, 407, 300, 390, 534, 257, 869, 1558, 281, 360, 309, 13, 400, 341, 390, 264, 700, 42761, 6532, 11, 51364, 51364, 457, 309, 575, 512, 15705, 13, 407, 264, 700, 27432, 307, 300, 291, 500, 380, 362, 604, 10815, 51572, 51572], "temperature": 0.0, "avg_logprob": -0.16532205280504728, "compression_ratio": 1.7605633802816902, "no_speech_prob": 1.4038037988939323e-05}, {"id": 416, "seek": 285196, "start": 2859.4, "end": 2865.56, "text": " you know, handcraft the spectral filter. I don't need to do that. This will be learned by", "tokens": [50364, 264, 42761, 6608, 293, 286, 478, 516, 281, 1466, 309, 538, 646, 38377, 13, 1033, 13, 407, 286, 500, 380, 643, 281, 11, 50676, 50736, 291, 458, 11, 1011, 5611, 264, 42761, 6608, 13, 286, 500, 380, 643, 281, 360, 300, 13, 639, 486, 312, 3264, 538, 51044, 51044, 646, 38377, 13, 407, 300, 390, 534, 257, 869, 1558, 281, 360, 309, 13, 400, 341, 390, 264, 700, 42761, 6532, 11, 51364, 51364, 457, 309, 575, 512, 15705, 13, 407, 264, 700, 27432, 307, 300, 291, 500, 380, 362, 604, 10815, 51572, 51572], "temperature": 0.0, "avg_logprob": -0.16532205280504728, "compression_ratio": 1.7605633802816902, "no_speech_prob": 1.4038037988939323e-05}, {"id": 417, "seek": 285196, "start": 2865.56, "end": 2871.96, "text": " back propagation. So that was really a great idea to do it. And this was the first spectral technique,", "tokens": [50364, 264, 42761, 6608, 293, 286, 478, 516, 281, 1466, 309, 538, 646, 38377, 13, 1033, 13, 407, 286, 500, 380, 643, 281, 11, 50676, 50736, 291, 458, 11, 1011, 5611, 264, 42761, 6608, 13, 286, 500, 380, 643, 281, 360, 300, 13, 639, 486, 312, 3264, 538, 51044, 51044, 646, 38377, 13, 407, 300, 390, 534, 257, 869, 1558, 281, 360, 309, 13, 400, 341, 390, 264, 700, 42761, 6532, 11, 51364, 51364, 457, 309, 575, 512, 15705, 13, 407, 264, 700, 27432, 307, 300, 291, 500, 380, 362, 604, 10815, 51572, 51572], "temperature": 0.0, "avg_logprob": -0.16532205280504728, "compression_ratio": 1.7605633802816902, "no_speech_prob": 1.4038037988939323e-05}, {"id": 418, "seek": 285196, "start": 2871.96, "end": 2876.12, "text": " but it has some limitations. So the first limitation is that you don't have any guarantee", "tokens": [50364, 264, 42761, 6608, 293, 286, 478, 516, 281, 1466, 309, 538, 646, 38377, 13, 1033, 13, 407, 286, 500, 380, 643, 281, 11, 50676, 50736, 291, 458, 11, 1011, 5611, 264, 42761, 6608, 13, 286, 500, 380, 643, 281, 360, 300, 13, 639, 486, 312, 3264, 538, 51044, 51044, 646, 38377, 13, 407, 300, 390, 534, 257, 869, 1558, 281, 360, 309, 13, 400, 341, 390, 264, 700, 42761, 6532, 11, 51364, 51364, 457, 309, 575, 512, 15705, 13, 407, 264, 700, 27432, 307, 300, 291, 500, 380, 362, 604, 10815, 51572, 51572], "temperature": 0.0, "avg_logprob": -0.16532205280504728, "compression_ratio": 1.7605633802816902, "no_speech_prob": 1.4038037988939323e-05}, {"id": 419, "seek": 287612, "start": 2876.12, "end": 2883.0, "text": " of special localization of filters. So remember that what we want, we want to have the local", "tokens": [50364, 295, 2121, 2654, 2144, 295, 15995, 13, 407, 1604, 300, 437, 321, 528, 11, 321, 528, 281, 362, 264, 2654, 50708, 50708, 21682, 2519, 570, 309, 311, 257, 588, 665, 4707, 281, 312, 1075, 281, 8947, 11, 291, 458, 11, 4825, 12, 20033, 51020, 51084, 4111, 11, 4825, 12, 20033, 8294, 490, 428, 6358, 13, 407, 291, 500, 380, 362, 341, 10815, 13, 51372, 51372, 440, 1150, 551, 307, 300, 577, 867, 9834, 360, 291, 643, 281, 1466, 30, 407, 291, 643, 281, 1466, 51644, 51644], "temperature": 0.0, "avg_logprob": -0.18400877172296698, "compression_ratio": 1.6376146788990826, "no_speech_prob": 2.5322566216345876e-05}, {"id": 420, "seek": 287612, "start": 2883.0, "end": 2889.24, "text": " reception field because it's a very good property to be able to extract, you know, multi-scale", "tokens": [50364, 295, 2121, 2654, 2144, 295, 15995, 13, 407, 1604, 300, 437, 321, 528, 11, 321, 528, 281, 362, 264, 2654, 50708, 50708, 21682, 2519, 570, 309, 311, 257, 588, 665, 4707, 281, 312, 1075, 281, 8947, 11, 291, 458, 11, 4825, 12, 20033, 51020, 51084, 4111, 11, 4825, 12, 20033, 8294, 490, 428, 6358, 13, 407, 291, 500, 380, 362, 341, 10815, 13, 51372, 51372, 440, 1150, 551, 307, 300, 577, 867, 9834, 360, 291, 643, 281, 1466, 30, 407, 291, 643, 281, 1466, 51644, 51644], "temperature": 0.0, "avg_logprob": -0.18400877172296698, "compression_ratio": 1.6376146788990826, "no_speech_prob": 2.5322566216345876e-05}, {"id": 421, "seek": 287612, "start": 2890.52, "end": 2896.2799999999997, "text": " feature, multi-scale patterns from your signal. So you don't have this guarantee.", "tokens": [50364, 295, 2121, 2654, 2144, 295, 15995, 13, 407, 1604, 300, 437, 321, 528, 11, 321, 528, 281, 362, 264, 2654, 50708, 50708, 21682, 2519, 570, 309, 311, 257, 588, 665, 4707, 281, 312, 1075, 281, 8947, 11, 291, 458, 11, 4825, 12, 20033, 51020, 51084, 4111, 11, 4825, 12, 20033, 8294, 490, 428, 6358, 13, 407, 291, 500, 380, 362, 341, 10815, 13, 51372, 51372, 440, 1150, 551, 307, 300, 577, 867, 9834, 360, 291, 643, 281, 1466, 30, 407, 291, 643, 281, 1466, 51644, 51644], "temperature": 0.0, "avg_logprob": -0.18400877172296698, "compression_ratio": 1.6376146788990826, "no_speech_prob": 2.5322566216345876e-05}, {"id": 422, "seek": 287612, "start": 2896.2799999999997, "end": 2901.72, "text": " The second thing is that how many parameters do you need to learn? So you need to learn", "tokens": [50364, 295, 2121, 2654, 2144, 295, 15995, 13, 407, 1604, 300, 437, 321, 528, 11, 321, 528, 281, 362, 264, 2654, 50708, 50708, 21682, 2519, 570, 309, 311, 257, 588, 665, 4707, 281, 312, 1075, 281, 8947, 11, 291, 458, 11, 4825, 12, 20033, 51020, 51084, 4111, 11, 4825, 12, 20033, 8294, 490, 428, 6358, 13, 407, 291, 500, 380, 362, 341, 10815, 13, 51372, 51372, 440, 1150, 551, 307, 300, 577, 867, 9834, 360, 291, 643, 281, 1466, 30, 407, 291, 643, 281, 1466, 51644, 51644], "temperature": 0.0, "avg_logprob": -0.18400877172296698, "compression_ratio": 1.6376146788990826, "no_speech_prob": 2.5322566216345876e-05}, {"id": 423, "seek": 290172, "start": 2901.72, "end": 2909.16, "text": " you need to learn N parameters. Okay. You need to learn this W hat non-linear one to W hat non-linear", "tokens": [50364, 291, 643, 281, 1466, 426, 9834, 13, 1033, 13, 509, 643, 281, 1466, 341, 343, 2385, 2107, 12, 28263, 472, 281, 343, 2385, 2107, 12, 28263, 50736, 50736, 426, 13, 407, 309, 311, 426, 9834, 13, 407, 797, 11, 498, 264, 4295, 307, 2416, 11, 411, 264, 3670, 11, 291, 458, 11, 420, 4384, 11, 51196, 51196, 550, 341, 307, 516, 281, 312, 17375, 295, 9834, 281, 1466, 13, 400, 341, 307, 337, 1184, 4583, 13, 407, 309, 311, 51512, 51512, 516, 281, 312, 534, 2603, 13, 400, 797, 11, 264, 2539, 16060, 507, 307, 516, 281, 312, 426, 3732, 570, 428, 51712, 51712], "temperature": 0.0, "avg_logprob": -0.12337526285423422, "compression_ratio": 1.8169014084507042, "no_speech_prob": 3.389734774827957e-05}, {"id": 424, "seek": 290172, "start": 2909.16, "end": 2918.3599999999997, "text": " N. So it's N parameters. So again, if the graph is large, like the web, you know, or Facebook,", "tokens": [50364, 291, 643, 281, 1466, 426, 9834, 13, 1033, 13, 509, 643, 281, 1466, 341, 343, 2385, 2107, 12, 28263, 472, 281, 343, 2385, 2107, 12, 28263, 50736, 50736, 426, 13, 407, 309, 311, 426, 9834, 13, 407, 797, 11, 498, 264, 4295, 307, 2416, 11, 411, 264, 3670, 11, 291, 458, 11, 420, 4384, 11, 51196, 51196, 550, 341, 307, 516, 281, 312, 17375, 295, 9834, 281, 1466, 13, 400, 341, 307, 337, 1184, 4583, 13, 407, 309, 311, 51512, 51512, 516, 281, 312, 534, 2603, 13, 400, 797, 11, 264, 2539, 16060, 507, 307, 516, 281, 312, 426, 3732, 570, 428, 51712, 51712], "temperature": 0.0, "avg_logprob": -0.12337526285423422, "compression_ratio": 1.8169014084507042, "no_speech_prob": 3.389734774827957e-05}, {"id": 425, "seek": 290172, "start": 2918.3599999999997, "end": 2924.68, "text": " then this is going to be billions of parameters to learn. And this is for each layer. So it's", "tokens": [50364, 291, 643, 281, 1466, 426, 9834, 13, 1033, 13, 509, 643, 281, 1466, 341, 343, 2385, 2107, 12, 28263, 472, 281, 343, 2385, 2107, 12, 28263, 50736, 50736, 426, 13, 407, 309, 311, 426, 9834, 13, 407, 797, 11, 498, 264, 4295, 307, 2416, 11, 411, 264, 3670, 11, 291, 458, 11, 420, 4384, 11, 51196, 51196, 550, 341, 307, 516, 281, 312, 17375, 295, 9834, 281, 1466, 13, 400, 341, 307, 337, 1184, 4583, 13, 407, 309, 311, 51512, 51512, 516, 281, 312, 534, 2603, 13, 400, 797, 11, 264, 2539, 16060, 507, 307, 516, 281, 312, 426, 3732, 570, 428, 51712, 51712], "temperature": 0.0, "avg_logprob": -0.12337526285423422, "compression_ratio": 1.8169014084507042, "no_speech_prob": 3.389734774827957e-05}, {"id": 426, "seek": 290172, "start": 2924.68, "end": 2928.68, "text": " going to be really huge. And again, the learning complicity is going to be N square because your", "tokens": [50364, 291, 643, 281, 1466, 426, 9834, 13, 1033, 13, 509, 643, 281, 1466, 341, 343, 2385, 2107, 12, 28263, 472, 281, 343, 2385, 2107, 12, 28263, 50736, 50736, 426, 13, 407, 309, 311, 426, 9834, 13, 407, 797, 11, 498, 264, 4295, 307, 2416, 11, 411, 264, 3670, 11, 291, 458, 11, 420, 4384, 11, 51196, 51196, 550, 341, 307, 516, 281, 312, 17375, 295, 9834, 281, 1466, 13, 400, 341, 307, 337, 1184, 4583, 13, 407, 309, 311, 51512, 51512, 516, 281, 312, 534, 2603, 13, 400, 797, 11, 264, 2539, 16060, 507, 307, 516, 281, 312, 426, 3732, 570, 428, 51712, 51712], "temperature": 0.0, "avg_logprob": -0.12337526285423422, "compression_ratio": 1.8169014084507042, "no_speech_prob": 3.389734774827957e-05}, {"id": 427, "seek": 292868, "start": 2928.68, "end": 2938.6, "text": " file is a dense matrix. So we need to improve this. Okay. So Yan and his collaborators, so they", "tokens": [50364, 3991, 307, 257, 18011, 8141, 13, 407, 321, 643, 281, 3470, 341, 13, 1033, 13, 407, 13633, 293, 702, 39789, 11, 370, 436, 50860, 50860, 3470, 264, 732, 7221, 13, 407, 264, 700, 4707, 390, 11, 1392, 11, 577, 360, 321, 483, 44574, 23598, 15995, 30, 51320, 51356, 1033, 13, 407, 337, 341, 11, 437, 436, 17421, 307, 281, 483, 44574, 23598, 6608, 13, 407, 291, 528, 746, 51836, 51836], "temperature": 0.0, "avg_logprob": -0.18380147880978054, "compression_ratio": 1.6590909090909092, "no_speech_prob": 8.925630936573725e-06}, {"id": 428, "seek": 292868, "start": 2938.6, "end": 2947.7999999999997, "text": " improve the two properties. So the first property was, okay, how do we get localized spatial filters?", "tokens": [50364, 3991, 307, 257, 18011, 8141, 13, 407, 321, 643, 281, 3470, 341, 13, 1033, 13, 407, 13633, 293, 702, 39789, 11, 370, 436, 50860, 50860, 3470, 264, 732, 7221, 13, 407, 264, 700, 4707, 390, 11, 1392, 11, 577, 360, 321, 483, 44574, 23598, 15995, 30, 51320, 51356, 1033, 13, 407, 337, 341, 11, 437, 436, 17421, 307, 281, 483, 44574, 23598, 6608, 13, 407, 291, 528, 746, 51836, 51836], "temperature": 0.0, "avg_logprob": -0.18380147880978054, "compression_ratio": 1.6590909090909092, "no_speech_prob": 8.925630936573725e-06}, {"id": 429, "seek": 292868, "start": 2948.52, "end": 2958.12, "text": " Okay. So for this, what they propose is to get localized spatial filter. So you want something", "tokens": [50364, 3991, 307, 257, 18011, 8141, 13, 407, 321, 643, 281, 3470, 341, 13, 1033, 13, 407, 13633, 293, 702, 39789, 11, 370, 436, 50860, 50860, 3470, 264, 732, 7221, 13, 407, 264, 700, 4707, 390, 11, 1392, 11, 577, 360, 321, 483, 44574, 23598, 15995, 30, 51320, 51356, 1033, 13, 407, 337, 341, 11, 437, 436, 17421, 307, 281, 483, 44574, 23598, 6608, 13, 407, 291, 528, 746, 51836, 51836], "temperature": 0.0, "avg_logprob": -0.18380147880978054, "compression_ratio": 1.6590909090909092, "no_speech_prob": 8.925630936573725e-06}, {"id": 430, "seek": 295812, "start": 2958.12, "end": 2966.7599999999998, "text": " which is localized. What you need to do is to compute smooth spectral filters, something very", "tokens": [50364, 597, 307, 44574, 13, 708, 291, 643, 281, 360, 307, 281, 14722, 5508, 42761, 15995, 11, 746, 588, 50796, 50796, 5508, 411, 341, 13, 1033, 13, 407, 983, 360, 291, 11, 983, 360, 291, 528, 5508, 42761, 6608, 30, 467, 311, 570, 498, 291, 51116, 51116, 366, 5508, 294, 264, 7893, 1901, 11, 550, 291, 366, 516, 281, 312, 44574, 294, 264, 1901, 9274, 13, 1033, 13, 51412, 51412, 407, 341, 307, 294, 10649, 11, 291, 458, 11, 264, 1119, 268, 6873, 311, 13977, 8665, 13, 400, 291, 393, 536, 300, 11, 291, 458, 11, 51656, 51656], "temperature": 0.0, "avg_logprob": -0.12874509830667516, "compression_ratio": 1.72, "no_speech_prob": 1.6343525203410536e-05}, {"id": 431, "seek": 295812, "start": 2966.7599999999998, "end": 2973.16, "text": " smooth like this. Okay. So why do you, why do you want smooth spectral filter? It's because if you", "tokens": [50364, 597, 307, 44574, 13, 708, 291, 643, 281, 360, 307, 281, 14722, 5508, 42761, 15995, 11, 746, 588, 50796, 50796, 5508, 411, 341, 13, 1033, 13, 407, 983, 360, 291, 11, 983, 360, 291, 528, 5508, 42761, 6608, 30, 467, 311, 570, 498, 291, 51116, 51116, 366, 5508, 294, 264, 7893, 1901, 11, 550, 291, 366, 516, 281, 312, 44574, 294, 264, 1901, 9274, 13, 1033, 13, 51412, 51412, 407, 341, 307, 294, 10649, 11, 291, 458, 11, 264, 1119, 268, 6873, 311, 13977, 8665, 13, 400, 291, 393, 536, 300, 11, 291, 458, 11, 51656, 51656], "temperature": 0.0, "avg_logprob": -0.12874509830667516, "compression_ratio": 1.72, "no_speech_prob": 1.6343525203410536e-05}, {"id": 432, "seek": 295812, "start": 2973.16, "end": 2979.08, "text": " are smooth in the frequency space, then you are going to be localized in the space domain. Okay.", "tokens": [50364, 597, 307, 44574, 13, 708, 291, 643, 281, 360, 307, 281, 14722, 5508, 42761, 15995, 11, 746, 588, 50796, 50796, 5508, 411, 341, 13, 1033, 13, 407, 983, 360, 291, 11, 983, 360, 291, 528, 5508, 42761, 6608, 30, 467, 311, 570, 498, 291, 51116, 51116, 366, 5508, 294, 264, 7893, 1901, 11, 550, 291, 366, 516, 281, 312, 44574, 294, 264, 1901, 9274, 13, 1033, 13, 51412, 51412, 407, 341, 307, 294, 10649, 11, 291, 458, 11, 264, 1119, 268, 6873, 311, 13977, 8665, 13, 400, 291, 393, 536, 300, 11, 291, 458, 11, 51656, 51656], "temperature": 0.0, "avg_logprob": -0.12874509830667516, "compression_ratio": 1.72, "no_speech_prob": 1.6343525203410536e-05}, {"id": 433, "seek": 295812, "start": 2979.08, "end": 2983.96, "text": " So this is in physics, you know, the Isenberg's entity principle. And you can see that, you know,", "tokens": [50364, 597, 307, 44574, 13, 708, 291, 643, 281, 360, 307, 281, 14722, 5508, 42761, 15995, 11, 746, 588, 50796, 50796, 5508, 411, 341, 13, 1033, 13, 407, 983, 360, 291, 11, 983, 360, 291, 528, 5508, 42761, 6608, 30, 467, 311, 570, 498, 291, 51116, 51116, 366, 5508, 294, 264, 7893, 1901, 11, 550, 291, 366, 516, 281, 312, 44574, 294, 264, 1901, 9274, 13, 1033, 13, 51412, 51412, 407, 341, 307, 294, 10649, 11, 291, 458, 11, 264, 1119, 268, 6873, 311, 13977, 8665, 13, 400, 291, 393, 536, 300, 11, 291, 458, 11, 51656, 51656], "temperature": 0.0, "avg_logprob": -0.12874509830667516, "compression_ratio": 1.72, "no_speech_prob": 1.6343525203410536e-05}, {"id": 434, "seek": 298396, "start": 2983.96, "end": 2989.64, "text": " with the possible identity, if let's, let's say that K is equal to one, if K is equal to one,", "tokens": [50364, 365, 264, 1944, 6575, 11, 498, 718, 311, 11, 718, 311, 584, 300, 591, 307, 2681, 281, 472, 11, 498, 591, 307, 2681, 281, 472, 11, 50648, 50648, 291, 362, 264, 700, 13760, 295, 11, 295, 264, 42761, 2445, 13, 407, 498, 291, 528, 341, 281, 312, 1359, 11, 50920, 50948, 1392, 13, 407, 291, 434, 516, 281, 362, 257, 5508, 2445, 13, 400, 337, 591, 2681, 281, 472, 11, 291, 536, 510, 307, 341, 307, 51252, 51252, 516, 281, 312, 264, 21977, 295, 428, 23598, 6608, 13, 407, 498, 341, 307, 1359, 11, 498, 264, 21977, 307, 1359, 11, 51548, 51548], "temperature": 0.0, "avg_logprob": -0.12266878898327167, "compression_ratio": 1.857843137254902, "no_speech_prob": 2.9278957299538888e-05}, {"id": 435, "seek": 298396, "start": 2989.64, "end": 2995.08, "text": " you have the first derivative of, of the spectral function. So if you want this to be small,", "tokens": [50364, 365, 264, 1944, 6575, 11, 498, 718, 311, 11, 718, 311, 584, 300, 591, 307, 2681, 281, 472, 11, 498, 591, 307, 2681, 281, 472, 11, 50648, 50648, 291, 362, 264, 700, 13760, 295, 11, 295, 264, 42761, 2445, 13, 407, 498, 291, 528, 341, 281, 312, 1359, 11, 50920, 50948, 1392, 13, 407, 291, 434, 516, 281, 362, 257, 5508, 2445, 13, 400, 337, 591, 2681, 281, 472, 11, 291, 536, 510, 307, 341, 307, 51252, 51252, 516, 281, 312, 264, 21977, 295, 428, 23598, 6608, 13, 407, 498, 341, 307, 1359, 11, 498, 264, 21977, 307, 1359, 11, 51548, 51548], "temperature": 0.0, "avg_logprob": -0.12266878898327167, "compression_ratio": 1.857843137254902, "no_speech_prob": 2.9278957299538888e-05}, {"id": 436, "seek": 298396, "start": 2995.64, "end": 3001.7200000000003, "text": " okay. So you're going to have a smooth function. And for K equal to one, you see here is this is", "tokens": [50364, 365, 264, 1944, 6575, 11, 498, 718, 311, 11, 718, 311, 584, 300, 591, 307, 2681, 281, 472, 11, 498, 591, 307, 2681, 281, 472, 11, 50648, 50648, 291, 362, 264, 700, 13760, 295, 11, 295, 264, 42761, 2445, 13, 407, 498, 291, 528, 341, 281, 312, 1359, 11, 50920, 50948, 1392, 13, 407, 291, 434, 516, 281, 362, 257, 5508, 2445, 13, 400, 337, 591, 2681, 281, 472, 11, 291, 536, 510, 307, 341, 307, 51252, 51252, 516, 281, 312, 264, 21977, 295, 428, 23598, 6608, 13, 407, 498, 341, 307, 1359, 11, 498, 264, 21977, 307, 1359, 11, 51548, 51548], "temperature": 0.0, "avg_logprob": -0.12266878898327167, "compression_ratio": 1.857843137254902, "no_speech_prob": 2.9278957299538888e-05}, {"id": 437, "seek": 298396, "start": 3001.7200000000003, "end": 3007.64, "text": " going to be the variance of your spatial filter. So if this is small, if the variance is small,", "tokens": [50364, 365, 264, 1944, 6575, 11, 498, 718, 311, 11, 718, 311, 584, 300, 591, 307, 2681, 281, 472, 11, 498, 591, 307, 2681, 281, 472, 11, 50648, 50648, 291, 362, 264, 700, 13760, 295, 11, 295, 264, 42761, 2445, 13, 407, 498, 291, 528, 341, 281, 312, 1359, 11, 50920, 50948, 1392, 13, 407, 291, 434, 516, 281, 362, 257, 5508, 2445, 13, 400, 337, 591, 2681, 281, 472, 11, 291, 536, 510, 307, 341, 307, 51252, 51252, 516, 281, 312, 264, 21977, 295, 428, 23598, 6608, 13, 407, 498, 341, 307, 1359, 11, 498, 264, 21977, 307, 1359, 11, 51548, 51548], "temperature": 0.0, "avg_logprob": -0.12266878898327167, "compression_ratio": 1.857843137254902, "no_speech_prob": 2.9278957299538888e-05}, {"id": 438, "seek": 300764, "start": 3007.64, "end": 3014.7599999999998, "text": " it means that you're going to have a small, you're going to have a spatial filter with a small compact", "tokens": [50364, 309, 1355, 300, 291, 434, 516, 281, 362, 257, 1359, 11, 291, 434, 516, 281, 362, 257, 23598, 6608, 365, 257, 1359, 14679, 50720, 50756, 1406, 13, 1033, 13, 407, 498, 291, 366, 5508, 294, 264, 7893, 1901, 11, 291, 434, 516, 281, 312, 44574, 51116, 51116, 294, 264, 23598, 1901, 13, 1033, 13, 407, 291, 643, 5508, 1287, 13, 1012, 360, 291, 483, 5508, 1287, 337, 42761, 6608, 30, 51400, 51400, 407, 291, 393, 611, 519, 466, 264, 11, 264, 4088, 295, 264, 1412, 295, 264, 11818, 11, 558, 30, 407, 321, 362, 11, 51636, 51636], "temperature": 0.0, "avg_logprob": -0.127478483951453, "compression_ratio": 1.8056872037914693, "no_speech_prob": 6.789906183257699e-05}, {"id": 439, "seek": 300764, "start": 3015.48, "end": 3022.68, "text": " support. Okay. So if you are smooth in the frequency space, you're going to be localized", "tokens": [50364, 309, 1355, 300, 291, 434, 516, 281, 362, 257, 1359, 11, 291, 434, 516, 281, 362, 257, 23598, 6608, 365, 257, 1359, 14679, 50720, 50756, 1406, 13, 1033, 13, 407, 498, 291, 366, 5508, 294, 264, 7893, 1901, 11, 291, 434, 516, 281, 312, 44574, 51116, 51116, 294, 264, 23598, 1901, 13, 1033, 13, 407, 291, 643, 5508, 1287, 13, 1012, 360, 291, 483, 5508, 1287, 337, 42761, 6608, 30, 51400, 51400, 407, 291, 393, 611, 519, 466, 264, 11, 264, 4088, 295, 264, 1412, 295, 264, 11818, 11, 558, 30, 407, 321, 362, 11, 51636, 51636], "temperature": 0.0, "avg_logprob": -0.127478483951453, "compression_ratio": 1.8056872037914693, "no_speech_prob": 6.789906183257699e-05}, {"id": 440, "seek": 300764, "start": 3022.68, "end": 3028.3599999999997, "text": " in the spatial space. Okay. So you need smoothness. How do you get smoothness for spectral filter?", "tokens": [50364, 309, 1355, 300, 291, 434, 516, 281, 362, 257, 1359, 11, 291, 434, 516, 281, 362, 257, 23598, 6608, 365, 257, 1359, 14679, 50720, 50756, 1406, 13, 1033, 13, 407, 498, 291, 366, 5508, 294, 264, 7893, 1901, 11, 291, 434, 516, 281, 312, 44574, 51116, 51116, 294, 264, 23598, 1901, 13, 1033, 13, 407, 291, 643, 5508, 1287, 13, 1012, 360, 291, 483, 5508, 1287, 337, 42761, 6608, 30, 51400, 51400, 407, 291, 393, 611, 519, 466, 264, 11, 264, 4088, 295, 264, 1412, 295, 264, 11818, 11, 558, 30, 407, 321, 362, 11, 51636, 51636], "temperature": 0.0, "avg_logprob": -0.127478483951453, "compression_ratio": 1.8056872037914693, "no_speech_prob": 6.789906183257699e-05}, {"id": 441, "seek": 300764, "start": 3028.3599999999997, "end": 3033.08, "text": " So you can also think about the, the transform of the data of the Iraq, right? So we have,", "tokens": [50364, 309, 1355, 300, 291, 434, 516, 281, 362, 257, 1359, 11, 291, 434, 516, 281, 362, 257, 23598, 6608, 365, 257, 1359, 14679, 50720, 50756, 1406, 13, 1033, 13, 407, 498, 291, 366, 5508, 294, 264, 7893, 1901, 11, 291, 434, 516, 281, 312, 44574, 51116, 51116, 294, 264, 23598, 1901, 13, 1033, 13, 407, 291, 643, 5508, 1287, 13, 1012, 360, 291, 483, 5508, 1287, 337, 42761, 6608, 30, 51400, 51400, 407, 291, 393, 611, 519, 466, 264, 11, 264, 4088, 295, 264, 1412, 295, 264, 11818, 11, 558, 30, 407, 321, 362, 11, 51636, 51636], "temperature": 0.0, "avg_logprob": -0.127478483951453, "compression_ratio": 1.8056872037914693, "no_speech_prob": 6.789906183257699e-05}, {"id": 442, "seek": 303308, "start": 3033.08, "end": 3037.64, "text": " if we have a data in the Iraq in the, in the time domain, then in the frequency, we're going to have", "tokens": [50364, 498, 321, 362, 257, 1412, 294, 264, 11818, 294, 264, 11, 294, 264, 565, 9274, 11, 550, 294, 264, 7893, 11, 321, 434, 516, 281, 362, 50592, 50592, 1936, 257, 4962, 11, 257, 2584, 4962, 4088, 11, 558, 30, 407, 456, 311, 1071, 1310, 636, 281, 536, 498, 50876, 50876, 1580, 1177, 380, 1596, 458, 264, 34082, 6575, 13, 865, 11, 2293, 13, 1779, 13, 400, 370, 11, 370, 577, 360, 291, 483, 257, 51272, 51272, 5508, 42761, 6608, 30, 407, 264, 1558, 307, 11, 1392, 11, 321, 393, 2935, 22867, 541, 11, 291, 458, 11, 264, 42761, 6608, 51640, 51676], "temperature": 0.0, "avg_logprob": -0.1462492896515189, "compression_ratio": 1.6131687242798354, "no_speech_prob": 1.2197215255582705e-05}, {"id": 443, "seek": 303308, "start": 3037.64, "end": 3043.3199999999997, "text": " basically a flat, a completely flat transform, right? So there's another maybe way to see if", "tokens": [50364, 498, 321, 362, 257, 1412, 294, 264, 11818, 294, 264, 11, 294, 264, 565, 9274, 11, 550, 294, 264, 7893, 11, 321, 434, 516, 281, 362, 50592, 50592, 1936, 257, 4962, 11, 257, 2584, 4962, 4088, 11, 558, 30, 407, 456, 311, 1071, 1310, 636, 281, 536, 498, 50876, 50876, 1580, 1177, 380, 1596, 458, 264, 34082, 6575, 13, 865, 11, 2293, 13, 1779, 13, 400, 370, 11, 370, 577, 360, 291, 483, 257, 51272, 51272, 5508, 42761, 6608, 30, 407, 264, 1558, 307, 11, 1392, 11, 321, 393, 2935, 22867, 541, 11, 291, 458, 11, 264, 42761, 6608, 51640, 51676], "temperature": 0.0, "avg_logprob": -0.1462492896515189, "compression_ratio": 1.6131687242798354, "no_speech_prob": 1.2197215255582705e-05}, {"id": 444, "seek": 303308, "start": 3043.3199999999997, "end": 3051.24, "text": " someone doesn't quite know the parcel identity. Yeah, exactly. Right. And so, so how do you get a", "tokens": [50364, 498, 321, 362, 257, 1412, 294, 264, 11818, 294, 264, 11, 294, 264, 565, 9274, 11, 550, 294, 264, 7893, 11, 321, 434, 516, 281, 362, 50592, 50592, 1936, 257, 4962, 11, 257, 2584, 4962, 4088, 11, 558, 30, 407, 456, 311, 1071, 1310, 636, 281, 536, 498, 50876, 50876, 1580, 1177, 380, 1596, 458, 264, 34082, 6575, 13, 865, 11, 2293, 13, 1779, 13, 400, 370, 11, 370, 577, 360, 291, 483, 257, 51272, 51272, 5508, 42761, 6608, 30, 407, 264, 1558, 307, 11, 1392, 11, 321, 393, 2935, 22867, 541, 11, 291, 458, 11, 264, 42761, 6608, 51640, 51676], "temperature": 0.0, "avg_logprob": -0.1462492896515189, "compression_ratio": 1.6131687242798354, "no_speech_prob": 1.2197215255582705e-05}, {"id": 445, "seek": 303308, "start": 3051.24, "end": 3058.6, "text": " smooth spectral filter? So the idea is, okay, we can simply decompose, you know, the spectral filter", "tokens": [50364, 498, 321, 362, 257, 1412, 294, 264, 11818, 294, 264, 11, 294, 264, 565, 9274, 11, 550, 294, 264, 7893, 11, 321, 434, 516, 281, 362, 50592, 50592, 1936, 257, 4962, 11, 257, 2584, 4962, 4088, 11, 558, 30, 407, 456, 311, 1071, 1310, 636, 281, 536, 498, 50876, 50876, 1580, 1177, 380, 1596, 458, 264, 34082, 6575, 13, 865, 11, 2293, 13, 1779, 13, 400, 370, 11, 370, 577, 360, 291, 483, 257, 51272, 51272, 5508, 42761, 6608, 30, 407, 264, 1558, 307, 11, 1392, 11, 321, 393, 2935, 22867, 541, 11, 291, 458, 11, 264, 42761, 6608, 51640, 51676], "temperature": 0.0, "avg_logprob": -0.1462492896515189, "compression_ratio": 1.6131687242798354, "no_speech_prob": 1.2197215255582705e-05}, {"id": 446, "seek": 305860, "start": 3058.6, "end": 3067.24, "text": " to be a linear combination of smooth kernels. Okay. So the smooth kernel was chosen to be splines", "tokens": [50364, 281, 312, 257, 8213, 6562, 295, 5508, 23434, 1625, 13, 1033, 13, 407, 264, 5508, 28256, 390, 8614, 281, 312, 4732, 1652, 50796, 50828, 570, 4732, 1652, 366, 1481, 13, 814, 366, 11, 291, 458, 11, 365, 14679, 1406, 293, 436, 366, 5508, 13, 51068, 51096, 400, 1936, 264, 1558, 307, 11, 1392, 11, 586, 718, 311, 1466, 257, 8062, 295, 591, 17619, 13, 400, 341, 307, 257, 591, 5508, 51416, 51416, 28256, 13, 1033, 13, 400, 291, 1466, 341, 17619, 538, 646, 38377, 13, 583, 5800, 11, 291, 458, 11, 51636, 51676], "temperature": 0.0, "avg_logprob": -0.20496525011564556, "compression_ratio": 1.6846846846846846, "no_speech_prob": 0.00015247058763634413}, {"id": 447, "seek": 305860, "start": 3067.88, "end": 3072.68, "text": " because splines are nice. They are, you know, with compact support and they are smooth.", "tokens": [50364, 281, 312, 257, 8213, 6562, 295, 5508, 23434, 1625, 13, 1033, 13, 407, 264, 5508, 28256, 390, 8614, 281, 312, 4732, 1652, 50796, 50828, 570, 4732, 1652, 366, 1481, 13, 814, 366, 11, 291, 458, 11, 365, 14679, 1406, 293, 436, 366, 5508, 13, 51068, 51096, 400, 1936, 264, 1558, 307, 11, 1392, 11, 586, 718, 311, 1466, 257, 8062, 295, 591, 17619, 13, 400, 341, 307, 257, 591, 5508, 51416, 51416, 28256, 13, 1033, 13, 400, 291, 1466, 341, 17619, 538, 646, 38377, 13, 583, 5800, 11, 291, 458, 11, 51636, 51676], "temperature": 0.0, "avg_logprob": -0.20496525011564556, "compression_ratio": 1.6846846846846846, "no_speech_prob": 0.00015247058763634413}, {"id": 448, "seek": 305860, "start": 3073.24, "end": 3079.64, "text": " And basically the idea is, okay, now let's learn a vector of K coefficient. And this is a K smooth", "tokens": [50364, 281, 312, 257, 8213, 6562, 295, 5508, 23434, 1625, 13, 1033, 13, 407, 264, 5508, 28256, 390, 8614, 281, 312, 4732, 1652, 50796, 50828, 570, 4732, 1652, 366, 1481, 13, 814, 366, 11, 291, 458, 11, 365, 14679, 1406, 293, 436, 366, 5508, 13, 51068, 51096, 400, 1936, 264, 1558, 307, 11, 1392, 11, 586, 718, 311, 1466, 257, 8062, 295, 591, 17619, 13, 400, 341, 307, 257, 591, 5508, 51416, 51416, 28256, 13, 1033, 13, 400, 291, 1466, 341, 17619, 538, 646, 38377, 13, 583, 5800, 11, 291, 458, 11, 51636, 51676], "temperature": 0.0, "avg_logprob": -0.20496525011564556, "compression_ratio": 1.6846846846846846, "no_speech_prob": 0.00015247058763634413}, {"id": 449, "seek": 305860, "start": 3079.64, "end": 3084.04, "text": " kernel. Okay. And you learn this coefficient by back propagation. But suddenly, you know,", "tokens": [50364, 281, 312, 257, 8213, 6562, 295, 5508, 23434, 1625, 13, 1033, 13, 407, 264, 5508, 28256, 390, 8614, 281, 312, 4732, 1652, 50796, 50828, 570, 4732, 1652, 366, 1481, 13, 814, 366, 11, 291, 458, 11, 365, 14679, 1406, 293, 436, 366, 5508, 13, 51068, 51096, 400, 1936, 264, 1558, 307, 11, 1392, 11, 586, 718, 311, 1466, 257, 8062, 295, 591, 17619, 13, 400, 341, 307, 257, 591, 5508, 51416, 51416, 28256, 13, 1033, 13, 400, 291, 1466, 341, 17619, 538, 646, 38377, 13, 583, 5800, 11, 291, 458, 11, 51636, 51676], "temperature": 0.0, "avg_logprob": -0.20496525011564556, "compression_ratio": 1.6846846846846846, "no_speech_prob": 0.00015247058763634413}, {"id": 450, "seek": 308404, "start": 3084.04, "end": 3090.04, "text": " everything is nice because you have localization in space and the number of parameters that you're", "tokens": [50364, 1203, 307, 1481, 570, 291, 362, 2654, 2144, 294, 1901, 293, 264, 1230, 295, 9834, 300, 291, 434, 50664, 50664, 516, 281, 1466, 307, 516, 281, 312, 591, 9834, 13, 407, 591, 337, 1365, 11, 718, 311, 584, 309, 311, 4949, 13, 1033, 13, 5459, 50988, 50988, 300, 949, 294, 264, 1389, 295, 11, 295, 45216, 13, 407, 291, 362, 264, 4230, 538, 4230, 11, 597, 307, 4949, 9834, 13, 51296, 51296, 407, 300, 393, 312, 264, 912, 13, 509, 393, 362, 4949, 9834, 281, 1466, 13, 509, 434, 516, 281, 11, 291, 434, 51472, 51472, 516, 281, 1466, 257, 6562, 295, 4949, 4732, 533, 6828, 13, 400, 11, 293, 300, 311, 309, 13, 407, 291, 393, 362, 51856, 51856], "temperature": 0.0, "avg_logprob": -0.22554949463390914, "compression_ratio": 1.9, "no_speech_prob": 1.862782664829865e-05}, {"id": 451, "seek": 308404, "start": 3090.04, "end": 3096.52, "text": " going to learn is going to be K parameters. So K for example, let's say it's nine. Okay. Remember", "tokens": [50364, 1203, 307, 1481, 570, 291, 362, 2654, 2144, 294, 1901, 293, 264, 1230, 295, 9834, 300, 291, 434, 50664, 50664, 516, 281, 1466, 307, 516, 281, 312, 591, 9834, 13, 407, 591, 337, 1365, 11, 718, 311, 584, 309, 311, 4949, 13, 1033, 13, 5459, 50988, 50988, 300, 949, 294, 264, 1389, 295, 11, 295, 45216, 13, 407, 291, 362, 264, 4230, 538, 4230, 11, 597, 307, 4949, 9834, 13, 51296, 51296, 407, 300, 393, 312, 264, 912, 13, 509, 393, 362, 4949, 9834, 281, 1466, 13, 509, 434, 516, 281, 11, 291, 434, 51472, 51472, 516, 281, 1466, 257, 6562, 295, 4949, 4732, 533, 6828, 13, 400, 11, 293, 300, 311, 309, 13, 407, 291, 393, 362, 51856, 51856], "temperature": 0.0, "avg_logprob": -0.22554949463390914, "compression_ratio": 1.9, "no_speech_prob": 1.862782664829865e-05}, {"id": 452, "seek": 308404, "start": 3096.52, "end": 3102.68, "text": " that before in the case of, of convolution. So you have the tree by tree, which is nine parameters.", "tokens": [50364, 1203, 307, 1481, 570, 291, 362, 2654, 2144, 294, 1901, 293, 264, 1230, 295, 9834, 300, 291, 434, 50664, 50664, 516, 281, 1466, 307, 516, 281, 312, 591, 9834, 13, 407, 591, 337, 1365, 11, 718, 311, 584, 309, 311, 4949, 13, 1033, 13, 5459, 50988, 50988, 300, 949, 294, 264, 1389, 295, 11, 295, 45216, 13, 407, 291, 362, 264, 4230, 538, 4230, 11, 597, 307, 4949, 9834, 13, 51296, 51296, 407, 300, 393, 312, 264, 912, 13, 509, 393, 362, 4949, 9834, 281, 1466, 13, 509, 434, 516, 281, 11, 291, 434, 51472, 51472, 516, 281, 1466, 257, 6562, 295, 4949, 4732, 533, 6828, 13, 400, 11, 293, 300, 311, 309, 13, 407, 291, 393, 362, 51856, 51856], "temperature": 0.0, "avg_logprob": -0.22554949463390914, "compression_ratio": 1.9, "no_speech_prob": 1.862782664829865e-05}, {"id": 453, "seek": 308404, "start": 3102.68, "end": 3106.2, "text": " So that can be the same. You can have nine parameters to learn. You're going to, you're", "tokens": [50364, 1203, 307, 1481, 570, 291, 362, 2654, 2144, 294, 1901, 293, 264, 1230, 295, 9834, 300, 291, 434, 50664, 50664, 516, 281, 1466, 307, 516, 281, 312, 591, 9834, 13, 407, 591, 337, 1365, 11, 718, 311, 584, 309, 311, 4949, 13, 1033, 13, 5459, 50988, 50988, 300, 949, 294, 264, 1389, 295, 11, 295, 45216, 13, 407, 291, 362, 264, 4230, 538, 4230, 11, 597, 307, 4949, 9834, 13, 51296, 51296, 407, 300, 393, 312, 264, 912, 13, 509, 393, 362, 4949, 9834, 281, 1466, 13, 509, 434, 516, 281, 11, 291, 434, 51472, 51472, 516, 281, 1466, 257, 6562, 295, 4949, 4732, 533, 6828, 13, 400, 11, 293, 300, 311, 309, 13, 407, 291, 393, 362, 51856, 51856], "temperature": 0.0, "avg_logprob": -0.22554949463390914, "compression_ratio": 1.9, "no_speech_prob": 1.862782664829865e-05}, {"id": 454, "seek": 308404, "start": 3106.2, "end": 3113.88, "text": " going to learn a combination of nine spline functions. And, and that's it. So you can have", "tokens": [50364, 1203, 307, 1481, 570, 291, 362, 2654, 2144, 294, 1901, 293, 264, 1230, 295, 9834, 300, 291, 434, 50664, 50664, 516, 281, 1466, 307, 516, 281, 312, 591, 9834, 13, 407, 591, 337, 1365, 11, 718, 311, 584, 309, 311, 4949, 13, 1033, 13, 5459, 50988, 50988, 300, 949, 294, 264, 1389, 295, 11, 295, 45216, 13, 407, 291, 362, 264, 4230, 538, 4230, 11, 597, 307, 4949, 9834, 13, 51296, 51296, 407, 300, 393, 312, 264, 912, 13, 509, 393, 362, 4949, 9834, 281, 1466, 13, 509, 434, 516, 281, 11, 291, 434, 51472, 51472, 516, 281, 1466, 257, 6562, 295, 4949, 4732, 533, 6828, 13, 400, 11, 293, 300, 311, 309, 13, 407, 291, 393, 362, 51856, 51856], "temperature": 0.0, "avg_logprob": -0.22554949463390914, "compression_ratio": 1.9, "no_speech_prob": 1.862782664829865e-05}, {"id": 455, "seek": 311388, "start": 3113.88, "end": 3120.6, "text": " a constant number of parameters to learn per layer. So this is nice, but we still have, you know,", "tokens": [50364, 257, 5754, 1230, 295, 9834, 281, 1466, 680, 4583, 13, 407, 341, 307, 1481, 11, 457, 321, 920, 362, 11, 291, 458, 11, 50700, 50700, 264, 11, 264, 1732, 8141, 13, 407, 264, 2539, 14024, 307, 920, 37262, 13, 1033, 13, 51012, 51268, 1033, 13, 407, 11, 370, 264, 1168, 307, 11, 577, 360, 321, 1466, 294, 8213, 565, 30, 1033, 13, 407, 577, 360, 321, 1466, 51588, 51620], "temperature": 0.0, "avg_logprob": -0.22901967545630228, "compression_ratio": 1.5602409638554218, "no_speech_prob": 7.692087820032611e-05}, {"id": 456, "seek": 311388, "start": 3120.6, "end": 3126.84, "text": " the, the five matrix. So the learning complexity is still quadratic. Okay.", "tokens": [50364, 257, 5754, 1230, 295, 9834, 281, 1466, 680, 4583, 13, 407, 341, 307, 1481, 11, 457, 321, 920, 362, 11, 291, 458, 11, 50700, 50700, 264, 11, 264, 1732, 8141, 13, 407, 264, 2539, 14024, 307, 920, 37262, 13, 1033, 13, 51012, 51268, 1033, 13, 407, 11, 370, 264, 1168, 307, 11, 577, 360, 321, 1466, 294, 8213, 565, 30, 1033, 13, 407, 577, 360, 321, 1466, 51588, 51620], "temperature": 0.0, "avg_logprob": -0.22901967545630228, "compression_ratio": 1.5602409638554218, "no_speech_prob": 7.692087820032611e-05}, {"id": 457, "seek": 311388, "start": 3131.96, "end": 3138.36, "text": " Okay. So, so the question is, how do we learn in linear time? Okay. So how do we learn", "tokens": [50364, 257, 5754, 1230, 295, 9834, 281, 1466, 680, 4583, 13, 407, 341, 307, 1481, 11, 457, 321, 920, 362, 11, 291, 458, 11, 50700, 50700, 264, 11, 264, 1732, 8141, 13, 407, 264, 2539, 14024, 307, 920, 37262, 13, 1033, 13, 51012, 51268, 1033, 13, 407, 11, 370, 264, 1168, 307, 11, 577, 360, 321, 1466, 294, 8213, 565, 30, 1033, 13, 407, 577, 360, 321, 1466, 51588, 51620], "temperature": 0.0, "avg_logprob": -0.22901967545630228, "compression_ratio": 1.5602409638554218, "no_speech_prob": 7.692087820032611e-05}, {"id": 458, "seek": 313836, "start": 3138.36, "end": 3146.52, "text": " with respect to the, to the graph size and so the problem of the quadratic complexity", "tokens": [50364, 365, 3104, 281, 264, 11, 281, 264, 4295, 2744, 293, 370, 264, 1154, 295, 264, 37262, 14024, 50772, 50772, 1487, 490, 3838, 490, 264, 764, 295, 264, 2369, 564, 326, 952, 797, 11, 18875, 13, 1033, 13, 407, 291, 536, 300, 264, 551, 51112, 51112, 300, 307, 11, 300, 307, 11304, 294, 341, 42761, 45216, 307, 406, 341, 21539, 8141, 13, 51420, 51420, 467, 311, 406, 341, 8062, 13, 467, 311, 341, 2146, 13, 1033, 13, 639, 307, 11, 341, 307, 264, 1732, 8141, 570, 309, 311, 257, 1577, 51712, 51712], "temperature": 0.0, "avg_logprob": -0.12476964150705645, "compression_ratio": 1.704225352112676, "no_speech_prob": 9.64063874562271e-05}, {"id": 459, "seek": 313836, "start": 3146.52, "end": 3153.32, "text": " comes from directly from the use of the Laplacian again, vectors. Okay. So you see that the thing", "tokens": [50364, 365, 3104, 281, 264, 11, 281, 264, 4295, 2744, 293, 370, 264, 1154, 295, 264, 37262, 14024, 50772, 50772, 1487, 490, 3838, 490, 264, 764, 295, 264, 2369, 564, 326, 952, 797, 11, 18875, 13, 1033, 13, 407, 291, 536, 300, 264, 551, 51112, 51112, 300, 307, 11, 300, 307, 11304, 294, 341, 42761, 45216, 307, 406, 341, 21539, 8141, 13, 51420, 51420, 467, 311, 406, 341, 8062, 13, 467, 311, 341, 2146, 13, 1033, 13, 639, 307, 11, 341, 307, 264, 1732, 8141, 570, 309, 311, 257, 1577, 51712, 51712], "temperature": 0.0, "avg_logprob": -0.12476964150705645, "compression_ratio": 1.704225352112676, "no_speech_prob": 9.64063874562271e-05}, {"id": 460, "seek": 313836, "start": 3153.32, "end": 3159.48, "text": " that is, that is annoying in this spectral convolution is not this diagonal matrix.", "tokens": [50364, 365, 3104, 281, 264, 11, 281, 264, 4295, 2744, 293, 370, 264, 1154, 295, 264, 37262, 14024, 50772, 50772, 1487, 490, 3838, 490, 264, 764, 295, 264, 2369, 564, 326, 952, 797, 11, 18875, 13, 1033, 13, 407, 291, 536, 300, 264, 551, 51112, 51112, 300, 307, 11, 300, 307, 11304, 294, 341, 42761, 45216, 307, 406, 341, 21539, 8141, 13, 51420, 51420, 467, 311, 406, 341, 8062, 13, 467, 311, 341, 2146, 13, 1033, 13, 639, 307, 11, 341, 307, 264, 1732, 8141, 570, 309, 311, 257, 1577, 51712, 51712], "temperature": 0.0, "avg_logprob": -0.12476964150705645, "compression_ratio": 1.704225352112676, "no_speech_prob": 9.64063874562271e-05}, {"id": 461, "seek": 313836, "start": 3159.48, "end": 3165.32, "text": " It's not this vector. It's this guy. Okay. This is, this is the five matrix because it's a full", "tokens": [50364, 365, 3104, 281, 264, 11, 281, 264, 4295, 2744, 293, 370, 264, 1154, 295, 264, 37262, 14024, 50772, 50772, 1487, 490, 3838, 490, 264, 764, 295, 264, 2369, 564, 326, 952, 797, 11, 18875, 13, 1033, 13, 407, 291, 536, 300, 264, 551, 51112, 51112, 300, 307, 11, 300, 307, 11304, 294, 341, 42761, 45216, 307, 406, 341, 21539, 8141, 13, 51420, 51420, 467, 311, 406, 341, 8062, 13, 467, 311, 341, 2146, 13, 1033, 13, 639, 307, 11, 341, 307, 264, 1732, 8141, 570, 309, 311, 257, 1577, 51712, 51712], "temperature": 0.0, "avg_logprob": -0.12476964150705645, "compression_ratio": 1.704225352112676, "no_speech_prob": 9.64063874562271e-05}, {"id": 462, "seek": 316532, "start": 3165.32, "end": 3170.28, "text": " matrix, right? It's a dense matrix. And, and then, and then it's an N square number of elements.", "tokens": [50364, 8141, 11, 558, 30, 467, 311, 257, 18011, 8141, 13, 400, 11, 293, 550, 11, 293, 550, 309, 311, 364, 426, 3732, 1230, 295, 4959, 13, 50612, 50612, 407, 341, 307, 264, 3218, 300, 321, 643, 281, 1689, 13, 407, 321, 458, 300, 498, 321, 528, 281, 5042, 264, 37262, 50904, 50904, 14024, 11, 321, 643, 281, 5042, 264, 797, 11, 264, 12686, 13, 1033, 13, 400, 11, 293, 11, 293, 1392, 13, 407, 321, 51288, 51288, 393, 5042, 797, 11, 264, 2535, 538, 2935, 3838, 1466, 2445, 295, 264, 2369, 564, 326, 952, 13, 1033, 13, 407, 341, 307, 51544, 51544], "temperature": 0.0, "avg_logprob": -0.16138133635887733, "compression_ratio": 1.7488372093023257, "no_speech_prob": 1.3827887414663564e-05}, {"id": 463, "seek": 316532, "start": 3170.28, "end": 3176.1200000000003, "text": " So this is the price that we need to pay. So we know that if we want to avoid the quadratic", "tokens": [50364, 8141, 11, 558, 30, 467, 311, 257, 18011, 8141, 13, 400, 11, 293, 550, 11, 293, 550, 309, 311, 364, 426, 3732, 1230, 295, 4959, 13, 50612, 50612, 407, 341, 307, 264, 3218, 300, 321, 643, 281, 1689, 13, 407, 321, 458, 300, 498, 321, 528, 281, 5042, 264, 37262, 50904, 50904, 14024, 11, 321, 643, 281, 5042, 264, 797, 11, 264, 12686, 13, 1033, 13, 400, 11, 293, 11, 293, 1392, 13, 407, 321, 51288, 51288, 393, 5042, 797, 11, 264, 2535, 538, 2935, 3838, 1466, 2445, 295, 264, 2369, 564, 326, 952, 13, 1033, 13, 407, 341, 307, 51544, 51544], "temperature": 0.0, "avg_logprob": -0.16138133635887733, "compression_ratio": 1.7488372093023257, "no_speech_prob": 1.3827887414663564e-05}, {"id": 464, "seek": 316532, "start": 3176.1200000000003, "end": 3183.8, "text": " complexity, we need to avoid the again, the composition. Okay. And, and, and okay. So we", "tokens": [50364, 8141, 11, 558, 30, 467, 311, 257, 18011, 8141, 13, 400, 11, 293, 550, 11, 293, 550, 309, 311, 364, 426, 3732, 1230, 295, 4959, 13, 50612, 50612, 407, 341, 307, 264, 3218, 300, 321, 643, 281, 1689, 13, 407, 321, 458, 300, 498, 321, 528, 281, 5042, 264, 37262, 50904, 50904, 14024, 11, 321, 643, 281, 5042, 264, 797, 11, 264, 12686, 13, 1033, 13, 400, 11, 293, 11, 293, 1392, 13, 407, 321, 51288, 51288, 393, 5042, 797, 11, 264, 2535, 538, 2935, 3838, 1466, 2445, 295, 264, 2369, 564, 326, 952, 13, 1033, 13, 407, 341, 307, 51544, 51544], "temperature": 0.0, "avg_logprob": -0.16138133635887733, "compression_ratio": 1.7488372093023257, "no_speech_prob": 1.3827887414663564e-05}, {"id": 465, "seek": 316532, "start": 3183.8, "end": 3188.92, "text": " can avoid again, the position by simply directly learn function of the Laplacian. Okay. So this is", "tokens": [50364, 8141, 11, 558, 30, 467, 311, 257, 18011, 8141, 13, 400, 11, 293, 550, 11, 293, 550, 309, 311, 364, 426, 3732, 1230, 295, 4959, 13, 50612, 50612, 407, 341, 307, 264, 3218, 300, 321, 643, 281, 1689, 13, 407, 321, 458, 300, 498, 321, 528, 281, 5042, 264, 37262, 50904, 50904, 14024, 11, 321, 643, 281, 5042, 264, 797, 11, 264, 12686, 13, 1033, 13, 400, 11, 293, 11, 293, 1392, 13, 407, 321, 51288, 51288, 393, 5042, 797, 11, 264, 2535, 538, 2935, 3838, 1466, 2445, 295, 264, 2369, 564, 326, 952, 13, 1033, 13, 407, 341, 307, 51544, 51544], "temperature": 0.0, "avg_logprob": -0.16138133635887733, "compression_ratio": 1.7488372093023257, "no_speech_prob": 1.3827887414663564e-05}, {"id": 466, "seek": 318892, "start": 3188.92, "end": 3199.16, "text": " what we propose in 2000, 2016. So the spectral function is just going to be, you know, a monomial", "tokens": [50364, 437, 321, 17421, 294, 8132, 11, 6549, 13, 407, 264, 42761, 2445, 307, 445, 516, 281, 312, 11, 291, 458, 11, 257, 1108, 47429, 50876, 50944, 2445, 295, 264, 2369, 564, 326, 952, 13, 663, 311, 309, 13, 407, 321, 445, 362, 257, 2408, 295, 512, 9834, 300, 321, 1466, 538, 51260, 51260, 646, 38377, 343, 42, 293, 2369, 564, 326, 952, 281, 264, 1347, 295, 591, 13, 1033, 13, 407, 11, 370, 562, 321, 360, 300, 11, 700, 456, 307, 51736, 51736], "temperature": 0.0, "avg_logprob": -0.1641047758214614, "compression_ratio": 1.4846938775510203, "no_speech_prob": 7.403595645882888e-06}, {"id": 467, "seek": 318892, "start": 3200.52, "end": 3206.84, "text": " function of the Laplacian. That's it. So we just have a sum of some parameters that we learn by", "tokens": [50364, 437, 321, 17421, 294, 8132, 11, 6549, 13, 407, 264, 42761, 2445, 307, 445, 516, 281, 312, 11, 291, 458, 11, 257, 1108, 47429, 50876, 50944, 2445, 295, 264, 2369, 564, 326, 952, 13, 663, 311, 309, 13, 407, 321, 445, 362, 257, 2408, 295, 512, 9834, 300, 321, 1466, 538, 51260, 51260, 646, 38377, 343, 42, 293, 2369, 564, 326, 952, 281, 264, 1347, 295, 591, 13, 1033, 13, 407, 11, 370, 562, 321, 360, 300, 11, 700, 456, 307, 51736, 51736], "temperature": 0.0, "avg_logprob": -0.1641047758214614, "compression_ratio": 1.4846938775510203, "no_speech_prob": 7.403595645882888e-06}, {"id": 468, "seek": 318892, "start": 3206.84, "end": 3216.36, "text": " back propagation WK and Laplacian to the power of K. Okay. So, so when we do that, first there is", "tokens": [50364, 437, 321, 17421, 294, 8132, 11, 6549, 13, 407, 264, 42761, 2445, 307, 445, 516, 281, 312, 11, 291, 458, 11, 257, 1108, 47429, 50876, 50944, 2445, 295, 264, 2369, 564, 326, 952, 13, 663, 311, 309, 13, 407, 321, 445, 362, 257, 2408, 295, 512, 9834, 300, 321, 1466, 538, 51260, 51260, 646, 38377, 343, 42, 293, 2369, 564, 326, 952, 281, 264, 1347, 295, 591, 13, 1033, 13, 407, 11, 370, 562, 321, 360, 300, 11, 700, 456, 307, 51736, 51736], "temperature": 0.0, "avg_logprob": -0.1641047758214614, "compression_ratio": 1.4846938775510203, "no_speech_prob": 7.403595645882888e-06}, {"id": 469, "seek": 321636, "start": 3216.36, "end": 3223.32, "text": " something which is, which is good is that we're going to have features that are exactly localized", "tokens": [50364, 746, 597, 307, 11, 597, 307, 665, 307, 300, 321, 434, 516, 281, 362, 4122, 300, 366, 2293, 44574, 50712, 50712, 294, 257, 2141, 3818, 1406, 13, 1033, 13, 407, 498, 321, 362, 264, 3861, 281, 264, 1347, 295, 591, 11, 264, 42761, 11, 51012, 51072, 286, 914, 11, 264, 2121, 4122, 486, 312, 2293, 44574, 294, 264, 1406, 295, 2141, 3818, 13, 407, 437, 307, 11, 51344, 51344, 437, 307, 264, 472, 3818, 5987, 7630, 30, 407, 718, 311, 584, 11, 337, 1365, 11, 291, 362, 341, 4295, 51644, 51644], "temperature": 0.0, "avg_logprob": -0.1854508512763567, "compression_ratio": 1.7302325581395348, "no_speech_prob": 9.956475878425408e-06}, {"id": 470, "seek": 321636, "start": 3223.32, "end": 3229.32, "text": " in a key hop support. Okay. So if we have the application to the power of K, the spectral,", "tokens": [50364, 746, 597, 307, 11, 597, 307, 665, 307, 300, 321, 434, 516, 281, 362, 4122, 300, 366, 2293, 44574, 50712, 50712, 294, 257, 2141, 3818, 1406, 13, 1033, 13, 407, 498, 321, 362, 264, 3861, 281, 264, 1347, 295, 591, 11, 264, 42761, 11, 51012, 51072, 286, 914, 11, 264, 2121, 4122, 486, 312, 2293, 44574, 294, 264, 1406, 295, 2141, 3818, 13, 407, 437, 307, 11, 51344, 51344, 437, 307, 264, 472, 3818, 5987, 7630, 30, 407, 718, 311, 584, 11, 337, 1365, 11, 291, 362, 341, 4295, 51644, 51644], "temperature": 0.0, "avg_logprob": -0.1854508512763567, "compression_ratio": 1.7302325581395348, "no_speech_prob": 9.956475878425408e-06}, {"id": 471, "seek": 321636, "start": 3230.52, "end": 3235.96, "text": " I mean, the special features will be exactly localized in the support of key hop. So what is,", "tokens": [50364, 746, 597, 307, 11, 597, 307, 665, 307, 300, 321, 434, 516, 281, 362, 4122, 300, 366, 2293, 44574, 50712, 50712, 294, 257, 2141, 3818, 1406, 13, 1033, 13, 407, 498, 321, 362, 264, 3861, 281, 264, 1347, 295, 591, 11, 264, 42761, 11, 51012, 51072, 286, 914, 11, 264, 2121, 4122, 486, 312, 2293, 44574, 294, 264, 1406, 295, 2141, 3818, 13, 407, 437, 307, 11, 51344, 51344, 437, 307, 264, 472, 3818, 5987, 7630, 30, 407, 718, 311, 584, 11, 337, 1365, 11, 291, 362, 341, 4295, 51644, 51644], "temperature": 0.0, "avg_logprob": -0.1854508512763567, "compression_ratio": 1.7302325581395348, "no_speech_prob": 9.956475878425408e-06}, {"id": 472, "seek": 321636, "start": 3235.96, "end": 3241.96, "text": " what is the one hop neighbor neighborhood? So let's say, for example, you have this graph", "tokens": [50364, 746, 597, 307, 11, 597, 307, 665, 307, 300, 321, 434, 516, 281, 362, 4122, 300, 366, 2293, 44574, 50712, 50712, 294, 257, 2141, 3818, 1406, 13, 1033, 13, 407, 498, 321, 362, 264, 3861, 281, 264, 1347, 295, 591, 11, 264, 42761, 11, 51012, 51072, 286, 914, 11, 264, 2121, 4122, 486, 312, 2293, 44574, 294, 264, 1406, 295, 2141, 3818, 13, 407, 437, 307, 11, 51344, 51344, 437, 307, 264, 472, 3818, 5987, 7630, 30, 407, 718, 311, 584, 11, 337, 1365, 11, 291, 362, 341, 4295, 51644, 51644], "temperature": 0.0, "avg_logprob": -0.1854508512763567, "compression_ratio": 1.7302325581395348, "no_speech_prob": 9.956475878425408e-06}, {"id": 473, "seek": 324196, "start": 3241.96, "end": 3247.48, "text": " and here I'm going to put a hit source. So the value is going to be one at this node and zero", "tokens": [50364, 293, 510, 286, 478, 516, 281, 829, 257, 2045, 4009, 13, 407, 264, 2158, 307, 516, 281, 312, 472, 412, 341, 9984, 293, 4018, 50640, 50640, 337, 439, 661, 13891, 13, 759, 286, 3079, 264, 2369, 564, 326, 952, 281, 341, 2045, 4009, 11, 550, 264, 6358, 11, 264, 1406, 295, 50932, 50932, 264, 6358, 307, 516, 281, 312, 6505, 538, 472, 3818, 13, 407, 633, 1936, 633, 13891, 300, 393, 312, 6488, 51296, 51296, 538, 472, 1691, 13, 1033, 13, 663, 291, 360, 300, 13, 400, 11, 293, 498, 291, 360, 732, 16704, 490, 341, 11, 291, 486, 11, 291, 486, 2524, 51660, 51660], "temperature": 0.0, "avg_logprob": -0.126518730805299, "compression_ratio": 1.7533632286995515, "no_speech_prob": 2.0239947843947448e-05}, {"id": 474, "seek": 324196, "start": 3247.48, "end": 3253.32, "text": " for all other nodes. If I apply the Laplacian to this hit source, then the signal, the support of", "tokens": [50364, 293, 510, 286, 478, 516, 281, 829, 257, 2045, 4009, 13, 407, 264, 2158, 307, 516, 281, 312, 472, 412, 341, 9984, 293, 4018, 50640, 50640, 337, 439, 661, 13891, 13, 759, 286, 3079, 264, 2369, 564, 326, 952, 281, 341, 2045, 4009, 11, 550, 264, 6358, 11, 264, 1406, 295, 50932, 50932, 264, 6358, 307, 516, 281, 312, 6505, 538, 472, 3818, 13, 407, 633, 1936, 633, 13891, 300, 393, 312, 6488, 51296, 51296, 538, 472, 1691, 13, 1033, 13, 663, 291, 360, 300, 13, 400, 11, 293, 498, 291, 360, 732, 16704, 490, 341, 11, 291, 486, 11, 291, 486, 2524, 51660, 51660], "temperature": 0.0, "avg_logprob": -0.126518730805299, "compression_ratio": 1.7533632286995515, "no_speech_prob": 2.0239947843947448e-05}, {"id": 475, "seek": 324196, "start": 3253.32, "end": 3260.6, "text": " the signal is going to be increased by one hop. So every basically every nodes that can be reached", "tokens": [50364, 293, 510, 286, 478, 516, 281, 829, 257, 2045, 4009, 13, 407, 264, 2158, 307, 516, 281, 312, 472, 412, 341, 9984, 293, 4018, 50640, 50640, 337, 439, 661, 13891, 13, 759, 286, 3079, 264, 2369, 564, 326, 952, 281, 341, 2045, 4009, 11, 550, 264, 6358, 11, 264, 1406, 295, 50932, 50932, 264, 6358, 307, 516, 281, 312, 6505, 538, 472, 3818, 13, 407, 633, 1936, 633, 13891, 300, 393, 312, 6488, 51296, 51296, 538, 472, 1691, 13, 1033, 13, 663, 291, 360, 300, 13, 400, 11, 293, 498, 291, 360, 732, 16704, 490, 341, 11, 291, 486, 11, 291, 486, 2524, 51660, 51660], "temperature": 0.0, "avg_logprob": -0.126518730805299, "compression_ratio": 1.7533632286995515, "no_speech_prob": 2.0239947843947448e-05}, {"id": 476, "seek": 324196, "start": 3260.6, "end": 3267.88, "text": " by one job. Okay. That you do that. And, and if you do two jumps from this, you will, you will reach", "tokens": [50364, 293, 510, 286, 478, 516, 281, 829, 257, 2045, 4009, 13, 407, 264, 2158, 307, 516, 281, 312, 472, 412, 341, 9984, 293, 4018, 50640, 50640, 337, 439, 661, 13891, 13, 759, 286, 3079, 264, 2369, 564, 326, 952, 281, 341, 2045, 4009, 11, 550, 264, 6358, 11, 264, 1406, 295, 50932, 50932, 264, 6358, 307, 516, 281, 312, 6505, 538, 472, 3818, 13, 407, 633, 1936, 633, 13891, 300, 393, 312, 6488, 51296, 51296, 538, 472, 1691, 13, 1033, 13, 663, 291, 360, 300, 13, 400, 11, 293, 498, 291, 360, 732, 16704, 490, 341, 11, 291, 486, 11, 291, 486, 2524, 51660, 51660], "temperature": 0.0, "avg_logprob": -0.126518730805299, "compression_ratio": 1.7533632286995515, "no_speech_prob": 2.0239947843947448e-05}, {"id": 477, "seek": 326788, "start": 3267.88, "end": 3276.6, "text": " the, the second hop neighborhood, which is your range, the orange nodes here. Okay. So if you", "tokens": [50364, 264, 11, 264, 1150, 3818, 7630, 11, 597, 307, 428, 3613, 11, 264, 7671, 13891, 510, 13, 1033, 13, 407, 498, 291, 50800, 50800, 3079, 264, 2369, 564, 326, 952, 732, 1413, 11, 341, 307, 516, 281, 312, 264, 1406, 13, 1033, 13, 759, 291, 3079, 264, 2369, 564, 326, 952, 51044, 51044, 591, 1413, 11, 550, 291, 486, 362, 257, 1406, 295, 591, 47579, 13, 407, 291, 11, 291, 2293, 1969, 264, 11, 264, 2744, 295, 428, 51384, 51384, 23598, 15995, 13, 1033, 13, 407, 300, 11, 300, 390, 264, 700, 935, 13, 440, 1150, 935, 11, 718, 385, 855, 291, 300, 291, 51788, 51788], "temperature": 0.0, "avg_logprob": -0.13842535901952674, "compression_ratio": 1.7808219178082192, "no_speech_prob": 1.162052467407193e-05}, {"id": 478, "seek": 326788, "start": 3276.6, "end": 3281.48, "text": " apply the Laplacian two times, this is going to be the support. Okay. If you apply the Laplacian", "tokens": [50364, 264, 11, 264, 1150, 3818, 7630, 11, 597, 307, 428, 3613, 11, 264, 7671, 13891, 510, 13, 1033, 13, 407, 498, 291, 50800, 50800, 3079, 264, 2369, 564, 326, 952, 732, 1413, 11, 341, 307, 516, 281, 312, 264, 1406, 13, 1033, 13, 759, 291, 3079, 264, 2369, 564, 326, 952, 51044, 51044, 591, 1413, 11, 550, 291, 486, 362, 257, 1406, 295, 591, 47579, 13, 407, 291, 11, 291, 2293, 1969, 264, 11, 264, 2744, 295, 428, 51384, 51384, 23598, 15995, 13, 1033, 13, 407, 300, 11, 300, 390, 264, 700, 935, 13, 440, 1150, 935, 11, 718, 385, 855, 291, 300, 291, 51788, 51788], "temperature": 0.0, "avg_logprob": -0.13842535901952674, "compression_ratio": 1.7808219178082192, "no_speech_prob": 1.162052467407193e-05}, {"id": 479, "seek": 326788, "start": 3281.48, "end": 3288.28, "text": " K times, then you will have a support of K hops. So you, you exactly control the, the size of your", "tokens": [50364, 264, 11, 264, 1150, 3818, 7630, 11, 597, 307, 428, 3613, 11, 264, 7671, 13891, 510, 13, 1033, 13, 407, 498, 291, 50800, 50800, 3079, 264, 2369, 564, 326, 952, 732, 1413, 11, 341, 307, 516, 281, 312, 264, 1406, 13, 1033, 13, 759, 291, 3079, 264, 2369, 564, 326, 952, 51044, 51044, 591, 1413, 11, 550, 291, 486, 362, 257, 1406, 295, 591, 47579, 13, 407, 291, 11, 291, 2293, 1969, 264, 11, 264, 2744, 295, 428, 51384, 51384, 23598, 15995, 13, 1033, 13, 407, 300, 11, 300, 390, 264, 700, 935, 13, 440, 1150, 935, 11, 718, 385, 855, 291, 300, 291, 51788, 51788], "temperature": 0.0, "avg_logprob": -0.13842535901952674, "compression_ratio": 1.7808219178082192, "no_speech_prob": 1.162052467407193e-05}, {"id": 480, "seek": 326788, "start": 3288.28, "end": 3296.36, "text": " spatial filters. Okay. So that, that was the first point. The second point, let me show you that you", "tokens": [50364, 264, 11, 264, 1150, 3818, 7630, 11, 597, 307, 428, 3613, 11, 264, 7671, 13891, 510, 13, 1033, 13, 407, 498, 291, 50800, 50800, 3079, 264, 2369, 564, 326, 952, 732, 1413, 11, 341, 307, 516, 281, 312, 264, 1406, 13, 1033, 13, 759, 291, 3079, 264, 2369, 564, 326, 952, 51044, 51044, 591, 1413, 11, 550, 291, 486, 362, 257, 1406, 295, 591, 47579, 13, 407, 291, 11, 291, 2293, 1969, 264, 11, 264, 2744, 295, 428, 51384, 51384, 23598, 15995, 13, 1033, 13, 407, 300, 11, 300, 390, 264, 700, 935, 13, 440, 1150, 935, 11, 718, 385, 855, 291, 300, 291, 51788, 51788], "temperature": 0.0, "avg_logprob": -0.13842535901952674, "compression_ratio": 1.7808219178082192, "no_speech_prob": 1.162052467407193e-05}, {"id": 481, "seek": 329636, "start": 3296.36, "end": 3305.32, "text": " get learning complexity. Okay. So, so again, you have your convolution, W H you have your spectral", "tokens": [50364, 483, 2539, 14024, 13, 1033, 13, 407, 11, 370, 797, 11, 291, 362, 428, 45216, 11, 343, 389, 291, 362, 428, 42761, 50812, 50812, 45216, 7123, 13, 286, 478, 1228, 510, 382, 257, 42761, 45216, 1108, 298, 12356, 295, 264, 11, 295, 264, 51192, 51192, 2369, 564, 326, 952, 13, 400, 550, 286, 478, 516, 281, 7406, 341, 2146, 13, 407, 264, 2369, 564, 326, 952, 1347, 295, 591, 1413, 264, 8062, 389, 51548, 51548], "temperature": 0.0, "avg_logprob": -0.1669553162215592, "compression_ratio": 1.6627906976744187, "no_speech_prob": 8.922625966079067e-06}, {"id": 482, "seek": 329636, "start": 3305.32, "end": 3312.92, "text": " convolution definition. I'm using here as a spectral convolution monomials of the, of the", "tokens": [50364, 483, 2539, 14024, 13, 1033, 13, 407, 11, 370, 797, 11, 291, 362, 428, 45216, 11, 343, 389, 291, 362, 428, 42761, 50812, 50812, 45216, 7123, 13, 286, 478, 1228, 510, 382, 257, 42761, 45216, 1108, 298, 12356, 295, 264, 11, 295, 264, 51192, 51192, 2369, 564, 326, 952, 13, 400, 550, 286, 478, 516, 281, 7406, 341, 2146, 13, 407, 264, 2369, 564, 326, 952, 1347, 295, 591, 1413, 264, 8062, 389, 51548, 51548], "temperature": 0.0, "avg_logprob": -0.1669553162215592, "compression_ratio": 1.6627906976744187, "no_speech_prob": 8.922625966079067e-06}, {"id": 483, "seek": 329636, "start": 3312.92, "end": 3320.04, "text": " Laplacian. And then I'm going to replace this guy. So the Laplacian power of K times the vector H", "tokens": [50364, 483, 2539, 14024, 13, 1033, 13, 407, 11, 370, 797, 11, 291, 362, 428, 45216, 11, 343, 389, 291, 362, 428, 42761, 50812, 50812, 45216, 7123, 13, 286, 478, 1228, 510, 382, 257, 42761, 45216, 1108, 298, 12356, 295, 264, 11, 295, 264, 51192, 51192, 2369, 564, 326, 952, 13, 400, 550, 286, 478, 516, 281, 7406, 341, 2146, 13, 407, 264, 2369, 564, 326, 952, 1347, 295, 591, 1413, 264, 8062, 389, 51548, 51548], "temperature": 0.0, "avg_logprob": -0.1669553162215592, "compression_ratio": 1.6627906976744187, "no_speech_prob": 8.922625966079067e-06}, {"id": 484, "seek": 332004, "start": 3320.04, "end": 3328.36, "text": " by the vector X K. Okay. And X K is actually given by your recursive equation. Okay. So recursive is", "tokens": [50364, 538, 264, 8062, 1783, 591, 13, 1033, 13, 400, 1783, 591, 307, 767, 2212, 538, 428, 20560, 488, 5367, 13, 1033, 13, 407, 20560, 488, 307, 50780, 50780, 1009, 665, 13, 1779, 13, 407, 309, 311, 516, 281, 312, 341, 20560, 488, 5367, 11, 597, 307, 264, 2369, 564, 326, 952, 51004, 51056, 1413, 264, 8062, 1783, 591, 3175, 472, 293, 264, 1783, 591, 2681, 281, 4018, 307, 2935, 264, 3380, 2445, 389, 13, 1033, 13, 51492, 51568], "temperature": 0.0, "avg_logprob": -0.18130278587341309, "compression_ratio": 1.580110497237569, "no_speech_prob": 2.250063516839873e-05}, {"id": 485, "seek": 332004, "start": 3328.36, "end": 3332.84, "text": " always good. Right. So it's going to be this recursive equation, which is the Laplacian", "tokens": [50364, 538, 264, 8062, 1783, 591, 13, 1033, 13, 400, 1783, 591, 307, 767, 2212, 538, 428, 20560, 488, 5367, 13, 1033, 13, 407, 20560, 488, 307, 50780, 50780, 1009, 665, 13, 1779, 13, 407, 309, 311, 516, 281, 312, 341, 20560, 488, 5367, 11, 597, 307, 264, 2369, 564, 326, 952, 51004, 51056, 1413, 264, 8062, 1783, 591, 3175, 472, 293, 264, 1783, 591, 2681, 281, 4018, 307, 2935, 264, 3380, 2445, 389, 13, 1033, 13, 51492, 51568], "temperature": 0.0, "avg_logprob": -0.18130278587341309, "compression_ratio": 1.580110497237569, "no_speech_prob": 2.250063516839873e-05}, {"id": 486, "seek": 332004, "start": 3333.88, "end": 3342.6, "text": " times the vector X K minus one and the X K equal to zero is simply the original function H. Okay.", "tokens": [50364, 538, 264, 8062, 1783, 591, 13, 1033, 13, 400, 1783, 591, 307, 767, 2212, 538, 428, 20560, 488, 5367, 13, 1033, 13, 407, 20560, 488, 307, 50780, 50780, 1009, 665, 13, 1779, 13, 407, 309, 311, 516, 281, 312, 341, 20560, 488, 5367, 11, 597, 307, 264, 2369, 564, 326, 952, 51004, 51056, 1413, 264, 8062, 1783, 591, 3175, 472, 293, 264, 1783, 591, 2681, 281, 4018, 307, 2935, 264, 3380, 2445, 389, 13, 1033, 13, 51492, 51568], "temperature": 0.0, "avg_logprob": -0.18130278587341309, "compression_ratio": 1.580110497237569, "no_speech_prob": 2.250063516839873e-05}, {"id": 487, "seek": 334260, "start": 3342.6, "end": 3349.88, "text": " So, so when I do that, you see that this sequence X of K is generated by multiplying a matrix.", "tokens": [50364, 407, 11, 370, 562, 286, 360, 300, 11, 291, 536, 300, 341, 8310, 1783, 295, 591, 307, 10833, 538, 30955, 257, 8141, 13, 50728, 50768, 407, 264, 2369, 564, 326, 952, 293, 264, 8062, 1783, 591, 3175, 472, 13, 407, 264, 14024, 295, 884, 300, 307, 264, 1230, 295, 8819, 13, 51100, 51144, 1033, 13, 400, 291, 360, 309, 300, 11, 291, 458, 11, 591, 1413, 13, 407, 1230, 295, 8819, 1413, 591, 13, 400, 264, 551, 307, 337, 957, 51520, 51520], "temperature": 0.0, "avg_logprob": -0.22938671566191174, "compression_ratio": 1.5336787564766838, "no_speech_prob": 8.707695997145493e-06}, {"id": 488, "seek": 334260, "start": 3350.68, "end": 3357.3199999999997, "text": " So the Laplacian and the vector X K minus one. So the complexity of doing that is the number of edges.", "tokens": [50364, 407, 11, 370, 562, 286, 360, 300, 11, 291, 536, 300, 341, 8310, 1783, 295, 591, 307, 10833, 538, 30955, 257, 8141, 13, 50728, 50768, 407, 264, 2369, 564, 326, 952, 293, 264, 8062, 1783, 591, 3175, 472, 13, 407, 264, 14024, 295, 884, 300, 307, 264, 1230, 295, 8819, 13, 51100, 51144, 1033, 13, 400, 291, 360, 309, 300, 11, 291, 458, 11, 591, 1413, 13, 407, 1230, 295, 8819, 1413, 591, 13, 400, 264, 551, 307, 337, 957, 51520, 51520], "temperature": 0.0, "avg_logprob": -0.22938671566191174, "compression_ratio": 1.5336787564766838, "no_speech_prob": 8.707695997145493e-06}, {"id": 489, "seek": 334260, "start": 3358.2, "end": 3365.72, "text": " Okay. And you do it that, you know, K times. So number of edges times K. And the thing is for real", "tokens": [50364, 407, 11, 370, 562, 286, 360, 300, 11, 291, 536, 300, 341, 8310, 1783, 295, 591, 307, 10833, 538, 30955, 257, 8141, 13, 50728, 50768, 407, 264, 2369, 564, 326, 952, 293, 264, 8062, 1783, 591, 3175, 472, 13, 407, 264, 14024, 295, 884, 300, 307, 264, 1230, 295, 8819, 13, 51100, 51144, 1033, 13, 400, 291, 360, 309, 300, 11, 291, 458, 11, 591, 1413, 13, 407, 1230, 295, 8819, 1413, 591, 13, 400, 264, 551, 307, 337, 957, 51520, 51520], "temperature": 0.0, "avg_logprob": -0.22938671566191174, "compression_ratio": 1.5336787564766838, "no_speech_prob": 8.707695997145493e-06}, {"id": 490, "seek": 336572, "start": 3365.72, "end": 3373.64, "text": " graph, real world graphs, basically they are all sparse. Okay. Because sparsity is structure.", "tokens": [50364, 4295, 11, 957, 1002, 24877, 11, 1936, 436, 366, 439, 637, 11668, 13, 1033, 13, 1436, 637, 685, 507, 307, 3877, 13, 50760, 50760, 407, 1604, 11, 337, 1365, 11, 337, 11, 337, 11, 337, 264, 3670, 11, 264, 3670, 575, 17375, 295, 11, 295, 3670, 7183, 11, 51172, 51172, 457, 337, 1184, 3670, 3028, 11, 309, 307, 364, 4274, 4582, 281, 2625, 661, 3670, 3028, 13, 407, 15763, 2625, 281, 472, 5218, 51532, 51532, 307, 1825, 13, 407, 2673, 11, 293, 264, 912, 611, 337, 264, 3567, 11, 264, 3567, 11, 309, 311, 588, 1090, 637, 11668, 13, 440, 912, 51844, 51844], "temperature": 0.0, "avg_logprob": -0.14664263952346074, "compression_ratio": 1.7066666666666668, "no_speech_prob": 1.9163637261954136e-05}, {"id": 491, "seek": 336572, "start": 3373.64, "end": 3381.8799999999997, "text": " So remember, for example, for, for, for the web, the web has billions of, of web pages,", "tokens": [50364, 4295, 11, 957, 1002, 24877, 11, 1936, 436, 366, 439, 637, 11668, 13, 1033, 13, 1436, 637, 685, 507, 307, 3877, 13, 50760, 50760, 407, 1604, 11, 337, 1365, 11, 337, 11, 337, 11, 337, 264, 3670, 11, 264, 3670, 575, 17375, 295, 11, 295, 3670, 7183, 11, 51172, 51172, 457, 337, 1184, 3670, 3028, 11, 309, 307, 364, 4274, 4582, 281, 2625, 661, 3670, 3028, 13, 407, 15763, 2625, 281, 472, 5218, 51532, 51532, 307, 1825, 13, 407, 2673, 11, 293, 264, 912, 611, 337, 264, 3567, 11, 264, 3567, 11, 309, 311, 588, 1090, 637, 11668, 13, 440, 912, 51844, 51844], "temperature": 0.0, "avg_logprob": -0.14664263952346074, "compression_ratio": 1.7066666666666668, "no_speech_prob": 1.9163637261954136e-05}, {"id": 492, "seek": 336572, "start": 3381.8799999999997, "end": 3389.08, "text": " but for each web page, it is an average connected to 50 other web page. So comparing 50 to one billion", "tokens": [50364, 4295, 11, 957, 1002, 24877, 11, 1936, 436, 366, 439, 637, 11668, 13, 1033, 13, 1436, 637, 685, 507, 307, 3877, 13, 50760, 50760, 407, 1604, 11, 337, 1365, 11, 337, 11, 337, 11, 337, 264, 3670, 11, 264, 3670, 575, 17375, 295, 11, 295, 3670, 7183, 11, 51172, 51172, 457, 337, 1184, 3670, 3028, 11, 309, 307, 364, 4274, 4582, 281, 2625, 661, 3670, 3028, 13, 407, 15763, 2625, 281, 472, 5218, 51532, 51532, 307, 1825, 13, 407, 2673, 11, 293, 264, 912, 611, 337, 264, 3567, 11, 264, 3567, 11, 309, 311, 588, 1090, 637, 11668, 13, 440, 912, 51844, 51844], "temperature": 0.0, "avg_logprob": -0.14664263952346074, "compression_ratio": 1.7066666666666668, "no_speech_prob": 1.9163637261954136e-05}, {"id": 493, "seek": 336572, "start": 3389.08, "end": 3395.3199999999997, "text": " is nothing. So usually, and the same also for the brain, the brain, it's very high sparse. The same", "tokens": [50364, 4295, 11, 957, 1002, 24877, 11, 1936, 436, 366, 439, 637, 11668, 13, 1033, 13, 1436, 637, 685, 507, 307, 3877, 13, 50760, 50760, 407, 1604, 11, 337, 1365, 11, 337, 11, 337, 11, 337, 264, 3670, 11, 264, 3670, 575, 17375, 295, 11, 295, 3670, 7183, 11, 51172, 51172, 457, 337, 1184, 3670, 3028, 11, 309, 307, 364, 4274, 4582, 281, 2625, 661, 3670, 3028, 13, 407, 15763, 2625, 281, 472, 5218, 51532, 51532, 307, 1825, 13, 407, 2673, 11, 293, 264, 912, 611, 337, 264, 3567, 11, 264, 3567, 11, 309, 311, 588, 1090, 637, 11668, 13, 440, 912, 51844, 51844], "temperature": 0.0, "avg_logprob": -0.14664263952346074, "compression_ratio": 1.7066666666666668, "no_speech_prob": 1.9163637261954136e-05}, {"id": 494, "seek": 339532, "start": 3395.32, "end": 3401.7200000000003, "text": " also for transport networks. So everything, every natural graph is usually sparse because sparsity", "tokens": [50364, 611, 337, 5495, 9590, 13, 407, 1203, 11, 633, 3303, 4295, 307, 2673, 637, 11668, 570, 637, 685, 507, 50684, 50684, 307, 3877, 13, 1033, 13, 407, 11, 370, 264, 1230, 295, 8819, 307, 11, 291, 458, 11, 512, 2158, 1413, 426, 13, 407, 412, 264, 917, 51020, 51020, 295, 264, 786, 11, 291, 362, 8213, 14024, 570, 337, 637, 11668, 957, 1002, 24877, 13, 1033, 13, 1033, 13, 407, 11, 51476, 51476, 293, 291, 536, 510, 307, 300, 286, 478, 1228, 264, 2369, 564, 326, 952, 293, 286, 1128, 360, 604, 6575, 12686, 295, 264, 51752, 51752], "temperature": 0.0, "avg_logprob": -0.11635704994201661, "compression_ratio": 1.61864406779661, "no_speech_prob": 1.4919712157279719e-05}, {"id": 495, "seek": 339532, "start": 3401.7200000000003, "end": 3408.44, "text": " is structure. Okay. So, so the number of edges is, you know, some value times N. So at the end", "tokens": [50364, 611, 337, 5495, 9590, 13, 407, 1203, 11, 633, 3303, 4295, 307, 2673, 637, 11668, 570, 637, 685, 507, 50684, 50684, 307, 3877, 13, 1033, 13, 407, 11, 370, 264, 1230, 295, 8819, 307, 11, 291, 458, 11, 512, 2158, 1413, 426, 13, 407, 412, 264, 917, 51020, 51020, 295, 264, 786, 11, 291, 362, 8213, 14024, 570, 337, 637, 11668, 957, 1002, 24877, 13, 1033, 13, 1033, 13, 407, 11, 51476, 51476, 293, 291, 536, 510, 307, 300, 286, 478, 1228, 264, 2369, 564, 326, 952, 293, 286, 1128, 360, 604, 6575, 12686, 295, 264, 51752, 51752], "temperature": 0.0, "avg_logprob": -0.11635704994201661, "compression_ratio": 1.61864406779661, "no_speech_prob": 1.4919712157279719e-05}, {"id": 496, "seek": 339532, "start": 3408.44, "end": 3417.56, "text": " of the day, you have linear complexity because for sparse real world graphs. Okay. Okay. So,", "tokens": [50364, 611, 337, 5495, 9590, 13, 407, 1203, 11, 633, 3303, 4295, 307, 2673, 637, 11668, 570, 637, 685, 507, 50684, 50684, 307, 3877, 13, 1033, 13, 407, 11, 370, 264, 1230, 295, 8819, 307, 11, 291, 458, 11, 512, 2158, 1413, 426, 13, 407, 412, 264, 917, 51020, 51020, 295, 264, 786, 11, 291, 362, 8213, 14024, 570, 337, 637, 11668, 957, 1002, 24877, 13, 1033, 13, 1033, 13, 407, 11, 51476, 51476, 293, 291, 536, 510, 307, 300, 286, 478, 1228, 264, 2369, 564, 326, 952, 293, 286, 1128, 360, 604, 6575, 12686, 295, 264, 51752, 51752], "temperature": 0.0, "avg_logprob": -0.11635704994201661, "compression_ratio": 1.61864406779661, "no_speech_prob": 1.4919712157279719e-05}, {"id": 497, "seek": 339532, "start": 3417.56, "end": 3423.0800000000004, "text": " and you see here is that I'm using the Laplacian and I never do any identity composition of the", "tokens": [50364, 611, 337, 5495, 9590, 13, 407, 1203, 11, 633, 3303, 4295, 307, 2673, 637, 11668, 570, 637, 685, 507, 50684, 50684, 307, 3877, 13, 1033, 13, 407, 11, 370, 264, 1230, 295, 8819, 307, 11, 291, 458, 11, 512, 2158, 1413, 426, 13, 407, 412, 264, 917, 51020, 51020, 295, 264, 786, 11, 291, 362, 8213, 14024, 570, 337, 637, 11668, 957, 1002, 24877, 13, 1033, 13, 1033, 13, 407, 11, 51476, 51476, 293, 291, 536, 510, 307, 300, 286, 478, 1228, 264, 2369, 564, 326, 952, 293, 286, 1128, 360, 604, 6575, 12686, 295, 264, 51752, 51752], "temperature": 0.0, "avg_logprob": -0.11635704994201661, "compression_ratio": 1.61864406779661, "no_speech_prob": 1.4919712157279719e-05}, {"id": 498, "seek": 342308, "start": 3423.08, "end": 3433.0, "text": " Laplacian. Okay. And there is, so there is a bit of, of confusion that sometimes I see is that,", "tokens": [50364, 2369, 564, 326, 952, 13, 1033, 13, 400, 456, 307, 11, 370, 456, 307, 257, 857, 295, 11, 295, 15075, 300, 2171, 286, 536, 307, 300, 11, 50860, 50860, 370, 286, 818, 341, 42761, 11, 291, 458, 11, 29435, 45, 11, 457, 341, 307, 11, 341, 1062, 312, 3346, 2794, 2112, 570, 286, 500, 380, 360, 604, 51232, 51232, 42761, 7705, 13, 1743, 11, 291, 458, 11, 286, 500, 380, 764, 604, 6575, 12686, 365, 264, 2369, 564, 326, 952, 13, 286, 500, 380, 51572, 51572, 362, 604, 10446, 303, 5547, 11, 10446, 46033, 13, 407, 11, 370, 412, 264, 917, 295, 264, 786, 11, 754, 498, 286, 764, 11, 291, 458, 11, 264, 51820, 51820], "temperature": 0.0, "avg_logprob": -0.11515608480421163, "compression_ratio": 1.6824034334763949, "no_speech_prob": 3.290001041023061e-05}, {"id": 499, "seek": 342308, "start": 3433.0, "end": 3440.44, "text": " so I call this spectral, you know, GCN, but this is, this might be misguided because I don't do any", "tokens": [50364, 2369, 564, 326, 952, 13, 1033, 13, 400, 456, 307, 11, 370, 456, 307, 257, 857, 295, 11, 295, 15075, 300, 2171, 286, 536, 307, 300, 11, 50860, 50860, 370, 286, 818, 341, 42761, 11, 291, 458, 11, 29435, 45, 11, 457, 341, 307, 11, 341, 1062, 312, 3346, 2794, 2112, 570, 286, 500, 380, 360, 604, 51232, 51232, 42761, 7705, 13, 1743, 11, 291, 458, 11, 286, 500, 380, 764, 604, 6575, 12686, 365, 264, 2369, 564, 326, 952, 13, 286, 500, 380, 51572, 51572, 362, 604, 10446, 303, 5547, 11, 10446, 46033, 13, 407, 11, 370, 412, 264, 917, 295, 264, 786, 11, 754, 498, 286, 764, 11, 291, 458, 11, 264, 51820, 51820], "temperature": 0.0, "avg_logprob": -0.11515608480421163, "compression_ratio": 1.6824034334763949, "no_speech_prob": 3.290001041023061e-05}, {"id": 500, "seek": 342308, "start": 3440.44, "end": 3447.24, "text": " spectral operations. Like, you know, I don't use any identity composition with the Laplacian. I don't", "tokens": [50364, 2369, 564, 326, 952, 13, 1033, 13, 400, 456, 307, 11, 370, 456, 307, 257, 857, 295, 11, 295, 15075, 300, 2171, 286, 536, 307, 300, 11, 50860, 50860, 370, 286, 818, 341, 42761, 11, 291, 458, 11, 29435, 45, 11, 457, 341, 307, 11, 341, 1062, 312, 3346, 2794, 2112, 570, 286, 500, 380, 360, 604, 51232, 51232, 42761, 7705, 13, 1743, 11, 291, 458, 11, 286, 500, 380, 764, 604, 6575, 12686, 365, 264, 2369, 564, 326, 952, 13, 286, 500, 380, 51572, 51572, 362, 604, 10446, 303, 5547, 11, 10446, 46033, 13, 407, 11, 370, 412, 264, 917, 295, 264, 786, 11, 754, 498, 286, 764, 11, 291, 458, 11, 264, 51820, 51820], "temperature": 0.0, "avg_logprob": -0.11515608480421163, "compression_ratio": 1.6824034334763949, "no_speech_prob": 3.290001041023061e-05}, {"id": 501, "seek": 342308, "start": 3447.24, "end": 3452.2, "text": " have any eigenvectors, eigenvalues. So, so at the end of the day, even if I use, you know, the", "tokens": [50364, 2369, 564, 326, 952, 13, 1033, 13, 400, 456, 307, 11, 370, 456, 307, 257, 857, 295, 11, 295, 15075, 300, 2171, 286, 536, 307, 300, 11, 50860, 50860, 370, 286, 818, 341, 42761, 11, 291, 458, 11, 29435, 45, 11, 457, 341, 307, 11, 341, 1062, 312, 3346, 2794, 2112, 570, 286, 500, 380, 360, 604, 51232, 51232, 42761, 7705, 13, 1743, 11, 291, 458, 11, 286, 500, 380, 764, 604, 6575, 12686, 365, 264, 2369, 564, 326, 952, 13, 286, 500, 380, 51572, 51572, 362, 604, 10446, 303, 5547, 11, 10446, 46033, 13, 407, 11, 370, 412, 264, 917, 295, 264, 786, 11, 754, 498, 286, 764, 11, 291, 458, 11, 264, 51820, 51820], "temperature": 0.0, "avg_logprob": -0.11515608480421163, "compression_ratio": 1.6824034334763949, "no_speech_prob": 3.290001041023061e-05}, {"id": 502, "seek": 345220, "start": 3452.2, "end": 3459.7999999999997, "text": " spectral theory to define this GCN, at the end of the day, the computation are all done in the special", "tokens": [50364, 42761, 5261, 281, 6964, 341, 29435, 45, 11, 412, 264, 917, 295, 264, 786, 11, 264, 24903, 366, 439, 1096, 294, 264, 2121, 50744, 50744, 9274, 1228, 264, 2369, 564, 326, 952, 13, 1033, 13, 286, 500, 380, 764, 604, 11, 286, 500, 380, 764, 264, 42761, 9274, 337, 264, 24903, 13, 51116, 51116, 286, 764, 11, 286, 360, 1203, 294, 264, 2121, 9274, 13, 407, 754, 498, 321, 818, 300, 42761, 29435, 45, 11, 321, 500, 380, 51436, 51436, 764, 11, 291, 458, 11, 294, 3124, 11, 264, 42761, 48356, 13, 407, 445, 11, 445, 472, 11, 472, 11, 472, 2871, 13, 51748, 51776], "temperature": 0.0, "avg_logprob": -0.10431514276522343, "compression_ratio": 1.8317757009345794, "no_speech_prob": 1.3191717698646244e-05}, {"id": 503, "seek": 345220, "start": 3459.7999999999997, "end": 3467.24, "text": " domain using the Laplacian. Okay. I don't use any, I don't use the spectral domain for the computation.", "tokens": [50364, 42761, 5261, 281, 6964, 341, 29435, 45, 11, 412, 264, 917, 295, 264, 786, 11, 264, 24903, 366, 439, 1096, 294, 264, 2121, 50744, 50744, 9274, 1228, 264, 2369, 564, 326, 952, 13, 1033, 13, 286, 500, 380, 764, 604, 11, 286, 500, 380, 764, 264, 42761, 9274, 337, 264, 24903, 13, 51116, 51116, 286, 764, 11, 286, 360, 1203, 294, 264, 2121, 9274, 13, 407, 754, 498, 321, 818, 300, 42761, 29435, 45, 11, 321, 500, 380, 51436, 51436, 764, 11, 291, 458, 11, 294, 3124, 11, 264, 42761, 48356, 13, 407, 445, 11, 445, 472, 11, 472, 11, 472, 2871, 13, 51748, 51776], "temperature": 0.0, "avg_logprob": -0.10431514276522343, "compression_ratio": 1.8317757009345794, "no_speech_prob": 1.3191717698646244e-05}, {"id": 504, "seek": 345220, "start": 3467.24, "end": 3473.64, "text": " I use, I do everything in the special domain. So even if we call that spectral GCN, we don't", "tokens": [50364, 42761, 5261, 281, 6964, 341, 29435, 45, 11, 412, 264, 917, 295, 264, 786, 11, 264, 24903, 366, 439, 1096, 294, 264, 2121, 50744, 50744, 9274, 1228, 264, 2369, 564, 326, 952, 13, 1033, 13, 286, 500, 380, 764, 604, 11, 286, 500, 380, 764, 264, 42761, 9274, 337, 264, 24903, 13, 51116, 51116, 286, 764, 11, 286, 360, 1203, 294, 264, 2121, 9274, 13, 407, 754, 498, 321, 818, 300, 42761, 29435, 45, 11, 321, 500, 380, 51436, 51436, 764, 11, 291, 458, 11, 294, 3124, 11, 264, 42761, 48356, 13, 407, 445, 11, 445, 472, 11, 472, 11, 472, 2871, 13, 51748, 51776], "temperature": 0.0, "avg_logprob": -0.10431514276522343, "compression_ratio": 1.8317757009345794, "no_speech_prob": 1.3191717698646244e-05}, {"id": 505, "seek": 345220, "start": 3473.64, "end": 3479.8799999999997, "text": " use, you know, in practice, the spectral decomposition. So just, just one, one, one comment.", "tokens": [50364, 42761, 5261, 281, 6964, 341, 29435, 45, 11, 412, 264, 917, 295, 264, 786, 11, 264, 24903, 366, 439, 1096, 294, 264, 2121, 50744, 50744, 9274, 1228, 264, 2369, 564, 326, 952, 13, 1033, 13, 286, 500, 380, 764, 604, 11, 286, 500, 380, 764, 264, 42761, 9274, 337, 264, 24903, 13, 51116, 51116, 286, 764, 11, 286, 360, 1203, 294, 264, 2121, 9274, 13, 407, 754, 498, 321, 818, 300, 42761, 29435, 45, 11, 321, 500, 380, 51436, 51436, 764, 11, 291, 458, 11, 294, 3124, 11, 264, 42761, 48356, 13, 407, 445, 11, 445, 472, 11, 472, 11, 472, 2871, 13, 51748, 51776], "temperature": 0.0, "avg_logprob": -0.10431514276522343, "compression_ratio": 1.8317757009345794, "no_speech_prob": 1.3191717698646244e-05}, {"id": 506, "seek": 347988, "start": 3479.88, "end": 3484.84, "text": " Okay. And the last, the last comment I want to do is that, so graph convolutional layers, again,", "tokens": [50364, 1033, 13, 400, 264, 1036, 11, 264, 1036, 2871, 286, 528, 281, 360, 307, 300, 11, 370, 4295, 45216, 304, 7914, 11, 797, 11, 50612, 50612, 341, 307, 445, 8213, 7705, 13, 407, 291, 445, 12972, 257, 8062, 11, 257, 8141, 538, 257, 8062, 13, 407, 321, 434, 50928, 50928, 445, 884, 364, 6916, 13, 407, 341, 307, 18407, 9208, 13, 440, 2734, 307, 300, 510, 291, 366, 884, 637, 11668, 8213, 51272, 51272, 21989, 293, 264, 6741, 18407, 366, 406, 26941, 337, 300, 13, 407, 341, 307, 11, 286, 519, 11, 472, 295, 264, 51584, 51584, 15705, 965, 337, 4295, 18161, 9590, 13, 492, 643, 281, 362, 2121, 1602, 8837, 337, 4295, 18161, 51832, 51832], "temperature": 0.0, "avg_logprob": -0.1936965231168068, "compression_ratio": 1.7481751824817517, "no_speech_prob": 6.0438633227022365e-06}, {"id": 507, "seek": 347988, "start": 3484.84, "end": 3491.1600000000003, "text": " this is just linear operations. So you just multiply a vector, a matrix by a vector. So we're", "tokens": [50364, 1033, 13, 400, 264, 1036, 11, 264, 1036, 2871, 286, 528, 281, 360, 307, 300, 11, 370, 4295, 45216, 304, 7914, 11, 797, 11, 50612, 50612, 341, 307, 445, 8213, 7705, 13, 407, 291, 445, 12972, 257, 8062, 11, 257, 8141, 538, 257, 8062, 13, 407, 321, 434, 50928, 50928, 445, 884, 364, 6916, 13, 407, 341, 307, 18407, 9208, 13, 440, 2734, 307, 300, 510, 291, 366, 884, 637, 11668, 8213, 51272, 51272, 21989, 293, 264, 6741, 18407, 366, 406, 26941, 337, 300, 13, 407, 341, 307, 11, 286, 519, 11, 472, 295, 264, 51584, 51584, 15705, 965, 337, 4295, 18161, 9590, 13, 492, 643, 281, 362, 2121, 1602, 8837, 337, 4295, 18161, 51832, 51832], "temperature": 0.0, "avg_logprob": -0.1936965231168068, "compression_ratio": 1.7481751824817517, "no_speech_prob": 6.0438633227022365e-06}, {"id": 508, "seek": 347988, "start": 3491.1600000000003, "end": 3498.04, "text": " just doing an operation. So this is GPU friendly. The issue is that here you are doing sparse linear", "tokens": [50364, 1033, 13, 400, 264, 1036, 11, 264, 1036, 2871, 286, 528, 281, 360, 307, 300, 11, 370, 4295, 45216, 304, 7914, 11, 797, 11, 50612, 50612, 341, 307, 445, 8213, 7705, 13, 407, 291, 445, 12972, 257, 8062, 11, 257, 8141, 538, 257, 8062, 13, 407, 321, 434, 50928, 50928, 445, 884, 364, 6916, 13, 407, 341, 307, 18407, 9208, 13, 440, 2734, 307, 300, 510, 291, 366, 884, 637, 11668, 8213, 51272, 51272, 21989, 293, 264, 6741, 18407, 366, 406, 26941, 337, 300, 13, 407, 341, 307, 11, 286, 519, 11, 472, 295, 264, 51584, 51584, 15705, 965, 337, 4295, 18161, 9590, 13, 492, 643, 281, 362, 2121, 1602, 8837, 337, 4295, 18161, 51832, 51832], "temperature": 0.0, "avg_logprob": -0.1936965231168068, "compression_ratio": 1.7481751824817517, "no_speech_prob": 6.0438633227022365e-06}, {"id": 509, "seek": 347988, "start": 3498.04, "end": 3504.28, "text": " algebra and the existing GPU are not optimized for that. So this is, I think, one of the", "tokens": [50364, 1033, 13, 400, 264, 1036, 11, 264, 1036, 2871, 286, 528, 281, 360, 307, 300, 11, 370, 4295, 45216, 304, 7914, 11, 797, 11, 50612, 50612, 341, 307, 445, 8213, 7705, 13, 407, 291, 445, 12972, 257, 8062, 11, 257, 8141, 538, 257, 8062, 13, 407, 321, 434, 50928, 50928, 445, 884, 364, 6916, 13, 407, 341, 307, 18407, 9208, 13, 440, 2734, 307, 300, 510, 291, 366, 884, 637, 11668, 8213, 51272, 51272, 21989, 293, 264, 6741, 18407, 366, 406, 26941, 337, 300, 13, 407, 341, 307, 11, 286, 519, 11, 472, 295, 264, 51584, 51584, 15705, 965, 337, 4295, 18161, 9590, 13, 492, 643, 281, 362, 2121, 1602, 8837, 337, 4295, 18161, 51832, 51832], "temperature": 0.0, "avg_logprob": -0.1936965231168068, "compression_ratio": 1.7481751824817517, "no_speech_prob": 6.0438633227022365e-06}, {"id": 510, "seek": 347988, "start": 3504.28, "end": 3509.2400000000002, "text": " limitations today for graph neural networks. We need to have specialized hardware for graph neural", "tokens": [50364, 1033, 13, 400, 264, 1036, 11, 264, 1036, 2871, 286, 528, 281, 360, 307, 300, 11, 370, 4295, 45216, 304, 7914, 11, 797, 11, 50612, 50612, 341, 307, 445, 8213, 7705, 13, 407, 291, 445, 12972, 257, 8062, 11, 257, 8141, 538, 257, 8062, 13, 407, 321, 434, 50928, 50928, 445, 884, 364, 6916, 13, 407, 341, 307, 18407, 9208, 13, 440, 2734, 307, 300, 510, 291, 366, 884, 637, 11668, 8213, 51272, 51272, 21989, 293, 264, 6741, 18407, 366, 406, 26941, 337, 300, 13, 407, 341, 307, 11, 286, 519, 11, 472, 295, 264, 51584, 51584, 15705, 965, 337, 4295, 18161, 9590, 13, 492, 643, 281, 362, 2121, 1602, 8837, 337, 4295, 18161, 51832, 51832], "temperature": 0.0, "avg_logprob": -0.1936965231168068, "compression_ratio": 1.7481751824817517, "no_speech_prob": 6.0438633227022365e-06}, {"id": 511, "seek": 350924, "start": 3509.24, "end": 3517.24, "text": " networks. We need to have hardware that adapt to the sparsity of these operations. And we don't have", "tokens": [50364, 9590, 13, 492, 643, 281, 362, 8837, 300, 6231, 281, 264, 637, 685, 507, 295, 613, 7705, 13, 400, 321, 500, 380, 362, 50764, 50764, 341, 965, 13, 407, 498, 321, 528, 341, 281, 483, 1400, 11, 588, 1400, 365, 4295, 18161, 3209, 11, 321, 643, 281, 362, 341, 51116, 51116, 19813, 8837, 13, 708, 466, 314, 8115, 82, 30, 1144, 291, 458, 1968, 314, 8115, 82, 393, 4813, 341, 30, 663, 311, 264, 912, 13, 51384, 51384, 663, 311, 264, 912, 13, 814, 366, 26941, 337, 1577, 11, 291, 458, 11, 8213, 7705, 11, 411, 1577, 32284, 13, 51724, 51756], "temperature": 0.0, "avg_logprob": -0.1969653749928891, "compression_ratio": 1.6652542372881356, "no_speech_prob": 2.3150831111706793e-05}, {"id": 512, "seek": 350924, "start": 3517.24, "end": 3524.2799999999997, "text": " this today. So if we want this to get far, very far with graph neural network, we need to have this", "tokens": [50364, 9590, 13, 492, 643, 281, 362, 8837, 300, 6231, 281, 264, 637, 685, 507, 295, 613, 7705, 13, 400, 321, 500, 380, 362, 50764, 50764, 341, 965, 13, 407, 498, 321, 528, 341, 281, 483, 1400, 11, 588, 1400, 365, 4295, 18161, 3209, 11, 321, 643, 281, 362, 341, 51116, 51116, 19813, 8837, 13, 708, 466, 314, 8115, 82, 30, 1144, 291, 458, 1968, 314, 8115, 82, 393, 4813, 341, 30, 663, 311, 264, 912, 13, 51384, 51384, 663, 311, 264, 912, 13, 814, 366, 26941, 337, 1577, 11, 291, 458, 11, 8213, 7705, 11, 411, 1577, 32284, 13, 51724, 51756], "temperature": 0.0, "avg_logprob": -0.1969653749928891, "compression_ratio": 1.6652542372881356, "no_speech_prob": 2.3150831111706793e-05}, {"id": 513, "seek": 350924, "start": 3524.2799999999997, "end": 3529.64, "text": " specialized hardware. What about TPUs? Do you know whether TPUs can handle this? That's the same.", "tokens": [50364, 9590, 13, 492, 643, 281, 362, 8837, 300, 6231, 281, 264, 637, 685, 507, 295, 613, 7705, 13, 400, 321, 500, 380, 362, 50764, 50764, 341, 965, 13, 407, 498, 321, 528, 341, 281, 483, 1400, 11, 588, 1400, 365, 4295, 18161, 3209, 11, 321, 643, 281, 362, 341, 51116, 51116, 19813, 8837, 13, 708, 466, 314, 8115, 82, 30, 1144, 291, 458, 1968, 314, 8115, 82, 393, 4813, 341, 30, 663, 311, 264, 912, 13, 51384, 51384, 663, 311, 264, 912, 13, 814, 366, 26941, 337, 1577, 11, 291, 458, 11, 8213, 7705, 11, 411, 1577, 32284, 13, 51724, 51756], "temperature": 0.0, "avg_logprob": -0.1969653749928891, "compression_ratio": 1.6652542372881356, "no_speech_prob": 2.3150831111706793e-05}, {"id": 514, "seek": 350924, "start": 3529.64, "end": 3536.4399999999996, "text": " That's the same. They are optimized for full, you know, linear operations, like full matrices.", "tokens": [50364, 9590, 13, 492, 643, 281, 362, 8837, 300, 6231, 281, 264, 637, 685, 507, 295, 613, 7705, 13, 400, 321, 500, 380, 362, 50764, 50764, 341, 965, 13, 407, 498, 321, 528, 341, 281, 483, 1400, 11, 588, 1400, 365, 4295, 18161, 3209, 11, 321, 643, 281, 362, 341, 51116, 51116, 19813, 8837, 13, 708, 466, 314, 8115, 82, 30, 1144, 291, 458, 1968, 314, 8115, 82, 393, 4813, 341, 30, 663, 311, 264, 912, 13, 51384, 51384, 663, 311, 264, 912, 13, 814, 366, 26941, 337, 1577, 11, 291, 458, 11, 8213, 7705, 11, 411, 1577, 32284, 13, 51724, 51756], "temperature": 0.0, "avg_logprob": -0.1969653749928891, "compression_ratio": 1.6652542372881356, "no_speech_prob": 2.3150831111706793e-05}, {"id": 515, "seek": 353644, "start": 3536.44, "end": 3542.36, "text": " They are specialized for that. But if you want to do sparse linear algebra, you need specialized", "tokens": [50364, 814, 366, 19813, 337, 300, 13, 583, 498, 291, 528, 281, 360, 637, 11668, 8213, 21989, 11, 291, 643, 19813, 50660, 50660, 8837, 281, 360, 300, 13, 42109, 13, 2561, 13, 865, 13, 1033, 13, 407, 577, 360, 321, 4445, 11, 51040, 51116, 577, 360, 321, 4445, 341, 30, 407, 337, 1365, 11, 321, 362, 257, 6358, 13, 492, 362, 257, 2445, 7642, 322, 264, 4295, 13, 51484, 51484, 407, 297, 307, 264, 1230, 295, 32053, 295, 428, 4295, 13, 400, 274, 307, 264, 10139, 1860, 295, 51800, 51844], "temperature": 0.0, "avg_logprob": -0.25043843866704585, "compression_ratio": 1.599078341013825, "no_speech_prob": 1.5190273188636638e-05}, {"id": 516, "seek": 353644, "start": 3542.36, "end": 3549.96, "text": " hardware to do that. Gotcha. Thanks. Yeah. Okay. So how do we implement,", "tokens": [50364, 814, 366, 19813, 337, 300, 13, 583, 498, 291, 528, 281, 360, 637, 11668, 8213, 21989, 11, 291, 643, 19813, 50660, 50660, 8837, 281, 360, 300, 13, 42109, 13, 2561, 13, 865, 13, 1033, 13, 407, 577, 360, 321, 4445, 11, 51040, 51116, 577, 360, 321, 4445, 341, 30, 407, 337, 1365, 11, 321, 362, 257, 6358, 13, 492, 362, 257, 2445, 7642, 322, 264, 4295, 13, 51484, 51484, 407, 297, 307, 264, 1230, 295, 32053, 295, 428, 4295, 13, 400, 274, 307, 264, 10139, 1860, 295, 51800, 51844], "temperature": 0.0, "avg_logprob": -0.25043843866704585, "compression_ratio": 1.599078341013825, "no_speech_prob": 1.5190273188636638e-05}, {"id": 517, "seek": 353644, "start": 3551.48, "end": 3558.84, "text": " how do we implement this? So for example, we have a signal. We have a function defined on the graph.", "tokens": [50364, 814, 366, 19813, 337, 300, 13, 583, 498, 291, 528, 281, 360, 637, 11668, 8213, 21989, 11, 291, 643, 19813, 50660, 50660, 8837, 281, 360, 300, 13, 42109, 13, 2561, 13, 865, 13, 1033, 13, 407, 577, 360, 321, 4445, 11, 51040, 51116, 577, 360, 321, 4445, 341, 30, 407, 337, 1365, 11, 321, 362, 257, 6358, 13, 492, 362, 257, 2445, 7642, 322, 264, 4295, 13, 51484, 51484, 407, 297, 307, 264, 1230, 295, 32053, 295, 428, 4295, 13, 400, 274, 307, 264, 10139, 1860, 295, 51800, 51844], "temperature": 0.0, "avg_logprob": -0.25043843866704585, "compression_ratio": 1.599078341013825, "no_speech_prob": 1.5190273188636638e-05}, {"id": 518, "seek": 353644, "start": 3558.84, "end": 3565.16, "text": " So n is the number of vertices of your graph. And d is the dimensionality of", "tokens": [50364, 814, 366, 19813, 337, 300, 13, 583, 498, 291, 528, 281, 360, 637, 11668, 8213, 21989, 11, 291, 643, 19813, 50660, 50660, 8837, 281, 360, 300, 13, 42109, 13, 2561, 13, 865, 13, 1033, 13, 407, 577, 360, 321, 4445, 11, 51040, 51116, 577, 360, 321, 4445, 341, 30, 407, 337, 1365, 11, 321, 362, 257, 6358, 13, 492, 362, 257, 2445, 7642, 322, 264, 4295, 13, 51484, 51484, 407, 297, 307, 264, 1230, 295, 32053, 295, 428, 4295, 13, 400, 274, 307, 264, 10139, 1860, 295, 51800, 51844], "temperature": 0.0, "avg_logprob": -0.25043843866704585, "compression_ratio": 1.599078341013825, "no_speech_prob": 1.5190273188636638e-05}, {"id": 519, "seek": 356516, "start": 3565.16, "end": 3572.68, "text": " of the feature. So for each node, you have a feature or vector of the dimension.", "tokens": [50364, 295, 264, 4111, 13, 407, 337, 1184, 9984, 11, 291, 362, 257, 4111, 420, 8062, 295, 264, 10139, 13, 50740, 50780, 407, 577, 360, 321, 360, 300, 30, 407, 321, 362, 2031, 74, 13, 400, 437, 321, 360, 307, 300, 321, 366, 445, 516, 281, 51016, 51084, 3909, 1507, 281, 360, 445, 8213, 7705, 13, 407, 2031, 74, 366, 516, 281, 312, 18721, 294, 257, 8141, 11, 291, 458, 11, 51476, 51552], "temperature": 0.0, "avg_logprob": -0.15026123459274704, "compression_ratio": 1.5575757575757576, "no_speech_prob": 1.642754432396032e-05}, {"id": 520, "seek": 356516, "start": 3573.48, "end": 3578.2, "text": " So how do we do that? So we have xk. And what we do is that we are just going to", "tokens": [50364, 295, 264, 4111, 13, 407, 337, 1184, 9984, 11, 291, 362, 257, 4111, 420, 8062, 295, 264, 10139, 13, 50740, 50780, 407, 577, 360, 321, 360, 300, 30, 407, 321, 362, 2031, 74, 13, 400, 437, 321, 360, 307, 300, 321, 366, 445, 516, 281, 51016, 51084, 3909, 1507, 281, 360, 445, 8213, 7705, 13, 407, 2031, 74, 366, 516, 281, 312, 18721, 294, 257, 8141, 11, 291, 458, 11, 51476, 51552], "temperature": 0.0, "avg_logprob": -0.15026123459274704, "compression_ratio": 1.5575757575757576, "no_speech_prob": 1.642754432396032e-05}, {"id": 521, "seek": 356516, "start": 3579.56, "end": 3587.3999999999996, "text": " shape stuff to do just linear operations. So xk are going to be arranged in a matrix, you know,", "tokens": [50364, 295, 264, 4111, 13, 407, 337, 1184, 9984, 11, 291, 362, 257, 4111, 420, 8062, 295, 264, 10139, 13, 50740, 50780, 407, 577, 360, 321, 360, 300, 30, 407, 321, 362, 2031, 74, 13, 400, 437, 321, 360, 307, 300, 321, 366, 445, 516, 281, 51016, 51084, 3909, 1507, 281, 360, 445, 8213, 7705, 13, 407, 2031, 74, 366, 516, 281, 312, 18721, 294, 257, 8141, 11, 291, 458, 11, 51476, 51552], "temperature": 0.0, "avg_logprob": -0.15026123459274704, "compression_ratio": 1.5575757575757576, "no_speech_prob": 1.642754432396032e-05}, {"id": 522, "seek": 358740, "start": 3587.4, "end": 3596.6, "text": " x bar, which is of the size of k times nd. Okay, so we just reshape, you know, this xk to be 1 times", "tokens": [50364, 2031, 2159, 11, 597, 307, 295, 264, 2744, 295, 350, 1413, 220, 273, 13, 1033, 11, 370, 321, 445, 725, 42406, 11, 291, 458, 11, 341, 2031, 74, 281, 312, 502, 1413, 50824, 50824, 220, 273, 13, 400, 550, 321, 362, 350, 1413, 220, 273, 13, 400, 550, 321, 12972, 341, 538, 264, 8062, 300, 321, 486, 1466, 51180, 51180, 538, 646, 38377, 11, 597, 307, 295, 264, 2744, 350, 538, 502, 13, 1033, 11, 321, 360, 300, 13, 440, 6916, 576, 976, 291, 51436, 51436, 502, 1413, 220, 273, 11, 291, 725, 42406, 293, 291, 483, 297, 1413, 274, 13, 407, 341, 307, 577, 286, 12270, 11, 291, 458, 11, 51704, 51752], "temperature": 0.0, "avg_logprob": -0.17359644019085427, "compression_ratio": 1.7488372093023257, "no_speech_prob": 1.5667921616113745e-05}, {"id": 523, "seek": 358740, "start": 3596.6, "end": 3603.7200000000003, "text": " nd. And then we have k times nd. And then we multiply this by the vector that we will learn", "tokens": [50364, 2031, 2159, 11, 597, 307, 295, 264, 2744, 295, 350, 1413, 220, 273, 13, 1033, 11, 370, 321, 445, 725, 42406, 11, 291, 458, 11, 341, 2031, 74, 281, 312, 502, 1413, 50824, 50824, 220, 273, 13, 400, 550, 321, 362, 350, 1413, 220, 273, 13, 400, 550, 321, 12972, 341, 538, 264, 8062, 300, 321, 486, 1466, 51180, 51180, 538, 646, 38377, 11, 597, 307, 295, 264, 2744, 350, 538, 502, 13, 1033, 11, 321, 360, 300, 13, 440, 6916, 576, 976, 291, 51436, 51436, 502, 1413, 220, 273, 11, 291, 725, 42406, 293, 291, 483, 297, 1413, 274, 13, 407, 341, 307, 577, 286, 12270, 11, 291, 458, 11, 51704, 51752], "temperature": 0.0, "avg_logprob": -0.17359644019085427, "compression_ratio": 1.7488372093023257, "no_speech_prob": 1.5667921616113745e-05}, {"id": 524, "seek": 358740, "start": 3603.7200000000003, "end": 3608.84, "text": " by back propagation, which is of the size k by 1. Okay, we do that. The operation would give you", "tokens": [50364, 2031, 2159, 11, 597, 307, 295, 264, 2744, 295, 350, 1413, 220, 273, 13, 1033, 11, 370, 321, 445, 725, 42406, 11, 291, 458, 11, 341, 2031, 74, 281, 312, 502, 1413, 50824, 50824, 220, 273, 13, 400, 550, 321, 362, 350, 1413, 220, 273, 13, 400, 550, 321, 12972, 341, 538, 264, 8062, 300, 321, 486, 1466, 51180, 51180, 538, 646, 38377, 11, 597, 307, 295, 264, 2744, 350, 538, 502, 13, 1033, 11, 321, 360, 300, 13, 440, 6916, 576, 976, 291, 51436, 51436, 502, 1413, 220, 273, 11, 291, 725, 42406, 293, 291, 483, 297, 1413, 274, 13, 407, 341, 307, 577, 286, 12270, 11, 291, 458, 11, 51704, 51752], "temperature": 0.0, "avg_logprob": -0.17359644019085427, "compression_ratio": 1.7488372093023257, "no_speech_prob": 1.5667921616113745e-05}, {"id": 525, "seek": 358740, "start": 3608.84, "end": 3614.2000000000003, "text": " 1 times nd, you reshape and you get n times d. So this is how I implemented, you know,", "tokens": [50364, 2031, 2159, 11, 597, 307, 295, 264, 2744, 295, 350, 1413, 220, 273, 13, 1033, 11, 370, 321, 445, 725, 42406, 11, 291, 458, 11, 341, 2031, 74, 281, 312, 502, 1413, 50824, 50824, 220, 273, 13, 400, 550, 321, 362, 350, 1413, 220, 273, 13, 400, 550, 321, 12972, 341, 538, 264, 8062, 300, 321, 486, 1466, 51180, 51180, 538, 646, 38377, 11, 597, 307, 295, 264, 2744, 350, 538, 502, 13, 1033, 11, 321, 360, 300, 13, 440, 6916, 576, 976, 291, 51436, 51436, 502, 1413, 220, 273, 11, 291, 725, 42406, 293, 291, 483, 297, 1413, 274, 13, 407, 341, 307, 577, 286, 12270, 11, 291, 458, 11, 51704, 51752], "temperature": 0.0, "avg_logprob": -0.17359644019085427, "compression_ratio": 1.7488372093023257, "no_speech_prob": 1.5667921616113745e-05}, {"id": 526, "seek": 361420, "start": 3614.2, "end": 3621.56, "text": " with PyTorch or TensorFlow, they will be the same. And this is how you do this spectral convolution.", "tokens": [50364, 365, 9953, 51, 284, 339, 420, 37624, 11, 436, 486, 312, 264, 912, 13, 400, 341, 307, 577, 291, 360, 341, 42761, 45216, 13, 50732, 50800, 407, 797, 11, 264, 7221, 307, 300, 15995, 366, 2293, 44574, 13, 509, 362, 257, 5754, 1230, 51080, 51080, 295, 9834, 281, 1466, 13, 407, 341, 307, 257, 350, 11, 291, 458, 11, 341, 307, 341, 307, 341, 350, 9834, 300, 291, 643, 281, 51388, 51388, 1466, 538, 646, 38377, 11, 291, 362, 257, 2539, 14024, 11, 257, 8213, 2539, 14024, 13, 583, 264, 51692, 51692], "temperature": 0.0, "avg_logprob": -0.17681040662400266, "compression_ratio": 1.691304347826087, "no_speech_prob": 0.0001557735085953027}, {"id": 527, "seek": 361420, "start": 3622.9199999999996, "end": 3628.52, "text": " So again, the properties is that filters are exactly localized. You have a constant number", "tokens": [50364, 365, 9953, 51, 284, 339, 420, 37624, 11, 436, 486, 312, 264, 912, 13, 400, 341, 307, 577, 291, 360, 341, 42761, 45216, 13, 50732, 50800, 407, 797, 11, 264, 7221, 307, 300, 15995, 366, 2293, 44574, 13, 509, 362, 257, 5754, 1230, 51080, 51080, 295, 9834, 281, 1466, 13, 407, 341, 307, 257, 350, 11, 291, 458, 11, 341, 307, 341, 307, 341, 350, 9834, 300, 291, 643, 281, 51388, 51388, 1466, 538, 646, 38377, 11, 291, 362, 257, 2539, 14024, 11, 257, 8213, 2539, 14024, 13, 583, 264, 51692, 51692], "temperature": 0.0, "avg_logprob": -0.17681040662400266, "compression_ratio": 1.691304347826087, "no_speech_prob": 0.0001557735085953027}, {"id": 528, "seek": 361420, "start": 3628.52, "end": 3634.68, "text": " of parameters to learn. So this is a k, you know, this is this is this k parameters that you need to", "tokens": [50364, 365, 9953, 51, 284, 339, 420, 37624, 11, 436, 486, 312, 264, 912, 13, 400, 341, 307, 577, 291, 360, 341, 42761, 45216, 13, 50732, 50800, 407, 797, 11, 264, 7221, 307, 300, 15995, 366, 2293, 44574, 13, 509, 362, 257, 5754, 1230, 51080, 51080, 295, 9834, 281, 1466, 13, 407, 341, 307, 257, 350, 11, 291, 458, 11, 341, 307, 341, 307, 341, 350, 9834, 300, 291, 643, 281, 51388, 51388, 1466, 538, 646, 38377, 11, 291, 362, 257, 2539, 14024, 11, 257, 8213, 2539, 14024, 13, 583, 264, 51692, 51692], "temperature": 0.0, "avg_logprob": -0.17681040662400266, "compression_ratio": 1.691304347826087, "no_speech_prob": 0.0001557735085953027}, {"id": 529, "seek": 361420, "start": 3634.68, "end": 3640.7599999999998, "text": " learn by back propagation, you have a learning complexity, a linear learning complexity. But the", "tokens": [50364, 365, 9953, 51, 284, 339, 420, 37624, 11, 436, 486, 312, 264, 912, 13, 400, 341, 307, 577, 291, 360, 341, 42761, 45216, 13, 50732, 50800, 407, 797, 11, 264, 7221, 307, 300, 15995, 366, 2293, 44574, 13, 509, 362, 257, 5754, 1230, 51080, 51080, 295, 9834, 281, 1466, 13, 407, 341, 307, 257, 350, 11, 291, 458, 11, 341, 307, 341, 307, 341, 350, 9834, 300, 291, 643, 281, 51388, 51388, 1466, 538, 646, 38377, 11, 291, 362, 257, 2539, 14024, 11, 257, 8213, 2539, 14024, 13, 583, 264, 51692, 51692], "temperature": 0.0, "avg_logprob": -0.17681040662400266, "compression_ratio": 1.691304347826087, "no_speech_prob": 0.0001557735085953027}, {"id": 530, "seek": 364076, "start": 3640.76, "end": 3648.0400000000004, "text": " thing which, which is not good is that here I'm using monomial basis. Okay, so I'm using", "tokens": [50364, 551, 597, 11, 597, 307, 406, 665, 307, 300, 510, 286, 478, 1228, 1108, 47429, 5143, 13, 1033, 11, 370, 286, 478, 1228, 50728, 50764, 1456, 47, 19837, 402, 2760, 281, 264, 1347, 4018, 11, 1456, 47, 19837, 402, 2760, 281, 264, 1347, 472, 11, 1347, 732, 11, 1347, 1045, 11, 293, 370, 322, 13, 50976, 50976, 1033, 11, 341, 307, 437, 286, 764, 510, 13, 400, 264, 551, 307, 1108, 47429, 5143, 366, 23742, 337, 19618, 11, 51348, 51348, 570, 341, 5143, 11, 291, 458, 11, 307, 406, 41488, 13, 407, 498, 291, 1319, 472, 17619, 11, 51664, 51692], "temperature": 0.0, "avg_logprob": -0.17314699584362553, "compression_ratio": 1.7136150234741785, "no_speech_prob": 1.0728490451583639e-05}, {"id": 531, "seek": 364076, "start": 3648.76, "end": 3653.0, "text": " LePlace shunt to the power zero, LePlace shunt to the power one, power two, power three, and so on.", "tokens": [50364, 551, 597, 11, 597, 307, 406, 665, 307, 300, 510, 286, 478, 1228, 1108, 47429, 5143, 13, 1033, 11, 370, 286, 478, 1228, 50728, 50764, 1456, 47, 19837, 402, 2760, 281, 264, 1347, 4018, 11, 1456, 47, 19837, 402, 2760, 281, 264, 1347, 472, 11, 1347, 732, 11, 1347, 1045, 11, 293, 370, 322, 13, 50976, 50976, 1033, 11, 341, 307, 437, 286, 764, 510, 13, 400, 264, 551, 307, 1108, 47429, 5143, 366, 23742, 337, 19618, 11, 51348, 51348, 570, 341, 5143, 11, 291, 458, 11, 307, 406, 41488, 13, 407, 498, 291, 1319, 472, 17619, 11, 51664, 51692], "temperature": 0.0, "avg_logprob": -0.17314699584362553, "compression_ratio": 1.7136150234741785, "no_speech_prob": 1.0728490451583639e-05}, {"id": 532, "seek": 364076, "start": 3653.0, "end": 3660.44, "text": " Okay, this is what I use here. And the thing is monomial basis are unstable for optimization,", "tokens": [50364, 551, 597, 11, 597, 307, 406, 665, 307, 300, 510, 286, 478, 1228, 1108, 47429, 5143, 13, 1033, 11, 370, 286, 478, 1228, 50728, 50764, 1456, 47, 19837, 402, 2760, 281, 264, 1347, 4018, 11, 1456, 47, 19837, 402, 2760, 281, 264, 1347, 472, 11, 1347, 732, 11, 1347, 1045, 11, 293, 370, 322, 13, 50976, 50976, 1033, 11, 341, 307, 437, 286, 764, 510, 13, 400, 264, 551, 307, 1108, 47429, 5143, 366, 23742, 337, 19618, 11, 51348, 51348, 570, 341, 5143, 11, 291, 458, 11, 307, 406, 41488, 13, 407, 498, 291, 1319, 472, 17619, 11, 51664, 51692], "temperature": 0.0, "avg_logprob": -0.17314699584362553, "compression_ratio": 1.7136150234741785, "no_speech_prob": 1.0728490451583639e-05}, {"id": 533, "seek": 364076, "start": 3660.44, "end": 3666.76, "text": " because this basis, you know, is not orthogonal. So if you change one coefficient,", "tokens": [50364, 551, 597, 11, 597, 307, 406, 665, 307, 300, 510, 286, 478, 1228, 1108, 47429, 5143, 13, 1033, 11, 370, 286, 478, 1228, 50728, 50764, 1456, 47, 19837, 402, 2760, 281, 264, 1347, 4018, 11, 1456, 47, 19837, 402, 2760, 281, 264, 1347, 472, 11, 1347, 732, 11, 1347, 1045, 11, 293, 370, 322, 13, 50976, 50976, 1033, 11, 341, 307, 437, 286, 764, 510, 13, 400, 264, 551, 307, 1108, 47429, 5143, 366, 23742, 337, 19618, 11, 51348, 51348, 570, 341, 5143, 11, 291, 458, 11, 307, 406, 41488, 13, 407, 498, 291, 1319, 472, 17619, 11, 51664, 51692], "temperature": 0.0, "avg_logprob": -0.17314699584362553, "compression_ratio": 1.7136150234741785, "no_speech_prob": 1.0728490451583639e-05}, {"id": 534, "seek": 366676, "start": 3666.76, "end": 3671.88, "text": " then you are going to change the approximation of your function. So you need orthogonality,", "tokens": [50364, 550, 291, 366, 516, 281, 1319, 264, 28023, 295, 428, 2445, 13, 407, 291, 643, 38130, 266, 1860, 11, 50620, 50620, 498, 291, 528, 281, 1466, 365, 11826, 13, 1033, 11, 370, 550, 291, 393, 764, 428, 2954, 11, 291, 458, 11, 51080, 51080, 420, 11943, 24440, 5143, 11, 457, 428, 2954, 420, 11943, 24440, 5143, 1633, 362, 257, 20560, 488, 5367, 13, 1033, 11, 51452, 51452, 370, 341, 307, 264, 787, 551, 300, 300, 300, 291, 300, 291, 643, 13, 509, 643, 428, 420, 11943, 24440, 5143, 51712, 51748], "temperature": 0.0, "avg_logprob": -0.16216430456741995, "compression_ratio": 1.82, "no_speech_prob": 0.0001508562418166548}, {"id": 535, "seek": 366676, "start": 3671.88, "end": 3681.0800000000004, "text": " if you want to learn with stability. Okay, so then you can use your favorite, you know,", "tokens": [50364, 550, 291, 366, 516, 281, 1319, 264, 28023, 295, 428, 2445, 13, 407, 291, 643, 38130, 266, 1860, 11, 50620, 50620, 498, 291, 528, 281, 1466, 365, 11826, 13, 1033, 11, 370, 550, 291, 393, 764, 428, 2954, 11, 291, 458, 11, 51080, 51080, 420, 11943, 24440, 5143, 11, 457, 428, 2954, 420, 11943, 24440, 5143, 1633, 362, 257, 20560, 488, 5367, 13, 1033, 11, 51452, 51452, 370, 341, 307, 264, 787, 551, 300, 300, 300, 291, 300, 291, 643, 13, 509, 643, 428, 420, 11943, 24440, 5143, 51712, 51748], "temperature": 0.0, "avg_logprob": -0.16216430456741995, "compression_ratio": 1.82, "no_speech_prob": 0.0001508562418166548}, {"id": 536, "seek": 366676, "start": 3681.0800000000004, "end": 3688.5200000000004, "text": " orthonormal basis, but your favorite orthonormal basis must have a recursive equation. Okay,", "tokens": [50364, 550, 291, 366, 516, 281, 1319, 264, 28023, 295, 428, 2445, 13, 407, 291, 643, 38130, 266, 1860, 11, 50620, 50620, 498, 291, 528, 281, 1466, 365, 11826, 13, 1033, 11, 370, 550, 291, 393, 764, 428, 2954, 11, 291, 458, 11, 51080, 51080, 420, 11943, 24440, 5143, 11, 457, 428, 2954, 420, 11943, 24440, 5143, 1633, 362, 257, 20560, 488, 5367, 13, 1033, 11, 51452, 51452, 370, 341, 307, 264, 787, 551, 300, 300, 300, 291, 300, 291, 643, 13, 509, 643, 428, 420, 11943, 24440, 5143, 51712, 51748], "temperature": 0.0, "avg_logprob": -0.16216430456741995, "compression_ratio": 1.82, "no_speech_prob": 0.0001508562418166548}, {"id": 537, "seek": 366676, "start": 3688.5200000000004, "end": 3693.7200000000003, "text": " so this is the only thing that that that you that you need. You need your orthonormal basis", "tokens": [50364, 550, 291, 366, 516, 281, 1319, 264, 28023, 295, 428, 2445, 13, 407, 291, 643, 38130, 266, 1860, 11, 50620, 50620, 498, 291, 528, 281, 1466, 365, 11826, 13, 1033, 11, 370, 550, 291, 393, 764, 428, 2954, 11, 291, 458, 11, 51080, 51080, 420, 11943, 24440, 5143, 11, 457, 428, 2954, 420, 11943, 24440, 5143, 1633, 362, 257, 20560, 488, 5367, 13, 1033, 11, 51452, 51452, 370, 341, 307, 264, 787, 551, 300, 300, 300, 291, 300, 291, 643, 13, 509, 643, 428, 420, 11943, 24440, 5143, 51712, 51748], "temperature": 0.0, "avg_logprob": -0.16216430456741995, "compression_ratio": 1.82, "no_speech_prob": 0.0001508562418166548}, {"id": 538, "seek": 369372, "start": 3693.72, "end": 3698.2799999999997, "text": " to have a recursive equation, because this is the key to have the linear complexity.", "tokens": [50364, 281, 362, 257, 20560, 488, 5367, 11, 570, 341, 307, 264, 2141, 281, 362, 264, 8213, 14024, 13, 50592, 50628, 407, 321, 764, 257, 3351, 65, 749, 675, 85, 22560, 12356, 13, 407, 341, 307, 746, 588, 731, 2570, 294, 6358, 9007, 13, 50892, 50960, 407, 321, 434, 516, 281, 30874, 11, 291, 458, 11, 264, 42761, 45216, 365, 257, 3351, 65, 749, 675, 85, 2445, 13, 51308, 51308, 440, 3351, 65, 749, 675, 85, 6828, 3079, 281, 389, 797, 393, 312, 10379, 538, 2031, 74, 11, 293, 2031, 74, 307, 2212, 538, 341, 51616, 51616], "temperature": 0.0, "avg_logprob": -0.21274395378268496, "compression_ratio": 1.6160714285714286, "no_speech_prob": 5.023728226660751e-05}, {"id": 539, "seek": 369372, "start": 3699.0, "end": 3704.2799999999997, "text": " So we use a Chebyshev polynomials. So this is something very well known in signal processing.", "tokens": [50364, 281, 362, 257, 20560, 488, 5367, 11, 570, 341, 307, 264, 2141, 281, 362, 264, 8213, 14024, 13, 50592, 50628, 407, 321, 764, 257, 3351, 65, 749, 675, 85, 22560, 12356, 13, 407, 341, 307, 746, 588, 731, 2570, 294, 6358, 9007, 13, 50892, 50960, 407, 321, 434, 516, 281, 30874, 11, 291, 458, 11, 264, 42761, 45216, 365, 257, 3351, 65, 749, 675, 85, 2445, 13, 51308, 51308, 440, 3351, 65, 749, 675, 85, 6828, 3079, 281, 389, 797, 393, 312, 10379, 538, 2031, 74, 11, 293, 2031, 74, 307, 2212, 538, 341, 51616, 51616], "temperature": 0.0, "avg_logprob": -0.21274395378268496, "compression_ratio": 1.6160714285714286, "no_speech_prob": 5.023728226660751e-05}, {"id": 540, "seek": 369372, "start": 3705.64, "end": 3712.6, "text": " So we're going to approximate, you know, the spectral convolution with a Chebyshev function.", "tokens": [50364, 281, 362, 257, 20560, 488, 5367, 11, 570, 341, 307, 264, 2141, 281, 362, 264, 8213, 14024, 13, 50592, 50628, 407, 321, 764, 257, 3351, 65, 749, 675, 85, 22560, 12356, 13, 407, 341, 307, 746, 588, 731, 2570, 294, 6358, 9007, 13, 50892, 50960, 407, 321, 434, 516, 281, 30874, 11, 291, 458, 11, 264, 42761, 45216, 365, 257, 3351, 65, 749, 675, 85, 2445, 13, 51308, 51308, 440, 3351, 65, 749, 675, 85, 6828, 3079, 281, 389, 797, 393, 312, 10379, 538, 2031, 74, 11, 293, 2031, 74, 307, 2212, 538, 341, 51616, 51616], "temperature": 0.0, "avg_logprob": -0.21274395378268496, "compression_ratio": 1.6160714285714286, "no_speech_prob": 5.023728226660751e-05}, {"id": 541, "seek": 369372, "start": 3712.6, "end": 3718.7599999999998, "text": " The Chebyshev functions apply to H again can be represented by xk, and xk is given by this", "tokens": [50364, 281, 362, 257, 20560, 488, 5367, 11, 570, 341, 307, 264, 2141, 281, 362, 264, 8213, 14024, 13, 50592, 50628, 407, 321, 764, 257, 3351, 65, 749, 675, 85, 22560, 12356, 13, 407, 341, 307, 746, 588, 731, 2570, 294, 6358, 9007, 13, 50892, 50960, 407, 321, 434, 516, 281, 30874, 11, 291, 458, 11, 264, 42761, 45216, 365, 257, 3351, 65, 749, 675, 85, 2445, 13, 51308, 51308, 440, 3351, 65, 749, 675, 85, 6828, 3079, 281, 389, 797, 393, 312, 10379, 538, 2031, 74, 11, 293, 2031, 74, 307, 2212, 538, 341, 51616, 51616], "temperature": 0.0, "avg_logprob": -0.21274395378268496, "compression_ratio": 1.6160714285714286, "no_speech_prob": 5.023728226660751e-05}, {"id": 542, "seek": 371876, "start": 3718.76, "end": 3724.0400000000004, "text": " recursive equation. Okay, so it's a little more complex than before. But in practice,", "tokens": [50364, 20560, 488, 5367, 13, 1033, 11, 370, 309, 311, 257, 707, 544, 3997, 813, 949, 13, 583, 294, 3124, 11, 50628, 50628, 341, 307, 445, 884, 797, 11, 27290, 295, 428, 635, 564, 326, 952, 1413, 264, 8062, 472, 8062, 13, 1033, 11, 50976, 50976, 412, 264, 917, 295, 264, 786, 11, 264, 14024, 307, 920, 8213, 11, 291, 500, 380, 1319, 1340, 13, 51164, 51260, 400, 341, 565, 291, 362, 11826, 1830, 428, 1830, 264, 2539, 1399, 13, 1033, 11, 370, 437, 321, 51588, 51588], "temperature": 0.0, "avg_logprob": -0.19157537547024814, "compression_ratio": 1.6, "no_speech_prob": 9.506131027592346e-05}, {"id": 543, "seek": 371876, "start": 3724.0400000000004, "end": 3731.0, "text": " this is just doing again, multiplication of your laplacian times the vector one vector. Okay,", "tokens": [50364, 20560, 488, 5367, 13, 1033, 11, 370, 309, 311, 257, 707, 544, 3997, 813, 949, 13, 583, 294, 3124, 11, 50628, 50628, 341, 307, 445, 884, 797, 11, 27290, 295, 428, 635, 564, 326, 952, 1413, 264, 8062, 472, 8062, 13, 1033, 11, 50976, 50976, 412, 264, 917, 295, 264, 786, 11, 264, 14024, 307, 920, 8213, 11, 291, 500, 380, 1319, 1340, 13, 51164, 51260, 400, 341, 565, 291, 362, 11826, 1830, 428, 1830, 264, 2539, 1399, 13, 1033, 11, 370, 437, 321, 51588, 51588], "temperature": 0.0, "avg_logprob": -0.19157537547024814, "compression_ratio": 1.6, "no_speech_prob": 9.506131027592346e-05}, {"id": 544, "seek": 371876, "start": 3731.0, "end": 3734.76, "text": " at the end of the day, the complexity is still linear, you don't change anything.", "tokens": [50364, 20560, 488, 5367, 13, 1033, 11, 370, 309, 311, 257, 707, 544, 3997, 813, 949, 13, 583, 294, 3124, 11, 50628, 50628, 341, 307, 445, 884, 797, 11, 27290, 295, 428, 635, 564, 326, 952, 1413, 264, 8062, 472, 8062, 13, 1033, 11, 50976, 50976, 412, 264, 917, 295, 264, 786, 11, 264, 14024, 307, 920, 8213, 11, 291, 500, 380, 1319, 1340, 13, 51164, 51260, 400, 341, 565, 291, 362, 11826, 1830, 428, 1830, 264, 2539, 1399, 13, 1033, 11, 370, 437, 321, 51588, 51588], "temperature": 0.0, "avg_logprob": -0.19157537547024814, "compression_ratio": 1.6, "no_speech_prob": 9.506131027592346e-05}, {"id": 545, "seek": 371876, "start": 3736.6800000000003, "end": 3743.2400000000002, "text": " And this time you have stability during your during the learning process. Okay, so what we", "tokens": [50364, 20560, 488, 5367, 13, 1033, 11, 370, 309, 311, 257, 707, 544, 3997, 813, 949, 13, 583, 294, 3124, 11, 50628, 50628, 341, 307, 445, 884, 797, 11, 27290, 295, 428, 635, 564, 326, 952, 1413, 264, 8062, 472, 8062, 13, 1033, 11, 50976, 50976, 412, 264, 917, 295, 264, 786, 11, 264, 14024, 307, 920, 8213, 11, 291, 500, 380, 1319, 1340, 13, 51164, 51260, 400, 341, 565, 291, 362, 11826, 1830, 428, 1830, 264, 2539, 1399, 13, 1033, 11, 370, 437, 321, 51588, 51588], "temperature": 0.0, "avg_logprob": -0.19157537547024814, "compression_ratio": 1.6, "no_speech_prob": 9.506131027592346e-05}, {"id": 546, "seek": 374324, "start": 3743.24, "end": 3752.3599999999997, "text": " did, we did the sanity check with MNIST. So and you see that so this is the number of vertices.", "tokens": [50364, 630, 11, 321, 630, 264, 47892, 1520, 365, 376, 45, 19756, 13, 407, 293, 291, 536, 300, 370, 341, 307, 264, 1230, 295, 32053, 13, 50820, 50820, 407, 337, 376, 45, 19756, 11, 264, 4295, 307, 264, 3832, 10748, 13, 1033, 11, 321, 764, 257, 591, 12, 45, 347, 271, 5987, 10748, 281, 360, 300, 13, 51180, 51180, 400, 291, 536, 300, 291, 362, 8213, 14024, 13, 1033, 11, 341, 307, 264, 1230, 295, 32053, 13, 400, 291, 51548, 51548, 362, 341, 1230, 295, 291, 362, 264, 8213, 14024, 13, 407, 341, 307, 665, 337, 264, 14170, 295, 264, 51840, 51840], "temperature": 0.0, "avg_logprob": -0.28037628618258875, "compression_ratio": 1.865, "no_speech_prob": 4.213567081023939e-05}, {"id": 547, "seek": 374324, "start": 3752.3599999999997, "end": 3759.56, "text": " So for MNIST, the graph is the standard grid. Okay, we use a K-Niris neighbor grid to do that.", "tokens": [50364, 630, 11, 321, 630, 264, 47892, 1520, 365, 376, 45, 19756, 13, 407, 293, 291, 536, 300, 370, 341, 307, 264, 1230, 295, 32053, 13, 50820, 50820, 407, 337, 376, 45, 19756, 11, 264, 4295, 307, 264, 3832, 10748, 13, 1033, 11, 321, 764, 257, 591, 12, 45, 347, 271, 5987, 10748, 281, 360, 300, 13, 51180, 51180, 400, 291, 536, 300, 291, 362, 8213, 14024, 13, 1033, 11, 341, 307, 264, 1230, 295, 32053, 13, 400, 291, 51548, 51548, 362, 341, 1230, 295, 291, 362, 264, 8213, 14024, 13, 407, 341, 307, 665, 337, 264, 14170, 295, 264, 51840, 51840], "temperature": 0.0, "avg_logprob": -0.28037628618258875, "compression_ratio": 1.865, "no_speech_prob": 4.213567081023939e-05}, {"id": 548, "seek": 374324, "start": 3759.56, "end": 3766.9199999999996, "text": " And you see that you have linear complexity. Okay, this is the number of vertices. And you", "tokens": [50364, 630, 11, 321, 630, 264, 47892, 1520, 365, 376, 45, 19756, 13, 407, 293, 291, 536, 300, 370, 341, 307, 264, 1230, 295, 32053, 13, 50820, 50820, 407, 337, 376, 45, 19756, 11, 264, 4295, 307, 264, 3832, 10748, 13, 1033, 11, 321, 764, 257, 591, 12, 45, 347, 271, 5987, 10748, 281, 360, 300, 13, 51180, 51180, 400, 291, 536, 300, 291, 362, 8213, 14024, 13, 1033, 11, 341, 307, 264, 1230, 295, 32053, 13, 400, 291, 51548, 51548, 362, 341, 1230, 295, 291, 362, 264, 8213, 14024, 13, 407, 341, 307, 665, 337, 264, 14170, 295, 264, 51840, 51840], "temperature": 0.0, "avg_logprob": -0.28037628618258875, "compression_ratio": 1.865, "no_speech_prob": 4.213567081023939e-05}, {"id": 549, "seek": 374324, "start": 3766.9199999999996, "end": 3772.7599999999998, "text": " have this number of you have the linear complexity. So this is good for the accuracy of the", "tokens": [50364, 630, 11, 321, 630, 264, 47892, 1520, 365, 376, 45, 19756, 13, 407, 293, 291, 536, 300, 370, 341, 307, 264, 1230, 295, 32053, 13, 50820, 50820, 407, 337, 376, 45, 19756, 11, 264, 4295, 307, 264, 3832, 10748, 13, 1033, 11, 321, 764, 257, 591, 12, 45, 347, 271, 5987, 10748, 281, 360, 300, 13, 51180, 51180, 400, 291, 536, 300, 291, 362, 8213, 14024, 13, 1033, 11, 341, 307, 264, 1230, 295, 32053, 13, 400, 291, 51548, 51548, 362, 341, 1230, 295, 291, 362, 264, 8213, 14024, 13, 407, 341, 307, 665, 337, 264, 14170, 295, 264, 51840, 51840], "temperature": 0.0, "avg_logprob": -0.28037628618258875, "compression_ratio": 1.865, "no_speech_prob": 4.213567081023939e-05}, {"id": 550, "seek": 377276, "start": 3772.76, "end": 3780.6800000000003, "text": " accuracy, we get to see 99% of accuracy compared to the standard learning five. Okay, so ChebNet", "tokens": [50364, 14170, 11, 321, 483, 281, 536, 11803, 4, 295, 14170, 5347, 281, 264, 3832, 2539, 1732, 13, 1033, 11, 370, 3351, 65, 31890, 50760, 50824, 407, 3351, 65, 31890, 307, 1936, 21056, 337, 23211, 4295, 11, 293, 321, 362, 264, 912, 8213, 2539, 51056, 51056, 14024, 13, 2720, 1164, 11, 264, 14024, 5754, 307, 709, 4833, 813, 813, 264, 3832, 813, 264, 51472, 51472, 3832, 15670, 13, 407, 309, 311, 746, 411, 945, 420, 2217, 13, 407, 309, 311, 709, 11, 709, 4356, 281, 1466, 322, 341, 11, 51752, 51752], "temperature": 0.0, "avg_logprob": -0.1897986660832944, "compression_ratio": 1.7252252252252251, "no_speech_prob": 5.789739589090459e-05}, {"id": 551, "seek": 377276, "start": 3781.96, "end": 3786.6000000000004, "text": " So ChebNet is basically coordinates for arbitrary graph, and we have the same linear learning", "tokens": [50364, 14170, 11, 321, 483, 281, 536, 11803, 4, 295, 14170, 5347, 281, 264, 3832, 2539, 1732, 13, 1033, 11, 370, 3351, 65, 31890, 50760, 50824, 407, 3351, 65, 31890, 307, 1936, 21056, 337, 23211, 4295, 11, 293, 321, 362, 264, 912, 8213, 2539, 51056, 51056, 14024, 13, 2720, 1164, 11, 264, 14024, 5754, 307, 709, 4833, 813, 813, 264, 3832, 813, 264, 51472, 51472, 3832, 15670, 13, 407, 309, 311, 746, 411, 945, 420, 2217, 13, 407, 309, 311, 709, 11, 709, 4356, 281, 1466, 322, 341, 11, 51752, 51752], "temperature": 0.0, "avg_logprob": -0.1897986660832944, "compression_ratio": 1.7252252252252251, "no_speech_prob": 5.789739589090459e-05}, {"id": 552, "seek": 377276, "start": 3786.6000000000004, "end": 3794.92, "text": " complexity. Of course, the complexity constant is much larger than than the standard than the", "tokens": [50364, 14170, 11, 321, 483, 281, 536, 11803, 4, 295, 14170, 5347, 281, 264, 3832, 2539, 1732, 13, 1033, 11, 370, 3351, 65, 31890, 50760, 50824, 407, 3351, 65, 31890, 307, 1936, 21056, 337, 23211, 4295, 11, 293, 321, 362, 264, 912, 8213, 2539, 51056, 51056, 14024, 13, 2720, 1164, 11, 264, 14024, 5754, 307, 709, 4833, 813, 813, 264, 3832, 813, 264, 51472, 51472, 3832, 15670, 13, 407, 309, 311, 746, 411, 945, 420, 2217, 13, 407, 309, 311, 709, 11, 709, 4356, 281, 1466, 322, 341, 11, 51752, 51752], "temperature": 0.0, "avg_logprob": -0.1897986660832944, "compression_ratio": 1.7252252252252251, "no_speech_prob": 5.789739589090459e-05}, {"id": 553, "seek": 377276, "start": 3794.92, "end": 3800.5200000000004, "text": " standard coordinate. So it's something like 20 or 30. So it's much, much smaller to learn on this,", "tokens": [50364, 14170, 11, 321, 483, 281, 536, 11803, 4, 295, 14170, 5347, 281, 264, 3832, 2539, 1732, 13, 1033, 11, 370, 3351, 65, 31890, 50760, 50824, 407, 3351, 65, 31890, 307, 1936, 21056, 337, 23211, 4295, 11, 293, 321, 362, 264, 912, 8213, 2539, 51056, 51056, 14024, 13, 2720, 1164, 11, 264, 14024, 5754, 307, 709, 4833, 813, 813, 264, 3832, 813, 264, 51472, 51472, 3832, 15670, 13, 407, 309, 311, 746, 411, 945, 420, 2217, 13, 407, 309, 311, 709, 11, 709, 4356, 281, 1466, 322, 341, 11, 51752, 51752], "temperature": 0.0, "avg_logprob": -0.1897986660832944, "compression_ratio": 1.7252252252252251, "no_speech_prob": 5.789739589090459e-05}, {"id": 554, "seek": 380052, "start": 3800.52, "end": 3805.64, "text": " but you get, you know, a coordinate for any arbitrary graph. So that's, that's, that's what", "tokens": [50364, 457, 291, 483, 11, 291, 458, 11, 257, 15670, 337, 604, 23211, 4295, 13, 407, 300, 311, 11, 300, 311, 11, 300, 311, 437, 50620, 50620, 291, 914, 13, 3996, 27432, 307, 11, 309, 311, 364, 38018, 39173, 2316, 13, 407, 11, 370, 718, 385, 751, 257, 707, 857, 466, 51000, 51040, 38018, 27514, 5717, 364, 271, 310, 27514, 13, 407, 498, 291, 574, 412, 11, 291, 458, 11, 264, 3832, 21056, 11, 51240, 51268, 550, 291, 366, 516, 281, 5258, 364, 271, 310, 39173, 15995, 411, 341, 472, 13, 1033, 11, 370, 291, 536, 300, 341, 6608, 51536, 51536], "temperature": 0.0, "avg_logprob": -0.10605682111253925, "compression_ratio": 1.7242990654205608, "no_speech_prob": 1.583734410814941e-05}, {"id": 555, "seek": 380052, "start": 3805.64, "end": 3813.24, "text": " you mean. Another limitation is, it's an isotropic model. So, so let me talk a little bit about", "tokens": [50364, 457, 291, 483, 11, 291, 458, 11, 257, 15670, 337, 604, 23211, 4295, 13, 407, 300, 311, 11, 300, 311, 11, 300, 311, 437, 50620, 50620, 291, 914, 13, 3996, 27432, 307, 11, 309, 311, 364, 38018, 39173, 2316, 13, 407, 11, 370, 718, 385, 751, 257, 707, 857, 466, 51000, 51040, 38018, 27514, 5717, 364, 271, 310, 27514, 13, 407, 498, 291, 574, 412, 11, 291, 458, 11, 264, 3832, 21056, 11, 51240, 51268, 550, 291, 366, 516, 281, 5258, 364, 271, 310, 39173, 15995, 411, 341, 472, 13, 1033, 11, 370, 291, 536, 300, 341, 6608, 51536, 51536], "temperature": 0.0, "avg_logprob": -0.10605682111253925, "compression_ratio": 1.7242990654205608, "no_speech_prob": 1.583734410814941e-05}, {"id": 556, "seek": 380052, "start": 3814.04, "end": 3818.04, "text": " isotropy versus anisotropy. So if you look at, you know, the standard coordinates,", "tokens": [50364, 457, 291, 483, 11, 291, 458, 11, 257, 15670, 337, 604, 23211, 4295, 13, 407, 300, 311, 11, 300, 311, 11, 300, 311, 437, 50620, 50620, 291, 914, 13, 3996, 27432, 307, 11, 309, 311, 364, 38018, 39173, 2316, 13, 407, 11, 370, 718, 385, 751, 257, 707, 857, 466, 51000, 51040, 38018, 27514, 5717, 364, 271, 310, 27514, 13, 407, 498, 291, 574, 412, 11, 291, 458, 11, 264, 3832, 21056, 11, 51240, 51268, 550, 291, 366, 516, 281, 5258, 364, 271, 310, 39173, 15995, 411, 341, 472, 13, 1033, 11, 370, 291, 536, 300, 341, 6608, 51536, 51536], "temperature": 0.0, "avg_logprob": -0.10605682111253925, "compression_ratio": 1.7242990654205608, "no_speech_prob": 1.583734410814941e-05}, {"id": 557, "seek": 380052, "start": 3818.6, "end": 3823.96, "text": " then you are going to produce anisotropic filters like this one. Okay, so you see that this filter", "tokens": [50364, 457, 291, 483, 11, 291, 458, 11, 257, 15670, 337, 604, 23211, 4295, 13, 407, 300, 311, 11, 300, 311, 11, 300, 311, 437, 50620, 50620, 291, 914, 13, 3996, 27432, 307, 11, 309, 311, 364, 38018, 39173, 2316, 13, 407, 11, 370, 718, 385, 751, 257, 707, 857, 466, 51000, 51040, 38018, 27514, 5717, 364, 271, 310, 27514, 13, 407, 498, 291, 574, 412, 11, 291, 458, 11, 264, 3832, 21056, 11, 51240, 51268, 550, 291, 366, 516, 281, 5258, 364, 271, 310, 39173, 15995, 411, 341, 472, 13, 1033, 11, 370, 291, 536, 300, 341, 6608, 51536, 51536], "temperature": 0.0, "avg_logprob": -0.10605682111253925, "compression_ratio": 1.7242990654205608, "no_speech_prob": 1.583734410814941e-05}, {"id": 558, "seek": 382396, "start": 3823.96, "end": 3830.84, "text": " is an isotropic, it goes in this direction. Okay, and we can get anisotropic filters with", "tokens": [50364, 307, 364, 38018, 39173, 11, 309, 1709, 294, 341, 3513, 13, 1033, 11, 293, 321, 393, 483, 364, 271, 310, 39173, 15995, 365, 50708, 50708, 3832, 21056, 11, 570, 321, 366, 1228, 257, 10748, 13, 400, 322, 257, 10748, 11, 321, 362, 11, 291, 458, 11, 42242, 11, 51068, 51068, 321, 362, 11095, 11, 321, 458, 689, 307, 264, 493, 11, 689, 307, 760, 11, 689, 307, 1411, 11, 689, 307, 558, 11, 558, 11, 51336, 51336, 1604, 300, 321, 458, 264, 21739, 295, 295, 264, 13891, 322, 264, 10748, 11, 321, 458, 300, 13, 583, 341, 307, 51692, 51692], "temperature": 0.0, "avg_logprob": -0.14387985304290174, "compression_ratio": 1.829268292682927, "no_speech_prob": 2.8383219614624977e-05}, {"id": 559, "seek": 382396, "start": 3830.84, "end": 3838.04, "text": " standard coordinates, because we are using a grid. And on a grid, we have, you know, directional,", "tokens": [50364, 307, 364, 38018, 39173, 11, 309, 1709, 294, 341, 3513, 13, 1033, 11, 293, 321, 393, 483, 364, 271, 310, 39173, 15995, 365, 50708, 50708, 3832, 21056, 11, 570, 321, 366, 1228, 257, 10748, 13, 400, 322, 257, 10748, 11, 321, 362, 11, 291, 458, 11, 42242, 11, 51068, 51068, 321, 362, 11095, 11, 321, 458, 689, 307, 264, 493, 11, 689, 307, 760, 11, 689, 307, 1411, 11, 689, 307, 558, 11, 558, 11, 51336, 51336, 1604, 300, 321, 458, 264, 21739, 295, 295, 264, 13891, 322, 264, 10748, 11, 321, 458, 300, 13, 583, 341, 307, 51692, 51692], "temperature": 0.0, "avg_logprob": -0.14387985304290174, "compression_ratio": 1.829268292682927, "no_speech_prob": 2.8383219614624977e-05}, {"id": 560, "seek": 382396, "start": 3838.04, "end": 3843.4, "text": " we have directions, we know where is the up, where is down, where is left, where is right, right,", "tokens": [50364, 307, 364, 38018, 39173, 11, 309, 1709, 294, 341, 3513, 13, 1033, 11, 293, 321, 393, 483, 364, 271, 310, 39173, 15995, 365, 50708, 50708, 3832, 21056, 11, 570, 321, 366, 1228, 257, 10748, 13, 400, 322, 257, 10748, 11, 321, 362, 11, 291, 458, 11, 42242, 11, 51068, 51068, 321, 362, 11095, 11, 321, 458, 689, 307, 264, 493, 11, 689, 307, 760, 11, 689, 307, 1411, 11, 689, 307, 558, 11, 558, 11, 51336, 51336, 1604, 300, 321, 458, 264, 21739, 295, 295, 264, 13891, 322, 264, 10748, 11, 321, 458, 300, 13, 583, 341, 307, 51692, 51692], "temperature": 0.0, "avg_logprob": -0.14387985304290174, "compression_ratio": 1.829268292682927, "no_speech_prob": 2.8383219614624977e-05}, {"id": 561, "seek": 382396, "start": 3843.4, "end": 3850.52, "text": " remember that we know the ordering of of the nodes on the grid, we know that. But this is", "tokens": [50364, 307, 364, 38018, 39173, 11, 309, 1709, 294, 341, 3513, 13, 1033, 11, 293, 321, 393, 483, 364, 271, 310, 39173, 15995, 365, 50708, 50708, 3832, 21056, 11, 570, 321, 366, 1228, 257, 10748, 13, 400, 322, 257, 10748, 11, 321, 362, 11, 291, 458, 11, 42242, 11, 51068, 51068, 321, 362, 11095, 11, 321, 458, 689, 307, 264, 493, 11, 689, 307, 760, 11, 689, 307, 1411, 11, 689, 307, 558, 11, 558, 11, 51336, 51336, 1604, 300, 321, 458, 264, 21739, 295, 295, 264, 13891, 322, 264, 10748, 11, 321, 458, 300, 13, 583, 341, 307, 51692, 51692], "temperature": 0.0, "avg_logprob": -0.14387985304290174, "compression_ratio": 1.829268292682927, "no_speech_prob": 2.8383219614624977e-05}, {"id": 562, "seek": 385052, "start": 3850.52, "end": 3856.12, "text": " different for graphs, we don't have any notion of direction, we don't know where is the where is up,", "tokens": [50364, 819, 337, 24877, 11, 321, 500, 380, 362, 604, 10710, 295, 3513, 11, 321, 500, 380, 458, 689, 307, 264, 689, 307, 493, 11, 50644, 50644, 689, 307, 760, 11, 689, 307, 1411, 11, 689, 307, 558, 13, 407, 264, 551, 11, 264, 787, 551, 300, 321, 393, 360, 412, 341, 50900, 50900, 935, 11, 307, 300, 321, 393, 787, 14722, 38018, 39173, 15995, 13, 1119, 310, 39173, 15995, 1355, 300, 264, 2158, 51236, 51236, 295, 264, 6608, 486, 312, 264, 912, 11, 291, 458, 11, 337, 294, 439, 11095, 11, 337, 11, 337, 11, 337, 11, 337, 17796, 11, 51680, 51680], "temperature": 0.0, "avg_logprob": -0.11657097706427941, "compression_ratio": 1.915, "no_speech_prob": 3.237242708564736e-06}, {"id": 563, "seek": 385052, "start": 3856.12, "end": 3861.24, "text": " where is down, where is left, where is right. So the thing, the only thing that we can do at this", "tokens": [50364, 819, 337, 24877, 11, 321, 500, 380, 362, 604, 10710, 295, 3513, 11, 321, 500, 380, 458, 689, 307, 264, 689, 307, 493, 11, 50644, 50644, 689, 307, 760, 11, 689, 307, 1411, 11, 689, 307, 558, 13, 407, 264, 551, 11, 264, 787, 551, 300, 321, 393, 360, 412, 341, 50900, 50900, 935, 11, 307, 300, 321, 393, 787, 14722, 38018, 39173, 15995, 13, 1119, 310, 39173, 15995, 1355, 300, 264, 2158, 51236, 51236, 295, 264, 6608, 486, 312, 264, 912, 11, 291, 458, 11, 337, 294, 439, 11095, 11, 337, 11, 337, 11, 337, 11, 337, 17796, 11, 51680, 51680], "temperature": 0.0, "avg_logprob": -0.11657097706427941, "compression_ratio": 1.915, "no_speech_prob": 3.237242708564736e-06}, {"id": 564, "seek": 385052, "start": 3861.24, "end": 3867.96, "text": " point, is that we can only compute isotropic filters. Isotropic filters means that the value", "tokens": [50364, 819, 337, 24877, 11, 321, 500, 380, 362, 604, 10710, 295, 3513, 11, 321, 500, 380, 458, 689, 307, 264, 689, 307, 493, 11, 50644, 50644, 689, 307, 760, 11, 689, 307, 1411, 11, 689, 307, 558, 13, 407, 264, 551, 11, 264, 787, 551, 300, 321, 393, 360, 412, 341, 50900, 50900, 935, 11, 307, 300, 321, 393, 787, 14722, 38018, 39173, 15995, 13, 1119, 310, 39173, 15995, 1355, 300, 264, 2158, 51236, 51236, 295, 264, 6608, 486, 312, 264, 912, 11, 291, 458, 11, 337, 294, 439, 11095, 11, 337, 11, 337, 11, 337, 11, 337, 17796, 11, 51680, 51680], "temperature": 0.0, "avg_logprob": -0.11657097706427941, "compression_ratio": 1.915, "no_speech_prob": 3.237242708564736e-06}, {"id": 565, "seek": 385052, "start": 3867.96, "end": 3876.84, "text": " of the filter will be the same, you know, for in all directions, for, for, for, for cycles,", "tokens": [50364, 819, 337, 24877, 11, 321, 500, 380, 362, 604, 10710, 295, 3513, 11, 321, 500, 380, 458, 689, 307, 264, 689, 307, 493, 11, 50644, 50644, 689, 307, 760, 11, 689, 307, 1411, 11, 689, 307, 558, 13, 407, 264, 551, 11, 264, 787, 551, 300, 321, 393, 360, 412, 341, 50900, 50900, 935, 11, 307, 300, 321, 393, 787, 14722, 38018, 39173, 15995, 13, 1119, 310, 39173, 15995, 1355, 300, 264, 2158, 51236, 51236, 295, 264, 6608, 486, 312, 264, 912, 11, 291, 458, 11, 337, 294, 439, 11095, 11, 337, 11, 337, 11, 337, 11, 337, 17796, 11, 51680, 51680], "temperature": 0.0, "avg_logprob": -0.11657097706427941, "compression_ratio": 1.915, "no_speech_prob": 3.237242708564736e-06}, {"id": 566, "seek": 387684, "start": 3876.84, "end": 3882.36, "text": " okay, for the four cycles of the same radius. Okay, so this is, this is what we can get, we can only", "tokens": [50364, 1392, 11, 337, 264, 1451, 17796, 295, 264, 912, 15845, 13, 1033, 11, 370, 341, 307, 11, 341, 307, 437, 321, 393, 483, 11, 321, 393, 787, 50640, 50640, 483, 38018, 39173, 15995, 562, 321, 764, 257, 11409, 7129, 11, 570, 321, 362, 572, 10710, 295, 3513, 322, 23211, 50972, 50972, 24877, 13, 400, 321, 808, 646, 281, 300, 11, 321, 808, 646, 281, 264, 38018, 27514, 5717, 364, 271, 310, 27514, 257, 857, 1780, 13, 51316, 51520, 1033, 11, 370, 437, 321, 437, 321, 630, 611, 307, 281, 588, 2661, 11, 286, 500, 380, 11, 286, 500, 380, 362, 264, 565, 13, 876, 11, 51832, 51832], "temperature": 0.0, "avg_logprob": -0.14591599385672754, "compression_ratio": 1.7477064220183487, "no_speech_prob": 1.4508234016830102e-05}, {"id": 567, "seek": 387684, "start": 3882.36, "end": 3889.0, "text": " get isotropic filters when we use a chipnet, because we have no notion of direction on arbitrary", "tokens": [50364, 1392, 11, 337, 264, 1451, 17796, 295, 264, 912, 15845, 13, 1033, 11, 370, 341, 307, 11, 341, 307, 437, 321, 393, 483, 11, 321, 393, 787, 50640, 50640, 483, 38018, 39173, 15995, 562, 321, 764, 257, 11409, 7129, 11, 570, 321, 362, 572, 10710, 295, 3513, 322, 23211, 50972, 50972, 24877, 13, 400, 321, 808, 646, 281, 300, 11, 321, 808, 646, 281, 264, 38018, 27514, 5717, 364, 271, 310, 27514, 257, 857, 1780, 13, 51316, 51520, 1033, 11, 370, 437, 321, 437, 321, 630, 611, 307, 281, 588, 2661, 11, 286, 500, 380, 11, 286, 500, 380, 362, 264, 565, 13, 876, 11, 51832, 51832], "temperature": 0.0, "avg_logprob": -0.14591599385672754, "compression_ratio": 1.7477064220183487, "no_speech_prob": 1.4508234016830102e-05}, {"id": 568, "seek": 387684, "start": 3889.0, "end": 3895.88, "text": " graphs. And we come back to that, we come back to the isotropy versus anisotropy a bit later.", "tokens": [50364, 1392, 11, 337, 264, 1451, 17796, 295, 264, 912, 15845, 13, 1033, 11, 370, 341, 307, 11, 341, 307, 437, 321, 393, 483, 11, 321, 393, 787, 50640, 50640, 483, 38018, 39173, 15995, 562, 321, 764, 257, 11409, 7129, 11, 570, 321, 362, 572, 10710, 295, 3513, 322, 23211, 50972, 50972, 24877, 13, 400, 321, 808, 646, 281, 300, 11, 321, 808, 646, 281, 264, 38018, 27514, 5717, 364, 271, 310, 27514, 257, 857, 1780, 13, 51316, 51520, 1033, 11, 370, 437, 321, 437, 321, 630, 611, 307, 281, 588, 2661, 11, 286, 500, 380, 11, 286, 500, 380, 362, 264, 565, 13, 876, 11, 51832, 51832], "temperature": 0.0, "avg_logprob": -0.14591599385672754, "compression_ratio": 1.7477064220183487, "no_speech_prob": 1.4508234016830102e-05}, {"id": 569, "seek": 387684, "start": 3899.96, "end": 3906.2000000000003, "text": " Okay, so what we what we did also is to very quickly, I don't, I don't have the time. Oh,", "tokens": [50364, 1392, 11, 337, 264, 1451, 17796, 295, 264, 912, 15845, 13, 1033, 11, 370, 341, 307, 11, 341, 307, 437, 321, 393, 483, 11, 321, 393, 787, 50640, 50640, 483, 38018, 39173, 15995, 562, 321, 764, 257, 11409, 7129, 11, 570, 321, 362, 572, 10710, 295, 3513, 322, 23211, 50972, 50972, 24877, 13, 400, 321, 808, 646, 281, 300, 11, 321, 808, 646, 281, 264, 38018, 27514, 5717, 364, 271, 310, 27514, 257, 857, 1780, 13, 51316, 51520, 1033, 11, 370, 437, 321, 437, 321, 630, 611, 307, 281, 588, 2661, 11, 286, 500, 380, 11, 286, 500, 380, 362, 264, 565, 13, 876, 11, 51832, 51832], "temperature": 0.0, "avg_logprob": -0.14591599385672754, "compression_ratio": 1.7477064220183487, "no_speech_prob": 1.4508234016830102e-05}, {"id": 570, "seek": 390620, "start": 3906.2, "end": 3911.7999999999997, "text": " wow, the time is up. So I need to speed up a little bit. So we did we did extend also this", "tokens": [50364, 6076, 11, 264, 565, 307, 493, 13, 407, 286, 643, 281, 3073, 493, 257, 707, 857, 13, 407, 321, 630, 321, 630, 10101, 611, 341, 50644, 50716, 42761, 45216, 490, 472, 4295, 281, 3866, 24877, 13, 407, 291, 393, 360, 300, 11, 291, 458, 11, 309, 311, 411, 50988, 50988, 24360, 490, 502, 35, 6358, 9007, 281, 568, 35, 3256, 9007, 13, 407, 10320, 307, 44003, 51284, 51312, 15325, 281, 360, 13, 400, 321, 630, 300, 11, 291, 458, 11, 337, 337, 1365, 11, 337, 2748, 260, 3652, 11, 51596, 51596], "temperature": 0.0, "avg_logprob": -0.08253948150142547, "compression_ratio": 1.6327433628318584, "no_speech_prob": 1.882293145172298e-05}, {"id": 571, "seek": 390620, "start": 3913.24, "end": 3918.68, "text": " spectral convolution from one graph to multiple graphs. So you can do that, you know, it's like", "tokens": [50364, 6076, 11, 264, 565, 307, 493, 13, 407, 286, 643, 281, 3073, 493, 257, 707, 857, 13, 407, 321, 630, 321, 630, 10101, 611, 341, 50644, 50716, 42761, 45216, 490, 472, 4295, 281, 3866, 24877, 13, 407, 291, 393, 360, 300, 11, 291, 458, 11, 309, 311, 411, 50988, 50988, 24360, 490, 502, 35, 6358, 9007, 281, 568, 35, 3256, 9007, 13, 407, 10320, 307, 44003, 51284, 51312, 15325, 281, 360, 13, 400, 321, 630, 300, 11, 291, 458, 11, 337, 337, 1365, 11, 337, 2748, 260, 3652, 11, 51596, 51596], "temperature": 0.0, "avg_logprob": -0.08253948150142547, "compression_ratio": 1.6327433628318584, "no_speech_prob": 1.882293145172298e-05}, {"id": 572, "seek": 390620, "start": 3918.68, "end": 3924.6, "text": " extending from 1D signal processing to 2D image processing. So extension is mathematically", "tokens": [50364, 6076, 11, 264, 565, 307, 493, 13, 407, 286, 643, 281, 3073, 493, 257, 707, 857, 13, 407, 321, 630, 321, 630, 10101, 611, 341, 50644, 50716, 42761, 45216, 490, 472, 4295, 281, 3866, 24877, 13, 407, 291, 393, 360, 300, 11, 291, 458, 11, 309, 311, 411, 50988, 50988, 24360, 490, 502, 35, 6358, 9007, 281, 568, 35, 3256, 9007, 13, 407, 10320, 307, 44003, 51284, 51312, 15325, 281, 360, 13, 400, 321, 630, 300, 11, 291, 458, 11, 337, 337, 1365, 11, 337, 2748, 260, 3652, 11, 51596, 51596], "temperature": 0.0, "avg_logprob": -0.08253948150142547, "compression_ratio": 1.6327433628318584, "no_speech_prob": 1.882293145172298e-05}, {"id": 573, "seek": 390620, "start": 3925.16, "end": 3930.8399999999997, "text": " straightforward to do. And we did that, you know, for for example, for recommender systems,", "tokens": [50364, 6076, 11, 264, 565, 307, 493, 13, 407, 286, 643, 281, 3073, 493, 257, 707, 857, 13, 407, 321, 630, 321, 630, 10101, 611, 341, 50644, 50716, 42761, 45216, 490, 472, 4295, 281, 3866, 24877, 13, 407, 291, 393, 360, 300, 11, 291, 458, 11, 309, 311, 411, 50988, 50988, 24360, 490, 502, 35, 6358, 9007, 281, 568, 35, 3256, 9007, 13, 407, 10320, 307, 44003, 51284, 51312, 15325, 281, 360, 13, 400, 321, 630, 300, 11, 291, 458, 11, 337, 337, 1365, 11, 337, 2748, 260, 3652, 11, 51596, 51596], "temperature": 0.0, "avg_logprob": -0.08253948150142547, "compression_ratio": 1.6327433628318584, "no_speech_prob": 1.882293145172298e-05}, {"id": 574, "seek": 393084, "start": 3930.84, "end": 3936.6000000000004, "text": " because we have users of movies and users of graphs. So that we also, as I said before,", "tokens": [50364, 570, 321, 362, 5022, 295, 6233, 293, 5022, 295, 24877, 13, 407, 300, 321, 611, 11, 382, 286, 848, 949, 11, 50652, 50652, 307, 300, 291, 393, 764, 428, 2954, 11, 291, 458, 11, 41488, 26110, 5143, 13, 407, 321, 764, 350, 12, 259, 1385, 11, 51052, 51052, 570, 3351, 65, 749, 675, 85, 366, 23742, 281, 2654, 1125, 7893, 13543, 295, 1179, 11, 597, 366, 1936, 51352, 51352, 264, 4295, 4456, 13, 492, 764, 300, 746, 544, 4005, 11, 291, 458, 11, 544, 4005, 42761, 51776, 51776], "temperature": 0.0, "avg_logprob": -0.1451104164123535, "compression_ratio": 1.6294642857142858, "no_speech_prob": 4.171691034571268e-05}, {"id": 575, "seek": 393084, "start": 3936.6000000000004, "end": 3944.6000000000004, "text": " is that you can use your favorite, you know, orthogonal polynomial basis. So we use k-inets,", "tokens": [50364, 570, 321, 362, 5022, 295, 6233, 293, 5022, 295, 24877, 13, 407, 300, 321, 611, 11, 382, 286, 848, 949, 11, 50652, 50652, 307, 300, 291, 393, 764, 428, 2954, 11, 291, 458, 11, 41488, 26110, 5143, 13, 407, 321, 764, 350, 12, 259, 1385, 11, 51052, 51052, 570, 3351, 65, 749, 675, 85, 366, 23742, 281, 2654, 1125, 7893, 13543, 295, 1179, 11, 597, 366, 1936, 51352, 51352, 264, 4295, 4456, 13, 492, 764, 300, 746, 544, 4005, 11, 291, 458, 11, 544, 4005, 42761, 51776, 51776], "temperature": 0.0, "avg_logprob": -0.1451104164123535, "compression_ratio": 1.6294642857142858, "no_speech_prob": 4.171691034571268e-05}, {"id": 576, "seek": 393084, "start": 3944.6000000000004, "end": 3950.6000000000004, "text": " because Chebyshev are unstable to localize frequency bands of interest, which are basically", "tokens": [50364, 570, 321, 362, 5022, 295, 6233, 293, 5022, 295, 24877, 13, 407, 300, 321, 611, 11, 382, 286, 848, 949, 11, 50652, 50652, 307, 300, 291, 393, 764, 428, 2954, 11, 291, 458, 11, 41488, 26110, 5143, 13, 407, 321, 764, 350, 12, 259, 1385, 11, 51052, 51052, 570, 3351, 65, 749, 675, 85, 366, 23742, 281, 2654, 1125, 7893, 13543, 295, 1179, 11, 597, 366, 1936, 51352, 51352, 264, 4295, 4456, 13, 492, 764, 300, 746, 544, 4005, 11, 291, 458, 11, 544, 4005, 42761, 51776, 51776], "temperature": 0.0, "avg_logprob": -0.1451104164123535, "compression_ratio": 1.6294642857142858, "no_speech_prob": 4.171691034571268e-05}, {"id": 577, "seek": 393084, "start": 3950.6000000000004, "end": 3959.08, "text": " the graph communities. We use that something more powerful, you know, more powerful spectral", "tokens": [50364, 570, 321, 362, 5022, 295, 6233, 293, 5022, 295, 24877, 13, 407, 300, 321, 611, 11, 382, 286, 848, 949, 11, 50652, 50652, 307, 300, 291, 393, 764, 428, 2954, 11, 291, 458, 11, 41488, 26110, 5143, 13, 407, 321, 764, 350, 12, 259, 1385, 11, 51052, 51052, 570, 3351, 65, 749, 675, 85, 366, 23742, 281, 2654, 1125, 7893, 13543, 295, 1179, 11, 597, 366, 1936, 51352, 51352, 264, 4295, 4456, 13, 492, 764, 300, 746, 544, 4005, 11, 291, 458, 11, 544, 4005, 42761, 51776, 51776], "temperature": 0.0, "avg_logprob": -0.1451104164123535, "compression_ratio": 1.6294642857142858, "no_speech_prob": 4.171691034571268e-05}, {"id": 578, "seek": 395908, "start": 3959.08, "end": 3967.48, "text": " functions. Okay, which is going in it. Okay, so now let me go to the to the to this class of", "tokens": [50364, 6828, 13, 1033, 11, 597, 307, 516, 294, 309, 13, 1033, 11, 370, 586, 718, 385, 352, 281, 264, 281, 264, 281, 341, 1508, 295, 50784, 50784, 4295, 21056, 300, 286, 818, 2121, 4295, 21056, 13, 400, 550, 337, 341, 1508, 11, 286, 478, 516, 51012, 51012, 646, 281, 264, 12379, 14324, 11, 291, 458, 11, 7123, 295, 45216, 13, 407, 577, 321, 360, 51268, 51268, 12379, 14324, 337, 24877, 13, 407, 1604, 300, 264, 2135, 2734, 11, 264, 2135, 2734, 562, 291, 528, 281, 360, 51676, 51676], "temperature": 0.0, "avg_logprob": -0.18255683051215277, "compression_ratio": 1.7451923076923077, "no_speech_prob": 2.140648939530365e-05}, {"id": 579, "seek": 395908, "start": 3967.48, "end": 3972.04, "text": " graph coordinates that I call special graph coordinates. And then for this class, I'm going", "tokens": [50364, 6828, 13, 1033, 11, 597, 307, 516, 294, 309, 13, 1033, 11, 370, 586, 718, 385, 352, 281, 264, 281, 264, 281, 341, 1508, 295, 50784, 50784, 4295, 21056, 300, 286, 818, 2121, 4295, 21056, 13, 400, 550, 337, 341, 1508, 11, 286, 478, 516, 51012, 51012, 646, 281, 264, 12379, 14324, 11, 291, 458, 11, 7123, 295, 45216, 13, 407, 577, 321, 360, 51268, 51268, 12379, 14324, 337, 24877, 13, 407, 1604, 300, 264, 2135, 2734, 11, 264, 2135, 2734, 562, 291, 528, 281, 360, 51676, 51676], "temperature": 0.0, "avg_logprob": -0.18255683051215277, "compression_ratio": 1.7451923076923077, "no_speech_prob": 2.140648939530365e-05}, {"id": 580, "seek": 395908, "start": 3972.04, "end": 3977.16, "text": " back to the template matching, you know, definition of convolution. So how we do", "tokens": [50364, 6828, 13, 1033, 11, 597, 307, 516, 294, 309, 13, 1033, 11, 370, 586, 718, 385, 352, 281, 264, 281, 264, 281, 341, 1508, 295, 50784, 50784, 4295, 21056, 300, 286, 818, 2121, 4295, 21056, 13, 400, 550, 337, 341, 1508, 11, 286, 478, 516, 51012, 51012, 646, 281, 264, 12379, 14324, 11, 291, 458, 11, 7123, 295, 45216, 13, 407, 577, 321, 360, 51268, 51268, 12379, 14324, 337, 24877, 13, 407, 1604, 300, 264, 2135, 2734, 11, 264, 2135, 2734, 562, 291, 528, 281, 360, 51676, 51676], "temperature": 0.0, "avg_logprob": -0.18255683051215277, "compression_ratio": 1.7451923076923077, "no_speech_prob": 2.140648939530365e-05}, {"id": 581, "seek": 395908, "start": 3977.16, "end": 3985.3199999999997, "text": " template matching for graphs. So remember that the main issue, the main issue when you want to do", "tokens": [50364, 6828, 13, 1033, 11, 597, 307, 516, 294, 309, 13, 1033, 11, 370, 586, 718, 385, 352, 281, 264, 281, 264, 281, 341, 1508, 295, 50784, 50784, 4295, 21056, 300, 286, 818, 2121, 4295, 21056, 13, 400, 550, 337, 341, 1508, 11, 286, 478, 516, 51012, 51012, 646, 281, 264, 12379, 14324, 11, 291, 458, 11, 7123, 295, 45216, 13, 407, 577, 321, 360, 51268, 51268, 12379, 14324, 337, 24877, 13, 407, 1604, 300, 264, 2135, 2734, 11, 264, 2135, 2734, 562, 291, 528, 281, 360, 51676, 51676], "temperature": 0.0, "avg_logprob": -0.18255683051215277, "compression_ratio": 1.7451923076923077, "no_speech_prob": 2.140648939530365e-05}, {"id": 582, "seek": 398532, "start": 3985.32, "end": 3991.56, "text": " template matching for graph is that you don't have any node ordering or positioning for your template.", "tokens": [50364, 12379, 14324, 337, 4295, 307, 300, 291, 500, 380, 362, 604, 9984, 21739, 420, 26381, 337, 428, 12379, 13, 50676, 50712, 1033, 11, 321, 500, 380, 362, 604, 26381, 13, 407, 1936, 11, 264, 787, 551, 300, 321, 362, 11, 321, 362, 264, 51012, 51056, 8186, 295, 264, 13891, 11, 293, 300, 311, 309, 13, 583, 264, 8186, 307, 406, 1547, 281, 2995, 11, 291, 458, 11, 1589, 51348, 51348, 1296, 13891, 13, 407, 577, 393, 321, 1715, 12379, 14324, 281, 312, 33270, 394, 281, 9984, 13075, 2144, 30, 51808, 51808], "temperature": 0.0, "avg_logprob": -0.11986739661103936, "compression_ratio": 1.7342342342342343, "no_speech_prob": 1.7305961591773666e-05}, {"id": 583, "seek": 398532, "start": 3992.28, "end": 3998.28, "text": " Okay, we don't have any positioning. So basically, the only thing that we have, we have the", "tokens": [50364, 12379, 14324, 337, 4295, 307, 300, 291, 500, 380, 362, 604, 9984, 21739, 420, 26381, 337, 428, 12379, 13, 50676, 50712, 1033, 11, 321, 500, 380, 362, 604, 26381, 13, 407, 1936, 11, 264, 787, 551, 300, 321, 362, 11, 321, 362, 264, 51012, 51056, 8186, 295, 264, 13891, 11, 293, 300, 311, 309, 13, 583, 264, 8186, 307, 406, 1547, 281, 2995, 11, 291, 458, 11, 1589, 51348, 51348, 1296, 13891, 13, 407, 577, 393, 321, 1715, 12379, 14324, 281, 312, 33270, 394, 281, 9984, 13075, 2144, 30, 51808, 51808], "temperature": 0.0, "avg_logprob": -0.11986739661103936, "compression_ratio": 1.7342342342342343, "no_speech_prob": 1.7305961591773666e-05}, {"id": 584, "seek": 398532, "start": 3999.1600000000003, "end": 4005.0, "text": " index of the nodes, and that's it. But the index is not enough to match, you know, information", "tokens": [50364, 12379, 14324, 337, 4295, 307, 300, 291, 500, 380, 362, 604, 9984, 21739, 420, 26381, 337, 428, 12379, 13, 50676, 50712, 1033, 11, 321, 500, 380, 362, 604, 26381, 13, 407, 1936, 11, 264, 787, 551, 300, 321, 362, 11, 321, 362, 264, 51012, 51056, 8186, 295, 264, 13891, 11, 293, 300, 311, 309, 13, 583, 264, 8186, 307, 406, 1547, 281, 2995, 11, 291, 458, 11, 1589, 51348, 51348, 1296, 13891, 13, 407, 577, 393, 321, 1715, 12379, 14324, 281, 312, 33270, 394, 281, 9984, 13075, 2144, 30, 51808, 51808], "temperature": 0.0, "avg_logprob": -0.11986739661103936, "compression_ratio": 1.7342342342342343, "no_speech_prob": 1.7305961591773666e-05}, {"id": 585, "seek": 398532, "start": 4005.0, "end": 4014.2000000000003, "text": " between nodes. So how can we design template matching to be invariant to node parameterization?", "tokens": [50364, 12379, 14324, 337, 4295, 307, 300, 291, 500, 380, 362, 604, 9984, 21739, 420, 26381, 337, 428, 12379, 13, 50676, 50712, 1033, 11, 321, 500, 380, 362, 604, 26381, 13, 407, 1936, 11, 264, 787, 551, 300, 321, 362, 11, 321, 362, 264, 51012, 51056, 8186, 295, 264, 13891, 11, 293, 300, 311, 309, 13, 583, 264, 8186, 307, 406, 1547, 281, 2995, 11, 291, 458, 11, 1589, 51348, 51348, 1296, 13891, 13, 407, 577, 393, 321, 1715, 12379, 14324, 281, 312, 33270, 394, 281, 9984, 13075, 2144, 30, 51808, 51808], "temperature": 0.0, "avg_logprob": -0.11986739661103936, "compression_ratio": 1.7342342342342343, "no_speech_prob": 1.7305961591773666e-05}, {"id": 586, "seek": 401420, "start": 4014.2, "end": 4021.56, "text": " Okay, so you have a graph, this index of the node is maybe, let's say, six, but it's completely", "tokens": [50364, 1033, 11, 370, 291, 362, 257, 4295, 11, 341, 8186, 295, 264, 9984, 307, 1310, 11, 718, 311, 584, 11, 2309, 11, 457, 309, 311, 2584, 50732, 50732, 23211, 13, 286, 393, 362, 364, 8186, 365, 264, 1230, 2272, 17, 11, 337, 1365, 13, 407, 286, 528, 281, 312, 1075, 281, 360, 51060, 51060, 12379, 14324, 21761, 295, 264, 8186, 295, 341, 9984, 13, 1033, 11, 370, 577, 286, 360, 300, 13, 407, 264, 51412, 51412], "temperature": 0.0, "avg_logprob": -0.10649732443002555, "compression_ratio": 1.521978021978022, "no_speech_prob": 1.0949491297651548e-05}, {"id": 587, "seek": 401420, "start": 4021.56, "end": 4028.12, "text": " arbitrary. I can have an index with the number 122, for example. So I want to be able to do", "tokens": [50364, 1033, 11, 370, 291, 362, 257, 4295, 11, 341, 8186, 295, 264, 9984, 307, 1310, 11, 718, 311, 584, 11, 2309, 11, 457, 309, 311, 2584, 50732, 50732, 23211, 13, 286, 393, 362, 364, 8186, 365, 264, 1230, 2272, 17, 11, 337, 1365, 13, 407, 286, 528, 281, 312, 1075, 281, 360, 51060, 51060, 12379, 14324, 21761, 295, 264, 8186, 295, 341, 9984, 13, 1033, 11, 370, 577, 286, 360, 300, 13, 407, 264, 51412, 51412], "temperature": 0.0, "avg_logprob": -0.10649732443002555, "compression_ratio": 1.521978021978022, "no_speech_prob": 1.0949491297651548e-05}, {"id": 588, "seek": 401420, "start": 4028.12, "end": 4035.16, "text": " template matching independently of the index of this node. Okay, so how I do that. So the", "tokens": [50364, 1033, 11, 370, 291, 362, 257, 4295, 11, 341, 8186, 295, 264, 9984, 307, 1310, 11, 718, 311, 584, 11, 2309, 11, 457, 309, 311, 2584, 50732, 50732, 23211, 13, 286, 393, 362, 364, 8186, 365, 264, 1230, 2272, 17, 11, 337, 1365, 13, 407, 286, 528, 281, 312, 1075, 281, 360, 51060, 51060, 12379, 14324, 21761, 295, 264, 8186, 295, 341, 9984, 13, 1033, 11, 370, 577, 286, 360, 300, 13, 407, 264, 51412, 51412], "temperature": 0.0, "avg_logprob": -0.10649732443002555, "compression_ratio": 1.521978021978022, "no_speech_prob": 1.0949491297651548e-05}, {"id": 589, "seek": 403516, "start": 4035.16, "end": 4045.56, "text": " simplest thing you can do is actually to have only one template vector to do the matching.", "tokens": [50364, 22811, 551, 291, 393, 360, 307, 767, 281, 362, 787, 472, 12379, 8062, 281, 360, 264, 14324, 13, 50884, 50912, 407, 291, 500, 380, 362, 11, 291, 458, 11, 343, 38, 16, 11, 343, 38, 17, 11, 343, 38, 18, 11, 291, 500, 380, 362, 341, 11, 291, 445, 362, 472, 8062, 343, 11, 51288, 51288, 293, 291, 366, 884, 264, 14324, 295, 341, 8062, 365, 439, 661, 4122, 322, 428, 4295, 13, 51648, 51704], "temperature": 0.0, "avg_logprob": -0.1425862374243798, "compression_ratio": 1.6047904191616766, "no_speech_prob": 1.5423769582412206e-05}, {"id": 590, "seek": 403516, "start": 4046.12, "end": 4053.64, "text": " So you don't have, you know, WG1, WG2, WG3, you don't have this, you just have one vector W,", "tokens": [50364, 22811, 551, 291, 393, 360, 307, 767, 281, 362, 787, 472, 12379, 8062, 281, 360, 264, 14324, 13, 50884, 50912, 407, 291, 500, 380, 362, 11, 291, 458, 11, 343, 38, 16, 11, 343, 38, 17, 11, 343, 38, 18, 11, 291, 500, 380, 362, 341, 11, 291, 445, 362, 472, 8062, 343, 11, 51288, 51288, 293, 291, 366, 884, 264, 14324, 295, 341, 8062, 365, 439, 661, 4122, 322, 428, 4295, 13, 51648, 51704], "temperature": 0.0, "avg_logprob": -0.1425862374243798, "compression_ratio": 1.6047904191616766, "no_speech_prob": 1.5423769582412206e-05}, {"id": 591, "seek": 403516, "start": 4053.64, "end": 4060.8399999999997, "text": " and you are doing the matching of this vector with all other features on your graph.", "tokens": [50364, 22811, 551, 291, 393, 360, 307, 767, 281, 362, 787, 472, 12379, 8062, 281, 360, 264, 14324, 13, 50884, 50912, 407, 291, 500, 380, 362, 11, 291, 458, 11, 343, 38, 16, 11, 343, 38, 17, 11, 343, 38, 18, 11, 291, 500, 380, 362, 341, 11, 291, 445, 362, 472, 8062, 343, 11, 51288, 51288, 293, 291, 366, 884, 264, 14324, 295, 341, 8062, 365, 439, 661, 4122, 322, 428, 4295, 13, 51648, 51704], "temperature": 0.0, "avg_logprob": -0.1425862374243798, "compression_ratio": 1.6047904191616766, "no_speech_prob": 1.5423769582412206e-05}, {"id": 592, "seek": 406084, "start": 4060.84, "end": 4066.6000000000004, "text": " Okay, this is the simplest template feature matching you can do, which is invariant by node", "tokens": [50364, 1033, 11, 341, 307, 264, 22811, 12379, 4111, 14324, 291, 393, 360, 11, 597, 307, 33270, 394, 538, 9984, 50652, 50652, 13075, 2144, 13, 400, 767, 11, 341, 4707, 307, 516, 281, 312, 1143, 337, 881, 4295, 18161, 9590, 50924, 50924, 965, 13, 1033, 11, 370, 510, 307, 264, 18894, 7123, 13, 407, 286, 478, 445, 516, 281, 360, 264, 1674, 51348, 51348, 1296, 264, 12379, 8062, 343, 412, 4583, 441, 11, 370, 341, 307, 257, 413, 538, 472, 11, 293, 286, 362, 264, 8062, 412, 9984, 508, 11, 51816, 51816], "temperature": 0.0, "avg_logprob": -0.1697469731812836, "compression_ratio": 1.5625, "no_speech_prob": 4.849560809816467e-06}, {"id": 593, "seek": 406084, "start": 4066.6000000000004, "end": 4072.04, "text": " parameterization. And actually, this property is going to be used for most graph neural networks", "tokens": [50364, 1033, 11, 341, 307, 264, 22811, 12379, 4111, 14324, 291, 393, 360, 11, 597, 307, 33270, 394, 538, 9984, 50652, 50652, 13075, 2144, 13, 400, 767, 11, 341, 4707, 307, 516, 281, 312, 1143, 337, 881, 4295, 18161, 9590, 50924, 50924, 965, 13, 1033, 11, 370, 510, 307, 264, 18894, 7123, 13, 407, 286, 478, 445, 516, 281, 360, 264, 1674, 51348, 51348, 1296, 264, 12379, 8062, 343, 412, 4583, 441, 11, 370, 341, 307, 257, 413, 538, 472, 11, 293, 286, 362, 264, 8062, 412, 9984, 508, 11, 51816, 51816], "temperature": 0.0, "avg_logprob": -0.1697469731812836, "compression_ratio": 1.5625, "no_speech_prob": 4.849560809816467e-06}, {"id": 594, "seek": 406084, "start": 4072.04, "end": 4080.52, "text": " today. Okay, so here is the mathematical definition. So I'm just going to do the product", "tokens": [50364, 1033, 11, 341, 307, 264, 22811, 12379, 4111, 14324, 291, 393, 360, 11, 597, 307, 33270, 394, 538, 9984, 50652, 50652, 13075, 2144, 13, 400, 767, 11, 341, 4707, 307, 516, 281, 312, 1143, 337, 881, 4295, 18161, 9590, 50924, 50924, 965, 13, 1033, 11, 370, 510, 307, 264, 18894, 7123, 13, 407, 286, 478, 445, 516, 281, 360, 264, 1674, 51348, 51348, 1296, 264, 12379, 8062, 343, 412, 4583, 441, 11, 370, 341, 307, 257, 413, 538, 472, 11, 293, 286, 362, 264, 8062, 412, 9984, 508, 11, 51816, 51816], "temperature": 0.0, "avg_logprob": -0.1697469731812836, "compression_ratio": 1.5625, "no_speech_prob": 4.849560809816467e-06}, {"id": 595, "seek": 406084, "start": 4080.52, "end": 4089.88, "text": " between the template vector W at layer L, so this is a D by one, and I have the vector at node J,", "tokens": [50364, 1033, 11, 341, 307, 264, 22811, 12379, 4111, 14324, 291, 393, 360, 11, 597, 307, 33270, 394, 538, 9984, 50652, 50652, 13075, 2144, 13, 400, 767, 11, 341, 4707, 307, 516, 281, 312, 1143, 337, 881, 4295, 18161, 9590, 50924, 50924, 965, 13, 1033, 11, 370, 510, 307, 264, 18894, 7123, 13, 407, 286, 478, 445, 516, 281, 360, 264, 1674, 51348, 51348, 1296, 264, 12379, 8062, 343, 412, 4583, 441, 11, 370, 341, 307, 257, 413, 538, 472, 11, 293, 286, 362, 264, 8062, 412, 9984, 508, 11, 51816, 51816], "temperature": 0.0, "avg_logprob": -0.1697469731812836, "compression_ratio": 1.5625, "no_speech_prob": 4.849560809816467e-06}, {"id": 596, "seek": 408988, "start": 4089.88, "end": 4095.1600000000003, "text": " which is also the dimensionality D by one. Okay, I will get a scalar. So here this is only for one", "tokens": [50364, 597, 307, 611, 264, 10139, 1860, 413, 538, 472, 13, 1033, 11, 286, 486, 483, 257, 39684, 13, 407, 510, 341, 307, 787, 337, 472, 50628, 50628, 4111, 13, 2720, 1164, 11, 291, 486, 362, 281, 483, 544, 4122, 13, 407, 2602, 295, 1419, 257, 8062, 413, 538, 472, 11, 50908, 50908, 291, 434, 516, 281, 764, 257, 8141, 413, 538, 413, 13, 407, 341, 636, 291, 393, 483, 11, 291, 458, 11, 413, 4122, 337, 1184, 9984, 286, 13, 51296, 51340, 1033, 11, 293, 550, 370, 341, 307, 264, 10290, 412, 9984, 286, 13, 286, 393, 829, 1203, 294, 8062, 10290, 13, 51736, 51736], "temperature": 0.0, "avg_logprob": -0.20772769963629892, "compression_ratio": 1.7412280701754386, "no_speech_prob": 6.5396297941333614e-06}, {"id": 597, "seek": 408988, "start": 4095.1600000000003, "end": 4100.76, "text": " feature. Of course, you will have to get more features. So instead of having a vector D by one,", "tokens": [50364, 597, 307, 611, 264, 10139, 1860, 413, 538, 472, 13, 1033, 11, 286, 486, 483, 257, 39684, 13, 407, 510, 341, 307, 787, 337, 472, 50628, 50628, 4111, 13, 2720, 1164, 11, 291, 486, 362, 281, 483, 544, 4122, 13, 407, 2602, 295, 1419, 257, 8062, 413, 538, 472, 11, 50908, 50908, 291, 434, 516, 281, 764, 257, 8141, 413, 538, 413, 13, 407, 341, 636, 291, 393, 483, 11, 291, 458, 11, 413, 4122, 337, 1184, 9984, 286, 13, 51296, 51340, 1033, 11, 293, 550, 370, 341, 307, 264, 10290, 412, 9984, 286, 13, 286, 393, 829, 1203, 294, 8062, 10290, 13, 51736, 51736], "temperature": 0.0, "avg_logprob": -0.20772769963629892, "compression_ratio": 1.7412280701754386, "no_speech_prob": 6.5396297941333614e-06}, {"id": 598, "seek": 408988, "start": 4100.76, "end": 4108.52, "text": " you're going to use a matrix D by D. So this way you can get, you know, D features for each node I.", "tokens": [50364, 597, 307, 611, 264, 10139, 1860, 413, 538, 472, 13, 1033, 11, 286, 486, 483, 257, 39684, 13, 407, 510, 341, 307, 787, 337, 472, 50628, 50628, 4111, 13, 2720, 1164, 11, 291, 486, 362, 281, 483, 544, 4122, 13, 407, 2602, 295, 1419, 257, 8062, 413, 538, 472, 11, 50908, 50908, 291, 434, 516, 281, 764, 257, 8141, 413, 538, 413, 13, 407, 341, 636, 291, 393, 483, 11, 291, 458, 11, 413, 4122, 337, 1184, 9984, 286, 13, 51296, 51340, 1033, 11, 293, 550, 370, 341, 307, 264, 10290, 412, 9984, 286, 13, 286, 393, 829, 1203, 294, 8062, 10290, 13, 51736, 51736], "temperature": 0.0, "avg_logprob": -0.20772769963629892, "compression_ratio": 1.7412280701754386, "no_speech_prob": 6.5396297941333614e-06}, {"id": 599, "seek": 408988, "start": 4109.400000000001, "end": 4117.32, "text": " Okay, and then so this is the representation at node I. I can put everything in vector representation.", "tokens": [50364, 597, 307, 611, 264, 10139, 1860, 413, 538, 472, 13, 1033, 11, 286, 486, 483, 257, 39684, 13, 407, 510, 341, 307, 787, 337, 472, 50628, 50628, 4111, 13, 2720, 1164, 11, 291, 486, 362, 281, 483, 544, 4122, 13, 407, 2602, 295, 1419, 257, 8062, 413, 538, 472, 11, 50908, 50908, 291, 434, 516, 281, 764, 257, 8141, 413, 538, 413, 13, 407, 341, 636, 291, 393, 483, 11, 291, 458, 11, 413, 4122, 337, 1184, 9984, 286, 13, 51296, 51340, 1033, 11, 293, 550, 370, 341, 307, 264, 10290, 412, 9984, 286, 13, 286, 393, 829, 1203, 294, 8062, 10290, 13, 51736, 51736], "temperature": 0.0, "avg_logprob": -0.20772769963629892, "compression_ratio": 1.7412280701754386, "no_speech_prob": 6.5396297941333614e-06}, {"id": 600, "seek": 411732, "start": 4117.32, "end": 4126.599999999999, "text": " Okay, this is my activation at layer L plus one. It is defined on the graph of n vertices,", "tokens": [50364, 1033, 11, 341, 307, 452, 24433, 412, 4583, 441, 1804, 472, 13, 467, 307, 7642, 322, 264, 4295, 295, 297, 32053, 11, 50828, 50828, 293, 309, 575, 413, 12819, 13, 1033, 11, 293, 341, 393, 312, 319, 26859, 382, 264, 22940, 3020, 8141, 316, 13, 407, 341, 307, 51216, 51216, 364, 297, 538, 297, 8141, 13, 639, 307, 452, 24433, 412, 264, 4583, 441, 13, 407, 341, 307, 297, 538, 274, 11, 291, 458, 11, 8141, 13, 51620, 51620], "temperature": 0.0, "avg_logprob": -0.21969418466827015, "compression_ratio": 1.5885714285714285, "no_speech_prob": 1.3847459740645718e-05}, {"id": 601, "seek": 411732, "start": 4126.599999999999, "end": 4134.36, "text": " and it has D dimensions. Okay, and this can be rewritten as the adjacency matrix A. So this is", "tokens": [50364, 1033, 11, 341, 307, 452, 24433, 412, 4583, 441, 1804, 472, 13, 467, 307, 7642, 322, 264, 4295, 295, 297, 32053, 11, 50828, 50828, 293, 309, 575, 413, 12819, 13, 1033, 11, 293, 341, 393, 312, 319, 26859, 382, 264, 22940, 3020, 8141, 316, 13, 407, 341, 307, 51216, 51216, 364, 297, 538, 297, 8141, 13, 639, 307, 452, 24433, 412, 264, 4583, 441, 13, 407, 341, 307, 297, 538, 274, 11, 291, 458, 11, 8141, 13, 51620, 51620], "temperature": 0.0, "avg_logprob": -0.21969418466827015, "compression_ratio": 1.5885714285714285, "no_speech_prob": 1.3847459740645718e-05}, {"id": 602, "seek": 411732, "start": 4134.36, "end": 4142.44, "text": " an n by n matrix. This is my activation at the layer L. So this is n by d, you know, matrix.", "tokens": [50364, 1033, 11, 341, 307, 452, 24433, 412, 4583, 441, 1804, 472, 13, 467, 307, 7642, 322, 264, 4295, 295, 297, 32053, 11, 50828, 50828, 293, 309, 575, 413, 12819, 13, 1033, 11, 293, 341, 393, 312, 319, 26859, 382, 264, 22940, 3020, 8141, 316, 13, 407, 341, 307, 51216, 51216, 364, 297, 538, 297, 8141, 13, 639, 307, 452, 24433, 412, 264, 4583, 441, 13, 407, 341, 307, 297, 538, 274, 11, 291, 458, 11, 8141, 13, 51620, 51620], "temperature": 0.0, "avg_logprob": -0.21969418466827015, "compression_ratio": 1.5885714285714285, "no_speech_prob": 1.3847459740645718e-05}, {"id": 603, "seek": 414244, "start": 4142.44, "end": 4150.5199999999995, "text": " And this is the template that I'm going to learn by backpropagation of the size D by D.", "tokens": [50364, 400, 341, 307, 264, 12379, 300, 286, 478, 516, 281, 1466, 538, 646, 79, 1513, 559, 399, 295, 264, 2744, 413, 538, 413, 13, 50768, 50768, 1033, 11, 370, 291, 360, 341, 1674, 11, 291, 483, 297, 538, 413, 13, 1033, 11, 370, 2361, 322, 341, 12379, 14324, 295, 4295, 11, 51316, 51316, 586, 286, 478, 516, 281, 6964, 732, 5359, 295, 23598, 29435, 45, 11, 597, 366, 264, 38018, 39173, 29435, 45, 293, 264, 364, 271, 310, 39173, 51816, 51816], "temperature": 0.0, "avg_logprob": -0.13591348119528898, "compression_ratio": 1.5519125683060109, "no_speech_prob": 9.604616025171708e-06}, {"id": 604, "seek": 414244, "start": 4150.5199999999995, "end": 4161.48, "text": " Okay, so you do this product, you get n by D. Okay, so based on this template matching of graph,", "tokens": [50364, 400, 341, 307, 264, 12379, 300, 286, 478, 516, 281, 1466, 538, 646, 79, 1513, 559, 399, 295, 264, 2744, 413, 538, 413, 13, 50768, 50768, 1033, 11, 370, 291, 360, 341, 1674, 11, 291, 483, 297, 538, 413, 13, 1033, 11, 370, 2361, 322, 341, 12379, 14324, 295, 4295, 11, 51316, 51316, 586, 286, 478, 516, 281, 6964, 732, 5359, 295, 23598, 29435, 45, 11, 597, 366, 264, 38018, 39173, 29435, 45, 293, 264, 364, 271, 310, 39173, 51816, 51816], "temperature": 0.0, "avg_logprob": -0.13591348119528898, "compression_ratio": 1.5519125683060109, "no_speech_prob": 9.604616025171708e-06}, {"id": 605, "seek": 414244, "start": 4161.48, "end": 4171.48, "text": " now I'm going to define two classes of spatial GCN, which are the isotropic GCN and the anisotropic", "tokens": [50364, 400, 341, 307, 264, 12379, 300, 286, 478, 516, 281, 1466, 538, 646, 79, 1513, 559, 399, 295, 264, 2744, 413, 538, 413, 13, 50768, 50768, 1033, 11, 370, 291, 360, 341, 1674, 11, 291, 483, 297, 538, 413, 13, 1033, 11, 370, 2361, 322, 341, 12379, 14324, 295, 4295, 11, 51316, 51316, 586, 286, 478, 516, 281, 6964, 732, 5359, 295, 23598, 29435, 45, 11, 597, 366, 264, 38018, 39173, 29435, 45, 293, 264, 364, 271, 310, 39173, 51816, 51816], "temperature": 0.0, "avg_logprob": -0.13591348119528898, "compression_ratio": 1.5519125683060109, "no_speech_prob": 9.604616025171708e-06}, {"id": 606, "seek": 417148, "start": 4171.48, "end": 4180.44, "text": " GCN. So let's start with the isotropic GCN. So this is actually quite some history. Okay, so", "tokens": [50364, 29435, 45, 13, 407, 718, 311, 722, 365, 264, 38018, 39173, 29435, 45, 13, 407, 341, 307, 767, 1596, 512, 2503, 13, 1033, 11, 370, 50812, 50864, 264, 22811, 37642, 295, 23598, 29435, 45, 390, 7268, 538, 7324, 685, 953, 293, 702, 598, 12, 34224, 13, 407, 51176, 51176, 415, 390, 294, 11453, 949, 264, 2452, 2539, 8894, 11, 293, 550, 544, 3938, 538, 8500, 20613, 11, 7402, 51504, 51504], "temperature": 0.0, "avg_logprob": -0.16672113206651476, "compression_ratio": 1.398989898989899, "no_speech_prob": 1.638376124901697e-05}, {"id": 607, "seek": 417148, "start": 4181.48, "end": 4187.719999999999, "text": " the simplest formulation of spatial GCN was introduced by Skarsily and his co-author. So", "tokens": [50364, 29435, 45, 13, 407, 718, 311, 722, 365, 264, 38018, 39173, 29435, 45, 13, 407, 341, 307, 767, 1596, 512, 2503, 13, 1033, 11, 370, 50812, 50864, 264, 22811, 37642, 295, 23598, 29435, 45, 390, 7268, 538, 7324, 685, 953, 293, 702, 598, 12, 34224, 13, 407, 51176, 51176, 415, 390, 294, 11453, 949, 264, 2452, 2539, 8894, 11, 293, 550, 544, 3938, 538, 8500, 20613, 11, 7402, 51504, 51504], "temperature": 0.0, "avg_logprob": -0.16672113206651476, "compression_ratio": 1.398989898989899, "no_speech_prob": 1.638376124901697e-05}, {"id": 608, "seek": 417148, "start": 4187.719999999999, "end": 4194.28, "text": " he was in 2009 before the deep learning revolution, and then more recently by Thomas Keith, Max", "tokens": [50364, 29435, 45, 13, 407, 718, 311, 722, 365, 264, 38018, 39173, 29435, 45, 13, 407, 341, 307, 767, 1596, 512, 2503, 13, 1033, 11, 370, 50812, 50864, 264, 22811, 37642, 295, 23598, 29435, 45, 390, 7268, 538, 7324, 685, 953, 293, 702, 598, 12, 34224, 13, 407, 51176, 51176, 415, 390, 294, 11453, 949, 264, 2452, 2539, 8894, 11, 293, 550, 544, 3938, 538, 8500, 20613, 11, 7402, 51504, 51504], "temperature": 0.0, "avg_logprob": -0.16672113206651476, "compression_ratio": 1.398989898989899, "no_speech_prob": 1.638376124901697e-05}, {"id": 609, "seek": 419428, "start": 4194.28, "end": 4203.96, "text": " Willing, and also Sian Sukubata and Arshur Slam and Rob Fergus in 2016. So this is actually", "tokens": [50364, 3099, 278, 11, 293, 611, 318, 952, 37898, 836, 3274, 293, 1587, 2716, 374, 318, 4326, 293, 5424, 10728, 21956, 294, 6549, 13, 407, 341, 307, 767, 50848, 50920, 341, 4295, 18161, 3209, 11, 370, 437, 286, 818, 264, 8979, 1426, 4295, 28270, 36170, 13, 1033, 11, 341, 307, 51208, 51208, 2293, 264, 912, 7123, 300, 286, 632, 949, 13, 1449, 510, 286, 829, 264, 460, 53, 8141, 294, 1270, 257, 636, 300, 51452, 51452, 286, 362, 264, 914, 2158, 13, 1033, 11, 286, 445, 360, 264, 914, 2158, 670, 264, 7630, 13, 1033, 11, 457, 341, 307, 51684, 51684], "temperature": 0.0, "avg_logprob": -0.2167193842869179, "compression_ratio": 1.5957446808510638, "no_speech_prob": 3.3195163268828765e-05}, {"id": 610, "seek": 419428, "start": 4205.4, "end": 4211.16, "text": " this graph neural network, so what I call the Vanina graph computational nets. Okay, this is", "tokens": [50364, 3099, 278, 11, 293, 611, 318, 952, 37898, 836, 3274, 293, 1587, 2716, 374, 318, 4326, 293, 5424, 10728, 21956, 294, 6549, 13, 407, 341, 307, 767, 50848, 50920, 341, 4295, 18161, 3209, 11, 370, 437, 286, 818, 264, 8979, 1426, 4295, 28270, 36170, 13, 1033, 11, 341, 307, 51208, 51208, 2293, 264, 912, 7123, 300, 286, 632, 949, 13, 1449, 510, 286, 829, 264, 460, 53, 8141, 294, 1270, 257, 636, 300, 51452, 51452, 286, 362, 264, 914, 2158, 13, 1033, 11, 286, 445, 360, 264, 914, 2158, 670, 264, 7630, 13, 1033, 11, 457, 341, 307, 51684, 51684], "temperature": 0.0, "avg_logprob": -0.2167193842869179, "compression_ratio": 1.5957446808510638, "no_speech_prob": 3.3195163268828765e-05}, {"id": 611, "seek": 419428, "start": 4211.16, "end": 4216.04, "text": " exactly the same definition that I had before. Just here I put the GV matrix in such a way that", "tokens": [50364, 3099, 278, 11, 293, 611, 318, 952, 37898, 836, 3274, 293, 1587, 2716, 374, 318, 4326, 293, 5424, 10728, 21956, 294, 6549, 13, 407, 341, 307, 767, 50848, 50920, 341, 4295, 18161, 3209, 11, 370, 437, 286, 818, 264, 8979, 1426, 4295, 28270, 36170, 13, 1033, 11, 341, 307, 51208, 51208, 2293, 264, 912, 7123, 300, 286, 632, 949, 13, 1449, 510, 286, 829, 264, 460, 53, 8141, 294, 1270, 257, 636, 300, 51452, 51452, 286, 362, 264, 914, 2158, 13, 1033, 11, 286, 445, 360, 264, 914, 2158, 670, 264, 7630, 13, 1033, 11, 457, 341, 307, 51684, 51684], "temperature": 0.0, "avg_logprob": -0.2167193842869179, "compression_ratio": 1.5957446808510638, "no_speech_prob": 3.3195163268828765e-05}, {"id": 612, "seek": 419428, "start": 4216.04, "end": 4220.679999999999, "text": " I have the mean value. Okay, I just do the mean value over the neighborhood. Okay, but this is", "tokens": [50364, 3099, 278, 11, 293, 611, 318, 952, 37898, 836, 3274, 293, 1587, 2716, 374, 318, 4326, 293, 5424, 10728, 21956, 294, 6549, 13, 407, 341, 307, 767, 50848, 50920, 341, 4295, 18161, 3209, 11, 370, 437, 286, 818, 264, 8979, 1426, 4295, 28270, 36170, 13, 1033, 11, 341, 307, 51208, 51208, 2293, 264, 912, 7123, 300, 286, 632, 949, 13, 1449, 510, 286, 829, 264, 460, 53, 8141, 294, 1270, 257, 636, 300, 51452, 51452, 286, 362, 264, 914, 2158, 13, 1033, 11, 286, 445, 360, 264, 914, 2158, 670, 264, 7630, 13, 1033, 11, 457, 341, 307, 51684, 51684], "temperature": 0.0, "avg_logprob": -0.2167193842869179, "compression_ratio": 1.5957446808510638, "no_speech_prob": 3.3195163268828765e-05}, {"id": 613, "seek": 422068, "start": 4220.68, "end": 4232.92, "text": " exactly the equation that I used before. Okay, and you see that so this equation is, it can handle", "tokens": [50364, 2293, 264, 5367, 300, 286, 1143, 949, 13, 1033, 11, 293, 291, 536, 300, 370, 341, 5367, 307, 11, 309, 393, 4813, 50976, 50976, 17145, 295, 9984, 21739, 13, 407, 341, 307, 2584, 33270, 394, 281, 9984, 13075, 2144, 13, 407, 797, 11, 51280, 51280, 498, 341, 8186, 307, 1310, 2309, 293, 286, 1319, 281, 312, 2272, 17, 11, 309, 311, 406, 516, 281, 1319, 1340, 294, 264, 51564, 51564], "temperature": 0.0, "avg_logprob": -0.1396480533811781, "compression_ratio": 1.5026455026455026, "no_speech_prob": 1.0195808499702252e-05}, {"id": 614, "seek": 422068, "start": 4232.92, "end": 4239.0, "text": " absence of node ordering. So this is completely invariant to node parameterization. So again,", "tokens": [50364, 2293, 264, 5367, 300, 286, 1143, 949, 13, 1033, 11, 293, 291, 536, 300, 370, 341, 5367, 307, 11, 309, 393, 4813, 50976, 50976, 17145, 295, 9984, 21739, 13, 407, 341, 307, 2584, 33270, 394, 281, 9984, 13075, 2144, 13, 407, 797, 11, 51280, 51280, 498, 341, 8186, 307, 1310, 2309, 293, 286, 1319, 281, 312, 2272, 17, 11, 309, 311, 406, 516, 281, 1319, 1340, 294, 264, 51564, 51564], "temperature": 0.0, "avg_logprob": -0.1396480533811781, "compression_ratio": 1.5026455026455026, "no_speech_prob": 1.0195808499702252e-05}, {"id": 615, "seek": 422068, "start": 4239.0, "end": 4244.68, "text": " if this index is maybe six and I change to be 122, it's not going to change anything in the", "tokens": [50364, 2293, 264, 5367, 300, 286, 1143, 949, 13, 1033, 11, 293, 291, 536, 300, 370, 341, 5367, 307, 11, 309, 393, 4813, 50976, 50976, 17145, 295, 9984, 21739, 13, 407, 341, 307, 2584, 33270, 394, 281, 9984, 13075, 2144, 13, 407, 797, 11, 51280, 51280, 498, 341, 8186, 307, 1310, 2309, 293, 286, 1319, 281, 312, 2272, 17, 11, 309, 311, 406, 516, 281, 1319, 1340, 294, 264, 51564, 51564], "temperature": 0.0, "avg_logprob": -0.1396480533811781, "compression_ratio": 1.5026455026455026, "no_speech_prob": 1.0195808499702252e-05}, {"id": 616, "seek": 424468, "start": 4244.68, "end": 4251.4800000000005, "text": " computation of the of H at the next layer. It's not going to change anything. You can also deal", "tokens": [50364, 24903, 295, 264, 295, 389, 412, 264, 958, 4583, 13, 467, 311, 406, 516, 281, 1319, 1340, 13, 509, 393, 611, 2028, 50704, 50704, 365, 257, 7630, 295, 819, 11602, 13, 1033, 11, 291, 500, 380, 1127, 498, 291, 362, 257, 7630, 295, 1451, 13891, 51032, 51032, 420, 257, 7630, 295, 1266, 13891, 11, 309, 311, 406, 516, 281, 1319, 420, 472, 9984, 11, 309, 311, 406, 516, 281, 1319, 1340, 13, 51216, 51216, 509, 362, 264, 2654, 21682, 2519, 538, 1715, 365, 4295, 18161, 3209, 11, 291, 445, 643, 281, 574, 412, 51464, 51464, 264, 12512, 293, 300, 311, 309, 13, 407, 309, 311, 2212, 281, 291, 13, 509, 362, 3364, 5414, 13, 1033, 11, 291, 362, 3364, 51748, 51748], "temperature": 0.0, "avg_logprob": -0.13820490022984946, "compression_ratio": 1.952755905511811, "no_speech_prob": 1.4050310710445046e-05}, {"id": 617, "seek": 424468, "start": 4251.4800000000005, "end": 4258.04, "text": " with a neighborhood of different sizes. Okay, you don't care if you have a neighborhood of four nodes", "tokens": [50364, 24903, 295, 264, 295, 389, 412, 264, 958, 4583, 13, 467, 311, 406, 516, 281, 1319, 1340, 13, 509, 393, 611, 2028, 50704, 50704, 365, 257, 7630, 295, 819, 11602, 13, 1033, 11, 291, 500, 380, 1127, 498, 291, 362, 257, 7630, 295, 1451, 13891, 51032, 51032, 420, 257, 7630, 295, 1266, 13891, 11, 309, 311, 406, 516, 281, 1319, 420, 472, 9984, 11, 309, 311, 406, 516, 281, 1319, 1340, 13, 51216, 51216, 509, 362, 264, 2654, 21682, 2519, 538, 1715, 365, 4295, 18161, 3209, 11, 291, 445, 643, 281, 574, 412, 51464, 51464, 264, 12512, 293, 300, 311, 309, 13, 407, 309, 311, 2212, 281, 291, 13, 509, 362, 3364, 5414, 13, 1033, 11, 291, 362, 3364, 51748, 51748], "temperature": 0.0, "avg_logprob": -0.13820490022984946, "compression_ratio": 1.952755905511811, "no_speech_prob": 1.4050310710445046e-05}, {"id": 618, "seek": 424468, "start": 4258.04, "end": 4261.72, "text": " or a neighborhood of 10 nodes, it's not going to change or one node, it's not going to change anything.", "tokens": [50364, 24903, 295, 264, 295, 389, 412, 264, 958, 4583, 13, 467, 311, 406, 516, 281, 1319, 1340, 13, 509, 393, 611, 2028, 50704, 50704, 365, 257, 7630, 295, 819, 11602, 13, 1033, 11, 291, 500, 380, 1127, 498, 291, 362, 257, 7630, 295, 1451, 13891, 51032, 51032, 420, 257, 7630, 295, 1266, 13891, 11, 309, 311, 406, 516, 281, 1319, 420, 472, 9984, 11, 309, 311, 406, 516, 281, 1319, 1340, 13, 51216, 51216, 509, 362, 264, 2654, 21682, 2519, 538, 1715, 365, 4295, 18161, 3209, 11, 291, 445, 643, 281, 574, 412, 51464, 51464, 264, 12512, 293, 300, 311, 309, 13, 407, 309, 311, 2212, 281, 291, 13, 509, 362, 3364, 5414, 13, 1033, 11, 291, 362, 3364, 51748, 51748], "temperature": 0.0, "avg_logprob": -0.13820490022984946, "compression_ratio": 1.952755905511811, "no_speech_prob": 1.4050310710445046e-05}, {"id": 619, "seek": 424468, "start": 4261.72, "end": 4266.68, "text": " You have the local reception field by design with graph neural network, you just need to look at", "tokens": [50364, 24903, 295, 264, 295, 389, 412, 264, 958, 4583, 13, 467, 311, 406, 516, 281, 1319, 1340, 13, 509, 393, 611, 2028, 50704, 50704, 365, 257, 7630, 295, 819, 11602, 13, 1033, 11, 291, 500, 380, 1127, 498, 291, 362, 257, 7630, 295, 1451, 13891, 51032, 51032, 420, 257, 7630, 295, 1266, 13891, 11, 309, 311, 406, 516, 281, 1319, 420, 472, 9984, 11, 309, 311, 406, 516, 281, 1319, 1340, 13, 51216, 51216, 509, 362, 264, 2654, 21682, 2519, 538, 1715, 365, 4295, 18161, 3209, 11, 291, 445, 643, 281, 574, 412, 51464, 51464, 264, 12512, 293, 300, 311, 309, 13, 407, 309, 311, 2212, 281, 291, 13, 509, 362, 3364, 5414, 13, 1033, 11, 291, 362, 3364, 51748, 51748], "temperature": 0.0, "avg_logprob": -0.13820490022984946, "compression_ratio": 1.952755905511811, "no_speech_prob": 1.4050310710445046e-05}, {"id": 620, "seek": 424468, "start": 4266.68, "end": 4272.360000000001, "text": " the neighbors and that's it. So it's given to you. You have weight sharing. Okay, you have weight", "tokens": [50364, 24903, 295, 264, 295, 389, 412, 264, 958, 4583, 13, 467, 311, 406, 516, 281, 1319, 1340, 13, 509, 393, 611, 2028, 50704, 50704, 365, 257, 7630, 295, 819, 11602, 13, 1033, 11, 291, 500, 380, 1127, 498, 291, 362, 257, 7630, 295, 1451, 13891, 51032, 51032, 420, 257, 7630, 295, 1266, 13891, 11, 309, 311, 406, 516, 281, 1319, 420, 472, 9984, 11, 309, 311, 406, 516, 281, 1319, 1340, 13, 51216, 51216, 509, 362, 264, 2654, 21682, 2519, 538, 1715, 365, 4295, 18161, 3209, 11, 291, 445, 643, 281, 574, 412, 51464, 51464, 264, 12512, 293, 300, 311, 309, 13, 407, 309, 311, 2212, 281, 291, 13, 509, 362, 3364, 5414, 13, 1033, 11, 291, 362, 3364, 51748, 51748], "temperature": 0.0, "avg_logprob": -0.13820490022984946, "compression_ratio": 1.952755905511811, "no_speech_prob": 1.4050310710445046e-05}, {"id": 621, "seek": 427236, "start": 4272.36, "end": 4279.16, "text": " sharing means that for all features, you are going to use the same W, whatever the position on the", "tokens": [50364, 5414, 1355, 300, 337, 439, 4122, 11, 291, 366, 516, 281, 764, 264, 912, 343, 11, 2035, 264, 2535, 322, 264, 50704, 50704, 4295, 13, 1033, 11, 370, 341, 307, 257, 45216, 4707, 13, 639, 37642, 307, 611, 6695, 295, 264, 4295, 51032, 51032, 2744, 11, 570, 439, 7705, 366, 1096, 16143, 13, 1033, 11, 291, 445, 764, 2654, 1589, 337, 264, 958, 51364, 51364, 337, 264, 958, 4583, 13, 407, 291, 393, 362, 257, 4295, 295, 1266, 13891, 420, 291, 393, 362, 257, 4295, 295, 1266, 5218, 13891, 13, 51632, 51684], "temperature": 0.0, "avg_logprob": -0.1375817542380475, "compression_ratio": 1.7668161434977578, "no_speech_prob": 2.4261962607852183e-05}, {"id": 622, "seek": 427236, "start": 4279.16, "end": 4285.719999999999, "text": " graph. Okay, so this is a convolution property. This formulation is also independent of the graph", "tokens": [50364, 5414, 1355, 300, 337, 439, 4122, 11, 291, 366, 516, 281, 764, 264, 912, 343, 11, 2035, 264, 2535, 322, 264, 50704, 50704, 4295, 13, 1033, 11, 370, 341, 307, 257, 45216, 4707, 13, 639, 37642, 307, 611, 6695, 295, 264, 4295, 51032, 51032, 2744, 11, 570, 439, 7705, 366, 1096, 16143, 13, 1033, 11, 291, 445, 764, 2654, 1589, 337, 264, 958, 51364, 51364, 337, 264, 958, 4583, 13, 407, 291, 393, 362, 257, 4295, 295, 1266, 13891, 420, 291, 393, 362, 257, 4295, 295, 1266, 5218, 13891, 13, 51632, 51684], "temperature": 0.0, "avg_logprob": -0.1375817542380475, "compression_ratio": 1.7668161434977578, "no_speech_prob": 2.4261962607852183e-05}, {"id": 623, "seek": 427236, "start": 4285.719999999999, "end": 4292.36, "text": " size, because all operations are done locally. Okay, you just use local information for the next", "tokens": [50364, 5414, 1355, 300, 337, 439, 4122, 11, 291, 366, 516, 281, 764, 264, 912, 343, 11, 2035, 264, 2535, 322, 264, 50704, 50704, 4295, 13, 1033, 11, 370, 341, 307, 257, 45216, 4707, 13, 639, 37642, 307, 611, 6695, 295, 264, 4295, 51032, 51032, 2744, 11, 570, 439, 7705, 366, 1096, 16143, 13, 1033, 11, 291, 445, 764, 2654, 1589, 337, 264, 958, 51364, 51364, 337, 264, 958, 4583, 13, 407, 291, 393, 362, 257, 4295, 295, 1266, 13891, 420, 291, 393, 362, 257, 4295, 295, 1266, 5218, 13891, 13, 51632, 51684], "temperature": 0.0, "avg_logprob": -0.1375817542380475, "compression_ratio": 1.7668161434977578, "no_speech_prob": 2.4261962607852183e-05}, {"id": 624, "seek": 427236, "start": 4292.36, "end": 4297.719999999999, "text": " for the next layer. So you can have a graph of 10 nodes or you can have a graph of 10 billion nodes.", "tokens": [50364, 5414, 1355, 300, 337, 439, 4122, 11, 291, 366, 516, 281, 764, 264, 912, 343, 11, 2035, 264, 2535, 322, 264, 50704, 50704, 4295, 13, 1033, 11, 370, 341, 307, 257, 45216, 4707, 13, 639, 37642, 307, 611, 6695, 295, 264, 4295, 51032, 51032, 2744, 11, 570, 439, 7705, 366, 1096, 16143, 13, 1033, 11, 291, 445, 764, 2654, 1589, 337, 264, 958, 51364, 51364, 337, 264, 958, 4583, 13, 407, 291, 393, 362, 257, 4295, 295, 1266, 13891, 420, 291, 393, 362, 257, 4295, 295, 1266, 5218, 13891, 13, 51632, 51684], "temperature": 0.0, "avg_logprob": -0.1375817542380475, "compression_ratio": 1.7668161434977578, "no_speech_prob": 2.4261962607852183e-05}, {"id": 625, "seek": 429772, "start": 4297.72, "end": 4303.16, "text": " It doesn't care. So you can do also everything in parallel. And but this is limited to isotropic", "tokens": [50364, 467, 1177, 380, 1127, 13, 407, 291, 393, 360, 611, 1203, 294, 8952, 13, 400, 457, 341, 307, 5567, 281, 38018, 39173, 50636, 50636, 13759, 13, 407, 264, 343, 307, 264, 912, 337, 439, 12512, 13, 407, 309, 311, 797, 11, 309, 311, 364, 38018, 39173, 2316, 307, 516, 281, 50996, 50996, 976, 264, 912, 2158, 337, 439, 12512, 13, 1033, 11, 457, 412, 264, 917, 295, 264, 786, 11, 341, 2316, 393, 312, 10379, 51280, 51280, 538, 341, 2573, 13, 407, 341, 11, 370, 264, 24433, 412, 264, 958, 4583, 307, 1936, 257, 2445, 295, 264, 24433, 51752, 51752], "temperature": 0.0, "avg_logprob": -0.1633286569632736, "compression_ratio": 1.748917748917749, "no_speech_prob": 6.183949153637514e-05}, {"id": 626, "seek": 429772, "start": 4303.16, "end": 4310.360000000001, "text": " capability. So the W is the same for all neighbors. So it's again, it's an isotropic model is going to", "tokens": [50364, 467, 1177, 380, 1127, 13, 407, 291, 393, 360, 611, 1203, 294, 8952, 13, 400, 457, 341, 307, 5567, 281, 38018, 39173, 50636, 50636, 13759, 13, 407, 264, 343, 307, 264, 912, 337, 439, 12512, 13, 407, 309, 311, 797, 11, 309, 311, 364, 38018, 39173, 2316, 307, 516, 281, 50996, 50996, 976, 264, 912, 2158, 337, 439, 12512, 13, 1033, 11, 457, 412, 264, 917, 295, 264, 786, 11, 341, 2316, 393, 312, 10379, 51280, 51280, 538, 341, 2573, 13, 407, 341, 11, 370, 264, 24433, 412, 264, 958, 4583, 307, 1936, 257, 2445, 295, 264, 24433, 51752, 51752], "temperature": 0.0, "avg_logprob": -0.1633286569632736, "compression_ratio": 1.748917748917749, "no_speech_prob": 6.183949153637514e-05}, {"id": 627, "seek": 429772, "start": 4310.360000000001, "end": 4316.04, "text": " give the same value for all neighbors. Okay, but at the end of the day, this model can be represented", "tokens": [50364, 467, 1177, 380, 1127, 13, 407, 291, 393, 360, 611, 1203, 294, 8952, 13, 400, 457, 341, 307, 5567, 281, 38018, 39173, 50636, 50636, 13759, 13, 407, 264, 343, 307, 264, 912, 337, 439, 12512, 13, 407, 309, 311, 797, 11, 309, 311, 364, 38018, 39173, 2316, 307, 516, 281, 50996, 50996, 976, 264, 912, 2158, 337, 439, 12512, 13, 1033, 11, 457, 412, 264, 917, 295, 264, 786, 11, 341, 2316, 393, 312, 10379, 51280, 51280, 538, 341, 2573, 13, 407, 341, 11, 370, 264, 24433, 412, 264, 958, 4583, 307, 1936, 257, 2445, 295, 264, 24433, 51752, 51752], "temperature": 0.0, "avg_logprob": -0.1633286569632736, "compression_ratio": 1.748917748917749, "no_speech_prob": 6.183949153637514e-05}, {"id": 628, "seek": 429772, "start": 4316.04, "end": 4325.4800000000005, "text": " by this figure. So this, so the activation at the next layer is basically a function of the activation", "tokens": [50364, 467, 1177, 380, 1127, 13, 407, 291, 393, 360, 611, 1203, 294, 8952, 13, 400, 457, 341, 307, 5567, 281, 38018, 39173, 50636, 50636, 13759, 13, 407, 264, 343, 307, 264, 912, 337, 439, 12512, 13, 407, 309, 311, 797, 11, 309, 311, 364, 38018, 39173, 2316, 307, 516, 281, 50996, 50996, 976, 264, 912, 2158, 337, 439, 12512, 13, 1033, 11, 457, 412, 264, 917, 295, 264, 786, 11, 341, 2316, 393, 312, 10379, 51280, 51280, 538, 341, 2573, 13, 407, 341, 11, 370, 264, 24433, 412, 264, 958, 4583, 307, 1936, 257, 2445, 295, 264, 24433, 51752, 51752], "temperature": 0.0, "avg_logprob": -0.1633286569632736, "compression_ratio": 1.748917748917749, "no_speech_prob": 6.183949153637514e-05}, {"id": 629, "seek": 432548, "start": 4325.48, "end": 4334.5199999999995, "text": " of the activation at the current layer at index at the node i and the neighborhood of the node i.", "tokens": [50364, 295, 264, 24433, 412, 264, 2190, 4583, 412, 8186, 412, 264, 9984, 741, 293, 264, 7630, 295, 264, 9984, 741, 13, 50816, 50816, 1033, 13, 400, 264, 787, 551, 300, 321, 434, 516, 281, 360, 1936, 307, 281, 1319, 264, 2445, 11, 264, 9836, 6642, 51152, 51152, 295, 264, 2445, 13, 400, 550, 291, 486, 483, 439, 1605, 295, 4295, 18161, 3209, 538, 445, 11, 291, 458, 11, 17990, 51500, 51500, 257, 819, 2445, 510, 11, 457, 1203, 307, 2361, 322, 341, 5367, 13, 407, 797, 11, 291, 362, 428, 4965, 51844], "temperature": 0.0, "avg_logprob": -0.16054881887233002, "compression_ratio": 1.7094017094017093, "no_speech_prob": 9.192292964144144e-06}, {"id": 630, "seek": 432548, "start": 4334.5199999999995, "end": 4341.24, "text": " Okay. And the only thing that we're going to do basically is to change the function, the instantiation", "tokens": [50364, 295, 264, 24433, 412, 264, 2190, 4583, 412, 8186, 412, 264, 9984, 741, 293, 264, 7630, 295, 264, 9984, 741, 13, 50816, 50816, 1033, 13, 400, 264, 787, 551, 300, 321, 434, 516, 281, 360, 1936, 307, 281, 1319, 264, 2445, 11, 264, 9836, 6642, 51152, 51152, 295, 264, 2445, 13, 400, 550, 291, 486, 483, 439, 1605, 295, 4295, 18161, 3209, 538, 445, 11, 291, 458, 11, 17990, 51500, 51500, 257, 819, 2445, 510, 11, 457, 1203, 307, 2361, 322, 341, 5367, 13, 407, 797, 11, 291, 362, 428, 4965, 51844], "temperature": 0.0, "avg_logprob": -0.16054881887233002, "compression_ratio": 1.7094017094017093, "no_speech_prob": 9.192292964144144e-06}, {"id": 631, "seek": 432548, "start": 4341.24, "end": 4348.2, "text": " of the function. And then you will get all family of graph neural network by just, you know, deciding", "tokens": [50364, 295, 264, 24433, 412, 264, 2190, 4583, 412, 8186, 412, 264, 9984, 741, 293, 264, 7630, 295, 264, 9984, 741, 13, 50816, 50816, 1033, 13, 400, 264, 787, 551, 300, 321, 434, 516, 281, 360, 1936, 307, 281, 1319, 264, 2445, 11, 264, 9836, 6642, 51152, 51152, 295, 264, 2445, 13, 400, 550, 291, 486, 483, 439, 1605, 295, 4295, 18161, 3209, 538, 445, 11, 291, 458, 11, 17990, 51500, 51500, 257, 819, 2445, 510, 11, 457, 1203, 307, 2361, 322, 341, 5367, 13, 407, 797, 11, 291, 362, 428, 4965, 51844], "temperature": 0.0, "avg_logprob": -0.16054881887233002, "compression_ratio": 1.7094017094017093, "no_speech_prob": 9.192292964144144e-06}, {"id": 632, "seek": 434820, "start": 4348.2, "end": 4356.44, "text": " a different function here, but everything is based on this equation. So again, you have your core node", "tokens": [50364, 257, 819, 2445, 510, 11, 457, 1203, 307, 2361, 322, 341, 5367, 13, 407, 797, 11, 291, 362, 428, 4965, 9984, 50776, 50776, 293, 550, 291, 362, 428, 7630, 281, 4536, 437, 486, 312, 264, 24433, 412, 264, 958, 4583, 13, 50984, 51148, 1033, 11, 370, 286, 478, 2614, 484, 295, 565, 13, 407, 286, 478, 406, 516, 281, 747, 886, 709, 565, 322, 341, 13, 583, 51352, 51352, 437, 291, 393, 855, 307, 300, 341, 14281, 82, 8979, 5291, 29435, 45, 286, 445, 855, 291, 307, 767, 257, 6883, 3774, 51680, 51680], "temperature": 0.0, "avg_logprob": -0.11661435177451686, "compression_ratio": 1.575, "no_speech_prob": 1.3618353477795608e-05}, {"id": 633, "seek": 434820, "start": 4356.44, "end": 4360.599999999999, "text": " and then you have your neighborhood to decide what will be the activation at the next layer.", "tokens": [50364, 257, 819, 2445, 510, 11, 457, 1203, 307, 2361, 322, 341, 5367, 13, 407, 797, 11, 291, 362, 428, 4965, 9984, 50776, 50776, 293, 550, 291, 362, 428, 7630, 281, 4536, 437, 486, 312, 264, 24433, 412, 264, 958, 4583, 13, 50984, 51148, 1033, 11, 370, 286, 478, 2614, 484, 295, 565, 13, 407, 286, 478, 406, 516, 281, 747, 886, 709, 565, 322, 341, 13, 583, 51352, 51352, 437, 291, 393, 855, 307, 300, 341, 14281, 82, 8979, 5291, 29435, 45, 286, 445, 855, 291, 307, 767, 257, 6883, 3774, 51680, 51680], "temperature": 0.0, "avg_logprob": -0.11661435177451686, "compression_ratio": 1.575, "no_speech_prob": 1.3618353477795608e-05}, {"id": 634, "seek": 434820, "start": 4363.88, "end": 4367.96, "text": " Okay, so I'm running out of time. So I'm not going to take too much time on this. But", "tokens": [50364, 257, 819, 2445, 510, 11, 457, 1203, 307, 2361, 322, 341, 5367, 13, 407, 797, 11, 291, 362, 428, 4965, 9984, 50776, 50776, 293, 550, 291, 362, 428, 7630, 281, 4536, 437, 486, 312, 264, 24433, 412, 264, 958, 4583, 13, 50984, 51148, 1033, 11, 370, 286, 478, 2614, 484, 295, 565, 13, 407, 286, 478, 406, 516, 281, 747, 886, 709, 565, 322, 341, 13, 583, 51352, 51352, 437, 291, 393, 855, 307, 300, 341, 14281, 82, 8979, 5291, 29435, 45, 286, 445, 855, 291, 307, 767, 257, 6883, 3774, 51680, 51680], "temperature": 0.0, "avg_logprob": -0.11661435177451686, "compression_ratio": 1.575, "no_speech_prob": 1.3618353477795608e-05}, {"id": 635, "seek": 434820, "start": 4367.96, "end": 4374.5199999999995, "text": " what you can show is that this previews Vanilla GCN I just show you is actually a simplification", "tokens": [50364, 257, 819, 2445, 510, 11, 457, 1203, 307, 2361, 322, 341, 5367, 13, 407, 797, 11, 291, 362, 428, 4965, 9984, 50776, 50776, 293, 550, 291, 362, 428, 7630, 281, 4536, 437, 486, 312, 264, 24433, 412, 264, 958, 4583, 13, 50984, 51148, 1033, 11, 370, 286, 478, 2614, 484, 295, 565, 13, 407, 286, 478, 406, 516, 281, 747, 886, 709, 565, 322, 341, 13, 583, 51352, 51352, 437, 291, 393, 855, 307, 300, 341, 14281, 82, 8979, 5291, 29435, 45, 286, 445, 855, 291, 307, 767, 257, 6883, 3774, 51680, 51680], "temperature": 0.0, "avg_logprob": -0.11661435177451686, "compression_ratio": 1.575, "no_speech_prob": 1.3618353477795608e-05}, {"id": 636, "seek": 437452, "start": 4374.52, "end": 4379.400000000001, "text": " of chain net. So if you truncate the expansion of chain net by using the first two", "tokens": [50364, 295, 5021, 2533, 13, 407, 498, 291, 504, 409, 66, 473, 264, 11260, 295, 5021, 2533, 538, 1228, 264, 700, 732, 50608, 50648, 5021, 2533, 2445, 11, 300, 412, 264, 917, 11, 291, 917, 493, 365, 264, 912, 5367, 13, 407, 11, 370, 341, 307, 341, 307, 50964, 50964, 264, 2480, 13, 1033, 11, 370, 472, 1880, 29435, 45, 307, 4295, 19721, 300, 390, 7268, 538, 6740, 51508, 51508], "temperature": 0.0, "avg_logprob": -0.25734178784867406, "compression_ratio": 1.5459770114942528, "no_speech_prob": 2.2896214431966655e-05}, {"id": 637, "seek": 437452, "start": 4380.200000000001, "end": 4386.52, "text": " chain net function, that at the end, you end up with the same equation. So, so this is this is", "tokens": [50364, 295, 5021, 2533, 13, 407, 498, 291, 504, 409, 66, 473, 264, 11260, 295, 5021, 2533, 538, 1228, 264, 700, 732, 50608, 50648, 5021, 2533, 2445, 11, 300, 412, 264, 917, 11, 291, 917, 493, 365, 264, 912, 5367, 13, 407, 11, 370, 341, 307, 341, 307, 50964, 50964, 264, 2480, 13, 1033, 11, 370, 472, 1880, 29435, 45, 307, 4295, 19721, 300, 390, 7268, 538, 6740, 51508, 51508], "temperature": 0.0, "avg_logprob": -0.25734178784867406, "compression_ratio": 1.5459770114942528, "no_speech_prob": 2.2896214431966655e-05}, {"id": 638, "seek": 437452, "start": 4386.52, "end": 4397.400000000001, "text": " the relationship. Okay, so one interesting GCN is graph sage that was introduced by William", "tokens": [50364, 295, 5021, 2533, 13, 407, 498, 291, 504, 409, 66, 473, 264, 11260, 295, 5021, 2533, 538, 1228, 264, 700, 732, 50608, 50648, 5021, 2533, 2445, 11, 300, 412, 264, 917, 11, 291, 917, 493, 365, 264, 912, 5367, 13, 407, 11, 370, 341, 307, 341, 307, 50964, 50964, 264, 2480, 13, 1033, 11, 370, 472, 1880, 29435, 45, 307, 4295, 19721, 300, 390, 7268, 538, 6740, 51508, 51508], "temperature": 0.0, "avg_logprob": -0.25734178784867406, "compression_ratio": 1.5459770114942528, "no_speech_prob": 2.2896214431966655e-05}, {"id": 639, "seek": 439740, "start": 4397.4, "end": 4404.36, "text": " Hamilton, Lee and Yuri Leskovic. So let's say for let's go back to the Vanilla GCN. So and let's suppose", "tokens": [50364, 18484, 11, 6957, 293, 33901, 6965, 4093, 25537, 13, 407, 718, 311, 584, 337, 718, 311, 352, 646, 281, 264, 8979, 5291, 29435, 45, 13, 407, 293, 718, 311, 7297, 50712, 50712, 300, 264, 22940, 3020, 8141, 382, 257, 2158, 472, 337, 264, 8819, 13, 1033, 11, 370, 286, 362, 341, 5367, 13, 51048, 51080, 407, 264, 551, 307, 11, 337, 341, 5367, 11, 286, 478, 516, 281, 2387, 11, 291, 458, 11, 264, 5777, 28162, 741, 293, 264, 51440, 51440, 7630, 365, 264, 912, 12379, 3364, 13, 1033, 11, 457, 286, 393, 23203, 300, 11, 291, 458, 11, 286, 393, 362, 51776, 51776], "temperature": 0.0, "avg_logprob": -0.15860386614529592, "compression_ratio": 1.6192468619246863, "no_speech_prob": 7.745754373900127e-06}, {"id": 640, "seek": 439740, "start": 4404.36, "end": 4411.08, "text": " that the adjacency matrix as a value one for the edges. Okay, so I have this equation.", "tokens": [50364, 18484, 11, 6957, 293, 33901, 6965, 4093, 25537, 13, 407, 718, 311, 584, 337, 718, 311, 352, 646, 281, 264, 8979, 5291, 29435, 45, 13, 407, 293, 718, 311, 7297, 50712, 50712, 300, 264, 22940, 3020, 8141, 382, 257, 2158, 472, 337, 264, 8819, 13, 1033, 11, 370, 286, 362, 341, 5367, 13, 51048, 51080, 407, 264, 551, 307, 11, 337, 341, 5367, 11, 286, 478, 516, 281, 2387, 11, 291, 458, 11, 264, 5777, 28162, 741, 293, 264, 51440, 51440, 7630, 365, 264, 912, 12379, 3364, 13, 1033, 11, 457, 286, 393, 23203, 300, 11, 291, 458, 11, 286, 393, 362, 51776, 51776], "temperature": 0.0, "avg_logprob": -0.15860386614529592, "compression_ratio": 1.6192468619246863, "no_speech_prob": 7.745754373900127e-06}, {"id": 641, "seek": 439740, "start": 4411.719999999999, "end": 4418.92, "text": " So the thing is, for this equation, I'm going to treat, you know, the central vertex i and the", "tokens": [50364, 18484, 11, 6957, 293, 33901, 6965, 4093, 25537, 13, 407, 718, 311, 584, 337, 718, 311, 352, 646, 281, 264, 8979, 5291, 29435, 45, 13, 407, 293, 718, 311, 7297, 50712, 50712, 300, 264, 22940, 3020, 8141, 382, 257, 2158, 472, 337, 264, 8819, 13, 1033, 11, 370, 286, 362, 341, 5367, 13, 51048, 51080, 407, 264, 551, 307, 11, 337, 341, 5367, 11, 286, 478, 516, 281, 2387, 11, 291, 458, 11, 264, 5777, 28162, 741, 293, 264, 51440, 51440, 7630, 365, 264, 912, 12379, 3364, 13, 1033, 11, 457, 286, 393, 23203, 300, 11, 291, 458, 11, 286, 393, 362, 51776, 51776], "temperature": 0.0, "avg_logprob": -0.15860386614529592, "compression_ratio": 1.6192468619246863, "no_speech_prob": 7.745754373900127e-06}, {"id": 642, "seek": 439740, "start": 4418.92, "end": 4425.639999999999, "text": " neighborhood with the same template weight. Okay, but I can differentiate that, you know, I can have", "tokens": [50364, 18484, 11, 6957, 293, 33901, 6965, 4093, 25537, 13, 407, 718, 311, 584, 337, 718, 311, 352, 646, 281, 264, 8979, 5291, 29435, 45, 13, 407, 293, 718, 311, 7297, 50712, 50712, 300, 264, 22940, 3020, 8141, 382, 257, 2158, 472, 337, 264, 8819, 13, 1033, 11, 370, 286, 362, 341, 5367, 13, 51048, 51080, 407, 264, 551, 307, 11, 337, 341, 5367, 11, 286, 478, 516, 281, 2387, 11, 291, 458, 11, 264, 5777, 28162, 741, 293, 264, 51440, 51440, 7630, 365, 264, 912, 12379, 3364, 13, 1033, 11, 457, 286, 393, 23203, 300, 11, 291, 458, 11, 286, 393, 362, 51776, 51776], "temperature": 0.0, "avg_logprob": -0.15860386614529592, "compression_ratio": 1.6192468619246863, "no_speech_prob": 7.745754373900127e-06}, {"id": 643, "seek": 442564, "start": 4425.64, "end": 4432.200000000001, "text": " a template for the central node, the body one, and I can have a template for the one hope neighborhood.", "tokens": [50364, 257, 12379, 337, 264, 5777, 9984, 11, 264, 1772, 472, 11, 293, 286, 393, 362, 257, 12379, 337, 264, 472, 1454, 7630, 13, 50692, 50692, 1033, 11, 538, 884, 300, 11, 291, 3470, 1217, 257, 688, 11, 291, 458, 11, 428, 264, 3389, 295, 428, 50948, 50948, 295, 428, 4295, 18161, 9590, 13, 407, 291, 352, 490, 510, 281, 510, 13, 407, 291, 362, 797, 11, 51232, 51292, 512, 12379, 337, 264, 5777, 9984, 293, 264, 12379, 337, 264, 7630, 13, 1033, 11, 457, 341, 307, 51572, 51572], "temperature": 0.0, "avg_logprob": -0.1582103623284234, "compression_ratio": 1.9202127659574468, "no_speech_prob": 5.952470473857829e-06}, {"id": 644, "seek": 442564, "start": 4432.200000000001, "end": 4437.320000000001, "text": " Okay, by doing that, you improve already a lot, you know, your the performance of your", "tokens": [50364, 257, 12379, 337, 264, 5777, 9984, 11, 264, 1772, 472, 11, 293, 286, 393, 362, 257, 12379, 337, 264, 472, 1454, 7630, 13, 50692, 50692, 1033, 11, 538, 884, 300, 11, 291, 3470, 1217, 257, 688, 11, 291, 458, 11, 428, 264, 3389, 295, 428, 50948, 50948, 295, 428, 4295, 18161, 9590, 13, 407, 291, 352, 490, 510, 281, 510, 13, 407, 291, 362, 797, 11, 51232, 51292, 512, 12379, 337, 264, 5777, 9984, 293, 264, 12379, 337, 264, 7630, 13, 1033, 11, 457, 341, 307, 51572, 51572], "temperature": 0.0, "avg_logprob": -0.1582103623284234, "compression_ratio": 1.9202127659574468, "no_speech_prob": 5.952470473857829e-06}, {"id": 645, "seek": 442564, "start": 4437.320000000001, "end": 4443.0, "text": " of your graph neural networks. So you go from here to here. So you have again,", "tokens": [50364, 257, 12379, 337, 264, 5777, 9984, 11, 264, 1772, 472, 11, 293, 286, 393, 362, 257, 12379, 337, 264, 472, 1454, 7630, 13, 50692, 50692, 1033, 11, 538, 884, 300, 11, 291, 3470, 1217, 257, 688, 11, 291, 458, 11, 428, 264, 3389, 295, 428, 50948, 50948, 295, 428, 4295, 18161, 9590, 13, 407, 291, 352, 490, 510, 281, 510, 13, 407, 291, 362, 797, 11, 51232, 51292, 512, 12379, 337, 264, 5777, 9984, 293, 264, 12379, 337, 264, 7630, 13, 1033, 11, 457, 341, 307, 51572, 51572], "temperature": 0.0, "avg_logprob": -0.1582103623284234, "compression_ratio": 1.9202127659574468, "no_speech_prob": 5.952470473857829e-06}, {"id": 646, "seek": 442564, "start": 4444.200000000001, "end": 4449.8, "text": " some template for the central node and the template for the neighborhood. Okay, but this is", "tokens": [50364, 257, 12379, 337, 264, 5777, 9984, 11, 264, 1772, 472, 11, 293, 286, 393, 362, 257, 12379, 337, 264, 472, 1454, 7630, 13, 50692, 50692, 1033, 11, 538, 884, 300, 11, 291, 3470, 1217, 257, 688, 11, 291, 458, 11, 428, 264, 3389, 295, 428, 50948, 50948, 295, 428, 4295, 18161, 9590, 13, 407, 291, 352, 490, 510, 281, 510, 13, 407, 291, 362, 797, 11, 51232, 51292, 512, 12379, 337, 264, 5777, 9984, 293, 264, 12379, 337, 264, 7630, 13, 1033, 11, 457, 341, 307, 51572, 51572], "temperature": 0.0, "avg_logprob": -0.1582103623284234, "compression_ratio": 1.9202127659574468, "no_speech_prob": 5.952470473857829e-06}, {"id": 647, "seek": 444980, "start": 4449.8, "end": 4455.8, "text": " still an isotropic, isotropic GCN. Okay, because you are treating all the neighbors with the same weight.", "tokens": [50364, 920, 364, 38018, 39173, 11, 38018, 39173, 29435, 45, 13, 1033, 11, 570, 291, 366, 15083, 439, 264, 12512, 365, 264, 912, 3364, 13, 50664, 50720, 1692, 11, 341, 307, 264, 914, 11, 457, 291, 393, 1319, 291, 393, 747, 264, 2408, 11, 291, 393, 611, 747, 264, 11469, 11, 50932, 50932, 291, 393, 747, 611, 746, 544, 16298, 770, 411, 441, 6840, 44, 13, 1033, 11, 586, 544, 2935, 561, 853, 281, 3470, 51324, 51352, 264, 20864, 3701, 295, 29435, 45, 13, 407, 456, 390, 264, 4295, 307, 32702, 1434, 11, 51736, 51788], "temperature": 0.0, "avg_logprob": -0.18857347965240479, "compression_ratio": 1.6591928251121075, "no_speech_prob": 2.1419229597086087e-05}, {"id": 648, "seek": 444980, "start": 4456.92, "end": 4461.16, "text": " Here, this is the mean, but you can change you can take the sum, you can also take the max,", "tokens": [50364, 920, 364, 38018, 39173, 11, 38018, 39173, 29435, 45, 13, 1033, 11, 570, 291, 366, 15083, 439, 264, 12512, 365, 264, 912, 3364, 13, 50664, 50720, 1692, 11, 341, 307, 264, 914, 11, 457, 291, 393, 1319, 291, 393, 747, 264, 2408, 11, 291, 393, 611, 747, 264, 11469, 11, 50932, 50932, 291, 393, 747, 611, 746, 544, 16298, 770, 411, 441, 6840, 44, 13, 1033, 11, 586, 544, 2935, 561, 853, 281, 3470, 51324, 51352, 264, 20864, 3701, 295, 29435, 45, 13, 407, 456, 390, 264, 4295, 307, 32702, 1434, 11, 51736, 51788], "temperature": 0.0, "avg_logprob": -0.18857347965240479, "compression_ratio": 1.6591928251121075, "no_speech_prob": 2.1419229597086087e-05}, {"id": 649, "seek": 444980, "start": 4461.16, "end": 4469.0, "text": " you can take also something more elaborated like LSTM. Okay, now more simply people try to improve", "tokens": [50364, 920, 364, 38018, 39173, 11, 38018, 39173, 29435, 45, 13, 1033, 11, 570, 291, 366, 15083, 439, 264, 12512, 365, 264, 912, 3364, 13, 50664, 50720, 1692, 11, 341, 307, 264, 914, 11, 457, 291, 393, 1319, 291, 393, 747, 264, 2408, 11, 291, 393, 611, 747, 264, 11469, 11, 50932, 50932, 291, 393, 747, 611, 746, 544, 16298, 770, 411, 441, 6840, 44, 13, 1033, 11, 586, 544, 2935, 561, 853, 281, 3470, 51324, 51352, 264, 20864, 3701, 295, 29435, 45, 13, 407, 456, 390, 264, 4295, 307, 32702, 1434, 11, 51736, 51788], "temperature": 0.0, "avg_logprob": -0.18857347965240479, "compression_ratio": 1.6591928251121075, "no_speech_prob": 2.1419229597086087e-05}, {"id": 650, "seek": 444980, "start": 4469.56, "end": 4477.24, "text": " the theoretical understanding of GCN. So there was the graph isomorphism,", "tokens": [50364, 920, 364, 38018, 39173, 11, 38018, 39173, 29435, 45, 13, 1033, 11, 570, 291, 366, 15083, 439, 264, 12512, 365, 264, 912, 3364, 13, 50664, 50720, 1692, 11, 341, 307, 264, 914, 11, 457, 291, 393, 1319, 291, 393, 747, 264, 2408, 11, 291, 393, 611, 747, 264, 11469, 11, 50932, 50932, 291, 393, 747, 611, 746, 544, 16298, 770, 411, 441, 6840, 44, 13, 1033, 11, 586, 544, 2935, 561, 853, 281, 3470, 51324, 51352, 264, 20864, 3701, 295, 29435, 45, 13, 407, 456, 390, 264, 4295, 307, 32702, 1434, 11, 51736, 51788], "temperature": 0.0, "avg_logprob": -0.18857347965240479, "compression_ratio": 1.6591928251121075, "no_speech_prob": 2.1419229597086087e-05}, {"id": 651, "seek": 447724, "start": 4477.24, "end": 4483.0, "text": " I see isomorphism networks are introduced by Yuri Leskovic", "tokens": [50364, 286, 536, 307, 32702, 1434, 9590, 366, 7268, 538, 33901, 6965, 4093, 25537, 50652, 50776, 294, 6096, 13, 407, 264, 1558, 307, 11, 393, 321, 1715, 364, 9482, 300, 393, 23203, 24877, 51012, 51012, 300, 366, 406, 307, 32702, 299, 30, 407, 291, 458, 307, 32702, 299, 307, 1936, 257, 3481, 295, 9052, 655, 1296, 51368, 51368, 1296, 24877, 13, 407, 613, 732, 24877, 366, 307, 32702, 299, 281, 1184, 661, 13, 400, 295, 1164, 11, 291, 528, 281, 2387, 51588, 51588, 552, 264, 912, 636, 13, 583, 498, 291, 366, 406, 307, 32702, 299, 11, 291, 528, 2318, 281, 2387, 552, 294, 257, 819, 51844, 51844], "temperature": 0.0, "avg_logprob": -0.12056460074328501, "compression_ratio": 1.7682926829268293, "no_speech_prob": 3.8074740587035194e-05}, {"id": 652, "seek": 447724, "start": 4485.48, "end": 4490.2, "text": " in 2018. So the idea is, can we design an architecture that can differentiate graphs", "tokens": [50364, 286, 536, 307, 32702, 1434, 9590, 366, 7268, 538, 33901, 6965, 4093, 25537, 50652, 50776, 294, 6096, 13, 407, 264, 1558, 307, 11, 393, 321, 1715, 364, 9482, 300, 393, 23203, 24877, 51012, 51012, 300, 366, 406, 307, 32702, 299, 30, 407, 291, 458, 307, 32702, 299, 307, 1936, 257, 3481, 295, 9052, 655, 1296, 51368, 51368, 1296, 24877, 13, 407, 613, 732, 24877, 366, 307, 32702, 299, 281, 1184, 661, 13, 400, 295, 1164, 11, 291, 528, 281, 2387, 51588, 51588, 552, 264, 912, 636, 13, 583, 498, 291, 366, 406, 307, 32702, 299, 11, 291, 528, 2318, 281, 2387, 552, 294, 257, 819, 51844, 51844], "temperature": 0.0, "avg_logprob": -0.12056460074328501, "compression_ratio": 1.7682926829268293, "no_speech_prob": 3.8074740587035194e-05}, {"id": 653, "seek": 447724, "start": 4490.2, "end": 4497.32, "text": " that are not isomorphic? So you know isomorphic is basically a measure of equivalence between", "tokens": [50364, 286, 536, 307, 32702, 1434, 9590, 366, 7268, 538, 33901, 6965, 4093, 25537, 50652, 50776, 294, 6096, 13, 407, 264, 1558, 307, 11, 393, 321, 1715, 364, 9482, 300, 393, 23203, 24877, 51012, 51012, 300, 366, 406, 307, 32702, 299, 30, 407, 291, 458, 307, 32702, 299, 307, 1936, 257, 3481, 295, 9052, 655, 1296, 51368, 51368, 1296, 24877, 13, 407, 613, 732, 24877, 366, 307, 32702, 299, 281, 1184, 661, 13, 400, 295, 1164, 11, 291, 528, 281, 2387, 51588, 51588, 552, 264, 912, 636, 13, 583, 498, 291, 366, 406, 307, 32702, 299, 11, 291, 528, 2318, 281, 2387, 552, 294, 257, 819, 51844, 51844], "temperature": 0.0, "avg_logprob": -0.12056460074328501, "compression_ratio": 1.7682926829268293, "no_speech_prob": 3.8074740587035194e-05}, {"id": 654, "seek": 447724, "start": 4497.32, "end": 4501.719999999999, "text": " between graphs. So these two graphs are isomorphic to each other. And of course, you want to treat", "tokens": [50364, 286, 536, 307, 32702, 1434, 9590, 366, 7268, 538, 33901, 6965, 4093, 25537, 50652, 50776, 294, 6096, 13, 407, 264, 1558, 307, 11, 393, 321, 1715, 364, 9482, 300, 393, 23203, 24877, 51012, 51012, 300, 366, 406, 307, 32702, 299, 30, 407, 291, 458, 307, 32702, 299, 307, 1936, 257, 3481, 295, 9052, 655, 1296, 51368, 51368, 1296, 24877, 13, 407, 613, 732, 24877, 366, 307, 32702, 299, 281, 1184, 661, 13, 400, 295, 1164, 11, 291, 528, 281, 2387, 51588, 51588, 552, 264, 912, 636, 13, 583, 498, 291, 366, 406, 307, 32702, 299, 11, 291, 528, 2318, 281, 2387, 552, 294, 257, 819, 51844, 51844], "temperature": 0.0, "avg_logprob": -0.12056460074328501, "compression_ratio": 1.7682926829268293, "no_speech_prob": 3.8074740587035194e-05}, {"id": 655, "seek": 447724, "start": 4501.719999999999, "end": 4506.84, "text": " them the same way. But if you are not isomorphic, you want especially to treat them in a different", "tokens": [50364, 286, 536, 307, 32702, 1434, 9590, 366, 7268, 538, 33901, 6965, 4093, 25537, 50652, 50776, 294, 6096, 13, 407, 264, 1558, 307, 11, 393, 321, 1715, 364, 9482, 300, 393, 23203, 24877, 51012, 51012, 300, 366, 406, 307, 32702, 299, 30, 407, 291, 458, 307, 32702, 299, 307, 1936, 257, 3481, 295, 9052, 655, 1296, 51368, 51368, 1296, 24877, 13, 407, 613, 732, 24877, 366, 307, 32702, 299, 281, 1184, 661, 13, 400, 295, 1164, 11, 291, 528, 281, 2387, 51588, 51588, 552, 264, 912, 636, 13, 583, 498, 291, 366, 406, 307, 32702, 299, 11, 291, 528, 2318, 281, 2387, 552, 294, 257, 819, 51844, 51844], "temperature": 0.0, "avg_logprob": -0.12056460074328501, "compression_ratio": 1.7682926829268293, "no_speech_prob": 3.8074740587035194e-05}, {"id": 656, "seek": 450684, "start": 4506.84, "end": 4514.76, "text": " way. Okay, so there was a graph neural network based on this one, on this definition, but this", "tokens": [50364, 636, 13, 1033, 11, 370, 456, 390, 257, 4295, 18161, 3209, 2361, 322, 341, 472, 11, 322, 341, 7123, 11, 457, 341, 50760, 50760, 307, 920, 364, 38018, 39173, 29435, 45, 13, 1033, 11, 370, 586, 286, 478, 516, 281, 751, 466, 364, 271, 310, 39173, 29435, 45, 13, 407, 797, 11, 51192, 51292, 797, 11, 370, 286, 352, 646, 281, 437, 286, 848, 949, 307, 300, 3832, 15670, 393, 5258, 51484, 51512, 364, 271, 310, 39173, 15995, 11, 570, 456, 307, 257, 10710, 295, 11095, 322, 677, 3742, 13, 1033, 11, 370, 291, 362, 341, 51804, 51844], "temperature": 0.0, "avg_logprob": -0.14101970672607422, "compression_ratio": 1.6409090909090909, "no_speech_prob": 6.357438542181626e-05}, {"id": 657, "seek": 450684, "start": 4514.76, "end": 4523.400000000001, "text": " is still an isotropic GCN. Okay, so now I'm going to talk about anisotropic GCN. So again,", "tokens": [50364, 636, 13, 1033, 11, 370, 456, 390, 257, 4295, 18161, 3209, 2361, 322, 341, 472, 11, 322, 341, 7123, 11, 457, 341, 50760, 50760, 307, 920, 364, 38018, 39173, 29435, 45, 13, 1033, 11, 370, 586, 286, 478, 516, 281, 751, 466, 364, 271, 310, 39173, 29435, 45, 13, 407, 797, 11, 51192, 51292, 797, 11, 370, 286, 352, 646, 281, 437, 286, 848, 949, 307, 300, 3832, 15670, 393, 5258, 51484, 51512, 364, 271, 310, 39173, 15995, 11, 570, 456, 307, 257, 10710, 295, 11095, 322, 677, 3742, 13, 1033, 11, 370, 291, 362, 341, 51804, 51844], "temperature": 0.0, "avg_logprob": -0.14101970672607422, "compression_ratio": 1.6409090909090909, "no_speech_prob": 6.357438542181626e-05}, {"id": 658, "seek": 450684, "start": 4525.400000000001, "end": 4529.24, "text": " again, so I go back to what I said before is that standard coordinate can produce", "tokens": [50364, 636, 13, 1033, 11, 370, 456, 390, 257, 4295, 18161, 3209, 2361, 322, 341, 472, 11, 322, 341, 7123, 11, 457, 341, 50760, 50760, 307, 920, 364, 38018, 39173, 29435, 45, 13, 1033, 11, 370, 586, 286, 478, 516, 281, 751, 466, 364, 271, 310, 39173, 29435, 45, 13, 407, 797, 11, 51192, 51292, 797, 11, 370, 286, 352, 646, 281, 437, 286, 848, 949, 307, 300, 3832, 15670, 393, 5258, 51484, 51512, 364, 271, 310, 39173, 15995, 11, 570, 456, 307, 257, 10710, 295, 11095, 322, 677, 3742, 13, 1033, 11, 370, 291, 362, 341, 51804, 51844], "temperature": 0.0, "avg_logprob": -0.14101970672607422, "compression_ratio": 1.6409090909090909, "no_speech_prob": 6.357438542181626e-05}, {"id": 659, "seek": 450684, "start": 4529.8, "end": 4535.64, "text": " anisotropic filters, because there is a notion of directions on grids. Okay, so you have this", "tokens": [50364, 636, 13, 1033, 11, 370, 456, 390, 257, 4295, 18161, 3209, 2361, 322, 341, 472, 11, 322, 341, 7123, 11, 457, 341, 50760, 50760, 307, 920, 364, 38018, 39173, 29435, 45, 13, 1033, 11, 370, 586, 286, 478, 516, 281, 751, 466, 364, 271, 310, 39173, 29435, 45, 13, 407, 797, 11, 51192, 51292, 797, 11, 370, 286, 352, 646, 281, 437, 286, 848, 949, 307, 300, 3832, 15670, 393, 5258, 51484, 51512, 364, 271, 310, 39173, 15995, 11, 570, 456, 307, 257, 10710, 295, 11095, 322, 677, 3742, 13, 1033, 11, 370, 291, 362, 341, 51804, 51844], "temperature": 0.0, "avg_logprob": -0.14101970672607422, "compression_ratio": 1.6409090909090909, "no_speech_prob": 6.357438542181626e-05}, {"id": 660, "seek": 453564, "start": 4535.64, "end": 4543.64, "text": " anisotropic filter in this direction. GCN like a ChemNet, KaliNet, Vanilla GCN, GraphSAGE, and GIN,", "tokens": [50364, 364, 271, 310, 39173, 6608, 294, 341, 3513, 13, 29435, 45, 411, 257, 21357, 31890, 11, 591, 5103, 31890, 11, 8979, 5291, 29435, 45, 11, 21884, 8886, 9177, 11, 293, 460, 1464, 11, 50764, 50764, 436, 14722, 38018, 39173, 15995, 13, 407, 291, 362, 341, 733, 295, 15995, 300, 291, 1466, 1830, 264, 1399, 11, 51080, 51080, 457, 436, 366, 38018, 39173, 13, 583, 321, 458, 300, 364, 271, 310, 27514, 307, 588, 4005, 11, 558, 30, 407, 577, 360, 321, 483, 646, 51408, 51408, 364, 271, 310, 27514, 294, 4295, 18161, 9590, 30, 407, 291, 393, 483, 364, 271, 310, 27514, 8195, 13, 1171, 1365, 11, 498, 291, 362, 51704, 51704], "temperature": 0.0, "avg_logprob": -0.18394425040797183, "compression_ratio": 1.6610878661087867, "no_speech_prob": 4.038202314404771e-05}, {"id": 661, "seek": 453564, "start": 4543.64, "end": 4549.96, "text": " they compute isotropic filters. So you have this kind of filters that you learn during the process,", "tokens": [50364, 364, 271, 310, 39173, 6608, 294, 341, 3513, 13, 29435, 45, 411, 257, 21357, 31890, 11, 591, 5103, 31890, 11, 8979, 5291, 29435, 45, 11, 21884, 8886, 9177, 11, 293, 460, 1464, 11, 50764, 50764, 436, 14722, 38018, 39173, 15995, 13, 407, 291, 362, 341, 733, 295, 15995, 300, 291, 1466, 1830, 264, 1399, 11, 51080, 51080, 457, 436, 366, 38018, 39173, 13, 583, 321, 458, 300, 364, 271, 310, 27514, 307, 588, 4005, 11, 558, 30, 407, 577, 360, 321, 483, 646, 51408, 51408, 364, 271, 310, 27514, 294, 4295, 18161, 9590, 30, 407, 291, 393, 483, 364, 271, 310, 27514, 8195, 13, 1171, 1365, 11, 498, 291, 362, 51704, 51704], "temperature": 0.0, "avg_logprob": -0.18394425040797183, "compression_ratio": 1.6610878661087867, "no_speech_prob": 4.038202314404771e-05}, {"id": 662, "seek": 453564, "start": 4549.96, "end": 4556.52, "text": " but they are isotropic. But we know that anisotropy is very powerful, right? So how do we get back", "tokens": [50364, 364, 271, 310, 39173, 6608, 294, 341, 3513, 13, 29435, 45, 411, 257, 21357, 31890, 11, 591, 5103, 31890, 11, 8979, 5291, 29435, 45, 11, 21884, 8886, 9177, 11, 293, 460, 1464, 11, 50764, 50764, 436, 14722, 38018, 39173, 15995, 13, 407, 291, 362, 341, 733, 295, 15995, 300, 291, 1466, 1830, 264, 1399, 11, 51080, 51080, 457, 436, 366, 38018, 39173, 13, 583, 321, 458, 300, 364, 271, 310, 27514, 307, 588, 4005, 11, 558, 30, 407, 577, 360, 321, 483, 646, 51408, 51408, 364, 271, 310, 27514, 294, 4295, 18161, 9590, 30, 407, 291, 393, 483, 364, 271, 310, 27514, 8195, 13, 1171, 1365, 11, 498, 291, 362, 51704, 51704], "temperature": 0.0, "avg_logprob": -0.18394425040797183, "compression_ratio": 1.6610878661087867, "no_speech_prob": 4.038202314404771e-05}, {"id": 663, "seek": 453564, "start": 4556.52, "end": 4562.4400000000005, "text": " anisotropy in graph neural networks? So you can get anisotropy naturally. For example, if you have", "tokens": [50364, 364, 271, 310, 39173, 6608, 294, 341, 3513, 13, 29435, 45, 411, 257, 21357, 31890, 11, 591, 5103, 31890, 11, 8979, 5291, 29435, 45, 11, 21884, 8886, 9177, 11, 293, 460, 1464, 11, 50764, 50764, 436, 14722, 38018, 39173, 15995, 13, 407, 291, 362, 341, 733, 295, 15995, 300, 291, 1466, 1830, 264, 1399, 11, 51080, 51080, 457, 436, 366, 38018, 39173, 13, 583, 321, 458, 300, 364, 271, 310, 27514, 307, 588, 4005, 11, 558, 30, 407, 577, 360, 321, 483, 646, 51408, 51408, 364, 271, 310, 27514, 294, 4295, 18161, 9590, 30, 407, 291, 393, 483, 364, 271, 310, 27514, 8195, 13, 1171, 1365, 11, 498, 291, 362, 51704, 51704], "temperature": 0.0, "avg_logprob": -0.18394425040797183, "compression_ratio": 1.6610878661087867, "no_speech_prob": 4.038202314404771e-05}, {"id": 664, "seek": 456244, "start": 4562.44, "end": 4569.879999999999, "text": " H features for like, if you take in chemistry molecules, you know that the bond features can", "tokens": [50364, 389, 4122, 337, 411, 11, 498, 291, 747, 294, 12558, 13093, 11, 291, 458, 300, 264, 6086, 4122, 393, 50736, 50736, 312, 819, 13, 814, 393, 312, 11, 291, 458, 11, 2167, 11, 3834, 11, 45831, 14713, 13, 407, 8195, 291, 576, 483, 364, 271, 310, 39173, 51008, 51084, 29435, 45, 13, 400, 797, 11, 498, 321, 528, 281, 1715, 257, 7513, 337, 364, 271, 310, 27514, 11, 321, 528, 341, 7513, 281, 312, 51480, 51480, 6695, 365, 3104, 281, 264, 18184, 6220, 302, 24959, 399, 13, 407, 281, 360, 300, 11, 321, 393, 764, 11, 337, 1365, 11, 389, 5310, 13, 51788, 51840], "temperature": 0.0, "avg_logprob": -0.15901139097393685, "compression_ratio": 1.6487603305785123, "no_speech_prob": 6.056341953808442e-05}, {"id": 665, "seek": 456244, "start": 4569.879999999999, "end": 4575.32, "text": " be different. They can be, you know, single, double, aromatic bonds. So naturally you would get anisotropic", "tokens": [50364, 389, 4122, 337, 411, 11, 498, 291, 747, 294, 12558, 13093, 11, 291, 458, 300, 264, 6086, 4122, 393, 50736, 50736, 312, 819, 13, 814, 393, 312, 11, 291, 458, 11, 2167, 11, 3834, 11, 45831, 14713, 13, 407, 8195, 291, 576, 483, 364, 271, 310, 39173, 51008, 51084, 29435, 45, 13, 400, 797, 11, 498, 321, 528, 281, 1715, 257, 7513, 337, 364, 271, 310, 27514, 11, 321, 528, 341, 7513, 281, 312, 51480, 51480, 6695, 365, 3104, 281, 264, 18184, 6220, 302, 24959, 399, 13, 407, 281, 360, 300, 11, 321, 393, 764, 11, 337, 1365, 11, 389, 5310, 13, 51788, 51840], "temperature": 0.0, "avg_logprob": -0.15901139097393685, "compression_ratio": 1.6487603305785123, "no_speech_prob": 6.056341953808442e-05}, {"id": 666, "seek": 456244, "start": 4576.839999999999, "end": 4584.759999999999, "text": " GCN. And again, if we want to design a mechanism for anisotropy, we want this mechanism to be", "tokens": [50364, 389, 4122, 337, 411, 11, 498, 291, 747, 294, 12558, 13093, 11, 291, 458, 300, 264, 6086, 4122, 393, 50736, 50736, 312, 819, 13, 814, 393, 312, 11, 291, 458, 11, 2167, 11, 3834, 11, 45831, 14713, 13, 407, 8195, 291, 576, 483, 364, 271, 310, 39173, 51008, 51084, 29435, 45, 13, 400, 797, 11, 498, 321, 528, 281, 1715, 257, 7513, 337, 364, 271, 310, 27514, 11, 321, 528, 341, 7513, 281, 312, 51480, 51480, 6695, 365, 3104, 281, 264, 18184, 6220, 302, 24959, 399, 13, 407, 281, 360, 300, 11, 321, 393, 764, 11, 337, 1365, 11, 389, 5310, 13, 51788, 51840], "temperature": 0.0, "avg_logprob": -0.15901139097393685, "compression_ratio": 1.6487603305785123, "no_speech_prob": 6.056341953808442e-05}, {"id": 667, "seek": 456244, "start": 4584.759999999999, "end": 4590.919999999999, "text": " independent with respect to the null parametrization. So to do that, we can use, for example, H degrees.", "tokens": [50364, 389, 4122, 337, 411, 11, 498, 291, 747, 294, 12558, 13093, 11, 291, 458, 300, 264, 6086, 4122, 393, 50736, 50736, 312, 819, 13, 814, 393, 312, 11, 291, 458, 11, 2167, 11, 3834, 11, 45831, 14713, 13, 407, 8195, 291, 576, 483, 364, 271, 310, 39173, 51008, 51084, 29435, 45, 13, 400, 797, 11, 498, 321, 528, 281, 1715, 257, 7513, 337, 364, 271, 310, 27514, 11, 321, 528, 341, 7513, 281, 312, 51480, 51480, 6695, 365, 3104, 281, 264, 18184, 6220, 302, 24959, 399, 13, 407, 281, 360, 300, 11, 321, 393, 764, 11, 337, 1365, 11, 389, 5310, 13, 51788, 51840], "temperature": 0.0, "avg_logprob": -0.15901139097393685, "compression_ratio": 1.6487603305785123, "no_speech_prob": 6.056341953808442e-05}, {"id": 668, "seek": 459092, "start": 4590.92, "end": 4597.32, "text": " And so that was proposed by Monet, Hgate that we propose in GAT GCN or attention mechanism", "tokens": [50364, 400, 370, 300, 390, 10348, 538, 4713, 302, 11, 389, 22514, 300, 321, 17421, 294, 460, 2218, 29435, 45, 420, 3202, 7513, 50684, 50720, 294, 460, 2218, 13, 400, 264, 1558, 307, 437, 286, 829, 510, 382, 364, 22645, 13, 1033, 13, 407, 510, 291, 434, 516, 281, 2387, 51068, 51068, 428, 12512, 294, 264, 912, 636, 13, 1033, 13, 407, 365, 264, 912, 12379, 11, 457, 291, 528, 281, 2387, 428, 12512, 51436, 51436, 294, 257, 819, 636, 11, 558, 30, 759, 341, 307, 508, 16, 11, 291, 528, 257, 819, 3364, 813, 498, 309, 390, 337, 508, 17, 13, 51684, 51684], "temperature": 0.0, "avg_logprob": -0.22692827497209822, "compression_ratio": 1.6637554585152838, "no_speech_prob": 5.953937034064438e-06}, {"id": 669, "seek": 459092, "start": 4598.04, "end": 4605.0, "text": " in GAT. And the idea is what I put here as an illustration. Okay. So here you're going to treat", "tokens": [50364, 400, 370, 300, 390, 10348, 538, 4713, 302, 11, 389, 22514, 300, 321, 17421, 294, 460, 2218, 29435, 45, 420, 3202, 7513, 50684, 50720, 294, 460, 2218, 13, 400, 264, 1558, 307, 437, 286, 829, 510, 382, 364, 22645, 13, 1033, 13, 407, 510, 291, 434, 516, 281, 2387, 51068, 51068, 428, 12512, 294, 264, 912, 636, 13, 1033, 13, 407, 365, 264, 912, 12379, 11, 457, 291, 528, 281, 2387, 428, 12512, 51436, 51436, 294, 257, 819, 636, 11, 558, 30, 759, 341, 307, 508, 16, 11, 291, 528, 257, 819, 3364, 813, 498, 309, 390, 337, 508, 17, 13, 51684, 51684], "temperature": 0.0, "avg_logprob": -0.22692827497209822, "compression_ratio": 1.6637554585152838, "no_speech_prob": 5.953937034064438e-06}, {"id": 670, "seek": 459092, "start": 4605.0, "end": 4612.36, "text": " your neighbors in the same way. Okay. So with the same template, but you want to treat your neighbors", "tokens": [50364, 400, 370, 300, 390, 10348, 538, 4713, 302, 11, 389, 22514, 300, 321, 17421, 294, 460, 2218, 29435, 45, 420, 3202, 7513, 50684, 50720, 294, 460, 2218, 13, 400, 264, 1558, 307, 437, 286, 829, 510, 382, 364, 22645, 13, 1033, 13, 407, 510, 291, 434, 516, 281, 2387, 51068, 51068, 428, 12512, 294, 264, 912, 636, 13, 1033, 13, 407, 365, 264, 912, 12379, 11, 457, 291, 528, 281, 2387, 428, 12512, 51436, 51436, 294, 257, 819, 636, 11, 558, 30, 759, 341, 307, 508, 16, 11, 291, 528, 257, 819, 3364, 813, 498, 309, 390, 337, 508, 17, 13, 51684, 51684], "temperature": 0.0, "avg_logprob": -0.22692827497209822, "compression_ratio": 1.6637554585152838, "no_speech_prob": 5.953937034064438e-06}, {"id": 671, "seek": 459092, "start": 4612.36, "end": 4617.32, "text": " in a different way, right? If this is J1, you want a different weight than if it was for J2.", "tokens": [50364, 400, 370, 300, 390, 10348, 538, 4713, 302, 11, 389, 22514, 300, 321, 17421, 294, 460, 2218, 29435, 45, 420, 3202, 7513, 50684, 50720, 294, 460, 2218, 13, 400, 264, 1558, 307, 437, 286, 829, 510, 382, 364, 22645, 13, 1033, 13, 407, 510, 291, 434, 516, 281, 2387, 51068, 51068, 428, 12512, 294, 264, 912, 636, 13, 1033, 13, 407, 365, 264, 912, 12379, 11, 457, 291, 528, 281, 2387, 428, 12512, 51436, 51436, 294, 257, 819, 636, 11, 558, 30, 759, 341, 307, 508, 16, 11, 291, 528, 257, 819, 3364, 813, 498, 309, 390, 337, 508, 17, 13, 51684, 51684], "temperature": 0.0, "avg_logprob": -0.22692827497209822, "compression_ratio": 1.6637554585152838, "no_speech_prob": 5.953937034064438e-06}, {"id": 672, "seek": 461732, "start": 4617.32, "end": 4623.16, "text": " What do you want that is, for example, if you want to analyze graphs, you know that you have communities", "tokens": [50364, 708, 360, 291, 528, 300, 307, 11, 337, 1365, 11, 498, 291, 528, 281, 12477, 24877, 11, 291, 458, 300, 291, 362, 4456, 50656, 50656, 295, 561, 597, 366, 819, 13, 1171, 1365, 11, 286, 500, 380, 458, 498, 309, 307, 7341, 11, 291, 362, 12017, 293, 50972, 50972, 12217, 13, 407, 291, 500, 380, 528, 11, 291, 458, 11, 281, 362, 264, 912, 5215, 337, 264, 912, 1594, 295, 561, 13, 51264, 51264, 407, 291, 528, 364, 271, 310, 27514, 337, 4295, 13, 663, 311, 1596, 1021, 13, 1033, 13, 407, 264, 700, 2316, 51608, 51652], "temperature": 0.0, "avg_logprob": -0.1176253232088956, "compression_ratio": 1.6842105263157894, "no_speech_prob": 5.646461431751959e-05}, {"id": 673, "seek": 461732, "start": 4623.16, "end": 4629.48, "text": " of people which are different. For example, I don't know if it is politics, you have Republicans and", "tokens": [50364, 708, 360, 291, 528, 300, 307, 11, 337, 1365, 11, 498, 291, 528, 281, 12477, 24877, 11, 291, 458, 300, 291, 362, 4456, 50656, 50656, 295, 561, 597, 366, 819, 13, 1171, 1365, 11, 286, 500, 380, 458, 498, 309, 307, 7341, 11, 291, 362, 12017, 293, 50972, 50972, 12217, 13, 407, 291, 500, 380, 528, 11, 291, 458, 11, 281, 362, 264, 912, 5215, 337, 264, 912, 1594, 295, 561, 13, 51264, 51264, 407, 291, 528, 364, 271, 310, 27514, 337, 4295, 13, 663, 311, 1596, 1021, 13, 1033, 13, 407, 264, 700, 2316, 51608, 51652], "temperature": 0.0, "avg_logprob": -0.1176253232088956, "compression_ratio": 1.6842105263157894, "no_speech_prob": 5.646461431751959e-05}, {"id": 674, "seek": 461732, "start": 4629.48, "end": 4635.32, "text": " Democrats. So you don't want, you know, to have the same analysis for the same group of people.", "tokens": [50364, 708, 360, 291, 528, 300, 307, 11, 337, 1365, 11, 498, 291, 528, 281, 12477, 24877, 11, 291, 458, 300, 291, 362, 4456, 50656, 50656, 295, 561, 597, 366, 819, 13, 1171, 1365, 11, 286, 500, 380, 458, 498, 309, 307, 7341, 11, 291, 362, 12017, 293, 50972, 50972, 12217, 13, 407, 291, 500, 380, 528, 11, 291, 458, 11, 281, 362, 264, 912, 5215, 337, 264, 912, 1594, 295, 561, 13, 51264, 51264, 407, 291, 528, 364, 271, 310, 27514, 337, 4295, 13, 663, 311, 1596, 1021, 13, 1033, 13, 407, 264, 700, 2316, 51608, 51652], "temperature": 0.0, "avg_logprob": -0.1176253232088956, "compression_ratio": 1.6842105263157894, "no_speech_prob": 5.646461431751959e-05}, {"id": 675, "seek": 461732, "start": 4635.32, "end": 4642.2, "text": " So you want anisotropy for graph. That's quite important. Okay. So the first model", "tokens": [50364, 708, 360, 291, 528, 300, 307, 11, 337, 1365, 11, 498, 291, 528, 281, 12477, 24877, 11, 291, 458, 300, 291, 362, 4456, 50656, 50656, 295, 561, 597, 366, 819, 13, 1171, 1365, 11, 286, 500, 380, 458, 498, 309, 307, 7341, 11, 291, 362, 12017, 293, 50972, 50972, 12217, 13, 407, 291, 500, 380, 528, 11, 291, 458, 11, 281, 362, 264, 912, 5215, 337, 264, 912, 1594, 295, 561, 13, 51264, 51264, 407, 291, 528, 364, 271, 310, 27514, 337, 4295, 13, 663, 311, 1596, 1021, 13, 1033, 13, 407, 264, 700, 2316, 51608, 51652], "temperature": 0.0, "avg_logprob": -0.1176253232088956, "compression_ratio": 1.6842105263157894, "no_speech_prob": 5.646461431751959e-05}, {"id": 676, "seek": 464220, "start": 4642.2, "end": 4647.88, "text": " who deal with anisotropy was Monet. So he was introduced by Federico Monti, Michael Bronstain,", "tokens": [50364, 567, 2028, 365, 364, 271, 310, 27514, 390, 4713, 302, 13, 407, 415, 390, 7268, 538, 45545, 2789, 7947, 72, 11, 5116, 1603, 4068, 491, 11, 50648, 50648, 293, 641, 598, 12, 34224, 13, 400, 264, 1558, 390, 281, 764, 16609, 44, 11, 370, 39148, 9925, 2316, 11, 293, 281, 1466, 264, 50936, 50936, 9834, 295, 264, 39148, 9925, 13, 407, 510, 436, 362, 591, 39148, 9925, 2316, 11, 293, 550, 1466, 264, 51176, 51176, 9834, 538, 1228, 264, 4314, 295, 264, 4295, 13, 1396, 456, 307, 611, 460, 2218, 13, 407, 309, 390, 4743, 538, 51644, 51644], "temperature": 0.0, "avg_logprob": -0.19049217224121093, "compression_ratio": 1.7793427230046948, "no_speech_prob": 2.3517282897955738e-05}, {"id": 677, "seek": 464220, "start": 4647.88, "end": 4653.639999999999, "text": " and their co-author. And the idea was to use GMM, so Gaussian mixture model, and to learn the", "tokens": [50364, 567, 2028, 365, 364, 271, 310, 27514, 390, 4713, 302, 13, 407, 415, 390, 7268, 538, 45545, 2789, 7947, 72, 11, 5116, 1603, 4068, 491, 11, 50648, 50648, 293, 641, 598, 12, 34224, 13, 400, 264, 1558, 390, 281, 764, 16609, 44, 11, 370, 39148, 9925, 2316, 11, 293, 281, 1466, 264, 50936, 50936, 9834, 295, 264, 39148, 9925, 13, 407, 510, 436, 362, 591, 39148, 9925, 2316, 11, 293, 550, 1466, 264, 51176, 51176, 9834, 538, 1228, 264, 4314, 295, 264, 4295, 13, 1396, 456, 307, 611, 460, 2218, 13, 407, 309, 390, 4743, 538, 51644, 51644], "temperature": 0.0, "avg_logprob": -0.19049217224121093, "compression_ratio": 1.7793427230046948, "no_speech_prob": 2.3517282897955738e-05}, {"id": 678, "seek": 464220, "start": 4653.639999999999, "end": 4658.44, "text": " parameters of the Gaussian mixture. So here they have K Gaussian mixture model, and then learn the", "tokens": [50364, 567, 2028, 365, 364, 271, 310, 27514, 390, 4713, 302, 13, 407, 415, 390, 7268, 538, 45545, 2789, 7947, 72, 11, 5116, 1603, 4068, 491, 11, 50648, 50648, 293, 641, 598, 12, 34224, 13, 400, 264, 1558, 390, 281, 764, 16609, 44, 11, 370, 39148, 9925, 2316, 11, 293, 281, 1466, 264, 50936, 50936, 9834, 295, 264, 39148, 9925, 13, 407, 510, 436, 362, 591, 39148, 9925, 2316, 11, 293, 550, 1466, 264, 51176, 51176, 9834, 538, 1228, 264, 4314, 295, 264, 4295, 13, 1396, 456, 307, 611, 460, 2218, 13, 407, 309, 390, 4743, 538, 51644, 51644], "temperature": 0.0, "avg_logprob": -0.19049217224121093, "compression_ratio": 1.7793427230046948, "no_speech_prob": 2.3517282897955738e-05}, {"id": 679, "seek": 464220, "start": 4658.44, "end": 4667.8, "text": " parameters by using the degree of the graph. Then there is also GAT. So it was developed by", "tokens": [50364, 567, 2028, 365, 364, 271, 310, 27514, 390, 4713, 302, 13, 407, 415, 390, 7268, 538, 45545, 2789, 7947, 72, 11, 5116, 1603, 4068, 491, 11, 50648, 50648, 293, 641, 598, 12, 34224, 13, 400, 264, 1558, 390, 281, 764, 16609, 44, 11, 370, 39148, 9925, 2316, 11, 293, 281, 1466, 264, 50936, 50936, 9834, 295, 264, 39148, 9925, 13, 407, 510, 436, 362, 591, 39148, 9925, 2316, 11, 293, 550, 1466, 264, 51176, 51176, 9834, 538, 1228, 264, 4314, 295, 264, 4295, 13, 1396, 456, 307, 611, 460, 2218, 13, 407, 309, 390, 4743, 538, 51644, 51644], "temperature": 0.0, "avg_logprob": -0.19049217224121093, "compression_ratio": 1.7793427230046948, "no_speech_prob": 2.3517282897955738e-05}, {"id": 680, "seek": 466780, "start": 4667.8, "end": 4673.56, "text": " Peter Velikovic and Yoshua Benjo and their co-author. It was basically to use the attention", "tokens": [50364, 6508, 17814, 1035, 5179, 299, 293, 38949, 4398, 3964, 5134, 293, 641, 598, 12, 34224, 13, 467, 390, 1936, 281, 764, 264, 3202, 50652, 50652, 7513, 4743, 538, 15709, 11523, 3730, 11, 38949, 4398, 3964, 5134, 11, 293, 12366, 281, 5366, 364, 271, 310, 27514, 294, 264, 7630, 50992, 50992, 24590, 2445, 13, 1033, 13, 400, 370, 341, 307, 437, 291, 536, 510, 13, 407, 291, 362, 11, 291, 434, 516, 281, 1588, 7186, 473, 11, 51308, 51308, 370, 309, 311, 257, 4825, 12, 1934, 9482, 13, 400, 510, 291, 362, 341, 3364, 11, 597, 366, 1936, 264, 2787, 41167, 51720, 51788], "temperature": 0.0, "avg_logprob": -0.20726607396052435, "compression_ratio": 1.5551181102362204, "no_speech_prob": 3.5890214348910376e-05}, {"id": 681, "seek": 466780, "start": 4673.56, "end": 4680.360000000001, "text": " mechanism developed by Jimmy Badano, Yoshua Benjo, and Cho to introduce anisotropy in the neighborhood", "tokens": [50364, 6508, 17814, 1035, 5179, 299, 293, 38949, 4398, 3964, 5134, 293, 641, 598, 12, 34224, 13, 467, 390, 1936, 281, 764, 264, 3202, 50652, 50652, 7513, 4743, 538, 15709, 11523, 3730, 11, 38949, 4398, 3964, 5134, 11, 293, 12366, 281, 5366, 364, 271, 310, 27514, 294, 264, 7630, 50992, 50992, 24590, 2445, 13, 1033, 13, 400, 370, 341, 307, 437, 291, 536, 510, 13, 407, 291, 362, 11, 291, 434, 516, 281, 1588, 7186, 473, 11, 51308, 51308, 370, 309, 311, 257, 4825, 12, 1934, 9482, 13, 400, 510, 291, 362, 341, 3364, 11, 597, 366, 1936, 264, 2787, 41167, 51720, 51788], "temperature": 0.0, "avg_logprob": -0.20726607396052435, "compression_ratio": 1.5551181102362204, "no_speech_prob": 3.5890214348910376e-05}, {"id": 682, "seek": 466780, "start": 4680.360000000001, "end": 4686.68, "text": " regression function. Okay. And so this is what you see here. So you have, you're going to concatenate,", "tokens": [50364, 6508, 17814, 1035, 5179, 299, 293, 38949, 4398, 3964, 5134, 293, 641, 598, 12, 34224, 13, 467, 390, 1936, 281, 764, 264, 3202, 50652, 50652, 7513, 4743, 538, 15709, 11523, 3730, 11, 38949, 4398, 3964, 5134, 11, 293, 12366, 281, 5366, 364, 271, 310, 27514, 294, 264, 7630, 50992, 50992, 24590, 2445, 13, 1033, 13, 400, 370, 341, 307, 437, 291, 536, 510, 13, 407, 291, 362, 11, 291, 434, 516, 281, 1588, 7186, 473, 11, 51308, 51308, 370, 309, 311, 257, 4825, 12, 1934, 9482, 13, 400, 510, 291, 362, 341, 3364, 11, 597, 366, 1936, 264, 2787, 41167, 51720, 51788], "temperature": 0.0, "avg_logprob": -0.20726607396052435, "compression_ratio": 1.5551181102362204, "no_speech_prob": 3.5890214348910376e-05}, {"id": 683, "seek": 466780, "start": 4686.68, "end": 4694.92, "text": " so it's a multi-head architecture. And here you have this weight, which are basically the softmax", "tokens": [50364, 6508, 17814, 1035, 5179, 299, 293, 38949, 4398, 3964, 5134, 293, 641, 598, 12, 34224, 13, 467, 390, 1936, 281, 764, 264, 3202, 50652, 50652, 7513, 4743, 538, 15709, 11523, 3730, 11, 38949, 4398, 3964, 5134, 11, 293, 12366, 281, 5366, 364, 271, 310, 27514, 294, 264, 7630, 50992, 50992, 24590, 2445, 13, 1033, 13, 400, 370, 341, 307, 437, 291, 536, 510, 13, 407, 291, 362, 11, 291, 434, 516, 281, 1588, 7186, 473, 11, 51308, 51308, 370, 309, 311, 257, 4825, 12, 1934, 9482, 13, 400, 510, 291, 362, 341, 3364, 11, 597, 366, 1936, 264, 2787, 41167, 51720, 51788], "temperature": 0.0, "avg_logprob": -0.20726607396052435, "compression_ratio": 1.5551181102362204, "no_speech_prob": 3.5890214348910376e-05}, {"id": 684, "seek": 469492, "start": 4694.92, "end": 4699.56, "text": " on the neighborhood. Okay. You do the softmax on the neighborhood. So some", "tokens": [50364, 322, 264, 7630, 13, 1033, 13, 509, 360, 264, 2787, 41167, 322, 264, 7630, 13, 407, 512, 50596, 50688, 13891, 486, 312, 544, 1021, 813, 264, 2357, 11, 2212, 538, 2787, 41167, 13, 708, 321, 764, 365, 8500, 49357, 51116, 51156, 293, 385, 294, 6591, 11, 321, 764, 257, 2199, 3205, 12, 847, 783, 7513, 11, 597, 307, 257, 2787, 3202, 1399, 51636, 51668], "temperature": 0.0, "avg_logprob": -0.2554051370331735, "compression_ratio": 1.4550561797752808, "no_speech_prob": 3.450404983595945e-05}, {"id": 685, "seek": 469492, "start": 4701.4, "end": 4709.96, "text": " nodes will be more important than the others, given by softmax. What we use with Thomas Laurent", "tokens": [50364, 322, 264, 7630, 13, 1033, 13, 509, 360, 264, 2787, 41167, 322, 264, 7630, 13, 407, 512, 50596, 50688, 13891, 486, 312, 544, 1021, 813, 264, 2357, 11, 2212, 538, 2787, 41167, 13, 708, 321, 764, 365, 8500, 49357, 51116, 51156, 293, 385, 294, 6591, 11, 321, 764, 257, 2199, 3205, 12, 847, 783, 7513, 11, 597, 307, 257, 2787, 3202, 1399, 51636, 51668], "temperature": 0.0, "avg_logprob": -0.2554051370331735, "compression_ratio": 1.4550561797752808, "no_speech_prob": 3.450404983595945e-05}, {"id": 686, "seek": 469492, "start": 4710.76, "end": 4720.36, "text": " and me in 2017, we use a simple age-getting mechanism, which is a soft attention process", "tokens": [50364, 322, 264, 7630, 13, 1033, 13, 509, 360, 264, 2787, 41167, 322, 264, 7630, 13, 407, 512, 50596, 50688, 13891, 486, 312, 544, 1021, 813, 264, 2357, 11, 2212, 538, 2787, 41167, 13, 708, 321, 764, 365, 8500, 49357, 51116, 51156, 293, 385, 294, 6591, 11, 321, 764, 257, 2199, 3205, 12, 847, 783, 7513, 11, 597, 307, 257, 2787, 3202, 1399, 51636, 51668], "temperature": 0.0, "avg_logprob": -0.2554051370331735, "compression_ratio": 1.4550561797752808, "no_speech_prob": 3.450404983595945e-05}, {"id": 687, "seek": 472036, "start": 4720.36, "end": 4727.16, "text": " compared to the sparse attention mechanism of Yoshua Benjo. And here what we did also, we use", "tokens": [50364, 5347, 281, 264, 637, 11668, 3202, 7513, 295, 38949, 4398, 3964, 5134, 13, 400, 510, 437, 321, 630, 611, 11, 321, 764, 50704, 50704, 389, 4111, 20803, 13, 400, 341, 767, 11, 3938, 321, 6941, 300, 341, 307, 588, 1021, 337, 389, 50960, 50960, 17630, 5633, 13, 759, 291, 362, 13691, 30359, 5633, 11, 341, 307, 1021, 281, 1066, 309, 13, 1033, 13, 407, 341, 51304, 51304, 307, 264, 2316, 300, 321, 1143, 13, 1033, 13, 1396, 11, 1392, 11, 370, 498, 286, 747, 31782, 11, 293, 498, 286, 2464, 760, 264, 51824], "temperature": 0.0, "avg_logprob": -0.20575336657072368, "compression_ratio": 1.6452991452991452, "no_speech_prob": 1.3530503565561958e-05}, {"id": 688, "seek": 472036, "start": 4727.16, "end": 4732.28, "text": " H feature explicitly. And this actually, recently we discovered that this is very important for H", "tokens": [50364, 5347, 281, 264, 637, 11668, 3202, 7513, 295, 38949, 4398, 3964, 5134, 13, 400, 510, 437, 321, 630, 611, 11, 321, 764, 50704, 50704, 389, 4111, 20803, 13, 400, 341, 767, 11, 3938, 321, 6941, 300, 341, 307, 588, 1021, 337, 389, 50960, 50960, 17630, 5633, 13, 759, 291, 362, 13691, 30359, 5633, 11, 341, 307, 1021, 281, 1066, 309, 13, 1033, 13, 407, 341, 51304, 51304, 307, 264, 2316, 300, 321, 1143, 13, 1033, 13, 1396, 11, 1392, 11, 370, 498, 286, 747, 31782, 11, 293, 498, 286, 2464, 760, 264, 51824], "temperature": 0.0, "avg_logprob": -0.20575336657072368, "compression_ratio": 1.6452991452991452, "no_speech_prob": 1.3530503565561958e-05}, {"id": 689, "seek": 472036, "start": 4732.28, "end": 4739.16, "text": " prediction task. If you have explicit expedition task, this is important to keep it. Okay. So this", "tokens": [50364, 5347, 281, 264, 637, 11668, 3202, 7513, 295, 38949, 4398, 3964, 5134, 13, 400, 510, 437, 321, 630, 611, 11, 321, 764, 50704, 50704, 389, 4111, 20803, 13, 400, 341, 767, 11, 3938, 321, 6941, 300, 341, 307, 588, 1021, 337, 389, 50960, 50960, 17630, 5633, 13, 759, 291, 362, 13691, 30359, 5633, 11, 341, 307, 1021, 281, 1066, 309, 13, 1033, 13, 407, 341, 51304, 51304, 307, 264, 2316, 300, 321, 1143, 13, 1033, 13, 1396, 11, 1392, 11, 370, 498, 286, 747, 31782, 11, 293, 498, 286, 2464, 760, 264, 51824], "temperature": 0.0, "avg_logprob": -0.20575336657072368, "compression_ratio": 1.6452991452991452, "no_speech_prob": 1.3530503565561958e-05}, {"id": 690, "seek": 473916, "start": 4739.16, "end": 4750.84, "text": " is the model that we used. Okay. So if I take transformer, and if I write down the equation", "tokens": [50364, 307, 264, 2316, 300, 321, 1143, 13, 1033, 13, 407, 498, 286, 747, 31782, 11, 293, 498, 286, 2464, 760, 264, 5367, 50948, 50948, 295, 264, 4295, 3037, 295, 31782, 11, 341, 307, 264, 1412, 321, 483, 13, 1033, 13, 407, 291, 5521, 510, 264, 2158, 11, 51236, 51236, 510, 291, 362, 264, 14581, 11, 510, 291, 362, 264, 2141, 11, 293, 510, 291, 362, 264, 2787, 41167, 11, 457, 264, 2787, 41167, 51496, 51496, 307, 1096, 294, 264, 7630, 11, 264, 472, 12, 71, 31451, 7630, 13, 1033, 13, 663, 576, 312, 341, 13, 51660, 51704], "temperature": 0.0, "avg_logprob": -0.15542830842914004, "compression_ratio": 1.8636363636363635, "no_speech_prob": 5.133223021402955e-05}, {"id": 691, "seek": 473916, "start": 4750.84, "end": 4756.599999999999, "text": " of the graph version of transformer, this is the data we get. Okay. So you recognize here the value,", "tokens": [50364, 307, 264, 2316, 300, 321, 1143, 13, 1033, 13, 407, 498, 286, 747, 31782, 11, 293, 498, 286, 2464, 760, 264, 5367, 50948, 50948, 295, 264, 4295, 3037, 295, 31782, 11, 341, 307, 264, 1412, 321, 483, 13, 1033, 13, 407, 291, 5521, 510, 264, 2158, 11, 51236, 51236, 510, 291, 362, 264, 14581, 11, 510, 291, 362, 264, 2141, 11, 293, 510, 291, 362, 264, 2787, 41167, 11, 457, 264, 2787, 41167, 51496, 51496, 307, 1096, 294, 264, 7630, 11, 264, 472, 12, 71, 31451, 7630, 13, 1033, 13, 663, 576, 312, 341, 13, 51660, 51704], "temperature": 0.0, "avg_logprob": -0.15542830842914004, "compression_ratio": 1.8636363636363635, "no_speech_prob": 5.133223021402955e-05}, {"id": 692, "seek": 473916, "start": 4756.599999999999, "end": 4761.8, "text": " here you have the query, here you have the key, and here you have the softmax, but the softmax", "tokens": [50364, 307, 264, 2316, 300, 321, 1143, 13, 1033, 13, 407, 498, 286, 747, 31782, 11, 293, 498, 286, 2464, 760, 264, 5367, 50948, 50948, 295, 264, 4295, 3037, 295, 31782, 11, 341, 307, 264, 1412, 321, 483, 13, 1033, 13, 407, 291, 5521, 510, 264, 2158, 11, 51236, 51236, 510, 291, 362, 264, 14581, 11, 510, 291, 362, 264, 2141, 11, 293, 510, 291, 362, 264, 2787, 41167, 11, 457, 264, 2787, 41167, 51496, 51496, 307, 1096, 294, 264, 7630, 11, 264, 472, 12, 71, 31451, 7630, 13, 1033, 13, 663, 576, 312, 341, 13, 51660, 51704], "temperature": 0.0, "avg_logprob": -0.15542830842914004, "compression_ratio": 1.8636363636363635, "no_speech_prob": 5.133223021402955e-05}, {"id": 693, "seek": 473916, "start": 4761.8, "end": 4765.08, "text": " is done in the neighborhood, the one-hawk neighborhood. Okay. That would be this.", "tokens": [50364, 307, 264, 2316, 300, 321, 1143, 13, 1033, 13, 407, 498, 286, 747, 31782, 11, 293, 498, 286, 2464, 760, 264, 5367, 50948, 50948, 295, 264, 4295, 3037, 295, 31782, 11, 341, 307, 264, 1412, 321, 483, 13, 1033, 13, 407, 291, 5521, 510, 264, 2158, 11, 51236, 51236, 510, 291, 362, 264, 14581, 11, 510, 291, 362, 264, 2141, 11, 293, 510, 291, 362, 264, 2787, 41167, 11, 457, 264, 2787, 41167, 51496, 51496, 307, 1096, 294, 264, 7630, 11, 264, 472, 12, 71, 31451, 7630, 13, 1033, 13, 663, 576, 312, 341, 13, 51660, 51704], "temperature": 0.0, "avg_logprob": -0.15542830842914004, "compression_ratio": 1.8636363636363635, "no_speech_prob": 5.133223021402955e-05}, {"id": 694, "seek": 476508, "start": 4765.08, "end": 4774.44, "text": " And here I'm going to make a connection with a transformer of Vasmohany and his collaborators.", "tokens": [50364, 400, 510, 286, 478, 516, 281, 652, 257, 4984, 365, 257, 31782, 295, 23299, 76, 1445, 1325, 293, 702, 39789, 13, 50832, 50860, 407, 437, 307, 257, 31782, 30, 407, 257, 3832, 31782, 307, 767, 257, 2121, 1389, 295, 4295, 51180, 51180, 16011, 36170, 562, 264, 4295, 307, 4498, 4582, 13, 1033, 13, 407, 341, 307, 257, 4498, 4582, 4295, 13, 51500, 51500, 407, 291, 747, 604, 9984, 11, 741, 11, 293, 341, 9984, 307, 516, 281, 312, 4582, 281, 439, 661, 13891, 294, 264, 4295, 13, 51860, 51860], "temperature": 0.0, "avg_logprob": -0.27413183778196903, "compression_ratio": 1.7641509433962264, "no_speech_prob": 1.4684864254377317e-05}, {"id": 695, "seek": 476508, "start": 4775.0, "end": 4781.4, "text": " So what is a transformer? So a standard transformer is actually a special case of graph", "tokens": [50364, 400, 510, 286, 478, 516, 281, 652, 257, 4984, 365, 257, 31782, 295, 23299, 76, 1445, 1325, 293, 702, 39789, 13, 50832, 50860, 407, 437, 307, 257, 31782, 30, 407, 257, 3832, 31782, 307, 767, 257, 2121, 1389, 295, 4295, 51180, 51180, 16011, 36170, 562, 264, 4295, 307, 4498, 4582, 13, 1033, 13, 407, 341, 307, 257, 4498, 4582, 4295, 13, 51500, 51500, 407, 291, 747, 604, 9984, 11, 741, 11, 293, 341, 9984, 307, 516, 281, 312, 4582, 281, 439, 661, 13891, 294, 264, 4295, 13, 51860, 51860], "temperature": 0.0, "avg_logprob": -0.27413183778196903, "compression_ratio": 1.7641509433962264, "no_speech_prob": 1.4684864254377317e-05}, {"id": 696, "seek": 476508, "start": 4781.4, "end": 4787.8, "text": " conventional nets when the graph is fully connected. Okay. So this is a fully connected graph.", "tokens": [50364, 400, 510, 286, 478, 516, 281, 652, 257, 4984, 365, 257, 31782, 295, 23299, 76, 1445, 1325, 293, 702, 39789, 13, 50832, 50860, 407, 437, 307, 257, 31782, 30, 407, 257, 3832, 31782, 307, 767, 257, 2121, 1389, 295, 4295, 51180, 51180, 16011, 36170, 562, 264, 4295, 307, 4498, 4582, 13, 1033, 13, 407, 341, 307, 257, 4498, 4582, 4295, 13, 51500, 51500, 407, 291, 747, 604, 9984, 11, 741, 11, 293, 341, 9984, 307, 516, 281, 312, 4582, 281, 439, 661, 13891, 294, 264, 4295, 13, 51860, 51860], "temperature": 0.0, "avg_logprob": -0.27413183778196903, "compression_ratio": 1.7641509433962264, "no_speech_prob": 1.4684864254377317e-05}, {"id": 697, "seek": 476508, "start": 4787.8, "end": 4795.0, "text": " So you take any node, i, and this node is going to be connected to all other nodes in the graph.", "tokens": [50364, 400, 510, 286, 478, 516, 281, 652, 257, 4984, 365, 257, 31782, 295, 23299, 76, 1445, 1325, 293, 702, 39789, 13, 50832, 50860, 407, 437, 307, 257, 31782, 30, 407, 257, 3832, 31782, 307, 767, 257, 2121, 1389, 295, 4295, 51180, 51180, 16011, 36170, 562, 264, 4295, 307, 4498, 4582, 13, 1033, 13, 407, 341, 307, 257, 4498, 4582, 4295, 13, 51500, 51500, 407, 291, 747, 604, 9984, 11, 741, 11, 293, 341, 9984, 307, 516, 281, 312, 4582, 281, 439, 661, 13891, 294, 264, 4295, 13, 51860, 51860], "temperature": 0.0, "avg_logprob": -0.27413183778196903, "compression_ratio": 1.7641509433962264, "no_speech_prob": 1.4684864254377317e-05}, {"id": 698, "seek": 479500, "start": 4795.0, "end": 4802.04, "text": " And it's included itself. Okay. So if you look at this equation, the equation I just wrote before,", "tokens": [50364, 400, 309, 311, 5556, 2564, 13, 1033, 13, 407, 498, 291, 574, 412, 341, 5367, 11, 264, 5367, 286, 445, 4114, 949, 11, 50716, 50716, 498, 264, 7630, 307, 341, 565, 406, 264, 472, 12, 71, 31451, 7630, 11, 457, 264, 1379, 4295, 11, 51084, 51120, 550, 291, 486, 483, 264, 3832, 5367, 300, 498, 291, 360, 364, 38095, 293, 31782, 11, 291, 486, 5521, 51484, 51484, 3838, 13, 1033, 13, 492, 1866, 341, 1036, 1243, 13, 407, 445, 485, 7587, 13, 407, 300, 311, 257, 1481, 6034, 13, 51856], "temperature": 0.0, "avg_logprob": -0.19855345850405487, "compression_ratio": 1.6355555555555557, "no_speech_prob": 5.489345494424924e-05}, {"id": 699, "seek": 479500, "start": 4802.04, "end": 4809.4, "text": " if the neighborhood is this time not the one-hawk neighborhood, but the whole graph,", "tokens": [50364, 400, 309, 311, 5556, 2564, 13, 1033, 13, 407, 498, 291, 574, 412, 341, 5367, 11, 264, 5367, 286, 445, 4114, 949, 11, 50716, 50716, 498, 264, 7630, 307, 341, 565, 406, 264, 472, 12, 71, 31451, 7630, 11, 457, 264, 1379, 4295, 11, 51084, 51120, 550, 291, 486, 483, 264, 3832, 5367, 300, 498, 291, 360, 364, 38095, 293, 31782, 11, 291, 486, 5521, 51484, 51484, 3838, 13, 1033, 13, 492, 1866, 341, 1036, 1243, 13, 407, 445, 485, 7587, 13, 407, 300, 311, 257, 1481, 6034, 13, 51856], "temperature": 0.0, "avg_logprob": -0.19855345850405487, "compression_ratio": 1.6355555555555557, "no_speech_prob": 5.489345494424924e-05}, {"id": 700, "seek": 479500, "start": 4810.12, "end": 4817.4, "text": " then you will get the standard equation that if you do an LP and transformer, you will recognize", "tokens": [50364, 400, 309, 311, 5556, 2564, 13, 1033, 13, 407, 498, 291, 574, 412, 341, 5367, 11, 264, 5367, 286, 445, 4114, 949, 11, 50716, 50716, 498, 264, 7630, 307, 341, 565, 406, 264, 472, 12, 71, 31451, 7630, 11, 457, 264, 1379, 4295, 11, 51084, 51120, 550, 291, 486, 483, 264, 3832, 5367, 300, 498, 291, 360, 364, 38095, 293, 31782, 11, 291, 486, 5521, 51484, 51484, 3838, 13, 1033, 13, 492, 1866, 341, 1036, 1243, 13, 407, 445, 485, 7587, 13, 407, 300, 311, 257, 1481, 6034, 13, 51856], "temperature": 0.0, "avg_logprob": -0.19855345850405487, "compression_ratio": 1.6355555555555557, "no_speech_prob": 5.489345494424924e-05}, {"id": 701, "seek": 481740, "start": 4817.4, "end": 4826.12, "text": " directly. Okay. We saw this last week. So just... Exactly. So that's a nice transition. So you see,", "tokens": [50364, 3838, 13, 1033, 13, 492, 1866, 341, 1036, 1243, 13, 407, 445, 485, 7587, 13, 407, 300, 311, 257, 1481, 6034, 13, 407, 291, 536, 11, 50800, 50800, 291, 362, 264, 24903, 13, 407, 341, 307, 4825, 12, 1934, 11, 291, 362, 264, 2787, 41167, 11, 264, 14581, 11, 264, 2141, 11, 293, 264, 51012, 51012, 2158, 11, 293, 550, 291, 362, 264, 3364, 337, 264, 4825, 12, 1934, 13, 407, 264, 787, 551, 300, 286, 360, 510, 51280, 51280, 44003, 11, 445, 1419, 264, 7630, 300, 764, 439, 4984, 13, 400, 562, 286, 360, 300, 11, 51620, 51620], "temperature": 0.0, "avg_logprob": -0.17393990318373878, "compression_ratio": 1.7058823529411764, "no_speech_prob": 4.392110349726863e-05}, {"id": 702, "seek": 481740, "start": 4826.12, "end": 4830.36, "text": " you have the computation. So this is multi-head, you have the softmax, the query, the key, and the", "tokens": [50364, 3838, 13, 1033, 13, 492, 1866, 341, 1036, 1243, 13, 407, 445, 485, 7587, 13, 407, 300, 311, 257, 1481, 6034, 13, 407, 291, 536, 11, 50800, 50800, 291, 362, 264, 24903, 13, 407, 341, 307, 4825, 12, 1934, 11, 291, 362, 264, 2787, 41167, 11, 264, 14581, 11, 264, 2141, 11, 293, 264, 51012, 51012, 2158, 11, 293, 550, 291, 362, 264, 3364, 337, 264, 4825, 12, 1934, 13, 407, 264, 787, 551, 300, 286, 360, 510, 51280, 51280, 44003, 11, 445, 1419, 264, 7630, 300, 764, 439, 4984, 13, 400, 562, 286, 360, 300, 11, 51620, 51620], "temperature": 0.0, "avg_logprob": -0.17393990318373878, "compression_ratio": 1.7058823529411764, "no_speech_prob": 4.392110349726863e-05}, {"id": 703, "seek": 481740, "start": 4830.36, "end": 4835.719999999999, "text": " value, and then you have the weight for the multi-head. So the only thing that I do here", "tokens": [50364, 3838, 13, 1033, 13, 492, 1866, 341, 1036, 1243, 13, 407, 445, 485, 7587, 13, 407, 300, 311, 257, 1481, 6034, 13, 407, 291, 536, 11, 50800, 50800, 291, 362, 264, 24903, 13, 407, 341, 307, 4825, 12, 1934, 11, 291, 362, 264, 2787, 41167, 11, 264, 14581, 11, 264, 2141, 11, 293, 264, 51012, 51012, 2158, 11, 293, 550, 291, 362, 264, 3364, 337, 264, 4825, 12, 1934, 13, 407, 264, 787, 551, 300, 286, 360, 510, 51280, 51280, 44003, 11, 445, 1419, 264, 7630, 300, 764, 439, 4984, 13, 400, 562, 286, 360, 300, 11, 51620, 51620], "temperature": 0.0, "avg_logprob": -0.17393990318373878, "compression_ratio": 1.7058823529411764, "no_speech_prob": 4.392110349726863e-05}, {"id": 704, "seek": 481740, "start": 4835.719999999999, "end": 4842.5199999999995, "text": " mathematically, just having the neighborhood that use all connection. And when I do that,", "tokens": [50364, 3838, 13, 1033, 13, 492, 1866, 341, 1036, 1243, 13, 407, 445, 485, 7587, 13, 407, 300, 311, 257, 1481, 6034, 13, 407, 291, 536, 11, 50800, 50800, 291, 362, 264, 24903, 13, 407, 341, 307, 4825, 12, 1934, 11, 291, 362, 264, 2787, 41167, 11, 264, 14581, 11, 264, 2141, 11, 293, 264, 51012, 51012, 2158, 11, 293, 550, 291, 362, 264, 3364, 337, 264, 4825, 12, 1934, 13, 407, 264, 787, 551, 300, 286, 360, 510, 51280, 51280, 44003, 11, 445, 1419, 264, 7630, 300, 764, 439, 4984, 13, 400, 562, 286, 360, 300, 11, 51620, 51620], "temperature": 0.0, "avg_logprob": -0.17393990318373878, "compression_ratio": 1.7058823529411764, "no_speech_prob": 4.392110349726863e-05}, {"id": 705, "seek": 484252, "start": 4842.52, "end": 4849.56, "text": " so there is the question. So what does it mean to do graph conventional nets for fully connected", "tokens": [50364, 370, 456, 307, 264, 1168, 13, 407, 437, 775, 309, 914, 281, 360, 4295, 16011, 36170, 337, 4498, 4582, 50716, 50716, 24877, 30, 400, 286, 519, 294, 341, 1389, 11, 309, 3643, 1570, 4420, 281, 751, 466, 24877, 11, 570, 562, 291, 362, 51028, 51028, 1184, 1412, 4582, 281, 439, 661, 1412, 11, 550, 291, 500, 380, 362, 604, 544, 2685, 4295, 3877, 13, 51296, 51324, 1436, 257, 4295, 11, 437, 307, 534, 1880, 365, 4295, 307, 264, 637, 685, 507, 3877, 11, 51520, 51520, 558, 30, 1743, 264, 3567, 21095, 11, 411, 264, 2093, 9590, 13, 708, 307, 1880, 307, 406, 51800, 51800], "temperature": 0.0, "avg_logprob": -0.13511161984137768, "compression_ratio": 1.7566539923954372, "no_speech_prob": 1.011024596664356e-05}, {"id": 706, "seek": 484252, "start": 4849.56, "end": 4855.8, "text": " graphs? And I think in this case, it becomes less useful to talk about graphs, because when you have", "tokens": [50364, 370, 456, 307, 264, 1168, 13, 407, 437, 775, 309, 914, 281, 360, 4295, 16011, 36170, 337, 4498, 4582, 50716, 50716, 24877, 30, 400, 286, 519, 294, 341, 1389, 11, 309, 3643, 1570, 4420, 281, 751, 466, 24877, 11, 570, 562, 291, 362, 51028, 51028, 1184, 1412, 4582, 281, 439, 661, 1412, 11, 550, 291, 500, 380, 362, 604, 544, 2685, 4295, 3877, 13, 51296, 51324, 1436, 257, 4295, 11, 437, 307, 534, 1880, 365, 4295, 307, 264, 637, 685, 507, 3877, 11, 51520, 51520, 558, 30, 1743, 264, 3567, 21095, 11, 411, 264, 2093, 9590, 13, 708, 307, 1880, 307, 406, 51800, 51800], "temperature": 0.0, "avg_logprob": -0.13511161984137768, "compression_ratio": 1.7566539923954372, "no_speech_prob": 1.011024596664356e-05}, {"id": 707, "seek": 484252, "start": 4855.8, "end": 4861.160000000001, "text": " each data connected to all other data, then you don't have any more specific graph structure.", "tokens": [50364, 370, 456, 307, 264, 1168, 13, 407, 437, 775, 309, 914, 281, 360, 4295, 16011, 36170, 337, 4498, 4582, 50716, 50716, 24877, 30, 400, 286, 519, 294, 341, 1389, 11, 309, 3643, 1570, 4420, 281, 751, 466, 24877, 11, 570, 562, 291, 362, 51028, 51028, 1184, 1412, 4582, 281, 439, 661, 1412, 11, 550, 291, 500, 380, 362, 604, 544, 2685, 4295, 3877, 13, 51296, 51324, 1436, 257, 4295, 11, 437, 307, 534, 1880, 365, 4295, 307, 264, 637, 685, 507, 3877, 11, 51520, 51520, 558, 30, 1743, 264, 3567, 21095, 11, 411, 264, 2093, 9590, 13, 708, 307, 1880, 307, 406, 51800, 51800], "temperature": 0.0, "avg_logprob": -0.13511161984137768, "compression_ratio": 1.7566539923954372, "no_speech_prob": 1.011024596664356e-05}, {"id": 708, "seek": 484252, "start": 4861.72, "end": 4865.64, "text": " Because a graph, what is really interesting with graph is the sparsity structure,", "tokens": [50364, 370, 456, 307, 264, 1168, 13, 407, 437, 775, 309, 914, 281, 360, 4295, 16011, 36170, 337, 4498, 4582, 50716, 50716, 24877, 30, 400, 286, 519, 294, 341, 1389, 11, 309, 3643, 1570, 4420, 281, 751, 466, 24877, 11, 570, 562, 291, 362, 51028, 51028, 1184, 1412, 4582, 281, 439, 661, 1412, 11, 550, 291, 500, 380, 362, 604, 544, 2685, 4295, 3877, 13, 51296, 51324, 1436, 257, 4295, 11, 437, 307, 534, 1880, 365, 4295, 307, 264, 637, 685, 507, 3877, 11, 51520, 51520, 558, 30, 1743, 264, 3567, 21095, 11, 411, 264, 2093, 9590, 13, 708, 307, 1880, 307, 406, 51800, 51800], "temperature": 0.0, "avg_logprob": -0.13511161984137768, "compression_ratio": 1.7566539923954372, "no_speech_prob": 1.011024596664356e-05}, {"id": 709, "seek": 484252, "start": 4865.64, "end": 4871.240000000001, "text": " right? Like the brain connectivity, like the social networks. What is interesting is not", "tokens": [50364, 370, 456, 307, 264, 1168, 13, 407, 437, 775, 309, 914, 281, 360, 4295, 16011, 36170, 337, 4498, 4582, 50716, 50716, 24877, 30, 400, 286, 519, 294, 341, 1389, 11, 309, 3643, 1570, 4420, 281, 751, 466, 24877, 11, 570, 562, 291, 362, 51028, 51028, 1184, 1412, 4582, 281, 439, 661, 1412, 11, 550, 291, 500, 380, 362, 604, 544, 2685, 4295, 3877, 13, 51296, 51324, 1436, 257, 4295, 11, 437, 307, 534, 1880, 365, 4295, 307, 264, 637, 685, 507, 3877, 11, 51520, 51520, 558, 30, 1743, 264, 3567, 21095, 11, 411, 264, 2093, 9590, 13, 708, 307, 1880, 307, 406, 51800, 51800], "temperature": 0.0, "avg_logprob": -0.13511161984137768, "compression_ratio": 1.7566539923954372, "no_speech_prob": 1.011024596664356e-05}, {"id": 710, "seek": 487124, "start": 4871.24, "end": 4877.08, "text": " everything to be connected to each other. It's only to have a sparse connection between the nodes.", "tokens": [50364, 1203, 281, 312, 4582, 281, 1184, 661, 13, 467, 311, 787, 281, 362, 257, 637, 11668, 4984, 1296, 264, 13891, 13, 50656, 50656, 407, 286, 519, 294, 341, 1389, 11, 309, 576, 312, 1101, 281, 751, 466, 6352, 813, 281, 751, 466, 24877, 13, 50864, 50904, 400, 321, 458, 300, 13, 492, 458, 300, 31782, 366, 992, 18161, 9590, 13, 407, 294, 512, 2020, 11, 2602, 295, 51244, 51244, 1237, 412, 257, 4498, 4582, 24877, 365, 4111, 11, 264, 551, 300, 321, 820, 574, 412, 307, 544, 257, 992, 295, 51552, 51552], "temperature": 0.0, "avg_logprob": -0.08772448275951629, "compression_ratio": 1.6812227074235808, "no_speech_prob": 7.70155202189926e-06}, {"id": 711, "seek": 487124, "start": 4877.08, "end": 4881.24, "text": " So I think in this case, it would be better to talk about sets than to talk about graphs.", "tokens": [50364, 1203, 281, 312, 4582, 281, 1184, 661, 13, 467, 311, 787, 281, 362, 257, 637, 11668, 4984, 1296, 264, 13891, 13, 50656, 50656, 407, 286, 519, 294, 341, 1389, 11, 309, 576, 312, 1101, 281, 751, 466, 6352, 813, 281, 751, 466, 24877, 13, 50864, 50904, 400, 321, 458, 300, 13, 492, 458, 300, 31782, 366, 992, 18161, 9590, 13, 407, 294, 512, 2020, 11, 2602, 295, 51244, 51244, 1237, 412, 257, 4498, 4582, 24877, 365, 4111, 11, 264, 551, 300, 321, 820, 574, 412, 307, 544, 257, 992, 295, 51552, 51552], "temperature": 0.0, "avg_logprob": -0.08772448275951629, "compression_ratio": 1.6812227074235808, "no_speech_prob": 7.70155202189926e-06}, {"id": 712, "seek": 487124, "start": 4882.04, "end": 4888.84, "text": " And we know that. We know that transformer are set neural networks. So in some sense, instead of", "tokens": [50364, 1203, 281, 312, 4582, 281, 1184, 661, 13, 467, 311, 787, 281, 362, 257, 637, 11668, 4984, 1296, 264, 13891, 13, 50656, 50656, 407, 286, 519, 294, 341, 1389, 11, 309, 576, 312, 1101, 281, 751, 466, 6352, 813, 281, 751, 466, 24877, 13, 50864, 50904, 400, 321, 458, 300, 13, 492, 458, 300, 31782, 366, 992, 18161, 9590, 13, 407, 294, 512, 2020, 11, 2602, 295, 51244, 51244, 1237, 412, 257, 4498, 4582, 24877, 365, 4111, 11, 264, 551, 300, 321, 820, 574, 412, 307, 544, 257, 992, 295, 51552, 51552], "temperature": 0.0, "avg_logprob": -0.08772448275951629, "compression_ratio": 1.6812227074235808, "no_speech_prob": 7.70155202189926e-06}, {"id": 713, "seek": 487124, "start": 4888.84, "end": 4895.0, "text": " looking at a fully connected graphs with feature, the thing that we should look at is more a set of", "tokens": [50364, 1203, 281, 312, 4582, 281, 1184, 661, 13, 467, 311, 787, 281, 362, 257, 637, 11668, 4984, 1296, 264, 13891, 13, 50656, 50656, 407, 286, 519, 294, 341, 1389, 11, 309, 576, 312, 1101, 281, 751, 466, 6352, 813, 281, 751, 466, 24877, 13, 50864, 50904, 400, 321, 458, 300, 13, 492, 458, 300, 31782, 366, 992, 18161, 9590, 13, 407, 294, 512, 2020, 11, 2602, 295, 51244, 51244, 1237, 412, 257, 4498, 4582, 24877, 365, 4111, 11, 264, 551, 300, 321, 820, 574, 412, 307, 544, 257, 992, 295, 51552, 51552], "temperature": 0.0, "avg_logprob": -0.08772448275951629, "compression_ratio": 1.6812227074235808, "no_speech_prob": 7.70155202189926e-06}, {"id": 714, "seek": 489500, "start": 4895.0, "end": 4901.64, "text": " features. And transformers are really good to process sets of feature vectors.", "tokens": [50364, 4122, 13, 400, 4088, 433, 366, 534, 665, 281, 1399, 6352, 295, 4111, 18875, 13, 50696, 50812, 2264, 13, 407, 456, 307, 257, 2715, 300, 286, 829, 510, 13, 407, 264, 2715, 307, 2361, 322, 11, 370, 341, 307, 264, 460, 2218, 38, 34, 45, 11, 51320, 51320, 264, 2316, 286, 10348, 13, 400, 341, 307, 365, 460, 19440, 13, 407, 341, 307, 264, 2452, 4295, 6405, 13, 407, 309, 390, 4743, 51596, 51596], "temperature": 0.0, "avg_logprob": -0.24698224820588766, "compression_ratio": 1.5202312138728324, "no_speech_prob": 2.2060759874875657e-05}, {"id": 715, "seek": 489500, "start": 4903.96, "end": 4914.12, "text": " OK. So there is a lab that I put here. So the lab is based on, so this is the GATGCN,", "tokens": [50364, 4122, 13, 400, 4088, 433, 366, 534, 665, 281, 1399, 6352, 295, 4111, 18875, 13, 50696, 50812, 2264, 13, 407, 456, 307, 257, 2715, 300, 286, 829, 510, 13, 407, 264, 2715, 307, 2361, 322, 11, 370, 341, 307, 264, 460, 2218, 38, 34, 45, 11, 51320, 51320, 264, 2316, 286, 10348, 13, 400, 341, 307, 365, 460, 19440, 13, 407, 341, 307, 264, 2452, 4295, 6405, 13, 407, 309, 390, 4743, 51596, 51596], "temperature": 0.0, "avg_logprob": -0.24698224820588766, "compression_ratio": 1.5202312138728324, "no_speech_prob": 2.2060759874875657e-05}, {"id": 716, "seek": 489500, "start": 4914.12, "end": 4919.64, "text": " the model I proposed. And this is with GGL. So this is the deep graph library. So it was developed", "tokens": [50364, 4122, 13, 400, 4088, 433, 366, 534, 665, 281, 1399, 6352, 295, 4111, 18875, 13, 50696, 50812, 2264, 13, 407, 456, 307, 257, 2715, 300, 286, 829, 510, 13, 407, 264, 2715, 307, 2361, 322, 11, 370, 341, 307, 264, 460, 2218, 38, 34, 45, 11, 51320, 51320, 264, 2316, 286, 10348, 13, 400, 341, 307, 365, 460, 19440, 13, 407, 341, 307, 264, 2452, 4295, 6405, 13, 407, 309, 390, 4743, 51596, 51596], "temperature": 0.0, "avg_logprob": -0.24698224820588766, "compression_ratio": 1.5202312138728324, "no_speech_prob": 2.2060759874875657e-05}, {"id": 717, "seek": 491964, "start": 4919.64, "end": 4926.12, "text": " by NYU Shanghai by Professor Zheng Zheng. And here, this is the link to the lab. So if you", "tokens": [50364, 538, 42682, 26135, 538, 8419, 31408, 31408, 13, 400, 510, 11, 341, 307, 264, 2113, 281, 264, 2715, 13, 407, 498, 291, 50688, 50688, 2052, 322, 341, 2113, 11, 291, 486, 352, 3838, 281, 264, 2715, 13, 400, 341, 307, 1228, 3329, 15584, 13, 407, 291, 51068, 51068, 486, 445, 643, 257, 36732, 2696, 281, 2105, 281, 341, 13, 400, 291, 486, 312, 1075, 281, 1190, 309, 322, 264, 3329, 8061, 13, 51312, 51372, 400, 437, 286, 829, 510, 11, 286, 829, 534, 264, 881, 1880, 6828, 300, 291, 643, 281, 1499, 51796, 51796], "temperature": 0.0, "avg_logprob": -0.13720446825027466, "compression_ratio": 1.6462882096069869, "no_speech_prob": 1.3119519280735403e-05}, {"id": 718, "seek": 491964, "start": 4926.12, "end": 4933.72, "text": " click on this link, you will go directly to the lab. And this is using Google collapse. So you", "tokens": [50364, 538, 42682, 26135, 538, 8419, 31408, 31408, 13, 400, 510, 11, 341, 307, 264, 2113, 281, 264, 2715, 13, 407, 498, 291, 50688, 50688, 2052, 322, 341, 2113, 11, 291, 486, 352, 3838, 281, 264, 2715, 13, 400, 341, 307, 1228, 3329, 15584, 13, 407, 291, 51068, 51068, 486, 445, 643, 257, 36732, 2696, 281, 2105, 281, 341, 13, 400, 291, 486, 312, 1075, 281, 1190, 309, 322, 264, 3329, 8061, 13, 51312, 51372, 400, 437, 286, 829, 510, 11, 286, 829, 534, 264, 881, 1880, 6828, 300, 291, 643, 281, 1499, 51796, 51796], "temperature": 0.0, "avg_logprob": -0.13720446825027466, "compression_ratio": 1.6462882096069869, "no_speech_prob": 1.3119519280735403e-05}, {"id": 719, "seek": 491964, "start": 4933.72, "end": 4938.6, "text": " will just need a Gmail account to access to this. And you will be able to run it on the Google Cloud.", "tokens": [50364, 538, 42682, 26135, 538, 8419, 31408, 31408, 13, 400, 510, 11, 341, 307, 264, 2113, 281, 264, 2715, 13, 407, 498, 291, 50688, 50688, 2052, 322, 341, 2113, 11, 291, 486, 352, 3838, 281, 264, 2715, 13, 400, 341, 307, 1228, 3329, 15584, 13, 407, 291, 51068, 51068, 486, 445, 643, 257, 36732, 2696, 281, 2105, 281, 341, 13, 400, 291, 486, 312, 1075, 281, 1190, 309, 322, 264, 3329, 8061, 13, 51312, 51372, 400, 437, 286, 829, 510, 11, 286, 829, 534, 264, 881, 1880, 6828, 300, 291, 643, 281, 1499, 51796, 51796], "temperature": 0.0, "avg_logprob": -0.13720446825027466, "compression_ratio": 1.6462882096069869, "no_speech_prob": 1.3119519280735403e-05}, {"id": 720, "seek": 491964, "start": 4939.8, "end": 4948.280000000001, "text": " And what I put here, I put really the most interesting functions that you need to develop", "tokens": [50364, 538, 42682, 26135, 538, 8419, 31408, 31408, 13, 400, 510, 11, 341, 307, 264, 2113, 281, 264, 2715, 13, 407, 498, 291, 50688, 50688, 2052, 322, 341, 2113, 11, 291, 486, 352, 3838, 281, 264, 2715, 13, 400, 341, 307, 1228, 3329, 15584, 13, 407, 291, 51068, 51068, 486, 445, 643, 257, 36732, 2696, 281, 2105, 281, 341, 13, 400, 291, 486, 312, 1075, 281, 1190, 309, 322, 264, 3329, 8061, 13, 51312, 51372, 400, 437, 286, 829, 510, 11, 286, 829, 534, 264, 881, 1880, 6828, 300, 291, 643, 281, 1499, 51796, 51796], "temperature": 0.0, "avg_logprob": -0.13720446825027466, "compression_ratio": 1.6462882096069869, "no_speech_prob": 1.3119519280735403e-05}, {"id": 721, "seek": 494828, "start": 4948.28, "end": 4955.0, "text": " a Gcm. So maybe tomorrow. Yeah, tomorrow we're going to be going over everything.", "tokens": [50364, 257, 460, 15210, 13, 407, 1310, 4153, 13, 865, 11, 4153, 321, 434, 516, 281, 312, 516, 670, 1203, 13, 50700, 50700, 2264, 11, 2176, 13, 509, 486, 360, 300, 13, 2264, 13, 407, 293, 510, 11, 286, 2729, 291, 458, 11, 286, 829, 512, 3053, 322, 264, 3089, 13, 51036, 51100, 400, 611, 11, 1338, 11, 611, 1223, 413, 19440, 11, 577, 413, 19440, 1985, 13, 407, 1391, 291, 603, 360, 300, 4153, 13, 51376, 51376, 1079, 11, 2086, 11, 2086, 13, 5490, 13, 2264, 13, 407, 718, 385, 586, 11, 286, 478, 516, 281, 264, 917, 13, 407, 718, 385, 751, 257, 707, 857, 466, 51680, 51716], "temperature": 0.0, "avg_logprob": -0.25304569210018124, "compression_ratio": 1.6322869955156951, "no_speech_prob": 7.245284359669313e-05}, {"id": 722, "seek": 494828, "start": 4955.0, "end": 4961.719999999999, "text": " OK, perfect. You will do that. OK. So and here, I gave you know, I put some comments on the code.", "tokens": [50364, 257, 460, 15210, 13, 407, 1310, 4153, 13, 865, 11, 4153, 321, 434, 516, 281, 312, 516, 670, 1203, 13, 50700, 50700, 2264, 11, 2176, 13, 509, 486, 360, 300, 13, 2264, 13, 407, 293, 510, 11, 286, 2729, 291, 458, 11, 286, 829, 512, 3053, 322, 264, 3089, 13, 51036, 51100, 400, 611, 11, 1338, 11, 611, 1223, 413, 19440, 11, 577, 413, 19440, 1985, 13, 407, 1391, 291, 603, 360, 300, 4153, 13, 51376, 51376, 1079, 11, 2086, 11, 2086, 13, 5490, 13, 2264, 13, 407, 718, 385, 586, 11, 286, 478, 516, 281, 264, 917, 13, 407, 718, 385, 751, 257, 707, 857, 466, 51680, 51716], "temperature": 0.0, "avg_logprob": -0.25304569210018124, "compression_ratio": 1.6322869955156951, "no_speech_prob": 7.245284359669313e-05}, {"id": 723, "seek": 494828, "start": 4963.0, "end": 4968.5199999999995, "text": " And also, yeah, also understand DGL, how DGL works. So probably you'll do that tomorrow.", "tokens": [50364, 257, 460, 15210, 13, 407, 1310, 4153, 13, 865, 11, 4153, 321, 434, 516, 281, 312, 516, 670, 1203, 13, 50700, 50700, 2264, 11, 2176, 13, 509, 486, 360, 300, 13, 2264, 13, 407, 293, 510, 11, 286, 2729, 291, 458, 11, 286, 829, 512, 3053, 322, 264, 3089, 13, 51036, 51100, 400, 611, 11, 1338, 11, 611, 1223, 413, 19440, 11, 577, 413, 19440, 1985, 13, 407, 1391, 291, 603, 360, 300, 4153, 13, 51376, 51376, 1079, 11, 2086, 11, 2086, 13, 5490, 13, 2264, 13, 407, 718, 385, 586, 11, 286, 478, 516, 281, 264, 917, 13, 407, 718, 385, 751, 257, 707, 857, 466, 51680, 51716], "temperature": 0.0, "avg_logprob": -0.25304569210018124, "compression_ratio": 1.6322869955156951, "no_speech_prob": 7.245284359669313e-05}, {"id": 724, "seek": 494828, "start": 4968.5199999999995, "end": 4974.599999999999, "text": " Yes, yes, yes. Nice. OK. So let me now, I'm going to the end. So let me talk a little bit about", "tokens": [50364, 257, 460, 15210, 13, 407, 1310, 4153, 13, 865, 11, 4153, 321, 434, 516, 281, 312, 516, 670, 1203, 13, 50700, 50700, 2264, 11, 2176, 13, 509, 486, 360, 300, 13, 2264, 13, 407, 293, 510, 11, 286, 2729, 291, 458, 11, 286, 829, 512, 3053, 322, 264, 3089, 13, 51036, 51100, 400, 611, 11, 1338, 11, 611, 1223, 413, 19440, 11, 577, 413, 19440, 1985, 13, 407, 1391, 291, 603, 360, 300, 4153, 13, 51376, 51376, 1079, 11, 2086, 11, 2086, 13, 5490, 13, 2264, 13, 407, 718, 385, 586, 11, 286, 478, 516, 281, 264, 917, 13, 407, 718, 385, 751, 257, 707, 857, 466, 51680, 51716], "temperature": 0.0, "avg_logprob": -0.25304569210018124, "compression_ratio": 1.6322869955156951, "no_speech_prob": 7.245284359669313e-05}, {"id": 725, "seek": 497460, "start": 4974.6, "end": 4982.6, "text": " benchmarking graph neural networks. So recently, we have this paper of benchmarking graph neural", "tokens": [50364, 18927, 278, 4295, 18161, 9590, 13, 407, 3938, 11, 321, 362, 341, 3035, 295, 18927, 278, 4295, 18161, 50764, 50764, 9590, 13, 407, 983, 321, 630, 341, 18927, 30, 1436, 498, 291, 574, 412, 264, 881, 6572, 460, 15210, 10577, 11, 51128, 51192, 881, 295, 264, 589, 767, 764, 1359, 1412, 992, 411, 383, 3252, 420, 42408, 1412, 992, 293, 787, 472, 5633, 11, 51456, 51456, 411, 21538, 13, 400, 562, 286, 1409, 884, 512, 12050, 322, 300, 11, 286, 445, 5334, 300, 51740, 51740], "temperature": 0.0, "avg_logprob": -0.2164128621419271, "compression_ratio": 1.6533333333333333, "no_speech_prob": 0.00010103813110617921}, {"id": 726, "seek": 497460, "start": 4982.6, "end": 4989.88, "text": " networks. So why we did this benchmark? Because if you look at the most published Gcm papers,", "tokens": [50364, 18927, 278, 4295, 18161, 9590, 13, 407, 3938, 11, 321, 362, 341, 3035, 295, 18927, 278, 4295, 18161, 50764, 50764, 9590, 13, 407, 983, 321, 630, 341, 18927, 30, 1436, 498, 291, 574, 412, 264, 881, 6572, 460, 15210, 10577, 11, 51128, 51192, 881, 295, 264, 589, 767, 764, 1359, 1412, 992, 411, 383, 3252, 420, 42408, 1412, 992, 293, 787, 472, 5633, 11, 51456, 51456, 411, 21538, 13, 400, 562, 286, 1409, 884, 512, 12050, 322, 300, 11, 286, 445, 5334, 300, 51740, 51740], "temperature": 0.0, "avg_logprob": -0.2164128621419271, "compression_ratio": 1.6533333333333333, "no_speech_prob": 0.00010103813110617921}, {"id": 727, "seek": 497460, "start": 4991.160000000001, "end": 4996.4400000000005, "text": " most of the work actually use small data set like Cora or TU data set and only one task,", "tokens": [50364, 18927, 278, 4295, 18161, 9590, 13, 407, 3938, 11, 321, 362, 341, 3035, 295, 18927, 278, 4295, 18161, 50764, 50764, 9590, 13, 407, 983, 321, 630, 341, 18927, 30, 1436, 498, 291, 574, 412, 264, 881, 6572, 460, 15210, 10577, 11, 51128, 51192, 881, 295, 264, 589, 767, 764, 1359, 1412, 992, 411, 383, 3252, 420, 42408, 1412, 992, 293, 787, 472, 5633, 11, 51456, 51456, 411, 21538, 13, 400, 562, 286, 1409, 884, 512, 12050, 322, 300, 11, 286, 445, 5334, 300, 51740, 51740], "temperature": 0.0, "avg_logprob": -0.2164128621419271, "compression_ratio": 1.6533333333333333, "no_speech_prob": 0.00010103813110617921}, {"id": 728, "seek": 497460, "start": 4996.4400000000005, "end": 5002.120000000001, "text": " like classification. And when I started doing some experiments on that, I just realized that", "tokens": [50364, 18927, 278, 4295, 18161, 9590, 13, 407, 3938, 11, 321, 362, 341, 3035, 295, 18927, 278, 4295, 18161, 50764, 50764, 9590, 13, 407, 983, 321, 630, 341, 18927, 30, 1436, 498, 291, 574, 412, 264, 881, 6572, 460, 15210, 10577, 11, 51128, 51192, 881, 295, 264, 589, 767, 764, 1359, 1412, 992, 411, 383, 3252, 420, 42408, 1412, 992, 293, 787, 472, 5633, 11, 51456, 51456, 411, 21538, 13, 400, 562, 286, 1409, 884, 512, 12050, 322, 300, 11, 286, 445, 5334, 300, 51740, 51740], "temperature": 0.0, "avg_logprob": -0.2164128621419271, "compression_ratio": 1.6533333333333333, "no_speech_prob": 0.00010103813110617921}, {"id": 729, "seek": 500212, "start": 5002.12, "end": 5006.92, "text": " if you use Gcm or if you don't use any Gcm, you will get statistically the same performance", "tokens": [50364, 498, 291, 764, 460, 15210, 420, 498, 291, 500, 380, 764, 604, 460, 15210, 11, 291, 486, 483, 36478, 264, 912, 3389, 50604, 50604, 570, 264, 3832, 25163, 307, 588, 1090, 337, 264, 1359, 1412, 6352, 13, 407, 264, 551, 307, 11, 50860, 50960, 321, 2644, 5876, 665, 460, 15210, 13, 492, 643, 746, 1646, 13, 400, 611, 11, 3938, 11, 370, 456, 575, 668, 51368, 51404, 257, 777, 20864, 3250, 337, 460, 15210, 13, 400, 264, 1168, 307, 11, 577, 665, 436, 366, 294, 3124, 13, 51728, 51784], "temperature": 0.0, "avg_logprob": -0.15470176738697095, "compression_ratio": 1.617117117117117, "no_speech_prob": 1.978574800887145e-05}, {"id": 730, "seek": 500212, "start": 5006.92, "end": 5012.04, "text": " because the standard deviation is very high for the small data sets. So the thing is,", "tokens": [50364, 498, 291, 764, 460, 15210, 420, 498, 291, 500, 380, 764, 604, 460, 15210, 11, 291, 486, 483, 36478, 264, 912, 3389, 50604, 50604, 570, 264, 3832, 25163, 307, 588, 1090, 337, 264, 1359, 1412, 6352, 13, 407, 264, 551, 307, 11, 50860, 50960, 321, 2644, 5876, 665, 460, 15210, 13, 492, 643, 746, 1646, 13, 400, 611, 11, 3938, 11, 370, 456, 575, 668, 51368, 51404, 257, 777, 20864, 3250, 337, 460, 15210, 13, 400, 264, 1168, 307, 11, 577, 665, 436, 366, 294, 3124, 13, 51728, 51784], "temperature": 0.0, "avg_logprob": -0.15470176738697095, "compression_ratio": 1.617117117117117, "no_speech_prob": 1.978574800887145e-05}, {"id": 731, "seek": 500212, "start": 5014.04, "end": 5022.2, "text": " we cannot identify good Gcm. We need something else. And also, recently, so there has been", "tokens": [50364, 498, 291, 764, 460, 15210, 420, 498, 291, 500, 380, 764, 604, 460, 15210, 11, 291, 486, 483, 36478, 264, 912, 3389, 50604, 50604, 570, 264, 3832, 25163, 307, 588, 1090, 337, 264, 1359, 1412, 6352, 13, 407, 264, 551, 307, 11, 50860, 50960, 321, 2644, 5876, 665, 460, 15210, 13, 492, 643, 746, 1646, 13, 400, 611, 11, 3938, 11, 370, 456, 575, 668, 51368, 51404, 257, 777, 20864, 3250, 337, 460, 15210, 13, 400, 264, 1168, 307, 11, 577, 665, 436, 366, 294, 3124, 13, 51728, 51784], "temperature": 0.0, "avg_logprob": -0.15470176738697095, "compression_ratio": 1.617117117117117, "no_speech_prob": 1.978574800887145e-05}, {"id": 732, "seek": 500212, "start": 5022.92, "end": 5029.4, "text": " a new theoretical development for Gcm. And the question is, how good they are in practice.", "tokens": [50364, 498, 291, 764, 460, 15210, 420, 498, 291, 500, 380, 764, 604, 460, 15210, 11, 291, 486, 483, 36478, 264, 912, 3389, 50604, 50604, 570, 264, 3832, 25163, 307, 588, 1090, 337, 264, 1359, 1412, 6352, 13, 407, 264, 551, 307, 11, 50860, 50960, 321, 2644, 5876, 665, 460, 15210, 13, 492, 643, 746, 1646, 13, 400, 611, 11, 3938, 11, 370, 456, 575, 668, 51368, 51404, 257, 777, 20864, 3250, 337, 460, 15210, 13, 400, 264, 1168, 307, 11, 577, 665, 436, 366, 294, 3124, 13, 51728, 51784], "temperature": 0.0, "avg_logprob": -0.15470176738697095, "compression_ratio": 1.617117117117117, "no_speech_prob": 1.978574800887145e-05}, {"id": 733, "seek": 502940, "start": 5029.4, "end": 5036.04, "text": " It's important to have some good mathematical justification of Gcm. But we need to be able to", "tokens": [50364, 467, 311, 1021, 281, 362, 512, 665, 18894, 31591, 295, 460, 15210, 13, 583, 321, 643, 281, 312, 1075, 281, 50696, 50696, 7081, 300, 341, 307, 746, 300, 307, 4420, 13, 400, 286, 519, 611, 18927, 575, 668, 588, 7115, 50976, 50976, 281, 652, 4205, 294, 867, 7909, 11, 411, 11, 295, 1164, 11, 2452, 2539, 365, 29903, 31890, 538, 39587, 12, 37, 17067, 8349, 13, 583, 51396, 51396, 264, 551, 307, 11, 437, 286, 11441, 307, 767, 561, 366, 1596, 33677, 281, 976, 5397, 281, 43751, 13, 51632, 51712], "temperature": 0.0, "avg_logprob": -0.23522648604019827, "compression_ratio": 1.536, "no_speech_prob": 4.3293774069752544e-05}, {"id": 734, "seek": 502940, "start": 5036.04, "end": 5041.639999999999, "text": " prove that this is something that is useful. And I think also benchmark has been very essential", "tokens": [50364, 467, 311, 1021, 281, 362, 512, 665, 18894, 31591, 295, 460, 15210, 13, 583, 321, 643, 281, 312, 1075, 281, 50696, 50696, 7081, 300, 341, 307, 746, 300, 307, 4420, 13, 400, 286, 519, 611, 18927, 575, 668, 588, 7115, 50976, 50976, 281, 652, 4205, 294, 867, 7909, 11, 411, 11, 295, 1164, 11, 2452, 2539, 365, 29903, 31890, 538, 39587, 12, 37, 17067, 8349, 13, 583, 51396, 51396, 264, 551, 307, 11, 437, 286, 11441, 307, 767, 561, 366, 1596, 33677, 281, 976, 5397, 281, 43751, 13, 51632, 51712], "temperature": 0.0, "avg_logprob": -0.23522648604019827, "compression_ratio": 1.536, "no_speech_prob": 4.3293774069752544e-05}, {"id": 735, "seek": 502940, "start": 5041.639999999999, "end": 5050.04, "text": " to make progress in many fields, like, of course, deep learning with ImageNet by Fei-Fei Li. But", "tokens": [50364, 467, 311, 1021, 281, 362, 512, 665, 18894, 31591, 295, 460, 15210, 13, 583, 321, 643, 281, 312, 1075, 281, 50696, 50696, 7081, 300, 341, 307, 746, 300, 307, 4420, 13, 400, 286, 519, 611, 18927, 575, 668, 588, 7115, 50976, 50976, 281, 652, 4205, 294, 867, 7909, 11, 411, 11, 295, 1164, 11, 2452, 2539, 365, 29903, 31890, 538, 39587, 12, 37, 17067, 8349, 13, 583, 51396, 51396, 264, 551, 307, 11, 437, 286, 11441, 307, 767, 561, 366, 1596, 33677, 281, 976, 5397, 281, 43751, 13, 51632, 51712], "temperature": 0.0, "avg_logprob": -0.23522648604019827, "compression_ratio": 1.536, "no_speech_prob": 4.3293774069752544e-05}, {"id": 736, "seek": 502940, "start": 5050.04, "end": 5054.759999999999, "text": " the thing is, what I observe is actually people are quite reluctant to give credit to benchmarks.", "tokens": [50364, 467, 311, 1021, 281, 362, 512, 665, 18894, 31591, 295, 460, 15210, 13, 583, 321, 643, 281, 312, 1075, 281, 50696, 50696, 7081, 300, 341, 307, 746, 300, 307, 4420, 13, 400, 286, 519, 611, 18927, 575, 668, 588, 7115, 50976, 50976, 281, 652, 4205, 294, 867, 7909, 11, 411, 11, 295, 1164, 11, 2452, 2539, 365, 29903, 31890, 538, 39587, 12, 37, 17067, 8349, 13, 583, 51396, 51396, 264, 551, 307, 11, 437, 286, 11441, 307, 767, 561, 366, 1596, 33677, 281, 976, 5397, 281, 43751, 13, 51632, 51712], "temperature": 0.0, "avg_logprob": -0.23522648604019827, "compression_ratio": 1.536, "no_speech_prob": 4.3293774069752544e-05}, {"id": 737, "seek": 505476, "start": 5054.76, "end": 5061.72, "text": " Anyway, so we introduced this open benchmark infrastructure. So it's on GitHub.", "tokens": [50364, 5684, 11, 370, 321, 7268, 341, 1269, 18927, 6896, 13, 407, 309, 311, 322, 23331, 13, 50712, 50752, 467, 311, 2361, 322, 9953, 51, 284, 339, 293, 413, 19440, 13, 400, 321, 7268, 2309, 777, 6399, 4373, 1412, 6352, 337, 264, 1451, 51048, 51048, 8088, 4295, 2740, 11, 411, 4295, 21538, 11, 4295, 24590, 11, 9984, 51284, 51284, 21538, 11, 293, 4691, 21538, 11, 597, 286, 519, 498, 291, 2060, 613, 1451, 8088, 51480, 51480, 4295, 2740, 11, 291, 1217, 458, 1596, 257, 688, 466, 264, 3389, 295, 428, 460, 15210, 13, 51768, 51768], "temperature": 0.0, "avg_logprob": -0.14409426848093668, "compression_ratio": 1.7044534412955465, "no_speech_prob": 6.89320731908083e-05}, {"id": 738, "seek": 505476, "start": 5062.52, "end": 5068.4400000000005, "text": " It's based on PyTorch and DGL. And we introduced six new medium scale data sets for the four", "tokens": [50364, 5684, 11, 370, 321, 7268, 341, 1269, 18927, 6896, 13, 407, 309, 311, 322, 23331, 13, 50712, 50752, 467, 311, 2361, 322, 9953, 51, 284, 339, 293, 413, 19440, 13, 400, 321, 7268, 2309, 777, 6399, 4373, 1412, 6352, 337, 264, 1451, 51048, 51048, 8088, 4295, 2740, 11, 411, 4295, 21538, 11, 4295, 24590, 11, 9984, 51284, 51284, 21538, 11, 293, 4691, 21538, 11, 597, 286, 519, 498, 291, 2060, 613, 1451, 8088, 51480, 51480, 4295, 2740, 11, 291, 1217, 458, 1596, 257, 688, 466, 264, 3389, 295, 428, 460, 15210, 13, 51768, 51768], "temperature": 0.0, "avg_logprob": -0.14409426848093668, "compression_ratio": 1.7044534412955465, "no_speech_prob": 6.89320731908083e-05}, {"id": 739, "seek": 505476, "start": 5068.4400000000005, "end": 5073.16, "text": " fundamental graph problems, like graph classification, graph regression, node", "tokens": [50364, 5684, 11, 370, 321, 7268, 341, 1269, 18927, 6896, 13, 407, 309, 311, 322, 23331, 13, 50712, 50752, 467, 311, 2361, 322, 9953, 51, 284, 339, 293, 413, 19440, 13, 400, 321, 7268, 2309, 777, 6399, 4373, 1412, 6352, 337, 264, 1451, 51048, 51048, 8088, 4295, 2740, 11, 411, 4295, 21538, 11, 4295, 24590, 11, 9984, 51284, 51284, 21538, 11, 293, 4691, 21538, 11, 597, 286, 519, 498, 291, 2060, 613, 1451, 8088, 51480, 51480, 4295, 2740, 11, 291, 1217, 458, 1596, 257, 688, 466, 264, 3389, 295, 428, 460, 15210, 13, 51768, 51768], "temperature": 0.0, "avg_logprob": -0.14409426848093668, "compression_ratio": 1.7044534412955465, "no_speech_prob": 6.89320731908083e-05}, {"id": 740, "seek": 505476, "start": 5073.16, "end": 5077.08, "text": " classification, and edge classification, which I think if you cover these four fundamental", "tokens": [50364, 5684, 11, 370, 321, 7268, 341, 1269, 18927, 6896, 13, 407, 309, 311, 322, 23331, 13, 50712, 50752, 467, 311, 2361, 322, 9953, 51, 284, 339, 293, 413, 19440, 13, 400, 321, 7268, 2309, 777, 6399, 4373, 1412, 6352, 337, 264, 1451, 51048, 51048, 8088, 4295, 2740, 11, 411, 4295, 21538, 11, 4295, 24590, 11, 9984, 51284, 51284, 21538, 11, 293, 4691, 21538, 11, 597, 286, 519, 498, 291, 2060, 613, 1451, 8088, 51480, 51480, 4295, 2740, 11, 291, 1217, 458, 1596, 257, 688, 466, 264, 3389, 295, 428, 460, 15210, 13, 51768, 51768], "temperature": 0.0, "avg_logprob": -0.14409426848093668, "compression_ratio": 1.7044534412955465, "no_speech_prob": 6.89320731908083e-05}, {"id": 741, "seek": 505476, "start": 5077.08, "end": 5082.84, "text": " graph problems, you already know quite a lot about the performance of your Gcm.", "tokens": [50364, 5684, 11, 370, 321, 7268, 341, 1269, 18927, 6896, 13, 407, 309, 311, 322, 23331, 13, 50712, 50752, 467, 311, 2361, 322, 9953, 51, 284, 339, 293, 413, 19440, 13, 400, 321, 7268, 2309, 777, 6399, 4373, 1412, 6352, 337, 264, 1451, 51048, 51048, 8088, 4295, 2740, 11, 411, 4295, 21538, 11, 4295, 24590, 11, 9984, 51284, 51284, 21538, 11, 293, 4691, 21538, 11, 597, 286, 519, 498, 291, 2060, 613, 1451, 8088, 51480, 51480, 4295, 2740, 11, 291, 1217, 458, 1596, 257, 688, 466, 264, 3389, 295, 428, 460, 15210, 13, 51768, 51768], "temperature": 0.0, "avg_logprob": -0.14409426848093668, "compression_ratio": 1.7044534412955465, "no_speech_prob": 6.89320731908083e-05}, {"id": 742, "seek": 508284, "start": 5082.84, "end": 5086.76, "text": " Can you spend a few words more about these four fundamental graph problems? I think we", "tokens": [50364, 1664, 291, 3496, 257, 1326, 2283, 544, 466, 613, 1451, 8088, 4295, 2740, 30, 286, 519, 321, 50560, 50560, 2378, 380, 2835, 552, 370, 1400, 11, 286, 519, 13, 865, 11, 2293, 13, 583, 437, 286, 2835, 307, 1936, 50956, 50956, 264, 700, 644, 295, 604, 45216, 304, 36170, 307, 577, 360, 291, 8947, 257, 4005, 4111, 13, 440, 1472, 307, 51268, 51268, 1596, 1858, 13, 759, 291, 528, 281, 360, 24590, 11, 291, 445, 764, 364, 21601, 47, 13, 759, 291, 528, 281, 360, 21538, 11, 51596, 51596], "temperature": 0.0, "avg_logprob": -0.1042324946476863, "compression_ratio": 1.5420168067226891, "no_speech_prob": 7.480861677322537e-05}, {"id": 743, "seek": 508284, "start": 5086.76, "end": 5094.68, "text": " haven't mentioned them so far, I think. Yeah, exactly. But what I mentioned is basically", "tokens": [50364, 1664, 291, 3496, 257, 1326, 2283, 544, 466, 613, 1451, 8088, 4295, 2740, 30, 286, 519, 321, 50560, 50560, 2378, 380, 2835, 552, 370, 1400, 11, 286, 519, 13, 865, 11, 2293, 13, 583, 437, 286, 2835, 307, 1936, 50956, 50956, 264, 700, 644, 295, 604, 45216, 304, 36170, 307, 577, 360, 291, 8947, 257, 4005, 4111, 13, 440, 1472, 307, 51268, 51268, 1596, 1858, 13, 759, 291, 528, 281, 360, 24590, 11, 291, 445, 764, 364, 21601, 47, 13, 759, 291, 528, 281, 360, 21538, 11, 51596, 51596], "temperature": 0.0, "avg_logprob": -0.1042324946476863, "compression_ratio": 1.5420168067226891, "no_speech_prob": 7.480861677322537e-05}, {"id": 744, "seek": 508284, "start": 5094.68, "end": 5100.92, "text": " the first part of any convolutional nets is how do you extract a powerful feature. The rest is", "tokens": [50364, 1664, 291, 3496, 257, 1326, 2283, 544, 466, 613, 1451, 8088, 4295, 2740, 30, 286, 519, 321, 50560, 50560, 2378, 380, 2835, 552, 370, 1400, 11, 286, 519, 13, 865, 11, 2293, 13, 583, 437, 286, 2835, 307, 1936, 50956, 50956, 264, 700, 644, 295, 604, 45216, 304, 36170, 307, 577, 360, 291, 8947, 257, 4005, 4111, 13, 440, 1472, 307, 51268, 51268, 1596, 1858, 13, 759, 291, 528, 281, 360, 24590, 11, 291, 445, 764, 364, 21601, 47, 13, 759, 291, 528, 281, 360, 21538, 11, 51596, 51596], "temperature": 0.0, "avg_logprob": -0.1042324946476863, "compression_ratio": 1.5420168067226891, "no_speech_prob": 7.480861677322537e-05}, {"id": 745, "seek": 508284, "start": 5100.92, "end": 5107.4800000000005, "text": " quite easy. If you want to do regression, you just use an MLP. If you want to do classification,", "tokens": [50364, 1664, 291, 3496, 257, 1326, 2283, 544, 466, 613, 1451, 8088, 4295, 2740, 30, 286, 519, 321, 50560, 50560, 2378, 380, 2835, 552, 370, 1400, 11, 286, 519, 13, 865, 11, 2293, 13, 583, 437, 286, 2835, 307, 1936, 50956, 50956, 264, 700, 644, 295, 604, 45216, 304, 36170, 307, 577, 360, 291, 8947, 257, 4005, 4111, 13, 440, 1472, 307, 51268, 51268, 1596, 1858, 13, 759, 291, 528, 281, 360, 24590, 11, 291, 445, 764, 364, 21601, 47, 13, 759, 291, 528, 281, 360, 21538, 11, 51596, 51596], "temperature": 0.0, "avg_logprob": -0.1042324946476863, "compression_ratio": 1.5420168067226891, "no_speech_prob": 7.480861677322537e-05}, {"id": 746, "seek": 510748, "start": 5107.48, "end": 5114.36, "text": " you should use MLP, with cross entropy. I can take more time to do that. But what I present", "tokens": [50364, 291, 820, 764, 21601, 47, 11, 365, 3278, 30867, 13, 286, 393, 747, 544, 565, 281, 360, 300, 13, 583, 437, 286, 1974, 50708, 50848, 307, 544, 1880, 813, 884, 445, 613, 1074, 13, 583, 498, 291, 976, 385, 1071, 1773, 11, 321, 727, 360, 300, 13, 51168, 51196, 286, 390, 1455, 264, 935, 300, 286, 519, 286, 1223, 586, 577, 321, 393, 1322, 257, 10290, 295, 257, 4295, 13, 51488, 51488, 583, 550, 370, 291, 576, 362, 341, 4111, 680, 9984, 13, 583, 550, 577, 576, 291, 352, 490, 341, 4111, 680, 51812, 51812], "temperature": 0.0, "avg_logprob": -0.20256559627572285, "compression_ratio": 1.7048458149779735, "no_speech_prob": 6.29025962552987e-05}, {"id": 747, "seek": 510748, "start": 5117.16, "end": 5123.5599999999995, "text": " is more interesting than doing just these guys. But if you give me another hour, we could do that.", "tokens": [50364, 291, 820, 764, 21601, 47, 11, 365, 3278, 30867, 13, 286, 393, 747, 544, 565, 281, 360, 300, 13, 583, 437, 286, 1974, 50708, 50848, 307, 544, 1880, 813, 884, 445, 613, 1074, 13, 583, 498, 291, 976, 385, 1071, 1773, 11, 321, 727, 360, 300, 13, 51168, 51196, 286, 390, 1455, 264, 935, 300, 286, 519, 286, 1223, 586, 577, 321, 393, 1322, 257, 10290, 295, 257, 4295, 13, 51488, 51488, 583, 550, 370, 291, 576, 362, 341, 4111, 680, 9984, 13, 583, 550, 577, 576, 291, 352, 490, 341, 4111, 680, 51812, 51812], "temperature": 0.0, "avg_logprob": -0.20256559627572285, "compression_ratio": 1.7048458149779735, "no_speech_prob": 6.29025962552987e-05}, {"id": 748, "seek": 510748, "start": 5124.12, "end": 5129.959999999999, "text": " I was making the point that I think I understand now how we can build a representation of a graph.", "tokens": [50364, 291, 820, 764, 21601, 47, 11, 365, 3278, 30867, 13, 286, 393, 747, 544, 565, 281, 360, 300, 13, 583, 437, 286, 1974, 50708, 50848, 307, 544, 1880, 813, 884, 445, 613, 1074, 13, 583, 498, 291, 976, 385, 1071, 1773, 11, 321, 727, 360, 300, 13, 51168, 51196, 286, 390, 1455, 264, 935, 300, 286, 519, 286, 1223, 586, 577, 321, 393, 1322, 257, 10290, 295, 257, 4295, 13, 51488, 51488, 583, 550, 370, 291, 576, 362, 341, 4111, 680, 9984, 13, 583, 550, 577, 576, 291, 352, 490, 341, 4111, 680, 51812, 51812], "temperature": 0.0, "avg_logprob": -0.20256559627572285, "compression_ratio": 1.7048458149779735, "no_speech_prob": 6.29025962552987e-05}, {"id": 749, "seek": 510748, "start": 5129.959999999999, "end": 5136.44, "text": " But then so you would have this feature per node. But then how would you go from this feature per", "tokens": [50364, 291, 820, 764, 21601, 47, 11, 365, 3278, 30867, 13, 286, 393, 747, 544, 565, 281, 360, 300, 13, 583, 437, 286, 1974, 50708, 50848, 307, 544, 1880, 813, 884, 445, 613, 1074, 13, 583, 498, 291, 976, 385, 1071, 1773, 11, 321, 727, 360, 300, 13, 51168, 51196, 286, 390, 1455, 264, 935, 300, 286, 519, 286, 1223, 586, 577, 321, 393, 1322, 257, 10290, 295, 257, 4295, 13, 51488, 51488, 583, 550, 370, 291, 576, 362, 341, 4111, 680, 9984, 13, 583, 550, 577, 576, 291, 352, 490, 341, 4111, 680, 51812, 51812], "temperature": 0.0, "avg_logprob": -0.20256559627572285, "compression_ratio": 1.7048458149779735, "no_speech_prob": 6.29025962552987e-05}, {"id": 750, "seek": 513644, "start": 5136.44, "end": 5142.36, "text": " node to the final task? Maybe we can mention this such that we can give some more. Sure. What you do", "tokens": [50364, 9984, 281, 264, 2572, 5633, 30, 2704, 321, 393, 2152, 341, 1270, 300, 321, 393, 976, 512, 544, 13, 4894, 13, 708, 291, 360, 50660, 50660, 1936, 11, 337, 1365, 11, 291, 362, 4111, 2293, 13, 509, 8947, 45216, 304, 4111, 680, 9984, 13, 51008, 51052, 1396, 5800, 11, 498, 291, 528, 281, 360, 11, 337, 1365, 11, 4295, 21538, 11, 437, 291, 486, 360, 11, 291, 486, 51252, 51252, 360, 512, 733, 295, 16743, 399, 2445, 322, 341, 4111, 9984, 13, 1171, 1365, 11, 264, 881, 2689, 472, 51584, 51584], "temperature": 0.0, "avg_logprob": -0.18832700995988744, "compression_ratio": 1.6977777777777778, "no_speech_prob": 2.710075023060199e-05}, {"id": 751, "seek": 513644, "start": 5142.36, "end": 5149.32, "text": " basically, for example, you have feature exactly. You extract convolutional feature per node.", "tokens": [50364, 9984, 281, 264, 2572, 5633, 30, 2704, 321, 393, 2152, 341, 1270, 300, 321, 393, 976, 512, 544, 13, 4894, 13, 708, 291, 360, 50660, 50660, 1936, 11, 337, 1365, 11, 291, 362, 4111, 2293, 13, 509, 8947, 45216, 304, 4111, 680, 9984, 13, 51008, 51052, 1396, 5800, 11, 498, 291, 528, 281, 360, 11, 337, 1365, 11, 4295, 21538, 11, 437, 291, 486, 360, 11, 291, 486, 51252, 51252, 360, 512, 733, 295, 16743, 399, 2445, 322, 341, 4111, 9984, 13, 1171, 1365, 11, 264, 881, 2689, 472, 51584, 51584], "temperature": 0.0, "avg_logprob": -0.18832700995988744, "compression_ratio": 1.6977777777777778, "no_speech_prob": 2.710075023060199e-05}, {"id": 752, "seek": 513644, "start": 5150.2, "end": 5154.2, "text": " Then suddenly, if you want to do, for example, graph classification, what you will do, you will", "tokens": [50364, 9984, 281, 264, 2572, 5633, 30, 2704, 321, 393, 2152, 341, 1270, 300, 321, 393, 976, 512, 544, 13, 4894, 13, 708, 291, 360, 50660, 50660, 1936, 11, 337, 1365, 11, 291, 362, 4111, 2293, 13, 509, 8947, 45216, 304, 4111, 680, 9984, 13, 51008, 51052, 1396, 5800, 11, 498, 291, 528, 281, 360, 11, 337, 1365, 11, 4295, 21538, 11, 437, 291, 486, 360, 11, 291, 486, 51252, 51252, 360, 512, 733, 295, 16743, 399, 2445, 322, 341, 4111, 9984, 13, 1171, 1365, 11, 264, 881, 2689, 472, 51584, 51584], "temperature": 0.0, "avg_logprob": -0.18832700995988744, "compression_ratio": 1.6977777777777778, "no_speech_prob": 2.710075023060199e-05}, {"id": 753, "seek": 513644, "start": 5154.2, "end": 5160.839999999999, "text": " do some kind of aggregation function on this feature node. For example, the most common one", "tokens": [50364, 9984, 281, 264, 2572, 5633, 30, 2704, 321, 393, 2152, 341, 1270, 300, 321, 393, 976, 512, 544, 13, 4894, 13, 708, 291, 360, 50660, 50660, 1936, 11, 337, 1365, 11, 291, 362, 4111, 2293, 13, 509, 8947, 45216, 304, 4111, 680, 9984, 13, 51008, 51052, 1396, 5800, 11, 498, 291, 528, 281, 360, 11, 337, 1365, 11, 4295, 21538, 11, 437, 291, 486, 360, 11, 291, 486, 51252, 51252, 360, 512, 733, 295, 16743, 399, 2445, 322, 341, 4111, 9984, 13, 1171, 1365, 11, 264, 881, 2689, 472, 51584, 51584], "temperature": 0.0, "avg_logprob": -0.18832700995988744, "compression_ratio": 1.6977777777777778, "no_speech_prob": 2.710075023060199e-05}, {"id": 754, "seek": 516084, "start": 5160.84, "end": 5167.0, "text": " is to do the average. You do the average of all feature nodes. Then on the top of that, you use an", "tokens": [50364, 307, 281, 360, 264, 4274, 13, 509, 360, 264, 4274, 295, 439, 4111, 13891, 13, 1396, 322, 264, 1192, 295, 300, 11, 291, 764, 364, 50672, 50672, 21601, 47, 13, 1396, 291, 486, 360, 21538, 295, 428, 4295, 13, 639, 576, 312, 337, 1009, 264, 912, 733, 50992, 50992, 295, 3877, 295, 264, 4295, 420, 291, 362, 819, 9227, 11, 411, 819, 3547, 295, 13891, 30, 51220, 51372, 759, 291, 764, 264, 914, 11, 309, 311, 2584, 6695, 295, 264, 1230, 295, 13891, 13, 51528, 51608, 759, 291, 360, 264, 2408, 11, 498, 291, 360, 264, 11469, 11, 291, 362, 867, 19077, 597, 366, 6695, 295, 264, 1230, 51824, 51824], "temperature": 0.0, "avg_logprob": -0.12876839297158377, "compression_ratio": 1.8414634146341464, "no_speech_prob": 2.930744994955603e-05}, {"id": 755, "seek": 516084, "start": 5167.0, "end": 5173.400000000001, "text": " MLP. Then you will do classification of your graph. This would be for always the same kind", "tokens": [50364, 307, 281, 360, 264, 4274, 13, 509, 360, 264, 4274, 295, 439, 4111, 13891, 13, 1396, 322, 264, 1192, 295, 300, 11, 291, 764, 364, 50672, 50672, 21601, 47, 13, 1396, 291, 486, 360, 21538, 295, 428, 4295, 13, 639, 576, 312, 337, 1009, 264, 912, 733, 50992, 50992, 295, 3877, 295, 264, 4295, 420, 291, 362, 819, 9227, 11, 411, 819, 3547, 295, 13891, 30, 51220, 51372, 759, 291, 764, 264, 914, 11, 309, 311, 2584, 6695, 295, 264, 1230, 295, 13891, 13, 51528, 51608, 759, 291, 360, 264, 2408, 11, 498, 291, 360, 264, 11469, 11, 291, 362, 867, 19077, 597, 366, 6695, 295, 264, 1230, 51824, 51824], "temperature": 0.0, "avg_logprob": -0.12876839297158377, "compression_ratio": 1.8414634146341464, "no_speech_prob": 2.930744994955603e-05}, {"id": 756, "seek": 516084, "start": 5173.400000000001, "end": 5177.96, "text": " of structure of the graph or you have different structures, like different numbers of nodes?", "tokens": [50364, 307, 281, 360, 264, 4274, 13, 509, 360, 264, 4274, 295, 439, 4111, 13891, 13, 1396, 322, 264, 1192, 295, 300, 11, 291, 764, 364, 50672, 50672, 21601, 47, 13, 1396, 291, 486, 360, 21538, 295, 428, 4295, 13, 639, 576, 312, 337, 1009, 264, 912, 733, 50992, 50992, 295, 3877, 295, 264, 4295, 420, 291, 362, 819, 9227, 11, 411, 819, 3547, 295, 13891, 30, 51220, 51372, 759, 291, 764, 264, 914, 11, 309, 311, 2584, 6695, 295, 264, 1230, 295, 13891, 13, 51528, 51608, 759, 291, 360, 264, 2408, 11, 498, 291, 360, 264, 11469, 11, 291, 362, 867, 19077, 597, 366, 6695, 295, 264, 1230, 51824, 51824], "temperature": 0.0, "avg_logprob": -0.12876839297158377, "compression_ratio": 1.8414634146341464, "no_speech_prob": 2.930744994955603e-05}, {"id": 757, "seek": 516084, "start": 5181.0, "end": 5184.12, "text": " If you use the mean, it's completely independent of the number of nodes.", "tokens": [50364, 307, 281, 360, 264, 4274, 13, 509, 360, 264, 4274, 295, 439, 4111, 13891, 13, 1396, 322, 264, 1192, 295, 300, 11, 291, 764, 364, 50672, 50672, 21601, 47, 13, 1396, 291, 486, 360, 21538, 295, 428, 4295, 13, 639, 576, 312, 337, 1009, 264, 912, 733, 50992, 50992, 295, 3877, 295, 264, 4295, 420, 291, 362, 819, 9227, 11, 411, 819, 3547, 295, 13891, 30, 51220, 51372, 759, 291, 764, 264, 914, 11, 309, 311, 2584, 6695, 295, 264, 1230, 295, 13891, 13, 51528, 51608, 759, 291, 360, 264, 2408, 11, 498, 291, 360, 264, 11469, 11, 291, 362, 867, 19077, 597, 366, 6695, 295, 264, 1230, 51824, 51824], "temperature": 0.0, "avg_logprob": -0.12876839297158377, "compression_ratio": 1.8414634146341464, "no_speech_prob": 2.930744994955603e-05}, {"id": 758, "seek": 516084, "start": 5185.72, "end": 5190.04, "text": " If you do the sum, if you do the max, you have many operators which are independent of the number", "tokens": [50364, 307, 281, 360, 264, 4274, 13, 509, 360, 264, 4274, 295, 439, 4111, 13891, 13, 1396, 322, 264, 1192, 295, 300, 11, 291, 764, 364, 50672, 50672, 21601, 47, 13, 1396, 291, 486, 360, 21538, 295, 428, 4295, 13, 639, 576, 312, 337, 1009, 264, 912, 733, 50992, 50992, 295, 3877, 295, 264, 4295, 420, 291, 362, 819, 9227, 11, 411, 819, 3547, 295, 13891, 30, 51220, 51372, 759, 291, 764, 264, 914, 11, 309, 311, 2584, 6695, 295, 264, 1230, 295, 13891, 13, 51528, 51608, 759, 291, 360, 264, 2408, 11, 498, 291, 360, 264, 11469, 11, 291, 362, 867, 19077, 597, 366, 6695, 295, 264, 1230, 51824, 51824], "temperature": 0.0, "avg_logprob": -0.12876839297158377, "compression_ratio": 1.8414634146341464, "no_speech_prob": 2.930744994955603e-05}, {"id": 759, "seek": 519004, "start": 5190.04, "end": 5202.2, "text": " of nodes. We have this. This medium size actually enough to statistically separate", "tokens": [50364, 295, 13891, 13, 492, 362, 341, 13, 639, 6399, 2744, 767, 1547, 281, 36478, 4994, 50972, 51000, 264, 3389, 295, 4295, 18161, 9590, 13, 492, 652, 1858, 337, 777, 5022, 281, 909, 777, 51288, 51388, 4295, 5245, 293, 611, 777, 1412, 6352, 13, 639, 307, 264, 2113, 281, 264, 49040, 13, 961, 385, 586, 2903, 264, 4295, 51840, 51840], "temperature": 0.0, "avg_logprob": -0.17047173859643155, "compression_ratio": 1.5266272189349113, "no_speech_prob": 2.30524437938584e-05}, {"id": 760, "seek": 519004, "start": 5202.76, "end": 5208.5199999999995, "text": " the performance of graph neural networks. We make easy for new users to add new", "tokens": [50364, 295, 13891, 13, 492, 362, 341, 13, 639, 6399, 2744, 767, 1547, 281, 36478, 4994, 50972, 51000, 264, 3389, 295, 4295, 18161, 9590, 13, 492, 652, 1858, 337, 777, 5022, 281, 909, 777, 51288, 51388, 4295, 5245, 293, 611, 777, 1412, 6352, 13, 639, 307, 264, 2113, 281, 264, 49040, 13, 961, 385, 586, 2903, 264, 4295, 51840, 51840], "temperature": 0.0, "avg_logprob": -0.17047173859643155, "compression_ratio": 1.5266272189349113, "no_speech_prob": 2.30524437938584e-05}, {"id": 761, "seek": 519004, "start": 5210.5199999999995, "end": 5219.56, "text": " graph models and also new data sets. This is the link to the repo. Let me now explain the graph", "tokens": [50364, 295, 13891, 13, 492, 362, 341, 13, 639, 6399, 2744, 767, 1547, 281, 36478, 4994, 50972, 51000, 264, 3389, 295, 4295, 18161, 9590, 13, 492, 652, 1858, 337, 777, 5022, 281, 909, 777, 51288, 51388, 4295, 5245, 293, 611, 777, 1412, 6352, 13, 639, 307, 264, 2113, 281, 264, 49040, 13, 961, 385, 586, 2903, 264, 4295, 51840, 51840], "temperature": 0.0, "avg_logprob": -0.17047173859643155, "compression_ratio": 1.5266272189349113, "no_speech_prob": 2.30524437938584e-05}, {"id": 762, "seek": 521956, "start": 5219.56, "end": 5225.240000000001, "text": " neural network pipeline. A standard graph neural network pipeline is composed of three layers.", "tokens": [50364, 18161, 3209, 15517, 13, 316, 3832, 4295, 18161, 3209, 15517, 307, 18204, 295, 1045, 7914, 13, 50648, 50648, 440, 700, 4583, 307, 516, 281, 312, 364, 4846, 4583, 293, 307, 516, 281, 652, 364, 12240, 3584, 295, 264, 4846, 9984, 50932, 50932, 293, 4691, 4122, 13, 1396, 291, 486, 362, 257, 2638, 295, 4295, 18161, 3209, 7914, 13, 6288, 11, 291, 486, 51280, 51280, 362, 257, 5633, 4583, 13, 821, 486, 312, 257, 17630, 4583, 337, 4295, 9984, 293, 4691, 5633, 13, 961, 385, 586, 6786, 51680, 51680], "temperature": 0.0, "avg_logprob": -0.06861506568060981, "compression_ratio": 1.945273631840796, "no_speech_prob": 1.73053122125566e-05}, {"id": 763, "seek": 521956, "start": 5225.240000000001, "end": 5230.92, "text": " The first layer is going to be an input layer and is going to make an embedding of the input node", "tokens": [50364, 18161, 3209, 15517, 13, 316, 3832, 4295, 18161, 3209, 15517, 307, 18204, 295, 1045, 7914, 13, 50648, 50648, 440, 700, 4583, 307, 516, 281, 312, 364, 4846, 4583, 293, 307, 516, 281, 652, 364, 12240, 3584, 295, 264, 4846, 9984, 50932, 50932, 293, 4691, 4122, 13, 1396, 291, 486, 362, 257, 2638, 295, 4295, 18161, 3209, 7914, 13, 6288, 11, 291, 486, 51280, 51280, 362, 257, 5633, 4583, 13, 821, 486, 312, 257, 17630, 4583, 337, 4295, 9984, 293, 4691, 5633, 13, 961, 385, 586, 6786, 51680, 51680], "temperature": 0.0, "avg_logprob": -0.06861506568060981, "compression_ratio": 1.945273631840796, "no_speech_prob": 1.73053122125566e-05}, {"id": 764, "seek": 521956, "start": 5230.92, "end": 5237.88, "text": " and edge features. Then you will have a series of graph neural network layers. Finally, you will", "tokens": [50364, 18161, 3209, 15517, 13, 316, 3832, 4295, 18161, 3209, 15517, 307, 18204, 295, 1045, 7914, 13, 50648, 50648, 440, 700, 4583, 307, 516, 281, 312, 364, 4846, 4583, 293, 307, 516, 281, 652, 364, 12240, 3584, 295, 264, 4846, 9984, 50932, 50932, 293, 4691, 4122, 13, 1396, 291, 486, 362, 257, 2638, 295, 4295, 18161, 3209, 7914, 13, 6288, 11, 291, 486, 51280, 51280, 362, 257, 5633, 4583, 13, 821, 486, 312, 257, 17630, 4583, 337, 4295, 9984, 293, 4691, 5633, 13, 961, 385, 586, 6786, 51680, 51680], "temperature": 0.0, "avg_logprob": -0.06861506568060981, "compression_ratio": 1.945273631840796, "no_speech_prob": 1.73053122125566e-05}, {"id": 765, "seek": 521956, "start": 5237.88, "end": 5245.88, "text": " have a task layer. There will be a prediction layer for graph node and edge task. Let me now describe", "tokens": [50364, 18161, 3209, 15517, 13, 316, 3832, 4295, 18161, 3209, 15517, 307, 18204, 295, 1045, 7914, 13, 50648, 50648, 440, 700, 4583, 307, 516, 281, 312, 364, 4846, 4583, 293, 307, 516, 281, 652, 364, 12240, 3584, 295, 264, 4846, 9984, 50932, 50932, 293, 4691, 4122, 13, 1396, 291, 486, 362, 257, 2638, 295, 4295, 18161, 3209, 7914, 13, 6288, 11, 291, 486, 51280, 51280, 362, 257, 5633, 4583, 13, 821, 486, 312, 257, 17630, 4583, 337, 4295, 9984, 293, 4691, 5633, 13, 961, 385, 586, 6786, 51680, 51680], "temperature": 0.0, "avg_logprob": -0.06861506568060981, "compression_ratio": 1.945273631840796, "no_speech_prob": 1.73053122125566e-05}, {"id": 766, "seek": 524588, "start": 5245.88, "end": 5255.16, "text": " in details each of these three layers. For the input layer, again, we will have the input node", "tokens": [50364, 294, 4365, 1184, 295, 613, 1045, 7914, 13, 1171, 264, 4846, 4583, 11, 797, 11, 321, 486, 362, 264, 4846, 9984, 50828, 50828, 293, 4691, 4122, 13, 639, 1487, 490, 264, 3861, 13, 663, 393, 312, 257, 9984, 4111, 11, 337, 1365, 11, 337, 51160, 51284, 2748, 260, 1185, 11, 337, 3383, 13, 467, 486, 976, 291, 512, 4111, 295, 428, 1674, 13, 51460, 51500, 708, 291, 486, 360, 307, 300, 291, 486, 747, 341, 1379, 4111, 293, 291, 486, 652, 364, 12240, 3584, 11, 51788, 51788], "temperature": 0.0, "avg_logprob": -0.16012725401460454, "compression_ratio": 1.7403846153846154, "no_speech_prob": 1.0871934136957861e-05}, {"id": 767, "seek": 524588, "start": 5255.16, "end": 5261.8, "text": " and edge features. This comes from the application. That can be a node feature, for example, for", "tokens": [50364, 294, 4365, 1184, 295, 613, 1045, 7914, 13, 1171, 264, 4846, 4583, 11, 797, 11, 321, 486, 362, 264, 4846, 9984, 50828, 50828, 293, 4691, 4122, 13, 639, 1487, 490, 264, 3861, 13, 663, 393, 312, 257, 9984, 4111, 11, 337, 1365, 11, 337, 51160, 51284, 2748, 260, 1185, 11, 337, 3383, 13, 467, 486, 976, 291, 512, 4111, 295, 428, 1674, 13, 51460, 51500, 708, 291, 486, 360, 307, 300, 291, 486, 747, 341, 1379, 4111, 293, 291, 486, 652, 364, 12240, 3584, 11, 51788, 51788], "temperature": 0.0, "avg_logprob": -0.16012725401460454, "compression_ratio": 1.7403846153846154, "no_speech_prob": 1.0871934136957861e-05}, {"id": 768, "seek": 524588, "start": 5264.28, "end": 5267.8, "text": " recommender system, for products. It will give you some feature of your product.", "tokens": [50364, 294, 4365, 1184, 295, 613, 1045, 7914, 13, 1171, 264, 4846, 4583, 11, 797, 11, 321, 486, 362, 264, 4846, 9984, 50828, 50828, 293, 4691, 4122, 13, 639, 1487, 490, 264, 3861, 13, 663, 393, 312, 257, 9984, 4111, 11, 337, 1365, 11, 337, 51160, 51284, 2748, 260, 1185, 11, 337, 3383, 13, 467, 486, 976, 291, 512, 4111, 295, 428, 1674, 13, 51460, 51500, 708, 291, 486, 360, 307, 300, 291, 486, 747, 341, 1379, 4111, 293, 291, 486, 652, 364, 12240, 3584, 11, 51788, 51788], "temperature": 0.0, "avg_logprob": -0.16012725401460454, "compression_ratio": 1.7403846153846154, "no_speech_prob": 1.0871934136957861e-05}, {"id": 769, "seek": 524588, "start": 5268.6, "end": 5274.36, "text": " What you will do is that you will take this whole feature and you will make an embedding,", "tokens": [50364, 294, 4365, 1184, 295, 613, 1045, 7914, 13, 1171, 264, 4846, 4583, 11, 797, 11, 321, 486, 362, 264, 4846, 9984, 50828, 50828, 293, 4691, 4122, 13, 639, 1487, 490, 264, 3861, 13, 663, 393, 312, 257, 9984, 4111, 11, 337, 1365, 11, 337, 51160, 51284, 2748, 260, 1185, 11, 337, 3383, 13, 467, 486, 976, 291, 512, 4111, 295, 428, 1674, 13, 51460, 51500, 708, 291, 486, 360, 307, 300, 291, 486, 747, 341, 1379, 4111, 293, 291, 486, 652, 364, 12240, 3584, 11, 51788, 51788], "temperature": 0.0, "avg_logprob": -0.16012725401460454, "compression_ratio": 1.7403846153846154, "no_speech_prob": 1.0871934136957861e-05}, {"id": 770, "seek": 527436, "start": 5274.36, "end": 5280.12, "text": " a linear embedding, and you will get a vector of d dimensions. We can do the same if we have some", "tokens": [50364, 257, 8213, 12240, 3584, 11, 293, 291, 486, 483, 257, 8062, 295, 274, 12819, 13, 492, 393, 360, 264, 912, 498, 321, 362, 512, 50652, 50652, 4691, 4111, 13, 492, 393, 360, 364, 12240, 3584, 295, 264, 4846, 4691, 4111, 293, 321, 486, 483, 257, 8062, 295, 274, 50908, 50908, 10139, 13, 8537, 11, 264, 5598, 295, 264, 12240, 3584, 4583, 486, 312, 337, 276, 11, 309, 311, 516, 281, 312, 257, 8141, 295, 51340, 51340, 297, 13891, 293, 274, 10139, 337, 264, 4122, 13, 1171, 264, 4691, 307, 516, 281, 312, 257, 8141, 295, 308, 11, 264, 1230, 295, 51764, 51764], "temperature": 0.0, "avg_logprob": -0.14339888095855713, "compression_ratio": 1.9746192893401016, "no_speech_prob": 2.784981370496098e-05}, {"id": 771, "seek": 527436, "start": 5280.12, "end": 5285.24, "text": " edge feature. We can do an embedding of the input edge feature and we will get a vector of d", "tokens": [50364, 257, 8213, 12240, 3584, 11, 293, 291, 486, 483, 257, 8062, 295, 274, 12819, 13, 492, 393, 360, 264, 912, 498, 321, 362, 512, 50652, 50652, 4691, 4111, 13, 492, 393, 360, 364, 12240, 3584, 295, 264, 4846, 4691, 4111, 293, 321, 486, 483, 257, 8062, 295, 274, 50908, 50908, 10139, 13, 8537, 11, 264, 5598, 295, 264, 12240, 3584, 4583, 486, 312, 337, 276, 11, 309, 311, 516, 281, 312, 257, 8141, 295, 51340, 51340, 297, 13891, 293, 274, 10139, 337, 264, 4122, 13, 1171, 264, 4691, 307, 516, 281, 312, 257, 8141, 295, 308, 11, 264, 1230, 295, 51764, 51764], "temperature": 0.0, "avg_logprob": -0.14339888095855713, "compression_ratio": 1.9746192893401016, "no_speech_prob": 2.784981370496098e-05}, {"id": 772, "seek": 527436, "start": 5285.24, "end": 5293.88, "text": " dimension. Basically, the output of the embedding layer will be for h, it's going to be a matrix of", "tokens": [50364, 257, 8213, 12240, 3584, 11, 293, 291, 486, 483, 257, 8062, 295, 274, 12819, 13, 492, 393, 360, 264, 912, 498, 321, 362, 512, 50652, 50652, 4691, 4111, 13, 492, 393, 360, 364, 12240, 3584, 295, 264, 4846, 4691, 4111, 293, 321, 486, 483, 257, 8062, 295, 274, 50908, 50908, 10139, 13, 8537, 11, 264, 5598, 295, 264, 12240, 3584, 4583, 486, 312, 337, 276, 11, 309, 311, 516, 281, 312, 257, 8141, 295, 51340, 51340, 297, 13891, 293, 274, 10139, 337, 264, 4122, 13, 1171, 264, 4691, 307, 516, 281, 312, 257, 8141, 295, 308, 11, 264, 1230, 295, 51764, 51764], "temperature": 0.0, "avg_logprob": -0.14339888095855713, "compression_ratio": 1.9746192893401016, "no_speech_prob": 2.784981370496098e-05}, {"id": 773, "seek": 527436, "start": 5293.88, "end": 5302.36, "text": " n nodes and d dimension for the features. For the edge is going to be a matrix of e, the number of", "tokens": [50364, 257, 8213, 12240, 3584, 11, 293, 291, 486, 483, 257, 8062, 295, 274, 12819, 13, 492, 393, 360, 264, 912, 498, 321, 362, 512, 50652, 50652, 4691, 4111, 13, 492, 393, 360, 364, 12240, 3584, 295, 264, 4846, 4691, 4111, 293, 321, 486, 483, 257, 8062, 295, 274, 50908, 50908, 10139, 13, 8537, 11, 264, 5598, 295, 264, 12240, 3584, 4583, 486, 312, 337, 276, 11, 309, 311, 516, 281, 312, 257, 8141, 295, 51340, 51340, 297, 13891, 293, 274, 10139, 337, 264, 4122, 13, 1171, 264, 4691, 307, 516, 281, 312, 257, 8141, 295, 308, 11, 264, 1230, 295, 51764, 51764], "temperature": 0.0, "avg_logprob": -0.14339888095855713, "compression_ratio": 1.9746192893401016, "no_speech_prob": 2.784981370496098e-05}, {"id": 774, "seek": 530236, "start": 5302.36, "end": 5318.5199999999995, "text": " edges times the number of features. We will give that. We will give this output of the embedding", "tokens": [50364, 8819, 1413, 264, 1230, 295, 4122, 13, 492, 486, 976, 300, 13, 492, 486, 976, 341, 5598, 295, 264, 12240, 3584, 51172, 51172, 4583, 307, 516, 281, 312, 264, 4846, 295, 264, 4295, 18161, 3209, 7914, 11, 597, 307, 510, 13, 1396, 437, 321, 486, 51672, 51672], "temperature": 0.0, "avg_logprob": -0.13071999257924605, "compression_ratio": 1.4961832061068703, "no_speech_prob": 1.3267370377434418e-05}, {"id": 775, "seek": 530236, "start": 5318.5199999999995, "end": 5328.5199999999995, "text": " layer is going to be the input of the graph neural network layers, which is here. Then what we will", "tokens": [50364, 8819, 1413, 264, 1230, 295, 4122, 13, 492, 486, 976, 300, 13, 492, 486, 976, 341, 5598, 295, 264, 12240, 3584, 51172, 51172, 4583, 307, 516, 281, 312, 264, 4846, 295, 264, 4295, 18161, 3209, 7914, 11, 597, 307, 510, 13, 1396, 437, 321, 486, 51672, 51672], "temperature": 0.0, "avg_logprob": -0.13071999257924605, "compression_ratio": 1.4961832061068703, "no_speech_prob": 1.3267370377434418e-05}, {"id": 776, "seek": 532852, "start": 5328.52, "end": 5339.8, "text": " do is that we will apply our favorite graph neural layer a number of L times. We have the node and", "tokens": [50364, 360, 307, 300, 321, 486, 3079, 527, 2954, 4295, 18161, 4583, 257, 1230, 295, 441, 1413, 13, 492, 362, 264, 9984, 293, 50928, 50928, 264, 4691, 10290, 412, 4583, 441, 13, 467, 486, 352, 807, 264, 460, 293, 426, 4583, 293, 309, 486, 976, 291, 51260, 51260, 9984, 10290, 295, 276, 293, 308, 412, 264, 958, 4583, 13, 492, 486, 360, 300, 426, 1230, 295, 1413, 13, 639, 486, 976, 51600, 51600], "temperature": 0.0, "avg_logprob": -0.15510122196094409, "compression_ratio": 1.7076023391812865, "no_speech_prob": 2.4627468519611284e-05}, {"id": 777, "seek": 532852, "start": 5339.8, "end": 5346.4400000000005, "text": " the edge representation at layer L. It will go through the G and N layer and it will give you", "tokens": [50364, 360, 307, 300, 321, 486, 3079, 527, 2954, 4295, 18161, 4583, 257, 1230, 295, 441, 1413, 13, 492, 362, 264, 9984, 293, 50928, 50928, 264, 4691, 10290, 412, 4583, 441, 13, 467, 486, 352, 807, 264, 460, 293, 426, 4583, 293, 309, 486, 976, 291, 51260, 51260, 9984, 10290, 295, 276, 293, 308, 412, 264, 958, 4583, 13, 492, 486, 360, 300, 426, 1230, 295, 1413, 13, 639, 486, 976, 51600, 51600], "temperature": 0.0, "avg_logprob": -0.15510122196094409, "compression_ratio": 1.7076023391812865, "no_speech_prob": 2.4627468519611284e-05}, {"id": 778, "seek": 532852, "start": 5346.4400000000005, "end": 5353.240000000001, "text": " node representation of h and e at the next layer. We will do that N number of times. This will give", "tokens": [50364, 360, 307, 300, 321, 486, 3079, 527, 2954, 4295, 18161, 4583, 257, 1230, 295, 441, 1413, 13, 492, 362, 264, 9984, 293, 50928, 50928, 264, 4691, 10290, 412, 4583, 441, 13, 467, 486, 352, 807, 264, 460, 293, 426, 4583, 293, 309, 486, 976, 291, 51260, 51260, 9984, 10290, 295, 276, 293, 308, 412, 264, 958, 4583, 13, 492, 486, 360, 300, 426, 1230, 295, 1413, 13, 639, 486, 976, 51600, 51600], "temperature": 0.0, "avg_logprob": -0.15510122196094409, "compression_ratio": 1.7076023391812865, "no_speech_prob": 2.4627468519611284e-05}, {"id": 779, "seek": 535324, "start": 5353.24, "end": 5360.5199999999995, "text": " us the output of the graph neural network layers. Again, it's going to be a matrix of n nodes and d", "tokens": [50364, 505, 264, 5598, 295, 264, 4295, 18161, 3209, 7914, 13, 3764, 11, 309, 311, 516, 281, 312, 257, 8141, 295, 297, 13891, 293, 274, 50728, 50728, 12819, 337, 264, 13891, 293, 337, 264, 8819, 13, 467, 311, 516, 281, 312, 257, 8141, 295, 308, 11, 597, 307, 264, 1230, 295, 51092, 51092, 8819, 1413, 264, 10139, 1860, 13, 639, 307, 264, 5598, 295, 527, 4295, 18161, 3209, 7914, 13, 51388, 51460], "temperature": 0.0, "avg_logprob": -0.11427288839261826, "compression_ratio": 1.875, "no_speech_prob": 4.608429298968986e-05}, {"id": 780, "seek": 535324, "start": 5360.5199999999995, "end": 5367.8, "text": " dimensions for the nodes and for the edges. It's going to be a matrix of e, which is the number of", "tokens": [50364, 505, 264, 5598, 295, 264, 4295, 18161, 3209, 7914, 13, 3764, 11, 309, 311, 516, 281, 312, 257, 8141, 295, 297, 13891, 293, 274, 50728, 50728, 12819, 337, 264, 13891, 293, 337, 264, 8819, 13, 467, 311, 516, 281, 312, 257, 8141, 295, 308, 11, 597, 307, 264, 1230, 295, 51092, 51092, 8819, 1413, 264, 10139, 1860, 13, 639, 307, 264, 5598, 295, 527, 4295, 18161, 3209, 7914, 13, 51388, 51460], "temperature": 0.0, "avg_logprob": -0.11427288839261826, "compression_ratio": 1.875, "no_speech_prob": 4.608429298968986e-05}, {"id": 781, "seek": 535324, "start": 5367.8, "end": 5373.719999999999, "text": " edges times the dimensionality. This is the output of our graph neural network layers.", "tokens": [50364, 505, 264, 5598, 295, 264, 4295, 18161, 3209, 7914, 13, 3764, 11, 309, 311, 516, 281, 312, 257, 8141, 295, 297, 13891, 293, 274, 50728, 50728, 12819, 337, 264, 13891, 293, 337, 264, 8819, 13, 467, 311, 516, 281, 312, 257, 8141, 295, 308, 11, 597, 307, 264, 1230, 295, 51092, 51092, 8819, 1413, 264, 10139, 1860, 13, 639, 307, 264, 5598, 295, 527, 4295, 18161, 3209, 7914, 13, 51388, 51460], "temperature": 0.0, "avg_logprob": -0.11427288839261826, "compression_ratio": 1.875, "no_speech_prob": 4.608429298968986e-05}, {"id": 782, "seek": 537372, "start": 5373.72, "end": 5382.6, "text": " Finally, for the last layer, this is a task-based layer. If we are doing some prediction at the", "tokens": [50364, 6288, 11, 337, 264, 1036, 4583, 11, 341, 307, 257, 5633, 12, 6032, 4583, 13, 759, 321, 366, 884, 512, 17630, 412, 264, 50808, 50808, 4295, 16949, 11, 437, 2314, 307, 300, 321, 366, 516, 281, 747, 264, 5598, 295, 264, 4295, 18161, 3209, 51132, 51132, 7914, 293, 321, 434, 516, 281, 652, 257, 914, 365, 3104, 281, 439, 13891, 295, 264, 4295, 13, 639, 486, 976, 505, 51508, 51556], "temperature": 0.0, "avg_logprob": -0.1569677193959554, "compression_ratio": 1.5977653631284916, "no_speech_prob": 1.1689623534039129e-05}, {"id": 783, "seek": 537372, "start": 5382.6, "end": 5389.08, "text": " graph labels, what happens is that we are going to take the output of the graph neural network", "tokens": [50364, 6288, 11, 337, 264, 1036, 4583, 11, 341, 307, 257, 5633, 12, 6032, 4583, 13, 759, 321, 366, 884, 512, 17630, 412, 264, 50808, 50808, 4295, 16949, 11, 437, 2314, 307, 300, 321, 366, 516, 281, 747, 264, 5598, 295, 264, 4295, 18161, 3209, 51132, 51132, 7914, 293, 321, 434, 516, 281, 652, 257, 914, 365, 3104, 281, 439, 13891, 295, 264, 4295, 13, 639, 486, 976, 505, 51508, 51556], "temperature": 0.0, "avg_logprob": -0.1569677193959554, "compression_ratio": 1.5977653631284916, "no_speech_prob": 1.1689623534039129e-05}, {"id": 784, "seek": 537372, "start": 5389.08, "end": 5396.6, "text": " layers and we're going to make a mean with respect to all nodes of the graph. This will give us", "tokens": [50364, 6288, 11, 337, 264, 1036, 4583, 11, 341, 307, 257, 5633, 12, 6032, 4583, 13, 759, 321, 366, 884, 512, 17630, 412, 264, 50808, 50808, 4295, 16949, 11, 437, 2314, 307, 300, 321, 366, 516, 281, 747, 264, 5598, 295, 264, 4295, 18161, 3209, 51132, 51132, 7914, 293, 321, 434, 516, 281, 652, 257, 914, 365, 3104, 281, 439, 13891, 295, 264, 4295, 13, 639, 486, 976, 505, 51508, 51556], "temperature": 0.0, "avg_logprob": -0.1569677193959554, "compression_ratio": 1.5977653631284916, "no_speech_prob": 1.1689623534039129e-05}, {"id": 785, "seek": 539660, "start": 5396.6, "end": 5407.160000000001, "text": " a representation of the graph of d dimension. Then we will give that to an MLP, a multi-layer", "tokens": [50364, 257, 10290, 295, 264, 4295, 295, 274, 10139, 13, 1396, 321, 486, 976, 300, 281, 364, 21601, 47, 11, 257, 4825, 12, 8376, 260, 50892, 50892, 43276, 2044, 11, 293, 309, 486, 976, 505, 257, 6175, 597, 393, 312, 257, 39684, 498, 321, 366, 884, 512, 4295, 51152, 51152, 24590, 411, 7313, 4707, 35701, 11, 420, 309, 393, 312, 21538, 498, 321, 366, 1382, 281, 33872, 51644, 51644], "temperature": 0.0, "avg_logprob": -0.201909487588065, "compression_ratio": 1.5833333333333333, "no_speech_prob": 3.386624302947894e-05}, {"id": 786, "seek": 539660, "start": 5407.160000000001, "end": 5412.360000000001, "text": " perceptron, and it will give us a score which can be a scalar if we are doing some graph", "tokens": [50364, 257, 10290, 295, 264, 4295, 295, 274, 10139, 13, 1396, 321, 486, 976, 300, 281, 364, 21601, 47, 11, 257, 4825, 12, 8376, 260, 50892, 50892, 43276, 2044, 11, 293, 309, 486, 976, 505, 257, 6175, 597, 393, 312, 257, 39684, 498, 321, 366, 884, 512, 4295, 51152, 51152, 24590, 411, 7313, 4707, 35701, 11, 420, 309, 393, 312, 21538, 498, 321, 366, 1382, 281, 33872, 51644, 51644], "temperature": 0.0, "avg_logprob": -0.201909487588065, "compression_ratio": 1.5833333333333333, "no_speech_prob": 3.386624302947894e-05}, {"id": 787, "seek": 539660, "start": 5412.360000000001, "end": 5422.200000000001, "text": " regression like chemical property estimation, or it can be classification if we are trying to classify", "tokens": [50364, 257, 10290, 295, 264, 4295, 295, 274, 10139, 13, 1396, 321, 486, 976, 300, 281, 364, 21601, 47, 11, 257, 4825, 12, 8376, 260, 50892, 50892, 43276, 2044, 11, 293, 309, 486, 976, 505, 257, 6175, 597, 393, 312, 257, 39684, 498, 321, 366, 884, 512, 4295, 51152, 51152, 24590, 411, 7313, 4707, 35701, 11, 420, 309, 393, 312, 21538, 498, 321, 366, 1382, 281, 33872, 51644, 51644], "temperature": 0.0, "avg_logprob": -0.201909487588065, "compression_ratio": 1.5833333333333333, "no_speech_prob": 3.386624302947894e-05}, {"id": 788, "seek": 542220, "start": 5422.2, "end": 5431.5599999999995, "text": " molecules to some classes. We can also have a node-level prediction. What we will do is that we", "tokens": [50364, 13093, 281, 512, 5359, 13, 492, 393, 611, 362, 257, 9984, 12, 12418, 17630, 13, 708, 321, 486, 360, 307, 300, 321, 50832, 50832, 486, 747, 264, 9984, 10290, 412, 264, 5598, 295, 264, 4295, 18161, 3209, 293, 321, 486, 976, 300, 51156, 51156, 281, 364, 21601, 47, 293, 321, 486, 483, 257, 6175, 337, 264, 9984, 741, 11, 597, 393, 312, 257, 39684, 337, 24590, 420, 393, 312, 257, 51496, 51496], "temperature": 0.0, "avg_logprob": -0.11644547694438212, "compression_ratio": 1.6497175141242937, "no_speech_prob": 9.056385351868812e-06}, {"id": 789, "seek": 542220, "start": 5431.5599999999995, "end": 5438.04, "text": " will take the node representation at the output of the graph neural network and we will give that", "tokens": [50364, 13093, 281, 512, 5359, 13, 492, 393, 611, 362, 257, 9984, 12, 12418, 17630, 13, 708, 321, 486, 360, 307, 300, 321, 50832, 50832, 486, 747, 264, 9984, 10290, 412, 264, 5598, 295, 264, 4295, 18161, 3209, 293, 321, 486, 976, 300, 51156, 51156, 281, 364, 21601, 47, 293, 321, 486, 483, 257, 6175, 337, 264, 9984, 741, 11, 597, 393, 312, 257, 39684, 337, 24590, 420, 393, 312, 257, 51496, 51496], "temperature": 0.0, "avg_logprob": -0.11644547694438212, "compression_ratio": 1.6497175141242937, "no_speech_prob": 9.056385351868812e-06}, {"id": 790, "seek": 542220, "start": 5438.04, "end": 5444.84, "text": " to an MLP and we will get a score for the node i, which can be a scalar for regression or can be a", "tokens": [50364, 13093, 281, 512, 5359, 13, 492, 393, 611, 362, 257, 9984, 12, 12418, 17630, 13, 708, 321, 486, 360, 307, 300, 321, 50832, 50832, 486, 747, 264, 9984, 10290, 412, 264, 5598, 295, 264, 4295, 18161, 3209, 293, 321, 486, 976, 300, 51156, 51156, 281, 364, 21601, 47, 293, 321, 486, 483, 257, 6175, 337, 264, 9984, 741, 11, 597, 393, 312, 257, 39684, 337, 24590, 420, 393, 312, 257, 51496, 51496], "temperature": 0.0, "avg_logprob": -0.11644547694438212, "compression_ratio": 1.6497175141242937, "no_speech_prob": 9.056385351868812e-06}, {"id": 791, "seek": 544484, "start": 5444.84, "end": 5454.12, "text": " k-dimensional vector for classification. We can also do edge-level prediction. We have a link", "tokens": [50364, 350, 12, 18759, 8062, 337, 21538, 13, 492, 393, 611, 360, 4691, 12, 12418, 17630, 13, 492, 362, 257, 2113, 50828, 50872, 1296, 9984, 741, 293, 9984, 361, 13, 467, 311, 516, 281, 312, 257, 1588, 7186, 399, 295, 264, 4295, 18161, 3209, 51200, 51256, 10290, 337, 9984, 741, 293, 9984, 361, 13, 492, 976, 300, 281, 364, 21601, 47, 293, 797, 11, 321, 1116, 362, 257, 6175, 337, 51520, 51520, 264, 2113, 1296, 9984, 741, 293, 9984, 361, 293, 309, 393, 312, 24590, 420, 21538, 13, 51716, 51808], "temperature": 0.0, "avg_logprob": -0.10521051385900476, "compression_ratio": 1.7878787878787878, "no_speech_prob": 4.8369853175245225e-05}, {"id": 792, "seek": 544484, "start": 5455.0, "end": 5461.56, "text": " between node i and node j. It's going to be a concatenation of the graph neural network", "tokens": [50364, 350, 12, 18759, 8062, 337, 21538, 13, 492, 393, 611, 360, 4691, 12, 12418, 17630, 13, 492, 362, 257, 2113, 50828, 50872, 1296, 9984, 741, 293, 9984, 361, 13, 467, 311, 516, 281, 312, 257, 1588, 7186, 399, 295, 264, 4295, 18161, 3209, 51200, 51256, 10290, 337, 9984, 741, 293, 9984, 361, 13, 492, 976, 300, 281, 364, 21601, 47, 293, 797, 11, 321, 1116, 362, 257, 6175, 337, 51520, 51520, 264, 2113, 1296, 9984, 741, 293, 9984, 361, 293, 309, 393, 312, 24590, 420, 21538, 13, 51716, 51808], "temperature": 0.0, "avg_logprob": -0.10521051385900476, "compression_ratio": 1.7878787878787878, "no_speech_prob": 4.8369853175245225e-05}, {"id": 793, "seek": 544484, "start": 5462.68, "end": 5467.96, "text": " representation for node i and node j. We give that to an MLP and again, we'd have a score for", "tokens": [50364, 350, 12, 18759, 8062, 337, 21538, 13, 492, 393, 611, 360, 4691, 12, 12418, 17630, 13, 492, 362, 257, 2113, 50828, 50872, 1296, 9984, 741, 293, 9984, 361, 13, 467, 311, 516, 281, 312, 257, 1588, 7186, 399, 295, 264, 4295, 18161, 3209, 51200, 51256, 10290, 337, 9984, 741, 293, 9984, 361, 13, 492, 976, 300, 281, 364, 21601, 47, 293, 797, 11, 321, 1116, 362, 257, 6175, 337, 51520, 51520, 264, 2113, 1296, 9984, 741, 293, 9984, 361, 293, 309, 393, 312, 24590, 420, 21538, 13, 51716, 51808], "temperature": 0.0, "avg_logprob": -0.10521051385900476, "compression_ratio": 1.7878787878787878, "no_speech_prob": 4.8369853175245225e-05}, {"id": 794, "seek": 544484, "start": 5467.96, "end": 5471.88, "text": " the link between node i and node j and it can be regression or classification.", "tokens": [50364, 350, 12, 18759, 8062, 337, 21538, 13, 492, 393, 611, 360, 4691, 12, 12418, 17630, 13, 492, 362, 257, 2113, 50828, 50872, 1296, 9984, 741, 293, 9984, 361, 13, 467, 311, 516, 281, 312, 257, 1588, 7186, 399, 295, 264, 4295, 18161, 3209, 51200, 51256, 10290, 337, 9984, 741, 293, 9984, 361, 13, 492, 976, 300, 281, 364, 21601, 47, 293, 797, 11, 321, 1116, 362, 257, 6175, 337, 51520, 51520, 264, 2113, 1296, 9984, 741, 293, 9984, 361, 293, 309, 393, 312, 24590, 420, 21538, 13, 51716, 51808], "temperature": 0.0, "avg_logprob": -0.10521051385900476, "compression_ratio": 1.7878787878787878, "no_speech_prob": 4.8369853175245225e-05}, {"id": 795, "seek": 547188, "start": 5471.88, "end": 5479.08, "text": " Quickly, because I'm running out of time, you have the graph classification task,", "tokens": [50364, 31800, 11, 570, 286, 478, 2614, 484, 295, 565, 11, 291, 362, 264, 4295, 21538, 5633, 11, 50724, 50724, 264, 4295, 24590, 5633, 11, 2597, 13, 639, 307, 337, 13093, 13, 1692, 321, 528, 281, 6069, 264, 19046, 51064, 51064, 1404, 836, 1140, 13, 1692, 291, 362, 264, 3199, 13, 639, 307, 623, 77, 19634, 29435, 45, 13, 492, 500, 380, 764, 604, 4295, 3877, 13, 51512, 51564], "temperature": 0.0, "avg_logprob": -0.1916572025844029, "compression_ratio": 1.5371428571428571, "no_speech_prob": 3.366606688359752e-05}, {"id": 796, "seek": 547188, "start": 5479.08, "end": 5485.88, "text": " the graph regression task, sorry. This is for molecules. Here we want to predict the molecular", "tokens": [50364, 31800, 11, 570, 286, 478, 2614, 484, 295, 565, 11, 291, 362, 264, 4295, 21538, 5633, 11, 50724, 50724, 264, 4295, 24590, 5633, 11, 2597, 13, 639, 307, 337, 13093, 13, 1692, 321, 528, 281, 6069, 264, 19046, 51064, 51064, 1404, 836, 1140, 13, 1692, 291, 362, 264, 3199, 13, 639, 307, 623, 77, 19634, 29435, 45, 13, 492, 500, 380, 764, 604, 4295, 3877, 13, 51512, 51564], "temperature": 0.0, "avg_logprob": -0.1916572025844029, "compression_ratio": 1.5371428571428571, "no_speech_prob": 3.366606688359752e-05}, {"id": 797, "seek": 547188, "start": 5485.88, "end": 5494.84, "text": " solubility. Here you have the table. This is agnostic GCN. We don't use any graph structure.", "tokens": [50364, 31800, 11, 570, 286, 478, 2614, 484, 295, 565, 11, 291, 362, 264, 4295, 21538, 5633, 11, 50724, 50724, 264, 4295, 24590, 5633, 11, 2597, 13, 639, 307, 337, 13093, 13, 1692, 321, 528, 281, 6069, 264, 19046, 51064, 51064, 1404, 836, 1140, 13, 1692, 291, 362, 264, 3199, 13, 639, 307, 623, 77, 19634, 29435, 45, 13, 492, 500, 380, 764, 604, 4295, 3877, 13, 51512, 51564], "temperature": 0.0, "avg_logprob": -0.1916572025844029, "compression_ratio": 1.5371428571428571, "no_speech_prob": 3.366606688359752e-05}, {"id": 798, "seek": 549484, "start": 5494.84, "end": 5503.96, "text": " The lower, the better. Here this is isotropic GCN and this is anisotropic GCN. Usually you will see", "tokens": [50364, 440, 3126, 11, 264, 1101, 13, 1692, 341, 307, 38018, 39173, 29435, 45, 293, 341, 307, 364, 271, 310, 39173, 29435, 45, 13, 11419, 291, 486, 536, 50820, 50820, 300, 337, 881, 12050, 11, 364, 271, 310, 39173, 29435, 45, 360, 1101, 1691, 813, 38018, 39173, 29435, 45, 570, 291, 764, 51280, 51280, 512, 42242, 4707, 13, 639, 307, 337, 4295, 24590, 13, 639, 307, 337, 4295, 21538, 13, 51604, 51604], "temperature": 0.0, "avg_logprob": -0.1457267656718215, "compression_ratio": 1.688622754491018, "no_speech_prob": 1.277127921639476e-05}, {"id": 799, "seek": 549484, "start": 5503.96, "end": 5513.16, "text": " that for most experiments, anisotropic GCN do better job than isotropic GCN because you use", "tokens": [50364, 440, 3126, 11, 264, 1101, 13, 1692, 341, 307, 38018, 39173, 29435, 45, 293, 341, 307, 364, 271, 310, 39173, 29435, 45, 13, 11419, 291, 486, 536, 50820, 50820, 300, 337, 881, 12050, 11, 364, 271, 310, 39173, 29435, 45, 360, 1101, 1691, 813, 38018, 39173, 29435, 45, 570, 291, 764, 51280, 51280, 512, 42242, 4707, 13, 639, 307, 337, 4295, 24590, 13, 639, 307, 337, 4295, 21538, 13, 51604, 51604], "temperature": 0.0, "avg_logprob": -0.1457267656718215, "compression_ratio": 1.688622754491018, "no_speech_prob": 1.277127921639476e-05}, {"id": 800, "seek": 549484, "start": 5513.16, "end": 5519.64, "text": " some directional property. This is for graph regression. This is for graph classification.", "tokens": [50364, 440, 3126, 11, 264, 1101, 13, 1692, 341, 307, 38018, 39173, 29435, 45, 293, 341, 307, 364, 271, 310, 39173, 29435, 45, 13, 11419, 291, 486, 536, 50820, 50820, 300, 337, 881, 12050, 11, 364, 271, 310, 39173, 29435, 45, 360, 1101, 1691, 813, 38018, 39173, 29435, 45, 570, 291, 764, 51280, 51280, 512, 42242, 4707, 13, 639, 307, 337, 4295, 24590, 13, 639, 307, 337, 4295, 21538, 13, 51604, 51604], "temperature": 0.0, "avg_logprob": -0.1457267656718215, "compression_ratio": 1.688622754491018, "no_speech_prob": 1.277127921639476e-05}, {"id": 801, "seek": 551964, "start": 5519.64, "end": 5528.4400000000005, "text": " You have supernodes of images and you want to classify the image to belong to one of the", "tokens": [50364, 509, 362, 1687, 77, 4789, 295, 5267, 293, 291, 528, 281, 33872, 264, 3256, 281, 5784, 281, 472, 295, 264, 50804, 50804, 5359, 13, 509, 611, 362, 4691, 21538, 13, 639, 307, 510, 264, 2512, 31927, 831, 19618, 1154, 295, 51288, 51288, 314, 27921, 11, 370, 264, 9712, 5763, 1601, 1154, 13, 509, 362, 257, 4295, 293, 550, 291, 528, 281, 458, 498, 341, 4691, 51600, 51600, 12953, 281, 264, 3827, 13, 759, 309, 12953, 281, 257, 3827, 11, 341, 307, 257, 1508, 472, 13, 759, 309, 1177, 380, 51828, 51828], "temperature": 0.0, "avg_logprob": -0.0974880854288737, "compression_ratio": 1.7630331753554502, "no_speech_prob": 2.07253142434638e-05}, {"id": 802, "seek": 551964, "start": 5528.4400000000005, "end": 5538.12, "text": " classes. You also have edge classification. This is here the combinatorial optimization problem of", "tokens": [50364, 509, 362, 1687, 77, 4789, 295, 5267, 293, 291, 528, 281, 33872, 264, 3256, 281, 5784, 281, 472, 295, 264, 50804, 50804, 5359, 13, 509, 611, 362, 4691, 21538, 13, 639, 307, 510, 264, 2512, 31927, 831, 19618, 1154, 295, 51288, 51288, 314, 27921, 11, 370, 264, 9712, 5763, 1601, 1154, 13, 509, 362, 257, 4295, 293, 550, 291, 528, 281, 458, 498, 341, 4691, 51600, 51600, 12953, 281, 264, 3827, 13, 759, 309, 12953, 281, 257, 3827, 11, 341, 307, 257, 1508, 472, 13, 759, 309, 1177, 380, 51828, 51828], "temperature": 0.0, "avg_logprob": -0.0974880854288737, "compression_ratio": 1.7630331753554502, "no_speech_prob": 2.07253142434638e-05}, {"id": 803, "seek": 551964, "start": 5538.12, "end": 5544.360000000001, "text": " TSP, so the traveling salesman problem. You have a graph and then you want to know if this edge", "tokens": [50364, 509, 362, 1687, 77, 4789, 295, 5267, 293, 291, 528, 281, 33872, 264, 3256, 281, 5784, 281, 472, 295, 264, 50804, 50804, 5359, 13, 509, 611, 362, 4691, 21538, 13, 639, 307, 510, 264, 2512, 31927, 831, 19618, 1154, 295, 51288, 51288, 314, 27921, 11, 370, 264, 9712, 5763, 1601, 1154, 13, 509, 362, 257, 4295, 293, 550, 291, 528, 281, 458, 498, 341, 4691, 51600, 51600, 12953, 281, 264, 3827, 13, 759, 309, 12953, 281, 257, 3827, 11, 341, 307, 257, 1508, 472, 13, 759, 309, 1177, 380, 51828, 51828], "temperature": 0.0, "avg_logprob": -0.0974880854288737, "compression_ratio": 1.7630331753554502, "no_speech_prob": 2.07253142434638e-05}, {"id": 804, "seek": 551964, "start": 5544.360000000001, "end": 5548.92, "text": " belongs to the solution. If it belongs to a solution, this is a class one. If it doesn't", "tokens": [50364, 509, 362, 1687, 77, 4789, 295, 5267, 293, 291, 528, 281, 33872, 264, 3256, 281, 5784, 281, 472, 295, 264, 50804, 50804, 5359, 13, 509, 611, 362, 4691, 21538, 13, 639, 307, 510, 264, 2512, 31927, 831, 19618, 1154, 295, 51288, 51288, 314, 27921, 11, 370, 264, 9712, 5763, 1601, 1154, 13, 509, 362, 257, 4295, 293, 550, 291, 528, 281, 458, 498, 341, 4691, 51600, 51600, 12953, 281, 264, 3827, 13, 759, 309, 12953, 281, 257, 3827, 11, 341, 307, 257, 1508, 472, 13, 759, 309, 1177, 380, 51828, 51828], "temperature": 0.0, "avg_logprob": -0.0974880854288737, "compression_ratio": 1.7630331753554502, "no_speech_prob": 2.07253142434638e-05}, {"id": 805, "seek": 554892, "start": 5548.92, "end": 5554.92, "text": " belong, this is class zero. We see that here you need explicit edge feature. You see that the only", "tokens": [50364, 5784, 11, 341, 307, 1508, 4018, 13, 492, 536, 300, 510, 291, 643, 13691, 4691, 4111, 13, 509, 536, 300, 264, 787, 50664, 50664, 2316, 300, 775, 257, 665, 1691, 5347, 281, 264, 29052, 415, 374, 3142, 307, 538, 1228, 13691, 4691, 4111, 13, 51048, 51164, 1692, 286, 478, 1228, 341, 2512, 31927, 831, 1365, 281, 652, 257, 13541, 12847, 13, 639, 307, 611, 437, 321, 51440, 51440], "temperature": 0.0, "avg_logprob": -0.08505831445966448, "compression_ratio": 1.5567567567567568, "no_speech_prob": 3.0245819289120845e-05}, {"id": 806, "seek": 554892, "start": 5554.92, "end": 5562.6, "text": " model that does a good job compared to the naive heuristic is by using explicit edge feature.", "tokens": [50364, 5784, 11, 341, 307, 1508, 4018, 13, 492, 536, 300, 510, 291, 643, 13691, 4691, 4111, 13, 509, 536, 300, 264, 787, 50664, 50664, 2316, 300, 775, 257, 665, 1691, 5347, 281, 264, 29052, 415, 374, 3142, 307, 538, 1228, 13691, 4691, 4111, 13, 51048, 51164, 1692, 286, 478, 1228, 341, 2512, 31927, 831, 1365, 281, 652, 257, 13541, 12847, 13, 639, 307, 611, 437, 321, 51440, 51440], "temperature": 0.0, "avg_logprob": -0.08505831445966448, "compression_ratio": 1.5567567567567568, "no_speech_prob": 3.0245819289120845e-05}, {"id": 807, "seek": 554892, "start": 5564.92, "end": 5570.4400000000005, "text": " Here I'm using this combinatorial example to make a workshop announcement. This is also what we", "tokens": [50364, 5784, 11, 341, 307, 1508, 4018, 13, 492, 536, 300, 510, 291, 643, 13691, 4691, 4111, 13, 509, 536, 300, 264, 787, 50664, 50664, 2316, 300, 775, 257, 665, 1691, 5347, 281, 264, 29052, 415, 374, 3142, 307, 538, 1228, 13691, 4691, 4111, 13, 51048, 51164, 1692, 286, 478, 1228, 341, 2512, 31927, 831, 1365, 281, 652, 257, 13541, 12847, 13, 639, 307, 611, 437, 321, 51440, 51440], "temperature": 0.0, "avg_logprob": -0.08505831445966448, "compression_ratio": 1.5567567567567568, "no_speech_prob": 3.0245819289120845e-05}, {"id": 808, "seek": 557044, "start": 5570.44, "end": 5580.679999999999, "text": " are organizing next year with Yan and also Peter, Stephanie, Andrea, Stan, and Max. We're organizing", "tokens": [50364, 366, 17608, 958, 1064, 365, 13633, 293, 611, 6508, 11, 18634, 11, 24215, 11, 10061, 11, 293, 7402, 13, 492, 434, 17608, 50876, 50876, 257, 13541, 322, 21928, 2452, 2539, 293, 2512, 31927, 831, 19618, 11, 597, 286, 519, 51060, 51060, 307, 257, 588, 1880, 3513, 295, 2132, 13, 1033, 11, 10063, 13, 492, 44498, 264, 3754, 2533, 51456, 51456, 281, 1412, 322, 24877, 13, 1171, 341, 11, 321, 2978, 281, 39853, 257, 45216, 12973, 322, 24877, 13, 492, 360, 300, 337, 51820, 51820], "temperature": 0.0, "avg_logprob": -0.2454930904299714, "compression_ratio": 1.5690376569037656, "no_speech_prob": 8.642413376946934e-06}, {"id": 809, "seek": 557044, "start": 5580.679999999999, "end": 5584.36, "text": " a workshop on combining deep learning and combinatorial optimization, which I think", "tokens": [50364, 366, 17608, 958, 1064, 365, 13633, 293, 611, 6508, 11, 18634, 11, 24215, 11, 10061, 11, 293, 7402, 13, 492, 434, 17608, 50876, 50876, 257, 13541, 322, 21928, 2452, 2539, 293, 2512, 31927, 831, 19618, 11, 597, 286, 519, 51060, 51060, 307, 257, 588, 1880, 3513, 295, 2132, 13, 1033, 11, 10063, 13, 492, 44498, 264, 3754, 2533, 51456, 51456, 281, 1412, 322, 24877, 13, 1171, 341, 11, 321, 2978, 281, 39853, 257, 45216, 12973, 322, 24877, 13, 492, 360, 300, 337, 51820, 51820], "temperature": 0.0, "avg_logprob": -0.2454930904299714, "compression_ratio": 1.5690376569037656, "no_speech_prob": 8.642413376946934e-06}, {"id": 810, "seek": 557044, "start": 5584.36, "end": 5592.28, "text": " is a very interesting direction of research. Okay, conclusion. We generalized the conv net", "tokens": [50364, 366, 17608, 958, 1064, 365, 13633, 293, 611, 6508, 11, 18634, 11, 24215, 11, 10061, 11, 293, 7402, 13, 492, 434, 17608, 50876, 50876, 257, 13541, 322, 21928, 2452, 2539, 293, 2512, 31927, 831, 19618, 11, 597, 286, 519, 51060, 51060, 307, 257, 588, 1880, 3513, 295, 2132, 13, 1033, 11, 10063, 13, 492, 44498, 264, 3754, 2533, 51456, 51456, 281, 1412, 322, 24877, 13, 1171, 341, 11, 321, 2978, 281, 39853, 257, 45216, 12973, 322, 24877, 13, 492, 360, 300, 337, 51820, 51820], "temperature": 0.0, "avg_logprob": -0.2454930904299714, "compression_ratio": 1.5690376569037656, "no_speech_prob": 8.642413376946934e-06}, {"id": 811, "seek": 557044, "start": 5592.28, "end": 5599.5599999999995, "text": " to data on graphs. For this, we needed to redesign a convolution operator on graphs. We do that for", "tokens": [50364, 366, 17608, 958, 1064, 365, 13633, 293, 611, 6508, 11, 18634, 11, 24215, 11, 10061, 11, 293, 7402, 13, 492, 434, 17608, 50876, 50876, 257, 13541, 322, 21928, 2452, 2539, 293, 2512, 31927, 831, 19618, 11, 597, 286, 519, 51060, 51060, 307, 257, 588, 1880, 3513, 295, 2132, 13, 1033, 11, 10063, 13, 492, 44498, 264, 3754, 2533, 51456, 51456, 281, 1412, 322, 24877, 13, 1171, 341, 11, 321, 2978, 281, 39853, 257, 45216, 12973, 322, 24877, 13, 492, 360, 300, 337, 51820, 51820], "temperature": 0.0, "avg_logprob": -0.2454930904299714, "compression_ratio": 1.5690376569037656, "no_speech_prob": 8.642413376946934e-06}, {"id": 812, "seek": 559956, "start": 5599.56, "end": 5607.0, "text": " template matching, which lead to the class of spatial GCN. We also did that with spectral", "tokens": [50364, 12379, 14324, 11, 597, 1477, 281, 264, 1508, 295, 23598, 29435, 45, 13, 492, 611, 630, 300, 365, 42761, 50736, 50736, 45216, 11, 597, 1477, 281, 264, 1508, 295, 42761, 45216, 11, 42761, 29435, 45, 13, 492, 362, 8213, 14024, 51084, 51084, 337, 957, 1002, 24877, 13, 492, 362, 18407, 11420, 11, 457, 1939, 309, 311, 406, 26941, 337, 264, 18407, 300, 321, 51432, 51432, 362, 965, 13, 492, 362, 11455, 2539, 6042, 11, 370, 341, 307, 264, 5162, 20864, 1985, 13, 51692, 51748], "temperature": 0.0, "avg_logprob": -0.11862629513407863, "compression_ratio": 1.7546296296296295, "no_speech_prob": 2.7886040697922e-05}, {"id": 813, "seek": 559956, "start": 5607.0, "end": 5613.96, "text": " convolution, which lead to the class of spectral convolution, spectral GCN. We have linear complexity", "tokens": [50364, 12379, 14324, 11, 597, 1477, 281, 264, 1508, 295, 23598, 29435, 45, 13, 492, 611, 630, 300, 365, 42761, 50736, 50736, 45216, 11, 597, 1477, 281, 264, 1508, 295, 42761, 45216, 11, 42761, 29435, 45, 13, 492, 362, 8213, 14024, 51084, 51084, 337, 957, 1002, 24877, 13, 492, 362, 18407, 11420, 11, 457, 1939, 309, 311, 406, 26941, 337, 264, 18407, 300, 321, 51432, 51432, 362, 965, 13, 492, 362, 11455, 2539, 6042, 11, 370, 341, 307, 264, 5162, 20864, 1985, 13, 51692, 51748], "temperature": 0.0, "avg_logprob": -0.11862629513407863, "compression_ratio": 1.7546296296296295, "no_speech_prob": 2.7886040697922e-05}, {"id": 814, "seek": 559956, "start": 5613.96, "end": 5620.92, "text": " for real world graphs. We have GPU implementation, but yet it's not optimized for the GPU that we", "tokens": [50364, 12379, 14324, 11, 597, 1477, 281, 264, 1508, 295, 23598, 29435, 45, 13, 492, 611, 630, 300, 365, 42761, 50736, 50736, 45216, 11, 597, 1477, 281, 264, 1508, 295, 42761, 45216, 11, 42761, 29435, 45, 13, 492, 362, 8213, 14024, 51084, 51084, 337, 957, 1002, 24877, 13, 492, 362, 18407, 11420, 11, 457, 1939, 309, 311, 406, 26941, 337, 264, 18407, 300, 321, 51432, 51432, 362, 965, 13, 492, 362, 11455, 2539, 6042, 11, 370, 341, 307, 264, 5162, 20864, 1985, 13, 51692, 51748], "temperature": 0.0, "avg_logprob": -0.11862629513407863, "compression_ratio": 1.7546296296296295, "no_speech_prob": 2.7886040697922e-05}, {"id": 815, "seek": 559956, "start": 5620.92, "end": 5626.120000000001, "text": " have today. We have universal learning capacity, so this is the recent theoretical works.", "tokens": [50364, 12379, 14324, 11, 597, 1477, 281, 264, 1508, 295, 23598, 29435, 45, 13, 492, 611, 630, 300, 365, 42761, 50736, 50736, 45216, 11, 597, 1477, 281, 264, 1508, 295, 42761, 45216, 11, 42761, 29435, 45, 13, 492, 362, 8213, 14024, 51084, 51084, 337, 957, 1002, 24877, 13, 492, 362, 18407, 11420, 11, 457, 1939, 309, 311, 406, 26941, 337, 264, 18407, 300, 321, 51432, 51432, 362, 965, 13, 492, 362, 11455, 2539, 6042, 11, 370, 341, 307, 264, 5162, 20864, 1985, 13, 51692, 51748], "temperature": 0.0, "avg_logprob": -0.11862629513407863, "compression_ratio": 1.7546296296296295, "no_speech_prob": 2.7886040697922e-05}, {"id": 816, "seek": 562612, "start": 5626.12, "end": 5632.92, "text": " We can do that for multiple graphs and also for graphs that can change dynamically. Application,", "tokens": [50364, 492, 393, 360, 300, 337, 3866, 24877, 293, 611, 337, 24877, 300, 393, 1319, 43492, 13, 39512, 11, 50704, 50704, 370, 286, 478, 2055, 586, 300, 286, 500, 380, 643, 281, 20833, 3602, 983, 321, 366, 884, 4295, 45216, 322, 36170, 51028, 51028, 281, 4472, 11, 370, 309, 311, 1242, 544, 293, 544, 3861, 13, 492, 536, 300, 412, 264, 1036, 11, 767, 51428, 51488], "temperature": 0.0, "avg_logprob": -0.2779615032139109, "compression_ratio": 1.5494505494505495, "no_speech_prob": 3.0512139346683398e-05}, {"id": 817, "seek": 562612, "start": 5632.92, "end": 5639.4, "text": " so I'm happy now that I don't need to justify anymore why we are doing graph convolution on nets", "tokens": [50364, 492, 393, 360, 300, 337, 3866, 24877, 293, 611, 337, 24877, 300, 393, 1319, 43492, 13, 39512, 11, 50704, 50704, 370, 286, 478, 2055, 586, 300, 286, 500, 380, 643, 281, 20833, 3602, 983, 321, 366, 884, 4295, 45216, 322, 36170, 51028, 51028, 281, 4472, 11, 370, 309, 311, 1242, 544, 293, 544, 3861, 13, 492, 536, 300, 412, 264, 1036, 11, 767, 51428, 51488], "temperature": 0.0, "avg_logprob": -0.2779615032139109, "compression_ratio": 1.5494505494505495, "no_speech_prob": 3.0512139346683398e-05}, {"id": 818, "seek": 562612, "start": 5639.4, "end": 5647.4, "text": " to anybody, so it's getting more and more application. We see that at the last, actually", "tokens": [50364, 492, 393, 360, 300, 337, 3866, 24877, 293, 611, 337, 24877, 300, 393, 1319, 43492, 13, 39512, 11, 50704, 50704, 370, 286, 478, 2055, 586, 300, 286, 500, 380, 643, 281, 20833, 3602, 983, 321, 366, 884, 4295, 45216, 322, 36170, 51028, 51028, 281, 4472, 11, 370, 309, 311, 1242, 544, 293, 544, 3861, 13, 492, 536, 300, 412, 264, 1036, 11, 767, 51428, 51488], "temperature": 0.0, "avg_logprob": -0.2779615032139109, "compression_ratio": 1.5494505494505495, "no_speech_prob": 3.0512139346683398e-05}, {"id": 819, "seek": 564740, "start": 5647.4, "end": 5656.679999999999, "text": " this week, ICLR conference. The key word that gets the most improvement was graph neural networks.", "tokens": [50364, 341, 1243, 11, 14360, 31722, 7586, 13, 440, 2141, 1349, 300, 2170, 264, 881, 10444, 390, 4295, 18161, 9590, 13, 50828, 50828, 509, 362, 586, 257, 13541, 293, 17616, 322, 4295, 18161, 9590, 412, 867, 295, 264, 1192, 51144, 51176, 2452, 2539, 293, 7318, 22032, 13, 639, 307, 264, 700, 1391, 17616, 322, 4295, 51468, 51496], "temperature": 0.0, "avg_logprob": -0.33734834605249864, "compression_ratio": 1.5662650602409638, "no_speech_prob": 2.090539965138305e-05}, {"id": 820, "seek": 564740, "start": 5656.679999999999, "end": 5663.0, "text": " You have now a workshop and tutorials on graph neural networks at many of the top", "tokens": [50364, 341, 1243, 11, 14360, 31722, 7586, 13, 440, 2141, 1349, 300, 2170, 264, 881, 10444, 390, 4295, 18161, 9590, 13, 50828, 50828, 509, 362, 586, 257, 13541, 293, 17616, 322, 4295, 18161, 9590, 412, 867, 295, 264, 1192, 51144, 51176, 2452, 2539, 293, 7318, 22032, 13, 639, 307, 264, 700, 1391, 17616, 322, 4295, 51468, 51496], "temperature": 0.0, "avg_logprob": -0.33734834605249864, "compression_ratio": 1.5662650602409638, "no_speech_prob": 2.090539965138305e-05}, {"id": 821, "seek": 564740, "start": 5663.639999999999, "end": 5669.48, "text": " deep learning and AI conferences. This is the first probably tutorials on graph", "tokens": [50364, 341, 1243, 11, 14360, 31722, 7586, 13, 440, 2141, 1349, 300, 2170, 264, 881, 10444, 390, 4295, 18161, 9590, 13, 50828, 50828, 509, 362, 586, 257, 13541, 293, 17616, 322, 4295, 18161, 9590, 412, 867, 295, 264, 1192, 51144, 51176, 2452, 2539, 293, 7318, 22032, 13, 639, 307, 264, 700, 1391, 17616, 322, 4295, 51468, 51496], "temperature": 0.0, "avg_logprob": -0.33734834605249864, "compression_ratio": 1.5662650602409638, "no_speech_prob": 2.090539965138305e-05}, {"id": 822, "seek": 566948, "start": 5669.48, "end": 5677.08, "text": " deep learning that we organized at the Norelips in 2017 and CDPR. Also, if you want some materials", "tokens": [50364, 2452, 2539, 300, 321, 9983, 412, 264, 426, 418, 75, 2600, 294, 6591, 293, 6743, 15958, 13, 2743, 11, 498, 291, 528, 512, 5319, 50744, 50744, 281, 574, 544, 11, 321, 362, 341, 12945, 13541, 9983, 294, 6096, 293, 611, 257, 1524, 12, 1010, 294, 6071, 13, 1171, 341, 11, 51228, 51228, 321, 362, 264, 960, 6686, 11, 370, 498, 291, 528, 281, 458, 544, 466, 341, 13, 492, 362, 257, 8388, 337, 13491, 11, 51556, 51556], "temperature": 0.0, "avg_logprob": -0.34493583968923064, "compression_ratio": 1.528497409326425, "no_speech_prob": 2.1728727006120607e-05}, {"id": 823, "seek": 566948, "start": 5677.08, "end": 5686.759999999999, "text": " to look more, we have this iPad workshop organized in 2018 and also a follow-up in 2019. For this,", "tokens": [50364, 2452, 2539, 300, 321, 9983, 412, 264, 426, 418, 75, 2600, 294, 6591, 293, 6743, 15958, 13, 2743, 11, 498, 291, 528, 512, 5319, 50744, 50744, 281, 574, 544, 11, 321, 362, 341, 12945, 13541, 9983, 294, 6096, 293, 611, 257, 1524, 12, 1010, 294, 6071, 13, 1171, 341, 11, 51228, 51228, 321, 362, 264, 960, 6686, 11, 370, 498, 291, 528, 281, 458, 544, 466, 341, 13, 492, 362, 257, 8388, 337, 13491, 11, 51556, 51556], "temperature": 0.0, "avg_logprob": -0.34493583968923064, "compression_ratio": 1.528497409326425, "no_speech_prob": 2.1728727006120607e-05}, {"id": 824, "seek": 566948, "start": 5686.759999999999, "end": 5693.32, "text": " we have the video talks, so if you want to know more about this. We have a framework for writers,", "tokens": [50364, 2452, 2539, 300, 321, 9983, 412, 264, 426, 418, 75, 2600, 294, 6591, 293, 6743, 15958, 13, 2743, 11, 498, 291, 528, 512, 5319, 50744, 50744, 281, 574, 544, 11, 321, 362, 341, 12945, 13541, 9983, 294, 6096, 293, 611, 257, 1524, 12, 1010, 294, 6071, 13, 1171, 341, 11, 51228, 51228, 321, 362, 264, 960, 6686, 11, 370, 498, 291, 528, 281, 458, 544, 466, 341, 13, 492, 362, 257, 8388, 337, 13491, 11, 51556, 51556], "temperature": 0.0, "avg_logprob": -0.34493583968923064, "compression_ratio": 1.528497409326425, "no_speech_prob": 2.1728727006120607e-05}, {"id": 825, "seek": 569332, "start": 5693.32, "end": 5700.759999999999, "text": " so Joshua Benjo, Michael Bronstein, Federico Monti, Chaitaina Joshi, Vijay Diwili,", "tokens": [50364, 370, 24005, 3964, 5134, 11, 5116, 19544, 9089, 11, 45545, 2789, 7947, 72, 11, 761, 1001, 43054, 9785, 72, 11, 41201, 320, 8789, 86, 2312, 11, 50736, 50736, 19344, 11, 8500, 37162, 89, 11, 1587, 2716, 374, 318, 4326, 11, 9949, 1456, 11869, 11, 5116, 1346, 479, 1973, 64, 11, 28461, 15458, 4053, 11, 16943, 318, 1215, 998, 11, 293, 51208, 51208, 13980, 316, 328, 1601, 13, 1044, 291, 13, 51408, 51560, 1044, 291, 13, 467, 390, 534, 8992, 293, 286, 519, 1518, 510, 390, 35394, 538, 264, 3125, 295, 264, 51840, 51840], "temperature": 0.0, "avg_logprob": -0.6229836714895148, "compression_ratio": 1.430622009569378, "no_speech_prob": 0.00013121475058142096}, {"id": 826, "seek": 569332, "start": 5700.759999999999, "end": 5710.2, "text": " Leo, Thomas Lorenz, Arshur Slam, Ron Levy, Michael De Fiora, Pierre Mandela, Eli Sampath, and", "tokens": [50364, 370, 24005, 3964, 5134, 11, 5116, 19544, 9089, 11, 45545, 2789, 7947, 72, 11, 761, 1001, 43054, 9785, 72, 11, 41201, 320, 8789, 86, 2312, 11, 50736, 50736, 19344, 11, 8500, 37162, 89, 11, 1587, 2716, 374, 318, 4326, 11, 9949, 1456, 11869, 11, 5116, 1346, 479, 1973, 64, 11, 28461, 15458, 4053, 11, 16943, 318, 1215, 998, 11, 293, 51208, 51208, 13980, 316, 328, 1601, 13, 1044, 291, 13, 51408, 51560, 1044, 291, 13, 467, 390, 534, 8992, 293, 286, 519, 1518, 510, 390, 35394, 538, 264, 3125, 295, 264, 51840, 51840], "temperature": 0.0, "avg_logprob": -0.6229836714895148, "compression_ratio": 1.430622009569378, "no_speech_prob": 0.00013121475058142096}, {"id": 827, "seek": 569332, "start": 5710.2, "end": 5714.2, "text": " Patrick Aigman. Thank you.", "tokens": [50364, 370, 24005, 3964, 5134, 11, 5116, 19544, 9089, 11, 45545, 2789, 7947, 72, 11, 761, 1001, 43054, 9785, 72, 11, 41201, 320, 8789, 86, 2312, 11, 50736, 50736, 19344, 11, 8500, 37162, 89, 11, 1587, 2716, 374, 318, 4326, 11, 9949, 1456, 11869, 11, 5116, 1346, 479, 1973, 64, 11, 28461, 15458, 4053, 11, 16943, 318, 1215, 998, 11, 293, 51208, 51208, 13980, 316, 328, 1601, 13, 1044, 291, 13, 51408, 51560, 1044, 291, 13, 467, 390, 534, 8992, 293, 286, 519, 1518, 510, 390, 35394, 538, 264, 3125, 295, 264, 51840, 51840], "temperature": 0.0, "avg_logprob": -0.6229836714895148, "compression_ratio": 1.430622009569378, "no_speech_prob": 0.00013121475058142096}, {"id": 828, "seek": 569332, "start": 5717.24, "end": 5722.84, "text": " Thank you. It was really impressive and I think everyone here was stunned by the quality of the", "tokens": [50364, 370, 24005, 3964, 5134, 11, 5116, 19544, 9089, 11, 45545, 2789, 7947, 72, 11, 761, 1001, 43054, 9785, 72, 11, 41201, 320, 8789, 86, 2312, 11, 50736, 50736, 19344, 11, 8500, 37162, 89, 11, 1587, 2716, 374, 318, 4326, 11, 9949, 1456, 11869, 11, 5116, 1346, 479, 1973, 64, 11, 28461, 15458, 4053, 11, 16943, 318, 1215, 998, 11, 293, 51208, 51208, 13980, 316, 328, 1601, 13, 1044, 291, 13, 51408, 51560, 1044, 291, 13, 467, 390, 534, 8992, 293, 286, 519, 1518, 510, 390, 35394, 538, 264, 3125, 295, 264, 51840, 51840], "temperature": 0.0, "avg_logprob": -0.6229836714895148, "compression_ratio": 1.430622009569378, "no_speech_prob": 0.00013121475058142096}, {"id": 829, "seek": 572284, "start": 5722.84, "end": 5728.04, "text": " slides and your explanations. We really, really enjoyed it. I'm getting so many private messages", "tokens": [50364, 9788, 293, 428, 28708, 13, 492, 534, 11, 534, 4626, 309, 13, 286, 478, 1242, 370, 867, 4551, 7897, 50624, 50624, 510, 13, 5198, 311, 1238, 2919, 13, 286, 362, 767, 257, 1326, 1651, 498, 291, 362, 512, 565, 1411, 13, 51076, 51180, 492, 2378, 380, 2825, 466, 1337, 1166, 5245, 13, 1144, 291, 362, 604, 2283, 466, 577, 321, 393, 11, 337, 1365, 11, 51528, 51528], "temperature": 0.0, "avg_logprob": -0.10944602109383846, "compression_ratio": 1.4690721649484537, "no_speech_prob": 0.00026871165027841926}, {"id": 830, "seek": 572284, "start": 5728.04, "end": 5737.08, "text": " here. Everyone's pretty excited. I have actually a few questions if you have some time left.", "tokens": [50364, 9788, 293, 428, 28708, 13, 492, 534, 11, 534, 4626, 309, 13, 286, 478, 1242, 370, 867, 4551, 7897, 50624, 50624, 510, 13, 5198, 311, 1238, 2919, 13, 286, 362, 767, 257, 1326, 1651, 498, 291, 362, 512, 565, 1411, 13, 51076, 51180, 492, 2378, 380, 2825, 466, 1337, 1166, 5245, 13, 1144, 291, 362, 604, 2283, 466, 577, 321, 393, 11, 337, 1365, 11, 51528, 51528], "temperature": 0.0, "avg_logprob": -0.10944602109383846, "compression_ratio": 1.4690721649484537, "no_speech_prob": 0.00026871165027841926}, {"id": 831, "seek": 572284, "start": 5739.16, "end": 5746.12, "text": " We haven't talked about generative models. Do you have any words about how we can, for example,", "tokens": [50364, 9788, 293, 428, 28708, 13, 492, 534, 11, 534, 4626, 309, 13, 286, 478, 1242, 370, 867, 4551, 7897, 50624, 50624, 510, 13, 5198, 311, 1238, 2919, 13, 286, 362, 767, 257, 1326, 1651, 498, 291, 362, 512, 565, 1411, 13, 51076, 51180, 492, 2378, 380, 2825, 466, 1337, 1166, 5245, 13, 1144, 291, 362, 604, 2283, 466, 577, 321, 393, 11, 337, 1365, 11, 51528, 51528], "temperature": 0.0, "avg_logprob": -0.10944602109383846, "compression_ratio": 1.4690721649484537, "no_speech_prob": 0.00026871165027841926}, {"id": 832, "seek": 574612, "start": 5746.12, "end": 5754.84, "text": " generate new proteins for figuring out whether we can find a cure for this COVID right now?", "tokens": [50364, 8460, 777, 15577, 337, 15213, 484, 1968, 321, 393, 915, 257, 13698, 337, 341, 4566, 558, 586, 30, 50800, 50868, 5135, 11, 577, 360, 291, 584, 11, 2190, 1168, 337, 264, 2190, 1002, 13, 51044, 51096, 865, 11, 3122, 13, 440, 1768, 307, 611, 1364, 322, 264, 4295, 1337, 1166, 5245, 13, 509, 362, 732, 51456, 51456, 11095, 13, 440, 700, 3513, 11, 291, 393, 360, 309, 294, 257, 20560, 488, 636, 13, 708, 291, 434, 516, 281, 360, 307, 300, 51768, 51768], "temperature": 0.0, "avg_logprob": -0.12118898279526655, "compression_ratio": 1.5374449339207048, "no_speech_prob": 7.833266136003658e-05}, {"id": 833, "seek": 574612, "start": 5756.2, "end": 5759.72, "text": " Actually, how do you say, current question for the current world.", "tokens": [50364, 8460, 777, 15577, 337, 15213, 484, 1968, 321, 393, 915, 257, 13698, 337, 341, 4566, 558, 586, 30, 50800, 50868, 5135, 11, 577, 360, 291, 584, 11, 2190, 1168, 337, 264, 2190, 1002, 13, 51044, 51096, 865, 11, 3122, 13, 440, 1768, 307, 611, 1364, 322, 264, 4295, 1337, 1166, 5245, 13, 509, 362, 732, 51456, 51456, 11095, 13, 440, 700, 3513, 11, 291, 393, 360, 309, 294, 257, 20560, 488, 636, 13, 708, 291, 434, 516, 281, 360, 307, 300, 51768, 51768], "temperature": 0.0, "avg_logprob": -0.12118898279526655, "compression_ratio": 1.5374449339207048, "no_speech_prob": 7.833266136003658e-05}, {"id": 834, "seek": 574612, "start": 5760.76, "end": 5767.96, "text": " Yeah, absolutely. The community is also working on the graph generative models. You have two", "tokens": [50364, 8460, 777, 15577, 337, 15213, 484, 1968, 321, 393, 915, 257, 13698, 337, 341, 4566, 558, 586, 30, 50800, 50868, 5135, 11, 577, 360, 291, 584, 11, 2190, 1168, 337, 264, 2190, 1002, 13, 51044, 51096, 865, 11, 3122, 13, 440, 1768, 307, 611, 1364, 322, 264, 4295, 1337, 1166, 5245, 13, 509, 362, 732, 51456, 51456, 11095, 13, 440, 700, 3513, 11, 291, 393, 360, 309, 294, 257, 20560, 488, 636, 13, 708, 291, 434, 516, 281, 360, 307, 300, 51768, 51768], "temperature": 0.0, "avg_logprob": -0.12118898279526655, "compression_ratio": 1.5374449339207048, "no_speech_prob": 7.833266136003658e-05}, {"id": 835, "seek": 574612, "start": 5767.96, "end": 5774.2, "text": " directions. The first direction, you can do it in a recursive way. What you're going to do is that", "tokens": [50364, 8460, 777, 15577, 337, 15213, 484, 1968, 321, 393, 915, 257, 13698, 337, 341, 4566, 558, 586, 30, 50800, 50868, 5135, 11, 577, 360, 291, 584, 11, 2190, 1168, 337, 264, 2190, 1002, 13, 51044, 51096, 865, 11, 3122, 13, 440, 1768, 307, 611, 1364, 322, 264, 4295, 1337, 1166, 5245, 13, 509, 362, 732, 51456, 51456, 11095, 13, 440, 700, 3513, 11, 291, 393, 360, 309, 294, 257, 20560, 488, 636, 13, 708, 291, 434, 516, 281, 360, 307, 300, 51768, 51768], "temperature": 0.0, "avg_logprob": -0.12118898279526655, "compression_ratio": 1.5374449339207048, "no_speech_prob": 7.833266136003658e-05}, {"id": 836, "seek": 577420, "start": 5774.2, "end": 5780.679999999999, "text": " you are creating your molecule atom after atom. You start with an atom, then you will have a", "tokens": [50364, 291, 366, 4084, 428, 15582, 12018, 934, 12018, 13, 509, 722, 365, 364, 12018, 11, 550, 291, 486, 362, 257, 50688, 50688, 11532, 337, 264, 958, 12018, 293, 611, 264, 958, 5472, 1296, 264, 732, 16871, 13, 509, 393, 360, 300, 13, 50964, 50964, 467, 311, 257, 441, 6840, 44, 3758, 13, 440, 1150, 3513, 307, 281, 360, 309, 294, 472, 3347, 13, 509, 643, 257, 3209, 300, 393, 51468, 51656], "temperature": 0.0, "avg_logprob": -0.10307474658913808, "compression_ratio": 1.521978021978022, "no_speech_prob": 4.3756768718594685e-05}, {"id": 837, "seek": 577420, "start": 5780.679999999999, "end": 5786.2, "text": " candidate for the next atom and also the next bound between the two atoms. You can do that.", "tokens": [50364, 291, 366, 4084, 428, 15582, 12018, 934, 12018, 13, 509, 722, 365, 364, 12018, 11, 550, 291, 486, 362, 257, 50688, 50688, 11532, 337, 264, 958, 12018, 293, 611, 264, 958, 5472, 1296, 264, 732, 16871, 13, 509, 393, 360, 300, 13, 50964, 50964, 467, 311, 257, 441, 6840, 44, 3758, 13, 440, 1150, 3513, 307, 281, 360, 309, 294, 472, 3347, 13, 509, 643, 257, 3209, 300, 393, 51468, 51656], "temperature": 0.0, "avg_logprob": -0.10307474658913808, "compression_ratio": 1.521978021978022, "no_speech_prob": 4.3756768718594685e-05}, {"id": 838, "seek": 577420, "start": 5786.2, "end": 5796.28, "text": " It's a LSTM style. The second direction is to do it in one shot. You need a network that can", "tokens": [50364, 291, 366, 4084, 428, 15582, 12018, 934, 12018, 13, 509, 722, 365, 364, 12018, 11, 550, 291, 486, 362, 257, 50688, 50688, 11532, 337, 264, 958, 12018, 293, 611, 264, 958, 5472, 1296, 264, 732, 16871, 13, 509, 393, 360, 300, 13, 50964, 50964, 467, 311, 257, 441, 6840, 44, 3758, 13, 440, 1150, 3513, 307, 281, 360, 309, 294, 472, 3347, 13, 509, 643, 257, 3209, 300, 393, 51468, 51656], "temperature": 0.0, "avg_logprob": -0.10307474658913808, "compression_ratio": 1.521978021978022, "no_speech_prob": 4.3756768718594685e-05}, {"id": 839, "seek": 579628, "start": 5796.28, "end": 5808.5199999999995, "text": " predict what is the length or the size of your molecule and then what are the connections.", "tokens": [50364, 6069, 437, 307, 264, 4641, 420, 264, 2744, 295, 428, 15582, 293, 550, 437, 366, 264, 9271, 13, 50976, 50976, 509, 362, 613, 732, 11095, 13, 509, 393, 360, 309, 294, 257, 20560, 488, 636, 420, 291, 393, 360, 309, 294, 472, 3347, 13, 51156, 51280, 440, 1768, 307, 544, 3102, 294, 264, 20560, 488, 636, 965, 13, 286, 362, 257, 3035, 322, 264, 472, 3347, 13, 51616, 51644], "temperature": 0.0, "avg_logprob": -0.24275637344575265, "compression_ratio": 1.7098765432098766, "no_speech_prob": 7.037902105366811e-05}, {"id": 840, "seek": 579628, "start": 5808.5199999999995, "end": 5812.12, "text": " You have these two directions. You can do it in a recursive way or you can do it in one shot.", "tokens": [50364, 6069, 437, 307, 264, 4641, 420, 264, 2744, 295, 428, 15582, 293, 550, 437, 366, 264, 9271, 13, 50976, 50976, 509, 362, 613, 732, 11095, 13, 509, 393, 360, 309, 294, 257, 20560, 488, 636, 420, 291, 393, 360, 309, 294, 472, 3347, 13, 51156, 51280, 440, 1768, 307, 544, 3102, 294, 264, 20560, 488, 636, 965, 13, 286, 362, 257, 3035, 322, 264, 472, 3347, 13, 51616, 51644], "temperature": 0.0, "avg_logprob": -0.24275637344575265, "compression_ratio": 1.7098765432098766, "no_speech_prob": 7.037902105366811e-05}, {"id": 841, "seek": 579628, "start": 5814.599999999999, "end": 5821.32, "text": " The community is more interested in the recursive way today. I have a paper on the one shot.", "tokens": [50364, 6069, 437, 307, 264, 4641, 420, 264, 2744, 295, 428, 15582, 293, 550, 437, 366, 264, 9271, 13, 50976, 50976, 509, 362, 613, 732, 11095, 13, 509, 393, 360, 309, 294, 257, 20560, 488, 636, 420, 291, 393, 360, 309, 294, 472, 3347, 13, 51156, 51280, 440, 1768, 307, 544, 3102, 294, 264, 20560, 488, 636, 965, 13, 286, 362, 257, 3035, 322, 264, 472, 3347, 13, 51616, 51644], "temperature": 0.0, "avg_logprob": -0.24275637344575265, "compression_ratio": 1.7098765432098766, "no_speech_prob": 7.037902105366811e-05}, {"id": 842, "seek": 582132, "start": 5821.32, "end": 5828.92, "text": " Basically, they are performing the same. I don't see any difference, but you can do it.", "tokens": [50364, 8537, 11, 436, 366, 10205, 264, 912, 13, 286, 500, 380, 536, 604, 2649, 11, 457, 291, 393, 360, 309, 13, 50744, 50744, 440, 787, 551, 307, 577, 360, 291, 2387, 30, 440, 1168, 307, 428, 15582, 393, 362, 819, 2744, 13, 51040, 51116, 639, 307, 264, 2141, 13, 286, 576, 584, 264, 3430, 510, 13, 1012, 360, 291, 2028, 365, 819, 11602, 30, 51592, 51592], "temperature": 0.0, "avg_logprob": -0.29968079398660097, "compression_ratio": 1.5142857142857142, "no_speech_prob": 1.3209056305640843e-05}, {"id": 843, "seek": 582132, "start": 5828.92, "end": 5834.84, "text": " The only thing is how do you treat? The question is your molecule can have different size.", "tokens": [50364, 8537, 11, 436, 366, 10205, 264, 912, 13, 286, 500, 380, 536, 604, 2649, 11, 457, 291, 393, 360, 309, 13, 50744, 50744, 440, 787, 551, 307, 577, 360, 291, 2387, 30, 440, 1168, 307, 428, 15582, 393, 362, 819, 2744, 13, 51040, 51116, 639, 307, 264, 2141, 13, 286, 576, 584, 264, 3430, 510, 13, 1012, 360, 291, 2028, 365, 819, 11602, 30, 51592, 51592], "temperature": 0.0, "avg_logprob": -0.29968079398660097, "compression_ratio": 1.5142857142857142, "no_speech_prob": 1.3209056305640843e-05}, {"id": 844, "seek": 582132, "start": 5836.36, "end": 5845.88, "text": " This is the key. I would say the challenge here. How do you deal with different sizes?", "tokens": [50364, 8537, 11, 436, 366, 10205, 264, 912, 13, 286, 500, 380, 536, 604, 2649, 11, 457, 291, 393, 360, 309, 13, 50744, 50744, 440, 787, 551, 307, 577, 360, 291, 2387, 30, 440, 1168, 307, 428, 15582, 393, 362, 819, 2744, 13, 51040, 51116, 639, 307, 264, 2141, 13, 286, 576, 584, 264, 3430, 510, 13, 1012, 360, 291, 2028, 365, 819, 11602, 30, 51592, 51592], "temperature": 0.0, "avg_logprob": -0.29968079398660097, "compression_ratio": 1.5142857142857142, "no_speech_prob": 1.3209056305640843e-05}, {"id": 845, "seek": 584588, "start": 5845.88, "end": 5853.4800000000005, "text": " We have different options to do that. What is very interesting related to the chemistry of that", "tokens": [50364, 492, 362, 819, 3956, 281, 360, 300, 13, 708, 307, 588, 1880, 4077, 281, 264, 12558, 295, 300, 50744, 50744, 307, 300, 437, 286, 528, 281, 652, 307, 300, 4295, 18161, 9590, 294, 512, 2020, 366, 886, 709, 11358, 13, 51020, 51228, 1133, 291, 352, 490, 264, 3832, 2656, 85, 31890, 11, 264, 10748, 307, 588, 18519, 13, 509, 393, 483, 257, 688, 295, 1589, 51668, 51668], "temperature": 0.0, "avg_logprob": -0.2109826544056768, "compression_ratio": 1.5077720207253886, "no_speech_prob": 8.459196396870539e-05}, {"id": 846, "seek": 584588, "start": 5853.4800000000005, "end": 5859.0, "text": " is that what I want to make is that graph neural networks in some sense are too much flexible.", "tokens": [50364, 492, 362, 819, 3956, 281, 360, 300, 13, 708, 307, 588, 1880, 4077, 281, 264, 12558, 295, 300, 50744, 50744, 307, 300, 437, 286, 528, 281, 652, 307, 300, 4295, 18161, 9590, 294, 512, 2020, 366, 886, 709, 11358, 13, 51020, 51228, 1133, 291, 352, 490, 264, 3832, 2656, 85, 31890, 11, 264, 10748, 307, 588, 18519, 13, 509, 393, 483, 257, 688, 295, 1589, 51668, 51668], "temperature": 0.0, "avg_logprob": -0.2109826544056768, "compression_ratio": 1.5077720207253886, "no_speech_prob": 8.459196396870539e-05}, {"id": 847, "seek": 584588, "start": 5863.16, "end": 5871.96, "text": " When you go from the standard ConvNet, the grid is very structured. You can get a lot of information", "tokens": [50364, 492, 362, 819, 3956, 281, 360, 300, 13, 708, 307, 588, 1880, 4077, 281, 264, 12558, 295, 300, 50744, 50744, 307, 300, 437, 286, 528, 281, 652, 307, 300, 4295, 18161, 9590, 294, 512, 2020, 366, 886, 709, 11358, 13, 51020, 51228, 1133, 291, 352, 490, 264, 3832, 2656, 85, 31890, 11, 264, 10748, 307, 588, 18519, 13, 509, 393, 483, 257, 688, 295, 1589, 51668, 51668], "temperature": 0.0, "avg_logprob": -0.2109826544056768, "compression_ratio": 1.5077720207253886, "no_speech_prob": 8.459196396870539e-05}, {"id": 848, "seek": 587196, "start": 5871.96, "end": 5878.84, "text": " for the structure of the grid, but you don't have this in graph. Again, you lose the node", "tokens": [50364, 337, 264, 3877, 295, 264, 10748, 11, 457, 291, 500, 380, 362, 341, 294, 4295, 13, 3764, 11, 291, 3624, 264, 9984, 50708, 50708, 21739, 293, 1203, 13, 492, 643, 281, 915, 257, 636, 281, 362, 544, 293, 544, 3877, 1854, 264, 4295, 51008, 51008, 18161, 9590, 13, 1485, 636, 281, 360, 300, 307, 264, 9482, 13, 1171, 1365, 11, 291, 576, 411, 281, 51264, 51264, 10432, 11, 337, 1365, 11, 498, 291, 360, 12558, 11, 291, 576, 411, 281, 10432, 2065, 340, 3584, 260, 5367, 11, 51524, 51572], "temperature": 0.0, "avg_logprob": -0.11350363427466088, "compression_ratio": 1.6774193548387097, "no_speech_prob": 1.7766806195140816e-05}, {"id": 849, "seek": 587196, "start": 5878.84, "end": 5884.84, "text": " ordering and everything. We need to find a way to have more and more structure inside the graph", "tokens": [50364, 337, 264, 3877, 295, 264, 10748, 11, 457, 291, 500, 380, 362, 341, 294, 4295, 13, 3764, 11, 291, 3624, 264, 9984, 50708, 50708, 21739, 293, 1203, 13, 492, 643, 281, 915, 257, 636, 281, 362, 544, 293, 544, 3877, 1854, 264, 4295, 51008, 51008, 18161, 9590, 13, 1485, 636, 281, 360, 300, 307, 264, 9482, 13, 1171, 1365, 11, 291, 576, 411, 281, 51264, 51264, 10432, 11, 337, 1365, 11, 498, 291, 360, 12558, 11, 291, 576, 411, 281, 10432, 2065, 340, 3584, 260, 5367, 11, 51524, 51572], "temperature": 0.0, "avg_logprob": -0.11350363427466088, "compression_ratio": 1.6774193548387097, "no_speech_prob": 1.7766806195140816e-05}, {"id": 850, "seek": 587196, "start": 5884.84, "end": 5889.96, "text": " neural networks. One way to do that is the architecture. For example, you would like to", "tokens": [50364, 337, 264, 3877, 295, 264, 10748, 11, 457, 291, 500, 380, 362, 341, 294, 4295, 13, 3764, 11, 291, 3624, 264, 9984, 50708, 50708, 21739, 293, 1203, 13, 492, 643, 281, 915, 257, 636, 281, 362, 544, 293, 544, 3877, 1854, 264, 4295, 51008, 51008, 18161, 9590, 13, 1485, 636, 281, 360, 300, 307, 264, 9482, 13, 1171, 1365, 11, 291, 576, 411, 281, 51264, 51264, 10432, 11, 337, 1365, 11, 498, 291, 360, 12558, 11, 291, 576, 411, 281, 10432, 2065, 340, 3584, 260, 5367, 11, 51524, 51572], "temperature": 0.0, "avg_logprob": -0.11350363427466088, "compression_ratio": 1.6774193548387097, "no_speech_prob": 1.7766806195140816e-05}, {"id": 851, "seek": 587196, "start": 5889.96, "end": 5895.16, "text": " combine, for example, if you do chemistry, you would like to combine Schrodinger equation,", "tokens": [50364, 337, 264, 3877, 295, 264, 10748, 11, 457, 291, 500, 380, 362, 341, 294, 4295, 13, 3764, 11, 291, 3624, 264, 9984, 50708, 50708, 21739, 293, 1203, 13, 492, 643, 281, 915, 257, 636, 281, 362, 544, 293, 544, 3877, 1854, 264, 4295, 51008, 51008, 18161, 9590, 13, 1485, 636, 281, 360, 300, 307, 264, 9482, 13, 1171, 1365, 11, 291, 576, 411, 281, 51264, 51264, 10432, 11, 337, 1365, 11, 498, 291, 360, 12558, 11, 291, 576, 411, 281, 10432, 2065, 340, 3584, 260, 5367, 11, 51524, 51572], "temperature": 0.0, "avg_logprob": -0.11350363427466088, "compression_ratio": 1.6774193548387097, "no_speech_prob": 1.7766806195140816e-05}, {"id": 852, "seek": 589516, "start": 5895.16, "end": 5902.76, "text": " like Hamilton energy. People are doing that to constrain better your graph neural networks.", "tokens": [50364, 411, 18484, 2281, 13, 3432, 366, 884, 300, 281, 1817, 7146, 1101, 428, 4295, 18161, 9590, 13, 50744, 50744, 3764, 11, 4295, 18161, 9590, 366, 294, 512, 2020, 886, 709, 11358, 13, 509, 643, 281, 915, 257, 636, 281, 909, 544, 51076, 51128, 11455, 18491, 13, 5135, 11, 466, 264, 11455, 18491, 11, 51336, 51336, 286, 658, 510, 257, 1168, 13, 708, 360, 291, 914, 538, 11455, 2539, 6042, 30, 51508, 51608], "temperature": 0.0, "avg_logprob": -0.16646565617741765, "compression_ratio": 1.6176470588235294, "no_speech_prob": 4.7389083192683756e-05}, {"id": 853, "seek": 589516, "start": 5902.76, "end": 5909.4, "text": " Again, graph neural networks are in some sense too much flexible. You need to find a way to add more", "tokens": [50364, 411, 18484, 2281, 13, 3432, 366, 884, 300, 281, 1817, 7146, 1101, 428, 4295, 18161, 9590, 13, 50744, 50744, 3764, 11, 4295, 18161, 9590, 366, 294, 512, 2020, 886, 709, 11358, 13, 509, 643, 281, 915, 257, 636, 281, 909, 544, 51076, 51128, 11455, 18491, 13, 5135, 11, 466, 264, 11455, 18491, 11, 51336, 51336, 286, 658, 510, 257, 1168, 13, 708, 360, 291, 914, 538, 11455, 2539, 6042, 30, 51508, 51608], "temperature": 0.0, "avg_logprob": -0.16646565617741765, "compression_ratio": 1.6176470588235294, "no_speech_prob": 4.7389083192683756e-05}, {"id": 854, "seek": 589516, "start": 5910.44, "end": 5914.599999999999, "text": " universal constraints. Actually, about the universal constraints,", "tokens": [50364, 411, 18484, 2281, 13, 3432, 366, 884, 300, 281, 1817, 7146, 1101, 428, 4295, 18161, 9590, 13, 50744, 50744, 3764, 11, 4295, 18161, 9590, 366, 294, 512, 2020, 886, 709, 11358, 13, 509, 643, 281, 915, 257, 636, 281, 909, 544, 51076, 51128, 11455, 18491, 13, 5135, 11, 466, 264, 11455, 18491, 11, 51336, 51336, 286, 658, 510, 257, 1168, 13, 708, 360, 291, 914, 538, 11455, 2539, 6042, 30, 51508, 51608], "temperature": 0.0, "avg_logprob": -0.16646565617741765, "compression_ratio": 1.6176470588235294, "no_speech_prob": 4.7389083192683756e-05}, {"id": 855, "seek": 589516, "start": 5914.599999999999, "end": 5918.04, "text": " I got here a question. What do you mean by universal learning capacity?", "tokens": [50364, 411, 18484, 2281, 13, 3432, 366, 884, 300, 281, 1817, 7146, 1101, 428, 4295, 18161, 9590, 13, 50744, 50744, 3764, 11, 4295, 18161, 9590, 366, 294, 512, 2020, 886, 709, 11358, 13, 509, 643, 281, 915, 257, 636, 281, 909, 544, 51076, 51128, 11455, 18491, 13, 5135, 11, 466, 264, 11455, 18491, 11, 51336, 51336, 286, 658, 510, 257, 1168, 13, 708, 360, 291, 914, 538, 11455, 2539, 6042, 30, 51508, 51608], "temperature": 0.0, "avg_logprob": -0.16646565617741765, "compression_ratio": 1.6176470588235294, "no_speech_prob": 4.7389083192683756e-05}, {"id": 856, "seek": 591804, "start": 5918.04, "end": 5926.12, "text": " Yes. This is the recent works on graph neural networks. In some sense, you're trying to", "tokens": [50364, 1079, 13, 639, 307, 264, 5162, 1985, 322, 4295, 18161, 9590, 13, 682, 512, 2020, 11, 291, 434, 1382, 281, 50768, 50768, 33872, 428, 18161, 9590, 13, 821, 366, 867, 25618, 322, 18161, 9590, 13, 1012, 360, 291, 51000, 51000, 33872, 552, 30, 509, 643, 281, 915, 18894, 7221, 411, 38018, 39173, 7221, 11, 364, 271, 310, 39173, 51276, 51276, 7221, 13, 5048, 3938, 11, 456, 366, 20864, 589, 322, 307, 32702, 1434, 293, 5109, 2841, 295, 4295, 51752, 51752], "temperature": 0.0, "avg_logprob": -0.14400608946637408, "compression_ratio": 1.732394366197183, "no_speech_prob": 9.651613254391123e-06}, {"id": 857, "seek": 591804, "start": 5926.12, "end": 5930.76, "text": " classify your neural networks. There are many publications on neural networks. How do you", "tokens": [50364, 1079, 13, 639, 307, 264, 5162, 1985, 322, 4295, 18161, 9590, 13, 682, 512, 2020, 11, 291, 434, 1382, 281, 50768, 50768, 33872, 428, 18161, 9590, 13, 821, 366, 867, 25618, 322, 18161, 9590, 13, 1012, 360, 291, 51000, 51000, 33872, 552, 30, 509, 643, 281, 915, 18894, 7221, 411, 38018, 39173, 7221, 11, 364, 271, 310, 39173, 51276, 51276, 7221, 13, 5048, 3938, 11, 456, 366, 20864, 589, 322, 307, 32702, 1434, 293, 5109, 2841, 295, 4295, 51752, 51752], "temperature": 0.0, "avg_logprob": -0.14400608946637408, "compression_ratio": 1.732394366197183, "no_speech_prob": 9.651613254391123e-06}, {"id": 858, "seek": 591804, "start": 5930.76, "end": 5936.28, "text": " classify them? You need to find mathematical properties like isotropic properties, anisotropic", "tokens": [50364, 1079, 13, 639, 307, 264, 5162, 1985, 322, 4295, 18161, 9590, 13, 682, 512, 2020, 11, 291, 434, 1382, 281, 50768, 50768, 33872, 428, 18161, 9590, 13, 821, 366, 867, 25618, 322, 18161, 9590, 13, 1012, 360, 291, 51000, 51000, 33872, 552, 30, 509, 643, 281, 915, 18894, 7221, 411, 38018, 39173, 7221, 11, 364, 271, 310, 39173, 51276, 51276, 7221, 13, 5048, 3938, 11, 456, 366, 20864, 589, 322, 307, 32702, 1434, 293, 5109, 2841, 295, 4295, 51752, 51752], "temperature": 0.0, "avg_logprob": -0.14400608946637408, "compression_ratio": 1.732394366197183, "no_speech_prob": 9.651613254391123e-06}, {"id": 859, "seek": 591804, "start": 5936.28, "end": 5945.8, "text": " properties. More recently, there are theoretical work on isomorphism and expressibility of graph", "tokens": [50364, 1079, 13, 639, 307, 264, 5162, 1985, 322, 4295, 18161, 9590, 13, 682, 512, 2020, 11, 291, 434, 1382, 281, 50768, 50768, 33872, 428, 18161, 9590, 13, 821, 366, 867, 25618, 322, 18161, 9590, 13, 1012, 360, 291, 51000, 51000, 33872, 552, 30, 509, 643, 281, 915, 18894, 7221, 411, 38018, 39173, 7221, 11, 364, 271, 310, 39173, 51276, 51276, 7221, 13, 5048, 3938, 11, 456, 366, 20864, 589, 322, 307, 32702, 1434, 293, 5109, 2841, 295, 4295, 51752, 51752], "temperature": 0.0, "avg_logprob": -0.14400608946637408, "compression_ratio": 1.732394366197183, "no_speech_prob": 9.651613254391123e-06}, {"id": 860, "seek": 594580, "start": 5945.8, "end": 5953.4800000000005, "text": " neural network depending on some class of theoretical graphs. Graphs are starting by", "tokens": [50364, 18161, 3209, 5413, 322, 512, 1508, 295, 20864, 24877, 13, 21884, 82, 366, 2891, 538, 50748, 50748, 3071, 11, 411, 2331, 924, 2057, 13, 492, 458, 257, 688, 466, 24877, 293, 321, 528, 281, 33872, 24877, 4650, 51020, 51020, 281, 512, 18894, 4707, 13, 639, 307, 437, 286, 390, 1382, 281, 2152, 300, 291, 393, 1715, 51436, 51436, 4295, 18161, 9590, 337, 512, 2121, 18894, 7221, 13, 286, 536, 13, 1044, 291, 13, 51688, 51768], "temperature": 0.0, "avg_logprob": -0.11792984256496677, "compression_ratio": 1.6556603773584906, "no_speech_prob": 6.67534040985629e-05}, {"id": 861, "seek": 594580, "start": 5953.4800000000005, "end": 5958.92, "text": " earlier, like 200 years ago. We know a lot about graphs and we want to classify graphs according", "tokens": [50364, 18161, 3209, 5413, 322, 512, 1508, 295, 20864, 24877, 13, 21884, 82, 366, 2891, 538, 50748, 50748, 3071, 11, 411, 2331, 924, 2057, 13, 492, 458, 257, 688, 466, 24877, 293, 321, 528, 281, 33872, 24877, 4650, 51020, 51020, 281, 512, 18894, 4707, 13, 639, 307, 437, 286, 390, 1382, 281, 2152, 300, 291, 393, 1715, 51436, 51436, 4295, 18161, 9590, 337, 512, 2121, 18894, 7221, 13, 286, 536, 13, 1044, 291, 13, 51688, 51768], "temperature": 0.0, "avg_logprob": -0.11792984256496677, "compression_ratio": 1.6556603773584906, "no_speech_prob": 6.67534040985629e-05}, {"id": 862, "seek": 594580, "start": 5958.92, "end": 5967.24, "text": " to some mathematical property. This is what I was trying to mention that you can design", "tokens": [50364, 18161, 3209, 5413, 322, 512, 1508, 295, 20864, 24877, 13, 21884, 82, 366, 2891, 538, 50748, 50748, 3071, 11, 411, 2331, 924, 2057, 13, 492, 458, 257, 688, 466, 24877, 293, 321, 528, 281, 33872, 24877, 4650, 51020, 51020, 281, 512, 18894, 4707, 13, 639, 307, 437, 286, 390, 1382, 281, 2152, 300, 291, 393, 1715, 51436, 51436, 4295, 18161, 9590, 337, 512, 2121, 18894, 7221, 13, 286, 536, 13, 1044, 291, 13, 51688, 51768], "temperature": 0.0, "avg_logprob": -0.11792984256496677, "compression_ratio": 1.6556603773584906, "no_speech_prob": 6.67534040985629e-05}, {"id": 863, "seek": 594580, "start": 5967.24, "end": 5972.28, "text": " graph neural networks for some special mathematical properties. I see. Thank you.", "tokens": [50364, 18161, 3209, 5413, 322, 512, 1508, 295, 20864, 24877, 13, 21884, 82, 366, 2891, 538, 50748, 50748, 3071, 11, 411, 2331, 924, 2057, 13, 492, 458, 257, 688, 466, 24877, 293, 321, 528, 281, 33872, 24877, 4650, 51020, 51020, 281, 512, 18894, 4707, 13, 639, 307, 437, 286, 390, 1382, 281, 2152, 300, 291, 393, 1715, 51436, 51436, 4295, 18161, 9590, 337, 512, 2121, 18894, 7221, 13, 286, 536, 13, 1044, 291, 13, 51688, 51768], "temperature": 0.0, "avg_logprob": -0.11792984256496677, "compression_ratio": 1.6556603773584906, "no_speech_prob": 6.67534040985629e-05}, {"id": 864, "seek": 597228, "start": 5972.28, "end": 5979.24, "text": " Okay. Guys, feel free to ask questions. You can also write to me if you're too shy. I'm not shy.", "tokens": [50364, 1033, 13, 7855, 11, 841, 1737, 281, 1029, 1651, 13, 509, 393, 611, 2464, 281, 385, 498, 291, 434, 886, 12685, 13, 286, 478, 406, 12685, 13, 50712, 50712, 286, 393, 445, 1401, 13, 286, 362, 257, 1168, 13, 1044, 291, 370, 709, 337, 341, 869, 7991, 13, 509, 2835, 300, 51028, 51028, 291, 2942, 257, 18927, 1412, 992, 370, 561, 393, 18927, 641, 819, 4295, 18161, 9590, 13, 51392, 51464, 286, 841, 411, 257, 688, 295, 729, 9590, 611, 1466, 512, 10290, 294, 264, 4295, 13, 316, 688, 295, 51752, 51752], "temperature": 0.0, "avg_logprob": -0.15245341240091526, "compression_ratio": 1.6336206896551724, "no_speech_prob": 5.223556581768207e-05}, {"id": 865, "seek": 597228, "start": 5979.24, "end": 5985.5599999999995, "text": " I can just read. I have a question. Thank you so much for this great lecture. You mentioned that", "tokens": [50364, 1033, 13, 7855, 11, 841, 1737, 281, 1029, 1651, 13, 509, 393, 611, 2464, 281, 385, 498, 291, 434, 886, 12685, 13, 286, 478, 406, 12685, 13, 50712, 50712, 286, 393, 445, 1401, 13, 286, 362, 257, 1168, 13, 1044, 291, 370, 709, 337, 341, 869, 7991, 13, 509, 2835, 300, 51028, 51028, 291, 2942, 257, 18927, 1412, 992, 370, 561, 393, 18927, 641, 819, 4295, 18161, 9590, 13, 51392, 51464, 286, 841, 411, 257, 688, 295, 729, 9590, 611, 1466, 512, 10290, 294, 264, 4295, 13, 316, 688, 295, 51752, 51752], "temperature": 0.0, "avg_logprob": -0.15245341240091526, "compression_ratio": 1.6336206896551724, "no_speech_prob": 5.223556581768207e-05}, {"id": 866, "seek": 597228, "start": 5985.5599999999995, "end": 5992.84, "text": " you created a benchmark data set so people can benchmark their different graph neural networks.", "tokens": [50364, 1033, 13, 7855, 11, 841, 1737, 281, 1029, 1651, 13, 509, 393, 611, 2464, 281, 385, 498, 291, 434, 886, 12685, 13, 286, 478, 406, 12685, 13, 50712, 50712, 286, 393, 445, 1401, 13, 286, 362, 257, 1168, 13, 1044, 291, 370, 709, 337, 341, 869, 7991, 13, 509, 2835, 300, 51028, 51028, 291, 2942, 257, 18927, 1412, 992, 370, 561, 393, 18927, 641, 819, 4295, 18161, 9590, 13, 51392, 51464, 286, 841, 411, 257, 688, 295, 729, 9590, 611, 1466, 512, 10290, 294, 264, 4295, 13, 316, 688, 295, 51752, 51752], "temperature": 0.0, "avg_logprob": -0.15245341240091526, "compression_ratio": 1.6336206896551724, "no_speech_prob": 5.223556581768207e-05}, {"id": 867, "seek": 597228, "start": 5994.28, "end": 6000.04, "text": " I feel like a lot of those networks also learn some representation in the graph. A lot of", "tokens": [50364, 1033, 13, 7855, 11, 841, 1737, 281, 1029, 1651, 13, 509, 393, 611, 2464, 281, 385, 498, 291, 434, 886, 12685, 13, 286, 478, 406, 12685, 13, 50712, 50712, 286, 393, 445, 1401, 13, 286, 362, 257, 1168, 13, 1044, 291, 370, 709, 337, 341, 869, 7991, 13, 509, 2835, 300, 51028, 51028, 291, 2942, 257, 18927, 1412, 992, 370, 561, 393, 18927, 641, 819, 4295, 18161, 9590, 13, 51392, 51464, 286, 841, 411, 257, 688, 295, 729, 9590, 611, 1466, 512, 10290, 294, 264, 4295, 13, 316, 688, 295, 51752, 51752], "temperature": 0.0, "avg_logprob": -0.15245341240091526, "compression_ratio": 1.6336206896551724, "no_speech_prob": 5.223556581768207e-05}, {"id": 868, "seek": 600004, "start": 6000.04, "end": 6005.64, "text": " downstream tasks could be like an unsupervised setting where I think in the benchmarking data", "tokens": [50364, 30621, 9608, 727, 312, 411, 364, 2693, 12879, 24420, 3287, 689, 286, 519, 294, 264, 18927, 278, 1412, 50644, 50644, 6352, 11, 291, 434, 439, 445, 1228, 14170, 544, 420, 1570, 13, 467, 311, 411, 291, 362, 16949, 11, 2727, 3494, 16949, 13, 50992, 50992, 467, 311, 544, 294, 264, 46533, 3287, 13, 1144, 291, 362, 604, 4598, 322, 577, 321, 727, 18927, 264, 4295, 51372, 51372, 3209, 311, 3389, 294, 364, 2693, 12879, 24420, 3287, 420, 12909, 12, 48172, 24420, 3287, 420, 538, 13389, 641, 51820, 51820], "temperature": 0.0, "avg_logprob": -0.1524386723836263, "compression_ratio": 1.8130841121495327, "no_speech_prob": 4.005652226624079e-05}, {"id": 869, "seek": 600004, "start": 6005.64, "end": 6012.6, "text": " sets, you're all just using accuracy more or less. It's like you have labels, ground truth labels.", "tokens": [50364, 30621, 9608, 727, 312, 411, 364, 2693, 12879, 24420, 3287, 689, 286, 519, 294, 264, 18927, 278, 1412, 50644, 50644, 6352, 11, 291, 434, 439, 445, 1228, 14170, 544, 420, 1570, 13, 467, 311, 411, 291, 362, 16949, 11, 2727, 3494, 16949, 13, 50992, 50992, 467, 311, 544, 294, 264, 46533, 3287, 13, 1144, 291, 362, 604, 4598, 322, 577, 321, 727, 18927, 264, 4295, 51372, 51372, 3209, 311, 3389, 294, 364, 2693, 12879, 24420, 3287, 420, 12909, 12, 48172, 24420, 3287, 420, 538, 13389, 641, 51820, 51820], "temperature": 0.0, "avg_logprob": -0.1524386723836263, "compression_ratio": 1.8130841121495327, "no_speech_prob": 4.005652226624079e-05}, {"id": 870, "seek": 600004, "start": 6012.6, "end": 6020.2, "text": " It's more in the supervised setting. Do you have any thoughts on how we could benchmark the graph", "tokens": [50364, 30621, 9608, 727, 312, 411, 364, 2693, 12879, 24420, 3287, 689, 286, 519, 294, 264, 18927, 278, 1412, 50644, 50644, 6352, 11, 291, 434, 439, 445, 1228, 14170, 544, 420, 1570, 13, 467, 311, 411, 291, 362, 16949, 11, 2727, 3494, 16949, 13, 50992, 50992, 467, 311, 544, 294, 264, 46533, 3287, 13, 1144, 291, 362, 604, 4598, 322, 577, 321, 727, 18927, 264, 4295, 51372, 51372, 3209, 311, 3389, 294, 364, 2693, 12879, 24420, 3287, 420, 12909, 12, 48172, 24420, 3287, 420, 538, 13389, 641, 51820, 51820], "temperature": 0.0, "avg_logprob": -0.1524386723836263, "compression_ratio": 1.8130841121495327, "no_speech_prob": 4.005652226624079e-05}, {"id": 871, "seek": 600004, "start": 6020.2, "end": 6029.16, "text": " network's performance in an unsupervised setting or semi-supervised setting or by measuring their", "tokens": [50364, 30621, 9608, 727, 312, 411, 364, 2693, 12879, 24420, 3287, 689, 286, 519, 294, 264, 18927, 278, 1412, 50644, 50644, 6352, 11, 291, 434, 439, 445, 1228, 14170, 544, 420, 1570, 13, 467, 311, 411, 291, 362, 16949, 11, 2727, 3494, 16949, 13, 50992, 50992, 467, 311, 544, 294, 264, 46533, 3287, 13, 1144, 291, 362, 604, 4598, 322, 577, 321, 727, 18927, 264, 4295, 51372, 51372, 3209, 311, 3389, 294, 364, 2693, 12879, 24420, 3287, 420, 12909, 12, 48172, 24420, 3287, 420, 538, 13389, 641, 51820, 51820], "temperature": 0.0, "avg_logprob": -0.1524386723836263, "compression_ratio": 1.8130841121495327, "no_speech_prob": 4.005652226624079e-05}, {"id": 872, "seek": 602916, "start": 6029.16, "end": 6035.32, "text": " performance in some common downstream tasks or application? I would like to hear your thoughts", "tokens": [50364, 3389, 294, 512, 2689, 30621, 9608, 420, 3861, 30, 286, 576, 411, 281, 1568, 428, 4598, 50672, 50672, 322, 300, 13, 1044, 291, 13, 286, 519, 341, 307, 472, 295, 264, 881, 2954, 8378, 295, 4956, 11, 264, 2698, 12, 48172, 24420, 13, 50980, 51124, 865, 11, 300, 311, 558, 13, 1018, 291, 393, 980, 11, 286, 3567, 86, 12219, 264, 1731, 294, 264, 1508, 588, 731, 13, 51380, 51380, 1079, 13, 663, 311, 983, 286, 478, 3365, 13, 2720, 1164, 11, 472, 295, 264, 1021, 1651, 51816], "temperature": 0.0, "avg_logprob": -0.14602058198716905, "compression_ratio": 1.497854077253219, "no_speech_prob": 3.5348752135178074e-05}, {"id": 873, "seek": 602916, "start": 6035.32, "end": 6041.48, "text": " on that. Thank you. I think this is one of the most favorite topics of Jan, the self-supervised.", "tokens": [50364, 3389, 294, 512, 2689, 30621, 9608, 420, 3861, 30, 286, 576, 411, 281, 1568, 428, 4598, 50672, 50672, 322, 300, 13, 1044, 291, 13, 286, 519, 341, 307, 472, 295, 264, 881, 2954, 8378, 295, 4956, 11, 264, 2698, 12, 48172, 24420, 13, 50980, 51124, 865, 11, 300, 311, 558, 13, 1018, 291, 393, 980, 11, 286, 3567, 86, 12219, 264, 1731, 294, 264, 1508, 588, 731, 13, 51380, 51380, 1079, 13, 663, 311, 983, 286, 478, 3365, 13, 2720, 1164, 11, 472, 295, 264, 1021, 1651, 51816], "temperature": 0.0, "avg_logprob": -0.14602058198716905, "compression_ratio": 1.497854077253219, "no_speech_prob": 3.5348752135178074e-05}, {"id": 874, "seek": 602916, "start": 6044.36, "end": 6049.48, "text": " Yeah, that's right. As you can tell, I brainwashed the students in the class very well.", "tokens": [50364, 3389, 294, 512, 2689, 30621, 9608, 420, 3861, 30, 286, 576, 411, 281, 1568, 428, 4598, 50672, 50672, 322, 300, 13, 1044, 291, 13, 286, 519, 341, 307, 472, 295, 264, 881, 2954, 8378, 295, 4956, 11, 264, 2698, 12, 48172, 24420, 13, 50980, 51124, 865, 11, 300, 311, 558, 13, 1018, 291, 393, 980, 11, 286, 3567, 86, 12219, 264, 1731, 294, 264, 1508, 588, 731, 13, 51380, 51380, 1079, 13, 663, 311, 983, 286, 478, 3365, 13, 2720, 1164, 11, 472, 295, 264, 1021, 1651, 51816], "temperature": 0.0, "avg_logprob": -0.14602058198716905, "compression_ratio": 1.497854077253219, "no_speech_prob": 3.5348752135178074e-05}, {"id": 875, "seek": 604948, "start": 6049.48, "end": 6064.12, "text": " Yes, so that's why I'm asking. Of course, one important question is you want to learn efficiently.", "tokens": [50364, 1079, 11, 370, 300, 311, 983, 286, 478, 3365, 13, 2720, 1164, 11, 472, 1021, 1168, 307, 291, 528, 281, 1466, 19621, 13, 51096, 51128, 509, 500, 380, 528, 281, 362, 886, 709, 16949, 281, 312, 1075, 281, 6069, 731, 13, 16348, 12, 48172, 24420, 2539, 51484, 51600], "temperature": 0.0, "avg_logprob": -0.16384294509887695, "compression_ratio": 1.3103448275862069, "no_speech_prob": 3.218876008759253e-05}, {"id": 876, "seek": 604948, "start": 6064.759999999999, "end": 6071.879999999999, "text": " You don't want to have too much labels to be able to predict well. Self-supervised learning", "tokens": [50364, 1079, 11, 370, 300, 311, 983, 286, 478, 3365, 13, 2720, 1164, 11, 472, 1021, 1168, 307, 291, 528, 281, 1466, 19621, 13, 51096, 51128, 509, 500, 380, 528, 281, 362, 886, 709, 16949, 281, 312, 1075, 281, 6069, 731, 13, 16348, 12, 48172, 24420, 2539, 51484, 51600], "temperature": 0.0, "avg_logprob": -0.16384294509887695, "compression_ratio": 1.3103448275862069, "no_speech_prob": 3.218876008759253e-05}, {"id": 877, "seek": 607188, "start": 6071.88, "end": 6082.28, "text": " is one way to do that. You can do that also with graph. You can hide some part of the information", "tokens": [50364, 307, 472, 636, 281, 360, 300, 13, 509, 393, 360, 300, 611, 365, 4295, 13, 509, 393, 6479, 512, 644, 295, 264, 1589, 50884, 50884, 295, 428, 4295, 293, 550, 291, 393, 6069, 341, 7633, 1589, 281, 483, 428, 10290, 13, 51156, 51280, 286, 2041, 586, 309, 311, 484, 337, 385, 281, 1524, 439, 264, 5162, 29435, 45, 589, 11, 457, 286, 2041, 498, 291, 3329, 309, 11, 51612, 51612], "temperature": 0.0, "avg_logprob": -0.16274752881791857, "compression_ratio": 1.5965909090909092, "no_speech_prob": 2.354253774683457e-05}, {"id": 878, "seek": 607188, "start": 6082.28, "end": 6087.72, "text": " of your graph and then you can predict this hidden information to get your representation.", "tokens": [50364, 307, 472, 636, 281, 360, 300, 13, 509, 393, 360, 300, 611, 365, 4295, 13, 509, 393, 6479, 512, 644, 295, 264, 1589, 50884, 50884, 295, 428, 4295, 293, 550, 291, 393, 6069, 341, 7633, 1589, 281, 483, 428, 10290, 13, 51156, 51280, 286, 2041, 586, 309, 311, 484, 337, 385, 281, 1524, 439, 264, 5162, 29435, 45, 589, 11, 457, 286, 2041, 498, 291, 3329, 309, 11, 51612, 51612], "temperature": 0.0, "avg_logprob": -0.16274752881791857, "compression_ratio": 1.5965909090909092, "no_speech_prob": 2.354253774683457e-05}, {"id": 879, "seek": 607188, "start": 6090.2, "end": 6096.84, "text": " I guess now it's out for me to follow all the recent GCN work, but I guess if you Google it,", "tokens": [50364, 307, 472, 636, 281, 360, 300, 13, 509, 393, 360, 300, 611, 365, 4295, 13, 509, 393, 6479, 512, 644, 295, 264, 1589, 50884, 50884, 295, 428, 4295, 293, 550, 291, 393, 6069, 341, 7633, 1589, 281, 483, 428, 10290, 13, 51156, 51280, 286, 2041, 586, 309, 311, 484, 337, 385, 281, 1524, 439, 264, 5162, 29435, 45, 589, 11, 457, 286, 2041, 498, 291, 3329, 309, 11, 51612, 51612], "temperature": 0.0, "avg_logprob": -0.16274752881791857, "compression_ratio": 1.5965909090909092, "no_speech_prob": 2.354253774683457e-05}, {"id": 880, "seek": 609684, "start": 6096.84, "end": 6103.0, "text": " there will probably already be one or two papers on this idea. There is nothing special with GCN.", "tokens": [50364, 456, 486, 1391, 1217, 312, 472, 420, 732, 10577, 322, 341, 1558, 13, 821, 307, 1825, 2121, 365, 29435, 45, 13, 50672, 50720, 509, 393, 3079, 264, 912, 3487, 411, 2698, 12, 48172, 24420, 2539, 281, 29435, 45, 13, 492, 500, 380, 829, 300, 294, 264, 51108, 51108, 18927, 1939, 13, 467, 311, 257, 665, 1558, 13, 663, 311, 746, 1310, 321, 727, 360, 13, 5135, 11, 26771, 11, 51432, 51480, 439, 295, 2698, 12, 48172, 24420, 2539, 767, 12382, 1208, 512, 1333, 295, 4295, 3877, 13, 51680, 51816], "temperature": 0.0, "avg_logprob": -0.12473740420498691, "compression_ratio": 1.584070796460177, "no_speech_prob": 3.940934402635321e-05}, {"id": 881, "seek": 609684, "start": 6103.96, "end": 6111.72, "text": " You can apply the same ideas like self-supervised learning to GCN. We don't put that in the", "tokens": [50364, 456, 486, 1391, 1217, 312, 472, 420, 732, 10577, 322, 341, 1558, 13, 821, 307, 1825, 2121, 365, 29435, 45, 13, 50672, 50720, 509, 393, 3079, 264, 912, 3487, 411, 2698, 12, 48172, 24420, 2539, 281, 29435, 45, 13, 492, 500, 380, 829, 300, 294, 264, 51108, 51108, 18927, 1939, 13, 467, 311, 257, 665, 1558, 13, 663, 311, 746, 1310, 321, 727, 360, 13, 5135, 11, 26771, 11, 51432, 51480, 439, 295, 2698, 12, 48172, 24420, 2539, 767, 12382, 1208, 512, 1333, 295, 4295, 3877, 13, 51680, 51816], "temperature": 0.0, "avg_logprob": -0.12473740420498691, "compression_ratio": 1.584070796460177, "no_speech_prob": 3.940934402635321e-05}, {"id": 882, "seek": 609684, "start": 6111.72, "end": 6118.2, "text": " benchmark yet. It's a good idea. That's something maybe we could do. Actually, arguably,", "tokens": [50364, 456, 486, 1391, 1217, 312, 472, 420, 732, 10577, 322, 341, 1558, 13, 821, 307, 1825, 2121, 365, 29435, 45, 13, 50672, 50720, 509, 393, 3079, 264, 912, 3487, 411, 2698, 12, 48172, 24420, 2539, 281, 29435, 45, 13, 492, 500, 380, 829, 300, 294, 264, 51108, 51108, 18927, 1939, 13, 467, 311, 257, 665, 1558, 13, 663, 311, 746, 1310, 321, 727, 360, 13, 5135, 11, 26771, 11, 51432, 51480, 439, 295, 2698, 12, 48172, 24420, 2539, 767, 12382, 1208, 512, 1333, 295, 4295, 3877, 13, 51680, 51816], "temperature": 0.0, "avg_logprob": -0.12473740420498691, "compression_ratio": 1.584070796460177, "no_speech_prob": 3.940934402635321e-05}, {"id": 883, "seek": 609684, "start": 6119.16, "end": 6123.16, "text": " all of self-supervised learning actually exploits some sort of graph structure.", "tokens": [50364, 456, 486, 1391, 1217, 312, 472, 420, 732, 10577, 322, 341, 1558, 13, 821, 307, 1825, 2121, 365, 29435, 45, 13, 50672, 50720, 509, 393, 3079, 264, 912, 3487, 411, 2698, 12, 48172, 24420, 2539, 281, 29435, 45, 13, 492, 500, 380, 829, 300, 294, 264, 51108, 51108, 18927, 1939, 13, 467, 311, 257, 665, 1558, 13, 663, 311, 746, 1310, 321, 727, 360, 13, 5135, 11, 26771, 11, 51432, 51480, 439, 295, 2698, 12, 48172, 24420, 2539, 767, 12382, 1208, 512, 1333, 295, 4295, 3877, 13, 51680, 51816], "temperature": 0.0, "avg_logprob": -0.12473740420498691, "compression_ratio": 1.584070796460177, "no_speech_prob": 3.940934402635321e-05}, {"id": 884, "seek": 612316, "start": 6123.16, "end": 6131.24, "text": " When you do self-supervised learning in text, for example, you take a sequence of words and you", "tokens": [50364, 1133, 291, 360, 2698, 12, 48172, 24420, 2539, 294, 2487, 11, 337, 1365, 11, 291, 747, 257, 8310, 295, 2283, 293, 291, 50768, 50768, 1466, 281, 6069, 257, 1349, 294, 264, 2808, 420, 5361, 2283, 11, 2035, 436, 366, 13, 821, 307, 257, 4295, 51092, 51092, 3877, 293, 300, 4295, 3877, 307, 577, 867, 1413, 257, 1349, 7038, 512, 4560, 1314, 490, 51468, 51468, 1071, 1349, 13, 11739, 291, 362, 439, 264, 2283, 293, 550, 291, 584, 1951, 341, 4319, 11, 51860, 51860], "temperature": 0.0, "avg_logprob": -0.09548060473273783, "compression_ratio": 1.6605504587155964, "no_speech_prob": 3.479972656350583e-05}, {"id": 885, "seek": 612316, "start": 6131.24, "end": 6137.72, "text": " learn to predict a word in the middle or missing words, whatever they are. There is a graph", "tokens": [50364, 1133, 291, 360, 2698, 12, 48172, 24420, 2539, 294, 2487, 11, 337, 1365, 11, 291, 747, 257, 8310, 295, 2283, 293, 291, 50768, 50768, 1466, 281, 6069, 257, 1349, 294, 264, 2808, 420, 5361, 2283, 11, 2035, 436, 366, 13, 821, 307, 257, 4295, 51092, 51092, 3877, 293, 300, 4295, 3877, 307, 577, 867, 1413, 257, 1349, 7038, 512, 4560, 1314, 490, 51468, 51468, 1071, 1349, 13, 11739, 291, 362, 439, 264, 2283, 293, 550, 291, 584, 1951, 341, 4319, 11, 51860, 51860], "temperature": 0.0, "avg_logprob": -0.09548060473273783, "compression_ratio": 1.6605504587155964, "no_speech_prob": 3.479972656350583e-05}, {"id": 886, "seek": 612316, "start": 6137.72, "end": 6145.24, "text": " structure and that graph structure is how many times a word appears some distance away from", "tokens": [50364, 1133, 291, 360, 2698, 12, 48172, 24420, 2539, 294, 2487, 11, 337, 1365, 11, 291, 747, 257, 8310, 295, 2283, 293, 291, 50768, 50768, 1466, 281, 6069, 257, 1349, 294, 264, 2808, 420, 5361, 2283, 11, 2035, 436, 366, 13, 821, 307, 257, 4295, 51092, 51092, 3877, 293, 300, 4295, 3877, 307, 577, 867, 1413, 257, 1349, 7038, 512, 4560, 1314, 490, 51468, 51468, 1071, 1349, 13, 11739, 291, 362, 439, 264, 2283, 293, 550, 291, 584, 1951, 341, 4319, 11, 51860, 51860], "temperature": 0.0, "avg_logprob": -0.09548060473273783, "compression_ratio": 1.6605504587155964, "no_speech_prob": 3.479972656350583e-05}, {"id": 887, "seek": 612316, "start": 6145.24, "end": 6153.08, "text": " another word. Imagine you have all the words and then you say within this context,", "tokens": [50364, 1133, 291, 360, 2698, 12, 48172, 24420, 2539, 294, 2487, 11, 337, 1365, 11, 291, 747, 257, 8310, 295, 2283, 293, 291, 50768, 50768, 1466, 281, 6069, 257, 1349, 294, 264, 2808, 420, 5361, 2283, 11, 2035, 436, 366, 13, 821, 307, 257, 4295, 51092, 51092, 3877, 293, 300, 4295, 3877, 307, 577, 867, 1413, 257, 1349, 7038, 512, 4560, 1314, 490, 51468, 51468, 1071, 1349, 13, 11739, 291, 362, 439, 264, 2283, 293, 550, 291, 584, 1951, 341, 4319, 11, 51860, 51860], "temperature": 0.0, "avg_logprob": -0.09548060473273783, "compression_ratio": 1.6605504587155964, "no_speech_prob": 3.479972656350583e-05}, {"id": 888, "seek": 615308, "start": 6153.08, "end": 6157.96, "text": " make a graph between words. This would be a very simplified version of it, but make a graph that", "tokens": [50364, 652, 257, 4295, 1296, 2283, 13, 639, 576, 312, 257, 588, 26335, 3037, 295, 309, 11, 457, 652, 257, 4295, 300, 50608, 50608, 16203, 577, 867, 1413, 341, 1349, 7038, 257, 4560, 1045, 490, 300, 661, 1349, 13, 1396, 291, 51020, 51020, 362, 1071, 4295, 337, 4560, 472, 11, 1071, 472, 337, 4560, 732, 11, 5183, 13, 663, 44204, 257, 4295, 51292, 51292, 293, 309, 311, 257, 4295, 300, 16203, 294, 437, 4319, 732, 2283, 16561, 4204, 13, 509, 393, 519, 295, 51612, 51728], "temperature": 0.0, "avg_logprob": -0.09476682751677758, "compression_ratio": 1.819047619047619, "no_speech_prob": 3.426365219638683e-05}, {"id": 889, "seek": 615308, "start": 6157.96, "end": 6166.2, "text": " indicates how many times this word appears a distance three from that other word. Then you", "tokens": [50364, 652, 257, 4295, 1296, 2283, 13, 639, 576, 312, 257, 588, 26335, 3037, 295, 309, 11, 457, 652, 257, 4295, 300, 50608, 50608, 16203, 577, 867, 1413, 341, 1349, 7038, 257, 4560, 1045, 490, 300, 661, 1349, 13, 1396, 291, 51020, 51020, 362, 1071, 4295, 337, 4560, 472, 11, 1071, 472, 337, 4560, 732, 11, 5183, 13, 663, 44204, 257, 4295, 51292, 51292, 293, 309, 311, 257, 4295, 300, 16203, 294, 437, 4319, 732, 2283, 16561, 4204, 13, 509, 393, 519, 295, 51612, 51728], "temperature": 0.0, "avg_logprob": -0.09476682751677758, "compression_ratio": 1.819047619047619, "no_speech_prob": 3.426365219638683e-05}, {"id": 890, "seek": 615308, "start": 6166.2, "end": 6171.64, "text": " have another graph for distance one, another one for distance two, etc. That constitutes a graph", "tokens": [50364, 652, 257, 4295, 1296, 2283, 13, 639, 576, 312, 257, 588, 26335, 3037, 295, 309, 11, 457, 652, 257, 4295, 300, 50608, 50608, 16203, 577, 867, 1413, 341, 1349, 7038, 257, 4560, 1045, 490, 300, 661, 1349, 13, 1396, 291, 51020, 51020, 362, 1071, 4295, 337, 4560, 472, 11, 1071, 472, 337, 4560, 732, 11, 5183, 13, 663, 44204, 257, 4295, 51292, 51292, 293, 309, 311, 257, 4295, 300, 16203, 294, 437, 4319, 732, 2283, 16561, 4204, 13, 509, 393, 519, 295, 51612, 51728], "temperature": 0.0, "avg_logprob": -0.09476682751677758, "compression_ratio": 1.819047619047619, "no_speech_prob": 3.426365219638683e-05}, {"id": 891, "seek": 615308, "start": 6171.64, "end": 6178.04, "text": " and it's a graph that indicates in what context two words simultaneously appear. You can think of", "tokens": [50364, 652, 257, 4295, 1296, 2283, 13, 639, 576, 312, 257, 588, 26335, 3037, 295, 309, 11, 457, 652, 257, 4295, 300, 50608, 50608, 16203, 577, 867, 1413, 341, 1349, 7038, 257, 4560, 1045, 490, 300, 661, 1349, 13, 1396, 291, 51020, 51020, 362, 1071, 4295, 337, 4560, 472, 11, 1071, 472, 337, 4560, 732, 11, 5183, 13, 663, 44204, 257, 4295, 51292, 51292, 293, 309, 311, 257, 4295, 300, 16203, 294, 437, 4319, 732, 2283, 16561, 4204, 13, 509, 393, 519, 295, 51612, 51728], "temperature": 0.0, "avg_logprob": -0.09476682751677758, "compression_ratio": 1.819047619047619, "no_speech_prob": 3.426365219638683e-05}, {"id": 892, "seek": 617804, "start": 6178.04, "end": 6186.04, "text": " a text as basically a linear graph and the neighbors that you take. When you train a", "tokens": [50364, 257, 2487, 382, 1936, 257, 8213, 4295, 293, 264, 12512, 300, 291, 747, 13, 1133, 291, 3847, 257, 50764, 50764, 31782, 11, 1936, 11, 309, 311, 1940, 257, 7630, 294, 341, 4295, 13, 1133, 291, 360, 20678, 2539, 11, 51076, 51076, 264, 2010, 295, 1507, 300, 1119, 1641, 376, 742, 424, 2825, 466, 11, 1228, 8712, 488, 3097, 689, 291, 362, 732, 51388, 51388, 10938, 300, 291, 458, 366, 2531, 293, 732, 10938, 291, 458, 366, 7802, 332, 2202, 11, 341, 1936, 307, 257, 4295, 13, 51620, 51620], "temperature": 0.0, "avg_logprob": -0.2227616416083442, "compression_ratio": 1.7819905213270142, "no_speech_prob": 1.6700345440767705e-05}, {"id": 893, "seek": 617804, "start": 6186.04, "end": 6192.28, "text": " transformer, basically, it's taking a neighborhood in this graph. When you do metric learning,", "tokens": [50364, 257, 2487, 382, 1936, 257, 8213, 4295, 293, 264, 12512, 300, 291, 747, 13, 1133, 291, 3847, 257, 50764, 50764, 31782, 11, 1936, 11, 309, 311, 1940, 257, 7630, 294, 341, 4295, 13, 1133, 291, 360, 20678, 2539, 11, 51076, 51076, 264, 2010, 295, 1507, 300, 1119, 1641, 376, 742, 424, 2825, 466, 11, 1228, 8712, 488, 3097, 689, 291, 362, 732, 51388, 51388, 10938, 300, 291, 458, 366, 2531, 293, 732, 10938, 291, 458, 366, 7802, 332, 2202, 11, 341, 1936, 307, 257, 4295, 13, 51620, 51620], "temperature": 0.0, "avg_logprob": -0.2227616416083442, "compression_ratio": 1.7819905213270142, "no_speech_prob": 1.6700345440767705e-05}, {"id": 894, "seek": 617804, "start": 6192.28, "end": 6198.5199999999995, "text": " the type of stuff that Isha Mishra talked about, using contrastive training where you have two", "tokens": [50364, 257, 2487, 382, 1936, 257, 8213, 4295, 293, 264, 12512, 300, 291, 747, 13, 1133, 291, 3847, 257, 50764, 50764, 31782, 11, 1936, 11, 309, 311, 1940, 257, 7630, 294, 341, 4295, 13, 1133, 291, 360, 20678, 2539, 11, 51076, 51076, 264, 2010, 295, 1507, 300, 1119, 1641, 376, 742, 424, 2825, 466, 11, 1228, 8712, 488, 3097, 689, 291, 362, 732, 51388, 51388, 10938, 300, 291, 458, 366, 2531, 293, 732, 10938, 291, 458, 366, 7802, 332, 2202, 11, 341, 1936, 307, 257, 4295, 13, 51620, 51620], "temperature": 0.0, "avg_logprob": -0.2227616416083442, "compression_ratio": 1.7819905213270142, "no_speech_prob": 1.6700345440767705e-05}, {"id": 895, "seek": 617804, "start": 6198.5199999999995, "end": 6203.16, "text": " samples that you know are similar and two samples you know are dissimilar, this basically is a graph.", "tokens": [50364, 257, 2487, 382, 1936, 257, 8213, 4295, 293, 264, 12512, 300, 291, 747, 13, 1133, 291, 3847, 257, 50764, 50764, 31782, 11, 1936, 11, 309, 311, 1940, 257, 7630, 294, 341, 4295, 13, 1133, 291, 360, 20678, 2539, 11, 51076, 51076, 264, 2010, 295, 1507, 300, 1119, 1641, 376, 742, 424, 2825, 466, 11, 1228, 8712, 488, 3097, 689, 291, 362, 732, 51388, 51388, 10938, 300, 291, 458, 366, 2531, 293, 732, 10938, 291, 458, 366, 7802, 332, 2202, 11, 341, 1936, 307, 257, 4295, 13, 51620, 51620], "temperature": 0.0, "avg_logprob": -0.2227616416083442, "compression_ratio": 1.7819905213270142, "no_speech_prob": 1.6700345440767705e-05}, {"id": 896, "seek": 620316, "start": 6203.16, "end": 6208.2, "text": " It's a similarity graph that you're using. You're telling the system, here are two samples that are", "tokens": [50364, 467, 311, 257, 32194, 4295, 300, 291, 434, 1228, 13, 509, 434, 3585, 264, 1185, 11, 510, 366, 732, 10938, 300, 366, 50616, 50616, 9408, 570, 286, 458, 436, 366, 2531, 293, 510, 366, 732, 10938, 300, 286, 458, 366, 406, 9408, 570, 50848, 50848, 286, 458, 436, 434, 7802, 332, 2202, 13, 286, 478, 1382, 281, 915, 257, 4295, 12240, 3584, 11, 4476, 13, 509, 393, 519, 295, 51096, 51096, 729, 18161, 36170, 366, 2539, 257, 4295, 12240, 3584, 337, 13891, 370, 300, 13891, 300, 366, 9408, 294, 264, 51416, 51416, 4295, 362, 2531, 18875, 293, 13891, 300, 366, 406, 366, 7802, 332, 2202, 18875, 13, 821, 307, 257, 588, 11, 588, 51732, 51732], "temperature": 0.0, "avg_logprob": -0.1451638865674663, "compression_ratio": 2.0638297872340425, "no_speech_prob": 1.8629916667123325e-05}, {"id": 897, "seek": 620316, "start": 6208.2, "end": 6212.84, "text": " linked because I know they are similar and here are two samples that I know are not linked because", "tokens": [50364, 467, 311, 257, 32194, 4295, 300, 291, 434, 1228, 13, 509, 434, 3585, 264, 1185, 11, 510, 366, 732, 10938, 300, 366, 50616, 50616, 9408, 570, 286, 458, 436, 366, 2531, 293, 510, 366, 732, 10938, 300, 286, 458, 366, 406, 9408, 570, 50848, 50848, 286, 458, 436, 434, 7802, 332, 2202, 13, 286, 478, 1382, 281, 915, 257, 4295, 12240, 3584, 11, 4476, 13, 509, 393, 519, 295, 51096, 51096, 729, 18161, 36170, 366, 2539, 257, 4295, 12240, 3584, 337, 13891, 370, 300, 13891, 300, 366, 9408, 294, 264, 51416, 51416, 4295, 362, 2531, 18875, 293, 13891, 300, 366, 406, 366, 7802, 332, 2202, 18875, 13, 821, 307, 257, 588, 11, 588, 51732, 51732], "temperature": 0.0, "avg_logprob": -0.1451638865674663, "compression_ratio": 2.0638297872340425, "no_speech_prob": 1.8629916667123325e-05}, {"id": 898, "seek": 620316, "start": 6212.84, "end": 6217.8, "text": " I know they're dissimilar. I'm trying to find a graph embedding, essentially. You can think of", "tokens": [50364, 467, 311, 257, 32194, 4295, 300, 291, 434, 1228, 13, 509, 434, 3585, 264, 1185, 11, 510, 366, 732, 10938, 300, 366, 50616, 50616, 9408, 570, 286, 458, 436, 366, 2531, 293, 510, 366, 732, 10938, 300, 286, 458, 366, 406, 9408, 570, 50848, 50848, 286, 458, 436, 434, 7802, 332, 2202, 13, 286, 478, 1382, 281, 915, 257, 4295, 12240, 3584, 11, 4476, 13, 509, 393, 519, 295, 51096, 51096, 729, 18161, 36170, 366, 2539, 257, 4295, 12240, 3584, 337, 13891, 370, 300, 13891, 300, 366, 9408, 294, 264, 51416, 51416, 4295, 362, 2531, 18875, 293, 13891, 300, 366, 406, 366, 7802, 332, 2202, 18875, 13, 821, 307, 257, 588, 11, 588, 51732, 51732], "temperature": 0.0, "avg_logprob": -0.1451638865674663, "compression_ratio": 2.0638297872340425, "no_speech_prob": 1.8629916667123325e-05}, {"id": 899, "seek": 620316, "start": 6217.8, "end": 6224.2, "text": " those neural nets are learning a graph embedding for nodes so that nodes that are linked in the", "tokens": [50364, 467, 311, 257, 32194, 4295, 300, 291, 434, 1228, 13, 509, 434, 3585, 264, 1185, 11, 510, 366, 732, 10938, 300, 366, 50616, 50616, 9408, 570, 286, 458, 436, 366, 2531, 293, 510, 366, 732, 10938, 300, 286, 458, 366, 406, 9408, 570, 50848, 50848, 286, 458, 436, 434, 7802, 332, 2202, 13, 286, 478, 1382, 281, 915, 257, 4295, 12240, 3584, 11, 4476, 13, 509, 393, 519, 295, 51096, 51096, 729, 18161, 36170, 366, 2539, 257, 4295, 12240, 3584, 337, 13891, 370, 300, 13891, 300, 366, 9408, 294, 264, 51416, 51416, 4295, 362, 2531, 18875, 293, 13891, 300, 366, 406, 366, 7802, 332, 2202, 18875, 13, 821, 307, 257, 588, 11, 588, 51732, 51732], "temperature": 0.0, "avg_logprob": -0.1451638865674663, "compression_ratio": 2.0638297872340425, "no_speech_prob": 1.8629916667123325e-05}, {"id": 900, "seek": 620316, "start": 6224.2, "end": 6230.5199999999995, "text": " graph have similar vectors and nodes that are not are dissimilar vectors. There is a very, very", "tokens": [50364, 467, 311, 257, 32194, 4295, 300, 291, 434, 1228, 13, 509, 434, 3585, 264, 1185, 11, 510, 366, 732, 10938, 300, 366, 50616, 50616, 9408, 570, 286, 458, 436, 366, 2531, 293, 510, 366, 732, 10938, 300, 286, 458, 366, 406, 9408, 570, 50848, 50848, 286, 458, 436, 434, 7802, 332, 2202, 13, 286, 478, 1382, 281, 915, 257, 4295, 12240, 3584, 11, 4476, 13, 509, 393, 519, 295, 51096, 51096, 729, 18161, 36170, 366, 2539, 257, 4295, 12240, 3584, 337, 13891, 370, 300, 13891, 300, 366, 9408, 294, 264, 51416, 51416, 4295, 362, 2531, 18875, 293, 13891, 300, 366, 406, 366, 7802, 332, 2202, 18875, 13, 821, 307, 257, 588, 11, 588, 51732, 51732], "temperature": 0.0, "avg_logprob": -0.1451638865674663, "compression_ratio": 2.0638297872340425, "no_speech_prob": 1.8629916667123325e-05}, {"id": 901, "seek": 623052, "start": 6230.52, "end": 6239.64, "text": " strong connection between self-supervised learning and the graph view of a training set. I don't", "tokens": [50364, 2068, 4984, 1296, 2698, 12, 48172, 24420, 2539, 293, 264, 4295, 1910, 295, 257, 3097, 992, 13, 286, 500, 380, 50820, 50820, 519, 309, 311, 668, 40918, 420, 5334, 1939, 538, 257, 688, 295, 561, 11, 370, 456, 1062, 312, 534, 1880, 51060, 51060, 1507, 281, 360, 456, 13, 286, 500, 380, 458, 437, 291, 519, 466, 341, 11, 44653, 13, 51180, 51180, 865, 11, 2293, 13, 639, 307, 2584, 4077, 281, 264, 4295, 13, 509, 500, 380, 362, 604, 51468, 51468, 2570, 26381, 13, 708, 291, 366, 2577, 307, 2293, 300, 13, 1012, 360, 321, 483, 26381, 1296, 51796, 51796], "temperature": 0.0, "avg_logprob": -0.21295406748947587, "compression_ratio": 1.6550387596899225, "no_speech_prob": 7.353487308137119e-05}, {"id": 902, "seek": 623052, "start": 6239.64, "end": 6244.4400000000005, "text": " think it's been exploited or realized yet by a lot of people, so there might be really interesting", "tokens": [50364, 2068, 4984, 1296, 2698, 12, 48172, 24420, 2539, 293, 264, 4295, 1910, 295, 257, 3097, 992, 13, 286, 500, 380, 50820, 50820, 519, 309, 311, 668, 40918, 420, 5334, 1939, 538, 257, 688, 295, 561, 11, 370, 456, 1062, 312, 534, 1880, 51060, 51060, 1507, 281, 360, 456, 13, 286, 500, 380, 458, 437, 291, 519, 466, 341, 11, 44653, 13, 51180, 51180, 865, 11, 2293, 13, 639, 307, 2584, 4077, 281, 264, 4295, 13, 509, 500, 380, 362, 604, 51468, 51468, 2570, 26381, 13, 708, 291, 366, 2577, 307, 2293, 300, 13, 1012, 360, 321, 483, 26381, 1296, 51796, 51796], "temperature": 0.0, "avg_logprob": -0.21295406748947587, "compression_ratio": 1.6550387596899225, "no_speech_prob": 7.353487308137119e-05}, {"id": 903, "seek": 623052, "start": 6244.4400000000005, "end": 6246.84, "text": " stuff to do there. I don't know what you think about this, Xavier.", "tokens": [50364, 2068, 4984, 1296, 2698, 12, 48172, 24420, 2539, 293, 264, 4295, 1910, 295, 257, 3097, 992, 13, 286, 500, 380, 50820, 50820, 519, 309, 311, 668, 40918, 420, 5334, 1939, 538, 257, 688, 295, 561, 11, 370, 456, 1062, 312, 534, 1880, 51060, 51060, 1507, 281, 360, 456, 13, 286, 500, 380, 458, 437, 291, 519, 466, 341, 11, 44653, 13, 51180, 51180, 865, 11, 2293, 13, 639, 307, 2584, 4077, 281, 264, 4295, 13, 509, 500, 380, 362, 604, 51468, 51468, 2570, 26381, 13, 708, 291, 366, 2577, 307, 2293, 300, 13, 1012, 360, 321, 483, 26381, 1296, 51796, 51796], "temperature": 0.0, "avg_logprob": -0.21295406748947587, "compression_ratio": 1.6550387596899225, "no_speech_prob": 7.353487308137119e-05}, {"id": 904, "seek": 623052, "start": 6246.84, "end": 6252.6, "text": " Yeah, exactly. This is completely related to the graph. You don't have any", "tokens": [50364, 2068, 4984, 1296, 2698, 12, 48172, 24420, 2539, 293, 264, 4295, 1910, 295, 257, 3097, 992, 13, 286, 500, 380, 50820, 50820, 519, 309, 311, 668, 40918, 420, 5334, 1939, 538, 257, 688, 295, 561, 11, 370, 456, 1062, 312, 534, 1880, 51060, 51060, 1507, 281, 360, 456, 13, 286, 500, 380, 458, 437, 291, 519, 466, 341, 11, 44653, 13, 51180, 51180, 865, 11, 2293, 13, 639, 307, 2584, 4077, 281, 264, 4295, 13, 509, 500, 380, 362, 604, 51468, 51468, 2570, 26381, 13, 708, 291, 366, 2577, 307, 2293, 300, 13, 1012, 360, 321, 483, 26381, 1296, 51796, 51796], "temperature": 0.0, "avg_logprob": -0.21295406748947587, "compression_ratio": 1.6550387596899225, "no_speech_prob": 7.353487308137119e-05}, {"id": 905, "seek": 623052, "start": 6252.6, "end": 6259.160000000001, "text": " known positioning. What you are seeing is exactly that. How do we get positioning between", "tokens": [50364, 2068, 4984, 1296, 2698, 12, 48172, 24420, 2539, 293, 264, 4295, 1910, 295, 257, 3097, 992, 13, 286, 500, 380, 50820, 50820, 519, 309, 311, 668, 40918, 420, 5334, 1939, 538, 257, 688, 295, 561, 11, 370, 456, 1062, 312, 534, 1880, 51060, 51060, 1507, 281, 360, 456, 13, 286, 500, 380, 458, 437, 291, 519, 466, 341, 11, 44653, 13, 51180, 51180, 865, 11, 2293, 13, 639, 307, 2584, 4077, 281, 264, 4295, 13, 509, 500, 380, 362, 604, 51468, 51468, 2570, 26381, 13, 708, 291, 366, 2577, 307, 2293, 300, 13, 1012, 360, 321, 483, 26381, 1296, 51796, 51796], "temperature": 0.0, "avg_logprob": -0.21295406748947587, "compression_ratio": 1.6550387596899225, "no_speech_prob": 7.353487308137119e-05}, {"id": 906, "seek": 625916, "start": 6259.16, "end": 6264.84, "text": " nodes that are relevant to your particular application? You want to do it in a self-supervised", "tokens": [50364, 13891, 300, 366, 7340, 281, 428, 1729, 3861, 30, 509, 528, 281, 360, 309, 294, 257, 2698, 12, 48172, 24420, 50648, 50648, 636, 570, 550, 291, 486, 1466, 439, 1944, 31493, 293, 291, 500, 380, 643, 281, 362, 16949, 51012, 51012, 281, 360, 300, 13, 639, 307, 264, 935, 13, 759, 291, 458, 577, 281, 6794, 13891, 11, 370, 1936, 577, 360, 291, 8947, 51504, 51504], "temperature": 0.0, "avg_logprob": -0.16546796349918141, "compression_ratio": 1.4921465968586387, "no_speech_prob": 1.1475169230834581e-05}, {"id": 907, "seek": 625916, "start": 6264.84, "end": 6272.12, "text": " way because then you will learn all possible configurations and you don't need to have labels", "tokens": [50364, 13891, 300, 366, 7340, 281, 428, 1729, 3861, 30, 509, 528, 281, 360, 309, 294, 257, 2698, 12, 48172, 24420, 50648, 50648, 636, 570, 550, 291, 486, 1466, 439, 1944, 31493, 293, 291, 500, 380, 643, 281, 362, 16949, 51012, 51012, 281, 360, 300, 13, 639, 307, 264, 935, 13, 759, 291, 458, 577, 281, 6794, 13891, 11, 370, 1936, 577, 360, 291, 8947, 51504, 51504], "temperature": 0.0, "avg_logprob": -0.16546796349918141, "compression_ratio": 1.4921465968586387, "no_speech_prob": 1.1475169230834581e-05}, {"id": 908, "seek": 625916, "start": 6272.12, "end": 6281.96, "text": " to do that. This is the point. If you know how to compare nodes, so basically how do you extract", "tokens": [50364, 13891, 300, 366, 7340, 281, 428, 1729, 3861, 30, 509, 528, 281, 360, 309, 294, 257, 2698, 12, 48172, 24420, 50648, 50648, 636, 570, 550, 291, 486, 1466, 439, 1944, 31493, 293, 291, 500, 380, 643, 281, 362, 16949, 51012, 51012, 281, 360, 300, 13, 639, 307, 264, 935, 13, 759, 291, 458, 577, 281, 6794, 13891, 11, 370, 1936, 577, 360, 291, 8947, 51504, 51504], "temperature": 0.0, "avg_logprob": -0.16546796349918141, "compression_ratio": 1.4921465968586387, "no_speech_prob": 1.1475169230834581e-05}, {"id": 909, "seek": 628196, "start": 6281.96, "end": 6289.32, "text": " positional encoding, then you will do a great job. That's one of the most important questions in", "tokens": [50364, 2535, 304, 43430, 11, 550, 291, 486, 360, 257, 869, 1691, 13, 663, 311, 472, 295, 264, 881, 1021, 1651, 294, 50732, 50732, 4295, 18161, 9590, 293, 611, 337, 426, 45196, 293, 867, 661, 5821, 13, 50904, 50904, 3769, 13, 1044, 291, 13, 51004, 51004, 316, 1168, 445, 6678, 510, 13, 7497, 291, 6264, 5078, 264, 881, 1021, 3166, 295, 4295, 51296, 51296, 365, 3202, 30, 286, 519, 321, 1310, 362, 2780, 257, 707, 4663, 293, 1580, 658, 257, 707, 857, 2731, 13, 51580, 51580], "temperature": 0.0, "avg_logprob": -0.22093485689711298, "compression_ratio": 1.5702127659574467, "no_speech_prob": 7.017615280346945e-05}, {"id": 910, "seek": 628196, "start": 6289.32, "end": 6292.76, "text": " graph neural networks and also for NLP and many other applications.", "tokens": [50364, 2535, 304, 43430, 11, 550, 291, 486, 360, 257, 869, 1691, 13, 663, 311, 472, 295, 264, 881, 1021, 1651, 294, 50732, 50732, 4295, 18161, 9590, 293, 611, 337, 426, 45196, 293, 867, 661, 5821, 13, 50904, 50904, 3769, 13, 1044, 291, 13, 51004, 51004, 316, 1168, 445, 6678, 510, 13, 7497, 291, 6264, 5078, 264, 881, 1021, 3166, 295, 4295, 51296, 51296, 365, 3202, 30, 286, 519, 321, 1310, 362, 2780, 257, 707, 4663, 293, 1580, 658, 257, 707, 857, 2731, 13, 51580, 51580], "temperature": 0.0, "avg_logprob": -0.22093485689711298, "compression_ratio": 1.5702127659574467, "no_speech_prob": 7.017615280346945e-05}, {"id": 911, "seek": 628196, "start": 6292.76, "end": 6294.76, "text": " Great. Thank you.", "tokens": [50364, 2535, 304, 43430, 11, 550, 291, 486, 360, 257, 869, 1691, 13, 663, 311, 472, 295, 264, 881, 1021, 1651, 294, 50732, 50732, 4295, 18161, 9590, 293, 611, 337, 426, 45196, 293, 867, 661, 5821, 13, 50904, 50904, 3769, 13, 1044, 291, 13, 51004, 51004, 316, 1168, 445, 6678, 510, 13, 7497, 291, 6264, 5078, 264, 881, 1021, 3166, 295, 4295, 51296, 51296, 365, 3202, 30, 286, 519, 321, 1310, 362, 2780, 257, 707, 4663, 293, 1580, 658, 257, 707, 857, 2731, 13, 51580, 51580], "temperature": 0.0, "avg_logprob": -0.22093485689711298, "compression_ratio": 1.5702127659574467, "no_speech_prob": 7.017615280346945e-05}, {"id": 912, "seek": 628196, "start": 6294.76, "end": 6300.6, "text": " A question just arrived here. Could you possibly highlight the most important parts of graph", "tokens": [50364, 2535, 304, 43430, 11, 550, 291, 486, 360, 257, 869, 1691, 13, 663, 311, 472, 295, 264, 881, 1021, 1651, 294, 50732, 50732, 4295, 18161, 9590, 293, 611, 337, 426, 45196, 293, 867, 661, 5821, 13, 50904, 50904, 3769, 13, 1044, 291, 13, 51004, 51004, 316, 1168, 445, 6678, 510, 13, 7497, 291, 6264, 5078, 264, 881, 1021, 3166, 295, 4295, 51296, 51296, 365, 3202, 30, 286, 519, 321, 1310, 362, 2780, 257, 707, 4663, 293, 1580, 658, 257, 707, 857, 2731, 13, 51580, 51580], "temperature": 0.0, "avg_logprob": -0.22093485689711298, "compression_ratio": 1.5702127659574467, "no_speech_prob": 7.017615280346945e-05}, {"id": 913, "seek": 628196, "start": 6300.6, "end": 6306.28, "text": " with attention? I think we maybe have gone a little faster and someone got a little bit lost.", "tokens": [50364, 2535, 304, 43430, 11, 550, 291, 486, 360, 257, 869, 1691, 13, 663, 311, 472, 295, 264, 881, 1021, 1651, 294, 50732, 50732, 4295, 18161, 9590, 293, 611, 337, 426, 45196, 293, 867, 661, 5821, 13, 50904, 50904, 3769, 13, 1044, 291, 13, 51004, 51004, 316, 1168, 445, 6678, 510, 13, 7497, 291, 6264, 5078, 264, 881, 1021, 3166, 295, 4295, 51296, 51296, 365, 3202, 30, 286, 519, 321, 1310, 362, 2780, 257, 707, 4663, 293, 1580, 658, 257, 707, 857, 2731, 13, 51580, 51580], "temperature": 0.0, "avg_logprob": -0.22093485689711298, "compression_ratio": 1.5702127659574467, "no_speech_prob": 7.017615280346945e-05}, {"id": 914, "seek": 630628, "start": 6306.28, "end": 6316.12, "text": " Graph attention network, the first technique was developed by Yoshua Benjo, Peter,", "tokens": [50364, 21884, 3202, 3209, 11, 264, 700, 6532, 390, 4743, 538, 38949, 4398, 3964, 5134, 11, 6508, 11, 50856, 50856, 293, 370, 309, 311, 1391, 264, 700, 589, 291, 576, 411, 281, 536, 13, 509, 393, 611, 747, 264, 31782, 11, 51340, 51340, 264, 3832, 31782, 11, 293, 550, 291, 393, 652, 309, 257, 4295, 3037, 13, 467, 311, 1596, 15325, 281, 360, 309, 13, 51648, 51648], "temperature": 0.0, "avg_logprob": -0.3192307247835047, "compression_ratio": 1.5271739130434783, "no_speech_prob": 0.00010060370550490916}, {"id": 915, "seek": 630628, "start": 6316.12, "end": 6325.8, "text": " and so it's probably the first work you would like to see. You can also take the transformer,", "tokens": [50364, 21884, 3202, 3209, 11, 264, 700, 6532, 390, 4743, 538, 38949, 4398, 3964, 5134, 11, 6508, 11, 50856, 50856, 293, 370, 309, 311, 1391, 264, 700, 589, 291, 576, 411, 281, 536, 13, 509, 393, 611, 747, 264, 31782, 11, 51340, 51340, 264, 3832, 31782, 11, 293, 550, 291, 393, 652, 309, 257, 4295, 3037, 13, 467, 311, 1596, 15325, 281, 360, 309, 13, 51648, 51648], "temperature": 0.0, "avg_logprob": -0.3192307247835047, "compression_ratio": 1.5271739130434783, "no_speech_prob": 0.00010060370550490916}, {"id": 916, "seek": 630628, "start": 6325.8, "end": 6331.96, "text": " the standard transformer, and then you can make it a graph version. It's quite straightforward to do it.", "tokens": [50364, 21884, 3202, 3209, 11, 264, 700, 6532, 390, 4743, 538, 38949, 4398, 3964, 5134, 11, 6508, 11, 50856, 50856, 293, 370, 309, 311, 1391, 264, 700, 589, 291, 576, 411, 281, 536, 13, 509, 393, 611, 747, 264, 31782, 11, 51340, 51340, 264, 3832, 31782, 11, 293, 550, 291, 393, 652, 309, 257, 4295, 3037, 13, 467, 311, 1596, 15325, 281, 360, 309, 13, 51648, 51648], "temperature": 0.0, "avg_logprob": -0.3192307247835047, "compression_ratio": 1.5271739130434783, "no_speech_prob": 0.00010060370550490916}, {"id": 917, "seek": 633196, "start": 6331.96, "end": 6337.32, "text": " Just by multiplying with the agency matrix, right?", "tokens": [50364, 1449, 538, 30955, 365, 264, 7934, 8141, 11, 558, 30, 50632, 50632, 865, 11, 2293, 13, 509, 393, 1217, 360, 309, 365, 9953, 51, 284, 339, 31782, 13, 821, 307, 257, 6094, 13, 50876, 50920, 7587, 11, 365, 257, 3175, 13202, 13, 50992, 50992, 865, 11, 257, 6094, 13, 7587, 13, 759, 291, 829, 3175, 13202, 365, 2787, 41167, 11, 291, 486, 483, 4018, 13, 51200, 51200, 7587, 13, 286, 519, 286, 478, 516, 281, 855, 341, 4153, 13, 51308, 51308, 865, 11, 2293, 13, 509, 393, 1217, 360, 4295, 31782, 588, 3612, 365, 9953, 51, 284, 339, 13, 51576, 51616], "temperature": 0.0, "avg_logprob": -0.2088973591628584, "compression_ratio": 1.7714285714285714, "no_speech_prob": 9.738119842950255e-05}, {"id": 918, "seek": 633196, "start": 6337.32, "end": 6342.2, "text": " Yeah, exactly. You can already do it with PyTorch transformer. There is a mask.", "tokens": [50364, 1449, 538, 30955, 365, 264, 7934, 8141, 11, 558, 30, 50632, 50632, 865, 11, 2293, 13, 509, 393, 1217, 360, 309, 365, 9953, 51, 284, 339, 31782, 13, 821, 307, 257, 6094, 13, 50876, 50920, 7587, 11, 365, 257, 3175, 13202, 13, 50992, 50992, 865, 11, 257, 6094, 13, 7587, 13, 759, 291, 829, 3175, 13202, 365, 2787, 41167, 11, 291, 486, 483, 4018, 13, 51200, 51200, 7587, 13, 286, 519, 286, 478, 516, 281, 855, 341, 4153, 13, 51308, 51308, 865, 11, 2293, 13, 509, 393, 1217, 360, 4295, 31782, 588, 3612, 365, 9953, 51, 284, 339, 13, 51576, 51616], "temperature": 0.0, "avg_logprob": -0.2088973591628584, "compression_ratio": 1.7714285714285714, "no_speech_prob": 9.738119842950255e-05}, {"id": 919, "seek": 633196, "start": 6343.08, "end": 6344.52, "text": " Exactly, with a minus infinity.", "tokens": [50364, 1449, 538, 30955, 365, 264, 7934, 8141, 11, 558, 30, 50632, 50632, 865, 11, 2293, 13, 509, 393, 1217, 360, 309, 365, 9953, 51, 284, 339, 31782, 13, 821, 307, 257, 6094, 13, 50876, 50920, 7587, 11, 365, 257, 3175, 13202, 13, 50992, 50992, 865, 11, 257, 6094, 13, 7587, 13, 759, 291, 829, 3175, 13202, 365, 2787, 41167, 11, 291, 486, 483, 4018, 13, 51200, 51200, 7587, 13, 286, 519, 286, 478, 516, 281, 855, 341, 4153, 13, 51308, 51308, 865, 11, 2293, 13, 509, 393, 1217, 360, 4295, 31782, 588, 3612, 365, 9953, 51, 284, 339, 13, 51576, 51616], "temperature": 0.0, "avg_logprob": -0.2088973591628584, "compression_ratio": 1.7714285714285714, "no_speech_prob": 9.738119842950255e-05}, {"id": 920, "seek": 633196, "start": 6344.52, "end": 6348.68, "text": " Yeah, a mask. Exactly. If you put minus infinity with softmax, you will get zero.", "tokens": [50364, 1449, 538, 30955, 365, 264, 7934, 8141, 11, 558, 30, 50632, 50632, 865, 11, 2293, 13, 509, 393, 1217, 360, 309, 365, 9953, 51, 284, 339, 31782, 13, 821, 307, 257, 6094, 13, 50876, 50920, 7587, 11, 365, 257, 3175, 13202, 13, 50992, 50992, 865, 11, 257, 6094, 13, 7587, 13, 759, 291, 829, 3175, 13202, 365, 2787, 41167, 11, 291, 486, 483, 4018, 13, 51200, 51200, 7587, 13, 286, 519, 286, 478, 516, 281, 855, 341, 4153, 13, 51308, 51308, 865, 11, 2293, 13, 509, 393, 1217, 360, 4295, 31782, 588, 3612, 365, 9953, 51, 284, 339, 13, 51576, 51616], "temperature": 0.0, "avg_logprob": -0.2088973591628584, "compression_ratio": 1.7714285714285714, "no_speech_prob": 9.738119842950255e-05}, {"id": 921, "seek": 633196, "start": 6348.68, "end": 6350.84, "text": " Exactly. I think I'm going to show this tomorrow.", "tokens": [50364, 1449, 538, 30955, 365, 264, 7934, 8141, 11, 558, 30, 50632, 50632, 865, 11, 2293, 13, 509, 393, 1217, 360, 309, 365, 9953, 51, 284, 339, 31782, 13, 821, 307, 257, 6094, 13, 50876, 50920, 7587, 11, 365, 257, 3175, 13202, 13, 50992, 50992, 865, 11, 257, 6094, 13, 7587, 13, 759, 291, 829, 3175, 13202, 365, 2787, 41167, 11, 291, 486, 483, 4018, 13, 51200, 51200, 7587, 13, 286, 519, 286, 478, 516, 281, 855, 341, 4153, 13, 51308, 51308, 865, 11, 2293, 13, 509, 393, 1217, 360, 4295, 31782, 588, 3612, 365, 9953, 51, 284, 339, 13, 51576, 51616], "temperature": 0.0, "avg_logprob": -0.2088973591628584, "compression_ratio": 1.7714285714285714, "no_speech_prob": 9.738119842950255e-05}, {"id": 922, "seek": 633196, "start": 6350.84, "end": 6356.2, "text": " Yeah, exactly. You can already do graph transformer very easily with PyTorch.", "tokens": [50364, 1449, 538, 30955, 365, 264, 7934, 8141, 11, 558, 30, 50632, 50632, 865, 11, 2293, 13, 509, 393, 1217, 360, 309, 365, 9953, 51, 284, 339, 31782, 13, 821, 307, 257, 6094, 13, 50876, 50920, 7587, 11, 365, 257, 3175, 13202, 13, 50992, 50992, 865, 11, 257, 6094, 13, 7587, 13, 759, 291, 829, 3175, 13202, 365, 2787, 41167, 11, 291, 486, 483, 4018, 13, 51200, 51200, 7587, 13, 286, 519, 286, 478, 516, 281, 855, 341, 4153, 13, 51308, 51308, 865, 11, 2293, 13, 509, 393, 1217, 360, 4295, 31782, 588, 3612, 365, 9953, 51, 284, 339, 13, 51576, 51616], "temperature": 0.0, "avg_logprob": -0.2088973591628584, "compression_ratio": 1.7714285714285714, "no_speech_prob": 9.738119842950255e-05}, {"id": 923, "seek": 635620, "start": 6356.2, "end": 6364.44, "text": " But the thing is, it's going to be a full matrix. It's going to use a lot of your GME memory", "tokens": [50364, 583, 264, 551, 307, 11, 309, 311, 516, 281, 312, 257, 1577, 8141, 13, 467, 311, 516, 281, 764, 257, 688, 295, 428, 460, 15454, 4675, 50776, 50776, 570, 456, 366, 867, 4190, 300, 291, 500, 380, 643, 13, 759, 291, 528, 281, 4373, 281, 4833, 24877, 11, 51096, 51096, 550, 291, 643, 746, 300, 45473, 264, 637, 685, 507, 411, 413, 19440, 420, 9953, 51, 284, 339, 33246, 11, 337, 1365, 13, 51384, 51384, 5264, 1243, 11, 321, 34874, 490, 8459, 13, 492, 767, 536, 439, 264, 7705, 1854, 11, 51660, 51660], "temperature": 0.0, "avg_logprob": -0.16575870513916016, "compression_ratio": 1.5128205128205128, "no_speech_prob": 4.398277815198526e-05}, {"id": 924, "seek": 635620, "start": 6364.44, "end": 6370.84, "text": " because there are many values that you don't need. If you want to scale to larger graphs,", "tokens": [50364, 583, 264, 551, 307, 11, 309, 311, 516, 281, 312, 257, 1577, 8141, 13, 467, 311, 516, 281, 764, 257, 688, 295, 428, 460, 15454, 4675, 50776, 50776, 570, 456, 366, 867, 4190, 300, 291, 500, 380, 643, 13, 759, 291, 528, 281, 4373, 281, 4833, 24877, 11, 51096, 51096, 550, 291, 643, 746, 300, 45473, 264, 637, 685, 507, 411, 413, 19440, 420, 9953, 51, 284, 339, 33246, 11, 337, 1365, 13, 51384, 51384, 5264, 1243, 11, 321, 34874, 490, 8459, 13, 492, 767, 536, 439, 264, 7705, 1854, 11, 51660, 51660], "temperature": 0.0, "avg_logprob": -0.16575870513916016, "compression_ratio": 1.5128205128205128, "no_speech_prob": 4.398277815198526e-05}, {"id": 925, "seek": 635620, "start": 6370.84, "end": 6376.599999999999, "text": " then you need something that explores the sparsity like DGL or PyTorch geometric, for example.", "tokens": [50364, 583, 264, 551, 307, 11, 309, 311, 516, 281, 312, 257, 1577, 8141, 13, 467, 311, 516, 281, 764, 257, 688, 295, 428, 460, 15454, 4675, 50776, 50776, 570, 456, 366, 867, 4190, 300, 291, 500, 380, 643, 13, 759, 291, 528, 281, 4373, 281, 4833, 24877, 11, 51096, 51096, 550, 291, 643, 746, 300, 45473, 264, 637, 685, 507, 411, 413, 19440, 420, 9953, 51, 284, 339, 33246, 11, 337, 1365, 13, 51384, 51384, 5264, 1243, 11, 321, 34874, 490, 8459, 13, 492, 767, 536, 439, 264, 7705, 1854, 11, 51660, 51660], "temperature": 0.0, "avg_logprob": -0.16575870513916016, "compression_ratio": 1.5128205128205128, "no_speech_prob": 4.398277815198526e-05}, {"id": 926, "seek": 635620, "start": 6376.599999999999, "end": 6382.12, "text": " Last week, we coded from scratch. We actually see all the operations inside,", "tokens": [50364, 583, 264, 551, 307, 11, 309, 311, 516, 281, 312, 257, 1577, 8141, 13, 467, 311, 516, 281, 764, 257, 688, 295, 428, 460, 15454, 4675, 50776, 50776, 570, 456, 366, 867, 4190, 300, 291, 500, 380, 643, 13, 759, 291, 528, 281, 4373, 281, 4833, 24877, 11, 51096, 51096, 550, 291, 643, 746, 300, 45473, 264, 637, 685, 507, 411, 413, 19440, 420, 9953, 51, 284, 339, 33246, 11, 337, 1365, 13, 51384, 51384, 5264, 1243, 11, 321, 34874, 490, 8459, 13, 492, 767, 536, 439, 264, 7705, 1854, 11, 51660, 51660], "temperature": 0.0, "avg_logprob": -0.16575870513916016, "compression_ratio": 1.5128205128205128, "no_speech_prob": 4.398277815198526e-05}, {"id": 927, "seek": 638212, "start": 6382.12, "end": 6387.48, "text": " and then maybe we can just add one additional matrix there just to make this masked part such", "tokens": [50364, 293, 550, 1310, 321, 393, 445, 909, 472, 4497, 8141, 456, 445, 281, 652, 341, 45249, 644, 1270, 50632, 50632, 300, 321, 393, 30254, 264, 4295, 45216, 304, 2533, 490, 264, 3089, 300, 321, 1217, 362, 3720, 13, 50888, 50888, 407, 300, 576, 312, 11, 286, 519, 11, 257, 4984, 337, 4153, 13, 6962, 322, 13, 821, 366, 544, 1651, 51120, 51120, 1348, 13, 1119, 456, 604, 3861, 689, 1228, 5995, 8929, 7129, 1062, 312, 1101, 813, 23598, 29435, 45, 30, 51476, 51704], "temperature": 0.0, "avg_logprob": -0.13636906567741844, "compression_ratio": 1.5560344827586208, "no_speech_prob": 0.0001711606455501169}, {"id": 928, "seek": 638212, "start": 6387.48, "end": 6392.599999999999, "text": " that we can retrieve the graph convolutional net from the code that we already have written.", "tokens": [50364, 293, 550, 1310, 321, 393, 445, 909, 472, 4497, 8141, 456, 445, 281, 652, 341, 45249, 644, 1270, 50632, 50632, 300, 321, 393, 30254, 264, 4295, 45216, 304, 2533, 490, 264, 3089, 300, 321, 1217, 362, 3720, 13, 50888, 50888, 407, 300, 576, 312, 11, 286, 519, 11, 257, 4984, 337, 4153, 13, 6962, 322, 13, 821, 366, 544, 1651, 51120, 51120, 1348, 13, 1119, 456, 604, 3861, 689, 1228, 5995, 8929, 7129, 1062, 312, 1101, 813, 23598, 29435, 45, 30, 51476, 51704], "temperature": 0.0, "avg_logprob": -0.13636906567741844, "compression_ratio": 1.5560344827586208, "no_speech_prob": 0.0001711606455501169}, {"id": 929, "seek": 638212, "start": 6392.599999999999, "end": 6397.24, "text": " So that would be, I think, a connection for tomorrow. Hold on. There are more questions", "tokens": [50364, 293, 550, 1310, 321, 393, 445, 909, 472, 4497, 8141, 456, 445, 281, 652, 341, 45249, 644, 1270, 50632, 50632, 300, 321, 393, 30254, 264, 4295, 45216, 304, 2533, 490, 264, 3089, 300, 321, 1217, 362, 3720, 13, 50888, 50888, 407, 300, 576, 312, 11, 286, 519, 11, 257, 4984, 337, 4153, 13, 6962, 322, 13, 821, 366, 544, 1651, 51120, 51120, 1348, 13, 1119, 456, 604, 3861, 689, 1228, 5995, 8929, 7129, 1062, 312, 1101, 813, 23598, 29435, 45, 30, 51476, 51704], "temperature": 0.0, "avg_logprob": -0.13636906567741844, "compression_ratio": 1.5560344827586208, "no_speech_prob": 0.0001711606455501169}, {"id": 930, "seek": 638212, "start": 6397.24, "end": 6404.36, "text": " coming. Is there any application where using CHEPnet might be better than spatial GCN?", "tokens": [50364, 293, 550, 1310, 321, 393, 445, 909, 472, 4497, 8141, 456, 445, 281, 652, 341, 45249, 644, 1270, 50632, 50632, 300, 321, 393, 30254, 264, 4295, 45216, 304, 2533, 490, 264, 3089, 300, 321, 1217, 362, 3720, 13, 50888, 50888, 407, 300, 576, 312, 11, 286, 519, 11, 257, 4984, 337, 4153, 13, 6962, 322, 13, 821, 366, 544, 1651, 51120, 51120, 1348, 13, 1119, 456, 604, 3861, 689, 1228, 5995, 8929, 7129, 1062, 312, 1101, 813, 23598, 29435, 45, 30, 51476, 51704], "temperature": 0.0, "avg_logprob": -0.13636906567741844, "compression_ratio": 1.5560344827586208, "no_speech_prob": 0.0001711606455501169}, {"id": 931, "seek": 640436, "start": 6404.36, "end": 6421.639999999999, "text": " So I would say they are part of the isotropic. This is the class I call isotropic GCN.", "tokens": [50364, 407, 286, 576, 584, 436, 366, 644, 295, 264, 38018, 39173, 13, 639, 307, 264, 1508, 286, 818, 38018, 39173, 29435, 45, 13, 51228, 51228, 407, 337, 385, 11, 295, 1164, 11, 309, 486, 5672, 322, 428, 1412, 11, 293, 309, 486, 5672, 322, 428, 5633, 13, 759, 291, 51676, 51676], "temperature": 0.0, "avg_logprob": -0.2621499547418558, "compression_ratio": 1.4274193548387097, "no_speech_prob": 4.5116987166693434e-05}, {"id": 932, "seek": 640436, "start": 6421.639999999999, "end": 6430.599999999999, "text": " So for me, of course, it will depend on your data, and it will depend on your task. If you", "tokens": [50364, 407, 286, 576, 584, 436, 366, 644, 295, 264, 38018, 39173, 13, 639, 307, 264, 1508, 286, 818, 38018, 39173, 29435, 45, 13, 51228, 51228, 407, 337, 385, 11, 295, 1164, 11, 309, 486, 5672, 322, 428, 1412, 11, 293, 309, 486, 5672, 322, 428, 5633, 13, 759, 291, 51676, 51676], "temperature": 0.0, "avg_logprob": -0.2621499547418558, "compression_ratio": 1.4274193548387097, "no_speech_prob": 4.5116987166693434e-05}, {"id": 933, "seek": 643060, "start": 6430.6, "end": 6435.96, "text": " have some task where your data is isotropic, this kind of information, then CHEPnet will do a very", "tokens": [50364, 362, 512, 5633, 689, 428, 1412, 307, 38018, 39173, 11, 341, 733, 295, 1589, 11, 550, 5995, 8929, 7129, 486, 360, 257, 588, 50632, 50632, 665, 1691, 337, 988, 13, 823, 11, 498, 291, 362, 1589, 689, 38018, 39173, 307, 1021, 11, 337, 1365, 11, 337, 50892, 50892, 2093, 9590, 11, 291, 500, 380, 528, 281, 2387, 264, 12512, 264, 912, 636, 11, 550, 309, 311, 406, 516, 281, 51268, 51268, 360, 257, 665, 1691, 13, 407, 309, 534, 5946, 322, 428, 5633, 689, 38018, 27514, 307, 588, 1021, 13, 759, 38018, 27514, 307, 51576, 51576], "temperature": 0.0, "avg_logprob": -0.11016144071306501, "compression_ratio": 1.6798245614035088, "no_speech_prob": 2.0782001229235902e-05}, {"id": 934, "seek": 643060, "start": 6435.96, "end": 6441.160000000001, "text": " good job for sure. Now, if you have information where isotropic is important, for example, for", "tokens": [50364, 362, 512, 5633, 689, 428, 1412, 307, 38018, 39173, 11, 341, 733, 295, 1589, 11, 550, 5995, 8929, 7129, 486, 360, 257, 588, 50632, 50632, 665, 1691, 337, 988, 13, 823, 11, 498, 291, 362, 1589, 689, 38018, 39173, 307, 1021, 11, 337, 1365, 11, 337, 50892, 50892, 2093, 9590, 11, 291, 500, 380, 528, 281, 2387, 264, 12512, 264, 912, 636, 11, 550, 309, 311, 406, 516, 281, 51268, 51268, 360, 257, 665, 1691, 13, 407, 309, 534, 5946, 322, 428, 5633, 689, 38018, 27514, 307, 588, 1021, 13, 759, 38018, 27514, 307, 51576, 51576], "temperature": 0.0, "avg_logprob": -0.11016144071306501, "compression_ratio": 1.6798245614035088, "no_speech_prob": 2.0782001229235902e-05}, {"id": 935, "seek": 643060, "start": 6441.160000000001, "end": 6448.68, "text": " social networks, you don't want to treat the neighbors the same way, then it's not going to", "tokens": [50364, 362, 512, 5633, 689, 428, 1412, 307, 38018, 39173, 11, 341, 733, 295, 1589, 11, 550, 5995, 8929, 7129, 486, 360, 257, 588, 50632, 50632, 665, 1691, 337, 988, 13, 823, 11, 498, 291, 362, 1589, 689, 38018, 39173, 307, 1021, 11, 337, 1365, 11, 337, 50892, 50892, 2093, 9590, 11, 291, 500, 380, 528, 281, 2387, 264, 12512, 264, 912, 636, 11, 550, 309, 311, 406, 516, 281, 51268, 51268, 360, 257, 665, 1691, 13, 407, 309, 534, 5946, 322, 428, 5633, 689, 38018, 27514, 307, 588, 1021, 13, 759, 38018, 27514, 307, 51576, 51576], "temperature": 0.0, "avg_logprob": -0.11016144071306501, "compression_ratio": 1.6798245614035088, "no_speech_prob": 2.0782001229235902e-05}, {"id": 936, "seek": 643060, "start": 6448.68, "end": 6454.84, "text": " do a good job. So it really depends on your task where isotropy is very important. If isotropy is", "tokens": [50364, 362, 512, 5633, 689, 428, 1412, 307, 38018, 39173, 11, 341, 733, 295, 1589, 11, 550, 5995, 8929, 7129, 486, 360, 257, 588, 50632, 50632, 665, 1691, 337, 988, 13, 823, 11, 498, 291, 362, 1589, 689, 38018, 39173, 307, 1021, 11, 337, 1365, 11, 337, 50892, 50892, 2093, 9590, 11, 291, 500, 380, 528, 281, 2387, 264, 12512, 264, 912, 636, 11, 550, 309, 311, 406, 516, 281, 51268, 51268, 360, 257, 665, 1691, 13, 407, 309, 534, 5946, 322, 428, 5633, 689, 38018, 27514, 307, 588, 1021, 13, 759, 38018, 27514, 307, 51576, 51576], "temperature": 0.0, "avg_logprob": -0.11016144071306501, "compression_ratio": 1.6798245614035088, "no_speech_prob": 2.0782001229235902e-05}, {"id": 937, "seek": 645484, "start": 6454.84, "end": 6461.24, "text": " very important, then you should use CHEPnet because CHEPnet is using all bit of information about your", "tokens": [50364, 588, 1021, 11, 550, 291, 820, 764, 5995, 8929, 7129, 570, 5995, 8929, 7129, 307, 1228, 439, 857, 295, 1589, 466, 428, 50684, 50684, 4295, 294, 364, 38018, 39173, 636, 13, 400, 498, 291, 366, 1228, 29435, 45, 11, 264, 8979, 5291, 29435, 45, 11, 291, 366, 445, 1228, 264, 700, 51028, 51028, 732, 2115, 295, 28023, 295, 5995, 8929, 7129, 13, 1079, 11, 2086, 11, 2086, 13, 821, 321, 393, 1466, 264, 8819, 11, 558, 30, 492, 393, 51308, 51308, 1466, 264, 10290, 337, 264, 8819, 1270, 300, 436, 366, 20828, 770, 1296, 12512, 11, 558, 30, 51516, 51568], "temperature": 0.0, "avg_logprob": -0.13790312000349456, "compression_ratio": 1.6680672268907564, "no_speech_prob": 6.909546937095001e-05}, {"id": 938, "seek": 645484, "start": 6461.24, "end": 6468.12, "text": " graph in an isotropic way. And if you are using GCN, the Vanilla GCN, you are just using the first", "tokens": [50364, 588, 1021, 11, 550, 291, 820, 764, 5995, 8929, 7129, 570, 5995, 8929, 7129, 307, 1228, 439, 857, 295, 1589, 466, 428, 50684, 50684, 4295, 294, 364, 38018, 39173, 636, 13, 400, 498, 291, 366, 1228, 29435, 45, 11, 264, 8979, 5291, 29435, 45, 11, 291, 366, 445, 1228, 264, 700, 51028, 51028, 732, 2115, 295, 28023, 295, 5995, 8929, 7129, 13, 1079, 11, 2086, 11, 2086, 13, 821, 321, 393, 1466, 264, 8819, 11, 558, 30, 492, 393, 51308, 51308, 1466, 264, 10290, 337, 264, 8819, 1270, 300, 436, 366, 20828, 770, 1296, 12512, 11, 558, 30, 51516, 51568], "temperature": 0.0, "avg_logprob": -0.13790312000349456, "compression_ratio": 1.6680672268907564, "no_speech_prob": 6.909546937095001e-05}, {"id": 939, "seek": 645484, "start": 6468.12, "end": 6473.72, "text": " two terms of approximation of CHEPnet. Yes, yes, yes. There we can learn the edges, right? We can", "tokens": [50364, 588, 1021, 11, 550, 291, 820, 764, 5995, 8929, 7129, 570, 5995, 8929, 7129, 307, 1228, 439, 857, 295, 1589, 466, 428, 50684, 50684, 4295, 294, 364, 38018, 39173, 636, 13, 400, 498, 291, 366, 1228, 29435, 45, 11, 264, 8979, 5291, 29435, 45, 11, 291, 366, 445, 1228, 264, 700, 51028, 51028, 732, 2115, 295, 28023, 295, 5995, 8929, 7129, 13, 1079, 11, 2086, 11, 2086, 13, 821, 321, 393, 1466, 264, 8819, 11, 558, 30, 492, 393, 51308, 51308, 1466, 264, 10290, 337, 264, 8819, 1270, 300, 436, 366, 20828, 770, 1296, 12512, 11, 558, 30, 51516, 51568], "temperature": 0.0, "avg_logprob": -0.13790312000349456, "compression_ratio": 1.6680672268907564, "no_speech_prob": 6.909546937095001e-05}, {"id": 940, "seek": 645484, "start": 6473.72, "end": 6477.88, "text": " learn the representation for the edges such that they are discriminated between neighbors, right?", "tokens": [50364, 588, 1021, 11, 550, 291, 820, 764, 5995, 8929, 7129, 570, 5995, 8929, 7129, 307, 1228, 439, 857, 295, 1589, 466, 428, 50684, 50684, 4295, 294, 364, 38018, 39173, 636, 13, 400, 498, 291, 366, 1228, 29435, 45, 11, 264, 8979, 5291, 29435, 45, 11, 291, 366, 445, 1228, 264, 700, 51028, 51028, 732, 2115, 295, 28023, 295, 5995, 8929, 7129, 13, 1079, 11, 2086, 11, 2086, 13, 821, 321, 393, 1466, 264, 8819, 11, 558, 30, 492, 393, 51308, 51308, 1466, 264, 10290, 337, 264, 8819, 1270, 300, 436, 366, 20828, 770, 1296, 12512, 11, 558, 30, 51516, 51568], "temperature": 0.0, "avg_logprob": -0.13790312000349456, "compression_ratio": 1.6680672268907564, "no_speech_prob": 6.909546937095001e-05}, {"id": 941, "seek": 647788, "start": 6477.88, "end": 6485.64, "text": " No, no, no, this one is an isotropic. You are talking about isotropic. What I mean by isotropic", "tokens": [50364, 883, 11, 572, 11, 572, 11, 341, 472, 307, 364, 38018, 39173, 13, 509, 366, 1417, 466, 38018, 39173, 13, 708, 286, 914, 538, 38018, 39173, 50752, 50752, 307, 300, 498, 291, 362, 257, 6075, 38018, 39173, 4295, 2740, 11, 550, 291, 820, 764, 5995, 8929, 7129, 13, 51132, 51132, 5995, 8929, 7129, 11, 5911, 11, 1338, 13, 51220, 51220, 583, 5911, 11, 1338, 11, 309, 311, 1101, 281, 764, 364, 38018, 39173, 29435, 45, 13, 51364, 51364, 2720, 1164, 13, 5048, 1651, 11, 1074, 30, 51588, 51644], "temperature": 0.0, "avg_logprob": -0.2523996141221788, "compression_ratio": 1.5806451612903225, "no_speech_prob": 3.6436435038922355e-05}, {"id": 942, "seek": 647788, "start": 6485.64, "end": 6493.24, "text": " is that if you have a pure isotropic graph problems, then you should use CHEPnet.", "tokens": [50364, 883, 11, 572, 11, 572, 11, 341, 472, 307, 364, 38018, 39173, 13, 509, 366, 1417, 466, 38018, 39173, 13, 708, 286, 914, 538, 38018, 39173, 50752, 50752, 307, 300, 498, 291, 362, 257, 6075, 38018, 39173, 4295, 2740, 11, 550, 291, 820, 764, 5995, 8929, 7129, 13, 51132, 51132, 5995, 8929, 7129, 11, 5911, 11, 1338, 13, 51220, 51220, 583, 5911, 11, 1338, 11, 309, 311, 1101, 281, 764, 364, 38018, 39173, 29435, 45, 13, 51364, 51364, 2720, 1164, 13, 5048, 1651, 11, 1074, 30, 51588, 51644], "temperature": 0.0, "avg_logprob": -0.2523996141221788, "compression_ratio": 1.5806451612903225, "no_speech_prob": 3.6436435038922355e-05}, {"id": 943, "seek": 647788, "start": 6493.24, "end": 6495.0, "text": " CHEPnet, otherwise, yeah.", "tokens": [50364, 883, 11, 572, 11, 572, 11, 341, 472, 307, 364, 38018, 39173, 13, 509, 366, 1417, 466, 38018, 39173, 13, 708, 286, 914, 538, 38018, 39173, 50752, 50752, 307, 300, 498, 291, 362, 257, 6075, 38018, 39173, 4295, 2740, 11, 550, 291, 820, 764, 5995, 8929, 7129, 13, 51132, 51132, 5995, 8929, 7129, 11, 5911, 11, 1338, 13, 51220, 51220, 583, 5911, 11, 1338, 11, 309, 311, 1101, 281, 764, 364, 38018, 39173, 29435, 45, 13, 51364, 51364, 2720, 1164, 13, 5048, 1651, 11, 1074, 30, 51588, 51644], "temperature": 0.0, "avg_logprob": -0.2523996141221788, "compression_ratio": 1.5806451612903225, "no_speech_prob": 3.6436435038922355e-05}, {"id": 944, "seek": 647788, "start": 6495.0, "end": 6497.88, "text": " But otherwise, yeah, it's better to use an isotropic GCN.", "tokens": [50364, 883, 11, 572, 11, 572, 11, 341, 472, 307, 364, 38018, 39173, 13, 509, 366, 1417, 466, 38018, 39173, 13, 708, 286, 914, 538, 38018, 39173, 50752, 50752, 307, 300, 498, 291, 362, 257, 6075, 38018, 39173, 4295, 2740, 11, 550, 291, 820, 764, 5995, 8929, 7129, 13, 51132, 51132, 5995, 8929, 7129, 11, 5911, 11, 1338, 13, 51220, 51220, 583, 5911, 11, 1338, 11, 309, 311, 1101, 281, 764, 364, 38018, 39173, 29435, 45, 13, 51364, 51364, 2720, 1164, 13, 5048, 1651, 11, 1074, 30, 51588, 51644], "temperature": 0.0, "avg_logprob": -0.2523996141221788, "compression_ratio": 1.5806451612903225, "no_speech_prob": 3.6436435038922355e-05}, {"id": 945, "seek": 647788, "start": 6497.88, "end": 6502.36, "text": " Of course. More questions, guys?", "tokens": [50364, 883, 11, 572, 11, 572, 11, 341, 472, 307, 364, 38018, 39173, 13, 509, 366, 1417, 466, 38018, 39173, 13, 708, 286, 914, 538, 38018, 39173, 50752, 50752, 307, 300, 498, 291, 362, 257, 6075, 38018, 39173, 4295, 2740, 11, 550, 291, 820, 764, 5995, 8929, 7129, 13, 51132, 51132, 5995, 8929, 7129, 11, 5911, 11, 1338, 13, 51220, 51220, 583, 5911, 11, 1338, 11, 309, 311, 1101, 281, 764, 364, 38018, 39173, 29435, 45, 13, 51364, 51364, 2720, 1164, 13, 5048, 1651, 11, 1074, 30, 51588, 51644], "temperature": 0.0, "avg_logprob": -0.2523996141221788, "compression_ratio": 1.5806451612903225, "no_speech_prob": 3.6436435038922355e-05}, {"id": 946, "seek": 650236, "start": 6502.36, "end": 6508.92, "text": " Hey, I have a question. Thanks for the talk. I was wondering, a lot of these methods require", "tokens": [50364, 1911, 11, 286, 362, 257, 1168, 13, 2561, 337, 264, 751, 13, 286, 390, 6359, 11, 257, 688, 295, 613, 7150, 3651, 50692, 50692, 364, 6741, 22940, 3020, 8141, 293, 337, 512, 2740, 13, 1171, 1365, 11, 291, 458, 300, 456, 307, 51064, 51064, 257, 4295, 3877, 11, 457, 291, 500, 380, 458, 264, 14217, 9271, 13, 1144, 291, 458, 295, 604, 589, 300, 16862, 51304, 51304, 341, 1154, 30, 51336, 51380, 865, 11, 3122, 13, 407, 1400, 11, 881, 1985, 1879, 322, 1419, 1217, 264, 4295, 3877, 13, 51744, 51796], "temperature": 0.0, "avg_logprob": -0.15876685932118406, "compression_ratio": 1.5551020408163265, "no_speech_prob": 7.960844232002273e-05}, {"id": 947, "seek": 650236, "start": 6508.92, "end": 6516.36, "text": " an existing adjacency matrix and for some problems. For example, you know that there is", "tokens": [50364, 1911, 11, 286, 362, 257, 1168, 13, 2561, 337, 264, 751, 13, 286, 390, 6359, 11, 257, 688, 295, 613, 7150, 3651, 50692, 50692, 364, 6741, 22940, 3020, 8141, 293, 337, 512, 2740, 13, 1171, 1365, 11, 291, 458, 300, 456, 307, 51064, 51064, 257, 4295, 3877, 11, 457, 291, 500, 380, 458, 264, 14217, 9271, 13, 1144, 291, 458, 295, 604, 589, 300, 16862, 51304, 51304, 341, 1154, 30, 51336, 51380, 865, 11, 3122, 13, 407, 1400, 11, 881, 1985, 1879, 322, 1419, 1217, 264, 4295, 3877, 13, 51744, 51796], "temperature": 0.0, "avg_logprob": -0.15876685932118406, "compression_ratio": 1.5551020408163265, "no_speech_prob": 7.960844232002273e-05}, {"id": 948, "seek": 650236, "start": 6516.36, "end": 6521.16, "text": " a graph structure, but you don't know the underlying connections. Do you know of any work that addresses", "tokens": [50364, 1911, 11, 286, 362, 257, 1168, 13, 2561, 337, 264, 751, 13, 286, 390, 6359, 11, 257, 688, 295, 613, 7150, 3651, 50692, 50692, 364, 6741, 22940, 3020, 8141, 293, 337, 512, 2740, 13, 1171, 1365, 11, 291, 458, 300, 456, 307, 51064, 51064, 257, 4295, 3877, 11, 457, 291, 500, 380, 458, 264, 14217, 9271, 13, 1144, 291, 458, 295, 604, 589, 300, 16862, 51304, 51304, 341, 1154, 30, 51336, 51380, 865, 11, 3122, 13, 407, 1400, 11, 881, 1985, 1879, 322, 1419, 1217, 264, 4295, 3877, 13, 51744, 51796], "temperature": 0.0, "avg_logprob": -0.15876685932118406, "compression_ratio": 1.5551020408163265, "no_speech_prob": 7.960844232002273e-05}, {"id": 949, "seek": 650236, "start": 6521.16, "end": 6521.799999999999, "text": " this problem?", "tokens": [50364, 1911, 11, 286, 362, 257, 1168, 13, 2561, 337, 264, 751, 13, 286, 390, 6359, 11, 257, 688, 295, 613, 7150, 3651, 50692, 50692, 364, 6741, 22940, 3020, 8141, 293, 337, 512, 2740, 13, 1171, 1365, 11, 291, 458, 300, 456, 307, 51064, 51064, 257, 4295, 3877, 11, 457, 291, 500, 380, 458, 264, 14217, 9271, 13, 1144, 291, 458, 295, 604, 589, 300, 16862, 51304, 51304, 341, 1154, 30, 51336, 51380, 865, 11, 3122, 13, 407, 1400, 11, 881, 1985, 1879, 322, 1419, 1217, 264, 4295, 3877, 13, 51744, 51796], "temperature": 0.0, "avg_logprob": -0.15876685932118406, "compression_ratio": 1.5551020408163265, "no_speech_prob": 7.960844232002273e-05}, {"id": 950, "seek": 650236, "start": 6522.679999999999, "end": 6529.96, "text": " Yeah, absolutely. So far, most works focus on having already the graph structure.", "tokens": [50364, 1911, 11, 286, 362, 257, 1168, 13, 2561, 337, 264, 751, 13, 286, 390, 6359, 11, 257, 688, 295, 613, 7150, 3651, 50692, 50692, 364, 6741, 22940, 3020, 8141, 293, 337, 512, 2740, 13, 1171, 1365, 11, 291, 458, 300, 456, 307, 51064, 51064, 257, 4295, 3877, 11, 457, 291, 500, 380, 458, 264, 14217, 9271, 13, 1144, 291, 458, 295, 604, 589, 300, 16862, 51304, 51304, 341, 1154, 30, 51336, 51380, 865, 11, 3122, 13, 407, 1400, 11, 881, 1985, 1879, 322, 1419, 1217, 264, 4295, 3877, 13, 51744, 51796], "temperature": 0.0, "avg_logprob": -0.15876685932118406, "compression_ratio": 1.5551020408163265, "no_speech_prob": 7.960844232002273e-05}, {"id": 951, "seek": 652996, "start": 6529.96, "end": 6538.76, "text": " And of course, sometimes you just have data. For example, you just have a set of features,", "tokens": [50364, 400, 295, 1164, 11, 2171, 291, 445, 362, 1412, 13, 1171, 1365, 11, 291, 445, 362, 257, 992, 295, 4122, 11, 50804, 50832, 293, 291, 528, 281, 1466, 512, 4295, 3877, 13, 467, 311, 588, 1152, 11, 588, 11, 588, 1152, 13, 407, 456, 366, 512, 1985, 51252, 51252, 884, 300, 13, 407, 436, 366, 1382, 281, 1466, 512, 4295, 3877, 11, 293, 412, 264, 912, 565, 11, 436, 366, 1382, 51552, 51552], "temperature": 0.0, "avg_logprob": -0.27068145751953127, "compression_ratio": 1.7425149700598803, "no_speech_prob": 1.8041982912109233e-05}, {"id": 952, "seek": 652996, "start": 6539.32, "end": 6547.72, "text": " and you want to learn some graph structure. It's very hard, very, very hard. So there are some works", "tokens": [50364, 400, 295, 1164, 11, 2171, 291, 445, 362, 1412, 13, 1171, 1365, 11, 291, 445, 362, 257, 992, 295, 4122, 11, 50804, 50832, 293, 291, 528, 281, 1466, 512, 4295, 3877, 13, 467, 311, 588, 1152, 11, 588, 11, 588, 1152, 13, 407, 456, 366, 512, 1985, 51252, 51252, 884, 300, 13, 407, 436, 366, 1382, 281, 1466, 512, 4295, 3877, 11, 293, 412, 264, 912, 565, 11, 436, 366, 1382, 51552, 51552], "temperature": 0.0, "avg_logprob": -0.27068145751953127, "compression_ratio": 1.7425149700598803, "no_speech_prob": 1.8041982912109233e-05}, {"id": 953, "seek": 652996, "start": 6547.72, "end": 6553.72, "text": " doing that. So they are trying to learn some graph structure, and at the same time, they are trying", "tokens": [50364, 400, 295, 1164, 11, 2171, 291, 445, 362, 1412, 13, 1171, 1365, 11, 291, 445, 362, 257, 992, 295, 4122, 11, 50804, 50832, 293, 291, 528, 281, 1466, 512, 4295, 3877, 13, 467, 311, 588, 1152, 11, 588, 11, 588, 1152, 13, 407, 456, 366, 512, 1985, 51252, 51252, 884, 300, 13, 407, 436, 366, 1382, 281, 1466, 512, 4295, 3877, 11, 293, 412, 264, 912, 565, 11, 436, 366, 1382, 51552, 51552], "temperature": 0.0, "avg_logprob": -0.27068145751953127, "compression_ratio": 1.7425149700598803, "no_speech_prob": 1.8041982912109233e-05}, {"id": 954, "seek": 655372, "start": 6553.72, "end": 6560.12, "text": " to learn another representation. So that's promising, that's interesting. And this is also", "tokens": [50364, 281, 1466, 1071, 10290, 13, 407, 300, 311, 20257, 11, 300, 311, 1880, 13, 400, 341, 307, 611, 50684, 50684, 512, 589, 300, 286, 478, 1382, 281, 360, 586, 13, 583, 286, 393, 980, 291, 309, 311, 588, 1152, 281, 360, 13, 400, 2318, 50892, 50892, 570, 498, 291, 718, 264, 22940, 3020, 8141, 281, 312, 257, 7006, 11, 550, 291, 366, 297, 8889, 13, 51332, 51412, 509, 362, 297, 8889, 9841, 9834, 281, 1466, 13, 407, 309, 311, 406, 1858, 13, 583, 1338, 11, 341, 307, 257, 51780, 51780], "temperature": 0.0, "avg_logprob": -0.2522015778914742, "compression_ratio": 1.5954545454545455, "no_speech_prob": 1.128427447838476e-05}, {"id": 955, "seek": 655372, "start": 6560.12, "end": 6564.280000000001, "text": " some work that I'm trying to do now. But I can tell you it's very hard to do. And especially", "tokens": [50364, 281, 1466, 1071, 10290, 13, 407, 300, 311, 20257, 11, 300, 311, 1880, 13, 400, 341, 307, 611, 50684, 50684, 512, 589, 300, 286, 478, 1382, 281, 360, 586, 13, 583, 286, 393, 980, 291, 309, 311, 588, 1152, 281, 360, 13, 400, 2318, 50892, 50892, 570, 498, 291, 718, 264, 22940, 3020, 8141, 281, 312, 257, 7006, 11, 550, 291, 366, 297, 8889, 13, 51332, 51412, 509, 362, 297, 8889, 9841, 9834, 281, 1466, 13, 407, 309, 311, 406, 1858, 13, 583, 1338, 11, 341, 307, 257, 51780, 51780], "temperature": 0.0, "avg_logprob": -0.2522015778914742, "compression_ratio": 1.5954545454545455, "no_speech_prob": 1.128427447838476e-05}, {"id": 956, "seek": 655372, "start": 6564.280000000001, "end": 6573.08, "text": " because if you let the adjacency matrix to be a variable, then you are n squared.", "tokens": [50364, 281, 1466, 1071, 10290, 13, 407, 300, 311, 20257, 11, 300, 311, 1880, 13, 400, 341, 307, 611, 50684, 50684, 512, 589, 300, 286, 478, 1382, 281, 360, 586, 13, 583, 286, 393, 980, 291, 309, 311, 588, 1152, 281, 360, 13, 400, 2318, 50892, 50892, 570, 498, 291, 718, 264, 22940, 3020, 8141, 281, 312, 257, 7006, 11, 550, 291, 366, 297, 8889, 13, 51332, 51412, 509, 362, 297, 8889, 9841, 9834, 281, 1466, 13, 407, 309, 311, 406, 1858, 13, 583, 1338, 11, 341, 307, 257, 51780, 51780], "temperature": 0.0, "avg_logprob": -0.2522015778914742, "compression_ratio": 1.5954545454545455, "no_speech_prob": 1.128427447838476e-05}, {"id": 957, "seek": 655372, "start": 6574.68, "end": 6582.04, "text": " You have n squared unknown parameters to learn. So it's not easy. But yeah, this is a", "tokens": [50364, 281, 1466, 1071, 10290, 13, 407, 300, 311, 20257, 11, 300, 311, 1880, 13, 400, 341, 307, 611, 50684, 50684, 512, 589, 300, 286, 478, 1382, 281, 360, 586, 13, 583, 286, 393, 980, 291, 309, 311, 588, 1152, 281, 360, 13, 400, 2318, 50892, 50892, 570, 498, 291, 718, 264, 22940, 3020, 8141, 281, 312, 257, 7006, 11, 550, 291, 366, 297, 8889, 13, 51332, 51412, 509, 362, 297, 8889, 9841, 9834, 281, 1466, 13, 407, 309, 311, 406, 1858, 13, 583, 1338, 11, 341, 307, 257, 51780, 51780], "temperature": 0.0, "avg_logprob": -0.2522015778914742, "compression_ratio": 1.5954545454545455, "no_speech_prob": 1.128427447838476e-05}, {"id": 958, "seek": 658204, "start": 6582.04, "end": 6588.28, "text": " So I would say that these techniques, there are many natural data coming with graphs.", "tokens": [50364, 407, 286, 576, 584, 300, 613, 7512, 11, 456, 366, 867, 3303, 1412, 1348, 365, 24877, 13, 50676, 50676, 509, 500, 380, 643, 281, 1322, 604, 24877, 13, 400, 341, 307, 1217, 2902, 291, 257, 688, 295, 665, 3873, 13, 50996, 51020, 823, 11, 498, 291, 393, 976, 385, 1310, 437, 291, 362, 294, 1575, 11, 437, 733, 295, 3861, 291, 362, 294, 1575, 11, 51248, 51248, 437, 291, 528, 281, 764, 11, 562, 291, 528, 281, 1466, 24877, 11, 412, 264, 912, 565, 11, 1310, 321, 393, 751, 466, 309, 13, 51556, 51556], "temperature": 0.0, "avg_logprob": -0.2203137477238973, "compression_ratio": 1.6727272727272726, "no_speech_prob": 3.425090835662559e-05}, {"id": 959, "seek": 658204, "start": 6588.28, "end": 6594.68, "text": " You don't need to build any graphs. And this is already giving you a lot of good tools.", "tokens": [50364, 407, 286, 576, 584, 300, 613, 7512, 11, 456, 366, 867, 3303, 1412, 1348, 365, 24877, 13, 50676, 50676, 509, 500, 380, 643, 281, 1322, 604, 24877, 13, 400, 341, 307, 1217, 2902, 291, 257, 688, 295, 665, 3873, 13, 50996, 51020, 823, 11, 498, 291, 393, 976, 385, 1310, 437, 291, 362, 294, 1575, 11, 437, 733, 295, 3861, 291, 362, 294, 1575, 11, 51248, 51248, 437, 291, 528, 281, 764, 11, 562, 291, 528, 281, 1466, 24877, 11, 412, 264, 912, 565, 11, 1310, 321, 393, 751, 466, 309, 13, 51556, 51556], "temperature": 0.0, "avg_logprob": -0.2203137477238973, "compression_ratio": 1.6727272727272726, "no_speech_prob": 3.425090835662559e-05}, {"id": 960, "seek": 658204, "start": 6595.16, "end": 6599.72, "text": " Now, if you can give me maybe what you have in mind, what kind of application you have in mind,", "tokens": [50364, 407, 286, 576, 584, 300, 613, 7512, 11, 456, 366, 867, 3303, 1412, 1348, 365, 24877, 13, 50676, 50676, 509, 500, 380, 643, 281, 1322, 604, 24877, 13, 400, 341, 307, 1217, 2902, 291, 257, 688, 295, 665, 3873, 13, 50996, 51020, 823, 11, 498, 291, 393, 976, 385, 1310, 437, 291, 362, 294, 1575, 11, 437, 733, 295, 3861, 291, 362, 294, 1575, 11, 51248, 51248, 437, 291, 528, 281, 764, 11, 562, 291, 528, 281, 1466, 24877, 11, 412, 264, 912, 565, 11, 1310, 321, 393, 751, 466, 309, 13, 51556, 51556], "temperature": 0.0, "avg_logprob": -0.2203137477238973, "compression_ratio": 1.6727272727272726, "no_speech_prob": 3.425090835662559e-05}, {"id": 961, "seek": 658204, "start": 6599.72, "end": 6605.88, "text": " what you want to use, when you want to learn graphs, at the same time, maybe we can talk about it.", "tokens": [50364, 407, 286, 576, 584, 300, 613, 7512, 11, 456, 366, 867, 3303, 1412, 1348, 365, 24877, 13, 50676, 50676, 509, 500, 380, 643, 281, 1322, 604, 24877, 13, 400, 341, 307, 1217, 2902, 291, 257, 688, 295, 665, 3873, 13, 50996, 51020, 823, 11, 498, 291, 393, 976, 385, 1310, 437, 291, 362, 294, 1575, 11, 437, 733, 295, 3861, 291, 362, 294, 1575, 11, 51248, 51248, 437, 291, 528, 281, 764, 11, 562, 291, 528, 281, 1466, 24877, 11, 412, 264, 912, 565, 11, 1310, 321, 393, 751, 466, 309, 13, 51556, 51556], "temperature": 0.0, "avg_logprob": -0.2203137477238973, "compression_ratio": 1.6727272727272726, "no_speech_prob": 3.425090835662559e-05}, {"id": 962, "seek": 660588, "start": 6605.88, "end": 6612.68, "text": " So I can tell you Xavier, of course, Ziming will correct me. But Ziming is actually working on", "tokens": [50364, 407, 286, 393, 980, 291, 44653, 11, 295, 1164, 11, 1176, 332, 278, 486, 3006, 385, 13, 583, 1176, 332, 278, 307, 767, 1364, 322, 50704, 50704, 32884, 7944, 2445, 17630, 11, 1936, 13, 400, 370, 264, 674, 990, 4295, 576, 312, 264, 11, 51088, 51088, 337, 1365, 11, 257, 3385, 4471, 420, 264, 733, 295, 27632, 4295, 295, 819, 7533, 322, 257, 7944, 13, 51364, 51364, 400, 291, 500, 380, 362, 300, 13, 286, 914, 11, 294, 881, 3331, 11, 291, 500, 380, 13, 663, 311, 733, 295, 437, 264, 721, 291, 51604, 51604, 362, 281, 6069, 13, 407, 291, 727, 764, 341, 382, 512, 1333, 295, 48994, 11, 291, 458, 11, 51800, 51800], "temperature": 0.0, "avg_logprob": -0.26432047134790665, "compression_ratio": 1.6716981132075472, "no_speech_prob": 3.1177598430076614e-05}, {"id": 963, "seek": 660588, "start": 6612.68, "end": 6620.36, "text": " predicting protein function prediction, basically. And so the undating graph would be the,", "tokens": [50364, 407, 286, 393, 980, 291, 44653, 11, 295, 1164, 11, 1176, 332, 278, 486, 3006, 385, 13, 583, 1176, 332, 278, 307, 767, 1364, 322, 50704, 50704, 32884, 7944, 2445, 17630, 11, 1936, 13, 400, 370, 264, 674, 990, 4295, 576, 312, 264, 11, 51088, 51088, 337, 1365, 11, 257, 3385, 4471, 420, 264, 733, 295, 27632, 4295, 295, 819, 7533, 322, 257, 7944, 13, 51364, 51364, 400, 291, 500, 380, 362, 300, 13, 286, 914, 11, 294, 881, 3331, 11, 291, 500, 380, 13, 663, 311, 733, 295, 437, 264, 721, 291, 51604, 51604, 362, 281, 6069, 13, 407, 291, 727, 764, 341, 382, 512, 1333, 295, 48994, 11, 291, 458, 11, 51800, 51800], "temperature": 0.0, "avg_logprob": -0.26432047134790665, "compression_ratio": 1.6716981132075472, "no_speech_prob": 3.1177598430076614e-05}, {"id": 964, "seek": 660588, "start": 6620.36, "end": 6625.88, "text": " for example, a contact map or the kind of proximity graph of different sites on a protein.", "tokens": [50364, 407, 286, 393, 980, 291, 44653, 11, 295, 1164, 11, 1176, 332, 278, 486, 3006, 385, 13, 583, 1176, 332, 278, 307, 767, 1364, 322, 50704, 50704, 32884, 7944, 2445, 17630, 11, 1936, 13, 400, 370, 264, 674, 990, 4295, 576, 312, 264, 11, 51088, 51088, 337, 1365, 11, 257, 3385, 4471, 420, 264, 733, 295, 27632, 4295, 295, 819, 7533, 322, 257, 7944, 13, 51364, 51364, 400, 291, 500, 380, 362, 300, 13, 286, 914, 11, 294, 881, 3331, 11, 291, 500, 380, 13, 663, 311, 733, 295, 437, 264, 721, 291, 51604, 51604, 362, 281, 6069, 13, 407, 291, 727, 764, 341, 382, 512, 1333, 295, 48994, 11, 291, 458, 11, 51800, 51800], "temperature": 0.0, "avg_logprob": -0.26432047134790665, "compression_ratio": 1.6716981132075472, "no_speech_prob": 3.1177598430076614e-05}, {"id": 965, "seek": 660588, "start": 6625.88, "end": 6630.68, "text": " And you don't have that. I mean, in most cases, you don't. That's kind of what the things you", "tokens": [50364, 407, 286, 393, 980, 291, 44653, 11, 295, 1164, 11, 1176, 332, 278, 486, 3006, 385, 13, 583, 1176, 332, 278, 307, 767, 1364, 322, 50704, 50704, 32884, 7944, 2445, 17630, 11, 1936, 13, 400, 370, 264, 674, 990, 4295, 576, 312, 264, 11, 51088, 51088, 337, 1365, 11, 257, 3385, 4471, 420, 264, 733, 295, 27632, 4295, 295, 819, 7533, 322, 257, 7944, 13, 51364, 51364, 400, 291, 500, 380, 362, 300, 13, 286, 914, 11, 294, 881, 3331, 11, 291, 500, 380, 13, 663, 311, 733, 295, 437, 264, 721, 291, 51604, 51604, 362, 281, 6069, 13, 407, 291, 727, 764, 341, 382, 512, 1333, 295, 48994, 11, 291, 458, 11, 51800, 51800], "temperature": 0.0, "avg_logprob": -0.26432047134790665, "compression_ratio": 1.6716981132075472, "no_speech_prob": 3.1177598430076614e-05}, {"id": 966, "seek": 660588, "start": 6630.68, "end": 6634.6, "text": " have to predict. So you could use this as some sort of latent, you know,", "tokens": [50364, 407, 286, 393, 980, 291, 44653, 11, 295, 1164, 11, 1176, 332, 278, 486, 3006, 385, 13, 583, 1176, 332, 278, 307, 767, 1364, 322, 50704, 50704, 32884, 7944, 2445, 17630, 11, 1936, 13, 400, 370, 264, 674, 990, 4295, 576, 312, 264, 11, 51088, 51088, 337, 1365, 11, 257, 3385, 4471, 420, 264, 733, 295, 27632, 4295, 295, 819, 7533, 322, 257, 7944, 13, 51364, 51364, 400, 291, 500, 380, 362, 300, 13, 286, 914, 11, 294, 881, 3331, 11, 291, 500, 380, 13, 663, 311, 733, 295, 437, 264, 721, 291, 51604, 51604, 362, 281, 6069, 13, 407, 291, 727, 764, 341, 382, 512, 1333, 295, 48994, 11, 291, 458, 11, 51800, 51800], "temperature": 0.0, "avg_logprob": -0.26432047134790665, "compression_ratio": 1.6716981132075472, "no_speech_prob": 3.1177598430076614e-05}, {"id": 967, "seek": 663460, "start": 6634.6, "end": 6639.88, "text": " graph variable. I see your model. Ziming, maybe you had some other idea in mind.", "tokens": [50364, 4295, 7006, 13, 286, 536, 428, 2316, 13, 1176, 332, 278, 11, 1310, 291, 632, 512, 661, 1558, 294, 1575, 13, 50628, 50628, 865, 11, 286, 519, 767, 11, 370, 264, 544, 2685, 1154, 307, 300, 512, 295, 613, 24877, 11, 291, 458, 11, 50928, 50928, 264, 8819, 293, 291, 11, 291, 458, 11, 512, 295, 264, 8819, 11, 457, 291, 500, 380, 458, 264, 661, 2306, 13, 1171, 1365, 11, 51240, 51240, 294, 7944, 2445, 17630, 11, 291, 393, 3811, 411, 732, 15577, 300, 362, 2531, 6828, 51532, 51532, 382, 1419, 364, 4691, 1296, 552, 13, 583, 436, 1062, 406, 362, 264, 912, 2445, 13, 407, 291, 500, 380, 458, 1333, 295, 51796, 51796], "temperature": 0.0, "avg_logprob": -0.2089650406796708, "compression_ratio": 1.744360902255639, "no_speech_prob": 3.822658254648559e-05}, {"id": 968, "seek": 663460, "start": 6639.88, "end": 6645.88, "text": " Yeah, I think actually, so the more specific problem is that some of these graphs, you know,", "tokens": [50364, 4295, 7006, 13, 286, 536, 428, 2316, 13, 1176, 332, 278, 11, 1310, 291, 632, 512, 661, 1558, 294, 1575, 13, 50628, 50628, 865, 11, 286, 519, 767, 11, 370, 264, 544, 2685, 1154, 307, 300, 512, 295, 613, 24877, 11, 291, 458, 11, 50928, 50928, 264, 8819, 293, 291, 11, 291, 458, 11, 512, 295, 264, 8819, 11, 457, 291, 500, 380, 458, 264, 661, 2306, 13, 1171, 1365, 11, 51240, 51240, 294, 7944, 2445, 17630, 11, 291, 393, 3811, 411, 732, 15577, 300, 362, 2531, 6828, 51532, 51532, 382, 1419, 364, 4691, 1296, 552, 13, 583, 436, 1062, 406, 362, 264, 912, 2445, 13, 407, 291, 500, 380, 458, 1333, 295, 51796, 51796], "temperature": 0.0, "avg_logprob": -0.2089650406796708, "compression_ratio": 1.744360902255639, "no_speech_prob": 3.822658254648559e-05}, {"id": 969, "seek": 663460, "start": 6645.88, "end": 6652.120000000001, "text": " the edges and you, you know, some of the edges, but you don't know the other ones. For example,", "tokens": [50364, 4295, 7006, 13, 286, 536, 428, 2316, 13, 1176, 332, 278, 11, 1310, 291, 632, 512, 661, 1558, 294, 1575, 13, 50628, 50628, 865, 11, 286, 519, 767, 11, 370, 264, 544, 2685, 1154, 307, 300, 512, 295, 613, 24877, 11, 291, 458, 11, 50928, 50928, 264, 8819, 293, 291, 11, 291, 458, 11, 512, 295, 264, 8819, 11, 457, 291, 500, 380, 458, 264, 661, 2306, 13, 1171, 1365, 11, 51240, 51240, 294, 7944, 2445, 17630, 11, 291, 393, 3811, 411, 732, 15577, 300, 362, 2531, 6828, 51532, 51532, 382, 1419, 364, 4691, 1296, 552, 13, 583, 436, 1062, 406, 362, 264, 912, 2445, 13, 407, 291, 500, 380, 458, 1333, 295, 51796, 51796], "temperature": 0.0, "avg_logprob": -0.2089650406796708, "compression_ratio": 1.744360902255639, "no_speech_prob": 3.822658254648559e-05}, {"id": 970, "seek": 663460, "start": 6652.120000000001, "end": 6657.96, "text": " in protein function prediction, you can imagine like two proteins that have similar functions", "tokens": [50364, 4295, 7006, 13, 286, 536, 428, 2316, 13, 1176, 332, 278, 11, 1310, 291, 632, 512, 661, 1558, 294, 1575, 13, 50628, 50628, 865, 11, 286, 519, 767, 11, 370, 264, 544, 2685, 1154, 307, 300, 512, 295, 613, 24877, 11, 291, 458, 11, 50928, 50928, 264, 8819, 293, 291, 11, 291, 458, 11, 512, 295, 264, 8819, 11, 457, 291, 500, 380, 458, 264, 661, 2306, 13, 1171, 1365, 11, 51240, 51240, 294, 7944, 2445, 17630, 11, 291, 393, 3811, 411, 732, 15577, 300, 362, 2531, 6828, 51532, 51532, 382, 1419, 364, 4691, 1296, 552, 13, 583, 436, 1062, 406, 362, 264, 912, 2445, 13, 407, 291, 500, 380, 458, 1333, 295, 51796, 51796], "temperature": 0.0, "avg_logprob": -0.2089650406796708, "compression_ratio": 1.744360902255639, "no_speech_prob": 3.822658254648559e-05}, {"id": 971, "seek": 663460, "start": 6657.96, "end": 6663.240000000001, "text": " as having an edge between them. But they might not have the same function. So you don't know sort of", "tokens": [50364, 4295, 7006, 13, 286, 536, 428, 2316, 13, 1176, 332, 278, 11, 1310, 291, 632, 512, 661, 1558, 294, 1575, 13, 50628, 50628, 865, 11, 286, 519, 767, 11, 370, 264, 544, 2685, 1154, 307, 300, 512, 295, 613, 24877, 11, 291, 458, 11, 50928, 50928, 264, 8819, 293, 291, 11, 291, 458, 11, 512, 295, 264, 8819, 11, 457, 291, 500, 380, 458, 264, 661, 2306, 13, 1171, 1365, 11, 51240, 51240, 294, 7944, 2445, 17630, 11, 291, 393, 3811, 411, 732, 15577, 300, 362, 2531, 6828, 51532, 51532, 382, 1419, 364, 4691, 1296, 552, 13, 583, 436, 1062, 406, 362, 264, 912, 2445, 13, 407, 291, 500, 380, 458, 1333, 295, 51796, 51796], "temperature": 0.0, "avg_logprob": -0.2089650406796708, "compression_ratio": 1.744360902255639, "no_speech_prob": 3.822658254648559e-05}, {"id": 972, "seek": 666324, "start": 6663.24, "end": 6670.5199999999995, "text": " the edge weights and you kind of have like a human labels that are inaccurate. So you know that", "tokens": [50364, 264, 4691, 17443, 293, 291, 733, 295, 362, 411, 257, 1952, 16949, 300, 366, 46443, 13, 407, 291, 458, 300, 50728, 50728, 436, 434, 4582, 294, 512, 636, 11, 457, 291, 500, 380, 458, 264, 4691, 17443, 293, 291, 458, 300, 456, 366, 661, 50916, 50916, 15577, 300, 820, 312, 4582, 11, 457, 291, 500, 380, 362, 16949, 337, 13, 407, 286, 2041, 341, 307, 544, 295, 257, 4295, 51164, 51164, 19372, 1154, 13, 865, 13, 400, 341, 472, 307, 1858, 13, 639, 472, 11, 498, 291, 362, 11, 309, 311, 411, 264, 12909, 11, 291, 458, 11, 51496, 51496, 264, 12909, 4295, 596, 48673, 1154, 13, 407, 498, 291, 1217, 362, 512, 7645, 11, 445, 257, 1326, 16949, 11, 51780, 51780], "temperature": 0.0, "avg_logprob": -0.15001821517944336, "compression_ratio": 1.8875968992248062, "no_speech_prob": 2.1442645447677933e-05}, {"id": 973, "seek": 666324, "start": 6670.5199999999995, "end": 6674.28, "text": " they're connected in some way, but you don't know the edge weights and you know that there are other", "tokens": [50364, 264, 4691, 17443, 293, 291, 733, 295, 362, 411, 257, 1952, 16949, 300, 366, 46443, 13, 407, 291, 458, 300, 50728, 50728, 436, 434, 4582, 294, 512, 636, 11, 457, 291, 500, 380, 458, 264, 4691, 17443, 293, 291, 458, 300, 456, 366, 661, 50916, 50916, 15577, 300, 820, 312, 4582, 11, 457, 291, 500, 380, 362, 16949, 337, 13, 407, 286, 2041, 341, 307, 544, 295, 257, 4295, 51164, 51164, 19372, 1154, 13, 865, 13, 400, 341, 472, 307, 1858, 13, 639, 472, 11, 498, 291, 362, 11, 309, 311, 411, 264, 12909, 11, 291, 458, 11, 51496, 51496, 264, 12909, 4295, 596, 48673, 1154, 13, 407, 498, 291, 1217, 362, 512, 7645, 11, 445, 257, 1326, 16949, 11, 51780, 51780], "temperature": 0.0, "avg_logprob": -0.15001821517944336, "compression_ratio": 1.8875968992248062, "no_speech_prob": 2.1442645447677933e-05}, {"id": 974, "seek": 666324, "start": 6674.28, "end": 6679.24, "text": " proteins that should be connected, but you don't have labels for. So I guess this is more of a graph", "tokens": [50364, 264, 4691, 17443, 293, 291, 733, 295, 362, 411, 257, 1952, 16949, 300, 366, 46443, 13, 407, 291, 458, 300, 50728, 50728, 436, 434, 4582, 294, 512, 636, 11, 457, 291, 500, 380, 458, 264, 4691, 17443, 293, 291, 458, 300, 456, 366, 661, 50916, 50916, 15577, 300, 820, 312, 4582, 11, 457, 291, 500, 380, 362, 16949, 337, 13, 407, 286, 2041, 341, 307, 544, 295, 257, 4295, 51164, 51164, 19372, 1154, 13, 865, 13, 400, 341, 472, 307, 1858, 13, 639, 472, 11, 498, 291, 362, 11, 309, 311, 411, 264, 12909, 11, 291, 458, 11, 51496, 51496, 264, 12909, 4295, 596, 48673, 1154, 13, 407, 498, 291, 1217, 362, 512, 7645, 11, 445, 257, 1326, 16949, 11, 51780, 51780], "temperature": 0.0, "avg_logprob": -0.15001821517944336, "compression_ratio": 1.8875968992248062, "no_speech_prob": 2.1442645447677933e-05}, {"id": 975, "seek": 666324, "start": 6679.24, "end": 6685.88, "text": " completion problem. Yeah. And this one is easy. This one, if you have, it's like the semi, you know,", "tokens": [50364, 264, 4691, 17443, 293, 291, 733, 295, 362, 411, 257, 1952, 16949, 300, 366, 46443, 13, 407, 291, 458, 300, 50728, 50728, 436, 434, 4582, 294, 512, 636, 11, 457, 291, 500, 380, 458, 264, 4691, 17443, 293, 291, 458, 300, 456, 366, 661, 50916, 50916, 15577, 300, 820, 312, 4582, 11, 457, 291, 500, 380, 362, 16949, 337, 13, 407, 286, 2041, 341, 307, 544, 295, 257, 4295, 51164, 51164, 19372, 1154, 13, 865, 13, 400, 341, 472, 307, 1858, 13, 639, 472, 11, 498, 291, 362, 11, 309, 311, 411, 264, 12909, 11, 291, 458, 11, 51496, 51496, 264, 12909, 4295, 596, 48673, 1154, 13, 407, 498, 291, 1217, 362, 512, 7645, 11, 445, 257, 1326, 16949, 11, 51780, 51780], "temperature": 0.0, "avg_logprob": -0.15001821517944336, "compression_ratio": 1.8875968992248062, "no_speech_prob": 2.1442645447677933e-05}, {"id": 976, "seek": 666324, "start": 6685.88, "end": 6691.5599999999995, "text": " the semi graph clustering problem. So if you already have some label, just a few labels,", "tokens": [50364, 264, 4691, 17443, 293, 291, 733, 295, 362, 411, 257, 1952, 16949, 300, 366, 46443, 13, 407, 291, 458, 300, 50728, 50728, 436, 434, 4582, 294, 512, 636, 11, 457, 291, 500, 380, 458, 264, 4691, 17443, 293, 291, 458, 300, 456, 366, 661, 50916, 50916, 15577, 300, 820, 312, 4582, 11, 457, 291, 500, 380, 362, 16949, 337, 13, 407, 286, 2041, 341, 307, 544, 295, 257, 4295, 51164, 51164, 19372, 1154, 13, 865, 13, 400, 341, 472, 307, 1858, 13, 639, 472, 11, 498, 291, 362, 11, 309, 311, 411, 264, 12909, 11, 291, 458, 11, 51496, 51496, 264, 12909, 4295, 596, 48673, 1154, 13, 407, 498, 291, 1217, 362, 512, 7645, 11, 445, 257, 1326, 16949, 11, 51780, 51780], "temperature": 0.0, "avg_logprob": -0.15001821517944336, "compression_ratio": 1.8875968992248062, "no_speech_prob": 2.1442645447677933e-05}, {"id": 977, "seek": 669156, "start": 6691.56, "end": 6697.400000000001, "text": " and you have some structure around this, that's something you can, you can live with.", "tokens": [50364, 293, 291, 362, 512, 3877, 926, 341, 11, 300, 311, 746, 291, 393, 11, 291, 393, 1621, 365, 13, 50656, 50696, 759, 291, 3122, 458, 3877, 322, 264, 4691, 293, 550, 291, 643, 281, 1466, 264, 4295, 11, 300, 307, 588, 1152, 13, 50924, 50960, 286, 536, 13, 1033, 13, 1044, 291, 13, 1911, 11, 286, 362, 257, 1168, 466, 51208, 51344, 37741, 295, 264, 1412, 562, 309, 767, 3097, 257, 18161, 3209, 13, 1436, 309, 311, 411, 11, 51700, 51740], "temperature": 0.0, "avg_logprob": -0.20367387978427381, "compression_ratio": 1.5333333333333334, "no_speech_prob": 2.0782879801117815e-05}, {"id": 978, "seek": 669156, "start": 6698.200000000001, "end": 6702.76, "text": " If you absolutely know structure on the edge and then you need to learn the graph, that is very hard.", "tokens": [50364, 293, 291, 362, 512, 3877, 926, 341, 11, 300, 311, 746, 291, 393, 11, 291, 393, 1621, 365, 13, 50656, 50696, 759, 291, 3122, 458, 3877, 322, 264, 4691, 293, 550, 291, 643, 281, 1466, 264, 4295, 11, 300, 307, 588, 1152, 13, 50924, 50960, 286, 536, 13, 1033, 13, 1044, 291, 13, 1911, 11, 286, 362, 257, 1168, 466, 51208, 51344, 37741, 295, 264, 1412, 562, 309, 767, 3097, 257, 18161, 3209, 13, 1436, 309, 311, 411, 11, 51700, 51740], "temperature": 0.0, "avg_logprob": -0.20367387978427381, "compression_ratio": 1.5333333333333334, "no_speech_prob": 2.0782879801117815e-05}, {"id": 979, "seek": 669156, "start": 6703.4800000000005, "end": 6708.4400000000005, "text": " I see. Okay. Thank you. Hey, I have a question about", "tokens": [50364, 293, 291, 362, 512, 3877, 926, 341, 11, 300, 311, 746, 291, 393, 11, 291, 393, 1621, 365, 13, 50656, 50696, 759, 291, 3122, 458, 3877, 322, 264, 4691, 293, 550, 291, 643, 281, 1466, 264, 4295, 11, 300, 307, 588, 1152, 13, 50924, 50960, 286, 536, 13, 1033, 13, 1044, 291, 13, 1911, 11, 286, 362, 257, 1168, 466, 51208, 51344, 37741, 295, 264, 1412, 562, 309, 767, 3097, 257, 18161, 3209, 13, 1436, 309, 311, 411, 11, 51700, 51740], "temperature": 0.0, "avg_logprob": -0.20367387978427381, "compression_ratio": 1.5333333333333334, "no_speech_prob": 2.0782879801117815e-05}, {"id": 980, "seek": 669156, "start": 6711.160000000001, "end": 6718.280000000001, "text": " splits of the data when it actually training a neural network. Because it's like,", "tokens": [50364, 293, 291, 362, 512, 3877, 926, 341, 11, 300, 311, 746, 291, 393, 11, 291, 393, 1621, 365, 13, 50656, 50696, 759, 291, 3122, 458, 3877, 322, 264, 4691, 293, 550, 291, 643, 281, 1466, 264, 4295, 11, 300, 307, 588, 1152, 13, 50924, 50960, 286, 536, 13, 1033, 13, 1044, 291, 13, 1911, 11, 286, 362, 257, 1168, 466, 51208, 51344, 37741, 295, 264, 1412, 562, 309, 767, 3097, 257, 18161, 3209, 13, 1436, 309, 311, 411, 11, 51700, 51740], "temperature": 0.0, "avg_logprob": -0.20367387978427381, "compression_ratio": 1.5333333333333334, "no_speech_prob": 2.0782879801117815e-05}, {"id": 981, "seek": 671828, "start": 6718.28, "end": 6722.36, "text": " can you talk about some of the things that you would want to consider when actually splitting", "tokens": [50364, 393, 291, 751, 466, 512, 295, 264, 721, 300, 291, 576, 528, 281, 1949, 562, 767, 30348, 50568, 50568, 264, 1412, 666, 584, 3097, 293, 24071, 30, 1743, 291, 1062, 528, 281, 362, 439, 295, 264, 13891, 294, 264, 50924, 50924, 3097, 1412, 337, 309, 281, 767, 312, 9495, 281, 1203, 300, 311, 294, 264, 4295, 1412, 13, 400, 291, 1062, 51340, 51340, 362, 257, 1389, 689, 819, 3467, 295, 8819, 366, 294, 4772, 294, 264, 1412, 992, 13, 1664, 291, 751, 466, 562, 51676, 51676], "temperature": 0.0, "avg_logprob": -0.1534985520622947, "compression_ratio": 1.7579908675799087, "no_speech_prob": 3.610998192016268e-06}, {"id": 982, "seek": 671828, "start": 6722.36, "end": 6729.48, "text": " the data into say training and validation? Like you might want to have all of the nodes in the", "tokens": [50364, 393, 291, 751, 466, 512, 295, 264, 721, 300, 291, 576, 528, 281, 1949, 562, 767, 30348, 50568, 50568, 264, 1412, 666, 584, 3097, 293, 24071, 30, 1743, 291, 1062, 528, 281, 362, 439, 295, 264, 13891, 294, 264, 50924, 50924, 3097, 1412, 337, 309, 281, 767, 312, 9495, 281, 1203, 300, 311, 294, 264, 4295, 1412, 13, 400, 291, 1062, 51340, 51340, 362, 257, 1389, 689, 819, 3467, 295, 8819, 366, 294, 4772, 294, 264, 1412, 992, 13, 1664, 291, 751, 466, 562, 51676, 51676], "temperature": 0.0, "avg_logprob": -0.1534985520622947, "compression_ratio": 1.7579908675799087, "no_speech_prob": 3.610998192016268e-06}, {"id": 983, "seek": 671828, "start": 6729.48, "end": 6737.8, "text": " training data for it to actually be exposed to everything that's in the graph data. And you might", "tokens": [50364, 393, 291, 751, 466, 512, 295, 264, 721, 300, 291, 576, 528, 281, 1949, 562, 767, 30348, 50568, 50568, 264, 1412, 666, 584, 3097, 293, 24071, 30, 1743, 291, 1062, 528, 281, 362, 439, 295, 264, 13891, 294, 264, 50924, 50924, 3097, 1412, 337, 309, 281, 767, 312, 9495, 281, 1203, 300, 311, 294, 264, 4295, 1412, 13, 400, 291, 1062, 51340, 51340, 362, 257, 1389, 689, 819, 3467, 295, 8819, 366, 294, 4772, 294, 264, 1412, 992, 13, 1664, 291, 751, 466, 562, 51676, 51676], "temperature": 0.0, "avg_logprob": -0.1534985520622947, "compression_ratio": 1.7579908675799087, "no_speech_prob": 3.610998192016268e-06}, {"id": 984, "seek": 671828, "start": 6737.8, "end": 6744.5199999999995, "text": " have a case where different types of edges are in balance in the data set. Can you talk about when", "tokens": [50364, 393, 291, 751, 466, 512, 295, 264, 721, 300, 291, 576, 528, 281, 1949, 562, 767, 30348, 50568, 50568, 264, 1412, 666, 584, 3097, 293, 24071, 30, 1743, 291, 1062, 528, 281, 362, 439, 295, 264, 13891, 294, 264, 50924, 50924, 3097, 1412, 337, 309, 281, 767, 312, 9495, 281, 1203, 300, 311, 294, 264, 4295, 1412, 13, 400, 291, 1062, 51340, 51340, 362, 257, 1389, 689, 819, 3467, 295, 8819, 366, 294, 4772, 294, 264, 1412, 992, 13, 1664, 291, 751, 466, 562, 51676, 51676], "temperature": 0.0, "avg_logprob": -0.1534985520622947, "compression_ratio": 1.7579908675799087, "no_speech_prob": 3.610998192016268e-06}, {"id": 985, "seek": 674452, "start": 6744.52, "end": 6748.52, "text": " that would be important? What are some of the considerations in splitting the data in training?", "tokens": [50364, 300, 576, 312, 1021, 30, 708, 366, 512, 295, 264, 24070, 294, 30348, 264, 1412, 294, 3097, 30, 50564, 50644, 4919, 11, 286, 478, 406, 988, 286, 1223, 264, 1168, 13, 407, 291, 366, 1417, 466, 517, 40251, 3097, 6352, 30, 50892, 50964, 1079, 13, 400, 611, 411, 11, 370, 498, 291, 362, 411, 257, 2603, 38444, 1412, 992, 11, 558, 30, 509, 393, 751, 466, 51396, 51396, 512, 295, 264, 24070, 337, 30348, 264, 1412, 562, 291, 434, 1382, 281, 3847, 257, 4295, 3209, 13, 51656, 51740], "temperature": 0.0, "avg_logprob": -0.2425516340467665, "compression_ratio": 1.7053571428571428, "no_speech_prob": 5.771441010438139e-06}, {"id": 986, "seek": 674452, "start": 6750.120000000001, "end": 6755.080000000001, "text": " Sorry, I'm not sure I understand the question. So you are talking about unbalanced training sets?", "tokens": [50364, 300, 576, 312, 1021, 30, 708, 366, 512, 295, 264, 24070, 294, 30348, 264, 1412, 294, 3097, 30, 50564, 50644, 4919, 11, 286, 478, 406, 988, 286, 1223, 264, 1168, 13, 407, 291, 366, 1417, 466, 517, 40251, 3097, 6352, 30, 50892, 50964, 1079, 13, 400, 611, 411, 11, 370, 498, 291, 362, 411, 257, 2603, 38444, 1412, 992, 11, 558, 30, 509, 393, 751, 466, 51396, 51396, 512, 295, 264, 24070, 337, 30348, 264, 1412, 562, 291, 434, 1382, 281, 3847, 257, 4295, 3209, 13, 51656, 51740], "temperature": 0.0, "avg_logprob": -0.2425516340467665, "compression_ratio": 1.7053571428571428, "no_speech_prob": 5.771441010438139e-06}, {"id": 987, "seek": 674452, "start": 6756.52, "end": 6765.160000000001, "text": " Yes. And also like, so if you have like a huge relational data set, right? You can talk about", "tokens": [50364, 300, 576, 312, 1021, 30, 708, 366, 512, 295, 264, 24070, 294, 30348, 264, 1412, 294, 3097, 30, 50564, 50644, 4919, 11, 286, 478, 406, 988, 286, 1223, 264, 1168, 13, 407, 291, 366, 1417, 466, 517, 40251, 3097, 6352, 30, 50892, 50964, 1079, 13, 400, 611, 411, 11, 370, 498, 291, 362, 411, 257, 2603, 38444, 1412, 992, 11, 558, 30, 509, 393, 751, 466, 51396, 51396, 512, 295, 264, 24070, 337, 30348, 264, 1412, 562, 291, 434, 1382, 281, 3847, 257, 4295, 3209, 13, 51656, 51740], "temperature": 0.0, "avg_logprob": -0.2425516340467665, "compression_ratio": 1.7053571428571428, "no_speech_prob": 5.771441010438139e-06}, {"id": 988, "seek": 674452, "start": 6765.160000000001, "end": 6770.360000000001, "text": " some of the considerations for splitting the data when you're trying to train a graph network.", "tokens": [50364, 300, 576, 312, 1021, 30, 708, 366, 512, 295, 264, 24070, 294, 30348, 264, 1412, 294, 3097, 30, 50564, 50644, 4919, 11, 286, 478, 406, 988, 286, 1223, 264, 1168, 13, 407, 291, 366, 1417, 466, 517, 40251, 3097, 6352, 30, 50892, 50964, 1079, 13, 400, 611, 411, 11, 370, 498, 291, 362, 411, 257, 2603, 38444, 1412, 992, 11, 558, 30, 509, 393, 751, 466, 51396, 51396, 512, 295, 264, 24070, 337, 30348, 264, 1412, 562, 291, 434, 1382, 281, 3847, 257, 4295, 3209, 13, 51656, 51740], "temperature": 0.0, "avg_logprob": -0.2425516340467665, "compression_ratio": 1.7053571428571428, "no_speech_prob": 5.771441010438139e-06}, {"id": 989, "seek": 677036, "start": 6770.36, "end": 6779.08, "text": " So for relational data sets, so you may have millions of small graphs. And it is fine. I mean,", "tokens": [50364, 407, 337, 38444, 1412, 6352, 11, 370, 291, 815, 362, 6803, 295, 1359, 24877, 13, 400, 309, 307, 2489, 13, 286, 914, 11, 50800, 50800, 570, 341, 4295, 18161, 3209, 11, 436, 366, 6695, 295, 264, 2744, 295, 428, 4295, 13, 407, 341, 51044, 51044, 307, 406, 364, 2734, 281, 1466, 512, 665, 4295, 2539, 10290, 13, 821, 307, 572, 2734, 365, 300, 13, 51288, 51320, 823, 11, 498, 291, 362, 517, 40251, 1412, 992, 11, 286, 500, 380, 458, 13, 407, 300, 311, 1310, 291, 393, 1310, 3079, 512, 51708, 51708], "temperature": 0.0, "avg_logprob": -0.23198006000924618, "compression_ratio": 1.6147186147186148, "no_speech_prob": 5.142127338331193e-05}, {"id": 990, "seek": 677036, "start": 6779.08, "end": 6783.96, "text": " because this graph neural network, they are independent of the size of your graph. So this", "tokens": [50364, 407, 337, 38444, 1412, 6352, 11, 370, 291, 815, 362, 6803, 295, 1359, 24877, 13, 400, 309, 307, 2489, 13, 286, 914, 11, 50800, 50800, 570, 341, 4295, 18161, 3209, 11, 436, 366, 6695, 295, 264, 2744, 295, 428, 4295, 13, 407, 341, 51044, 51044, 307, 406, 364, 2734, 281, 1466, 512, 665, 4295, 2539, 10290, 13, 821, 307, 572, 2734, 365, 300, 13, 51288, 51320, 823, 11, 498, 291, 362, 517, 40251, 1412, 992, 11, 286, 500, 380, 458, 13, 407, 300, 311, 1310, 291, 393, 1310, 3079, 512, 51708, 51708], "temperature": 0.0, "avg_logprob": -0.23198006000924618, "compression_ratio": 1.6147186147186148, "no_speech_prob": 5.142127338331193e-05}, {"id": 991, "seek": 677036, "start": 6783.96, "end": 6788.839999999999, "text": " is not an issue to learn some good graph learning representation. There is no issue with that.", "tokens": [50364, 407, 337, 38444, 1412, 6352, 11, 370, 291, 815, 362, 6803, 295, 1359, 24877, 13, 400, 309, 307, 2489, 13, 286, 914, 11, 50800, 50800, 570, 341, 4295, 18161, 3209, 11, 436, 366, 6695, 295, 264, 2744, 295, 428, 4295, 13, 407, 341, 51044, 51044, 307, 406, 364, 2734, 281, 1466, 512, 665, 4295, 2539, 10290, 13, 821, 307, 572, 2734, 365, 300, 13, 51288, 51320, 823, 11, 498, 291, 362, 517, 40251, 1412, 992, 11, 286, 500, 380, 458, 13, 407, 300, 311, 1310, 291, 393, 1310, 3079, 512, 51708, 51708], "temperature": 0.0, "avg_logprob": -0.23198006000924618, "compression_ratio": 1.6147186147186148, "no_speech_prob": 5.142127338331193e-05}, {"id": 992, "seek": 677036, "start": 6789.48, "end": 6797.24, "text": " Now, if you have unbalanced data set, I don't know. So that's maybe you can maybe apply some", "tokens": [50364, 407, 337, 38444, 1412, 6352, 11, 370, 291, 815, 362, 6803, 295, 1359, 24877, 13, 400, 309, 307, 2489, 13, 286, 914, 11, 50800, 50800, 570, 341, 4295, 18161, 3209, 11, 436, 366, 6695, 295, 264, 2744, 295, 428, 4295, 13, 407, 341, 51044, 51044, 307, 406, 364, 2734, 281, 1466, 512, 665, 4295, 2539, 10290, 13, 821, 307, 572, 2734, 365, 300, 13, 51288, 51320, 823, 11, 498, 291, 362, 517, 40251, 1412, 992, 11, 286, 500, 380, 458, 13, 407, 300, 311, 1310, 291, 393, 1310, 3079, 512, 51708, 51708], "temperature": 0.0, "avg_logprob": -0.23198006000924618, "compression_ratio": 1.6147186147186148, "no_speech_prob": 5.142127338331193e-05}, {"id": 993, "seek": 679724, "start": 6797.24, "end": 6803.5599999999995, "text": " standard techniques to do that. So you can also, for cross entropy, for example, you can weight", "tokens": [50364, 3832, 7512, 281, 360, 300, 13, 407, 291, 393, 611, 11, 337, 3278, 30867, 11, 337, 1365, 11, 291, 393, 3364, 50680, 50680, 428, 3278, 30867, 5413, 322, 264, 2744, 295, 1184, 1508, 13, 407, 300, 815, 312, 746, 291, 393, 360, 13, 50936, 51008, 583, 286, 1128, 1194, 886, 709, 466, 341, 13, 1033, 11, 1309, 291, 13, 51260, 51408, 2639, 544, 1651, 30, 286, 478, 920, 1242, 721, 3720, 510, 11, 457, 291, 393, 3177, 1803, 498, 291, 366, 51712, 51760], "temperature": 0.0, "avg_logprob": -0.2474452299230239, "compression_ratio": 1.573394495412844, "no_speech_prob": 4.673251896747388e-05}, {"id": 994, "seek": 679724, "start": 6803.5599999999995, "end": 6808.679999999999, "text": " your cross entropy depending on the size of each class. So that may be something you can do.", "tokens": [50364, 3832, 7512, 281, 360, 300, 13, 407, 291, 393, 611, 11, 337, 3278, 30867, 11, 337, 1365, 11, 291, 393, 3364, 50680, 50680, 428, 3278, 30867, 5413, 322, 264, 2744, 295, 1184, 1508, 13, 407, 300, 815, 312, 746, 291, 393, 360, 13, 50936, 51008, 583, 286, 1128, 1194, 886, 709, 466, 341, 13, 1033, 11, 1309, 291, 13, 51260, 51408, 2639, 544, 1651, 30, 286, 478, 920, 1242, 721, 3720, 510, 11, 457, 291, 393, 3177, 1803, 498, 291, 366, 51712, 51760], "temperature": 0.0, "avg_logprob": -0.2474452299230239, "compression_ratio": 1.573394495412844, "no_speech_prob": 4.673251896747388e-05}, {"id": 995, "seek": 679724, "start": 6810.12, "end": 6815.16, "text": " But I never thought too much about this. Okay, thank you.", "tokens": [50364, 3832, 7512, 281, 360, 300, 13, 407, 291, 393, 611, 11, 337, 3278, 30867, 11, 337, 1365, 11, 291, 393, 3364, 50680, 50680, 428, 3278, 30867, 5413, 322, 264, 2744, 295, 1184, 1508, 13, 407, 300, 815, 312, 746, 291, 393, 360, 13, 50936, 51008, 583, 286, 1128, 1194, 886, 709, 466, 341, 13, 1033, 11, 1309, 291, 13, 51260, 51408, 2639, 544, 1651, 30, 286, 478, 920, 1242, 721, 3720, 510, 11, 457, 291, 393, 3177, 1803, 498, 291, 366, 51712, 51760], "temperature": 0.0, "avg_logprob": -0.2474452299230239, "compression_ratio": 1.573394495412844, "no_speech_prob": 4.673251896747388e-05}, {"id": 996, "seek": 679724, "start": 6818.12, "end": 6824.2, "text": " Any more questions? I'm still getting things written here, but you can voice yourself if you are", "tokens": [50364, 3832, 7512, 281, 360, 300, 13, 407, 291, 393, 611, 11, 337, 3278, 30867, 11, 337, 1365, 11, 291, 393, 3364, 50680, 50680, 428, 3278, 30867, 5413, 322, 264, 2744, 295, 1184, 1508, 13, 407, 300, 815, 312, 746, 291, 393, 360, 13, 50936, 51008, 583, 286, 1128, 1194, 886, 709, 466, 341, 13, 1033, 11, 1309, 291, 13, 51260, 51408, 2639, 544, 1651, 30, 286, 478, 920, 1242, 721, 3720, 510, 11, 457, 291, 393, 3177, 1803, 498, 291, 366, 51712, 51760], "temperature": 0.0, "avg_logprob": -0.2474452299230239, "compression_ratio": 1.573394495412844, "no_speech_prob": 4.673251896747388e-05}, {"id": 997, "seek": 682420, "start": 6824.2, "end": 6831.5599999999995, "text": " Yeah, I have a question actually. First of all, thanks a lot for the lecture at this time,", "tokens": [50364, 865, 11, 286, 362, 257, 1168, 767, 13, 2386, 295, 439, 11, 3231, 257, 688, 337, 264, 7991, 412, 341, 565, 11, 50732, 50732, 2318, 337, 291, 13, 407, 577, 360, 291, 2028, 365, 3331, 689, 264, 13891, 360, 406, 362, 264, 912, 10139, 30, 51056, 51056, 1743, 498, 286, 528, 281, 1190, 257, 1359, 11, 2199, 17528, 4295, 1207, 21680, 798, 3209, 11, 457, 452, 13891, 51328, 51328, 366, 746, 411, 754, 337, 4384, 11, 561, 293, 550, 7183, 11, 293, 286, 528, 819, 12819, 13, 407, 51620, 51620], "temperature": 0.0, "avg_logprob": -0.20268937815790591, "compression_ratio": 1.5690376569037656, "no_speech_prob": 2.2469266696134582e-05}, {"id": 998, "seek": 682420, "start": 6831.5599999999995, "end": 6838.04, "text": " especially for you. So how do you deal with cases where the nodes do not have the same dimension?", "tokens": [50364, 865, 11, 286, 362, 257, 1168, 767, 13, 2386, 295, 439, 11, 3231, 257, 688, 337, 264, 7991, 412, 341, 565, 11, 50732, 50732, 2318, 337, 291, 13, 407, 577, 360, 291, 2028, 365, 3331, 689, 264, 13891, 360, 406, 362, 264, 912, 10139, 30, 51056, 51056, 1743, 498, 286, 528, 281, 1190, 257, 1359, 11, 2199, 17528, 4295, 1207, 21680, 798, 3209, 11, 457, 452, 13891, 51328, 51328, 366, 746, 411, 754, 337, 4384, 11, 561, 293, 550, 7183, 11, 293, 286, 528, 819, 12819, 13, 407, 51620, 51620], "temperature": 0.0, "avg_logprob": -0.20268937815790591, "compression_ratio": 1.5690376569037656, "no_speech_prob": 2.2469266696134582e-05}, {"id": 999, "seek": 682420, "start": 6838.04, "end": 6843.48, "text": " Like if I want to run a small, simple vanilla graph count relieving network, but my nodes", "tokens": [50364, 865, 11, 286, 362, 257, 1168, 767, 13, 2386, 295, 439, 11, 3231, 257, 688, 337, 264, 7991, 412, 341, 565, 11, 50732, 50732, 2318, 337, 291, 13, 407, 577, 360, 291, 2028, 365, 3331, 689, 264, 13891, 360, 406, 362, 264, 912, 10139, 30, 51056, 51056, 1743, 498, 286, 528, 281, 1190, 257, 1359, 11, 2199, 17528, 4295, 1207, 21680, 798, 3209, 11, 457, 452, 13891, 51328, 51328, 366, 746, 411, 754, 337, 4384, 11, 561, 293, 550, 7183, 11, 293, 286, 528, 819, 12819, 13, 407, 51620, 51620], "temperature": 0.0, "avg_logprob": -0.20268937815790591, "compression_ratio": 1.5690376569037656, "no_speech_prob": 2.2469266696134582e-05}, {"id": 1000, "seek": 682420, "start": 6843.48, "end": 6849.32, "text": " are something like even for Facebook, people and then pages, and I want different dimensions. So", "tokens": [50364, 865, 11, 286, 362, 257, 1168, 767, 13, 2386, 295, 439, 11, 3231, 257, 688, 337, 264, 7991, 412, 341, 565, 11, 50732, 50732, 2318, 337, 291, 13, 407, 577, 360, 291, 2028, 365, 3331, 689, 264, 13891, 360, 406, 362, 264, 912, 10139, 30, 51056, 51056, 1743, 498, 286, 528, 281, 1190, 257, 1359, 11, 2199, 17528, 4295, 1207, 21680, 798, 3209, 11, 457, 452, 13891, 51328, 51328, 366, 746, 411, 754, 337, 4384, 11, 561, 293, 550, 7183, 11, 293, 286, 528, 819, 12819, 13, 407, 51620, 51620], "temperature": 0.0, "avg_logprob": -0.20268937815790591, "compression_ratio": 1.5690376569037656, "no_speech_prob": 2.2469266696134582e-05}, {"id": 1001, "seek": 684932, "start": 6849.32, "end": 6854.36, "text": " how do you think about graph, like very, very simple graph neural network in that?", "tokens": [50364, 577, 360, 291, 519, 466, 4295, 11, 411, 588, 11, 588, 2199, 4295, 18161, 3209, 294, 300, 30, 50616, 50712, 6693, 575, 1825, 281, 360, 365, 4295, 18161, 9590, 13, 759, 291, 362, 819, 12819, 337, 50936, 50936, 428, 8062, 11, 370, 1391, 291, 643, 281, 829, 1203, 322, 264, 912, 10139, 11, 293, 550, 291, 643, 281, 764, 51192, 51192, 512, 16961, 2445, 11, 411, 472, 562, 291, 362, 264, 1589, 293, 4018, 562, 291, 500, 380, 362, 604, 51412, 51412, 1589, 13, 400, 341, 486, 312, 1143, 1830, 264, 24903, 295, 264, 4470, 13, 400, 550, 562, 291, 646, 51652, 51652], "temperature": 0.0, "avg_logprob": -0.21465123494466146, "compression_ratio": 1.8412698412698412, "no_speech_prob": 3.0662136850878596e-05}, {"id": 1002, "seek": 684932, "start": 6856.28, "end": 6860.759999999999, "text": " Nothing has nothing to do with graph neural networks. If you have different dimensions for", "tokens": [50364, 577, 360, 291, 519, 466, 4295, 11, 411, 588, 11, 588, 2199, 4295, 18161, 3209, 294, 300, 30, 50616, 50712, 6693, 575, 1825, 281, 360, 365, 4295, 18161, 9590, 13, 759, 291, 362, 819, 12819, 337, 50936, 50936, 428, 8062, 11, 370, 1391, 291, 643, 281, 829, 1203, 322, 264, 912, 10139, 11, 293, 550, 291, 643, 281, 764, 51192, 51192, 512, 16961, 2445, 11, 411, 472, 562, 291, 362, 264, 1589, 293, 4018, 562, 291, 500, 380, 362, 604, 51412, 51412, 1589, 13, 400, 341, 486, 312, 1143, 1830, 264, 24903, 295, 264, 4470, 13, 400, 550, 562, 291, 646, 51652, 51652], "temperature": 0.0, "avg_logprob": -0.21465123494466146, "compression_ratio": 1.8412698412698412, "no_speech_prob": 3.0662136850878596e-05}, {"id": 1003, "seek": 684932, "start": 6860.759999999999, "end": 6865.88, "text": " your vector, so probably you need to put everything on the same dimension, and then you need to use", "tokens": [50364, 577, 360, 291, 519, 466, 4295, 11, 411, 588, 11, 588, 2199, 4295, 18161, 3209, 294, 300, 30, 50616, 50712, 6693, 575, 1825, 281, 360, 365, 4295, 18161, 9590, 13, 759, 291, 362, 819, 12819, 337, 50936, 50936, 428, 8062, 11, 370, 1391, 291, 643, 281, 829, 1203, 322, 264, 912, 10139, 11, 293, 550, 291, 643, 281, 764, 51192, 51192, 512, 16961, 2445, 11, 411, 472, 562, 291, 362, 264, 1589, 293, 4018, 562, 291, 500, 380, 362, 604, 51412, 51412, 1589, 13, 400, 341, 486, 312, 1143, 1830, 264, 24903, 295, 264, 4470, 13, 400, 550, 562, 291, 646, 51652, 51652], "temperature": 0.0, "avg_logprob": -0.21465123494466146, "compression_ratio": 1.8412698412698412, "no_speech_prob": 3.0662136850878596e-05}, {"id": 1004, "seek": 684932, "start": 6865.88, "end": 6870.28, "text": " some indicator function, like one when you have the information and zero when you don't have any", "tokens": [50364, 577, 360, 291, 519, 466, 4295, 11, 411, 588, 11, 588, 2199, 4295, 18161, 3209, 294, 300, 30, 50616, 50712, 6693, 575, 1825, 281, 360, 365, 4295, 18161, 9590, 13, 759, 291, 362, 819, 12819, 337, 50936, 50936, 428, 8062, 11, 370, 1391, 291, 643, 281, 829, 1203, 322, 264, 912, 10139, 11, 293, 550, 291, 643, 281, 764, 51192, 51192, 512, 16961, 2445, 11, 411, 472, 562, 291, 362, 264, 1589, 293, 4018, 562, 291, 500, 380, 362, 604, 51412, 51412, 1589, 13, 400, 341, 486, 312, 1143, 1830, 264, 24903, 295, 264, 4470, 13, 400, 550, 562, 291, 646, 51652, 51652], "temperature": 0.0, "avg_logprob": -0.21465123494466146, "compression_ratio": 1.8412698412698412, "no_speech_prob": 3.0662136850878596e-05}, {"id": 1005, "seek": 684932, "start": 6870.28, "end": 6875.08, "text": " information. And this will be used during the computation of the loss. And then when you back", "tokens": [50364, 577, 360, 291, 519, 466, 4295, 11, 411, 588, 11, 588, 2199, 4295, 18161, 3209, 294, 300, 30, 50616, 50712, 6693, 575, 1825, 281, 360, 365, 4295, 18161, 9590, 13, 759, 291, 362, 819, 12819, 337, 50936, 50936, 428, 8062, 11, 370, 1391, 291, 643, 281, 829, 1203, 322, 264, 912, 10139, 11, 293, 550, 291, 643, 281, 764, 51192, 51192, 512, 16961, 2445, 11, 411, 472, 562, 291, 362, 264, 1589, 293, 4018, 562, 291, 500, 380, 362, 604, 51412, 51412, 1589, 13, 400, 341, 486, 312, 1143, 1830, 264, 24903, 295, 264, 4470, 13, 400, 550, 562, 291, 646, 51652, 51652], "temperature": 0.0, "avg_logprob": -0.21465123494466146, "compression_ratio": 1.8412698412698412, "no_speech_prob": 3.0662136850878596e-05}, {"id": 1006, "seek": 687508, "start": 6875.08, "end": 6880.84, "text": " propagate, if you don't have any feature information, you will not use it. But nothing", "tokens": [50364, 48256, 11, 498, 291, 500, 380, 362, 604, 4111, 1589, 11, 291, 486, 406, 764, 309, 13, 583, 1825, 50652, 50652, 575, 1340, 281, 360, 365, 4295, 18161, 9590, 13, 50732, 50868, 1033, 11, 1309, 291, 13, 50900, 51408, 6962, 322, 11, 291, 434, 3579, 11, 286, 478, 3760, 370, 709, 13, 51544, 51704], "temperature": 0.0, "avg_logprob": -0.3841032641274588, "compression_ratio": 1.3517241379310345, "no_speech_prob": 3.804043444688432e-05}, {"id": 1007, "seek": 687508, "start": 6880.84, "end": 6882.44, "text": " has anything to do with graph neural networks.", "tokens": [50364, 48256, 11, 498, 291, 500, 380, 362, 604, 4111, 1589, 11, 291, 486, 406, 764, 309, 13, 583, 1825, 50652, 50652, 575, 1340, 281, 360, 365, 4295, 18161, 9590, 13, 50732, 50868, 1033, 11, 1309, 291, 13, 50900, 51408, 6962, 322, 11, 291, 434, 3579, 11, 286, 478, 3760, 370, 709, 13, 51544, 51704], "temperature": 0.0, "avg_logprob": -0.3841032641274588, "compression_ratio": 1.3517241379310345, "no_speech_prob": 3.804043444688432e-05}, {"id": 1008, "seek": 687508, "start": 6885.16, "end": 6885.8, "text": " Okay, thank you.", "tokens": [50364, 48256, 11, 498, 291, 500, 380, 362, 604, 4111, 1589, 11, 291, 486, 406, 764, 309, 13, 583, 1825, 50652, 50652, 575, 1340, 281, 360, 365, 4295, 18161, 9590, 13, 50732, 50868, 1033, 11, 1309, 291, 13, 50900, 51408, 6962, 322, 11, 291, 434, 3579, 11, 286, 478, 3760, 370, 709, 13, 51544, 51704], "temperature": 0.0, "avg_logprob": -0.3841032641274588, "compression_ratio": 1.3517241379310345, "no_speech_prob": 3.804043444688432e-05}, {"id": 1009, "seek": 687508, "start": 6895.96, "end": 6898.68, "text": " Hold on, you're writing, I'm reading so much.", "tokens": [50364, 48256, 11, 498, 291, 500, 380, 362, 604, 4111, 1589, 11, 291, 486, 406, 764, 309, 13, 583, 1825, 50652, 50652, 575, 1340, 281, 360, 365, 4295, 18161, 9590, 13, 50732, 50868, 1033, 11, 1309, 291, 13, 50900, 51408, 6962, 322, 11, 291, 434, 3579, 11, 286, 478, 3760, 370, 709, 13, 51544, 51704], "temperature": 0.0, "avg_logprob": -0.3841032641274588, "compression_ratio": 1.3517241379310345, "no_speech_prob": 3.804043444688432e-05}, {"id": 1010, "seek": 689868, "start": 6898.68, "end": 6906.280000000001, "text": " So maybe I don't understand the question, but I will read it out loud anyway. Is there any GCN", "tokens": [50364, 407, 1310, 286, 500, 380, 1223, 264, 1168, 11, 457, 286, 486, 1401, 309, 484, 6588, 4033, 13, 1119, 456, 604, 29435, 45, 50744, 50744, 597, 393, 589, 322, 3866, 7934, 32284, 1214, 30, 1171, 1365, 11, 257, 12957, 621, 41048, 4295, 13, 51092, 51124, 286, 500, 380, 458, 437, 341, 1355, 13, 51184, 51228, 407, 11, 286, 519, 300, 311, 257, 665, 1168, 13, 407, 11, 286, 519, 300, 311, 257, 665, 1168, 13, 407, 11, 286, 519, 300, 311, 257, 665, 51540, 51540], "temperature": 0.0, "avg_logprob": -0.5531019451974453, "compression_ratio": 1.690217391304348, "no_speech_prob": 0.00018453634402249008}, {"id": 1011, "seek": 689868, "start": 6906.280000000001, "end": 6913.240000000001, "text": " which can work on multiple agency matrices together? For example, a bidirectional graph.", "tokens": [50364, 407, 1310, 286, 500, 380, 1223, 264, 1168, 11, 457, 286, 486, 1401, 309, 484, 6588, 4033, 13, 1119, 456, 604, 29435, 45, 50744, 50744, 597, 393, 589, 322, 3866, 7934, 32284, 1214, 30, 1171, 1365, 11, 257, 12957, 621, 41048, 4295, 13, 51092, 51124, 286, 500, 380, 458, 437, 341, 1355, 13, 51184, 51228, 407, 11, 286, 519, 300, 311, 257, 665, 1168, 13, 407, 11, 286, 519, 300, 311, 257, 665, 1168, 13, 407, 11, 286, 519, 300, 311, 257, 665, 51540, 51540], "temperature": 0.0, "avg_logprob": -0.5531019451974453, "compression_ratio": 1.690217391304348, "no_speech_prob": 0.00018453634402249008}, {"id": 1012, "seek": 689868, "start": 6913.88, "end": 6915.08, "text": " I don't know what this means.", "tokens": [50364, 407, 1310, 286, 500, 380, 1223, 264, 1168, 11, 457, 286, 486, 1401, 309, 484, 6588, 4033, 13, 1119, 456, 604, 29435, 45, 50744, 50744, 597, 393, 589, 322, 3866, 7934, 32284, 1214, 30, 1171, 1365, 11, 257, 12957, 621, 41048, 4295, 13, 51092, 51124, 286, 500, 380, 458, 437, 341, 1355, 13, 51184, 51228, 407, 11, 286, 519, 300, 311, 257, 665, 1168, 13, 407, 11, 286, 519, 300, 311, 257, 665, 1168, 13, 407, 11, 286, 519, 300, 311, 257, 665, 51540, 51540], "temperature": 0.0, "avg_logprob": -0.5531019451974453, "compression_ratio": 1.690217391304348, "no_speech_prob": 0.00018453634402249008}, {"id": 1013, "seek": 689868, "start": 6915.96, "end": 6922.200000000001, "text": " So, I think that's a good question. So, I think that's a good question. So, I think that's a good", "tokens": [50364, 407, 1310, 286, 500, 380, 1223, 264, 1168, 11, 457, 286, 486, 1401, 309, 484, 6588, 4033, 13, 1119, 456, 604, 29435, 45, 50744, 50744, 597, 393, 589, 322, 3866, 7934, 32284, 1214, 30, 1171, 1365, 11, 257, 12957, 621, 41048, 4295, 13, 51092, 51124, 286, 500, 380, 458, 437, 341, 1355, 13, 51184, 51228, 407, 11, 286, 519, 300, 311, 257, 665, 1168, 13, 407, 11, 286, 519, 300, 311, 257, 665, 1168, 13, 407, 11, 286, 519, 300, 311, 257, 665, 51540, 51540], "temperature": 0.0, "avg_logprob": -0.5531019451974453, "compression_ratio": 1.690217391304348, "no_speech_prob": 0.00018453634402249008}, {"id": 1014, "seek": 692220, "start": 6922.2, "end": 6928.599999999999, "text": " agency matrices together. For example, a bidirectional graph. I don't know what this means.", "tokens": [50364, 7934, 32284, 1214, 13, 1171, 1365, 11, 257, 12957, 621, 41048, 4295, 13, 286, 500, 380, 458, 437, 341, 1355, 13, 50684, 50760, 407, 11, 498, 264, 1168, 307, 466, 9848, 34091, 11, 370, 291, 458, 291, 815, 362, 544, 813, 472, 3205, 50988, 50988, 11015, 428, 13891, 13, 1079, 11, 456, 366, 512, 589, 466, 341, 13, 467, 311, 364, 10320, 11, 51196, 51196, 309, 311, 257, 3303, 10320, 44003, 13, 407, 11, 291, 393, 360, 300, 13, 821, 307, 572, 27432, 281, 352, 281, 51528, 51528], "temperature": 0.0, "avg_logprob": -0.1712022993299696, "compression_ratio": 1.5535714285714286, "no_speech_prob": 0.00012328135198913515}, {"id": 1015, "seek": 692220, "start": 6930.12, "end": 6934.679999999999, "text": " So, if the question is about hypergraph, so you know you may have more than one age", "tokens": [50364, 7934, 32284, 1214, 13, 1171, 1365, 11, 257, 12957, 621, 41048, 4295, 13, 286, 500, 380, 458, 437, 341, 1355, 13, 50684, 50760, 407, 11, 498, 264, 1168, 307, 466, 9848, 34091, 11, 370, 291, 458, 291, 815, 362, 544, 813, 472, 3205, 50988, 50988, 11015, 428, 13891, 13, 1079, 11, 456, 366, 512, 589, 466, 341, 13, 467, 311, 364, 10320, 11, 51196, 51196, 309, 311, 257, 3303, 10320, 44003, 13, 407, 11, 291, 393, 360, 300, 13, 821, 307, 572, 27432, 281, 352, 281, 51528, 51528], "temperature": 0.0, "avg_logprob": -0.1712022993299696, "compression_ratio": 1.5535714285714286, "no_speech_prob": 0.00012328135198913515}, {"id": 1016, "seek": 692220, "start": 6934.679999999999, "end": 6938.84, "text": " connecting your nodes. Yes, there are some work about this. It's an extension,", "tokens": [50364, 7934, 32284, 1214, 13, 1171, 1365, 11, 257, 12957, 621, 41048, 4295, 13, 286, 500, 380, 458, 437, 341, 1355, 13, 50684, 50760, 407, 11, 498, 264, 1168, 307, 466, 9848, 34091, 11, 370, 291, 458, 291, 815, 362, 544, 813, 472, 3205, 50988, 50988, 11015, 428, 13891, 13, 1079, 11, 456, 366, 512, 589, 466, 341, 13, 467, 311, 364, 10320, 11, 51196, 51196, 309, 311, 257, 3303, 10320, 44003, 13, 407, 11, 291, 393, 360, 300, 13, 821, 307, 572, 27432, 281, 352, 281, 51528, 51528], "temperature": 0.0, "avg_logprob": -0.1712022993299696, "compression_ratio": 1.5535714285714286, "no_speech_prob": 0.00012328135198913515}, {"id": 1017, "seek": 692220, "start": 6938.84, "end": 6945.48, "text": " it's a natural extension mathematically. So, you can do that. There is no limitation to go to", "tokens": [50364, 7934, 32284, 1214, 13, 1171, 1365, 11, 257, 12957, 621, 41048, 4295, 13, 286, 500, 380, 458, 437, 341, 1355, 13, 50684, 50760, 407, 11, 498, 264, 1168, 307, 466, 9848, 34091, 11, 370, 291, 458, 291, 815, 362, 544, 813, 472, 3205, 50988, 50988, 11015, 428, 13891, 13, 1079, 11, 456, 366, 512, 589, 466, 341, 13, 467, 311, 364, 10320, 11, 51196, 51196, 309, 311, 257, 3303, 10320, 44003, 13, 407, 11, 291, 393, 360, 300, 13, 821, 307, 572, 27432, 281, 352, 281, 51528, 51528], "temperature": 0.0, "avg_logprob": -0.1712022993299696, "compression_ratio": 1.5535714285714286, "no_speech_prob": 0.00012328135198913515}, {"id": 1018, "seek": 694548, "start": 6945.48, "end": 6956.2, "text": " hypergraph. It's fine. And there are now some data sets for this task. So, if there is an application,", "tokens": [50364, 9848, 34091, 13, 467, 311, 2489, 13, 400, 456, 366, 586, 512, 1412, 6352, 337, 341, 5633, 13, 407, 11, 498, 456, 307, 364, 3861, 11, 50900, 50996, 370, 1731, 576, 312, 28235, 281, 360, 11, 456, 307, 1217, 257, 1412, 992, 293, 10577, 466, 341, 13, 51240, 51272, 1033, 11, 1071, 1168, 576, 312, 11, 775, 309, 652, 2020, 281, 362, 13891, 300, 366, 4122, 295, 257, 954, 51540, 51572], "temperature": 0.0, "avg_logprob": -0.1379321242031986, "compression_ratio": 1.5294117647058822, "no_speech_prob": 3.525273859850131e-05}, {"id": 1019, "seek": 694548, "start": 6958.12, "end": 6963.0, "text": " so students would be trusting to do, there is already a data set and papers about this.", "tokens": [50364, 9848, 34091, 13, 467, 311, 2489, 13, 400, 456, 366, 586, 512, 1412, 6352, 337, 341, 5633, 13, 407, 11, 498, 456, 307, 364, 3861, 11, 50900, 50996, 370, 1731, 576, 312, 28235, 281, 360, 11, 456, 307, 1217, 257, 1412, 992, 293, 10577, 466, 341, 13, 51240, 51272, 1033, 11, 1071, 1168, 576, 312, 11, 775, 309, 652, 2020, 281, 362, 13891, 300, 366, 4122, 295, 257, 954, 51540, 51572], "temperature": 0.0, "avg_logprob": -0.1379321242031986, "compression_ratio": 1.5294117647058822, "no_speech_prob": 3.525273859850131e-05}, {"id": 1020, "seek": 694548, "start": 6963.639999999999, "end": 6969.0, "text": " Okay, another question would be, does it make sense to have nodes that are features of a person", "tokens": [50364, 9848, 34091, 13, 467, 311, 2489, 13, 400, 456, 366, 586, 512, 1412, 6352, 337, 341, 5633, 13, 407, 11, 498, 456, 307, 364, 3861, 11, 50900, 50996, 370, 1731, 576, 312, 28235, 281, 360, 11, 456, 307, 1217, 257, 1412, 992, 293, 10577, 466, 341, 13, 51240, 51272, 1033, 11, 1071, 1168, 576, 312, 11, 775, 309, 652, 2020, 281, 362, 13891, 300, 366, 4122, 295, 257, 954, 51540, 51572], "temperature": 0.0, "avg_logprob": -0.1379321242031986, "compression_ratio": 1.5294117647058822, "no_speech_prob": 3.525273859850131e-05}, {"id": 1021, "seek": 696900, "start": 6969.0, "end": 6975.08, "text": " and do graph classification or have nodes as person and do node classification?", "tokens": [50364, 293, 360, 4295, 21538, 420, 362, 13891, 382, 954, 293, 360, 9984, 21538, 30, 50668, 50768, 286, 500, 380, 458, 13, 50793, 50820, 286, 500, 380, 458, 13, 407, 11, 2049, 561, 1029, 385, 264, 1168, 11, 393, 286, 360, 257, 4295, 2212, 341, 1412, 30, 51168, 51236, 407, 11, 309, 311, 534, 5633, 12334, 13, 286, 519, 309, 311, 534, 11, 562, 307, 516, 281, 312, 4420, 420, 406, 11, 51532, 51532, 562, 291, 483, 512, 665, 6159, 13, 1436, 437, 307, 257, 4295, 30, 467, 311, 445, 257, 5765, 295, 6119, 3711, 11, 51800, 51824], "temperature": 0.0, "avg_logprob": -0.2776582891290838, "compression_ratio": 1.6712328767123288, "no_speech_prob": 5.0480710342526436e-05}, {"id": 1022, "seek": 696900, "start": 6977.08, "end": 6977.58, "text": " I don't know.", "tokens": [50364, 293, 360, 4295, 21538, 420, 362, 13891, 382, 954, 293, 360, 9984, 21538, 30, 50668, 50768, 286, 500, 380, 458, 13, 50793, 50820, 286, 500, 380, 458, 13, 407, 11, 2049, 561, 1029, 385, 264, 1168, 11, 393, 286, 360, 257, 4295, 2212, 341, 1412, 30, 51168, 51236, 407, 11, 309, 311, 534, 5633, 12334, 13, 286, 519, 309, 311, 534, 11, 562, 307, 516, 281, 312, 4420, 420, 406, 11, 51532, 51532, 562, 291, 483, 512, 665, 6159, 13, 1436, 437, 307, 257, 4295, 30, 467, 311, 445, 257, 5765, 295, 6119, 3711, 11, 51800, 51824], "temperature": 0.0, "avg_logprob": -0.2776582891290838, "compression_ratio": 1.6712328767123288, "no_speech_prob": 5.0480710342526436e-05}, {"id": 1023, "seek": 696900, "start": 6978.12, "end": 6985.08, "text": " I don't know. So, often people ask me the question, can I do a graph given this data?", "tokens": [50364, 293, 360, 4295, 21538, 420, 362, 13891, 382, 954, 293, 360, 9984, 21538, 30, 50668, 50768, 286, 500, 380, 458, 13, 50793, 50820, 286, 500, 380, 458, 13, 407, 11, 2049, 561, 1029, 385, 264, 1168, 11, 393, 286, 360, 257, 4295, 2212, 341, 1412, 30, 51168, 51236, 407, 11, 309, 311, 534, 5633, 12334, 13, 286, 519, 309, 311, 534, 11, 562, 307, 516, 281, 312, 4420, 420, 406, 11, 51532, 51532, 562, 291, 483, 512, 665, 6159, 13, 1436, 437, 307, 257, 4295, 30, 467, 311, 445, 257, 5765, 295, 6119, 3711, 11, 51800, 51824], "temperature": 0.0, "avg_logprob": -0.2776582891290838, "compression_ratio": 1.6712328767123288, "no_speech_prob": 5.0480710342526436e-05}, {"id": 1024, "seek": 696900, "start": 6986.44, "end": 6992.36, "text": " So, it's really task dependent. I think it's really, when is going to be useful or not,", "tokens": [50364, 293, 360, 4295, 21538, 420, 362, 13891, 382, 954, 293, 360, 9984, 21538, 30, 50668, 50768, 286, 500, 380, 458, 13, 50793, 50820, 286, 500, 380, 458, 13, 407, 11, 2049, 561, 1029, 385, 264, 1168, 11, 393, 286, 360, 257, 4295, 2212, 341, 1412, 30, 51168, 51236, 407, 11, 309, 311, 534, 5633, 12334, 13, 286, 519, 309, 311, 534, 11, 562, 307, 516, 281, 312, 4420, 420, 406, 11, 51532, 51532, 562, 291, 483, 512, 665, 6159, 13, 1436, 437, 307, 257, 4295, 30, 467, 311, 445, 257, 5765, 295, 6119, 3711, 11, 51800, 51824], "temperature": 0.0, "avg_logprob": -0.2776582891290838, "compression_ratio": 1.6712328767123288, "no_speech_prob": 5.0480710342526436e-05}, {"id": 1025, "seek": 696900, "start": 6992.36, "end": 6997.72, "text": " when you get some good relationships. Because what is a graph? It's just a collection of pairwise,", "tokens": [50364, 293, 360, 4295, 21538, 420, 362, 13891, 382, 954, 293, 360, 9984, 21538, 30, 50668, 50768, 286, 500, 380, 458, 13, 50793, 50820, 286, 500, 380, 458, 13, 407, 11, 2049, 561, 1029, 385, 264, 1168, 11, 393, 286, 360, 257, 4295, 2212, 341, 1412, 30, 51168, 51236, 407, 11, 309, 311, 534, 5633, 12334, 13, 286, 519, 309, 311, 534, 11, 562, 307, 516, 281, 312, 4420, 420, 406, 11, 51532, 51532, 562, 291, 483, 512, 665, 6159, 13, 1436, 437, 307, 257, 4295, 30, 467, 311, 445, 257, 5765, 295, 6119, 3711, 11, 51800, 51824], "temperature": 0.0, "avg_logprob": -0.2776582891290838, "compression_ratio": 1.6712328767123288, "no_speech_prob": 5.0480710342526436e-05}, {"id": 1026, "seek": 699772, "start": 6997.72, "end": 7005.72, "text": " you know, pairwise connections. So, that's it. So, the question is when it is relevant to solve your", "tokens": [50364, 291, 458, 11, 6119, 3711, 9271, 13, 407, 11, 300, 311, 309, 13, 407, 11, 264, 1168, 307, 562, 309, 307, 7340, 281, 5039, 428, 50764, 50764, 5633, 13, 4803, 309, 307, 7340, 11, 2171, 309, 311, 406, 13, 407, 11, 309, 534, 5946, 322, 264, 11, 1338, 11, 309, 311, 6322, 11, 51060, 51060, 457, 309, 534, 5946, 322, 264, 1412, 293, 264, 5633, 291, 528, 281, 5039, 13, 51232, 51232, 407, 11, 1338, 13, 51257, 51292, 865, 11, 264, 3107, 307, 11239, 365, 428, 1867, 13, 51392, 51572, 286, 519, 321, 5872, 484, 295, 1651, 11, 5969, 456, 366, 544, 1348, 452, 636, 13, 51796, 51860], "temperature": 0.0, "avg_logprob": -0.29132430336692117, "compression_ratio": 1.7802690582959642, "no_speech_prob": 2.422523539280519e-05}, {"id": 1027, "seek": 699772, "start": 7005.72, "end": 7011.64, "text": " task. Sometimes it is relevant, sometimes it's not. So, it really depends on the, yeah, it's obvious,", "tokens": [50364, 291, 458, 11, 6119, 3711, 9271, 13, 407, 11, 300, 311, 309, 13, 407, 11, 264, 1168, 307, 562, 309, 307, 7340, 281, 5039, 428, 50764, 50764, 5633, 13, 4803, 309, 307, 7340, 11, 2171, 309, 311, 406, 13, 407, 11, 309, 534, 5946, 322, 264, 11, 1338, 11, 309, 311, 6322, 11, 51060, 51060, 457, 309, 534, 5946, 322, 264, 1412, 293, 264, 5633, 291, 528, 281, 5039, 13, 51232, 51232, 407, 11, 1338, 13, 51257, 51292, 865, 11, 264, 3107, 307, 11239, 365, 428, 1867, 13, 51392, 51572, 286, 519, 321, 5872, 484, 295, 1651, 11, 5969, 456, 366, 544, 1348, 452, 636, 13, 51796, 51860], "temperature": 0.0, "avg_logprob": -0.29132430336692117, "compression_ratio": 1.7802690582959642, "no_speech_prob": 2.422523539280519e-05}, {"id": 1028, "seek": 699772, "start": 7011.64, "end": 7015.08, "text": " but it really depends on the data and the task you want to solve.", "tokens": [50364, 291, 458, 11, 6119, 3711, 9271, 13, 407, 11, 300, 311, 309, 13, 407, 11, 264, 1168, 307, 562, 309, 307, 7340, 281, 5039, 428, 50764, 50764, 5633, 13, 4803, 309, 307, 7340, 11, 2171, 309, 311, 406, 13, 407, 11, 309, 534, 5946, 322, 264, 11, 1338, 11, 309, 311, 6322, 11, 51060, 51060, 457, 309, 534, 5946, 322, 264, 1412, 293, 264, 5633, 291, 528, 281, 5039, 13, 51232, 51232, 407, 11, 1338, 13, 51257, 51292, 865, 11, 264, 3107, 307, 11239, 365, 428, 1867, 13, 51392, 51572, 286, 519, 321, 5872, 484, 295, 1651, 11, 5969, 456, 366, 544, 1348, 452, 636, 13, 51796, 51860], "temperature": 0.0, "avg_logprob": -0.29132430336692117, "compression_ratio": 1.7802690582959642, "no_speech_prob": 2.422523539280519e-05}, {"id": 1029, "seek": 699772, "start": 7015.08, "end": 7015.58, "text": " So, yeah.", "tokens": [50364, 291, 458, 11, 6119, 3711, 9271, 13, 407, 11, 300, 311, 309, 13, 407, 11, 264, 1168, 307, 562, 309, 307, 7340, 281, 5039, 428, 50764, 50764, 5633, 13, 4803, 309, 307, 7340, 11, 2171, 309, 311, 406, 13, 407, 11, 309, 534, 5946, 322, 264, 11, 1338, 11, 309, 311, 6322, 11, 51060, 51060, 457, 309, 534, 5946, 322, 264, 1412, 293, 264, 5633, 291, 528, 281, 5039, 13, 51232, 51232, 407, 11, 1338, 13, 51257, 51292, 865, 11, 264, 3107, 307, 11239, 365, 428, 1867, 13, 51392, 51572, 286, 519, 321, 5872, 484, 295, 1651, 11, 5969, 456, 366, 544, 1348, 452, 636, 13, 51796, 51860], "temperature": 0.0, "avg_logprob": -0.29132430336692117, "compression_ratio": 1.7802690582959642, "no_speech_prob": 2.422523539280519e-05}, {"id": 1030, "seek": 699772, "start": 7016.280000000001, "end": 7018.280000000001, "text": " Yeah, the student is satisfied with your answer.", "tokens": [50364, 291, 458, 11, 6119, 3711, 9271, 13, 407, 11, 300, 311, 309, 13, 407, 11, 264, 1168, 307, 562, 309, 307, 7340, 281, 5039, 428, 50764, 50764, 5633, 13, 4803, 309, 307, 7340, 11, 2171, 309, 311, 406, 13, 407, 11, 309, 534, 5946, 322, 264, 11, 1338, 11, 309, 311, 6322, 11, 51060, 51060, 457, 309, 534, 5946, 322, 264, 1412, 293, 264, 5633, 291, 528, 281, 5039, 13, 51232, 51232, 407, 11, 1338, 13, 51257, 51292, 865, 11, 264, 3107, 307, 11239, 365, 428, 1867, 13, 51392, 51572, 286, 519, 321, 5872, 484, 295, 1651, 11, 5969, 456, 366, 544, 1348, 452, 636, 13, 51796, 51860], "temperature": 0.0, "avg_logprob": -0.29132430336692117, "compression_ratio": 1.7802690582959642, "no_speech_prob": 2.422523539280519e-05}, {"id": 1031, "seek": 699772, "start": 7021.88, "end": 7026.360000000001, "text": " I think we ran out of questions, unless there are more coming my way.", "tokens": [50364, 291, 458, 11, 6119, 3711, 9271, 13, 407, 11, 300, 311, 309, 13, 407, 11, 264, 1168, 307, 562, 309, 307, 7340, 281, 5039, 428, 50764, 50764, 5633, 13, 4803, 309, 307, 7340, 11, 2171, 309, 311, 406, 13, 407, 11, 309, 534, 5946, 322, 264, 11, 1338, 11, 309, 311, 6322, 11, 51060, 51060, 457, 309, 534, 5946, 322, 264, 1412, 293, 264, 5633, 291, 528, 281, 5039, 13, 51232, 51232, 407, 11, 1338, 13, 51257, 51292, 865, 11, 264, 3107, 307, 11239, 365, 428, 1867, 13, 51392, 51572, 286, 519, 321, 5872, 484, 295, 1651, 11, 5969, 456, 366, 544, 1348, 452, 636, 13, 51796, 51860], "temperature": 0.0, "avg_logprob": -0.29132430336692117, "compression_ratio": 1.7802690582959642, "no_speech_prob": 2.422523539280519e-05}, {"id": 1032, "seek": 702636, "start": 7026.36, "end": 7029.88, "text": " No, it starts getting bright outside there.", "tokens": [50364, 883, 11, 309, 3719, 1242, 4730, 2380, 456, 13, 50540, 50540, 7587, 13, 286, 390, 21814, 13, 440, 3295, 307, 11636, 13, 50640, 50740, 663, 311, 1481, 13, 1033, 13, 286, 519, 300, 390, 309, 13, 1044, 291, 370, 11, 370, 709, 13, 467, 390, 411, 11, 286, 914, 11, 534, 11, 51176, 51176, 729, 645, 370, 1238, 13, 1981, 9788, 645, 370, 1238, 13, 286, 632, 281, 1466, 370, 709, 490, 264, 636, 291, 2924, 13, 51536, 51636], "temperature": 0.0, "avg_logprob": -0.37057080680941357, "compression_ratio": 1.547486033519553, "no_speech_prob": 0.0002765665703918785}, {"id": 1033, "seek": 702636, "start": 7029.88, "end": 7031.88, "text": " Exactly. I was noticing. The sun is rising.", "tokens": [50364, 883, 11, 309, 3719, 1242, 4730, 2380, 456, 13, 50540, 50540, 7587, 13, 286, 390, 21814, 13, 440, 3295, 307, 11636, 13, 50640, 50740, 663, 311, 1481, 13, 1033, 13, 286, 519, 300, 390, 309, 13, 1044, 291, 370, 11, 370, 709, 13, 467, 390, 411, 11, 286, 914, 11, 534, 11, 51176, 51176, 729, 645, 370, 1238, 13, 1981, 9788, 645, 370, 1238, 13, 286, 632, 281, 1466, 370, 709, 490, 264, 636, 291, 2924, 13, 51536, 51636], "temperature": 0.0, "avg_logprob": -0.37057080680941357, "compression_ratio": 1.547486033519553, "no_speech_prob": 0.0002765665703918785}, {"id": 1034, "seek": 702636, "start": 7033.88, "end": 7042.599999999999, "text": " That's nice. Okay. I think that was it. Thank you so, so much. It was like, I mean, really,", "tokens": [50364, 883, 11, 309, 3719, 1242, 4730, 2380, 456, 13, 50540, 50540, 7587, 13, 286, 390, 21814, 13, 440, 3295, 307, 11636, 13, 50640, 50740, 663, 311, 1481, 13, 1033, 13, 286, 519, 300, 390, 309, 13, 1044, 291, 370, 11, 370, 709, 13, 467, 390, 411, 11, 286, 914, 11, 534, 11, 51176, 51176, 729, 645, 370, 1238, 13, 1981, 9788, 645, 370, 1238, 13, 286, 632, 281, 1466, 370, 709, 490, 264, 636, 291, 2924, 13, 51536, 51636], "temperature": 0.0, "avg_logprob": -0.37057080680941357, "compression_ratio": 1.547486033519553, "no_speech_prob": 0.0002765665703918785}, {"id": 1035, "seek": 702636, "start": 7042.599999999999, "end": 7049.799999999999, "text": " those were so pretty. These slides were so pretty. I had to learn so much from the way you teach.", "tokens": [50364, 883, 11, 309, 3719, 1242, 4730, 2380, 456, 13, 50540, 50540, 7587, 13, 286, 390, 21814, 13, 440, 3295, 307, 11636, 13, 50640, 50740, 663, 311, 1481, 13, 1033, 13, 286, 519, 300, 390, 309, 13, 1044, 291, 370, 11, 370, 709, 13, 467, 390, 411, 11, 286, 914, 11, 534, 11, 51176, 51176, 729, 645, 370, 1238, 13, 1981, 9788, 645, 370, 1238, 13, 286, 632, 281, 1466, 370, 709, 490, 264, 636, 291, 2924, 13, 51536, 51636], "temperature": 0.0, "avg_logprob": -0.37057080680941357, "compression_ratio": 1.547486033519553, "no_speech_prob": 0.0002765665703918785}, {"id": 1036, "seek": 704980, "start": 7049.8, "end": 7057.08, "text": " Yeah. Thank you again for waking us early. I mean, I think this is a fascinating topic.", "tokens": [50364, 865, 13, 1044, 291, 797, 337, 20447, 505, 2440, 13, 286, 914, 11, 286, 519, 341, 307, 257, 10343, 4829, 13, 50728, 50728, 1018, 291, 458, 11, 286, 600, 668, 3288, 294, 341, 412, 264, 2863, 11, 293, 286, 519, 309, 9870, 257, 2584, 777, 51024, 51024, 2853, 281, 5821, 295, 3479, 2539, 293, 18161, 36170, 13, 467, 311, 257, 777, 1002, 13, 467, 311, 257, 2584, 51276, 51276, 819, 1002, 13, 286, 458, 428, 14476, 19161, 632, 668, 1364, 322, 4295, 2309, 11, 457, 286, 478, 406, 988, 51620, 51620], "temperature": 0.0, "avg_logprob": -0.2971446129583543, "compression_ratio": 1.5982532751091703, "no_speech_prob": 3.168270632158965e-05}, {"id": 1037, "seek": 704980, "start": 7057.08, "end": 7063.0, "text": " As you know, I've been involved in this at the beginning, and I think it opens a completely new", "tokens": [50364, 865, 13, 1044, 291, 797, 337, 20447, 505, 2440, 13, 286, 914, 11, 286, 519, 341, 307, 257, 10343, 4829, 13, 50728, 50728, 1018, 291, 458, 11, 286, 600, 668, 3288, 294, 341, 412, 264, 2863, 11, 293, 286, 519, 309, 9870, 257, 2584, 777, 51024, 51024, 2853, 281, 5821, 295, 3479, 2539, 293, 18161, 36170, 13, 467, 311, 257, 777, 1002, 13, 467, 311, 257, 2584, 51276, 51276, 819, 1002, 13, 286, 458, 428, 14476, 19161, 632, 668, 1364, 322, 4295, 2309, 11, 457, 286, 478, 406, 988, 51620, 51620], "temperature": 0.0, "avg_logprob": -0.2971446129583543, "compression_ratio": 1.5982532751091703, "no_speech_prob": 3.168270632158965e-05}, {"id": 1038, "seek": 704980, "start": 7063.0, "end": 7068.04, "text": " door to applications of machine learning and neural nets. It's a new world. It's a completely", "tokens": [50364, 865, 13, 1044, 291, 797, 337, 20447, 505, 2440, 13, 286, 914, 11, 286, 519, 341, 307, 257, 10343, 4829, 13, 50728, 50728, 1018, 291, 458, 11, 286, 600, 668, 3288, 294, 341, 412, 264, 2863, 11, 293, 286, 519, 309, 9870, 257, 2584, 777, 51024, 51024, 2853, 281, 5821, 295, 3479, 2539, 293, 18161, 36170, 13, 467, 311, 257, 777, 1002, 13, 467, 311, 257, 2584, 51276, 51276, 819, 1002, 13, 286, 458, 428, 14476, 19161, 632, 668, 1364, 322, 4295, 2309, 11, 457, 286, 478, 406, 988, 51620, 51620], "temperature": 0.0, "avg_logprob": -0.2971446129583543, "compression_ratio": 1.5982532751091703, "no_speech_prob": 3.168270632158965e-05}, {"id": 1039, "seek": 704980, "start": 7068.04, "end": 7074.92, "text": " different world. I know your PhD advisor had been working on graph six, but I'm not sure", "tokens": [50364, 865, 13, 1044, 291, 797, 337, 20447, 505, 2440, 13, 286, 914, 11, 286, 519, 341, 307, 257, 10343, 4829, 13, 50728, 50728, 1018, 291, 458, 11, 286, 600, 668, 3288, 294, 341, 412, 264, 2863, 11, 293, 286, 519, 309, 9870, 257, 2584, 777, 51024, 51024, 2853, 281, 5821, 295, 3479, 2539, 293, 18161, 36170, 13, 467, 311, 257, 777, 1002, 13, 467, 311, 257, 2584, 51276, 51276, 819, 1002, 13, 286, 458, 428, 14476, 19161, 632, 668, 1364, 322, 4295, 2309, 11, 457, 286, 478, 406, 988, 51620, 51620], "temperature": 0.0, "avg_logprob": -0.2971446129583543, "compression_ratio": 1.5982532751091703, "no_speech_prob": 3.168270632158965e-05}, {"id": 1040, "seek": 707492, "start": 7074.92, "end": 7080.36, "text": " if that's the right word. I know your PhD advisor had been working on graph signal processing for", "tokens": [50364, 498, 300, 311, 264, 558, 1349, 13, 286, 458, 428, 14476, 19161, 632, 668, 1364, 322, 4295, 6358, 9007, 337, 50636, 50636, 257, 938, 565, 13, 407, 341, 390, 733, 295, 257, 3303, 6034, 337, 796, 293, 337, 291, 11, 286, 2041, 13, 583, 50848, 51008, 286, 519, 321, 2378, 380, 1612, 264, 917, 295, 341, 13, 492, 434, 516, 281, 312, 6100, 538, 437, 311, 516, 281, 808, 484, 51284, 51284, 295, 341, 13, 286, 914, 11, 456, 311, 534, 1217, 1333, 295, 10343, 589, 294, 300, 1859, 11, 294, 1090, 2281, 51540, 51540], "temperature": 0.0, "avg_logprob": -0.18812374232970563, "compression_ratio": 1.5732217573221758, "no_speech_prob": 3.4790675272233784e-05}, {"id": 1041, "seek": 707492, "start": 7080.36, "end": 7084.6, "text": " a long time. So this was kind of a natural transition for him and for you, I guess. But", "tokens": [50364, 498, 300, 311, 264, 558, 1349, 13, 286, 458, 428, 14476, 19161, 632, 668, 1364, 322, 4295, 6358, 9007, 337, 50636, 50636, 257, 938, 565, 13, 407, 341, 390, 733, 295, 257, 3303, 6034, 337, 796, 293, 337, 291, 11, 286, 2041, 13, 583, 50848, 51008, 286, 519, 321, 2378, 380, 1612, 264, 917, 295, 341, 13, 492, 434, 516, 281, 312, 6100, 538, 437, 311, 516, 281, 808, 484, 51284, 51284, 295, 341, 13, 286, 914, 11, 456, 311, 534, 1217, 1333, 295, 10343, 589, 294, 300, 1859, 11, 294, 1090, 2281, 51540, 51540], "temperature": 0.0, "avg_logprob": -0.18812374232970563, "compression_ratio": 1.5732217573221758, "no_speech_prob": 3.4790675272233784e-05}, {"id": 1042, "seek": 707492, "start": 7087.8, "end": 7093.32, "text": " I think we haven't seen the end of this. We're going to be surprised by what's going to come out", "tokens": [50364, 498, 300, 311, 264, 558, 1349, 13, 286, 458, 428, 14476, 19161, 632, 668, 1364, 322, 4295, 6358, 9007, 337, 50636, 50636, 257, 938, 565, 13, 407, 341, 390, 733, 295, 257, 3303, 6034, 337, 796, 293, 337, 291, 11, 286, 2041, 13, 583, 50848, 51008, 286, 519, 321, 2378, 380, 1612, 264, 917, 295, 341, 13, 492, 434, 516, 281, 312, 6100, 538, 437, 311, 516, 281, 808, 484, 51284, 51284, 295, 341, 13, 286, 914, 11, 456, 311, 534, 1217, 1333, 295, 10343, 589, 294, 300, 1859, 11, 294, 1090, 2281, 51540, 51540], "temperature": 0.0, "avg_logprob": -0.18812374232970563, "compression_ratio": 1.5732217573221758, "no_speech_prob": 3.4790675272233784e-05}, {"id": 1043, "seek": 707492, "start": 7093.32, "end": 7098.4400000000005, "text": " of this. I mean, there's really already sort of fascinating work in that area, in high energy", "tokens": [50364, 498, 300, 311, 264, 558, 1349, 13, 286, 458, 428, 14476, 19161, 632, 668, 1364, 322, 4295, 6358, 9007, 337, 50636, 50636, 257, 938, 565, 13, 407, 341, 390, 733, 295, 257, 3303, 6034, 337, 796, 293, 337, 291, 11, 286, 2041, 13, 583, 50848, 51008, 286, 519, 321, 2378, 380, 1612, 264, 917, 295, 341, 13, 492, 434, 516, 281, 312, 6100, 538, 437, 311, 516, 281, 808, 484, 51284, 51284, 295, 341, 13, 286, 914, 11, 456, 311, 534, 1217, 1333, 295, 10343, 589, 294, 300, 1859, 11, 294, 1090, 2281, 51540, 51540], "temperature": 0.0, "avg_logprob": -0.18812374232970563, "compression_ratio": 1.5732217573221758, "no_speech_prob": 3.4790675272233784e-05}, {"id": 1044, "seek": 709844, "start": 7098.44, "end": 7109.639999999999, "text": " physics, in computational chemistry, in social network applications. And you kind of cited all", "tokens": [50364, 10649, 11, 294, 28270, 12558, 11, 294, 2093, 3209, 5821, 13, 400, 291, 733, 295, 30134, 439, 50924, 50924, 264, 955, 5288, 294, 264, 11, 291, 458, 11, 498, 291, 434, 3102, 294, 341, 4829, 11, 498, 291, 434, 4764, 281, 341, 11, 51120, 51120, 33901, 6965, 4093, 25537, 307, 472, 295, 264, 955, 5288, 11, 294, 4500, 281, 44653, 11, 2745, 13, 400, 3139, 12674, 1603, 409, 515, 11, 51452, 51452, 7101, 291, 458, 11, 570, 415, 311, 257, 8304, 510, 11, 293, 415, 6686, 466, 309, 294, 341, 1164, 13, 5116, 51696, 51696], "temperature": 0.0, "avg_logprob": -0.18757161405897632, "compression_ratio": 1.6277056277056277, "no_speech_prob": 4.067353074788116e-05}, {"id": 1045, "seek": 709844, "start": 7109.639999999999, "end": 7113.5599999999995, "text": " the big names in the, you know, if you're interested in this topic, if you're listening to this,", "tokens": [50364, 10649, 11, 294, 28270, 12558, 11, 294, 2093, 3209, 5821, 13, 400, 291, 733, 295, 30134, 439, 50924, 50924, 264, 955, 5288, 294, 264, 11, 291, 458, 11, 498, 291, 434, 3102, 294, 341, 4829, 11, 498, 291, 434, 4764, 281, 341, 11, 51120, 51120, 33901, 6965, 4093, 25537, 307, 472, 295, 264, 955, 5288, 11, 294, 4500, 281, 44653, 11, 2745, 13, 400, 3139, 12674, 1603, 409, 515, 11, 51452, 51452, 7101, 291, 458, 11, 570, 415, 311, 257, 8304, 510, 11, 293, 415, 6686, 466, 309, 294, 341, 1164, 13, 5116, 51696, 51696], "temperature": 0.0, "avg_logprob": -0.18757161405897632, "compression_ratio": 1.6277056277056277, "no_speech_prob": 4.067353074788116e-05}, {"id": 1046, "seek": 709844, "start": 7113.5599999999995, "end": 7120.2, "text": " Yuri Leskovic is one of the big names, in addition to Xavier, obviously. And Joanne Brunard,", "tokens": [50364, 10649, 11, 294, 28270, 12558, 11, 294, 2093, 3209, 5821, 13, 400, 291, 733, 295, 30134, 439, 50924, 50924, 264, 955, 5288, 294, 264, 11, 291, 458, 11, 498, 291, 434, 3102, 294, 341, 4829, 11, 498, 291, 434, 4764, 281, 341, 11, 51120, 51120, 33901, 6965, 4093, 25537, 307, 472, 295, 264, 955, 5288, 11, 294, 4500, 281, 44653, 11, 2745, 13, 400, 3139, 12674, 1603, 409, 515, 11, 51452, 51452, 7101, 291, 458, 11, 570, 415, 311, 257, 8304, 510, 11, 293, 415, 6686, 466, 309, 294, 341, 1164, 13, 5116, 51696, 51696], "temperature": 0.0, "avg_logprob": -0.18757161405897632, "compression_ratio": 1.6277056277056277, "no_speech_prob": 4.067353074788116e-05}, {"id": 1047, "seek": 709844, "start": 7120.2, "end": 7125.08, "text": " whom you know, because he's a professor here, and he talks about it in this course. Michael", "tokens": [50364, 10649, 11, 294, 28270, 12558, 11, 294, 2093, 3209, 5821, 13, 400, 291, 733, 295, 30134, 439, 50924, 50924, 264, 955, 5288, 294, 264, 11, 291, 458, 11, 498, 291, 434, 3102, 294, 341, 4829, 11, 498, 291, 434, 4764, 281, 341, 11, 51120, 51120, 33901, 6965, 4093, 25537, 307, 472, 295, 264, 955, 5288, 11, 294, 4500, 281, 44653, 11, 2745, 13, 400, 3139, 12674, 1603, 409, 515, 11, 51452, 51452, 7101, 291, 458, 11, 570, 415, 311, 257, 8304, 510, 11, 293, 415, 6686, 466, 309, 294, 341, 1164, 13, 5116, 51696, 51696], "temperature": 0.0, "avg_logprob": -0.18757161405897632, "compression_ratio": 1.6277056277056277, "no_speech_prob": 4.067353074788116e-05}, {"id": 1048, "seek": 712508, "start": 7125.08, "end": 7131.48, "text": " Bronstein is also a big contributor. He's made some really interesting contributions to the", "tokens": [50364, 19544, 9089, 307, 611, 257, 955, 42859, 13, 634, 311, 1027, 512, 534, 1880, 15725, 281, 264, 50684, 50684, 4829, 11, 611, 322, 1333, 295, 4748, 819, 7150, 813, 264, 472, 300, 291, 2825, 466, 965, 11, 322, 411, 11, 50992, 50992, 291, 458, 11, 1228, 4295, 18161, 36170, 337, 411, 805, 35, 3813, 8076, 293, 337, 3820, 11837, 293, 721, 411, 51448, 51448, 300, 13, 407, 286, 3986, 13, 286, 519, 341, 307, 611, 257, 2519, 11, 291, 458, 11, 689, 456, 307, 257, 646, 293, 5220, 1296, 11, 51848, 51848], "temperature": 0.0, "avg_logprob": -0.16069307733089366, "compression_ratio": 1.6495726495726495, "no_speech_prob": 1.6696631064405665e-05}, {"id": 1049, "seek": 712508, "start": 7131.48, "end": 7137.64, "text": " topic, also on sort of slightly different methods than the one that you talked about today, on like,", "tokens": [50364, 19544, 9089, 307, 611, 257, 955, 42859, 13, 634, 311, 1027, 512, 534, 1880, 15725, 281, 264, 50684, 50684, 4829, 11, 611, 322, 1333, 295, 4748, 819, 7150, 813, 264, 472, 300, 291, 2825, 466, 965, 11, 322, 411, 11, 50992, 50992, 291, 458, 11, 1228, 4295, 18161, 36170, 337, 411, 805, 35, 3813, 8076, 293, 337, 3820, 11837, 293, 721, 411, 51448, 51448, 300, 13, 407, 286, 3986, 13, 286, 519, 341, 307, 611, 257, 2519, 11, 291, 458, 11, 689, 456, 307, 257, 646, 293, 5220, 1296, 11, 51848, 51848], "temperature": 0.0, "avg_logprob": -0.16069307733089366, "compression_ratio": 1.6495726495726495, "no_speech_prob": 1.6696631064405665e-05}, {"id": 1050, "seek": 712508, "start": 7137.64, "end": 7146.76, "text": " you know, using graph neural nets for like 3D meshes and for computer graphics and things like", "tokens": [50364, 19544, 9089, 307, 611, 257, 955, 42859, 13, 634, 311, 1027, 512, 534, 1880, 15725, 281, 264, 50684, 50684, 4829, 11, 611, 322, 1333, 295, 4748, 819, 7150, 813, 264, 472, 300, 291, 2825, 466, 965, 11, 322, 411, 11, 50992, 50992, 291, 458, 11, 1228, 4295, 18161, 36170, 337, 411, 805, 35, 3813, 8076, 293, 337, 3820, 11837, 293, 721, 411, 51448, 51448, 300, 13, 407, 286, 3986, 13, 286, 519, 341, 307, 611, 257, 2519, 11, 291, 458, 11, 689, 456, 307, 257, 646, 293, 5220, 1296, 11, 51848, 51848], "temperature": 0.0, "avg_logprob": -0.16069307733089366, "compression_ratio": 1.6495726495726495, "no_speech_prob": 1.6696631064405665e-05}, {"id": 1051, "seek": 712508, "start": 7146.76, "end": 7154.76, "text": " that. So I agree. I think this is also a field, you know, where there is a back and forth between,", "tokens": [50364, 19544, 9089, 307, 611, 257, 955, 42859, 13, 634, 311, 1027, 512, 534, 1880, 15725, 281, 264, 50684, 50684, 4829, 11, 611, 322, 1333, 295, 4748, 819, 7150, 813, 264, 472, 300, 291, 2825, 466, 965, 11, 322, 411, 11, 50992, 50992, 291, 458, 11, 1228, 4295, 18161, 36170, 337, 411, 805, 35, 3813, 8076, 293, 337, 3820, 11837, 293, 721, 411, 51448, 51448, 300, 13, 407, 286, 3986, 13, 286, 519, 341, 307, 611, 257, 2519, 11, 291, 458, 11, 689, 456, 307, 257, 646, 293, 5220, 1296, 11, 51848, 51848], "temperature": 0.0, "avg_logprob": -0.16069307733089366, "compression_ratio": 1.6495726495726495, "no_speech_prob": 1.6696631064405665e-05}, {"id": 1052, "seek": 715476, "start": 7154.76, "end": 7160.360000000001, "text": " you know, mathematics and also applications. So if you look at, for example, this protein stuff,", "tokens": [50364, 291, 458, 11, 18666, 293, 611, 5821, 13, 407, 498, 291, 574, 412, 11, 337, 1365, 11, 341, 7944, 1507, 11, 50644, 50644, 309, 311, 588, 11, 588, 1152, 13, 583, 412, 264, 912, 565, 11, 321, 393, 1466, 257, 688, 11, 291, 458, 11, 490, 264, 18894, 50896, 50896, 1252, 11, 321, 393, 11, 321, 393, 11, 293, 309, 311, 588, 4670, 11, 558, 30, 1436, 291, 528, 1293, 11, 498, 291, 528, 281, 312, 51144, 51144, 1075, 281, 652, 8134, 12114, 11, 291, 643, 281, 312, 11, 291, 458, 11, 9555, 538, 512, 957, 1002, 588, 1152, 51556, 51556, 1154, 13, 400, 550, 412, 264, 912, 565, 11, 291, 362, 613, 777, 3873, 11, 291, 458, 11, 1348, 493, 365, 4295, 5261, 11, 51788, 51824], "temperature": 0.0, "avg_logprob": -0.10201592408409414, "compression_ratio": 1.7859778597785978, "no_speech_prob": 3.819146513706073e-05}, {"id": 1053, "seek": 715476, "start": 7160.360000000001, "end": 7165.400000000001, "text": " it's very, very hard. But at the same time, we can learn a lot, you know, from the mathematical", "tokens": [50364, 291, 458, 11, 18666, 293, 611, 5821, 13, 407, 498, 291, 574, 412, 11, 337, 1365, 11, 341, 7944, 1507, 11, 50644, 50644, 309, 311, 588, 11, 588, 1152, 13, 583, 412, 264, 912, 565, 11, 321, 393, 1466, 257, 688, 11, 291, 458, 11, 490, 264, 18894, 50896, 50896, 1252, 11, 321, 393, 11, 321, 393, 11, 293, 309, 311, 588, 4670, 11, 558, 30, 1436, 291, 528, 1293, 11, 498, 291, 528, 281, 312, 51144, 51144, 1075, 281, 652, 8134, 12114, 11, 291, 643, 281, 312, 11, 291, 458, 11, 9555, 538, 512, 957, 1002, 588, 1152, 51556, 51556, 1154, 13, 400, 550, 412, 264, 912, 565, 11, 291, 362, 613, 777, 3873, 11, 291, 458, 11, 1348, 493, 365, 4295, 5261, 11, 51788, 51824], "temperature": 0.0, "avg_logprob": -0.10201592408409414, "compression_ratio": 1.7859778597785978, "no_speech_prob": 3.819146513706073e-05}, {"id": 1054, "seek": 715476, "start": 7165.400000000001, "end": 7170.360000000001, "text": " side, we can, we can, and it's very exciting, right? Because you want both, if you want to be", "tokens": [50364, 291, 458, 11, 18666, 293, 611, 5821, 13, 407, 498, 291, 574, 412, 11, 337, 1365, 11, 341, 7944, 1507, 11, 50644, 50644, 309, 311, 588, 11, 588, 1152, 13, 583, 412, 264, 912, 565, 11, 321, 393, 1466, 257, 688, 11, 291, 458, 11, 490, 264, 18894, 50896, 50896, 1252, 11, 321, 393, 11, 321, 393, 11, 293, 309, 311, 588, 4670, 11, 558, 30, 1436, 291, 528, 1293, 11, 498, 291, 528, 281, 312, 51144, 51144, 1075, 281, 652, 8134, 12114, 11, 291, 643, 281, 312, 11, 291, 458, 11, 9555, 538, 512, 957, 1002, 588, 1152, 51556, 51556, 1154, 13, 400, 550, 412, 264, 912, 565, 11, 291, 362, 613, 777, 3873, 11, 291, 458, 11, 1348, 493, 365, 4295, 5261, 11, 51788, 51824], "temperature": 0.0, "avg_logprob": -0.10201592408409414, "compression_ratio": 1.7859778597785978, "no_speech_prob": 3.819146513706073e-05}, {"id": 1055, "seek": 715476, "start": 7170.360000000001, "end": 7178.6, "text": " able to make scientific discovery, you need to be, you know, driven by some real world very hard", "tokens": [50364, 291, 458, 11, 18666, 293, 611, 5821, 13, 407, 498, 291, 574, 412, 11, 337, 1365, 11, 341, 7944, 1507, 11, 50644, 50644, 309, 311, 588, 11, 588, 1152, 13, 583, 412, 264, 912, 565, 11, 321, 393, 1466, 257, 688, 11, 291, 458, 11, 490, 264, 18894, 50896, 50896, 1252, 11, 321, 393, 11, 321, 393, 11, 293, 309, 311, 588, 4670, 11, 558, 30, 1436, 291, 528, 1293, 11, 498, 291, 528, 281, 312, 51144, 51144, 1075, 281, 652, 8134, 12114, 11, 291, 643, 281, 312, 11, 291, 458, 11, 9555, 538, 512, 957, 1002, 588, 1152, 51556, 51556, 1154, 13, 400, 550, 412, 264, 912, 565, 11, 291, 362, 613, 777, 3873, 11, 291, 458, 11, 1348, 493, 365, 4295, 5261, 11, 51788, 51824], "temperature": 0.0, "avg_logprob": -0.10201592408409414, "compression_ratio": 1.7859778597785978, "no_speech_prob": 3.819146513706073e-05}, {"id": 1056, "seek": 715476, "start": 7178.6, "end": 7183.24, "text": " problem. And then at the same time, you have these new tools, you know, coming up with graph theory,", "tokens": [50364, 291, 458, 11, 18666, 293, 611, 5821, 13, 407, 498, 291, 574, 412, 11, 337, 1365, 11, 341, 7944, 1507, 11, 50644, 50644, 309, 311, 588, 11, 588, 1152, 13, 583, 412, 264, 912, 565, 11, 321, 393, 1466, 257, 688, 11, 291, 458, 11, 490, 264, 18894, 50896, 50896, 1252, 11, 321, 393, 11, 321, 393, 11, 293, 309, 311, 588, 4670, 11, 558, 30, 1436, 291, 528, 1293, 11, 498, 291, 528, 281, 312, 51144, 51144, 1075, 281, 652, 8134, 12114, 11, 291, 643, 281, 312, 11, 291, 458, 11, 9555, 538, 512, 957, 1002, 588, 1152, 51556, 51556, 1154, 13, 400, 550, 412, 264, 912, 565, 11, 291, 362, 613, 777, 3873, 11, 291, 458, 11, 1348, 493, 365, 4295, 5261, 11, 51788, 51824], "temperature": 0.0, "avg_logprob": -0.10201592408409414, "compression_ratio": 1.7859778597785978, "no_speech_prob": 3.819146513706073e-05}, {"id": 1057, "seek": 718324, "start": 7183.24, "end": 7188.2, "text": " neural networks, and it's a way also for us to better understand, you know, why neural networks", "tokens": [50364, 18161, 9590, 11, 293, 309, 311, 257, 636, 611, 337, 505, 281, 1101, 1223, 11, 291, 458, 11, 983, 18161, 9590, 50612, 50612, 589, 370, 731, 13, 400, 341, 307, 11, 291, 458, 11, 257, 3513, 689, 309, 1542, 411, 11, 291, 458, 11, 1184, 786, 11, 436, 366, 50948, 50948, 411, 257, 777, 1154, 294, 341, 3513, 13, 407, 264, 1730, 307, 955, 11, 293, 337, 1518, 11, 337, 264, 2037, 1731, 51260, 51260, 281, 808, 293, 281, 2103, 11, 291, 458, 11, 341, 1859, 295, 2132, 13, 51480, 51600], "temperature": 0.0, "avg_logprob": -0.20211094681934644, "compression_ratio": 1.6926829268292682, "no_speech_prob": 9.274124749936163e-05}, {"id": 1058, "seek": 718324, "start": 7188.2, "end": 7194.92, "text": " work so well. And this is, you know, a direction where it looks like, you know, each day, they are", "tokens": [50364, 18161, 9590, 11, 293, 309, 311, 257, 636, 611, 337, 505, 281, 1101, 1223, 11, 291, 458, 11, 983, 18161, 9590, 50612, 50612, 589, 370, 731, 13, 400, 341, 307, 11, 291, 458, 11, 257, 3513, 689, 309, 1542, 411, 11, 291, 458, 11, 1184, 786, 11, 436, 366, 50948, 50948, 411, 257, 777, 1154, 294, 341, 3513, 13, 407, 264, 1730, 307, 955, 11, 293, 337, 1518, 11, 337, 264, 2037, 1731, 51260, 51260, 281, 808, 293, 281, 2103, 11, 291, 458, 11, 341, 1859, 295, 2132, 13, 51480, 51600], "temperature": 0.0, "avg_logprob": -0.20211094681934644, "compression_ratio": 1.6926829268292682, "no_speech_prob": 9.274124749936163e-05}, {"id": 1059, "seek": 718324, "start": 7194.92, "end": 7201.16, "text": " like a new problem in this direction. So the pie is big, and for everyone, for the young students", "tokens": [50364, 18161, 9590, 11, 293, 309, 311, 257, 636, 611, 337, 505, 281, 1101, 1223, 11, 291, 458, 11, 983, 18161, 9590, 50612, 50612, 589, 370, 731, 13, 400, 341, 307, 11, 291, 458, 11, 257, 3513, 689, 309, 1542, 411, 11, 291, 458, 11, 1184, 786, 11, 436, 366, 50948, 50948, 411, 257, 777, 1154, 294, 341, 3513, 13, 407, 264, 1730, 307, 955, 11, 293, 337, 1518, 11, 337, 264, 2037, 1731, 51260, 51260, 281, 808, 293, 281, 2103, 11, 291, 458, 11, 341, 1859, 295, 2132, 13, 51480, 51600], "temperature": 0.0, "avg_logprob": -0.20211094681934644, "compression_ratio": 1.6926829268292682, "no_speech_prob": 9.274124749936163e-05}, {"id": 1060, "seek": 718324, "start": 7201.16, "end": 7205.5599999999995, "text": " to come and to enjoy, you know, this area of research.", "tokens": [50364, 18161, 9590, 11, 293, 309, 311, 257, 636, 611, 337, 505, 281, 1101, 1223, 11, 291, 458, 11, 983, 18161, 9590, 50612, 50612, 589, 370, 731, 13, 400, 341, 307, 11, 291, 458, 11, 257, 3513, 689, 309, 1542, 411, 11, 291, 458, 11, 1184, 786, 11, 436, 366, 50948, 50948, 411, 257, 777, 1154, 294, 341, 3513, 13, 407, 264, 1730, 307, 955, 11, 293, 337, 1518, 11, 337, 264, 2037, 1731, 51260, 51260, 281, 808, 293, 281, 2103, 11, 291, 458, 11, 341, 1859, 295, 2132, 13, 51480, 51600], "temperature": 0.0, "avg_logprob": -0.20211094681934644, "compression_ratio": 1.6926829268292682, "no_speech_prob": 9.274124749936163e-05}, {"id": 1061, "seek": 720556, "start": 7205.56, "end": 7211.0, "text": " Great. Well, thank you again, and enjoy your day. Yeah, thanks again.", "tokens": [50364, 3769, 13, 1042, 11, 1309, 291, 797, 11, 293, 2103, 428, 786, 13, 865, 11, 3231, 797, 13, 50636, 50712, 1044, 291, 370, 709, 11, 1074, 13, 50760, 50800, 1057, 558, 13, 4621, 6543, 13, 50852, 50852, 4621, 13, 50892, 50892, 7855, 11, 536, 291, 4153, 13, 50952], "temperature": 0.0, "avg_logprob": -0.5087222671508789, "compression_ratio": 1.2543859649122806, "no_speech_prob": 6.697962089674547e-05}, {"id": 1062, "seek": 720556, "start": 7212.52, "end": 7213.4800000000005, "text": " Thank you so much, guys.", "tokens": [50364, 3769, 13, 1042, 11, 1309, 291, 797, 11, 293, 2103, 428, 786, 13, 865, 11, 3231, 797, 13, 50636, 50712, 1044, 291, 370, 709, 11, 1074, 13, 50760, 50800, 1057, 558, 13, 4621, 6543, 13, 50852, 50852, 4621, 13, 50892, 50892, 7855, 11, 536, 291, 4153, 13, 50952], "temperature": 0.0, "avg_logprob": -0.5087222671508789, "compression_ratio": 1.2543859649122806, "no_speech_prob": 6.697962089674547e-05}, {"id": 1063, "seek": 720556, "start": 7214.280000000001, "end": 7215.320000000001, "text": " All right. Bye bye.", "tokens": [50364, 3769, 13, 1042, 11, 1309, 291, 797, 11, 293, 2103, 428, 786, 13, 865, 11, 3231, 797, 13, 50636, 50712, 1044, 291, 370, 709, 11, 1074, 13, 50760, 50800, 1057, 558, 13, 4621, 6543, 13, 50852, 50852, 4621, 13, 50892, 50892, 7855, 11, 536, 291, 4153, 13, 50952], "temperature": 0.0, "avg_logprob": -0.5087222671508789, "compression_ratio": 1.2543859649122806, "no_speech_prob": 6.697962089674547e-05}, {"id": 1064, "seek": 720556, "start": 7215.320000000001, "end": 7216.120000000001, "text": " Bye.", "tokens": [50364, 3769, 13, 1042, 11, 1309, 291, 797, 11, 293, 2103, 428, 786, 13, 865, 11, 3231, 797, 13, 50636, 50712, 1044, 291, 370, 709, 11, 1074, 13, 50760, 50800, 1057, 558, 13, 4621, 6543, 13, 50852, 50852, 4621, 13, 50892, 50892, 7855, 11, 536, 291, 4153, 13, 50952], "temperature": 0.0, "avg_logprob": -0.5087222671508789, "compression_ratio": 1.2543859649122806, "no_speech_prob": 6.697962089674547e-05}, {"id": 1065, "seek": 721612, "start": 7216.12, "end": 7235.96, "text": " Guys, see you tomorrow.", "tokens": [50364, 7855, 11, 536, 291, 4153, 13, 51356], "temperature": 0.0, "avg_logprob": -0.5430244339836968, "compression_ratio": 0.7419354838709677, "no_speech_prob": 0.00021872788784094155}], "language": "en", "video_id": "Iiv9R6BjxHM", "entity": "Yann LeCun"}}