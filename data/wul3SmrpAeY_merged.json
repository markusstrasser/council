{"video_id": "wul3SmrpAeY", "title": "3.1 Classification | Motivations  --[Machine Learning | Andrew Ng]", "description": "First Course:\nSupervised Machine Learning : Regression and Classification.\n\nIf you liked the content please subscribe and put a little blue thumb.\nTake heart!", "author": "Machine Learning", "keywords": [], "channel_url": "https://www.youtube.com/channel/UClG5HEAJJFOavT_UolqYROQ", "length": 588, "views": 296, "publish_date": "11/04/2022", "timestamp": 1661126400, "entity": "ML Specialization, Andrew Ng (2022)", "transcript": {"text": " Welcome to the third week of this course. By the end of this week, you have completed the first course of this specialization. So let's jump in. Last week, you learned about linear regression, which predicts a number. This week, you learned about classification, where your output variable y can take on only one of a small handful of possible values, instead of any number in an infinite range of numbers. It turns out that linear regression is not a good algorithm for classification problems. Let's take a look at why, and this will lead us into a different algorithm called logistic regression, which is one of the most popular and most widely used learning algorithms today. Here are some examples of classification problems. Recall the example of trying to figure out whether an email is spam. So the answer you want to output is going to be either a no or a yes. Another example would be figuring out if an online financial transaction is fraudulent. Fighting online financial fraud is something I once worked on, and it was strangely exhilarating because I knew there were forces out there trying to steal money, and my team's job was to stop them. So the problem is, given a financial transaction, can your learning algorithm figure out is this transaction fraudulent, such as was this credit card stolen? Another example we've touched on before was trying to classify a tumor as malignant versus not. In each of these problems, the variable that you want to predict can only be one of two possible values, no or yes. This type of classification problem, where there are only two possible outputs, is called binary classification, where the word binary refers to there being only two possible classes, or two possible categories. In these problems, I will use the terms class and category relatively interchangeably. They mean basically the same thing. By convention, we can refer to these two classes or categories in a few common ways. We often designate classes as no or yes, or sometimes equivalently, false or true, or very commonly using the numbers 0 or 1, following the common convention in computer science with 0 denoting false and 1 denoting true. I'm usually going to use the numbers 0 and 1 to represent the answer why, because that will fit in most easily with the types of learning algorithms we want to implement. But when we talk about it, we'll often say no or yes, or false or true, as well. One of the terminology is commonly used is to call the false or zero class the negative class and the true or the one class the positive class. For example, for spam classification, an email that is not spam may be referred to as a negative example because the output to the question of is it spam? The output is no or zero. In contrast, an email that is spam might be referred to as a positive training example because the answer to is it spam is yes or true or one. To be clear, negative and positive do not necessarily mean bad versus good or evil versus good. It's just that negative and positive examples are used to convey the concepts of absence or zero or false versus the presence or true or one of something you might be looking for, such as the absence or presence of the spam units or the spam property of an email or the absence of presence of fraudulent activity or absence of presence of malignancy in a tumor. Between non-spam and spam emails, which one you call false or zero and which one you call true or one is a little bit arbitrary. Often either choice could work. So a different engineer might actually swap it around and have the positive class be the presence of a good email or the positive class be the presence of a real financial transaction or a healthy patient. So how do you build a classification algorithm? Here's the example of a training set for classifying if a tumor is malignant. A class one positive class, yes class or benign class zero or negative class. I plotted both the tumor size on the horizontal axis as well as the label Y on the vertical axis. By the way, in week one, when we first talked about classification, this is how we previously visualized it on the number line, except that now we're calling the classes zero and one and plotting them on the vertical axis. Now one thing you could try on this training set is to apply the algorithm you already know linear regression and try to fit a straight line to the data. If you do that, maybe the straight line looks like this, right? And that's your f of X. Linear regression predicts not just the values zero and one, but all numbers between zero and one or even less than zero or greater than one. But here we want to predict categories. One thing you could try is to pick a threshold of say 0.5 so that if the model outputs a value below 0.5, then you predict Y equals zero or not malignant. And if the model outputs a number equal to or greater than 0.5, then predict Y equals one or malignant. Notice that this threshold value 0.5 intersects the best fit straight line at this point. So if you draw this vertical line here, everything to the left ends up with a prediction of Y equals zero and everything on the right ends up with a prediction of Y equals one. Now for this particular data set, it looks like linear regression could do something reasonable. But now let's see what happens if your data set has one more training example. This one way over here on the right. Let's also extend the horizontal axis. Notice that this training example shouldn't really change how you classify the data points. This vertical dividing line that we drew just now still makes sense as the cutoff where two minutes smaller than this should be classified as zero and two minutes greater than this should be classified as one. But once you've added this extra training example on the right, the best fit line for linear regression will shift over like this. And if you continue using the threshold of 0.5, you now notice that everything to the left of this point is predicted as zero, non-malignant, and everything to the right of this point is predicted to be one or malignant. This isn't what we want, because adding that example way to the right shouldn't change any of our conclusions about how to classify malignant versus benign tumors. But if you try to do this with linear regression, adding this one example, which feels like it shouldn't be changing anything, it ends up with us learning a much worse function for this classification problem. Clearly, when a tumor is large, we want the algorithm to classify it as malignant. So what we just saw was linear regression causes the best fit line when we added one more example to the right to shift over, and thus the dividing line also called the decision boundary to shift over to the right. You learn more about the decision boundary in the next video. You also learn about an algorithm called logistic regression, where the output value of the outcome will always be between 0 and 1, and the algorithm will avoid these problems that we're seeing on the slide. By the way, one thing confusing about the name logistic regression is that even though it has the word regression in it, it's actually used for classification. Don't be confused by the name, which was given for historical reasons. It's actually used to solve binary classification problems where the output label y is either 0 or 1. In the upcoming optional lab, you also get to take a look at what happens when you try to use linear regression for classification. Sometimes you get lucky and it may work, but often it will not work well, which is why I don't use linear regression myself for classification. In the optional lab, you see an interactive plot that attempts to classify between two categories, and you hopefully notice how this often doesn't work very well, which is okay, because that motivates the need for a different model to do classification tasks. So please check out this optional lab, and after that, we'll go on to the next video to look at logistic regression for classification.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 3.72, "text": " Welcome to the third week of this course.", "tokens": [50364, 4027, 281, 264, 2636, 1243, 295, 341, 1164, 13, 50550, 50550, 3146, 264, 917, 295, 341, 1243, 11, 291, 362, 7365, 264, 700, 1164, 295, 341, 2121, 2144, 13, 50784, 50784, 407, 718, 311, 3012, 294, 13, 50874, 50874, 5264, 1243, 11, 291, 3264, 466, 8213, 24590, 11, 597, 6069, 82, 257, 1230, 13, 51121, 51121, 639, 1243, 11, 291, 3264, 466, 21538, 11, 689, 428, 5598, 7006, 288, 393, 747, 322, 787, 51364, 51364, 472, 295, 257, 1359, 16458, 295, 1944, 4190, 11, 2602, 295, 604, 1230, 294, 364, 13785, 3613, 51629, 51629, 295, 3547, 13, 51718, 51718], "temperature": 0.0, "avg_logprob": -0.11738119030943012, "compression_ratio": 1.698744769874477, "no_speech_prob": 0.009407917968928814}, {"id": 1, "seek": 0, "start": 3.72, "end": 8.4, "text": " By the end of this week, you have completed the first course of this specialization.", "tokens": [50364, 4027, 281, 264, 2636, 1243, 295, 341, 1164, 13, 50550, 50550, 3146, 264, 917, 295, 341, 1243, 11, 291, 362, 7365, 264, 700, 1164, 295, 341, 2121, 2144, 13, 50784, 50784, 407, 718, 311, 3012, 294, 13, 50874, 50874, 5264, 1243, 11, 291, 3264, 466, 8213, 24590, 11, 597, 6069, 82, 257, 1230, 13, 51121, 51121, 639, 1243, 11, 291, 3264, 466, 21538, 11, 689, 428, 5598, 7006, 288, 393, 747, 322, 787, 51364, 51364, 472, 295, 257, 1359, 16458, 295, 1944, 4190, 11, 2602, 295, 604, 1230, 294, 364, 13785, 3613, 51629, 51629, 295, 3547, 13, 51718, 51718], "temperature": 0.0, "avg_logprob": -0.11738119030943012, "compression_ratio": 1.698744769874477, "no_speech_prob": 0.009407917968928814}, {"id": 2, "seek": 0, "start": 8.4, "end": 10.200000000000001, "text": " So let's jump in.", "tokens": [50364, 4027, 281, 264, 2636, 1243, 295, 341, 1164, 13, 50550, 50550, 3146, 264, 917, 295, 341, 1243, 11, 291, 362, 7365, 264, 700, 1164, 295, 341, 2121, 2144, 13, 50784, 50784, 407, 718, 311, 3012, 294, 13, 50874, 50874, 5264, 1243, 11, 291, 3264, 466, 8213, 24590, 11, 597, 6069, 82, 257, 1230, 13, 51121, 51121, 639, 1243, 11, 291, 3264, 466, 21538, 11, 689, 428, 5598, 7006, 288, 393, 747, 322, 787, 51364, 51364, 472, 295, 257, 1359, 16458, 295, 1944, 4190, 11, 2602, 295, 604, 1230, 294, 364, 13785, 3613, 51629, 51629, 295, 3547, 13, 51718, 51718], "temperature": 0.0, "avg_logprob": -0.11738119030943012, "compression_ratio": 1.698744769874477, "no_speech_prob": 0.009407917968928814}, {"id": 3, "seek": 0, "start": 10.200000000000001, "end": 15.14, "text": " Last week, you learned about linear regression, which predicts a number.", "tokens": [50364, 4027, 281, 264, 2636, 1243, 295, 341, 1164, 13, 50550, 50550, 3146, 264, 917, 295, 341, 1243, 11, 291, 362, 7365, 264, 700, 1164, 295, 341, 2121, 2144, 13, 50784, 50784, 407, 718, 311, 3012, 294, 13, 50874, 50874, 5264, 1243, 11, 291, 3264, 466, 8213, 24590, 11, 597, 6069, 82, 257, 1230, 13, 51121, 51121, 639, 1243, 11, 291, 3264, 466, 21538, 11, 689, 428, 5598, 7006, 288, 393, 747, 322, 787, 51364, 51364, 472, 295, 257, 1359, 16458, 295, 1944, 4190, 11, 2602, 295, 604, 1230, 294, 364, 13785, 3613, 51629, 51629, 295, 3547, 13, 51718, 51718], "temperature": 0.0, "avg_logprob": -0.11738119030943012, "compression_ratio": 1.698744769874477, "no_speech_prob": 0.009407917968928814}, {"id": 4, "seek": 0, "start": 15.14, "end": 20.0, "text": " This week, you learned about classification, where your output variable y can take on only", "tokens": [50364, 4027, 281, 264, 2636, 1243, 295, 341, 1164, 13, 50550, 50550, 3146, 264, 917, 295, 341, 1243, 11, 291, 362, 7365, 264, 700, 1164, 295, 341, 2121, 2144, 13, 50784, 50784, 407, 718, 311, 3012, 294, 13, 50874, 50874, 5264, 1243, 11, 291, 3264, 466, 8213, 24590, 11, 597, 6069, 82, 257, 1230, 13, 51121, 51121, 639, 1243, 11, 291, 3264, 466, 21538, 11, 689, 428, 5598, 7006, 288, 393, 747, 322, 787, 51364, 51364, 472, 295, 257, 1359, 16458, 295, 1944, 4190, 11, 2602, 295, 604, 1230, 294, 364, 13785, 3613, 51629, 51629, 295, 3547, 13, 51718, 51718], "temperature": 0.0, "avg_logprob": -0.11738119030943012, "compression_ratio": 1.698744769874477, "no_speech_prob": 0.009407917968928814}, {"id": 5, "seek": 0, "start": 20.0, "end": 25.3, "text": " one of a small handful of possible values, instead of any number in an infinite range", "tokens": [50364, 4027, 281, 264, 2636, 1243, 295, 341, 1164, 13, 50550, 50550, 3146, 264, 917, 295, 341, 1243, 11, 291, 362, 7365, 264, 700, 1164, 295, 341, 2121, 2144, 13, 50784, 50784, 407, 718, 311, 3012, 294, 13, 50874, 50874, 5264, 1243, 11, 291, 3264, 466, 8213, 24590, 11, 597, 6069, 82, 257, 1230, 13, 51121, 51121, 639, 1243, 11, 291, 3264, 466, 21538, 11, 689, 428, 5598, 7006, 288, 393, 747, 322, 787, 51364, 51364, 472, 295, 257, 1359, 16458, 295, 1944, 4190, 11, 2602, 295, 604, 1230, 294, 364, 13785, 3613, 51629, 51629, 295, 3547, 13, 51718, 51718], "temperature": 0.0, "avg_logprob": -0.11738119030943012, "compression_ratio": 1.698744769874477, "no_speech_prob": 0.009407917968928814}, {"id": 6, "seek": 0, "start": 25.3, "end": 27.080000000000002, "text": " of numbers.", "tokens": [50364, 4027, 281, 264, 2636, 1243, 295, 341, 1164, 13, 50550, 50550, 3146, 264, 917, 295, 341, 1243, 11, 291, 362, 7365, 264, 700, 1164, 295, 341, 2121, 2144, 13, 50784, 50784, 407, 718, 311, 3012, 294, 13, 50874, 50874, 5264, 1243, 11, 291, 3264, 466, 8213, 24590, 11, 597, 6069, 82, 257, 1230, 13, 51121, 51121, 639, 1243, 11, 291, 3264, 466, 21538, 11, 689, 428, 5598, 7006, 288, 393, 747, 322, 787, 51364, 51364, 472, 295, 257, 1359, 16458, 295, 1944, 4190, 11, 2602, 295, 604, 1230, 294, 364, 13785, 3613, 51629, 51629, 295, 3547, 13, 51718, 51718], "temperature": 0.0, "avg_logprob": -0.11738119030943012, "compression_ratio": 1.698744769874477, "no_speech_prob": 0.009407917968928814}, {"id": 7, "seek": 2708, "start": 27.08, "end": 32.96, "text": " It turns out that linear regression is not a good algorithm for classification problems.", "tokens": [50364, 467, 4523, 484, 300, 8213, 24590, 307, 406, 257, 665, 9284, 337, 21538, 2740, 13, 50658, 50658, 961, 311, 747, 257, 574, 412, 983, 11, 293, 341, 486, 1477, 505, 666, 257, 819, 9284, 1219, 3565, 3142, 50924, 50924, 24590, 11, 597, 307, 472, 295, 264, 881, 3743, 293, 881, 13371, 1143, 2539, 14642, 965, 13, 51194, 51194, 1692, 366, 512, 5110, 295, 21538, 2740, 13, 51378, 51378, 9647, 336, 264, 1365, 295, 1382, 281, 2573, 484, 1968, 364, 3796, 307, 24028, 13, 51642, 51642], "temperature": 0.0, "avg_logprob": -0.08990257087795214, "compression_ratio": 1.6824034334763949, "no_speech_prob": 5.6822668739187066e-06}, {"id": 8, "seek": 2708, "start": 32.96, "end": 38.28, "text": " Let's take a look at why, and this will lead us into a different algorithm called logistic", "tokens": [50364, 467, 4523, 484, 300, 8213, 24590, 307, 406, 257, 665, 9284, 337, 21538, 2740, 13, 50658, 50658, 961, 311, 747, 257, 574, 412, 983, 11, 293, 341, 486, 1477, 505, 666, 257, 819, 9284, 1219, 3565, 3142, 50924, 50924, 24590, 11, 597, 307, 472, 295, 264, 881, 3743, 293, 881, 13371, 1143, 2539, 14642, 965, 13, 51194, 51194, 1692, 366, 512, 5110, 295, 21538, 2740, 13, 51378, 51378, 9647, 336, 264, 1365, 295, 1382, 281, 2573, 484, 1968, 364, 3796, 307, 24028, 13, 51642, 51642], "temperature": 0.0, "avg_logprob": -0.08990257087795214, "compression_ratio": 1.6824034334763949, "no_speech_prob": 5.6822668739187066e-06}, {"id": 9, "seek": 2708, "start": 38.28, "end": 43.68, "text": " regression, which is one of the most popular and most widely used learning algorithms today.", "tokens": [50364, 467, 4523, 484, 300, 8213, 24590, 307, 406, 257, 665, 9284, 337, 21538, 2740, 13, 50658, 50658, 961, 311, 747, 257, 574, 412, 983, 11, 293, 341, 486, 1477, 505, 666, 257, 819, 9284, 1219, 3565, 3142, 50924, 50924, 24590, 11, 597, 307, 472, 295, 264, 881, 3743, 293, 881, 13371, 1143, 2539, 14642, 965, 13, 51194, 51194, 1692, 366, 512, 5110, 295, 21538, 2740, 13, 51378, 51378, 9647, 336, 264, 1365, 295, 1382, 281, 2573, 484, 1968, 364, 3796, 307, 24028, 13, 51642, 51642], "temperature": 0.0, "avg_logprob": -0.08990257087795214, "compression_ratio": 1.6824034334763949, "no_speech_prob": 5.6822668739187066e-06}, {"id": 10, "seek": 2708, "start": 43.68, "end": 47.36, "text": " Here are some examples of classification problems.", "tokens": [50364, 467, 4523, 484, 300, 8213, 24590, 307, 406, 257, 665, 9284, 337, 21538, 2740, 13, 50658, 50658, 961, 311, 747, 257, 574, 412, 983, 11, 293, 341, 486, 1477, 505, 666, 257, 819, 9284, 1219, 3565, 3142, 50924, 50924, 24590, 11, 597, 307, 472, 295, 264, 881, 3743, 293, 881, 13371, 1143, 2539, 14642, 965, 13, 51194, 51194, 1692, 366, 512, 5110, 295, 21538, 2740, 13, 51378, 51378, 9647, 336, 264, 1365, 295, 1382, 281, 2573, 484, 1968, 364, 3796, 307, 24028, 13, 51642, 51642], "temperature": 0.0, "avg_logprob": -0.08990257087795214, "compression_ratio": 1.6824034334763949, "no_speech_prob": 5.6822668739187066e-06}, {"id": 11, "seek": 2708, "start": 47.36, "end": 52.64, "text": " Recall the example of trying to figure out whether an email is spam.", "tokens": [50364, 467, 4523, 484, 300, 8213, 24590, 307, 406, 257, 665, 9284, 337, 21538, 2740, 13, 50658, 50658, 961, 311, 747, 257, 574, 412, 983, 11, 293, 341, 486, 1477, 505, 666, 257, 819, 9284, 1219, 3565, 3142, 50924, 50924, 24590, 11, 597, 307, 472, 295, 264, 881, 3743, 293, 881, 13371, 1143, 2539, 14642, 965, 13, 51194, 51194, 1692, 366, 512, 5110, 295, 21538, 2740, 13, 51378, 51378, 9647, 336, 264, 1365, 295, 1382, 281, 2573, 484, 1968, 364, 3796, 307, 24028, 13, 51642, 51642], "temperature": 0.0, "avg_logprob": -0.08990257087795214, "compression_ratio": 1.6824034334763949, "no_speech_prob": 5.6822668739187066e-06}, {"id": 12, "seek": 5264, "start": 52.64, "end": 58.26, "text": " So the answer you want to output is going to be either a no or a yes.", "tokens": [50364, 407, 264, 1867, 291, 528, 281, 5598, 307, 516, 281, 312, 2139, 257, 572, 420, 257, 2086, 13, 50645, 50645, 3996, 1365, 576, 312, 15213, 484, 498, 364, 2950, 4669, 14425, 307, 14560, 23405, 13, 50972, 50972, 25694, 2950, 4669, 14560, 307, 746, 286, 1564, 2732, 322, 11, 293, 309, 390, 39851, 31052, 2202, 990, 51262, 51262, 570, 286, 2586, 456, 645, 5874, 484, 456, 1382, 281, 11009, 1460, 11, 293, 452, 1469, 311, 1691, 390, 51514, 51514, 281, 1590, 552, 13, 51611, 51611], "temperature": 0.0, "avg_logprob": -0.08220892728761185, "compression_ratio": 1.640552995391705, "no_speech_prob": 1.1478357919258997e-05}, {"id": 13, "seek": 5264, "start": 58.26, "end": 64.8, "text": " Another example would be figuring out if an online financial transaction is fraudulent.", "tokens": [50364, 407, 264, 1867, 291, 528, 281, 5598, 307, 516, 281, 312, 2139, 257, 572, 420, 257, 2086, 13, 50645, 50645, 3996, 1365, 576, 312, 15213, 484, 498, 364, 2950, 4669, 14425, 307, 14560, 23405, 13, 50972, 50972, 25694, 2950, 4669, 14560, 307, 746, 286, 1564, 2732, 322, 11, 293, 309, 390, 39851, 31052, 2202, 990, 51262, 51262, 570, 286, 2586, 456, 645, 5874, 484, 456, 1382, 281, 11009, 1460, 11, 293, 452, 1469, 311, 1691, 390, 51514, 51514, 281, 1590, 552, 13, 51611, 51611], "temperature": 0.0, "avg_logprob": -0.08220892728761185, "compression_ratio": 1.640552995391705, "no_speech_prob": 1.1478357919258997e-05}, {"id": 14, "seek": 5264, "start": 64.8, "end": 70.6, "text": " Fighting online financial fraud is something I once worked on, and it was strangely exhilarating", "tokens": [50364, 407, 264, 1867, 291, 528, 281, 5598, 307, 516, 281, 312, 2139, 257, 572, 420, 257, 2086, 13, 50645, 50645, 3996, 1365, 576, 312, 15213, 484, 498, 364, 2950, 4669, 14425, 307, 14560, 23405, 13, 50972, 50972, 25694, 2950, 4669, 14560, 307, 746, 286, 1564, 2732, 322, 11, 293, 309, 390, 39851, 31052, 2202, 990, 51262, 51262, 570, 286, 2586, 456, 645, 5874, 484, 456, 1382, 281, 11009, 1460, 11, 293, 452, 1469, 311, 1691, 390, 51514, 51514, 281, 1590, 552, 13, 51611, 51611], "temperature": 0.0, "avg_logprob": -0.08220892728761185, "compression_ratio": 1.640552995391705, "no_speech_prob": 1.1478357919258997e-05}, {"id": 15, "seek": 5264, "start": 70.6, "end": 75.64, "text": " because I knew there were forces out there trying to steal money, and my team's job was", "tokens": [50364, 407, 264, 1867, 291, 528, 281, 5598, 307, 516, 281, 312, 2139, 257, 572, 420, 257, 2086, 13, 50645, 50645, 3996, 1365, 576, 312, 15213, 484, 498, 364, 2950, 4669, 14425, 307, 14560, 23405, 13, 50972, 50972, 25694, 2950, 4669, 14560, 307, 746, 286, 1564, 2732, 322, 11, 293, 309, 390, 39851, 31052, 2202, 990, 51262, 51262, 570, 286, 2586, 456, 645, 5874, 484, 456, 1382, 281, 11009, 1460, 11, 293, 452, 1469, 311, 1691, 390, 51514, 51514, 281, 1590, 552, 13, 51611, 51611], "temperature": 0.0, "avg_logprob": -0.08220892728761185, "compression_ratio": 1.640552995391705, "no_speech_prob": 1.1478357919258997e-05}, {"id": 16, "seek": 5264, "start": 75.64, "end": 77.58, "text": " to stop them.", "tokens": [50364, 407, 264, 1867, 291, 528, 281, 5598, 307, 516, 281, 312, 2139, 257, 572, 420, 257, 2086, 13, 50645, 50645, 3996, 1365, 576, 312, 15213, 484, 498, 364, 2950, 4669, 14425, 307, 14560, 23405, 13, 50972, 50972, 25694, 2950, 4669, 14560, 307, 746, 286, 1564, 2732, 322, 11, 293, 309, 390, 39851, 31052, 2202, 990, 51262, 51262, 570, 286, 2586, 456, 645, 5874, 484, 456, 1382, 281, 11009, 1460, 11, 293, 452, 1469, 311, 1691, 390, 51514, 51514, 281, 1590, 552, 13, 51611, 51611], "temperature": 0.0, "avg_logprob": -0.08220892728761185, "compression_ratio": 1.640552995391705, "no_speech_prob": 1.1478357919258997e-05}, {"id": 17, "seek": 7758, "start": 77.58, "end": 83.72, "text": " So the problem is, given a financial transaction, can your learning algorithm figure out is", "tokens": [50364, 407, 264, 1154, 307, 11, 2212, 257, 4669, 14425, 11, 393, 428, 2539, 9284, 2573, 484, 307, 50671, 50671, 341, 14425, 14560, 23405, 11, 1270, 382, 390, 341, 5397, 2920, 15900, 30, 50973, 50973, 3996, 1365, 321, 600, 9828, 322, 949, 390, 1382, 281, 33872, 257, 22512, 382, 2806, 36818, 5717, 51281, 51281, 406, 13, 51385, 51385, 682, 1184, 295, 613, 2740, 11, 264, 7006, 300, 291, 528, 281, 6069, 393, 787, 312, 472, 295, 732, 51667, 51667, 1944, 4190, 11, 572, 420, 2086, 13, 51834, 51834], "temperature": 0.0, "avg_logprob": -0.09282519308368811, "compression_ratio": 1.5635593220338984, "no_speech_prob": 1.1911024557775818e-06}, {"id": 18, "seek": 7758, "start": 83.72, "end": 89.75999999999999, "text": " this transaction fraudulent, such as was this credit card stolen?", "tokens": [50364, 407, 264, 1154, 307, 11, 2212, 257, 4669, 14425, 11, 393, 428, 2539, 9284, 2573, 484, 307, 50671, 50671, 341, 14425, 14560, 23405, 11, 1270, 382, 390, 341, 5397, 2920, 15900, 30, 50973, 50973, 3996, 1365, 321, 600, 9828, 322, 949, 390, 1382, 281, 33872, 257, 22512, 382, 2806, 36818, 5717, 51281, 51281, 406, 13, 51385, 51385, 682, 1184, 295, 613, 2740, 11, 264, 7006, 300, 291, 528, 281, 6069, 393, 787, 312, 472, 295, 732, 51667, 51667, 1944, 4190, 11, 572, 420, 2086, 13, 51834, 51834], "temperature": 0.0, "avg_logprob": -0.09282519308368811, "compression_ratio": 1.5635593220338984, "no_speech_prob": 1.1911024557775818e-06}, {"id": 19, "seek": 7758, "start": 89.75999999999999, "end": 95.92, "text": " Another example we've touched on before was trying to classify a tumor as malignant versus", "tokens": [50364, 407, 264, 1154, 307, 11, 2212, 257, 4669, 14425, 11, 393, 428, 2539, 9284, 2573, 484, 307, 50671, 50671, 341, 14425, 14560, 23405, 11, 1270, 382, 390, 341, 5397, 2920, 15900, 30, 50973, 50973, 3996, 1365, 321, 600, 9828, 322, 949, 390, 1382, 281, 33872, 257, 22512, 382, 2806, 36818, 5717, 51281, 51281, 406, 13, 51385, 51385, 682, 1184, 295, 613, 2740, 11, 264, 7006, 300, 291, 528, 281, 6069, 393, 787, 312, 472, 295, 732, 51667, 51667, 1944, 4190, 11, 572, 420, 2086, 13, 51834, 51834], "temperature": 0.0, "avg_logprob": -0.09282519308368811, "compression_ratio": 1.5635593220338984, "no_speech_prob": 1.1911024557775818e-06}, {"id": 20, "seek": 7758, "start": 95.92, "end": 98.0, "text": " not.", "tokens": [50364, 407, 264, 1154, 307, 11, 2212, 257, 4669, 14425, 11, 393, 428, 2539, 9284, 2573, 484, 307, 50671, 50671, 341, 14425, 14560, 23405, 11, 1270, 382, 390, 341, 5397, 2920, 15900, 30, 50973, 50973, 3996, 1365, 321, 600, 9828, 322, 949, 390, 1382, 281, 33872, 257, 22512, 382, 2806, 36818, 5717, 51281, 51281, 406, 13, 51385, 51385, 682, 1184, 295, 613, 2740, 11, 264, 7006, 300, 291, 528, 281, 6069, 393, 787, 312, 472, 295, 732, 51667, 51667, 1944, 4190, 11, 572, 420, 2086, 13, 51834, 51834], "temperature": 0.0, "avg_logprob": -0.09282519308368811, "compression_ratio": 1.5635593220338984, "no_speech_prob": 1.1911024557775818e-06}, {"id": 21, "seek": 7758, "start": 98.0, "end": 103.64, "text": " In each of these problems, the variable that you want to predict can only be one of two", "tokens": [50364, 407, 264, 1154, 307, 11, 2212, 257, 4669, 14425, 11, 393, 428, 2539, 9284, 2573, 484, 307, 50671, 50671, 341, 14425, 14560, 23405, 11, 1270, 382, 390, 341, 5397, 2920, 15900, 30, 50973, 50973, 3996, 1365, 321, 600, 9828, 322, 949, 390, 1382, 281, 33872, 257, 22512, 382, 2806, 36818, 5717, 51281, 51281, 406, 13, 51385, 51385, 682, 1184, 295, 613, 2740, 11, 264, 7006, 300, 291, 528, 281, 6069, 393, 787, 312, 472, 295, 732, 51667, 51667, 1944, 4190, 11, 572, 420, 2086, 13, 51834, 51834], "temperature": 0.0, "avg_logprob": -0.09282519308368811, "compression_ratio": 1.5635593220338984, "no_speech_prob": 1.1911024557775818e-06}, {"id": 22, "seek": 7758, "start": 103.64, "end": 106.98, "text": " possible values, no or yes.", "tokens": [50364, 407, 264, 1154, 307, 11, 2212, 257, 4669, 14425, 11, 393, 428, 2539, 9284, 2573, 484, 307, 50671, 50671, 341, 14425, 14560, 23405, 11, 1270, 382, 390, 341, 5397, 2920, 15900, 30, 50973, 50973, 3996, 1365, 321, 600, 9828, 322, 949, 390, 1382, 281, 33872, 257, 22512, 382, 2806, 36818, 5717, 51281, 51281, 406, 13, 51385, 51385, 682, 1184, 295, 613, 2740, 11, 264, 7006, 300, 291, 528, 281, 6069, 393, 787, 312, 472, 295, 732, 51667, 51667, 1944, 4190, 11, 572, 420, 2086, 13, 51834, 51834], "temperature": 0.0, "avg_logprob": -0.09282519308368811, "compression_ratio": 1.5635593220338984, "no_speech_prob": 1.1911024557775818e-06}, {"id": 23, "seek": 10698, "start": 106.98, "end": 111.60000000000001, "text": " This type of classification problem, where there are only two possible outputs, is called", "tokens": [50364, 639, 2010, 295, 21538, 1154, 11, 689, 456, 366, 787, 732, 1944, 23930, 11, 307, 1219, 50595, 50595, 17434, 21538, 11, 689, 264, 1349, 17434, 14942, 281, 456, 885, 787, 732, 1944, 5359, 11, 50929, 50929, 420, 732, 1944, 10479, 13, 51117, 51117, 682, 613, 2740, 11, 286, 486, 764, 264, 2115, 1508, 293, 7719, 7226, 30358, 1188, 13, 51525, 51525, 814, 914, 1936, 264, 912, 551, 13, 51639, 51639], "temperature": 0.0, "avg_logprob": -0.08413051896625096, "compression_ratio": 1.7765957446808511, "no_speech_prob": 6.7479618337529246e-06}, {"id": 24, "seek": 10698, "start": 111.60000000000001, "end": 118.28, "text": " binary classification, where the word binary refers to there being only two possible classes,", "tokens": [50364, 639, 2010, 295, 21538, 1154, 11, 689, 456, 366, 787, 732, 1944, 23930, 11, 307, 1219, 50595, 50595, 17434, 21538, 11, 689, 264, 1349, 17434, 14942, 281, 456, 885, 787, 732, 1944, 5359, 11, 50929, 50929, 420, 732, 1944, 10479, 13, 51117, 51117, 682, 613, 2740, 11, 286, 486, 764, 264, 2115, 1508, 293, 7719, 7226, 30358, 1188, 13, 51525, 51525, 814, 914, 1936, 264, 912, 551, 13, 51639, 51639], "temperature": 0.0, "avg_logprob": -0.08413051896625096, "compression_ratio": 1.7765957446808511, "no_speech_prob": 6.7479618337529246e-06}, {"id": 25, "seek": 10698, "start": 118.28, "end": 122.04, "text": " or two possible categories.", "tokens": [50364, 639, 2010, 295, 21538, 1154, 11, 689, 456, 366, 787, 732, 1944, 23930, 11, 307, 1219, 50595, 50595, 17434, 21538, 11, 689, 264, 1349, 17434, 14942, 281, 456, 885, 787, 732, 1944, 5359, 11, 50929, 50929, 420, 732, 1944, 10479, 13, 51117, 51117, 682, 613, 2740, 11, 286, 486, 764, 264, 2115, 1508, 293, 7719, 7226, 30358, 1188, 13, 51525, 51525, 814, 914, 1936, 264, 912, 551, 13, 51639, 51639], "temperature": 0.0, "avg_logprob": -0.08413051896625096, "compression_ratio": 1.7765957446808511, "no_speech_prob": 6.7479618337529246e-06}, {"id": 26, "seek": 10698, "start": 122.04, "end": 130.2, "text": " In these problems, I will use the terms class and category relatively interchangeably.", "tokens": [50364, 639, 2010, 295, 21538, 1154, 11, 689, 456, 366, 787, 732, 1944, 23930, 11, 307, 1219, 50595, 50595, 17434, 21538, 11, 689, 264, 1349, 17434, 14942, 281, 456, 885, 787, 732, 1944, 5359, 11, 50929, 50929, 420, 732, 1944, 10479, 13, 51117, 51117, 682, 613, 2740, 11, 286, 486, 764, 264, 2115, 1508, 293, 7719, 7226, 30358, 1188, 13, 51525, 51525, 814, 914, 1936, 264, 912, 551, 13, 51639, 51639], "temperature": 0.0, "avg_logprob": -0.08413051896625096, "compression_ratio": 1.7765957446808511, "no_speech_prob": 6.7479618337529246e-06}, {"id": 27, "seek": 10698, "start": 130.2, "end": 132.48000000000002, "text": " They mean basically the same thing.", "tokens": [50364, 639, 2010, 295, 21538, 1154, 11, 689, 456, 366, 787, 732, 1944, 23930, 11, 307, 1219, 50595, 50595, 17434, 21538, 11, 689, 264, 1349, 17434, 14942, 281, 456, 885, 787, 732, 1944, 5359, 11, 50929, 50929, 420, 732, 1944, 10479, 13, 51117, 51117, 682, 613, 2740, 11, 286, 486, 764, 264, 2115, 1508, 293, 7719, 7226, 30358, 1188, 13, 51525, 51525, 814, 914, 1936, 264, 912, 551, 13, 51639, 51639], "temperature": 0.0, "avg_logprob": -0.08413051896625096, "compression_ratio": 1.7765957446808511, "no_speech_prob": 6.7479618337529246e-06}, {"id": 28, "seek": 13248, "start": 132.48, "end": 138.89999999999998, "text": " By convention, we can refer to these two classes or categories in a few common ways.", "tokens": [50364, 3146, 10286, 11, 321, 393, 2864, 281, 613, 732, 5359, 420, 10479, 294, 257, 1326, 2689, 2098, 13, 50685, 50685, 492, 2049, 1715, 473, 5359, 382, 572, 420, 2086, 11, 420, 2171, 9052, 2276, 11, 7908, 420, 2074, 11, 420, 51094, 51094, 588, 12719, 1228, 264, 3547, 1958, 420, 502, 11, 3480, 264, 2689, 10286, 294, 3820, 3497, 51464, 51464, 365, 1958, 1441, 17001, 7908, 293, 502, 1441, 17001, 2074, 13, 51692, 51692], "temperature": 0.0, "avg_logprob": -0.09258405685424805, "compression_ratio": 1.605263157894737, "no_speech_prob": 2.6425607302371645e-06}, {"id": 29, "seek": 13248, "start": 138.89999999999998, "end": 147.07999999999998, "text": " We often designate classes as no or yes, or sometimes equivalently, false or true, or", "tokens": [50364, 3146, 10286, 11, 321, 393, 2864, 281, 613, 732, 5359, 420, 10479, 294, 257, 1326, 2689, 2098, 13, 50685, 50685, 492, 2049, 1715, 473, 5359, 382, 572, 420, 2086, 11, 420, 2171, 9052, 2276, 11, 7908, 420, 2074, 11, 420, 51094, 51094, 588, 12719, 1228, 264, 3547, 1958, 420, 502, 11, 3480, 264, 2689, 10286, 294, 3820, 3497, 51464, 51464, 365, 1958, 1441, 17001, 7908, 293, 502, 1441, 17001, 2074, 13, 51692, 51692], "temperature": 0.0, "avg_logprob": -0.09258405685424805, "compression_ratio": 1.605263157894737, "no_speech_prob": 2.6425607302371645e-06}, {"id": 30, "seek": 13248, "start": 147.07999999999998, "end": 154.48, "text": " very commonly using the numbers 0 or 1, following the common convention in computer science", "tokens": [50364, 3146, 10286, 11, 321, 393, 2864, 281, 613, 732, 5359, 420, 10479, 294, 257, 1326, 2689, 2098, 13, 50685, 50685, 492, 2049, 1715, 473, 5359, 382, 572, 420, 2086, 11, 420, 2171, 9052, 2276, 11, 7908, 420, 2074, 11, 420, 51094, 51094, 588, 12719, 1228, 264, 3547, 1958, 420, 502, 11, 3480, 264, 2689, 10286, 294, 3820, 3497, 51464, 51464, 365, 1958, 1441, 17001, 7908, 293, 502, 1441, 17001, 2074, 13, 51692, 51692], "temperature": 0.0, "avg_logprob": -0.09258405685424805, "compression_ratio": 1.605263157894737, "no_speech_prob": 2.6425607302371645e-06}, {"id": 31, "seek": 13248, "start": 154.48, "end": 159.04, "text": " with 0 denoting false and 1 denoting true.", "tokens": [50364, 3146, 10286, 11, 321, 393, 2864, 281, 613, 732, 5359, 420, 10479, 294, 257, 1326, 2689, 2098, 13, 50685, 50685, 492, 2049, 1715, 473, 5359, 382, 572, 420, 2086, 11, 420, 2171, 9052, 2276, 11, 7908, 420, 2074, 11, 420, 51094, 51094, 588, 12719, 1228, 264, 3547, 1958, 420, 502, 11, 3480, 264, 2689, 10286, 294, 3820, 3497, 51464, 51464, 365, 1958, 1441, 17001, 7908, 293, 502, 1441, 17001, 2074, 13, 51692, 51692], "temperature": 0.0, "avg_logprob": -0.09258405685424805, "compression_ratio": 1.605263157894737, "no_speech_prob": 2.6425607302371645e-06}, {"id": 32, "seek": 15904, "start": 159.04, "end": 165.2, "text": " I'm usually going to use the numbers 0 and 1 to represent the answer why, because that", "tokens": [50364, 286, 478, 2673, 516, 281, 764, 264, 3547, 1958, 293, 502, 281, 2906, 264, 1867, 983, 11, 570, 300, 50672, 50672, 486, 3318, 294, 881, 3612, 365, 264, 3467, 295, 2539, 14642, 321, 528, 281, 4445, 13, 50936, 50936, 583, 562, 321, 751, 466, 309, 11, 321, 603, 2049, 584, 572, 420, 2086, 11, 420, 7908, 420, 2074, 11, 382, 731, 13, 51292, 51292, 1485, 295, 264, 27575, 307, 12719, 1143, 307, 281, 818, 264, 7908, 420, 4018, 1508, 264, 3671, 51568, 51568], "temperature": 0.0, "avg_logprob": -0.13758587556726792, "compression_ratio": 1.5339366515837105, "no_speech_prob": 8.059349170252972e-07}, {"id": 33, "seek": 15904, "start": 165.2, "end": 170.48, "text": " will fit in most easily with the types of learning algorithms we want to implement.", "tokens": [50364, 286, 478, 2673, 516, 281, 764, 264, 3547, 1958, 293, 502, 281, 2906, 264, 1867, 983, 11, 570, 300, 50672, 50672, 486, 3318, 294, 881, 3612, 365, 264, 3467, 295, 2539, 14642, 321, 528, 281, 4445, 13, 50936, 50936, 583, 562, 321, 751, 466, 309, 11, 321, 603, 2049, 584, 572, 420, 2086, 11, 420, 7908, 420, 2074, 11, 382, 731, 13, 51292, 51292, 1485, 295, 264, 27575, 307, 12719, 1143, 307, 281, 818, 264, 7908, 420, 4018, 1508, 264, 3671, 51568, 51568], "temperature": 0.0, "avg_logprob": -0.13758587556726792, "compression_ratio": 1.5339366515837105, "no_speech_prob": 8.059349170252972e-07}, {"id": 34, "seek": 15904, "start": 170.48, "end": 177.6, "text": " But when we talk about it, we'll often say no or yes, or false or true, as well.", "tokens": [50364, 286, 478, 2673, 516, 281, 764, 264, 3547, 1958, 293, 502, 281, 2906, 264, 1867, 983, 11, 570, 300, 50672, 50672, 486, 3318, 294, 881, 3612, 365, 264, 3467, 295, 2539, 14642, 321, 528, 281, 4445, 13, 50936, 50936, 583, 562, 321, 751, 466, 309, 11, 321, 603, 2049, 584, 572, 420, 2086, 11, 420, 7908, 420, 2074, 11, 382, 731, 13, 51292, 51292, 1485, 295, 264, 27575, 307, 12719, 1143, 307, 281, 818, 264, 7908, 420, 4018, 1508, 264, 3671, 51568, 51568], "temperature": 0.0, "avg_logprob": -0.13758587556726792, "compression_ratio": 1.5339366515837105, "no_speech_prob": 8.059349170252972e-07}, {"id": 35, "seek": 15904, "start": 177.6, "end": 183.12, "text": " One of the terminology is commonly used is to call the false or zero class the negative", "tokens": [50364, 286, 478, 2673, 516, 281, 764, 264, 3547, 1958, 293, 502, 281, 2906, 264, 1867, 983, 11, 570, 300, 50672, 50672, 486, 3318, 294, 881, 3612, 365, 264, 3467, 295, 2539, 14642, 321, 528, 281, 4445, 13, 50936, 50936, 583, 562, 321, 751, 466, 309, 11, 321, 603, 2049, 584, 572, 420, 2086, 11, 420, 7908, 420, 2074, 11, 382, 731, 13, 51292, 51292, 1485, 295, 264, 27575, 307, 12719, 1143, 307, 281, 818, 264, 7908, 420, 4018, 1508, 264, 3671, 51568, 51568], "temperature": 0.0, "avg_logprob": -0.13758587556726792, "compression_ratio": 1.5339366515837105, "no_speech_prob": 8.059349170252972e-07}, {"id": 36, "seek": 18312, "start": 183.12, "end": 189.44, "text": " class and the true or the one class the positive class.", "tokens": [50364, 1508, 293, 264, 2074, 420, 264, 472, 1508, 264, 3353, 1508, 13, 50680, 50680, 1171, 1365, 11, 337, 24028, 21538, 11, 364, 3796, 300, 307, 406, 24028, 815, 312, 10839, 281, 382, 257, 3671, 51008, 51008, 1365, 570, 264, 5598, 281, 264, 1168, 295, 307, 309, 24028, 30, 51224, 51224, 440, 5598, 307, 572, 420, 4018, 13, 51394, 51394, 682, 8712, 11, 364, 3796, 300, 307, 24028, 1062, 312, 10839, 281, 382, 257, 3353, 3097, 1365, 51722, 51722], "temperature": 0.0, "avg_logprob": -0.11440850496292114, "compression_ratio": 1.8044692737430168, "no_speech_prob": 9.223306733474601e-06}, {"id": 37, "seek": 18312, "start": 189.44, "end": 196.0, "text": " For example, for spam classification, an email that is not spam may be referred to as a negative", "tokens": [50364, 1508, 293, 264, 2074, 420, 264, 472, 1508, 264, 3353, 1508, 13, 50680, 50680, 1171, 1365, 11, 337, 24028, 21538, 11, 364, 3796, 300, 307, 406, 24028, 815, 312, 10839, 281, 382, 257, 3671, 51008, 51008, 1365, 570, 264, 5598, 281, 264, 1168, 295, 307, 309, 24028, 30, 51224, 51224, 440, 5598, 307, 572, 420, 4018, 13, 51394, 51394, 682, 8712, 11, 364, 3796, 300, 307, 24028, 1062, 312, 10839, 281, 382, 257, 3353, 3097, 1365, 51722, 51722], "temperature": 0.0, "avg_logprob": -0.11440850496292114, "compression_ratio": 1.8044692737430168, "no_speech_prob": 9.223306733474601e-06}, {"id": 38, "seek": 18312, "start": 196.0, "end": 200.32, "text": " example because the output to the question of is it spam?", "tokens": [50364, 1508, 293, 264, 2074, 420, 264, 472, 1508, 264, 3353, 1508, 13, 50680, 50680, 1171, 1365, 11, 337, 24028, 21538, 11, 364, 3796, 300, 307, 406, 24028, 815, 312, 10839, 281, 382, 257, 3671, 51008, 51008, 1365, 570, 264, 5598, 281, 264, 1168, 295, 307, 309, 24028, 30, 51224, 51224, 440, 5598, 307, 572, 420, 4018, 13, 51394, 51394, 682, 8712, 11, 364, 3796, 300, 307, 24028, 1062, 312, 10839, 281, 382, 257, 3353, 3097, 1365, 51722, 51722], "temperature": 0.0, "avg_logprob": -0.11440850496292114, "compression_ratio": 1.8044692737430168, "no_speech_prob": 9.223306733474601e-06}, {"id": 39, "seek": 18312, "start": 200.32, "end": 203.72, "text": " The output is no or zero.", "tokens": [50364, 1508, 293, 264, 2074, 420, 264, 472, 1508, 264, 3353, 1508, 13, 50680, 50680, 1171, 1365, 11, 337, 24028, 21538, 11, 364, 3796, 300, 307, 406, 24028, 815, 312, 10839, 281, 382, 257, 3671, 51008, 51008, 1365, 570, 264, 5598, 281, 264, 1168, 295, 307, 309, 24028, 30, 51224, 51224, 440, 5598, 307, 572, 420, 4018, 13, 51394, 51394, 682, 8712, 11, 364, 3796, 300, 307, 24028, 1062, 312, 10839, 281, 382, 257, 3353, 3097, 1365, 51722, 51722], "temperature": 0.0, "avg_logprob": -0.11440850496292114, "compression_ratio": 1.8044692737430168, "no_speech_prob": 9.223306733474601e-06}, {"id": 40, "seek": 18312, "start": 203.72, "end": 210.28, "text": " In contrast, an email that is spam might be referred to as a positive training example", "tokens": [50364, 1508, 293, 264, 2074, 420, 264, 472, 1508, 264, 3353, 1508, 13, 50680, 50680, 1171, 1365, 11, 337, 24028, 21538, 11, 364, 3796, 300, 307, 406, 24028, 815, 312, 10839, 281, 382, 257, 3671, 51008, 51008, 1365, 570, 264, 5598, 281, 264, 1168, 295, 307, 309, 24028, 30, 51224, 51224, 440, 5598, 307, 572, 420, 4018, 13, 51394, 51394, 682, 8712, 11, 364, 3796, 300, 307, 24028, 1062, 312, 10839, 281, 382, 257, 3353, 3097, 1365, 51722, 51722], "temperature": 0.0, "avg_logprob": -0.11440850496292114, "compression_ratio": 1.8044692737430168, "no_speech_prob": 9.223306733474601e-06}, {"id": 41, "seek": 21028, "start": 210.28, "end": 216.72, "text": " because the answer to is it spam is yes or true or one.", "tokens": [50364, 570, 264, 1867, 281, 307, 309, 24028, 307, 2086, 420, 2074, 420, 472, 13, 50686, 50686, 1407, 312, 1850, 11, 3671, 293, 3353, 360, 406, 4725, 914, 1578, 5717, 665, 420, 6724, 5717, 50954, 50954, 665, 13, 51004, 51004, 467, 311, 445, 300, 3671, 293, 3353, 5110, 366, 1143, 281, 16965, 264, 10392, 295, 17145, 51248, 51248, 420, 4018, 420, 7908, 5717, 264, 6814, 420, 2074, 420, 472, 295, 746, 291, 1062, 312, 1237, 337, 11, 51554, 51554], "temperature": 0.0, "avg_logprob": -0.12606041431427, "compression_ratio": 1.6717171717171717, "no_speech_prob": 9.080255949811544e-06}, {"id": 42, "seek": 21028, "start": 216.72, "end": 222.08, "text": " To be clear, negative and positive do not necessarily mean bad versus good or evil versus", "tokens": [50364, 570, 264, 1867, 281, 307, 309, 24028, 307, 2086, 420, 2074, 420, 472, 13, 50686, 50686, 1407, 312, 1850, 11, 3671, 293, 3353, 360, 406, 4725, 914, 1578, 5717, 665, 420, 6724, 5717, 50954, 50954, 665, 13, 51004, 51004, 467, 311, 445, 300, 3671, 293, 3353, 5110, 366, 1143, 281, 16965, 264, 10392, 295, 17145, 51248, 51248, 420, 4018, 420, 7908, 5717, 264, 6814, 420, 2074, 420, 472, 295, 746, 291, 1062, 312, 1237, 337, 11, 51554, 51554], "temperature": 0.0, "avg_logprob": -0.12606041431427, "compression_ratio": 1.6717171717171717, "no_speech_prob": 9.080255949811544e-06}, {"id": 43, "seek": 21028, "start": 222.08, "end": 223.08, "text": " good.", "tokens": [50364, 570, 264, 1867, 281, 307, 309, 24028, 307, 2086, 420, 2074, 420, 472, 13, 50686, 50686, 1407, 312, 1850, 11, 3671, 293, 3353, 360, 406, 4725, 914, 1578, 5717, 665, 420, 6724, 5717, 50954, 50954, 665, 13, 51004, 51004, 467, 311, 445, 300, 3671, 293, 3353, 5110, 366, 1143, 281, 16965, 264, 10392, 295, 17145, 51248, 51248, 420, 4018, 420, 7908, 5717, 264, 6814, 420, 2074, 420, 472, 295, 746, 291, 1062, 312, 1237, 337, 11, 51554, 51554], "temperature": 0.0, "avg_logprob": -0.12606041431427, "compression_ratio": 1.6717171717171717, "no_speech_prob": 9.080255949811544e-06}, {"id": 44, "seek": 21028, "start": 223.08, "end": 227.96, "text": " It's just that negative and positive examples are used to convey the concepts of absence", "tokens": [50364, 570, 264, 1867, 281, 307, 309, 24028, 307, 2086, 420, 2074, 420, 472, 13, 50686, 50686, 1407, 312, 1850, 11, 3671, 293, 3353, 360, 406, 4725, 914, 1578, 5717, 665, 420, 6724, 5717, 50954, 50954, 665, 13, 51004, 51004, 467, 311, 445, 300, 3671, 293, 3353, 5110, 366, 1143, 281, 16965, 264, 10392, 295, 17145, 51248, 51248, 420, 4018, 420, 7908, 5717, 264, 6814, 420, 2074, 420, 472, 295, 746, 291, 1062, 312, 1237, 337, 11, 51554, 51554], "temperature": 0.0, "avg_logprob": -0.12606041431427, "compression_ratio": 1.6717171717171717, "no_speech_prob": 9.080255949811544e-06}, {"id": 45, "seek": 21028, "start": 227.96, "end": 234.08, "text": " or zero or false versus the presence or true or one of something you might be looking for,", "tokens": [50364, 570, 264, 1867, 281, 307, 309, 24028, 307, 2086, 420, 2074, 420, 472, 13, 50686, 50686, 1407, 312, 1850, 11, 3671, 293, 3353, 360, 406, 4725, 914, 1578, 5717, 665, 420, 6724, 5717, 50954, 50954, 665, 13, 51004, 51004, 467, 311, 445, 300, 3671, 293, 3353, 5110, 366, 1143, 281, 16965, 264, 10392, 295, 17145, 51248, 51248, 420, 4018, 420, 7908, 5717, 264, 6814, 420, 2074, 420, 472, 295, 746, 291, 1062, 312, 1237, 337, 11, 51554, 51554], "temperature": 0.0, "avg_logprob": -0.12606041431427, "compression_ratio": 1.6717171717171717, "no_speech_prob": 9.080255949811544e-06}, {"id": 46, "seek": 23408, "start": 234.08, "end": 240.8, "text": " such as the absence or presence of the spam units or the spam property of an email or", "tokens": [50364, 1270, 382, 264, 17145, 420, 6814, 295, 264, 24028, 6815, 420, 264, 24028, 4707, 295, 364, 3796, 420, 50700, 50700, 264, 17145, 295, 6814, 295, 14560, 23405, 5191, 420, 17145, 295, 6814, 295, 2806, 788, 6717, 294, 257, 51028, 51028, 22512, 13, 51078, 51078, 18967, 2107, 12, 4952, 335, 293, 24028, 12524, 11, 597, 472, 291, 818, 7908, 420, 4018, 293, 597, 472, 291, 818, 51374, 51374, 2074, 420, 472, 307, 257, 707, 857, 23211, 13, 51562, 51562, 20043, 2139, 3922, 727, 589, 13, 51686, 51686], "temperature": 0.0, "avg_logprob": -0.14478766918182373, "compression_ratio": 1.78125, "no_speech_prob": 5.771797532361234e-06}, {"id": 47, "seek": 23408, "start": 240.8, "end": 247.36, "text": " the absence of presence of fraudulent activity or absence of presence of malignancy in a", "tokens": [50364, 1270, 382, 264, 17145, 420, 6814, 295, 264, 24028, 6815, 420, 264, 24028, 4707, 295, 364, 3796, 420, 50700, 50700, 264, 17145, 295, 6814, 295, 14560, 23405, 5191, 420, 17145, 295, 6814, 295, 2806, 788, 6717, 294, 257, 51028, 51028, 22512, 13, 51078, 51078, 18967, 2107, 12, 4952, 335, 293, 24028, 12524, 11, 597, 472, 291, 818, 7908, 420, 4018, 293, 597, 472, 291, 818, 51374, 51374, 2074, 420, 472, 307, 257, 707, 857, 23211, 13, 51562, 51562, 20043, 2139, 3922, 727, 589, 13, 51686, 51686], "temperature": 0.0, "avg_logprob": -0.14478766918182373, "compression_ratio": 1.78125, "no_speech_prob": 5.771797532361234e-06}, {"id": 48, "seek": 23408, "start": 247.36, "end": 248.36, "text": " tumor.", "tokens": [50364, 1270, 382, 264, 17145, 420, 6814, 295, 264, 24028, 6815, 420, 264, 24028, 4707, 295, 364, 3796, 420, 50700, 50700, 264, 17145, 295, 6814, 295, 14560, 23405, 5191, 420, 17145, 295, 6814, 295, 2806, 788, 6717, 294, 257, 51028, 51028, 22512, 13, 51078, 51078, 18967, 2107, 12, 4952, 335, 293, 24028, 12524, 11, 597, 472, 291, 818, 7908, 420, 4018, 293, 597, 472, 291, 818, 51374, 51374, 2074, 420, 472, 307, 257, 707, 857, 23211, 13, 51562, 51562, 20043, 2139, 3922, 727, 589, 13, 51686, 51686], "temperature": 0.0, "avg_logprob": -0.14478766918182373, "compression_ratio": 1.78125, "no_speech_prob": 5.771797532361234e-06}, {"id": 49, "seek": 23408, "start": 248.36, "end": 254.28, "text": " Between non-spam and spam emails, which one you call false or zero and which one you call", "tokens": [50364, 1270, 382, 264, 17145, 420, 6814, 295, 264, 24028, 6815, 420, 264, 24028, 4707, 295, 364, 3796, 420, 50700, 50700, 264, 17145, 295, 6814, 295, 14560, 23405, 5191, 420, 17145, 295, 6814, 295, 2806, 788, 6717, 294, 257, 51028, 51028, 22512, 13, 51078, 51078, 18967, 2107, 12, 4952, 335, 293, 24028, 12524, 11, 597, 472, 291, 818, 7908, 420, 4018, 293, 597, 472, 291, 818, 51374, 51374, 2074, 420, 472, 307, 257, 707, 857, 23211, 13, 51562, 51562, 20043, 2139, 3922, 727, 589, 13, 51686, 51686], "temperature": 0.0, "avg_logprob": -0.14478766918182373, "compression_ratio": 1.78125, "no_speech_prob": 5.771797532361234e-06}, {"id": 50, "seek": 23408, "start": 254.28, "end": 258.04, "text": " true or one is a little bit arbitrary.", "tokens": [50364, 1270, 382, 264, 17145, 420, 6814, 295, 264, 24028, 6815, 420, 264, 24028, 4707, 295, 364, 3796, 420, 50700, 50700, 264, 17145, 295, 6814, 295, 14560, 23405, 5191, 420, 17145, 295, 6814, 295, 2806, 788, 6717, 294, 257, 51028, 51028, 22512, 13, 51078, 51078, 18967, 2107, 12, 4952, 335, 293, 24028, 12524, 11, 597, 472, 291, 818, 7908, 420, 4018, 293, 597, 472, 291, 818, 51374, 51374, 2074, 420, 472, 307, 257, 707, 857, 23211, 13, 51562, 51562, 20043, 2139, 3922, 727, 589, 13, 51686, 51686], "temperature": 0.0, "avg_logprob": -0.14478766918182373, "compression_ratio": 1.78125, "no_speech_prob": 5.771797532361234e-06}, {"id": 51, "seek": 23408, "start": 258.04, "end": 260.52000000000004, "text": " Often either choice could work.", "tokens": [50364, 1270, 382, 264, 17145, 420, 6814, 295, 264, 24028, 6815, 420, 264, 24028, 4707, 295, 364, 3796, 420, 50700, 50700, 264, 17145, 295, 6814, 295, 14560, 23405, 5191, 420, 17145, 295, 6814, 295, 2806, 788, 6717, 294, 257, 51028, 51028, 22512, 13, 51078, 51078, 18967, 2107, 12, 4952, 335, 293, 24028, 12524, 11, 597, 472, 291, 818, 7908, 420, 4018, 293, 597, 472, 291, 818, 51374, 51374, 2074, 420, 472, 307, 257, 707, 857, 23211, 13, 51562, 51562, 20043, 2139, 3922, 727, 589, 13, 51686, 51686], "temperature": 0.0, "avg_logprob": -0.14478766918182373, "compression_ratio": 1.78125, "no_speech_prob": 5.771797532361234e-06}, {"id": 52, "seek": 26052, "start": 260.52, "end": 264.91999999999996, "text": " So a different engineer might actually swap it around and have the positive class be the", "tokens": [50364, 407, 257, 819, 11403, 1062, 767, 18135, 309, 926, 293, 362, 264, 3353, 1508, 312, 264, 50584, 50584, 6814, 295, 257, 665, 3796, 420, 264, 3353, 1508, 312, 264, 6814, 295, 257, 957, 4669, 14425, 50920, 50920, 420, 257, 4627, 4537, 13, 51070, 51070, 407, 577, 360, 291, 1322, 257, 21538, 9284, 30, 51280, 51280, 1692, 311, 264, 1365, 295, 257, 3097, 992, 337, 1508, 5489, 498, 257, 22512, 307, 2806, 36818, 13, 51534, 51534], "temperature": 0.0, "avg_logprob": -0.12065470063841188, "compression_ratio": 1.6974358974358974, "no_speech_prob": 7.22440177014505e-07}, {"id": 53, "seek": 26052, "start": 264.91999999999996, "end": 271.64, "text": " presence of a good email or the positive class be the presence of a real financial transaction", "tokens": [50364, 407, 257, 819, 11403, 1062, 767, 18135, 309, 926, 293, 362, 264, 3353, 1508, 312, 264, 50584, 50584, 6814, 295, 257, 665, 3796, 420, 264, 3353, 1508, 312, 264, 6814, 295, 257, 957, 4669, 14425, 50920, 50920, 420, 257, 4627, 4537, 13, 51070, 51070, 407, 577, 360, 291, 1322, 257, 21538, 9284, 30, 51280, 51280, 1692, 311, 264, 1365, 295, 257, 3097, 992, 337, 1508, 5489, 498, 257, 22512, 307, 2806, 36818, 13, 51534, 51534], "temperature": 0.0, "avg_logprob": -0.12065470063841188, "compression_ratio": 1.6974358974358974, "no_speech_prob": 7.22440177014505e-07}, {"id": 54, "seek": 26052, "start": 271.64, "end": 274.64, "text": " or a healthy patient.", "tokens": [50364, 407, 257, 819, 11403, 1062, 767, 18135, 309, 926, 293, 362, 264, 3353, 1508, 312, 264, 50584, 50584, 6814, 295, 257, 665, 3796, 420, 264, 3353, 1508, 312, 264, 6814, 295, 257, 957, 4669, 14425, 50920, 50920, 420, 257, 4627, 4537, 13, 51070, 51070, 407, 577, 360, 291, 1322, 257, 21538, 9284, 30, 51280, 51280, 1692, 311, 264, 1365, 295, 257, 3097, 992, 337, 1508, 5489, 498, 257, 22512, 307, 2806, 36818, 13, 51534, 51534], "temperature": 0.0, "avg_logprob": -0.12065470063841188, "compression_ratio": 1.6974358974358974, "no_speech_prob": 7.22440177014505e-07}, {"id": 55, "seek": 26052, "start": 274.64, "end": 278.84, "text": " So how do you build a classification algorithm?", "tokens": [50364, 407, 257, 819, 11403, 1062, 767, 18135, 309, 926, 293, 362, 264, 3353, 1508, 312, 264, 50584, 50584, 6814, 295, 257, 665, 3796, 420, 264, 3353, 1508, 312, 264, 6814, 295, 257, 957, 4669, 14425, 50920, 50920, 420, 257, 4627, 4537, 13, 51070, 51070, 407, 577, 360, 291, 1322, 257, 21538, 9284, 30, 51280, 51280, 1692, 311, 264, 1365, 295, 257, 3097, 992, 337, 1508, 5489, 498, 257, 22512, 307, 2806, 36818, 13, 51534, 51534], "temperature": 0.0, "avg_logprob": -0.12065470063841188, "compression_ratio": 1.6974358974358974, "no_speech_prob": 7.22440177014505e-07}, {"id": 56, "seek": 26052, "start": 278.84, "end": 283.91999999999996, "text": " Here's the example of a training set for classifying if a tumor is malignant.", "tokens": [50364, 407, 257, 819, 11403, 1062, 767, 18135, 309, 926, 293, 362, 264, 3353, 1508, 312, 264, 50584, 50584, 6814, 295, 257, 665, 3796, 420, 264, 3353, 1508, 312, 264, 6814, 295, 257, 957, 4669, 14425, 50920, 50920, 420, 257, 4627, 4537, 13, 51070, 51070, 407, 577, 360, 291, 1322, 257, 21538, 9284, 30, 51280, 51280, 1692, 311, 264, 1365, 295, 257, 3097, 992, 337, 1508, 5489, 498, 257, 22512, 307, 2806, 36818, 13, 51534, 51534], "temperature": 0.0, "avg_logprob": -0.12065470063841188, "compression_ratio": 1.6974358974358974, "no_speech_prob": 7.22440177014505e-07}, {"id": 57, "seek": 28392, "start": 283.92, "end": 291.64000000000004, "text": " A class one positive class, yes class or benign class zero or negative class.", "tokens": [50364, 316, 1508, 472, 3353, 1508, 11, 2086, 1508, 420, 3271, 788, 1508, 4018, 420, 3671, 1508, 13, 50750, 50750, 286, 43288, 1293, 264, 22512, 2744, 322, 264, 12750, 10298, 382, 731, 382, 264, 7645, 398, 322, 264, 9429, 51066, 51066, 10298, 13, 51148, 51148, 3146, 264, 636, 11, 294, 1243, 472, 11, 562, 321, 700, 2825, 466, 21538, 11, 341, 307, 577, 321, 8046, 51416, 51416, 5056, 1602, 309, 322, 264, 1230, 1622, 11, 3993, 300, 586, 321, 434, 5141, 264, 5359, 4018, 293, 472, 51708, 51708], "temperature": 0.0, "avg_logprob": -0.13019425681467806, "compression_ratio": 1.6422018348623852, "no_speech_prob": 2.0261293229850708e-06}, {"id": 58, "seek": 28392, "start": 291.64000000000004, "end": 297.96000000000004, "text": " I plotted both the tumor size on the horizontal axis as well as the label Y on the vertical", "tokens": [50364, 316, 1508, 472, 3353, 1508, 11, 2086, 1508, 420, 3271, 788, 1508, 4018, 420, 3671, 1508, 13, 50750, 50750, 286, 43288, 1293, 264, 22512, 2744, 322, 264, 12750, 10298, 382, 731, 382, 264, 7645, 398, 322, 264, 9429, 51066, 51066, 10298, 13, 51148, 51148, 3146, 264, 636, 11, 294, 1243, 472, 11, 562, 321, 700, 2825, 466, 21538, 11, 341, 307, 577, 321, 8046, 51416, 51416, 5056, 1602, 309, 322, 264, 1230, 1622, 11, 3993, 300, 586, 321, 434, 5141, 264, 5359, 4018, 293, 472, 51708, 51708], "temperature": 0.0, "avg_logprob": -0.13019425681467806, "compression_ratio": 1.6422018348623852, "no_speech_prob": 2.0261293229850708e-06}, {"id": 59, "seek": 28392, "start": 297.96000000000004, "end": 299.6, "text": " axis.", "tokens": [50364, 316, 1508, 472, 3353, 1508, 11, 2086, 1508, 420, 3271, 788, 1508, 4018, 420, 3671, 1508, 13, 50750, 50750, 286, 43288, 1293, 264, 22512, 2744, 322, 264, 12750, 10298, 382, 731, 382, 264, 7645, 398, 322, 264, 9429, 51066, 51066, 10298, 13, 51148, 51148, 3146, 264, 636, 11, 294, 1243, 472, 11, 562, 321, 700, 2825, 466, 21538, 11, 341, 307, 577, 321, 8046, 51416, 51416, 5056, 1602, 309, 322, 264, 1230, 1622, 11, 3993, 300, 586, 321, 434, 5141, 264, 5359, 4018, 293, 472, 51708, 51708], "temperature": 0.0, "avg_logprob": -0.13019425681467806, "compression_ratio": 1.6422018348623852, "no_speech_prob": 2.0261293229850708e-06}, {"id": 60, "seek": 28392, "start": 299.6, "end": 304.96000000000004, "text": " By the way, in week one, when we first talked about classification, this is how we previously", "tokens": [50364, 316, 1508, 472, 3353, 1508, 11, 2086, 1508, 420, 3271, 788, 1508, 4018, 420, 3671, 1508, 13, 50750, 50750, 286, 43288, 1293, 264, 22512, 2744, 322, 264, 12750, 10298, 382, 731, 382, 264, 7645, 398, 322, 264, 9429, 51066, 51066, 10298, 13, 51148, 51148, 3146, 264, 636, 11, 294, 1243, 472, 11, 562, 321, 700, 2825, 466, 21538, 11, 341, 307, 577, 321, 8046, 51416, 51416, 5056, 1602, 309, 322, 264, 1230, 1622, 11, 3993, 300, 586, 321, 434, 5141, 264, 5359, 4018, 293, 472, 51708, 51708], "temperature": 0.0, "avg_logprob": -0.13019425681467806, "compression_ratio": 1.6422018348623852, "no_speech_prob": 2.0261293229850708e-06}, {"id": 61, "seek": 28392, "start": 304.96000000000004, "end": 310.8, "text": " visualized it on the number line, except that now we're calling the classes zero and one", "tokens": [50364, 316, 1508, 472, 3353, 1508, 11, 2086, 1508, 420, 3271, 788, 1508, 4018, 420, 3671, 1508, 13, 50750, 50750, 286, 43288, 1293, 264, 22512, 2744, 322, 264, 12750, 10298, 382, 731, 382, 264, 7645, 398, 322, 264, 9429, 51066, 51066, 10298, 13, 51148, 51148, 3146, 264, 636, 11, 294, 1243, 472, 11, 562, 321, 700, 2825, 466, 21538, 11, 341, 307, 577, 321, 8046, 51416, 51416, 5056, 1602, 309, 322, 264, 1230, 1622, 11, 3993, 300, 586, 321, 434, 5141, 264, 5359, 4018, 293, 472, 51708, 51708], "temperature": 0.0, "avg_logprob": -0.13019425681467806, "compression_ratio": 1.6422018348623852, "no_speech_prob": 2.0261293229850708e-06}, {"id": 62, "seek": 31080, "start": 310.8, "end": 314.8, "text": " and plotting them on the vertical axis.", "tokens": [50364, 293, 41178, 552, 322, 264, 9429, 10298, 13, 50564, 50564, 823, 472, 551, 291, 727, 853, 322, 341, 3097, 992, 307, 281, 3079, 264, 9284, 291, 1217, 50824, 50824, 458, 8213, 24590, 293, 853, 281, 3318, 257, 2997, 1622, 281, 264, 1412, 13, 51090, 51090, 759, 291, 360, 300, 11, 1310, 264, 2997, 1622, 1542, 411, 341, 11, 558, 30, 51282, 51282, 400, 300, 311, 428, 283, 295, 1783, 13, 51425, 51425, 14670, 289, 24590, 6069, 82, 406, 445, 264, 4190, 4018, 293, 472, 11, 457, 439, 3547, 1296, 4018, 51708, 51708], "temperature": 0.0, "avg_logprob": -0.11474296894479305, "compression_ratio": 1.65625, "no_speech_prob": 1.553482093186176e-06}, {"id": 63, "seek": 31080, "start": 314.8, "end": 320.0, "text": " Now one thing you could try on this training set is to apply the algorithm you already", "tokens": [50364, 293, 41178, 552, 322, 264, 9429, 10298, 13, 50564, 50564, 823, 472, 551, 291, 727, 853, 322, 341, 3097, 992, 307, 281, 3079, 264, 9284, 291, 1217, 50824, 50824, 458, 8213, 24590, 293, 853, 281, 3318, 257, 2997, 1622, 281, 264, 1412, 13, 51090, 51090, 759, 291, 360, 300, 11, 1310, 264, 2997, 1622, 1542, 411, 341, 11, 558, 30, 51282, 51282, 400, 300, 311, 428, 283, 295, 1783, 13, 51425, 51425, 14670, 289, 24590, 6069, 82, 406, 445, 264, 4190, 4018, 293, 472, 11, 457, 439, 3547, 1296, 4018, 51708, 51708], "temperature": 0.0, "avg_logprob": -0.11474296894479305, "compression_ratio": 1.65625, "no_speech_prob": 1.553482093186176e-06}, {"id": 64, "seek": 31080, "start": 320.0, "end": 325.32, "text": " know linear regression and try to fit a straight line to the data.", "tokens": [50364, 293, 41178, 552, 322, 264, 9429, 10298, 13, 50564, 50564, 823, 472, 551, 291, 727, 853, 322, 341, 3097, 992, 307, 281, 3079, 264, 9284, 291, 1217, 50824, 50824, 458, 8213, 24590, 293, 853, 281, 3318, 257, 2997, 1622, 281, 264, 1412, 13, 51090, 51090, 759, 291, 360, 300, 11, 1310, 264, 2997, 1622, 1542, 411, 341, 11, 558, 30, 51282, 51282, 400, 300, 311, 428, 283, 295, 1783, 13, 51425, 51425, 14670, 289, 24590, 6069, 82, 406, 445, 264, 4190, 4018, 293, 472, 11, 457, 439, 3547, 1296, 4018, 51708, 51708], "temperature": 0.0, "avg_logprob": -0.11474296894479305, "compression_ratio": 1.65625, "no_speech_prob": 1.553482093186176e-06}, {"id": 65, "seek": 31080, "start": 325.32, "end": 329.16, "text": " If you do that, maybe the straight line looks like this, right?", "tokens": [50364, 293, 41178, 552, 322, 264, 9429, 10298, 13, 50564, 50564, 823, 472, 551, 291, 727, 853, 322, 341, 3097, 992, 307, 281, 3079, 264, 9284, 291, 1217, 50824, 50824, 458, 8213, 24590, 293, 853, 281, 3318, 257, 2997, 1622, 281, 264, 1412, 13, 51090, 51090, 759, 291, 360, 300, 11, 1310, 264, 2997, 1622, 1542, 411, 341, 11, 558, 30, 51282, 51282, 400, 300, 311, 428, 283, 295, 1783, 13, 51425, 51425, 14670, 289, 24590, 6069, 82, 406, 445, 264, 4190, 4018, 293, 472, 11, 457, 439, 3547, 1296, 4018, 51708, 51708], "temperature": 0.0, "avg_logprob": -0.11474296894479305, "compression_ratio": 1.65625, "no_speech_prob": 1.553482093186176e-06}, {"id": 66, "seek": 31080, "start": 329.16, "end": 332.02, "text": " And that's your f of X.", "tokens": [50364, 293, 41178, 552, 322, 264, 9429, 10298, 13, 50564, 50564, 823, 472, 551, 291, 727, 853, 322, 341, 3097, 992, 307, 281, 3079, 264, 9284, 291, 1217, 50824, 50824, 458, 8213, 24590, 293, 853, 281, 3318, 257, 2997, 1622, 281, 264, 1412, 13, 51090, 51090, 759, 291, 360, 300, 11, 1310, 264, 2997, 1622, 1542, 411, 341, 11, 558, 30, 51282, 51282, 400, 300, 311, 428, 283, 295, 1783, 13, 51425, 51425, 14670, 289, 24590, 6069, 82, 406, 445, 264, 4190, 4018, 293, 472, 11, 457, 439, 3547, 1296, 4018, 51708, 51708], "temperature": 0.0, "avg_logprob": -0.11474296894479305, "compression_ratio": 1.65625, "no_speech_prob": 1.553482093186176e-06}, {"id": 67, "seek": 31080, "start": 332.02, "end": 337.68, "text": " Linear regression predicts not just the values zero and one, but all numbers between zero", "tokens": [50364, 293, 41178, 552, 322, 264, 9429, 10298, 13, 50564, 50564, 823, 472, 551, 291, 727, 853, 322, 341, 3097, 992, 307, 281, 3079, 264, 9284, 291, 1217, 50824, 50824, 458, 8213, 24590, 293, 853, 281, 3318, 257, 2997, 1622, 281, 264, 1412, 13, 51090, 51090, 759, 291, 360, 300, 11, 1310, 264, 2997, 1622, 1542, 411, 341, 11, 558, 30, 51282, 51282, 400, 300, 311, 428, 283, 295, 1783, 13, 51425, 51425, 14670, 289, 24590, 6069, 82, 406, 445, 264, 4190, 4018, 293, 472, 11, 457, 439, 3547, 1296, 4018, 51708, 51708], "temperature": 0.0, "avg_logprob": -0.11474296894479305, "compression_ratio": 1.65625, "no_speech_prob": 1.553482093186176e-06}, {"id": 68, "seek": 33768, "start": 337.68, "end": 342.04, "text": " and one or even less than zero or greater than one.", "tokens": [50364, 293, 472, 420, 754, 1570, 813, 4018, 420, 5044, 813, 472, 13, 50582, 50582, 583, 510, 321, 528, 281, 6069, 10479, 13, 50802, 50802, 1485, 551, 291, 727, 853, 307, 281, 1888, 257, 14678, 295, 584, 1958, 13, 20, 370, 300, 498, 264, 2316, 23930, 257, 51186, 51186, 2158, 2507, 1958, 13, 20, 11, 550, 291, 6069, 398, 6915, 4018, 420, 406, 2806, 36818, 13, 51542, 51542], "temperature": 0.0, "avg_logprob": -0.10171926885411359, "compression_ratio": 1.430232558139535, "no_speech_prob": 3.1875297281658277e-06}, {"id": 69, "seek": 33768, "start": 342.04, "end": 346.44, "text": " But here we want to predict categories.", "tokens": [50364, 293, 472, 420, 754, 1570, 813, 4018, 420, 5044, 813, 472, 13, 50582, 50582, 583, 510, 321, 528, 281, 6069, 10479, 13, 50802, 50802, 1485, 551, 291, 727, 853, 307, 281, 1888, 257, 14678, 295, 584, 1958, 13, 20, 370, 300, 498, 264, 2316, 23930, 257, 51186, 51186, 2158, 2507, 1958, 13, 20, 11, 550, 291, 6069, 398, 6915, 4018, 420, 406, 2806, 36818, 13, 51542, 51542], "temperature": 0.0, "avg_logprob": -0.10171926885411359, "compression_ratio": 1.430232558139535, "no_speech_prob": 3.1875297281658277e-06}, {"id": 70, "seek": 33768, "start": 346.44, "end": 354.12, "text": " One thing you could try is to pick a threshold of say 0.5 so that if the model outputs a", "tokens": [50364, 293, 472, 420, 754, 1570, 813, 4018, 420, 5044, 813, 472, 13, 50582, 50582, 583, 510, 321, 528, 281, 6069, 10479, 13, 50802, 50802, 1485, 551, 291, 727, 853, 307, 281, 1888, 257, 14678, 295, 584, 1958, 13, 20, 370, 300, 498, 264, 2316, 23930, 257, 51186, 51186, 2158, 2507, 1958, 13, 20, 11, 550, 291, 6069, 398, 6915, 4018, 420, 406, 2806, 36818, 13, 51542, 51542], "temperature": 0.0, "avg_logprob": -0.10171926885411359, "compression_ratio": 1.430232558139535, "no_speech_prob": 3.1875297281658277e-06}, {"id": 71, "seek": 33768, "start": 354.12, "end": 361.24, "text": " value below 0.5, then you predict Y equals zero or not malignant.", "tokens": [50364, 293, 472, 420, 754, 1570, 813, 4018, 420, 5044, 813, 472, 13, 50582, 50582, 583, 510, 321, 528, 281, 6069, 10479, 13, 50802, 50802, 1485, 551, 291, 727, 853, 307, 281, 1888, 257, 14678, 295, 584, 1958, 13, 20, 370, 300, 498, 264, 2316, 23930, 257, 51186, 51186, 2158, 2507, 1958, 13, 20, 11, 550, 291, 6069, 398, 6915, 4018, 420, 406, 2806, 36818, 13, 51542, 51542], "temperature": 0.0, "avg_logprob": -0.10171926885411359, "compression_ratio": 1.430232558139535, "no_speech_prob": 3.1875297281658277e-06}, {"id": 72, "seek": 36124, "start": 361.24, "end": 367.88, "text": " And if the model outputs a number equal to or greater than 0.5, then predict Y equals", "tokens": [50364, 400, 498, 264, 2316, 23930, 257, 1230, 2681, 281, 420, 5044, 813, 1958, 13, 20, 11, 550, 6069, 398, 6915, 50696, 50696, 472, 420, 2806, 36818, 13, 50836, 50836, 13428, 300, 341, 14678, 2158, 1958, 13, 20, 27815, 82, 264, 1151, 3318, 2997, 1622, 412, 341, 935, 13, 51234, 51234, 407, 498, 291, 2642, 341, 9429, 1622, 510, 11, 1203, 281, 264, 1411, 5314, 493, 365, 257, 17630, 295, 398, 51526, 51526], "temperature": 0.0, "avg_logprob": -0.08972495955389899, "compression_ratio": 1.4870466321243523, "no_speech_prob": 1.191099499919801e-06}, {"id": 73, "seek": 36124, "start": 367.88, "end": 370.68, "text": " one or malignant.", "tokens": [50364, 400, 498, 264, 2316, 23930, 257, 1230, 2681, 281, 420, 5044, 813, 1958, 13, 20, 11, 550, 6069, 398, 6915, 50696, 50696, 472, 420, 2806, 36818, 13, 50836, 50836, 13428, 300, 341, 14678, 2158, 1958, 13, 20, 27815, 82, 264, 1151, 3318, 2997, 1622, 412, 341, 935, 13, 51234, 51234, 407, 498, 291, 2642, 341, 9429, 1622, 510, 11, 1203, 281, 264, 1411, 5314, 493, 365, 257, 17630, 295, 398, 51526, 51526], "temperature": 0.0, "avg_logprob": -0.08972495955389899, "compression_ratio": 1.4870466321243523, "no_speech_prob": 1.191099499919801e-06}, {"id": 74, "seek": 36124, "start": 370.68, "end": 378.64, "text": " Notice that this threshold value 0.5 intersects the best fit straight line at this point.", "tokens": [50364, 400, 498, 264, 2316, 23930, 257, 1230, 2681, 281, 420, 5044, 813, 1958, 13, 20, 11, 550, 6069, 398, 6915, 50696, 50696, 472, 420, 2806, 36818, 13, 50836, 50836, 13428, 300, 341, 14678, 2158, 1958, 13, 20, 27815, 82, 264, 1151, 3318, 2997, 1622, 412, 341, 935, 13, 51234, 51234, 407, 498, 291, 2642, 341, 9429, 1622, 510, 11, 1203, 281, 264, 1411, 5314, 493, 365, 257, 17630, 295, 398, 51526, 51526], "temperature": 0.0, "avg_logprob": -0.08972495955389899, "compression_ratio": 1.4870466321243523, "no_speech_prob": 1.191099499919801e-06}, {"id": 75, "seek": 36124, "start": 378.64, "end": 384.48, "text": " So if you draw this vertical line here, everything to the left ends up with a prediction of Y", "tokens": [50364, 400, 498, 264, 2316, 23930, 257, 1230, 2681, 281, 420, 5044, 813, 1958, 13, 20, 11, 550, 6069, 398, 6915, 50696, 50696, 472, 420, 2806, 36818, 13, 50836, 50836, 13428, 300, 341, 14678, 2158, 1958, 13, 20, 27815, 82, 264, 1151, 3318, 2997, 1622, 412, 341, 935, 13, 51234, 51234, 407, 498, 291, 2642, 341, 9429, 1622, 510, 11, 1203, 281, 264, 1411, 5314, 493, 365, 257, 17630, 295, 398, 51526, 51526], "temperature": 0.0, "avg_logprob": -0.08972495955389899, "compression_ratio": 1.4870466321243523, "no_speech_prob": 1.191099499919801e-06}, {"id": 76, "seek": 38448, "start": 384.48, "end": 391.88, "text": " equals zero and everything on the right ends up with a prediction of Y equals one.", "tokens": [50364, 6915, 4018, 293, 1203, 322, 264, 558, 5314, 493, 365, 257, 17630, 295, 398, 6915, 472, 13, 50734, 50734, 823, 337, 341, 1729, 1412, 992, 11, 309, 1542, 411, 8213, 24590, 727, 360, 746, 50966, 50966, 10585, 13, 51016, 51016, 583, 586, 718, 311, 536, 437, 2314, 498, 428, 1412, 992, 575, 472, 544, 3097, 1365, 13, 51302, 51302, 639, 472, 636, 670, 510, 322, 264, 558, 13, 51456, 51456, 961, 311, 611, 10101, 264, 12750, 10298, 13, 51638, 51638], "temperature": 0.0, "avg_logprob": -0.10645667518057474, "compression_ratio": 1.5391705069124424, "no_speech_prob": 1.5534867543465225e-06}, {"id": 77, "seek": 38448, "start": 391.88, "end": 396.52000000000004, "text": " Now for this particular data set, it looks like linear regression could do something", "tokens": [50364, 6915, 4018, 293, 1203, 322, 264, 558, 5314, 493, 365, 257, 17630, 295, 398, 6915, 472, 13, 50734, 50734, 823, 337, 341, 1729, 1412, 992, 11, 309, 1542, 411, 8213, 24590, 727, 360, 746, 50966, 50966, 10585, 13, 51016, 51016, 583, 586, 718, 311, 536, 437, 2314, 498, 428, 1412, 992, 575, 472, 544, 3097, 1365, 13, 51302, 51302, 639, 472, 636, 670, 510, 322, 264, 558, 13, 51456, 51456, 961, 311, 611, 10101, 264, 12750, 10298, 13, 51638, 51638], "temperature": 0.0, "avg_logprob": -0.10645667518057474, "compression_ratio": 1.5391705069124424, "no_speech_prob": 1.5534867543465225e-06}, {"id": 78, "seek": 38448, "start": 396.52000000000004, "end": 397.52000000000004, "text": " reasonable.", "tokens": [50364, 6915, 4018, 293, 1203, 322, 264, 558, 5314, 493, 365, 257, 17630, 295, 398, 6915, 472, 13, 50734, 50734, 823, 337, 341, 1729, 1412, 992, 11, 309, 1542, 411, 8213, 24590, 727, 360, 746, 50966, 50966, 10585, 13, 51016, 51016, 583, 586, 718, 311, 536, 437, 2314, 498, 428, 1412, 992, 575, 472, 544, 3097, 1365, 13, 51302, 51302, 639, 472, 636, 670, 510, 322, 264, 558, 13, 51456, 51456, 961, 311, 611, 10101, 264, 12750, 10298, 13, 51638, 51638], "temperature": 0.0, "avg_logprob": -0.10645667518057474, "compression_ratio": 1.5391705069124424, "no_speech_prob": 1.5534867543465225e-06}, {"id": 79, "seek": 38448, "start": 397.52000000000004, "end": 403.24, "text": " But now let's see what happens if your data set has one more training example.", "tokens": [50364, 6915, 4018, 293, 1203, 322, 264, 558, 5314, 493, 365, 257, 17630, 295, 398, 6915, 472, 13, 50734, 50734, 823, 337, 341, 1729, 1412, 992, 11, 309, 1542, 411, 8213, 24590, 727, 360, 746, 50966, 50966, 10585, 13, 51016, 51016, 583, 586, 718, 311, 536, 437, 2314, 498, 428, 1412, 992, 575, 472, 544, 3097, 1365, 13, 51302, 51302, 639, 472, 636, 670, 510, 322, 264, 558, 13, 51456, 51456, 961, 311, 611, 10101, 264, 12750, 10298, 13, 51638, 51638], "temperature": 0.0, "avg_logprob": -0.10645667518057474, "compression_ratio": 1.5391705069124424, "no_speech_prob": 1.5534867543465225e-06}, {"id": 80, "seek": 38448, "start": 403.24, "end": 406.32, "text": " This one way over here on the right.", "tokens": [50364, 6915, 4018, 293, 1203, 322, 264, 558, 5314, 493, 365, 257, 17630, 295, 398, 6915, 472, 13, 50734, 50734, 823, 337, 341, 1729, 1412, 992, 11, 309, 1542, 411, 8213, 24590, 727, 360, 746, 50966, 50966, 10585, 13, 51016, 51016, 583, 586, 718, 311, 536, 437, 2314, 498, 428, 1412, 992, 575, 472, 544, 3097, 1365, 13, 51302, 51302, 639, 472, 636, 670, 510, 322, 264, 558, 13, 51456, 51456, 961, 311, 611, 10101, 264, 12750, 10298, 13, 51638, 51638], "temperature": 0.0, "avg_logprob": -0.10645667518057474, "compression_ratio": 1.5391705069124424, "no_speech_prob": 1.5534867543465225e-06}, {"id": 81, "seek": 38448, "start": 406.32, "end": 409.96000000000004, "text": " Let's also extend the horizontal axis.", "tokens": [50364, 6915, 4018, 293, 1203, 322, 264, 558, 5314, 493, 365, 257, 17630, 295, 398, 6915, 472, 13, 50734, 50734, 823, 337, 341, 1729, 1412, 992, 11, 309, 1542, 411, 8213, 24590, 727, 360, 746, 50966, 50966, 10585, 13, 51016, 51016, 583, 586, 718, 311, 536, 437, 2314, 498, 428, 1412, 992, 575, 472, 544, 3097, 1365, 13, 51302, 51302, 639, 472, 636, 670, 510, 322, 264, 558, 13, 51456, 51456, 961, 311, 611, 10101, 264, 12750, 10298, 13, 51638, 51638], "temperature": 0.0, "avg_logprob": -0.10645667518057474, "compression_ratio": 1.5391705069124424, "no_speech_prob": 1.5534867543465225e-06}, {"id": 82, "seek": 40996, "start": 409.96, "end": 415.71999999999997, "text": " Notice that this training example shouldn't really change how you classify the data points.", "tokens": [50364, 13428, 300, 341, 3097, 1365, 4659, 380, 534, 1319, 577, 291, 33872, 264, 1412, 2793, 13, 50652, 50652, 639, 9429, 26764, 1622, 300, 321, 12804, 445, 586, 920, 1669, 2020, 382, 264, 1723, 4506, 689, 50880, 50880, 732, 2077, 4356, 813, 341, 820, 312, 20627, 382, 4018, 293, 732, 2077, 5044, 813, 341, 51131, 51131, 820, 312, 20627, 382, 472, 13, 51254, 51254, 583, 1564, 291, 600, 3869, 341, 2857, 3097, 1365, 322, 264, 558, 11, 264, 1151, 3318, 1622, 337, 51448, 51448, 8213, 24590, 486, 5513, 670, 411, 341, 13, 51674, 51674], "temperature": 0.0, "avg_logprob": -0.1079614237735146, "compression_ratio": 1.7851239669421488, "no_speech_prob": 3.0415640139835887e-06}, {"id": 83, "seek": 40996, "start": 415.71999999999997, "end": 420.28, "text": " This vertical dividing line that we drew just now still makes sense as the cutoff where", "tokens": [50364, 13428, 300, 341, 3097, 1365, 4659, 380, 534, 1319, 577, 291, 33872, 264, 1412, 2793, 13, 50652, 50652, 639, 9429, 26764, 1622, 300, 321, 12804, 445, 586, 920, 1669, 2020, 382, 264, 1723, 4506, 689, 50880, 50880, 732, 2077, 4356, 813, 341, 820, 312, 20627, 382, 4018, 293, 732, 2077, 5044, 813, 341, 51131, 51131, 820, 312, 20627, 382, 472, 13, 51254, 51254, 583, 1564, 291, 600, 3869, 341, 2857, 3097, 1365, 322, 264, 558, 11, 264, 1151, 3318, 1622, 337, 51448, 51448, 8213, 24590, 486, 5513, 670, 411, 341, 13, 51674, 51674], "temperature": 0.0, "avg_logprob": -0.1079614237735146, "compression_ratio": 1.7851239669421488, "no_speech_prob": 3.0415640139835887e-06}, {"id": 84, "seek": 40996, "start": 420.28, "end": 425.29999999999995, "text": " two minutes smaller than this should be classified as zero and two minutes greater than this", "tokens": [50364, 13428, 300, 341, 3097, 1365, 4659, 380, 534, 1319, 577, 291, 33872, 264, 1412, 2793, 13, 50652, 50652, 639, 9429, 26764, 1622, 300, 321, 12804, 445, 586, 920, 1669, 2020, 382, 264, 1723, 4506, 689, 50880, 50880, 732, 2077, 4356, 813, 341, 820, 312, 20627, 382, 4018, 293, 732, 2077, 5044, 813, 341, 51131, 51131, 820, 312, 20627, 382, 472, 13, 51254, 51254, 583, 1564, 291, 600, 3869, 341, 2857, 3097, 1365, 322, 264, 558, 11, 264, 1151, 3318, 1622, 337, 51448, 51448, 8213, 24590, 486, 5513, 670, 411, 341, 13, 51674, 51674], "temperature": 0.0, "avg_logprob": -0.1079614237735146, "compression_ratio": 1.7851239669421488, "no_speech_prob": 3.0415640139835887e-06}, {"id": 85, "seek": 40996, "start": 425.29999999999995, "end": 427.76, "text": " should be classified as one.", "tokens": [50364, 13428, 300, 341, 3097, 1365, 4659, 380, 534, 1319, 577, 291, 33872, 264, 1412, 2793, 13, 50652, 50652, 639, 9429, 26764, 1622, 300, 321, 12804, 445, 586, 920, 1669, 2020, 382, 264, 1723, 4506, 689, 50880, 50880, 732, 2077, 4356, 813, 341, 820, 312, 20627, 382, 4018, 293, 732, 2077, 5044, 813, 341, 51131, 51131, 820, 312, 20627, 382, 472, 13, 51254, 51254, 583, 1564, 291, 600, 3869, 341, 2857, 3097, 1365, 322, 264, 558, 11, 264, 1151, 3318, 1622, 337, 51448, 51448, 8213, 24590, 486, 5513, 670, 411, 341, 13, 51674, 51674], "temperature": 0.0, "avg_logprob": -0.1079614237735146, "compression_ratio": 1.7851239669421488, "no_speech_prob": 3.0415640139835887e-06}, {"id": 86, "seek": 40996, "start": 427.76, "end": 431.64, "text": " But once you've added this extra training example on the right, the best fit line for", "tokens": [50364, 13428, 300, 341, 3097, 1365, 4659, 380, 534, 1319, 577, 291, 33872, 264, 1412, 2793, 13, 50652, 50652, 639, 9429, 26764, 1622, 300, 321, 12804, 445, 586, 920, 1669, 2020, 382, 264, 1723, 4506, 689, 50880, 50880, 732, 2077, 4356, 813, 341, 820, 312, 20627, 382, 4018, 293, 732, 2077, 5044, 813, 341, 51131, 51131, 820, 312, 20627, 382, 472, 13, 51254, 51254, 583, 1564, 291, 600, 3869, 341, 2857, 3097, 1365, 322, 264, 558, 11, 264, 1151, 3318, 1622, 337, 51448, 51448, 8213, 24590, 486, 5513, 670, 411, 341, 13, 51674, 51674], "temperature": 0.0, "avg_logprob": -0.1079614237735146, "compression_ratio": 1.7851239669421488, "no_speech_prob": 3.0415640139835887e-06}, {"id": 87, "seek": 40996, "start": 431.64, "end": 436.15999999999997, "text": " linear regression will shift over like this.", "tokens": [50364, 13428, 300, 341, 3097, 1365, 4659, 380, 534, 1319, 577, 291, 33872, 264, 1412, 2793, 13, 50652, 50652, 639, 9429, 26764, 1622, 300, 321, 12804, 445, 586, 920, 1669, 2020, 382, 264, 1723, 4506, 689, 50880, 50880, 732, 2077, 4356, 813, 341, 820, 312, 20627, 382, 4018, 293, 732, 2077, 5044, 813, 341, 51131, 51131, 820, 312, 20627, 382, 472, 13, 51254, 51254, 583, 1564, 291, 600, 3869, 341, 2857, 3097, 1365, 322, 264, 558, 11, 264, 1151, 3318, 1622, 337, 51448, 51448, 8213, 24590, 486, 5513, 670, 411, 341, 13, 51674, 51674], "temperature": 0.0, "avg_logprob": -0.1079614237735146, "compression_ratio": 1.7851239669421488, "no_speech_prob": 3.0415640139835887e-06}, {"id": 88, "seek": 43616, "start": 436.16, "end": 442.12, "text": " And if you continue using the threshold of 0.5, you now notice that everything to the", "tokens": [50364, 400, 498, 291, 2354, 1228, 264, 14678, 295, 1958, 13, 20, 11, 291, 586, 3449, 300, 1203, 281, 264, 50662, 50662, 1411, 295, 341, 935, 307, 19147, 382, 4018, 11, 2107, 12, 5579, 36818, 11, 293, 1203, 281, 264, 558, 295, 341, 935, 51022, 51022, 307, 19147, 281, 312, 472, 420, 2806, 36818, 13, 51241, 51241, 639, 1943, 380, 437, 321, 528, 11, 570, 5127, 300, 1365, 636, 281, 264, 558, 4659, 380, 1319, 51536, 51536, 604, 295, 527, 22865, 466, 577, 281, 33872, 2806, 36818, 5717, 3271, 788, 38466, 13, 51824, 51824], "temperature": 0.0, "avg_logprob": -0.08379477952655993, "compression_ratio": 1.737556561085973, "no_speech_prob": 5.422113190434175e-06}, {"id": 89, "seek": 43616, "start": 442.12, "end": 449.32000000000005, "text": " left of this point is predicted as zero, non-malignant, and everything to the right of this point", "tokens": [50364, 400, 498, 291, 2354, 1228, 264, 14678, 295, 1958, 13, 20, 11, 291, 586, 3449, 300, 1203, 281, 264, 50662, 50662, 1411, 295, 341, 935, 307, 19147, 382, 4018, 11, 2107, 12, 5579, 36818, 11, 293, 1203, 281, 264, 558, 295, 341, 935, 51022, 51022, 307, 19147, 281, 312, 472, 420, 2806, 36818, 13, 51241, 51241, 639, 1943, 380, 437, 321, 528, 11, 570, 5127, 300, 1365, 636, 281, 264, 558, 4659, 380, 1319, 51536, 51536, 604, 295, 527, 22865, 466, 577, 281, 33872, 2806, 36818, 5717, 3271, 788, 38466, 13, 51824, 51824], "temperature": 0.0, "avg_logprob": -0.08379477952655993, "compression_ratio": 1.737556561085973, "no_speech_prob": 5.422113190434175e-06}, {"id": 90, "seek": 43616, "start": 449.32000000000005, "end": 453.70000000000005, "text": " is predicted to be one or malignant.", "tokens": [50364, 400, 498, 291, 2354, 1228, 264, 14678, 295, 1958, 13, 20, 11, 291, 586, 3449, 300, 1203, 281, 264, 50662, 50662, 1411, 295, 341, 935, 307, 19147, 382, 4018, 11, 2107, 12, 5579, 36818, 11, 293, 1203, 281, 264, 558, 295, 341, 935, 51022, 51022, 307, 19147, 281, 312, 472, 420, 2806, 36818, 13, 51241, 51241, 639, 1943, 380, 437, 321, 528, 11, 570, 5127, 300, 1365, 636, 281, 264, 558, 4659, 380, 1319, 51536, 51536, 604, 295, 527, 22865, 466, 577, 281, 33872, 2806, 36818, 5717, 3271, 788, 38466, 13, 51824, 51824], "temperature": 0.0, "avg_logprob": -0.08379477952655993, "compression_ratio": 1.737556561085973, "no_speech_prob": 5.422113190434175e-06}, {"id": 91, "seek": 43616, "start": 453.70000000000005, "end": 459.6, "text": " This isn't what we want, because adding that example way to the right shouldn't change", "tokens": [50364, 400, 498, 291, 2354, 1228, 264, 14678, 295, 1958, 13, 20, 11, 291, 586, 3449, 300, 1203, 281, 264, 50662, 50662, 1411, 295, 341, 935, 307, 19147, 382, 4018, 11, 2107, 12, 5579, 36818, 11, 293, 1203, 281, 264, 558, 295, 341, 935, 51022, 51022, 307, 19147, 281, 312, 472, 420, 2806, 36818, 13, 51241, 51241, 639, 1943, 380, 437, 321, 528, 11, 570, 5127, 300, 1365, 636, 281, 264, 558, 4659, 380, 1319, 51536, 51536, 604, 295, 527, 22865, 466, 577, 281, 33872, 2806, 36818, 5717, 3271, 788, 38466, 13, 51824, 51824], "temperature": 0.0, "avg_logprob": -0.08379477952655993, "compression_ratio": 1.737556561085973, "no_speech_prob": 5.422113190434175e-06}, {"id": 92, "seek": 43616, "start": 459.6, "end": 465.36, "text": " any of our conclusions about how to classify malignant versus benign tumors.", "tokens": [50364, 400, 498, 291, 2354, 1228, 264, 14678, 295, 1958, 13, 20, 11, 291, 586, 3449, 300, 1203, 281, 264, 50662, 50662, 1411, 295, 341, 935, 307, 19147, 382, 4018, 11, 2107, 12, 5579, 36818, 11, 293, 1203, 281, 264, 558, 295, 341, 935, 51022, 51022, 307, 19147, 281, 312, 472, 420, 2806, 36818, 13, 51241, 51241, 639, 1943, 380, 437, 321, 528, 11, 570, 5127, 300, 1365, 636, 281, 264, 558, 4659, 380, 1319, 51536, 51536, 604, 295, 527, 22865, 466, 577, 281, 33872, 2806, 36818, 5717, 3271, 788, 38466, 13, 51824, 51824], "temperature": 0.0, "avg_logprob": -0.08379477952655993, "compression_ratio": 1.737556561085973, "no_speech_prob": 5.422113190434175e-06}, {"id": 93, "seek": 46536, "start": 465.36, "end": 470.7, "text": " But if you try to do this with linear regression, adding this one example, which feels like", "tokens": [50364, 583, 498, 291, 853, 281, 360, 341, 365, 8213, 24590, 11, 5127, 341, 472, 1365, 11, 597, 3417, 411, 50631, 50631, 309, 4659, 380, 312, 4473, 1340, 11, 309, 5314, 493, 365, 505, 2539, 257, 709, 5324, 2445, 50862, 50862, 337, 341, 21538, 1154, 13, 50960, 50960, 24120, 11, 562, 257, 22512, 307, 2416, 11, 321, 528, 264, 9284, 281, 33872, 309, 382, 2806, 36818, 13, 51284, 51284, 407, 437, 321, 445, 1866, 390, 8213, 24590, 7700, 264, 1151, 3318, 1622, 562, 321, 3869, 472, 51596, 51596], "temperature": 0.0, "avg_logprob": -0.10736911216478669, "compression_ratio": 1.6391304347826088, "no_speech_prob": 2.123362719430588e-06}, {"id": 94, "seek": 46536, "start": 470.7, "end": 475.32, "text": " it shouldn't be changing anything, it ends up with us learning a much worse function", "tokens": [50364, 583, 498, 291, 853, 281, 360, 341, 365, 8213, 24590, 11, 5127, 341, 472, 1365, 11, 597, 3417, 411, 50631, 50631, 309, 4659, 380, 312, 4473, 1340, 11, 309, 5314, 493, 365, 505, 2539, 257, 709, 5324, 2445, 50862, 50862, 337, 341, 21538, 1154, 13, 50960, 50960, 24120, 11, 562, 257, 22512, 307, 2416, 11, 321, 528, 264, 9284, 281, 33872, 309, 382, 2806, 36818, 13, 51284, 51284, 407, 437, 321, 445, 1866, 390, 8213, 24590, 7700, 264, 1151, 3318, 1622, 562, 321, 3869, 472, 51596, 51596], "temperature": 0.0, "avg_logprob": -0.10736911216478669, "compression_ratio": 1.6391304347826088, "no_speech_prob": 2.123362719430588e-06}, {"id": 95, "seek": 46536, "start": 475.32, "end": 477.28000000000003, "text": " for this classification problem.", "tokens": [50364, 583, 498, 291, 853, 281, 360, 341, 365, 8213, 24590, 11, 5127, 341, 472, 1365, 11, 597, 3417, 411, 50631, 50631, 309, 4659, 380, 312, 4473, 1340, 11, 309, 5314, 493, 365, 505, 2539, 257, 709, 5324, 2445, 50862, 50862, 337, 341, 21538, 1154, 13, 50960, 50960, 24120, 11, 562, 257, 22512, 307, 2416, 11, 321, 528, 264, 9284, 281, 33872, 309, 382, 2806, 36818, 13, 51284, 51284, 407, 437, 321, 445, 1866, 390, 8213, 24590, 7700, 264, 1151, 3318, 1622, 562, 321, 3869, 472, 51596, 51596], "temperature": 0.0, "avg_logprob": -0.10736911216478669, "compression_ratio": 1.6391304347826088, "no_speech_prob": 2.123362719430588e-06}, {"id": 96, "seek": 46536, "start": 477.28000000000003, "end": 483.76, "text": " Clearly, when a tumor is large, we want the algorithm to classify it as malignant.", "tokens": [50364, 583, 498, 291, 853, 281, 360, 341, 365, 8213, 24590, 11, 5127, 341, 472, 1365, 11, 597, 3417, 411, 50631, 50631, 309, 4659, 380, 312, 4473, 1340, 11, 309, 5314, 493, 365, 505, 2539, 257, 709, 5324, 2445, 50862, 50862, 337, 341, 21538, 1154, 13, 50960, 50960, 24120, 11, 562, 257, 22512, 307, 2416, 11, 321, 528, 264, 9284, 281, 33872, 309, 382, 2806, 36818, 13, 51284, 51284, 407, 437, 321, 445, 1866, 390, 8213, 24590, 7700, 264, 1151, 3318, 1622, 562, 321, 3869, 472, 51596, 51596], "temperature": 0.0, "avg_logprob": -0.10736911216478669, "compression_ratio": 1.6391304347826088, "no_speech_prob": 2.123362719430588e-06}, {"id": 97, "seek": 46536, "start": 483.76, "end": 490.0, "text": " So what we just saw was linear regression causes the best fit line when we added one", "tokens": [50364, 583, 498, 291, 853, 281, 360, 341, 365, 8213, 24590, 11, 5127, 341, 472, 1365, 11, 597, 3417, 411, 50631, 50631, 309, 4659, 380, 312, 4473, 1340, 11, 309, 5314, 493, 365, 505, 2539, 257, 709, 5324, 2445, 50862, 50862, 337, 341, 21538, 1154, 13, 50960, 50960, 24120, 11, 562, 257, 22512, 307, 2416, 11, 321, 528, 264, 9284, 281, 33872, 309, 382, 2806, 36818, 13, 51284, 51284, 407, 437, 321, 445, 1866, 390, 8213, 24590, 7700, 264, 1151, 3318, 1622, 562, 321, 3869, 472, 51596, 51596], "temperature": 0.0, "avg_logprob": -0.10736911216478669, "compression_ratio": 1.6391304347826088, "no_speech_prob": 2.123362719430588e-06}, {"id": 98, "seek": 49000, "start": 490.0, "end": 497.16, "text": " more example to the right to shift over, and thus the dividing line also called the decision", "tokens": [50364, 544, 1365, 281, 264, 558, 281, 5513, 670, 11, 293, 8807, 264, 26764, 1622, 611, 1219, 264, 3537, 50722, 50722, 12866, 281, 5513, 670, 281, 264, 558, 13, 50926, 50926, 509, 1466, 544, 466, 264, 3537, 12866, 294, 264, 958, 960, 13, 51151, 51151, 509, 611, 1466, 466, 364, 9284, 1219, 3565, 3142, 24590, 11, 689, 264, 5598, 2158, 295, 264, 51432, 51432, 9700, 486, 1009, 312, 1296, 1958, 293, 502, 11, 293, 264, 9284, 486, 5042, 613, 2740, 300, 51732, 51732, 321, 434, 2577, 322, 264, 4137, 13, 51820, 51820], "temperature": 0.0, "avg_logprob": -0.11009656229326802, "compression_ratio": 1.8302752293577982, "no_speech_prob": 4.092865310667548e-06}, {"id": 99, "seek": 49000, "start": 497.16, "end": 501.24, "text": " boundary to shift over to the right.", "tokens": [50364, 544, 1365, 281, 264, 558, 281, 5513, 670, 11, 293, 8807, 264, 26764, 1622, 611, 1219, 264, 3537, 50722, 50722, 12866, 281, 5513, 670, 281, 264, 558, 13, 50926, 50926, 509, 1466, 544, 466, 264, 3537, 12866, 294, 264, 958, 960, 13, 51151, 51151, 509, 611, 1466, 466, 364, 9284, 1219, 3565, 3142, 24590, 11, 689, 264, 5598, 2158, 295, 264, 51432, 51432, 9700, 486, 1009, 312, 1296, 1958, 293, 502, 11, 293, 264, 9284, 486, 5042, 613, 2740, 300, 51732, 51732, 321, 434, 2577, 322, 264, 4137, 13, 51820, 51820], "temperature": 0.0, "avg_logprob": -0.11009656229326802, "compression_ratio": 1.8302752293577982, "no_speech_prob": 4.092865310667548e-06}, {"id": 100, "seek": 49000, "start": 501.24, "end": 505.74, "text": " You learn more about the decision boundary in the next video.", "tokens": [50364, 544, 1365, 281, 264, 558, 281, 5513, 670, 11, 293, 8807, 264, 26764, 1622, 611, 1219, 264, 3537, 50722, 50722, 12866, 281, 5513, 670, 281, 264, 558, 13, 50926, 50926, 509, 1466, 544, 466, 264, 3537, 12866, 294, 264, 958, 960, 13, 51151, 51151, 509, 611, 1466, 466, 364, 9284, 1219, 3565, 3142, 24590, 11, 689, 264, 5598, 2158, 295, 264, 51432, 51432, 9700, 486, 1009, 312, 1296, 1958, 293, 502, 11, 293, 264, 9284, 486, 5042, 613, 2740, 300, 51732, 51732, 321, 434, 2577, 322, 264, 4137, 13, 51820, 51820], "temperature": 0.0, "avg_logprob": -0.11009656229326802, "compression_ratio": 1.8302752293577982, "no_speech_prob": 4.092865310667548e-06}, {"id": 101, "seek": 49000, "start": 505.74, "end": 511.36, "text": " You also learn about an algorithm called logistic regression, where the output value of the", "tokens": [50364, 544, 1365, 281, 264, 558, 281, 5513, 670, 11, 293, 8807, 264, 26764, 1622, 611, 1219, 264, 3537, 50722, 50722, 12866, 281, 5513, 670, 281, 264, 558, 13, 50926, 50926, 509, 1466, 544, 466, 264, 3537, 12866, 294, 264, 958, 960, 13, 51151, 51151, 509, 611, 1466, 466, 364, 9284, 1219, 3565, 3142, 24590, 11, 689, 264, 5598, 2158, 295, 264, 51432, 51432, 9700, 486, 1009, 312, 1296, 1958, 293, 502, 11, 293, 264, 9284, 486, 5042, 613, 2740, 300, 51732, 51732, 321, 434, 2577, 322, 264, 4137, 13, 51820, 51820], "temperature": 0.0, "avg_logprob": -0.11009656229326802, "compression_ratio": 1.8302752293577982, "no_speech_prob": 4.092865310667548e-06}, {"id": 102, "seek": 49000, "start": 511.36, "end": 517.36, "text": " outcome will always be between 0 and 1, and the algorithm will avoid these problems that", "tokens": [50364, 544, 1365, 281, 264, 558, 281, 5513, 670, 11, 293, 8807, 264, 26764, 1622, 611, 1219, 264, 3537, 50722, 50722, 12866, 281, 5513, 670, 281, 264, 558, 13, 50926, 50926, 509, 1466, 544, 466, 264, 3537, 12866, 294, 264, 958, 960, 13, 51151, 51151, 509, 611, 1466, 466, 364, 9284, 1219, 3565, 3142, 24590, 11, 689, 264, 5598, 2158, 295, 264, 51432, 51432, 9700, 486, 1009, 312, 1296, 1958, 293, 502, 11, 293, 264, 9284, 486, 5042, 613, 2740, 300, 51732, 51732, 321, 434, 2577, 322, 264, 4137, 13, 51820, 51820], "temperature": 0.0, "avg_logprob": -0.11009656229326802, "compression_ratio": 1.8302752293577982, "no_speech_prob": 4.092865310667548e-06}, {"id": 103, "seek": 49000, "start": 517.36, "end": 519.12, "text": " we're seeing on the slide.", "tokens": [50364, 544, 1365, 281, 264, 558, 281, 5513, 670, 11, 293, 8807, 264, 26764, 1622, 611, 1219, 264, 3537, 50722, 50722, 12866, 281, 5513, 670, 281, 264, 558, 13, 50926, 50926, 509, 1466, 544, 466, 264, 3537, 12866, 294, 264, 958, 960, 13, 51151, 51151, 509, 611, 1466, 466, 364, 9284, 1219, 3565, 3142, 24590, 11, 689, 264, 5598, 2158, 295, 264, 51432, 51432, 9700, 486, 1009, 312, 1296, 1958, 293, 502, 11, 293, 264, 9284, 486, 5042, 613, 2740, 300, 51732, 51732, 321, 434, 2577, 322, 264, 4137, 13, 51820, 51820], "temperature": 0.0, "avg_logprob": -0.11009656229326802, "compression_ratio": 1.8302752293577982, "no_speech_prob": 4.092865310667548e-06}, {"id": 104, "seek": 51912, "start": 519.12, "end": 524.68, "text": " By the way, one thing confusing about the name logistic regression is that even though", "tokens": [50364, 3146, 264, 636, 11, 472, 551, 13181, 466, 264, 1315, 3565, 3142, 24590, 307, 300, 754, 1673, 50642, 50642, 309, 575, 264, 1349, 24590, 294, 309, 11, 309, 311, 767, 1143, 337, 21538, 13, 50892, 50892, 1468, 380, 312, 9019, 538, 264, 1315, 11, 597, 390, 2212, 337, 8584, 4112, 13, 51104, 51104, 467, 311, 767, 1143, 281, 5039, 17434, 21538, 2740, 689, 264, 5598, 7645, 288, 307, 2139, 51360, 51360, 1958, 420, 502, 13, 51500, 51500, 682, 264, 11500, 17312, 2715, 11, 291, 611, 483, 281, 747, 257, 574, 412, 437, 2314, 562, 291, 853, 51722, 51722], "temperature": 0.0, "avg_logprob": -0.10874335289001465, "compression_ratio": 1.689516129032258, "no_speech_prob": 7.4111148933297954e-06}, {"id": 105, "seek": 51912, "start": 524.68, "end": 529.68, "text": " it has the word regression in it, it's actually used for classification.", "tokens": [50364, 3146, 264, 636, 11, 472, 551, 13181, 466, 264, 1315, 3565, 3142, 24590, 307, 300, 754, 1673, 50642, 50642, 309, 575, 264, 1349, 24590, 294, 309, 11, 309, 311, 767, 1143, 337, 21538, 13, 50892, 50892, 1468, 380, 312, 9019, 538, 264, 1315, 11, 597, 390, 2212, 337, 8584, 4112, 13, 51104, 51104, 467, 311, 767, 1143, 281, 5039, 17434, 21538, 2740, 689, 264, 5598, 7645, 288, 307, 2139, 51360, 51360, 1958, 420, 502, 13, 51500, 51500, 682, 264, 11500, 17312, 2715, 11, 291, 611, 483, 281, 747, 257, 574, 412, 437, 2314, 562, 291, 853, 51722, 51722], "temperature": 0.0, "avg_logprob": -0.10874335289001465, "compression_ratio": 1.689516129032258, "no_speech_prob": 7.4111148933297954e-06}, {"id": 106, "seek": 51912, "start": 529.68, "end": 533.92, "text": " Don't be confused by the name, which was given for historical reasons.", "tokens": [50364, 3146, 264, 636, 11, 472, 551, 13181, 466, 264, 1315, 3565, 3142, 24590, 307, 300, 754, 1673, 50642, 50642, 309, 575, 264, 1349, 24590, 294, 309, 11, 309, 311, 767, 1143, 337, 21538, 13, 50892, 50892, 1468, 380, 312, 9019, 538, 264, 1315, 11, 597, 390, 2212, 337, 8584, 4112, 13, 51104, 51104, 467, 311, 767, 1143, 281, 5039, 17434, 21538, 2740, 689, 264, 5598, 7645, 288, 307, 2139, 51360, 51360, 1958, 420, 502, 13, 51500, 51500, 682, 264, 11500, 17312, 2715, 11, 291, 611, 483, 281, 747, 257, 574, 412, 437, 2314, 562, 291, 853, 51722, 51722], "temperature": 0.0, "avg_logprob": -0.10874335289001465, "compression_ratio": 1.689516129032258, "no_speech_prob": 7.4111148933297954e-06}, {"id": 107, "seek": 51912, "start": 533.92, "end": 539.04, "text": " It's actually used to solve binary classification problems where the output label y is either", "tokens": [50364, 3146, 264, 636, 11, 472, 551, 13181, 466, 264, 1315, 3565, 3142, 24590, 307, 300, 754, 1673, 50642, 50642, 309, 575, 264, 1349, 24590, 294, 309, 11, 309, 311, 767, 1143, 337, 21538, 13, 50892, 50892, 1468, 380, 312, 9019, 538, 264, 1315, 11, 597, 390, 2212, 337, 8584, 4112, 13, 51104, 51104, 467, 311, 767, 1143, 281, 5039, 17434, 21538, 2740, 689, 264, 5598, 7645, 288, 307, 2139, 51360, 51360, 1958, 420, 502, 13, 51500, 51500, 682, 264, 11500, 17312, 2715, 11, 291, 611, 483, 281, 747, 257, 574, 412, 437, 2314, 562, 291, 853, 51722, 51722], "temperature": 0.0, "avg_logprob": -0.10874335289001465, "compression_ratio": 1.689516129032258, "no_speech_prob": 7.4111148933297954e-06}, {"id": 108, "seek": 51912, "start": 539.04, "end": 541.84, "text": " 0 or 1.", "tokens": [50364, 3146, 264, 636, 11, 472, 551, 13181, 466, 264, 1315, 3565, 3142, 24590, 307, 300, 754, 1673, 50642, 50642, 309, 575, 264, 1349, 24590, 294, 309, 11, 309, 311, 767, 1143, 337, 21538, 13, 50892, 50892, 1468, 380, 312, 9019, 538, 264, 1315, 11, 597, 390, 2212, 337, 8584, 4112, 13, 51104, 51104, 467, 311, 767, 1143, 281, 5039, 17434, 21538, 2740, 689, 264, 5598, 7645, 288, 307, 2139, 51360, 51360, 1958, 420, 502, 13, 51500, 51500, 682, 264, 11500, 17312, 2715, 11, 291, 611, 483, 281, 747, 257, 574, 412, 437, 2314, 562, 291, 853, 51722, 51722], "temperature": 0.0, "avg_logprob": -0.10874335289001465, "compression_ratio": 1.689516129032258, "no_speech_prob": 7.4111148933297954e-06}, {"id": 109, "seek": 51912, "start": 541.84, "end": 546.28, "text": " In the upcoming optional lab, you also get to take a look at what happens when you try", "tokens": [50364, 3146, 264, 636, 11, 472, 551, 13181, 466, 264, 1315, 3565, 3142, 24590, 307, 300, 754, 1673, 50642, 50642, 309, 575, 264, 1349, 24590, 294, 309, 11, 309, 311, 767, 1143, 337, 21538, 13, 50892, 50892, 1468, 380, 312, 9019, 538, 264, 1315, 11, 597, 390, 2212, 337, 8584, 4112, 13, 51104, 51104, 467, 311, 767, 1143, 281, 5039, 17434, 21538, 2740, 689, 264, 5598, 7645, 288, 307, 2139, 51360, 51360, 1958, 420, 502, 13, 51500, 51500, 682, 264, 11500, 17312, 2715, 11, 291, 611, 483, 281, 747, 257, 574, 412, 437, 2314, 562, 291, 853, 51722, 51722], "temperature": 0.0, "avg_logprob": -0.10874335289001465, "compression_ratio": 1.689516129032258, "no_speech_prob": 7.4111148933297954e-06}, {"id": 110, "seek": 54628, "start": 546.28, "end": 551.24, "text": " to use linear regression for classification.", "tokens": [50364, 281, 764, 8213, 24590, 337, 21538, 13, 50612, 50612, 4803, 291, 483, 6356, 293, 309, 815, 589, 11, 457, 2049, 309, 486, 406, 589, 731, 11, 597, 307, 983, 50908, 50908, 286, 500, 380, 764, 8213, 24590, 2059, 337, 21538, 13, 51140, 51140, 682, 264, 17312, 2715, 11, 291, 536, 364, 15141, 7542, 300, 15257, 281, 33872, 1296, 732, 51376, 51376, 10479, 11, 293, 291, 4696, 3449, 577, 341, 2049, 1177, 380, 589, 588, 731, 11, 597, 307, 1392, 11, 51732, 51732], "temperature": 0.0, "avg_logprob": -0.11734191576639812, "compression_ratio": 1.7345971563981042, "no_speech_prob": 7.88915258453926e-06}, {"id": 111, "seek": 54628, "start": 551.24, "end": 557.16, "text": " Sometimes you get lucky and it may work, but often it will not work well, which is why", "tokens": [50364, 281, 764, 8213, 24590, 337, 21538, 13, 50612, 50612, 4803, 291, 483, 6356, 293, 309, 815, 589, 11, 457, 2049, 309, 486, 406, 589, 731, 11, 597, 307, 983, 50908, 50908, 286, 500, 380, 764, 8213, 24590, 2059, 337, 21538, 13, 51140, 51140, 682, 264, 17312, 2715, 11, 291, 536, 364, 15141, 7542, 300, 15257, 281, 33872, 1296, 732, 51376, 51376, 10479, 11, 293, 291, 4696, 3449, 577, 341, 2049, 1177, 380, 589, 588, 731, 11, 597, 307, 1392, 11, 51732, 51732], "temperature": 0.0, "avg_logprob": -0.11734191576639812, "compression_ratio": 1.7345971563981042, "no_speech_prob": 7.88915258453926e-06}, {"id": 112, "seek": 54628, "start": 557.16, "end": 561.8, "text": " I don't use linear regression myself for classification.", "tokens": [50364, 281, 764, 8213, 24590, 337, 21538, 13, 50612, 50612, 4803, 291, 483, 6356, 293, 309, 815, 589, 11, 457, 2049, 309, 486, 406, 589, 731, 11, 597, 307, 983, 50908, 50908, 286, 500, 380, 764, 8213, 24590, 2059, 337, 21538, 13, 51140, 51140, 682, 264, 17312, 2715, 11, 291, 536, 364, 15141, 7542, 300, 15257, 281, 33872, 1296, 732, 51376, 51376, 10479, 11, 293, 291, 4696, 3449, 577, 341, 2049, 1177, 380, 589, 588, 731, 11, 597, 307, 1392, 11, 51732, 51732], "temperature": 0.0, "avg_logprob": -0.11734191576639812, "compression_ratio": 1.7345971563981042, "no_speech_prob": 7.88915258453926e-06}, {"id": 113, "seek": 54628, "start": 561.8, "end": 566.52, "text": " In the optional lab, you see an interactive plot that attempts to classify between two", "tokens": [50364, 281, 764, 8213, 24590, 337, 21538, 13, 50612, 50612, 4803, 291, 483, 6356, 293, 309, 815, 589, 11, 457, 2049, 309, 486, 406, 589, 731, 11, 597, 307, 983, 50908, 50908, 286, 500, 380, 764, 8213, 24590, 2059, 337, 21538, 13, 51140, 51140, 682, 264, 17312, 2715, 11, 291, 536, 364, 15141, 7542, 300, 15257, 281, 33872, 1296, 732, 51376, 51376, 10479, 11, 293, 291, 4696, 3449, 577, 341, 2049, 1177, 380, 589, 588, 731, 11, 597, 307, 1392, 11, 51732, 51732], "temperature": 0.0, "avg_logprob": -0.11734191576639812, "compression_ratio": 1.7345971563981042, "no_speech_prob": 7.88915258453926e-06}, {"id": 114, "seek": 54628, "start": 566.52, "end": 573.64, "text": " categories, and you hopefully notice how this often doesn't work very well, which is okay,", "tokens": [50364, 281, 764, 8213, 24590, 337, 21538, 13, 50612, 50612, 4803, 291, 483, 6356, 293, 309, 815, 589, 11, 457, 2049, 309, 486, 406, 589, 731, 11, 597, 307, 983, 50908, 50908, 286, 500, 380, 764, 8213, 24590, 2059, 337, 21538, 13, 51140, 51140, 682, 264, 17312, 2715, 11, 291, 536, 364, 15141, 7542, 300, 15257, 281, 33872, 1296, 732, 51376, 51376, 10479, 11, 293, 291, 4696, 3449, 577, 341, 2049, 1177, 380, 589, 588, 731, 11, 597, 307, 1392, 11, 51732, 51732], "temperature": 0.0, "avg_logprob": -0.11734191576639812, "compression_ratio": 1.7345971563981042, "no_speech_prob": 7.88915258453926e-06}, {"id": 115, "seek": 57364, "start": 573.64, "end": 578.6, "text": " because that motivates the need for a different model to do classification tasks.", "tokens": [50364, 570, 300, 42569, 264, 643, 337, 257, 819, 2316, 281, 360, 21538, 9608, 13, 50612, 50612, 407, 1767, 1520, 484, 341, 17312, 2715, 11, 293, 934, 300, 11, 321, 603, 352, 322, 281, 264, 958, 960, 50874, 50874, 281, 574, 412, 3565, 3142, 24590, 337, 21538, 13, 51012], "temperature": 0.0, "avg_logprob": -0.151566219329834, "compression_ratio": 1.4761904761904763, "no_speech_prob": 2.387796666880604e-05}, {"id": 116, "seek": 57364, "start": 578.6, "end": 583.84, "text": " So please check out this optional lab, and after that, we'll go on to the next video", "tokens": [50364, 570, 300, 42569, 264, 643, 337, 257, 819, 2316, 281, 360, 21538, 9608, 13, 50612, 50612, 407, 1767, 1520, 484, 341, 17312, 2715, 11, 293, 934, 300, 11, 321, 603, 352, 322, 281, 264, 958, 960, 50874, 50874, 281, 574, 412, 3565, 3142, 24590, 337, 21538, 13, 51012], "temperature": 0.0, "avg_logprob": -0.151566219329834, "compression_ratio": 1.4761904761904763, "no_speech_prob": 2.387796666880604e-05}, {"id": 117, "seek": 58384, "start": 583.84, "end": 604.24, "text": " to look at logistic regression for classification.", "tokens": [50364, 281, 574, 412, 3565, 3142, 24590, 337, 21538, 13, 51384], "temperature": 0.0, "avg_logprob": -0.43206433455149335, "compression_ratio": 0.9259259259259259, "no_speech_prob": 5.583712663792539e-06}], "language": "en", "video_id": "wul3SmrpAeY", "entity": "ML Specialization, Andrew Ng (2022)"}}