{"video_id": "Q3cLU1trK_E", "title": "4.9 TensorFlow implementation | Data in TensorFlow --[Machine Learning | Andrew Ng]", "description": "Second Course:\nAdvanced Learning Algorithms.\n\n\nIf you liked the content please subscribe and put a little blue thumb.\nTake heart!", "author": "Machine Learning", "keywords": [], "channel_url": "https://www.youtube.com/channel/UClG5HEAJJFOavT_UolqYROQ", "length": 679, "views": 126, "publish_date": "11/04/2022", "timestamp": 1661385600, "entity": "ML Specialization, Andrew Ng (2022)", "transcript": {"text": " In this video, I want to step through with you how data is represented in NumPy and IntensiveLow so that as you're implementing new neural networks, you can have a consistent framework to think about how to represent your data. One of the unfortunate things about the way things are done in code today is that many, many years ago, NumPy was first created and became a standard library for linear algebra in Python. And then much later, the Google Brain team, the team that I had started and once led, created TensorFlow. And so unfortunately, there are some inconsistencies between how data is represented in NumPy and IntensiveLow. So it's good to be aware of these conventions so that you can implement correct code and hopefully get things running in your neural networks. Let's start by taking a look at how TensorFlow represents data. Let's say you have a data set like this from the coffee example. I mentioned that you would write x as follows. So why do you have this double square bracket here? Let's take a look at how NumPy stores vectors and matrices. In case you think matrices and vectors are complicated mathematical concepts, don't worry about it. We'll go through a few concrete examples and you'll be able to do everything you need to do with matrices and vectors in order to implement neural networks. Let's start with an example of a matrix. Here is a matrix with two rows and three columns. Notice that there are one, two rows and one, two, three columns. So we call this a two by three matrix. And so the convention is the dimension of the matrix is written as the number of rows by the number of columns. So in code to store this matrix, this two by three matrix, you just write x equals NP dot array of these numbers like these, where you notice that the square brackets tells you that one, two, three is the first row of this matrix and four, five, six is the second row of this matrix. And then this alphas square bracket groups the first and the second row together. So this says x to be this 2D array of numbers. So a matrix is just a 2D array of numbers. Let's look at one more example. Here I've written out another matrix. How many rows and how many columns does this have? Well we count this as one, two, three, four rows and it has one, two columns. So this is a number of rows by number of columns matrix. So it's a four by two matrix. And so to store this in code, you would write x equals NP dot array and then this syntax over here to store these four rows of a matrix in the variable x. So this creates a 2D array of these eight numbers. Matrices can have different dimensions. We saw an example of a two by three matrix and a four by two matrix. A matrix can also be other dimensions like one by two or two by one. And we'll see examples of these on the next slide. So what we did previously when setting x to be input feature vectors was set x to be equal to NP array with two square brackets 200 comma 17. And what that does is this creates a one by two matrix that is just one row and two columns. Let's look at a different example. If you were to define x to be NP array, but now written like this, this creates a two by one matrix that has two rows and one column. Because the first row is just a number 200 and the second row is just the number 17. And so this has the same numbers, but in a two by one instead of a one by two matrix. In nav, this example on top is also called a row vector. It's a vector that is just a single row. And this example is also called a column vector because it's a vector that just has a single column. And the difference between using double square brackets like this versus a single square bracket like this is that whereas the two examples on top are two D arrays where one of the dimensions happens to be one. This example results in a one D vector. So this is just a one D array that has no rows or columns. Although by convention, we may write x as a column like this. So on a contrast this with what we had previously done in the first course, which was to write x like this with a single square bracket. And that resulted in what's called in Python a one D vector instead of a two D matrix. And this technically is not one by two or two by one. It's just a linear array with no rows or no columns. And it's just a list of numbers. So whereas in course one, when we're working with linear regression, logistic regression, we use these one D vectors to represent the input features x. With TensorFlow, the convention is to use matrices to represent the data. And why is there this switch in conventions? Well, it turns out that TensorFlow was designed to handle very large datasets. And by representing the data in matrices instead of one D arrays, it lets TensorFlow be a bit more computationally efficient internally. So going back to our original example, for the first training example in this dataset with features 200 degrees Celsius in 17 minutes, we would represent it like this. And so this is actually a one by two matrix that happens to have one row and two columns to store the numbers 217. And in case this seems like a lot of details and really complicated conventions, don't worry about it. All this will become clearer. And you get to see the concrete implementations of the code yourself in the optional labs and in the practice labs. Going back to the code for carrying out for propagation or inference in the neural network, when you compute a one equals layer one applied to X, what is a one? Well, a one is actually going to be because there's three numbers is actually going to be a one by three matrix. And if you print out a one, you will get something like this is TF dot tensor point 2.7.3 is a shape of one by three, one three refers to that this is a one by three matrix. And this is TensorFlow's way of saying that this is a floating point number, meaning that it's a number that can have a decimal point represented using 32 bits of memory in your computer. That's what a float 32 is. And what is a tensor? A tensor here is a data type that the TensorFlow team had created in order to store and carry out computations on matrices efficiently. So whenever you see tensor, just think of it as matrix on these few slides. Technically a tensor is a little bit more general than the matrix, but for the purposes of this course, think of tensor as just a way of representing matrices. So remember I said at the start of this video that there's the TensorFlow way of representing a matrix and the NumPy way of representing matrix. This is an artifact of the history of how NumPy and TensorFlow were created. And unfortunately, there are two ways of representing a matrix that have been baked into these systems. And in fact, if you want to take a one, which is a tensor and want to convert it back to NumPy array, you can do so with this function a one dot NumPy and it will take the same data and return it in the form of a NumPy array rather than in the form of a TensorFlow array or TensorFlow matrix. Now let's take a look at what the activations output by the second layer would look like. Here's the code that we had from before. Layer two is a dense layer with one unit and a six point activation. And a two is computed by taking layer two and applying it to a one. So what is a two? A two may be a number like 0.8 and technically this is a one by one matrix. It's a 2D array with one row and one column. And so it's equal to this number 0.8. And if you print out a two, you see that it is a TensorFlow tensor with just one element, one number 0.8. And it is a one by one matrix. Again it is a flow 32 decimal point number taking up 32 bits in computer memory. Once again you can convert from a TensorFlow tensor to a NumPy matrix using a two dot NumPy and that will turn this back into a NumPy array that looks like this. So that hopefully gives you a sense of how data is represented in TensorFlow and in NumPy. I'm used to loading data and manipulating data in NumPy. But when you pass a NumPy array into TensorFlow, TensorFlow likes to convert it to its own internal format, the tensor, and then operate efficiently using tensors. And when you read the data back out, you can keep it as a tensor or convert it back to a NumPy array. I think it's a bit unfortunate that the history of how these libraries evolve has led us to do this extra conversion work when actually the two libraries can work quite well together. But when you convert back and forth, whether you're using a NumPy array or a tensor, it's just something to be aware of when you're writing code. Next, let's take what we've learned and put it together to actually build a neural network. Let's go see that in the next video.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 9.16, "text": " In this video, I want to step through with you how data is represented in NumPy and IntensiveLow", "tokens": [50364, 682, 341, 960, 11, 286, 528, 281, 1823, 807, 365, 291, 577, 1412, 307, 10379, 294, 22592, 47, 88, 293, 5681, 2953, 43, 305, 50822, 50822, 370, 300, 382, 291, 434, 18114, 777, 18161, 9590, 11, 291, 393, 362, 257, 8398, 8388, 51114, 51114, 281, 519, 466, 577, 281, 2906, 428, 1412, 13, 51294, 51294, 1485, 295, 264, 17843, 721, 466, 264, 636, 721, 366, 1096, 294, 3089, 965, 307, 300, 867, 11, 51530, 51530, 867, 924, 2057, 11, 22592, 47, 88, 390, 700, 2942, 293, 3062, 257, 3832, 6405, 337, 8213, 21989, 51802, 51802], "temperature": 0.0, "avg_logprob": -0.12778150420827963, "compression_ratio": 1.6095617529880477, "no_speech_prob": 0.02515357919037342}, {"id": 1, "seek": 0, "start": 9.16, "end": 15.0, "text": " so that as you're implementing new neural networks, you can have a consistent framework", "tokens": [50364, 682, 341, 960, 11, 286, 528, 281, 1823, 807, 365, 291, 577, 1412, 307, 10379, 294, 22592, 47, 88, 293, 5681, 2953, 43, 305, 50822, 50822, 370, 300, 382, 291, 434, 18114, 777, 18161, 9590, 11, 291, 393, 362, 257, 8398, 8388, 51114, 51114, 281, 519, 466, 577, 281, 2906, 428, 1412, 13, 51294, 51294, 1485, 295, 264, 17843, 721, 466, 264, 636, 721, 366, 1096, 294, 3089, 965, 307, 300, 867, 11, 51530, 51530, 867, 924, 2057, 11, 22592, 47, 88, 390, 700, 2942, 293, 3062, 257, 3832, 6405, 337, 8213, 21989, 51802, 51802], "temperature": 0.0, "avg_logprob": -0.12778150420827963, "compression_ratio": 1.6095617529880477, "no_speech_prob": 0.02515357919037342}, {"id": 2, "seek": 0, "start": 15.0, "end": 18.6, "text": " to think about how to represent your data.", "tokens": [50364, 682, 341, 960, 11, 286, 528, 281, 1823, 807, 365, 291, 577, 1412, 307, 10379, 294, 22592, 47, 88, 293, 5681, 2953, 43, 305, 50822, 50822, 370, 300, 382, 291, 434, 18114, 777, 18161, 9590, 11, 291, 393, 362, 257, 8398, 8388, 51114, 51114, 281, 519, 466, 577, 281, 2906, 428, 1412, 13, 51294, 51294, 1485, 295, 264, 17843, 721, 466, 264, 636, 721, 366, 1096, 294, 3089, 965, 307, 300, 867, 11, 51530, 51530, 867, 924, 2057, 11, 22592, 47, 88, 390, 700, 2942, 293, 3062, 257, 3832, 6405, 337, 8213, 21989, 51802, 51802], "temperature": 0.0, "avg_logprob": -0.12778150420827963, "compression_ratio": 1.6095617529880477, "no_speech_prob": 0.02515357919037342}, {"id": 3, "seek": 0, "start": 18.6, "end": 23.32, "text": " One of the unfortunate things about the way things are done in code today is that many,", "tokens": [50364, 682, 341, 960, 11, 286, 528, 281, 1823, 807, 365, 291, 577, 1412, 307, 10379, 294, 22592, 47, 88, 293, 5681, 2953, 43, 305, 50822, 50822, 370, 300, 382, 291, 434, 18114, 777, 18161, 9590, 11, 291, 393, 362, 257, 8398, 8388, 51114, 51114, 281, 519, 466, 577, 281, 2906, 428, 1412, 13, 51294, 51294, 1485, 295, 264, 17843, 721, 466, 264, 636, 721, 366, 1096, 294, 3089, 965, 307, 300, 867, 11, 51530, 51530, 867, 924, 2057, 11, 22592, 47, 88, 390, 700, 2942, 293, 3062, 257, 3832, 6405, 337, 8213, 21989, 51802, 51802], "temperature": 0.0, "avg_logprob": -0.12778150420827963, "compression_ratio": 1.6095617529880477, "no_speech_prob": 0.02515357919037342}, {"id": 4, "seek": 0, "start": 23.32, "end": 28.76, "text": " many years ago, NumPy was first created and became a standard library for linear algebra", "tokens": [50364, 682, 341, 960, 11, 286, 528, 281, 1823, 807, 365, 291, 577, 1412, 307, 10379, 294, 22592, 47, 88, 293, 5681, 2953, 43, 305, 50822, 50822, 370, 300, 382, 291, 434, 18114, 777, 18161, 9590, 11, 291, 393, 362, 257, 8398, 8388, 51114, 51114, 281, 519, 466, 577, 281, 2906, 428, 1412, 13, 51294, 51294, 1485, 295, 264, 17843, 721, 466, 264, 636, 721, 366, 1096, 294, 3089, 965, 307, 300, 867, 11, 51530, 51530, 867, 924, 2057, 11, 22592, 47, 88, 390, 700, 2942, 293, 3062, 257, 3832, 6405, 337, 8213, 21989, 51802, 51802], "temperature": 0.0, "avg_logprob": -0.12778150420827963, "compression_ratio": 1.6095617529880477, "no_speech_prob": 0.02515357919037342}, {"id": 5, "seek": 2876, "start": 28.76, "end": 30.080000000000002, "text": " in Python.", "tokens": [50364, 294, 15329, 13, 50430, 50430, 400, 550, 709, 1780, 11, 264, 3329, 29783, 1469, 11, 264, 1469, 300, 286, 632, 1409, 293, 1564, 4684, 11, 50682, 50682, 2942, 37624, 13, 50756, 50756, 400, 370, 7015, 11, 456, 366, 512, 22039, 4821, 4629, 1296, 577, 1412, 307, 10379, 294, 22592, 47, 88, 293, 51054, 51054, 5681, 2953, 43, 305, 13, 51134, 51134, 407, 309, 311, 665, 281, 312, 3650, 295, 613, 33520, 370, 300, 291, 393, 4445, 3006, 3089, 293, 51386, 51386, 4696, 483, 721, 2614, 294, 428, 18161, 9590, 13, 51550, 51550, 961, 311, 722, 538, 1940, 257, 574, 412, 577, 37624, 8855, 1412, 13, 51768, 51768], "temperature": 0.0, "avg_logprob": -0.13535644811227782, "compression_ratio": 1.599264705882353, "no_speech_prob": 5.4742191423429176e-05}, {"id": 6, "seek": 2876, "start": 30.080000000000002, "end": 35.120000000000005, "text": " And then much later, the Google Brain team, the team that I had started and once led,", "tokens": [50364, 294, 15329, 13, 50430, 50430, 400, 550, 709, 1780, 11, 264, 3329, 29783, 1469, 11, 264, 1469, 300, 286, 632, 1409, 293, 1564, 4684, 11, 50682, 50682, 2942, 37624, 13, 50756, 50756, 400, 370, 7015, 11, 456, 366, 512, 22039, 4821, 4629, 1296, 577, 1412, 307, 10379, 294, 22592, 47, 88, 293, 51054, 51054, 5681, 2953, 43, 305, 13, 51134, 51134, 407, 309, 311, 665, 281, 312, 3650, 295, 613, 33520, 370, 300, 291, 393, 4445, 3006, 3089, 293, 51386, 51386, 4696, 483, 721, 2614, 294, 428, 18161, 9590, 13, 51550, 51550, 961, 311, 722, 538, 1940, 257, 574, 412, 577, 37624, 8855, 1412, 13, 51768, 51768], "temperature": 0.0, "avg_logprob": -0.13535644811227782, "compression_ratio": 1.599264705882353, "no_speech_prob": 5.4742191423429176e-05}, {"id": 7, "seek": 2876, "start": 35.120000000000005, "end": 36.6, "text": " created TensorFlow.", "tokens": [50364, 294, 15329, 13, 50430, 50430, 400, 550, 709, 1780, 11, 264, 3329, 29783, 1469, 11, 264, 1469, 300, 286, 632, 1409, 293, 1564, 4684, 11, 50682, 50682, 2942, 37624, 13, 50756, 50756, 400, 370, 7015, 11, 456, 366, 512, 22039, 4821, 4629, 1296, 577, 1412, 307, 10379, 294, 22592, 47, 88, 293, 51054, 51054, 5681, 2953, 43, 305, 13, 51134, 51134, 407, 309, 311, 665, 281, 312, 3650, 295, 613, 33520, 370, 300, 291, 393, 4445, 3006, 3089, 293, 51386, 51386, 4696, 483, 721, 2614, 294, 428, 18161, 9590, 13, 51550, 51550, 961, 311, 722, 538, 1940, 257, 574, 412, 577, 37624, 8855, 1412, 13, 51768, 51768], "temperature": 0.0, "avg_logprob": -0.13535644811227782, "compression_ratio": 1.599264705882353, "no_speech_prob": 5.4742191423429176e-05}, {"id": 8, "seek": 2876, "start": 36.6, "end": 42.56, "text": " And so unfortunately, there are some inconsistencies between how data is represented in NumPy and", "tokens": [50364, 294, 15329, 13, 50430, 50430, 400, 550, 709, 1780, 11, 264, 3329, 29783, 1469, 11, 264, 1469, 300, 286, 632, 1409, 293, 1564, 4684, 11, 50682, 50682, 2942, 37624, 13, 50756, 50756, 400, 370, 7015, 11, 456, 366, 512, 22039, 4821, 4629, 1296, 577, 1412, 307, 10379, 294, 22592, 47, 88, 293, 51054, 51054, 5681, 2953, 43, 305, 13, 51134, 51134, 407, 309, 311, 665, 281, 312, 3650, 295, 613, 33520, 370, 300, 291, 393, 4445, 3006, 3089, 293, 51386, 51386, 4696, 483, 721, 2614, 294, 428, 18161, 9590, 13, 51550, 51550, 961, 311, 722, 538, 1940, 257, 574, 412, 577, 37624, 8855, 1412, 13, 51768, 51768], "temperature": 0.0, "avg_logprob": -0.13535644811227782, "compression_ratio": 1.599264705882353, "no_speech_prob": 5.4742191423429176e-05}, {"id": 9, "seek": 2876, "start": 42.56, "end": 44.160000000000004, "text": " IntensiveLow.", "tokens": [50364, 294, 15329, 13, 50430, 50430, 400, 550, 709, 1780, 11, 264, 3329, 29783, 1469, 11, 264, 1469, 300, 286, 632, 1409, 293, 1564, 4684, 11, 50682, 50682, 2942, 37624, 13, 50756, 50756, 400, 370, 7015, 11, 456, 366, 512, 22039, 4821, 4629, 1296, 577, 1412, 307, 10379, 294, 22592, 47, 88, 293, 51054, 51054, 5681, 2953, 43, 305, 13, 51134, 51134, 407, 309, 311, 665, 281, 312, 3650, 295, 613, 33520, 370, 300, 291, 393, 4445, 3006, 3089, 293, 51386, 51386, 4696, 483, 721, 2614, 294, 428, 18161, 9590, 13, 51550, 51550, 961, 311, 722, 538, 1940, 257, 574, 412, 577, 37624, 8855, 1412, 13, 51768, 51768], "temperature": 0.0, "avg_logprob": -0.13535644811227782, "compression_ratio": 1.599264705882353, "no_speech_prob": 5.4742191423429176e-05}, {"id": 10, "seek": 2876, "start": 44.160000000000004, "end": 49.2, "text": " So it's good to be aware of these conventions so that you can implement correct code and", "tokens": [50364, 294, 15329, 13, 50430, 50430, 400, 550, 709, 1780, 11, 264, 3329, 29783, 1469, 11, 264, 1469, 300, 286, 632, 1409, 293, 1564, 4684, 11, 50682, 50682, 2942, 37624, 13, 50756, 50756, 400, 370, 7015, 11, 456, 366, 512, 22039, 4821, 4629, 1296, 577, 1412, 307, 10379, 294, 22592, 47, 88, 293, 51054, 51054, 5681, 2953, 43, 305, 13, 51134, 51134, 407, 309, 311, 665, 281, 312, 3650, 295, 613, 33520, 370, 300, 291, 393, 4445, 3006, 3089, 293, 51386, 51386, 4696, 483, 721, 2614, 294, 428, 18161, 9590, 13, 51550, 51550, 961, 311, 722, 538, 1940, 257, 574, 412, 577, 37624, 8855, 1412, 13, 51768, 51768], "temperature": 0.0, "avg_logprob": -0.13535644811227782, "compression_ratio": 1.599264705882353, "no_speech_prob": 5.4742191423429176e-05}, {"id": 11, "seek": 2876, "start": 49.2, "end": 52.480000000000004, "text": " hopefully get things running in your neural networks.", "tokens": [50364, 294, 15329, 13, 50430, 50430, 400, 550, 709, 1780, 11, 264, 3329, 29783, 1469, 11, 264, 1469, 300, 286, 632, 1409, 293, 1564, 4684, 11, 50682, 50682, 2942, 37624, 13, 50756, 50756, 400, 370, 7015, 11, 456, 366, 512, 22039, 4821, 4629, 1296, 577, 1412, 307, 10379, 294, 22592, 47, 88, 293, 51054, 51054, 5681, 2953, 43, 305, 13, 51134, 51134, 407, 309, 311, 665, 281, 312, 3650, 295, 613, 33520, 370, 300, 291, 393, 4445, 3006, 3089, 293, 51386, 51386, 4696, 483, 721, 2614, 294, 428, 18161, 9590, 13, 51550, 51550, 961, 311, 722, 538, 1940, 257, 574, 412, 577, 37624, 8855, 1412, 13, 51768, 51768], "temperature": 0.0, "avg_logprob": -0.13535644811227782, "compression_ratio": 1.599264705882353, "no_speech_prob": 5.4742191423429176e-05}, {"id": 12, "seek": 2876, "start": 52.480000000000004, "end": 56.84, "text": " Let's start by taking a look at how TensorFlow represents data.", "tokens": [50364, 294, 15329, 13, 50430, 50430, 400, 550, 709, 1780, 11, 264, 3329, 29783, 1469, 11, 264, 1469, 300, 286, 632, 1409, 293, 1564, 4684, 11, 50682, 50682, 2942, 37624, 13, 50756, 50756, 400, 370, 7015, 11, 456, 366, 512, 22039, 4821, 4629, 1296, 577, 1412, 307, 10379, 294, 22592, 47, 88, 293, 51054, 51054, 5681, 2953, 43, 305, 13, 51134, 51134, 407, 309, 311, 665, 281, 312, 3650, 295, 613, 33520, 370, 300, 291, 393, 4445, 3006, 3089, 293, 51386, 51386, 4696, 483, 721, 2614, 294, 428, 18161, 9590, 13, 51550, 51550, 961, 311, 722, 538, 1940, 257, 574, 412, 577, 37624, 8855, 1412, 13, 51768, 51768], "temperature": 0.0, "avg_logprob": -0.13535644811227782, "compression_ratio": 1.599264705882353, "no_speech_prob": 5.4742191423429176e-05}, {"id": 13, "seek": 5684, "start": 56.84, "end": 61.88, "text": " Let's say you have a data set like this from the coffee example.", "tokens": [50364, 961, 311, 584, 291, 362, 257, 1412, 992, 411, 341, 490, 264, 4982, 1365, 13, 50616, 50616, 286, 2835, 300, 291, 576, 2464, 2031, 382, 10002, 13, 50826, 50826, 407, 983, 360, 291, 362, 341, 3834, 3732, 16904, 510, 30, 51080, 51080, 961, 311, 747, 257, 574, 412, 577, 22592, 47, 88, 9512, 18875, 293, 32284, 13, 51376, 51376, 682, 1389, 291, 519, 32284, 293, 18875, 366, 6179, 18894, 10392, 11, 500, 380, 3292, 51678, 51678, 466, 309, 13, 51728, 51728], "temperature": 0.0, "avg_logprob": -0.09110661587083196, "compression_ratio": 1.5235849056603774, "no_speech_prob": 7.411109891108936e-06}, {"id": 14, "seek": 5684, "start": 61.88, "end": 66.08, "text": " I mentioned that you would write x as follows.", "tokens": [50364, 961, 311, 584, 291, 362, 257, 1412, 992, 411, 341, 490, 264, 4982, 1365, 13, 50616, 50616, 286, 2835, 300, 291, 576, 2464, 2031, 382, 10002, 13, 50826, 50826, 407, 983, 360, 291, 362, 341, 3834, 3732, 16904, 510, 30, 51080, 51080, 961, 311, 747, 257, 574, 412, 577, 22592, 47, 88, 9512, 18875, 293, 32284, 13, 51376, 51376, 682, 1389, 291, 519, 32284, 293, 18875, 366, 6179, 18894, 10392, 11, 500, 380, 3292, 51678, 51678, 466, 309, 13, 51728, 51728], "temperature": 0.0, "avg_logprob": -0.09110661587083196, "compression_ratio": 1.5235849056603774, "no_speech_prob": 7.411109891108936e-06}, {"id": 15, "seek": 5684, "start": 66.08, "end": 71.16, "text": " So why do you have this double square bracket here?", "tokens": [50364, 961, 311, 584, 291, 362, 257, 1412, 992, 411, 341, 490, 264, 4982, 1365, 13, 50616, 50616, 286, 2835, 300, 291, 576, 2464, 2031, 382, 10002, 13, 50826, 50826, 407, 983, 360, 291, 362, 341, 3834, 3732, 16904, 510, 30, 51080, 51080, 961, 311, 747, 257, 574, 412, 577, 22592, 47, 88, 9512, 18875, 293, 32284, 13, 51376, 51376, 682, 1389, 291, 519, 32284, 293, 18875, 366, 6179, 18894, 10392, 11, 500, 380, 3292, 51678, 51678, 466, 309, 13, 51728, 51728], "temperature": 0.0, "avg_logprob": -0.09110661587083196, "compression_ratio": 1.5235849056603774, "no_speech_prob": 7.411109891108936e-06}, {"id": 16, "seek": 5684, "start": 71.16, "end": 77.08000000000001, "text": " Let's take a look at how NumPy stores vectors and matrices.", "tokens": [50364, 961, 311, 584, 291, 362, 257, 1412, 992, 411, 341, 490, 264, 4982, 1365, 13, 50616, 50616, 286, 2835, 300, 291, 576, 2464, 2031, 382, 10002, 13, 50826, 50826, 407, 983, 360, 291, 362, 341, 3834, 3732, 16904, 510, 30, 51080, 51080, 961, 311, 747, 257, 574, 412, 577, 22592, 47, 88, 9512, 18875, 293, 32284, 13, 51376, 51376, 682, 1389, 291, 519, 32284, 293, 18875, 366, 6179, 18894, 10392, 11, 500, 380, 3292, 51678, 51678, 466, 309, 13, 51728, 51728], "temperature": 0.0, "avg_logprob": -0.09110661587083196, "compression_ratio": 1.5235849056603774, "no_speech_prob": 7.411109891108936e-06}, {"id": 17, "seek": 5684, "start": 77.08000000000001, "end": 83.12, "text": " In case you think matrices and vectors are complicated mathematical concepts, don't worry", "tokens": [50364, 961, 311, 584, 291, 362, 257, 1412, 992, 411, 341, 490, 264, 4982, 1365, 13, 50616, 50616, 286, 2835, 300, 291, 576, 2464, 2031, 382, 10002, 13, 50826, 50826, 407, 983, 360, 291, 362, 341, 3834, 3732, 16904, 510, 30, 51080, 51080, 961, 311, 747, 257, 574, 412, 577, 22592, 47, 88, 9512, 18875, 293, 32284, 13, 51376, 51376, 682, 1389, 291, 519, 32284, 293, 18875, 366, 6179, 18894, 10392, 11, 500, 380, 3292, 51678, 51678, 466, 309, 13, 51728, 51728], "temperature": 0.0, "avg_logprob": -0.09110661587083196, "compression_ratio": 1.5235849056603774, "no_speech_prob": 7.411109891108936e-06}, {"id": 18, "seek": 5684, "start": 83.12, "end": 84.12, "text": " about it.", "tokens": [50364, 961, 311, 584, 291, 362, 257, 1412, 992, 411, 341, 490, 264, 4982, 1365, 13, 50616, 50616, 286, 2835, 300, 291, 576, 2464, 2031, 382, 10002, 13, 50826, 50826, 407, 983, 360, 291, 362, 341, 3834, 3732, 16904, 510, 30, 51080, 51080, 961, 311, 747, 257, 574, 412, 577, 22592, 47, 88, 9512, 18875, 293, 32284, 13, 51376, 51376, 682, 1389, 291, 519, 32284, 293, 18875, 366, 6179, 18894, 10392, 11, 500, 380, 3292, 51678, 51678, 466, 309, 13, 51728, 51728], "temperature": 0.0, "avg_logprob": -0.09110661587083196, "compression_ratio": 1.5235849056603774, "no_speech_prob": 7.411109891108936e-06}, {"id": 19, "seek": 8412, "start": 84.12, "end": 88.88000000000001, "text": " We'll go through a few concrete examples and you'll be able to do everything you need to", "tokens": [50364, 492, 603, 352, 807, 257, 1326, 9859, 5110, 293, 291, 603, 312, 1075, 281, 360, 1203, 291, 643, 281, 50602, 50602, 360, 365, 32284, 293, 18875, 294, 1668, 281, 4445, 18161, 9590, 13, 50848, 50848, 961, 311, 722, 365, 364, 1365, 295, 257, 8141, 13, 51014, 51014, 1692, 307, 257, 8141, 365, 732, 13241, 293, 1045, 13766, 13, 51336, 51336, 13428, 300, 456, 366, 472, 11, 732, 13241, 293, 472, 11, 732, 11, 1045, 13766, 13, 51756, 51756], "temperature": 0.0, "avg_logprob": -0.10424914360046386, "compression_ratio": 1.6595744680851063, "no_speech_prob": 2.4060118448687717e-06}, {"id": 20, "seek": 8412, "start": 88.88000000000001, "end": 93.80000000000001, "text": " do with matrices and vectors in order to implement neural networks.", "tokens": [50364, 492, 603, 352, 807, 257, 1326, 9859, 5110, 293, 291, 603, 312, 1075, 281, 360, 1203, 291, 643, 281, 50602, 50602, 360, 365, 32284, 293, 18875, 294, 1668, 281, 4445, 18161, 9590, 13, 50848, 50848, 961, 311, 722, 365, 364, 1365, 295, 257, 8141, 13, 51014, 51014, 1692, 307, 257, 8141, 365, 732, 13241, 293, 1045, 13766, 13, 51336, 51336, 13428, 300, 456, 366, 472, 11, 732, 13241, 293, 472, 11, 732, 11, 1045, 13766, 13, 51756, 51756], "temperature": 0.0, "avg_logprob": -0.10424914360046386, "compression_ratio": 1.6595744680851063, "no_speech_prob": 2.4060118448687717e-06}, {"id": 21, "seek": 8412, "start": 93.80000000000001, "end": 97.12, "text": " Let's start with an example of a matrix.", "tokens": [50364, 492, 603, 352, 807, 257, 1326, 9859, 5110, 293, 291, 603, 312, 1075, 281, 360, 1203, 291, 643, 281, 50602, 50602, 360, 365, 32284, 293, 18875, 294, 1668, 281, 4445, 18161, 9590, 13, 50848, 50848, 961, 311, 722, 365, 364, 1365, 295, 257, 8141, 13, 51014, 51014, 1692, 307, 257, 8141, 365, 732, 13241, 293, 1045, 13766, 13, 51336, 51336, 13428, 300, 456, 366, 472, 11, 732, 13241, 293, 472, 11, 732, 11, 1045, 13766, 13, 51756, 51756], "temperature": 0.0, "avg_logprob": -0.10424914360046386, "compression_ratio": 1.6595744680851063, "no_speech_prob": 2.4060118448687717e-06}, {"id": 22, "seek": 8412, "start": 97.12, "end": 103.56, "text": " Here is a matrix with two rows and three columns.", "tokens": [50364, 492, 603, 352, 807, 257, 1326, 9859, 5110, 293, 291, 603, 312, 1075, 281, 360, 1203, 291, 643, 281, 50602, 50602, 360, 365, 32284, 293, 18875, 294, 1668, 281, 4445, 18161, 9590, 13, 50848, 50848, 961, 311, 722, 365, 364, 1365, 295, 257, 8141, 13, 51014, 51014, 1692, 307, 257, 8141, 365, 732, 13241, 293, 1045, 13766, 13, 51336, 51336, 13428, 300, 456, 366, 472, 11, 732, 13241, 293, 472, 11, 732, 11, 1045, 13766, 13, 51756, 51756], "temperature": 0.0, "avg_logprob": -0.10424914360046386, "compression_ratio": 1.6595744680851063, "no_speech_prob": 2.4060118448687717e-06}, {"id": 23, "seek": 8412, "start": 103.56, "end": 111.96000000000001, "text": " Notice that there are one, two rows and one, two, three columns.", "tokens": [50364, 492, 603, 352, 807, 257, 1326, 9859, 5110, 293, 291, 603, 312, 1075, 281, 360, 1203, 291, 643, 281, 50602, 50602, 360, 365, 32284, 293, 18875, 294, 1668, 281, 4445, 18161, 9590, 13, 50848, 50848, 961, 311, 722, 365, 364, 1365, 295, 257, 8141, 13, 51014, 51014, 1692, 307, 257, 8141, 365, 732, 13241, 293, 1045, 13766, 13, 51336, 51336, 13428, 300, 456, 366, 472, 11, 732, 13241, 293, 472, 11, 732, 11, 1045, 13766, 13, 51756, 51756], "temperature": 0.0, "avg_logprob": -0.10424914360046386, "compression_ratio": 1.6595744680851063, "no_speech_prob": 2.4060118448687717e-06}, {"id": 24, "seek": 11196, "start": 111.96, "end": 117.36, "text": " So we call this a two by three matrix.", "tokens": [50364, 407, 321, 818, 341, 257, 732, 538, 1045, 8141, 13, 50634, 50634, 400, 370, 264, 10286, 307, 264, 10139, 295, 264, 8141, 307, 3720, 382, 264, 1230, 295, 13241, 50964, 50964, 538, 264, 1230, 295, 13766, 13, 51074, 51074, 407, 294, 3089, 281, 3531, 341, 8141, 11, 341, 732, 538, 1045, 8141, 11, 291, 445, 2464, 2031, 6915, 38611, 51460, 51460], "temperature": 0.0, "avg_logprob": -0.19296544695657397, "compression_ratio": 1.6164383561643836, "no_speech_prob": 2.857243771359208e-06}, {"id": 25, "seek": 11196, "start": 117.36, "end": 123.96, "text": " And so the convention is the dimension of the matrix is written as the number of rows", "tokens": [50364, 407, 321, 818, 341, 257, 732, 538, 1045, 8141, 13, 50634, 50634, 400, 370, 264, 10286, 307, 264, 10139, 295, 264, 8141, 307, 3720, 382, 264, 1230, 295, 13241, 50964, 50964, 538, 264, 1230, 295, 13766, 13, 51074, 51074, 407, 294, 3089, 281, 3531, 341, 8141, 11, 341, 732, 538, 1045, 8141, 11, 291, 445, 2464, 2031, 6915, 38611, 51460, 51460], "temperature": 0.0, "avg_logprob": -0.19296544695657397, "compression_ratio": 1.6164383561643836, "no_speech_prob": 2.857243771359208e-06}, {"id": 26, "seek": 11196, "start": 123.96, "end": 126.16, "text": " by the number of columns.", "tokens": [50364, 407, 321, 818, 341, 257, 732, 538, 1045, 8141, 13, 50634, 50634, 400, 370, 264, 10286, 307, 264, 10139, 295, 264, 8141, 307, 3720, 382, 264, 1230, 295, 13241, 50964, 50964, 538, 264, 1230, 295, 13766, 13, 51074, 51074, 407, 294, 3089, 281, 3531, 341, 8141, 11, 341, 732, 538, 1045, 8141, 11, 291, 445, 2464, 2031, 6915, 38611, 51460, 51460], "temperature": 0.0, "avg_logprob": -0.19296544695657397, "compression_ratio": 1.6164383561643836, "no_speech_prob": 2.857243771359208e-06}, {"id": 27, "seek": 11196, "start": 126.16, "end": 133.88, "text": " So in code to store this matrix, this two by three matrix, you just write x equals NP", "tokens": [50364, 407, 321, 818, 341, 257, 732, 538, 1045, 8141, 13, 50634, 50634, 400, 370, 264, 10286, 307, 264, 10139, 295, 264, 8141, 307, 3720, 382, 264, 1230, 295, 13241, 50964, 50964, 538, 264, 1230, 295, 13766, 13, 51074, 51074, 407, 294, 3089, 281, 3531, 341, 8141, 11, 341, 732, 538, 1045, 8141, 11, 291, 445, 2464, 2031, 6915, 38611, 51460, 51460], "temperature": 0.0, "avg_logprob": -0.19296544695657397, "compression_ratio": 1.6164383561643836, "no_speech_prob": 2.857243771359208e-06}, {"id": 28, "seek": 13388, "start": 133.88, "end": 141.56, "text": " dot array of these numbers like these, where you notice that the square brackets tells", "tokens": [50364, 5893, 10225, 295, 613, 3547, 411, 613, 11, 689, 291, 3449, 300, 264, 3732, 26179, 5112, 50748, 50748, 291, 300, 472, 11, 732, 11, 1045, 307, 264, 700, 5386, 295, 341, 8141, 293, 1451, 11, 1732, 11, 2309, 307, 264, 51114, 51114, 1150, 5386, 295, 341, 8141, 13, 51270, 51270, 400, 550, 341, 419, 7485, 3732, 16904, 3935, 264, 700, 293, 264, 1150, 5386, 1214, 13, 51588, 51588], "temperature": 0.0, "avg_logprob": -0.18725118637084961, "compression_ratio": 1.8, "no_speech_prob": 1.0615704013616778e-05}, {"id": 29, "seek": 13388, "start": 141.56, "end": 148.88, "text": " you that one, two, three is the first row of this matrix and four, five, six is the", "tokens": [50364, 5893, 10225, 295, 613, 3547, 411, 613, 11, 689, 291, 3449, 300, 264, 3732, 26179, 5112, 50748, 50748, 291, 300, 472, 11, 732, 11, 1045, 307, 264, 700, 5386, 295, 341, 8141, 293, 1451, 11, 1732, 11, 2309, 307, 264, 51114, 51114, 1150, 5386, 295, 341, 8141, 13, 51270, 51270, 400, 550, 341, 419, 7485, 3732, 16904, 3935, 264, 700, 293, 264, 1150, 5386, 1214, 13, 51588, 51588], "temperature": 0.0, "avg_logprob": -0.18725118637084961, "compression_ratio": 1.8, "no_speech_prob": 1.0615704013616778e-05}, {"id": 30, "seek": 13388, "start": 148.88, "end": 152.0, "text": " second row of this matrix.", "tokens": [50364, 5893, 10225, 295, 613, 3547, 411, 613, 11, 689, 291, 3449, 300, 264, 3732, 26179, 5112, 50748, 50748, 291, 300, 472, 11, 732, 11, 1045, 307, 264, 700, 5386, 295, 341, 8141, 293, 1451, 11, 1732, 11, 2309, 307, 264, 51114, 51114, 1150, 5386, 295, 341, 8141, 13, 51270, 51270, 400, 550, 341, 419, 7485, 3732, 16904, 3935, 264, 700, 293, 264, 1150, 5386, 1214, 13, 51588, 51588], "temperature": 0.0, "avg_logprob": -0.18725118637084961, "compression_ratio": 1.8, "no_speech_prob": 1.0615704013616778e-05}, {"id": 31, "seek": 13388, "start": 152.0, "end": 158.35999999999999, "text": " And then this alphas square bracket groups the first and the second row together.", "tokens": [50364, 5893, 10225, 295, 613, 3547, 411, 613, 11, 689, 291, 3449, 300, 264, 3732, 26179, 5112, 50748, 50748, 291, 300, 472, 11, 732, 11, 1045, 307, 264, 700, 5386, 295, 341, 8141, 293, 1451, 11, 1732, 11, 2309, 307, 264, 51114, 51114, 1150, 5386, 295, 341, 8141, 13, 51270, 51270, 400, 550, 341, 419, 7485, 3732, 16904, 3935, 264, 700, 293, 264, 1150, 5386, 1214, 13, 51588, 51588], "temperature": 0.0, "avg_logprob": -0.18725118637084961, "compression_ratio": 1.8, "no_speech_prob": 1.0615704013616778e-05}, {"id": 32, "seek": 15836, "start": 158.36, "end": 163.92000000000002, "text": " So this says x to be this 2D array of numbers.", "tokens": [50364, 407, 341, 1619, 2031, 281, 312, 341, 568, 35, 10225, 295, 3547, 13, 50642, 50642, 407, 257, 8141, 307, 445, 257, 568, 35, 10225, 295, 3547, 13, 50888, 50888, 961, 311, 574, 412, 472, 544, 1365, 13, 51016, 51016, 1692, 286, 600, 3720, 484, 1071, 8141, 13, 51160, 51160, 1012, 867, 13241, 293, 577, 867, 13766, 775, 341, 362, 30, 51300, 51300, 1042, 321, 1207, 341, 382, 472, 11, 732, 11, 1045, 11, 1451, 13241, 293, 309, 575, 472, 11, 732, 13766, 13, 51732, 51732], "temperature": 0.0, "avg_logprob": -0.13985975857438712, "compression_ratio": 1.6, "no_speech_prob": 2.1233320239844033e-06}, {"id": 33, "seek": 15836, "start": 163.92000000000002, "end": 168.84, "text": " So a matrix is just a 2D array of numbers.", "tokens": [50364, 407, 341, 1619, 2031, 281, 312, 341, 568, 35, 10225, 295, 3547, 13, 50642, 50642, 407, 257, 8141, 307, 445, 257, 568, 35, 10225, 295, 3547, 13, 50888, 50888, 961, 311, 574, 412, 472, 544, 1365, 13, 51016, 51016, 1692, 286, 600, 3720, 484, 1071, 8141, 13, 51160, 51160, 1012, 867, 13241, 293, 577, 867, 13766, 775, 341, 362, 30, 51300, 51300, 1042, 321, 1207, 341, 382, 472, 11, 732, 11, 1045, 11, 1451, 13241, 293, 309, 575, 472, 11, 732, 13766, 13, 51732, 51732], "temperature": 0.0, "avg_logprob": -0.13985975857438712, "compression_ratio": 1.6, "no_speech_prob": 2.1233320239844033e-06}, {"id": 34, "seek": 15836, "start": 168.84, "end": 171.4, "text": " Let's look at one more example.", "tokens": [50364, 407, 341, 1619, 2031, 281, 312, 341, 568, 35, 10225, 295, 3547, 13, 50642, 50642, 407, 257, 8141, 307, 445, 257, 568, 35, 10225, 295, 3547, 13, 50888, 50888, 961, 311, 574, 412, 472, 544, 1365, 13, 51016, 51016, 1692, 286, 600, 3720, 484, 1071, 8141, 13, 51160, 51160, 1012, 867, 13241, 293, 577, 867, 13766, 775, 341, 362, 30, 51300, 51300, 1042, 321, 1207, 341, 382, 472, 11, 732, 11, 1045, 11, 1451, 13241, 293, 309, 575, 472, 11, 732, 13766, 13, 51732, 51732], "temperature": 0.0, "avg_logprob": -0.13985975857438712, "compression_ratio": 1.6, "no_speech_prob": 2.1233320239844033e-06}, {"id": 35, "seek": 15836, "start": 171.4, "end": 174.28, "text": " Here I've written out another matrix.", "tokens": [50364, 407, 341, 1619, 2031, 281, 312, 341, 568, 35, 10225, 295, 3547, 13, 50642, 50642, 407, 257, 8141, 307, 445, 257, 568, 35, 10225, 295, 3547, 13, 50888, 50888, 961, 311, 574, 412, 472, 544, 1365, 13, 51016, 51016, 1692, 286, 600, 3720, 484, 1071, 8141, 13, 51160, 51160, 1012, 867, 13241, 293, 577, 867, 13766, 775, 341, 362, 30, 51300, 51300, 1042, 321, 1207, 341, 382, 472, 11, 732, 11, 1045, 11, 1451, 13241, 293, 309, 575, 472, 11, 732, 13766, 13, 51732, 51732], "temperature": 0.0, "avg_logprob": -0.13985975857438712, "compression_ratio": 1.6, "no_speech_prob": 2.1233320239844033e-06}, {"id": 36, "seek": 15836, "start": 174.28, "end": 177.08, "text": " How many rows and how many columns does this have?", "tokens": [50364, 407, 341, 1619, 2031, 281, 312, 341, 568, 35, 10225, 295, 3547, 13, 50642, 50642, 407, 257, 8141, 307, 445, 257, 568, 35, 10225, 295, 3547, 13, 50888, 50888, 961, 311, 574, 412, 472, 544, 1365, 13, 51016, 51016, 1692, 286, 600, 3720, 484, 1071, 8141, 13, 51160, 51160, 1012, 867, 13241, 293, 577, 867, 13766, 775, 341, 362, 30, 51300, 51300, 1042, 321, 1207, 341, 382, 472, 11, 732, 11, 1045, 11, 1451, 13241, 293, 309, 575, 472, 11, 732, 13766, 13, 51732, 51732], "temperature": 0.0, "avg_logprob": -0.13985975857438712, "compression_ratio": 1.6, "no_speech_prob": 2.1233320239844033e-06}, {"id": 37, "seek": 15836, "start": 177.08, "end": 185.72000000000003, "text": " Well we count this as one, two, three, four rows and it has one, two columns.", "tokens": [50364, 407, 341, 1619, 2031, 281, 312, 341, 568, 35, 10225, 295, 3547, 13, 50642, 50642, 407, 257, 8141, 307, 445, 257, 568, 35, 10225, 295, 3547, 13, 50888, 50888, 961, 311, 574, 412, 472, 544, 1365, 13, 51016, 51016, 1692, 286, 600, 3720, 484, 1071, 8141, 13, 51160, 51160, 1012, 867, 13241, 293, 577, 867, 13766, 775, 341, 362, 30, 51300, 51300, 1042, 321, 1207, 341, 382, 472, 11, 732, 11, 1045, 11, 1451, 13241, 293, 309, 575, 472, 11, 732, 13766, 13, 51732, 51732], "temperature": 0.0, "avg_logprob": -0.13985975857438712, "compression_ratio": 1.6, "no_speech_prob": 2.1233320239844033e-06}, {"id": 38, "seek": 18572, "start": 185.72, "end": 190.06, "text": " So this is a number of rows by number of columns matrix.", "tokens": [50364, 407, 341, 307, 257, 1230, 295, 13241, 538, 1230, 295, 13766, 8141, 13, 50581, 50581, 407, 309, 311, 257, 1451, 538, 732, 8141, 13, 50708, 50708, 400, 370, 281, 3531, 341, 294, 3089, 11, 291, 576, 2464, 2031, 6915, 38611, 5893, 10225, 293, 550, 341, 28431, 51066, 51066, 670, 510, 281, 3531, 613, 1451, 13241, 295, 257, 8141, 294, 264, 7006, 2031, 13, 51353, 51353, 407, 341, 7829, 257, 568, 35, 10225, 295, 613, 3180, 3547, 13, 51628, 51628, 6789, 24373, 393, 362, 819, 12819, 13, 51737, 51737], "temperature": 0.0, "avg_logprob": -0.12106374104817709, "compression_ratio": 1.6116504854368932, "no_speech_prob": 3.393115321159712e-06}, {"id": 39, "seek": 18572, "start": 190.06, "end": 192.6, "text": " So it's a four by two matrix.", "tokens": [50364, 407, 341, 307, 257, 1230, 295, 13241, 538, 1230, 295, 13766, 8141, 13, 50581, 50581, 407, 309, 311, 257, 1451, 538, 732, 8141, 13, 50708, 50708, 400, 370, 281, 3531, 341, 294, 3089, 11, 291, 576, 2464, 2031, 6915, 38611, 5893, 10225, 293, 550, 341, 28431, 51066, 51066, 670, 510, 281, 3531, 613, 1451, 13241, 295, 257, 8141, 294, 264, 7006, 2031, 13, 51353, 51353, 407, 341, 7829, 257, 568, 35, 10225, 295, 613, 3180, 3547, 13, 51628, 51628, 6789, 24373, 393, 362, 819, 12819, 13, 51737, 51737], "temperature": 0.0, "avg_logprob": -0.12106374104817709, "compression_ratio": 1.6116504854368932, "no_speech_prob": 3.393115321159712e-06}, {"id": 40, "seek": 18572, "start": 192.6, "end": 199.76, "text": " And so to store this in code, you would write x equals NP dot array and then this syntax", "tokens": [50364, 407, 341, 307, 257, 1230, 295, 13241, 538, 1230, 295, 13766, 8141, 13, 50581, 50581, 407, 309, 311, 257, 1451, 538, 732, 8141, 13, 50708, 50708, 400, 370, 281, 3531, 341, 294, 3089, 11, 291, 576, 2464, 2031, 6915, 38611, 5893, 10225, 293, 550, 341, 28431, 51066, 51066, 670, 510, 281, 3531, 613, 1451, 13241, 295, 257, 8141, 294, 264, 7006, 2031, 13, 51353, 51353, 407, 341, 7829, 257, 568, 35, 10225, 295, 613, 3180, 3547, 13, 51628, 51628, 6789, 24373, 393, 362, 819, 12819, 13, 51737, 51737], "temperature": 0.0, "avg_logprob": -0.12106374104817709, "compression_ratio": 1.6116504854368932, "no_speech_prob": 3.393115321159712e-06}, {"id": 41, "seek": 18572, "start": 199.76, "end": 205.5, "text": " over here to store these four rows of a matrix in the variable x.", "tokens": [50364, 407, 341, 307, 257, 1230, 295, 13241, 538, 1230, 295, 13766, 8141, 13, 50581, 50581, 407, 309, 311, 257, 1451, 538, 732, 8141, 13, 50708, 50708, 400, 370, 281, 3531, 341, 294, 3089, 11, 291, 576, 2464, 2031, 6915, 38611, 5893, 10225, 293, 550, 341, 28431, 51066, 51066, 670, 510, 281, 3531, 613, 1451, 13241, 295, 257, 8141, 294, 264, 7006, 2031, 13, 51353, 51353, 407, 341, 7829, 257, 568, 35, 10225, 295, 613, 3180, 3547, 13, 51628, 51628, 6789, 24373, 393, 362, 819, 12819, 13, 51737, 51737], "temperature": 0.0, "avg_logprob": -0.12106374104817709, "compression_ratio": 1.6116504854368932, "no_speech_prob": 3.393115321159712e-06}, {"id": 42, "seek": 18572, "start": 205.5, "end": 211.0, "text": " So this creates a 2D array of these eight numbers.", "tokens": [50364, 407, 341, 307, 257, 1230, 295, 13241, 538, 1230, 295, 13766, 8141, 13, 50581, 50581, 407, 309, 311, 257, 1451, 538, 732, 8141, 13, 50708, 50708, 400, 370, 281, 3531, 341, 294, 3089, 11, 291, 576, 2464, 2031, 6915, 38611, 5893, 10225, 293, 550, 341, 28431, 51066, 51066, 670, 510, 281, 3531, 613, 1451, 13241, 295, 257, 8141, 294, 264, 7006, 2031, 13, 51353, 51353, 407, 341, 7829, 257, 568, 35, 10225, 295, 613, 3180, 3547, 13, 51628, 51628, 6789, 24373, 393, 362, 819, 12819, 13, 51737, 51737], "temperature": 0.0, "avg_logprob": -0.12106374104817709, "compression_ratio": 1.6116504854368932, "no_speech_prob": 3.393115321159712e-06}, {"id": 43, "seek": 18572, "start": 211.0, "end": 213.18, "text": " Matrices can have different dimensions.", "tokens": [50364, 407, 341, 307, 257, 1230, 295, 13241, 538, 1230, 295, 13766, 8141, 13, 50581, 50581, 407, 309, 311, 257, 1451, 538, 732, 8141, 13, 50708, 50708, 400, 370, 281, 3531, 341, 294, 3089, 11, 291, 576, 2464, 2031, 6915, 38611, 5893, 10225, 293, 550, 341, 28431, 51066, 51066, 670, 510, 281, 3531, 613, 1451, 13241, 295, 257, 8141, 294, 264, 7006, 2031, 13, 51353, 51353, 407, 341, 7829, 257, 568, 35, 10225, 295, 613, 3180, 3547, 13, 51628, 51628, 6789, 24373, 393, 362, 819, 12819, 13, 51737, 51737], "temperature": 0.0, "avg_logprob": -0.12106374104817709, "compression_ratio": 1.6116504854368932, "no_speech_prob": 3.393115321159712e-06}, {"id": 44, "seek": 21318, "start": 213.18, "end": 219.08, "text": " We saw an example of a two by three matrix and a four by two matrix.", "tokens": [50364, 492, 1866, 364, 1365, 295, 257, 732, 538, 1045, 8141, 293, 257, 1451, 538, 732, 8141, 13, 50659, 50659, 316, 8141, 393, 611, 312, 661, 12819, 411, 472, 538, 732, 420, 732, 538, 472, 13, 50997, 50997, 400, 321, 603, 536, 5110, 295, 613, 322, 264, 958, 4137, 13, 51173, 51173, 407, 437, 321, 630, 8046, 562, 3287, 2031, 281, 312, 4846, 4111, 18875, 390, 992, 2031, 281, 312, 2681, 51511, 51511, 281, 38611, 10225, 365, 732, 3732, 26179, 2331, 22117, 3282, 13, 51849, 51849], "temperature": 0.0, "avg_logprob": -0.094784550283147, "compression_ratio": 1.5639810426540284, "no_speech_prob": 5.5074228839657735e-06}, {"id": 45, "seek": 21318, "start": 219.08, "end": 225.84, "text": " A matrix can also be other dimensions like one by two or two by one.", "tokens": [50364, 492, 1866, 364, 1365, 295, 257, 732, 538, 1045, 8141, 293, 257, 1451, 538, 732, 8141, 13, 50659, 50659, 316, 8141, 393, 611, 312, 661, 12819, 411, 472, 538, 732, 420, 732, 538, 472, 13, 50997, 50997, 400, 321, 603, 536, 5110, 295, 613, 322, 264, 958, 4137, 13, 51173, 51173, 407, 437, 321, 630, 8046, 562, 3287, 2031, 281, 312, 4846, 4111, 18875, 390, 992, 2031, 281, 312, 2681, 51511, 51511, 281, 38611, 10225, 365, 732, 3732, 26179, 2331, 22117, 3282, 13, 51849, 51849], "temperature": 0.0, "avg_logprob": -0.094784550283147, "compression_ratio": 1.5639810426540284, "no_speech_prob": 5.5074228839657735e-06}, {"id": 46, "seek": 21318, "start": 225.84, "end": 229.36, "text": " And we'll see examples of these on the next slide.", "tokens": [50364, 492, 1866, 364, 1365, 295, 257, 732, 538, 1045, 8141, 293, 257, 1451, 538, 732, 8141, 13, 50659, 50659, 316, 8141, 393, 611, 312, 661, 12819, 411, 472, 538, 732, 420, 732, 538, 472, 13, 50997, 50997, 400, 321, 603, 536, 5110, 295, 613, 322, 264, 958, 4137, 13, 51173, 51173, 407, 437, 321, 630, 8046, 562, 3287, 2031, 281, 312, 4846, 4111, 18875, 390, 992, 2031, 281, 312, 2681, 51511, 51511, 281, 38611, 10225, 365, 732, 3732, 26179, 2331, 22117, 3282, 13, 51849, 51849], "temperature": 0.0, "avg_logprob": -0.094784550283147, "compression_ratio": 1.5639810426540284, "no_speech_prob": 5.5074228839657735e-06}, {"id": 47, "seek": 21318, "start": 229.36, "end": 236.12, "text": " So what we did previously when setting x to be input feature vectors was set x to be equal", "tokens": [50364, 492, 1866, 364, 1365, 295, 257, 732, 538, 1045, 8141, 293, 257, 1451, 538, 732, 8141, 13, 50659, 50659, 316, 8141, 393, 611, 312, 661, 12819, 411, 472, 538, 732, 420, 732, 538, 472, 13, 50997, 50997, 400, 321, 603, 536, 5110, 295, 613, 322, 264, 958, 4137, 13, 51173, 51173, 407, 437, 321, 630, 8046, 562, 3287, 2031, 281, 312, 4846, 4111, 18875, 390, 992, 2031, 281, 312, 2681, 51511, 51511, 281, 38611, 10225, 365, 732, 3732, 26179, 2331, 22117, 3282, 13, 51849, 51849], "temperature": 0.0, "avg_logprob": -0.094784550283147, "compression_ratio": 1.5639810426540284, "no_speech_prob": 5.5074228839657735e-06}, {"id": 48, "seek": 21318, "start": 236.12, "end": 242.88, "text": " to NP array with two square brackets 200 comma 17.", "tokens": [50364, 492, 1866, 364, 1365, 295, 257, 732, 538, 1045, 8141, 293, 257, 1451, 538, 732, 8141, 13, 50659, 50659, 316, 8141, 393, 611, 312, 661, 12819, 411, 472, 538, 732, 420, 732, 538, 472, 13, 50997, 50997, 400, 321, 603, 536, 5110, 295, 613, 322, 264, 958, 4137, 13, 51173, 51173, 407, 437, 321, 630, 8046, 562, 3287, 2031, 281, 312, 4846, 4111, 18875, 390, 992, 2031, 281, 312, 2681, 51511, 51511, 281, 38611, 10225, 365, 732, 3732, 26179, 2331, 22117, 3282, 13, 51849, 51849], "temperature": 0.0, "avg_logprob": -0.094784550283147, "compression_ratio": 1.5639810426540284, "no_speech_prob": 5.5074228839657735e-06}, {"id": 49, "seek": 24288, "start": 242.88, "end": 253.24, "text": " And what that does is this creates a one by two matrix that is just one row and two columns.", "tokens": [50364, 400, 437, 300, 775, 307, 341, 7829, 257, 472, 538, 732, 8141, 300, 307, 445, 472, 5386, 293, 732, 13766, 13, 50882, 50882, 961, 311, 574, 412, 257, 819, 1365, 13, 51012, 51012, 759, 291, 645, 281, 6964, 2031, 281, 312, 38611, 10225, 11, 457, 586, 3720, 411, 341, 11, 341, 7829, 257, 732, 51372, 51372, 538, 472, 8141, 300, 575, 732, 13241, 293, 472, 7738, 13, 51778, 51778], "temperature": 0.0, "avg_logprob": -0.08403964781425369, "compression_ratio": 1.5535714285714286, "no_speech_prob": 1.1478274245746434e-05}, {"id": 50, "seek": 24288, "start": 253.24, "end": 255.84, "text": " Let's look at a different example.", "tokens": [50364, 400, 437, 300, 775, 307, 341, 7829, 257, 472, 538, 732, 8141, 300, 307, 445, 472, 5386, 293, 732, 13766, 13, 50882, 50882, 961, 311, 574, 412, 257, 819, 1365, 13, 51012, 51012, 759, 291, 645, 281, 6964, 2031, 281, 312, 38611, 10225, 11, 457, 586, 3720, 411, 341, 11, 341, 7829, 257, 732, 51372, 51372, 538, 472, 8141, 300, 575, 732, 13241, 293, 472, 7738, 13, 51778, 51778], "temperature": 0.0, "avg_logprob": -0.08403964781425369, "compression_ratio": 1.5535714285714286, "no_speech_prob": 1.1478274245746434e-05}, {"id": 51, "seek": 24288, "start": 255.84, "end": 263.04, "text": " If you were to define x to be NP array, but now written like this, this creates a two", "tokens": [50364, 400, 437, 300, 775, 307, 341, 7829, 257, 472, 538, 732, 8141, 300, 307, 445, 472, 5386, 293, 732, 13766, 13, 50882, 50882, 961, 311, 574, 412, 257, 819, 1365, 13, 51012, 51012, 759, 291, 645, 281, 6964, 2031, 281, 312, 38611, 10225, 11, 457, 586, 3720, 411, 341, 11, 341, 7829, 257, 732, 51372, 51372, 538, 472, 8141, 300, 575, 732, 13241, 293, 472, 7738, 13, 51778, 51778], "temperature": 0.0, "avg_logprob": -0.08403964781425369, "compression_ratio": 1.5535714285714286, "no_speech_prob": 1.1478274245746434e-05}, {"id": 52, "seek": 24288, "start": 263.04, "end": 271.15999999999997, "text": " by one matrix that has two rows and one column.", "tokens": [50364, 400, 437, 300, 775, 307, 341, 7829, 257, 472, 538, 732, 8141, 300, 307, 445, 472, 5386, 293, 732, 13766, 13, 50882, 50882, 961, 311, 574, 412, 257, 819, 1365, 13, 51012, 51012, 759, 291, 645, 281, 6964, 2031, 281, 312, 38611, 10225, 11, 457, 586, 3720, 411, 341, 11, 341, 7829, 257, 732, 51372, 51372, 538, 472, 8141, 300, 575, 732, 13241, 293, 472, 7738, 13, 51778, 51778], "temperature": 0.0, "avg_logprob": -0.08403964781425369, "compression_ratio": 1.5535714285714286, "no_speech_prob": 1.1478274245746434e-05}, {"id": 53, "seek": 27116, "start": 271.16, "end": 279.08000000000004, "text": " Because the first row is just a number 200 and the second row is just the number 17.", "tokens": [50364, 1436, 264, 700, 5386, 307, 445, 257, 1230, 2331, 293, 264, 1150, 5386, 307, 445, 264, 1230, 3282, 13, 50760, 50760, 400, 370, 341, 575, 264, 912, 3547, 11, 457, 294, 257, 732, 538, 472, 2602, 295, 257, 472, 538, 732, 8141, 13, 51099, 51099, 682, 5947, 11, 341, 1365, 322, 1192, 307, 611, 1219, 257, 5386, 8062, 13, 51270, 51270, 467, 311, 257, 8062, 300, 307, 445, 257, 2167, 5386, 13, 51438, 51438, 400, 341, 1365, 307, 611, 1219, 257, 7738, 8062, 570, 309, 311, 257, 8062, 300, 445, 575, 257, 2167, 51686, 51686, 7738, 13, 51812, 51812], "temperature": 0.0, "avg_logprob": -0.14775503743993174, "compression_ratio": 1.8730964467005076, "no_speech_prob": 7.411113074340392e-06}, {"id": 54, "seek": 27116, "start": 279.08000000000004, "end": 285.86, "text": " And so this has the same numbers, but in a two by one instead of a one by two matrix.", "tokens": [50364, 1436, 264, 700, 5386, 307, 445, 257, 1230, 2331, 293, 264, 1150, 5386, 307, 445, 264, 1230, 3282, 13, 50760, 50760, 400, 370, 341, 575, 264, 912, 3547, 11, 457, 294, 257, 732, 538, 472, 2602, 295, 257, 472, 538, 732, 8141, 13, 51099, 51099, 682, 5947, 11, 341, 1365, 322, 1192, 307, 611, 1219, 257, 5386, 8062, 13, 51270, 51270, 467, 311, 257, 8062, 300, 307, 445, 257, 2167, 5386, 13, 51438, 51438, 400, 341, 1365, 307, 611, 1219, 257, 7738, 8062, 570, 309, 311, 257, 8062, 300, 445, 575, 257, 2167, 51686, 51686, 7738, 13, 51812, 51812], "temperature": 0.0, "avg_logprob": -0.14775503743993174, "compression_ratio": 1.8730964467005076, "no_speech_prob": 7.411113074340392e-06}, {"id": 55, "seek": 27116, "start": 285.86, "end": 289.28000000000003, "text": " In nav, this example on top is also called a row vector.", "tokens": [50364, 1436, 264, 700, 5386, 307, 445, 257, 1230, 2331, 293, 264, 1150, 5386, 307, 445, 264, 1230, 3282, 13, 50760, 50760, 400, 370, 341, 575, 264, 912, 3547, 11, 457, 294, 257, 732, 538, 472, 2602, 295, 257, 472, 538, 732, 8141, 13, 51099, 51099, 682, 5947, 11, 341, 1365, 322, 1192, 307, 611, 1219, 257, 5386, 8062, 13, 51270, 51270, 467, 311, 257, 8062, 300, 307, 445, 257, 2167, 5386, 13, 51438, 51438, 400, 341, 1365, 307, 611, 1219, 257, 7738, 8062, 570, 309, 311, 257, 8062, 300, 445, 575, 257, 2167, 51686, 51686, 7738, 13, 51812, 51812], "temperature": 0.0, "avg_logprob": -0.14775503743993174, "compression_ratio": 1.8730964467005076, "no_speech_prob": 7.411113074340392e-06}, {"id": 56, "seek": 27116, "start": 289.28000000000003, "end": 292.64000000000004, "text": " It's a vector that is just a single row.", "tokens": [50364, 1436, 264, 700, 5386, 307, 445, 257, 1230, 2331, 293, 264, 1150, 5386, 307, 445, 264, 1230, 3282, 13, 50760, 50760, 400, 370, 341, 575, 264, 912, 3547, 11, 457, 294, 257, 732, 538, 472, 2602, 295, 257, 472, 538, 732, 8141, 13, 51099, 51099, 682, 5947, 11, 341, 1365, 322, 1192, 307, 611, 1219, 257, 5386, 8062, 13, 51270, 51270, 467, 311, 257, 8062, 300, 307, 445, 257, 2167, 5386, 13, 51438, 51438, 400, 341, 1365, 307, 611, 1219, 257, 7738, 8062, 570, 309, 311, 257, 8062, 300, 445, 575, 257, 2167, 51686, 51686, 7738, 13, 51812, 51812], "temperature": 0.0, "avg_logprob": -0.14775503743993174, "compression_ratio": 1.8730964467005076, "no_speech_prob": 7.411113074340392e-06}, {"id": 57, "seek": 27116, "start": 292.64000000000004, "end": 297.6, "text": " And this example is also called a column vector because it's a vector that just has a single", "tokens": [50364, 1436, 264, 700, 5386, 307, 445, 257, 1230, 2331, 293, 264, 1150, 5386, 307, 445, 264, 1230, 3282, 13, 50760, 50760, 400, 370, 341, 575, 264, 912, 3547, 11, 457, 294, 257, 732, 538, 472, 2602, 295, 257, 472, 538, 732, 8141, 13, 51099, 51099, 682, 5947, 11, 341, 1365, 322, 1192, 307, 611, 1219, 257, 5386, 8062, 13, 51270, 51270, 467, 311, 257, 8062, 300, 307, 445, 257, 2167, 5386, 13, 51438, 51438, 400, 341, 1365, 307, 611, 1219, 257, 7738, 8062, 570, 309, 311, 257, 8062, 300, 445, 575, 257, 2167, 51686, 51686, 7738, 13, 51812, 51812], "temperature": 0.0, "avg_logprob": -0.14775503743993174, "compression_ratio": 1.8730964467005076, "no_speech_prob": 7.411113074340392e-06}, {"id": 58, "seek": 27116, "start": 297.6, "end": 300.12, "text": " column.", "tokens": [50364, 1436, 264, 700, 5386, 307, 445, 257, 1230, 2331, 293, 264, 1150, 5386, 307, 445, 264, 1230, 3282, 13, 50760, 50760, 400, 370, 341, 575, 264, 912, 3547, 11, 457, 294, 257, 732, 538, 472, 2602, 295, 257, 472, 538, 732, 8141, 13, 51099, 51099, 682, 5947, 11, 341, 1365, 322, 1192, 307, 611, 1219, 257, 5386, 8062, 13, 51270, 51270, 467, 311, 257, 8062, 300, 307, 445, 257, 2167, 5386, 13, 51438, 51438, 400, 341, 1365, 307, 611, 1219, 257, 7738, 8062, 570, 309, 311, 257, 8062, 300, 445, 575, 257, 2167, 51686, 51686, 7738, 13, 51812, 51812], "temperature": 0.0, "avg_logprob": -0.14775503743993174, "compression_ratio": 1.8730964467005076, "no_speech_prob": 7.411113074340392e-06}, {"id": 59, "seek": 30012, "start": 300.12, "end": 306.08, "text": " And the difference between using double square brackets like this versus a single square", "tokens": [50364, 400, 264, 2649, 1296, 1228, 3834, 3732, 26179, 411, 341, 5717, 257, 2167, 3732, 50662, 50662, 16904, 411, 341, 307, 300, 9735, 264, 732, 5110, 322, 1192, 366, 732, 413, 41011, 689, 472, 51076, 51076, 295, 264, 12819, 2314, 281, 312, 472, 13, 51254, 51254, 639, 1365, 3542, 294, 257, 472, 413, 8062, 13, 51474, 51474, 407, 341, 307, 445, 257, 472, 413, 10225, 300, 575, 572, 13241, 420, 13766, 13, 51782, 51782], "temperature": 0.0, "avg_logprob": -0.11936766306559245, "compression_ratio": 1.6524064171122994, "no_speech_prob": 6.643276719842106e-06}, {"id": 60, "seek": 30012, "start": 306.08, "end": 314.36, "text": " bracket like this is that whereas the two examples on top are two D arrays where one", "tokens": [50364, 400, 264, 2649, 1296, 1228, 3834, 3732, 26179, 411, 341, 5717, 257, 2167, 3732, 50662, 50662, 16904, 411, 341, 307, 300, 9735, 264, 732, 5110, 322, 1192, 366, 732, 413, 41011, 689, 472, 51076, 51076, 295, 264, 12819, 2314, 281, 312, 472, 13, 51254, 51254, 639, 1365, 3542, 294, 257, 472, 413, 8062, 13, 51474, 51474, 407, 341, 307, 445, 257, 472, 413, 10225, 300, 575, 572, 13241, 420, 13766, 13, 51782, 51782], "temperature": 0.0, "avg_logprob": -0.11936766306559245, "compression_ratio": 1.6524064171122994, "no_speech_prob": 6.643276719842106e-06}, {"id": 61, "seek": 30012, "start": 314.36, "end": 317.92, "text": " of the dimensions happens to be one.", "tokens": [50364, 400, 264, 2649, 1296, 1228, 3834, 3732, 26179, 411, 341, 5717, 257, 2167, 3732, 50662, 50662, 16904, 411, 341, 307, 300, 9735, 264, 732, 5110, 322, 1192, 366, 732, 413, 41011, 689, 472, 51076, 51076, 295, 264, 12819, 2314, 281, 312, 472, 13, 51254, 51254, 639, 1365, 3542, 294, 257, 472, 413, 8062, 13, 51474, 51474, 407, 341, 307, 445, 257, 472, 413, 10225, 300, 575, 572, 13241, 420, 13766, 13, 51782, 51782], "temperature": 0.0, "avg_logprob": -0.11936766306559245, "compression_ratio": 1.6524064171122994, "no_speech_prob": 6.643276719842106e-06}, {"id": 62, "seek": 30012, "start": 317.92, "end": 322.32, "text": " This example results in a one D vector.", "tokens": [50364, 400, 264, 2649, 1296, 1228, 3834, 3732, 26179, 411, 341, 5717, 257, 2167, 3732, 50662, 50662, 16904, 411, 341, 307, 300, 9735, 264, 732, 5110, 322, 1192, 366, 732, 413, 41011, 689, 472, 51076, 51076, 295, 264, 12819, 2314, 281, 312, 472, 13, 51254, 51254, 639, 1365, 3542, 294, 257, 472, 413, 8062, 13, 51474, 51474, 407, 341, 307, 445, 257, 472, 413, 10225, 300, 575, 572, 13241, 420, 13766, 13, 51782, 51782], "temperature": 0.0, "avg_logprob": -0.11936766306559245, "compression_ratio": 1.6524064171122994, "no_speech_prob": 6.643276719842106e-06}, {"id": 63, "seek": 30012, "start": 322.32, "end": 328.48, "text": " So this is just a one D array that has no rows or columns.", "tokens": [50364, 400, 264, 2649, 1296, 1228, 3834, 3732, 26179, 411, 341, 5717, 257, 2167, 3732, 50662, 50662, 16904, 411, 341, 307, 300, 9735, 264, 732, 5110, 322, 1192, 366, 732, 413, 41011, 689, 472, 51076, 51076, 295, 264, 12819, 2314, 281, 312, 472, 13, 51254, 51254, 639, 1365, 3542, 294, 257, 472, 413, 8062, 13, 51474, 51474, 407, 341, 307, 445, 257, 472, 413, 10225, 300, 575, 572, 13241, 420, 13766, 13, 51782, 51782], "temperature": 0.0, "avg_logprob": -0.11936766306559245, "compression_ratio": 1.6524064171122994, "no_speech_prob": 6.643276719842106e-06}, {"id": 64, "seek": 32848, "start": 328.48, "end": 333.62, "text": " Although by convention, we may write x as a column like this.", "tokens": [50364, 5780, 538, 10286, 11, 321, 815, 2464, 2031, 382, 257, 7738, 411, 341, 13, 50621, 50621, 407, 322, 257, 8712, 341, 365, 437, 321, 632, 8046, 1096, 294, 264, 700, 1164, 11, 597, 390, 281, 2464, 50934, 50934, 2031, 411, 341, 365, 257, 2167, 3732, 16904, 13, 51134, 51134, 400, 300, 18753, 294, 437, 311, 1219, 294, 15329, 257, 472, 413, 8062, 2602, 295, 257, 732, 413, 8141, 13, 51462, 51462, 400, 341, 12120, 307, 406, 472, 538, 732, 420, 732, 538, 472, 13, 51642, 51642, 467, 311, 445, 257, 8213, 10225, 365, 572, 13241, 420, 572, 13766, 13, 51862, 51862], "temperature": 0.0, "avg_logprob": -0.14812868544198934, "compression_ratio": 1.6131687242798354, "no_speech_prob": 8.530128980055451e-06}, {"id": 65, "seek": 32848, "start": 333.62, "end": 339.88, "text": " So on a contrast this with what we had previously done in the first course, which was to write", "tokens": [50364, 5780, 538, 10286, 11, 321, 815, 2464, 2031, 382, 257, 7738, 411, 341, 13, 50621, 50621, 407, 322, 257, 8712, 341, 365, 437, 321, 632, 8046, 1096, 294, 264, 700, 1164, 11, 597, 390, 281, 2464, 50934, 50934, 2031, 411, 341, 365, 257, 2167, 3732, 16904, 13, 51134, 51134, 400, 300, 18753, 294, 437, 311, 1219, 294, 15329, 257, 472, 413, 8062, 2602, 295, 257, 732, 413, 8141, 13, 51462, 51462, 400, 341, 12120, 307, 406, 472, 538, 732, 420, 732, 538, 472, 13, 51642, 51642, 467, 311, 445, 257, 8213, 10225, 365, 572, 13241, 420, 572, 13766, 13, 51862, 51862], "temperature": 0.0, "avg_logprob": -0.14812868544198934, "compression_ratio": 1.6131687242798354, "no_speech_prob": 8.530128980055451e-06}, {"id": 66, "seek": 32848, "start": 339.88, "end": 343.88, "text": " x like this with a single square bracket.", "tokens": [50364, 5780, 538, 10286, 11, 321, 815, 2464, 2031, 382, 257, 7738, 411, 341, 13, 50621, 50621, 407, 322, 257, 8712, 341, 365, 437, 321, 632, 8046, 1096, 294, 264, 700, 1164, 11, 597, 390, 281, 2464, 50934, 50934, 2031, 411, 341, 365, 257, 2167, 3732, 16904, 13, 51134, 51134, 400, 300, 18753, 294, 437, 311, 1219, 294, 15329, 257, 472, 413, 8062, 2602, 295, 257, 732, 413, 8141, 13, 51462, 51462, 400, 341, 12120, 307, 406, 472, 538, 732, 420, 732, 538, 472, 13, 51642, 51642, 467, 311, 445, 257, 8213, 10225, 365, 572, 13241, 420, 572, 13766, 13, 51862, 51862], "temperature": 0.0, "avg_logprob": -0.14812868544198934, "compression_ratio": 1.6131687242798354, "no_speech_prob": 8.530128980055451e-06}, {"id": 67, "seek": 32848, "start": 343.88, "end": 350.44, "text": " And that resulted in what's called in Python a one D vector instead of a two D matrix.", "tokens": [50364, 5780, 538, 10286, 11, 321, 815, 2464, 2031, 382, 257, 7738, 411, 341, 13, 50621, 50621, 407, 322, 257, 8712, 341, 365, 437, 321, 632, 8046, 1096, 294, 264, 700, 1164, 11, 597, 390, 281, 2464, 50934, 50934, 2031, 411, 341, 365, 257, 2167, 3732, 16904, 13, 51134, 51134, 400, 300, 18753, 294, 437, 311, 1219, 294, 15329, 257, 472, 413, 8062, 2602, 295, 257, 732, 413, 8141, 13, 51462, 51462, 400, 341, 12120, 307, 406, 472, 538, 732, 420, 732, 538, 472, 13, 51642, 51642, 467, 311, 445, 257, 8213, 10225, 365, 572, 13241, 420, 572, 13766, 13, 51862, 51862], "temperature": 0.0, "avg_logprob": -0.14812868544198934, "compression_ratio": 1.6131687242798354, "no_speech_prob": 8.530128980055451e-06}, {"id": 68, "seek": 32848, "start": 350.44, "end": 354.04, "text": " And this technically is not one by two or two by one.", "tokens": [50364, 5780, 538, 10286, 11, 321, 815, 2464, 2031, 382, 257, 7738, 411, 341, 13, 50621, 50621, 407, 322, 257, 8712, 341, 365, 437, 321, 632, 8046, 1096, 294, 264, 700, 1164, 11, 597, 390, 281, 2464, 50934, 50934, 2031, 411, 341, 365, 257, 2167, 3732, 16904, 13, 51134, 51134, 400, 300, 18753, 294, 437, 311, 1219, 294, 15329, 257, 472, 413, 8062, 2602, 295, 257, 732, 413, 8141, 13, 51462, 51462, 400, 341, 12120, 307, 406, 472, 538, 732, 420, 732, 538, 472, 13, 51642, 51642, 467, 311, 445, 257, 8213, 10225, 365, 572, 13241, 420, 572, 13766, 13, 51862, 51862], "temperature": 0.0, "avg_logprob": -0.14812868544198934, "compression_ratio": 1.6131687242798354, "no_speech_prob": 8.530128980055451e-06}, {"id": 69, "seek": 32848, "start": 354.04, "end": 358.44, "text": " It's just a linear array with no rows or no columns.", "tokens": [50364, 5780, 538, 10286, 11, 321, 815, 2464, 2031, 382, 257, 7738, 411, 341, 13, 50621, 50621, 407, 322, 257, 8712, 341, 365, 437, 321, 632, 8046, 1096, 294, 264, 700, 1164, 11, 597, 390, 281, 2464, 50934, 50934, 2031, 411, 341, 365, 257, 2167, 3732, 16904, 13, 51134, 51134, 400, 300, 18753, 294, 437, 311, 1219, 294, 15329, 257, 472, 413, 8062, 2602, 295, 257, 732, 413, 8141, 13, 51462, 51462, 400, 341, 12120, 307, 406, 472, 538, 732, 420, 732, 538, 472, 13, 51642, 51642, 467, 311, 445, 257, 8213, 10225, 365, 572, 13241, 420, 572, 13766, 13, 51862, 51862], "temperature": 0.0, "avg_logprob": -0.14812868544198934, "compression_ratio": 1.6131687242798354, "no_speech_prob": 8.530128980055451e-06}, {"id": 70, "seek": 35844, "start": 358.44, "end": 360.96, "text": " And it's just a list of numbers.", "tokens": [50364, 400, 309, 311, 445, 257, 1329, 295, 3547, 13, 50490, 50490, 407, 9735, 294, 1164, 472, 11, 562, 321, 434, 1364, 365, 8213, 24590, 11, 3565, 3142, 24590, 11, 50726, 50726, 321, 764, 613, 472, 413, 18875, 281, 2906, 264, 4846, 4122, 2031, 13, 50978, 50978, 2022, 37624, 11, 264, 10286, 307, 281, 764, 32284, 281, 2906, 264, 1412, 13, 51278, 51278, 400, 983, 307, 456, 341, 3679, 294, 33520, 30, 51376, 51376, 1042, 11, 309, 4523, 484, 300, 37624, 390, 4761, 281, 4813, 588, 2416, 42856, 13, 51663, 51663], "temperature": 0.0, "avg_logprob": -0.15717736534450366, "compression_ratio": 1.625531914893617, "no_speech_prob": 2.1567354906437686e-06}, {"id": 71, "seek": 35844, "start": 360.96, "end": 365.68, "text": " So whereas in course one, when we're working with linear regression, logistic regression,", "tokens": [50364, 400, 309, 311, 445, 257, 1329, 295, 3547, 13, 50490, 50490, 407, 9735, 294, 1164, 472, 11, 562, 321, 434, 1364, 365, 8213, 24590, 11, 3565, 3142, 24590, 11, 50726, 50726, 321, 764, 613, 472, 413, 18875, 281, 2906, 264, 4846, 4122, 2031, 13, 50978, 50978, 2022, 37624, 11, 264, 10286, 307, 281, 764, 32284, 281, 2906, 264, 1412, 13, 51278, 51278, 400, 983, 307, 456, 341, 3679, 294, 33520, 30, 51376, 51376, 1042, 11, 309, 4523, 484, 300, 37624, 390, 4761, 281, 4813, 588, 2416, 42856, 13, 51663, 51663], "temperature": 0.0, "avg_logprob": -0.15717736534450366, "compression_ratio": 1.625531914893617, "no_speech_prob": 2.1567354906437686e-06}, {"id": 72, "seek": 35844, "start": 365.68, "end": 370.72, "text": " we use these one D vectors to represent the input features x.", "tokens": [50364, 400, 309, 311, 445, 257, 1329, 295, 3547, 13, 50490, 50490, 407, 9735, 294, 1164, 472, 11, 562, 321, 434, 1364, 365, 8213, 24590, 11, 3565, 3142, 24590, 11, 50726, 50726, 321, 764, 613, 472, 413, 18875, 281, 2906, 264, 4846, 4122, 2031, 13, 50978, 50978, 2022, 37624, 11, 264, 10286, 307, 281, 764, 32284, 281, 2906, 264, 1412, 13, 51278, 51278, 400, 983, 307, 456, 341, 3679, 294, 33520, 30, 51376, 51376, 1042, 11, 309, 4523, 484, 300, 37624, 390, 4761, 281, 4813, 588, 2416, 42856, 13, 51663, 51663], "temperature": 0.0, "avg_logprob": -0.15717736534450366, "compression_ratio": 1.625531914893617, "no_speech_prob": 2.1567354906437686e-06}, {"id": 73, "seek": 35844, "start": 370.72, "end": 376.72, "text": " With TensorFlow, the convention is to use matrices to represent the data.", "tokens": [50364, 400, 309, 311, 445, 257, 1329, 295, 3547, 13, 50490, 50490, 407, 9735, 294, 1164, 472, 11, 562, 321, 434, 1364, 365, 8213, 24590, 11, 3565, 3142, 24590, 11, 50726, 50726, 321, 764, 613, 472, 413, 18875, 281, 2906, 264, 4846, 4122, 2031, 13, 50978, 50978, 2022, 37624, 11, 264, 10286, 307, 281, 764, 32284, 281, 2906, 264, 1412, 13, 51278, 51278, 400, 983, 307, 456, 341, 3679, 294, 33520, 30, 51376, 51376, 1042, 11, 309, 4523, 484, 300, 37624, 390, 4761, 281, 4813, 588, 2416, 42856, 13, 51663, 51663], "temperature": 0.0, "avg_logprob": -0.15717736534450366, "compression_ratio": 1.625531914893617, "no_speech_prob": 2.1567354906437686e-06}, {"id": 74, "seek": 35844, "start": 376.72, "end": 378.68, "text": " And why is there this switch in conventions?", "tokens": [50364, 400, 309, 311, 445, 257, 1329, 295, 3547, 13, 50490, 50490, 407, 9735, 294, 1164, 472, 11, 562, 321, 434, 1364, 365, 8213, 24590, 11, 3565, 3142, 24590, 11, 50726, 50726, 321, 764, 613, 472, 413, 18875, 281, 2906, 264, 4846, 4122, 2031, 13, 50978, 50978, 2022, 37624, 11, 264, 10286, 307, 281, 764, 32284, 281, 2906, 264, 1412, 13, 51278, 51278, 400, 983, 307, 456, 341, 3679, 294, 33520, 30, 51376, 51376, 1042, 11, 309, 4523, 484, 300, 37624, 390, 4761, 281, 4813, 588, 2416, 42856, 13, 51663, 51663], "temperature": 0.0, "avg_logprob": -0.15717736534450366, "compression_ratio": 1.625531914893617, "no_speech_prob": 2.1567354906437686e-06}, {"id": 75, "seek": 35844, "start": 378.68, "end": 384.42, "text": " Well, it turns out that TensorFlow was designed to handle very large datasets.", "tokens": [50364, 400, 309, 311, 445, 257, 1329, 295, 3547, 13, 50490, 50490, 407, 9735, 294, 1164, 472, 11, 562, 321, 434, 1364, 365, 8213, 24590, 11, 3565, 3142, 24590, 11, 50726, 50726, 321, 764, 613, 472, 413, 18875, 281, 2906, 264, 4846, 4122, 2031, 13, 50978, 50978, 2022, 37624, 11, 264, 10286, 307, 281, 764, 32284, 281, 2906, 264, 1412, 13, 51278, 51278, 400, 983, 307, 456, 341, 3679, 294, 33520, 30, 51376, 51376, 1042, 11, 309, 4523, 484, 300, 37624, 390, 4761, 281, 4813, 588, 2416, 42856, 13, 51663, 51663], "temperature": 0.0, "avg_logprob": -0.15717736534450366, "compression_ratio": 1.625531914893617, "no_speech_prob": 2.1567354906437686e-06}, {"id": 76, "seek": 38442, "start": 384.42, "end": 390.48, "text": " And by representing the data in matrices instead of one D arrays, it lets TensorFlow be a bit", "tokens": [50364, 400, 538, 13460, 264, 1412, 294, 32284, 2602, 295, 472, 413, 41011, 11, 309, 6653, 37624, 312, 257, 857, 50667, 50667, 544, 24903, 379, 7148, 19501, 13, 50861, 50861, 407, 516, 646, 281, 527, 3380, 1365, 11, 337, 264, 700, 3097, 1365, 294, 341, 28872, 51113, 51113, 365, 4122, 2331, 5310, 22658, 294, 3282, 2077, 11, 321, 576, 2906, 309, 411, 341, 13, 51438, 51438, 400, 370, 341, 307, 767, 257, 472, 538, 732, 8141, 300, 2314, 281, 362, 472, 5386, 293, 732, 13766, 51827, 51827], "temperature": 0.0, "avg_logprob": -0.08602625673467462, "compression_ratio": 1.547244094488189, "no_speech_prob": 1.7061181551980553e-06}, {"id": 77, "seek": 38442, "start": 390.48, "end": 394.36, "text": " more computationally efficient internally.", "tokens": [50364, 400, 538, 13460, 264, 1412, 294, 32284, 2602, 295, 472, 413, 41011, 11, 309, 6653, 37624, 312, 257, 857, 50667, 50667, 544, 24903, 379, 7148, 19501, 13, 50861, 50861, 407, 516, 646, 281, 527, 3380, 1365, 11, 337, 264, 700, 3097, 1365, 294, 341, 28872, 51113, 51113, 365, 4122, 2331, 5310, 22658, 294, 3282, 2077, 11, 321, 576, 2906, 309, 411, 341, 13, 51438, 51438, 400, 370, 341, 307, 767, 257, 472, 538, 732, 8141, 300, 2314, 281, 362, 472, 5386, 293, 732, 13766, 51827, 51827], "temperature": 0.0, "avg_logprob": -0.08602625673467462, "compression_ratio": 1.547244094488189, "no_speech_prob": 1.7061181551980553e-06}, {"id": 78, "seek": 38442, "start": 394.36, "end": 399.40000000000003, "text": " So going back to our original example, for the first training example in this dataset", "tokens": [50364, 400, 538, 13460, 264, 1412, 294, 32284, 2602, 295, 472, 413, 41011, 11, 309, 6653, 37624, 312, 257, 857, 50667, 50667, 544, 24903, 379, 7148, 19501, 13, 50861, 50861, 407, 516, 646, 281, 527, 3380, 1365, 11, 337, 264, 700, 3097, 1365, 294, 341, 28872, 51113, 51113, 365, 4122, 2331, 5310, 22658, 294, 3282, 2077, 11, 321, 576, 2906, 309, 411, 341, 13, 51438, 51438, 400, 370, 341, 307, 767, 257, 472, 538, 732, 8141, 300, 2314, 281, 362, 472, 5386, 293, 732, 13766, 51827, 51827], "temperature": 0.0, "avg_logprob": -0.08602625673467462, "compression_ratio": 1.547244094488189, "no_speech_prob": 1.7061181551980553e-06}, {"id": 79, "seek": 38442, "start": 399.40000000000003, "end": 405.90000000000003, "text": " with features 200 degrees Celsius in 17 minutes, we would represent it like this.", "tokens": [50364, 400, 538, 13460, 264, 1412, 294, 32284, 2602, 295, 472, 413, 41011, 11, 309, 6653, 37624, 312, 257, 857, 50667, 50667, 544, 24903, 379, 7148, 19501, 13, 50861, 50861, 407, 516, 646, 281, 527, 3380, 1365, 11, 337, 264, 700, 3097, 1365, 294, 341, 28872, 51113, 51113, 365, 4122, 2331, 5310, 22658, 294, 3282, 2077, 11, 321, 576, 2906, 309, 411, 341, 13, 51438, 51438, 400, 370, 341, 307, 767, 257, 472, 538, 732, 8141, 300, 2314, 281, 362, 472, 5386, 293, 732, 13766, 51827, 51827], "temperature": 0.0, "avg_logprob": -0.08602625673467462, "compression_ratio": 1.547244094488189, "no_speech_prob": 1.7061181551980553e-06}, {"id": 80, "seek": 38442, "start": 405.90000000000003, "end": 413.68, "text": " And so this is actually a one by two matrix that happens to have one row and two columns", "tokens": [50364, 400, 538, 13460, 264, 1412, 294, 32284, 2602, 295, 472, 413, 41011, 11, 309, 6653, 37624, 312, 257, 857, 50667, 50667, 544, 24903, 379, 7148, 19501, 13, 50861, 50861, 407, 516, 646, 281, 527, 3380, 1365, 11, 337, 264, 700, 3097, 1365, 294, 341, 28872, 51113, 51113, 365, 4122, 2331, 5310, 22658, 294, 3282, 2077, 11, 321, 576, 2906, 309, 411, 341, 13, 51438, 51438, 400, 370, 341, 307, 767, 257, 472, 538, 732, 8141, 300, 2314, 281, 362, 472, 5386, 293, 732, 13766, 51827, 51827], "temperature": 0.0, "avg_logprob": -0.08602625673467462, "compression_ratio": 1.547244094488189, "no_speech_prob": 1.7061181551980553e-06}, {"id": 81, "seek": 41368, "start": 413.68, "end": 417.68, "text": " to store the numbers 217.", "tokens": [50364, 281, 3531, 264, 3547, 5080, 22, 13, 50564, 50564, 400, 294, 1389, 341, 2544, 411, 257, 688, 295, 4365, 293, 534, 6179, 33520, 11, 500, 380, 50806, 50806, 3292, 466, 309, 13, 50856, 50856, 1057, 341, 486, 1813, 26131, 13, 50946, 50946, 400, 291, 483, 281, 536, 264, 9859, 4445, 763, 295, 264, 3089, 1803, 294, 264, 17312, 20339, 51202, 51202, 293, 294, 264, 3124, 20339, 13, 51280, 51280, 10963, 646, 281, 264, 3089, 337, 9792, 484, 337, 38377, 420, 38253, 294, 264, 18161, 3209, 11, 51614, 51614], "temperature": 0.0, "avg_logprob": -0.12699187596638997, "compression_ratio": 1.6266666666666667, "no_speech_prob": 1.7061624930647667e-06}, {"id": 82, "seek": 41368, "start": 417.68, "end": 422.52, "text": " And in case this seems like a lot of details and really complicated conventions, don't", "tokens": [50364, 281, 3531, 264, 3547, 5080, 22, 13, 50564, 50564, 400, 294, 1389, 341, 2544, 411, 257, 688, 295, 4365, 293, 534, 6179, 33520, 11, 500, 380, 50806, 50806, 3292, 466, 309, 13, 50856, 50856, 1057, 341, 486, 1813, 26131, 13, 50946, 50946, 400, 291, 483, 281, 536, 264, 9859, 4445, 763, 295, 264, 3089, 1803, 294, 264, 17312, 20339, 51202, 51202, 293, 294, 264, 3124, 20339, 13, 51280, 51280, 10963, 646, 281, 264, 3089, 337, 9792, 484, 337, 38377, 420, 38253, 294, 264, 18161, 3209, 11, 51614, 51614], "temperature": 0.0, "avg_logprob": -0.12699187596638997, "compression_ratio": 1.6266666666666667, "no_speech_prob": 1.7061624930647667e-06}, {"id": 83, "seek": 41368, "start": 422.52, "end": 423.52, "text": " worry about it.", "tokens": [50364, 281, 3531, 264, 3547, 5080, 22, 13, 50564, 50564, 400, 294, 1389, 341, 2544, 411, 257, 688, 295, 4365, 293, 534, 6179, 33520, 11, 500, 380, 50806, 50806, 3292, 466, 309, 13, 50856, 50856, 1057, 341, 486, 1813, 26131, 13, 50946, 50946, 400, 291, 483, 281, 536, 264, 9859, 4445, 763, 295, 264, 3089, 1803, 294, 264, 17312, 20339, 51202, 51202, 293, 294, 264, 3124, 20339, 13, 51280, 51280, 10963, 646, 281, 264, 3089, 337, 9792, 484, 337, 38377, 420, 38253, 294, 264, 18161, 3209, 11, 51614, 51614], "temperature": 0.0, "avg_logprob": -0.12699187596638997, "compression_ratio": 1.6266666666666667, "no_speech_prob": 1.7061624930647667e-06}, {"id": 84, "seek": 41368, "start": 423.52, "end": 425.32, "text": " All this will become clearer.", "tokens": [50364, 281, 3531, 264, 3547, 5080, 22, 13, 50564, 50564, 400, 294, 1389, 341, 2544, 411, 257, 688, 295, 4365, 293, 534, 6179, 33520, 11, 500, 380, 50806, 50806, 3292, 466, 309, 13, 50856, 50856, 1057, 341, 486, 1813, 26131, 13, 50946, 50946, 400, 291, 483, 281, 536, 264, 9859, 4445, 763, 295, 264, 3089, 1803, 294, 264, 17312, 20339, 51202, 51202, 293, 294, 264, 3124, 20339, 13, 51280, 51280, 10963, 646, 281, 264, 3089, 337, 9792, 484, 337, 38377, 420, 38253, 294, 264, 18161, 3209, 11, 51614, 51614], "temperature": 0.0, "avg_logprob": -0.12699187596638997, "compression_ratio": 1.6266666666666667, "no_speech_prob": 1.7061624930647667e-06}, {"id": 85, "seek": 41368, "start": 425.32, "end": 430.44, "text": " And you get to see the concrete implementations of the code yourself in the optional labs", "tokens": [50364, 281, 3531, 264, 3547, 5080, 22, 13, 50564, 50564, 400, 294, 1389, 341, 2544, 411, 257, 688, 295, 4365, 293, 534, 6179, 33520, 11, 500, 380, 50806, 50806, 3292, 466, 309, 13, 50856, 50856, 1057, 341, 486, 1813, 26131, 13, 50946, 50946, 400, 291, 483, 281, 536, 264, 9859, 4445, 763, 295, 264, 3089, 1803, 294, 264, 17312, 20339, 51202, 51202, 293, 294, 264, 3124, 20339, 13, 51280, 51280, 10963, 646, 281, 264, 3089, 337, 9792, 484, 337, 38377, 420, 38253, 294, 264, 18161, 3209, 11, 51614, 51614], "temperature": 0.0, "avg_logprob": -0.12699187596638997, "compression_ratio": 1.6266666666666667, "no_speech_prob": 1.7061624930647667e-06}, {"id": 86, "seek": 41368, "start": 430.44, "end": 432.0, "text": " and in the practice labs.", "tokens": [50364, 281, 3531, 264, 3547, 5080, 22, 13, 50564, 50564, 400, 294, 1389, 341, 2544, 411, 257, 688, 295, 4365, 293, 534, 6179, 33520, 11, 500, 380, 50806, 50806, 3292, 466, 309, 13, 50856, 50856, 1057, 341, 486, 1813, 26131, 13, 50946, 50946, 400, 291, 483, 281, 536, 264, 9859, 4445, 763, 295, 264, 3089, 1803, 294, 264, 17312, 20339, 51202, 51202, 293, 294, 264, 3124, 20339, 13, 51280, 51280, 10963, 646, 281, 264, 3089, 337, 9792, 484, 337, 38377, 420, 38253, 294, 264, 18161, 3209, 11, 51614, 51614], "temperature": 0.0, "avg_logprob": -0.12699187596638997, "compression_ratio": 1.6266666666666667, "no_speech_prob": 1.7061624930647667e-06}, {"id": 87, "seek": 41368, "start": 432.0, "end": 438.68, "text": " Going back to the code for carrying out for propagation or inference in the neural network,", "tokens": [50364, 281, 3531, 264, 3547, 5080, 22, 13, 50564, 50564, 400, 294, 1389, 341, 2544, 411, 257, 688, 295, 4365, 293, 534, 6179, 33520, 11, 500, 380, 50806, 50806, 3292, 466, 309, 13, 50856, 50856, 1057, 341, 486, 1813, 26131, 13, 50946, 50946, 400, 291, 483, 281, 536, 264, 9859, 4445, 763, 295, 264, 3089, 1803, 294, 264, 17312, 20339, 51202, 51202, 293, 294, 264, 3124, 20339, 13, 51280, 51280, 10963, 646, 281, 264, 3089, 337, 9792, 484, 337, 38377, 420, 38253, 294, 264, 18161, 3209, 11, 51614, 51614], "temperature": 0.0, "avg_logprob": -0.12699187596638997, "compression_ratio": 1.6266666666666667, "no_speech_prob": 1.7061624930647667e-06}, {"id": 88, "seek": 43868, "start": 438.68, "end": 446.08, "text": " when you compute a one equals layer one applied to X, what is a one?", "tokens": [50364, 562, 291, 14722, 257, 472, 6915, 4583, 472, 6456, 281, 1783, 11, 437, 307, 257, 472, 30, 50734, 50734, 1042, 11, 257, 472, 307, 767, 516, 281, 312, 570, 456, 311, 1045, 3547, 307, 767, 516, 281, 51010, 51010, 312, 257, 472, 538, 1045, 8141, 13, 51198, 51198, 400, 498, 291, 4482, 484, 257, 472, 11, 291, 486, 483, 746, 411, 341, 307, 40964, 5893, 40863, 935, 568, 13, 22, 13, 18, 307, 51656, 51656], "temperature": 0.0, "avg_logprob": -0.189182727367847, "compression_ratio": 1.5307262569832403, "no_speech_prob": 3.119707616860978e-05}, {"id": 89, "seek": 43868, "start": 446.08, "end": 451.6, "text": " Well, a one is actually going to be because there's three numbers is actually going to", "tokens": [50364, 562, 291, 14722, 257, 472, 6915, 4583, 472, 6456, 281, 1783, 11, 437, 307, 257, 472, 30, 50734, 50734, 1042, 11, 257, 472, 307, 767, 516, 281, 312, 570, 456, 311, 1045, 3547, 307, 767, 516, 281, 51010, 51010, 312, 257, 472, 538, 1045, 8141, 13, 51198, 51198, 400, 498, 291, 4482, 484, 257, 472, 11, 291, 486, 483, 746, 411, 341, 307, 40964, 5893, 40863, 935, 568, 13, 22, 13, 18, 307, 51656, 51656], "temperature": 0.0, "avg_logprob": -0.189182727367847, "compression_ratio": 1.5307262569832403, "no_speech_prob": 3.119707616860978e-05}, {"id": 90, "seek": 43868, "start": 451.6, "end": 455.36, "text": " be a one by three matrix.", "tokens": [50364, 562, 291, 14722, 257, 472, 6915, 4583, 472, 6456, 281, 1783, 11, 437, 307, 257, 472, 30, 50734, 50734, 1042, 11, 257, 472, 307, 767, 516, 281, 312, 570, 456, 311, 1045, 3547, 307, 767, 516, 281, 51010, 51010, 312, 257, 472, 538, 1045, 8141, 13, 51198, 51198, 400, 498, 291, 4482, 484, 257, 472, 11, 291, 486, 483, 746, 411, 341, 307, 40964, 5893, 40863, 935, 568, 13, 22, 13, 18, 307, 51656, 51656], "temperature": 0.0, "avg_logprob": -0.189182727367847, "compression_ratio": 1.5307262569832403, "no_speech_prob": 3.119707616860978e-05}, {"id": 91, "seek": 43868, "start": 455.36, "end": 464.52, "text": " And if you print out a one, you will get something like this is TF dot tensor point 2.7.3 is", "tokens": [50364, 562, 291, 14722, 257, 472, 6915, 4583, 472, 6456, 281, 1783, 11, 437, 307, 257, 472, 30, 50734, 50734, 1042, 11, 257, 472, 307, 767, 516, 281, 312, 570, 456, 311, 1045, 3547, 307, 767, 516, 281, 51010, 51010, 312, 257, 472, 538, 1045, 8141, 13, 51198, 51198, 400, 498, 291, 4482, 484, 257, 472, 11, 291, 486, 483, 746, 411, 341, 307, 40964, 5893, 40863, 935, 568, 13, 22, 13, 18, 307, 51656, 51656], "temperature": 0.0, "avg_logprob": -0.189182727367847, "compression_ratio": 1.5307262569832403, "no_speech_prob": 3.119707616860978e-05}, {"id": 92, "seek": 46452, "start": 464.52, "end": 471.03999999999996, "text": " a shape of one by three, one three refers to that this is a one by three matrix.", "tokens": [50364, 257, 3909, 295, 472, 538, 1045, 11, 472, 1045, 14942, 281, 300, 341, 307, 257, 472, 538, 1045, 8141, 13, 50690, 50690, 400, 341, 307, 37624, 311, 636, 295, 1566, 300, 341, 307, 257, 12607, 935, 1230, 11, 3620, 300, 50945, 50945, 309, 311, 257, 1230, 300, 393, 362, 257, 26601, 935, 10379, 1228, 8858, 9239, 295, 4675, 294, 428, 51246, 51246, 3820, 13, 51296, 51296, 663, 311, 437, 257, 15706, 8858, 307, 13, 51380, 51380, 400, 437, 307, 257, 40863, 30, 51434, 51434, 316, 40863, 510, 307, 257, 1412, 2010, 300, 264, 37624, 1469, 632, 2942, 294, 1668, 281, 3531, 293, 3985, 51754, 51754], "temperature": 0.0, "avg_logprob": -0.11611313686192593, "compression_ratio": 1.7639484978540771, "no_speech_prob": 2.5612050649215234e-06}, {"id": 93, "seek": 46452, "start": 471.03999999999996, "end": 476.14, "text": " And this is TensorFlow's way of saying that this is a floating point number, meaning that", "tokens": [50364, 257, 3909, 295, 472, 538, 1045, 11, 472, 1045, 14942, 281, 300, 341, 307, 257, 472, 538, 1045, 8141, 13, 50690, 50690, 400, 341, 307, 37624, 311, 636, 295, 1566, 300, 341, 307, 257, 12607, 935, 1230, 11, 3620, 300, 50945, 50945, 309, 311, 257, 1230, 300, 393, 362, 257, 26601, 935, 10379, 1228, 8858, 9239, 295, 4675, 294, 428, 51246, 51246, 3820, 13, 51296, 51296, 663, 311, 437, 257, 15706, 8858, 307, 13, 51380, 51380, 400, 437, 307, 257, 40863, 30, 51434, 51434, 316, 40863, 510, 307, 257, 1412, 2010, 300, 264, 37624, 1469, 632, 2942, 294, 1668, 281, 3531, 293, 3985, 51754, 51754], "temperature": 0.0, "avg_logprob": -0.11611313686192593, "compression_ratio": 1.7639484978540771, "no_speech_prob": 2.5612050649215234e-06}, {"id": 94, "seek": 46452, "start": 476.14, "end": 482.15999999999997, "text": " it's a number that can have a decimal point represented using 32 bits of memory in your", "tokens": [50364, 257, 3909, 295, 472, 538, 1045, 11, 472, 1045, 14942, 281, 300, 341, 307, 257, 472, 538, 1045, 8141, 13, 50690, 50690, 400, 341, 307, 37624, 311, 636, 295, 1566, 300, 341, 307, 257, 12607, 935, 1230, 11, 3620, 300, 50945, 50945, 309, 311, 257, 1230, 300, 393, 362, 257, 26601, 935, 10379, 1228, 8858, 9239, 295, 4675, 294, 428, 51246, 51246, 3820, 13, 51296, 51296, 663, 311, 437, 257, 15706, 8858, 307, 13, 51380, 51380, 400, 437, 307, 257, 40863, 30, 51434, 51434, 316, 40863, 510, 307, 257, 1412, 2010, 300, 264, 37624, 1469, 632, 2942, 294, 1668, 281, 3531, 293, 3985, 51754, 51754], "temperature": 0.0, "avg_logprob": -0.11611313686192593, "compression_ratio": 1.7639484978540771, "no_speech_prob": 2.5612050649215234e-06}, {"id": 95, "seek": 46452, "start": 482.15999999999997, "end": 483.15999999999997, "text": " computer.", "tokens": [50364, 257, 3909, 295, 472, 538, 1045, 11, 472, 1045, 14942, 281, 300, 341, 307, 257, 472, 538, 1045, 8141, 13, 50690, 50690, 400, 341, 307, 37624, 311, 636, 295, 1566, 300, 341, 307, 257, 12607, 935, 1230, 11, 3620, 300, 50945, 50945, 309, 311, 257, 1230, 300, 393, 362, 257, 26601, 935, 10379, 1228, 8858, 9239, 295, 4675, 294, 428, 51246, 51246, 3820, 13, 51296, 51296, 663, 311, 437, 257, 15706, 8858, 307, 13, 51380, 51380, 400, 437, 307, 257, 40863, 30, 51434, 51434, 316, 40863, 510, 307, 257, 1412, 2010, 300, 264, 37624, 1469, 632, 2942, 294, 1668, 281, 3531, 293, 3985, 51754, 51754], "temperature": 0.0, "avg_logprob": -0.11611313686192593, "compression_ratio": 1.7639484978540771, "no_speech_prob": 2.5612050649215234e-06}, {"id": 96, "seek": 46452, "start": 483.15999999999997, "end": 484.84, "text": " That's what a float 32 is.", "tokens": [50364, 257, 3909, 295, 472, 538, 1045, 11, 472, 1045, 14942, 281, 300, 341, 307, 257, 472, 538, 1045, 8141, 13, 50690, 50690, 400, 341, 307, 37624, 311, 636, 295, 1566, 300, 341, 307, 257, 12607, 935, 1230, 11, 3620, 300, 50945, 50945, 309, 311, 257, 1230, 300, 393, 362, 257, 26601, 935, 10379, 1228, 8858, 9239, 295, 4675, 294, 428, 51246, 51246, 3820, 13, 51296, 51296, 663, 311, 437, 257, 15706, 8858, 307, 13, 51380, 51380, 400, 437, 307, 257, 40863, 30, 51434, 51434, 316, 40863, 510, 307, 257, 1412, 2010, 300, 264, 37624, 1469, 632, 2942, 294, 1668, 281, 3531, 293, 3985, 51754, 51754], "temperature": 0.0, "avg_logprob": -0.11611313686192593, "compression_ratio": 1.7639484978540771, "no_speech_prob": 2.5612050649215234e-06}, {"id": 97, "seek": 46452, "start": 484.84, "end": 485.91999999999996, "text": " And what is a tensor?", "tokens": [50364, 257, 3909, 295, 472, 538, 1045, 11, 472, 1045, 14942, 281, 300, 341, 307, 257, 472, 538, 1045, 8141, 13, 50690, 50690, 400, 341, 307, 37624, 311, 636, 295, 1566, 300, 341, 307, 257, 12607, 935, 1230, 11, 3620, 300, 50945, 50945, 309, 311, 257, 1230, 300, 393, 362, 257, 26601, 935, 10379, 1228, 8858, 9239, 295, 4675, 294, 428, 51246, 51246, 3820, 13, 51296, 51296, 663, 311, 437, 257, 15706, 8858, 307, 13, 51380, 51380, 400, 437, 307, 257, 40863, 30, 51434, 51434, 316, 40863, 510, 307, 257, 1412, 2010, 300, 264, 37624, 1469, 632, 2942, 294, 1668, 281, 3531, 293, 3985, 51754, 51754], "temperature": 0.0, "avg_logprob": -0.11611313686192593, "compression_ratio": 1.7639484978540771, "no_speech_prob": 2.5612050649215234e-06}, {"id": 98, "seek": 46452, "start": 485.91999999999996, "end": 492.32, "text": " A tensor here is a data type that the TensorFlow team had created in order to store and carry", "tokens": [50364, 257, 3909, 295, 472, 538, 1045, 11, 472, 1045, 14942, 281, 300, 341, 307, 257, 472, 538, 1045, 8141, 13, 50690, 50690, 400, 341, 307, 37624, 311, 636, 295, 1566, 300, 341, 307, 257, 12607, 935, 1230, 11, 3620, 300, 50945, 50945, 309, 311, 257, 1230, 300, 393, 362, 257, 26601, 935, 10379, 1228, 8858, 9239, 295, 4675, 294, 428, 51246, 51246, 3820, 13, 51296, 51296, 663, 311, 437, 257, 15706, 8858, 307, 13, 51380, 51380, 400, 437, 307, 257, 40863, 30, 51434, 51434, 316, 40863, 510, 307, 257, 1412, 2010, 300, 264, 37624, 1469, 632, 2942, 294, 1668, 281, 3531, 293, 3985, 51754, 51754], "temperature": 0.0, "avg_logprob": -0.11611313686192593, "compression_ratio": 1.7639484978540771, "no_speech_prob": 2.5612050649215234e-06}, {"id": 99, "seek": 49232, "start": 492.32, "end": 495.52, "text": " out computations on matrices efficiently.", "tokens": [50364, 484, 2807, 763, 322, 32284, 19621, 13, 50524, 50524, 407, 5699, 291, 536, 40863, 11, 445, 519, 295, 309, 382, 8141, 322, 613, 1326, 9788, 13, 50852, 50852, 42494, 257, 40863, 307, 257, 707, 857, 544, 2674, 813, 264, 8141, 11, 457, 337, 264, 9932, 51034, 51034, 295, 341, 1164, 11, 519, 295, 40863, 382, 445, 257, 636, 295, 13460, 32284, 13, 51296, 51296, 407, 1604, 286, 848, 412, 264, 722, 295, 341, 960, 300, 456, 311, 264, 37624, 636, 295, 13460, 51584, 51584, 257, 8141, 293, 264, 22592, 47, 88, 636, 295, 13460, 8141, 13, 51753, 51753], "temperature": 0.0, "avg_logprob": -0.14074763298034668, "compression_ratio": 1.780590717299578, "no_speech_prob": 7.527758498326875e-06}, {"id": 100, "seek": 49232, "start": 495.52, "end": 502.08, "text": " So whenever you see tensor, just think of it as matrix on these few slides.", "tokens": [50364, 484, 2807, 763, 322, 32284, 19621, 13, 50524, 50524, 407, 5699, 291, 536, 40863, 11, 445, 519, 295, 309, 382, 8141, 322, 613, 1326, 9788, 13, 50852, 50852, 42494, 257, 40863, 307, 257, 707, 857, 544, 2674, 813, 264, 8141, 11, 457, 337, 264, 9932, 51034, 51034, 295, 341, 1164, 11, 519, 295, 40863, 382, 445, 257, 636, 295, 13460, 32284, 13, 51296, 51296, 407, 1604, 286, 848, 412, 264, 722, 295, 341, 960, 300, 456, 311, 264, 37624, 636, 295, 13460, 51584, 51584, 257, 8141, 293, 264, 22592, 47, 88, 636, 295, 13460, 8141, 13, 51753, 51753], "temperature": 0.0, "avg_logprob": -0.14074763298034668, "compression_ratio": 1.780590717299578, "no_speech_prob": 7.527758498326875e-06}, {"id": 101, "seek": 49232, "start": 502.08, "end": 505.71999999999997, "text": " Technically a tensor is a little bit more general than the matrix, but for the purposes", "tokens": [50364, 484, 2807, 763, 322, 32284, 19621, 13, 50524, 50524, 407, 5699, 291, 536, 40863, 11, 445, 519, 295, 309, 382, 8141, 322, 613, 1326, 9788, 13, 50852, 50852, 42494, 257, 40863, 307, 257, 707, 857, 544, 2674, 813, 264, 8141, 11, 457, 337, 264, 9932, 51034, 51034, 295, 341, 1164, 11, 519, 295, 40863, 382, 445, 257, 636, 295, 13460, 32284, 13, 51296, 51296, 407, 1604, 286, 848, 412, 264, 722, 295, 341, 960, 300, 456, 311, 264, 37624, 636, 295, 13460, 51584, 51584, 257, 8141, 293, 264, 22592, 47, 88, 636, 295, 13460, 8141, 13, 51753, 51753], "temperature": 0.0, "avg_logprob": -0.14074763298034668, "compression_ratio": 1.780590717299578, "no_speech_prob": 7.527758498326875e-06}, {"id": 102, "seek": 49232, "start": 505.71999999999997, "end": 510.96, "text": " of this course, think of tensor as just a way of representing matrices.", "tokens": [50364, 484, 2807, 763, 322, 32284, 19621, 13, 50524, 50524, 407, 5699, 291, 536, 40863, 11, 445, 519, 295, 309, 382, 8141, 322, 613, 1326, 9788, 13, 50852, 50852, 42494, 257, 40863, 307, 257, 707, 857, 544, 2674, 813, 264, 8141, 11, 457, 337, 264, 9932, 51034, 51034, 295, 341, 1164, 11, 519, 295, 40863, 382, 445, 257, 636, 295, 13460, 32284, 13, 51296, 51296, 407, 1604, 286, 848, 412, 264, 722, 295, 341, 960, 300, 456, 311, 264, 37624, 636, 295, 13460, 51584, 51584, 257, 8141, 293, 264, 22592, 47, 88, 636, 295, 13460, 8141, 13, 51753, 51753], "temperature": 0.0, "avg_logprob": -0.14074763298034668, "compression_ratio": 1.780590717299578, "no_speech_prob": 7.527758498326875e-06}, {"id": 103, "seek": 49232, "start": 510.96, "end": 516.72, "text": " So remember I said at the start of this video that there's the TensorFlow way of representing", "tokens": [50364, 484, 2807, 763, 322, 32284, 19621, 13, 50524, 50524, 407, 5699, 291, 536, 40863, 11, 445, 519, 295, 309, 382, 8141, 322, 613, 1326, 9788, 13, 50852, 50852, 42494, 257, 40863, 307, 257, 707, 857, 544, 2674, 813, 264, 8141, 11, 457, 337, 264, 9932, 51034, 51034, 295, 341, 1164, 11, 519, 295, 40863, 382, 445, 257, 636, 295, 13460, 32284, 13, 51296, 51296, 407, 1604, 286, 848, 412, 264, 722, 295, 341, 960, 300, 456, 311, 264, 37624, 636, 295, 13460, 51584, 51584, 257, 8141, 293, 264, 22592, 47, 88, 636, 295, 13460, 8141, 13, 51753, 51753], "temperature": 0.0, "avg_logprob": -0.14074763298034668, "compression_ratio": 1.780590717299578, "no_speech_prob": 7.527758498326875e-06}, {"id": 104, "seek": 49232, "start": 516.72, "end": 520.1, "text": " a matrix and the NumPy way of representing matrix.", "tokens": [50364, 484, 2807, 763, 322, 32284, 19621, 13, 50524, 50524, 407, 5699, 291, 536, 40863, 11, 445, 519, 295, 309, 382, 8141, 322, 613, 1326, 9788, 13, 50852, 50852, 42494, 257, 40863, 307, 257, 707, 857, 544, 2674, 813, 264, 8141, 11, 457, 337, 264, 9932, 51034, 51034, 295, 341, 1164, 11, 519, 295, 40863, 382, 445, 257, 636, 295, 13460, 32284, 13, 51296, 51296, 407, 1604, 286, 848, 412, 264, 722, 295, 341, 960, 300, 456, 311, 264, 37624, 636, 295, 13460, 51584, 51584, 257, 8141, 293, 264, 22592, 47, 88, 636, 295, 13460, 8141, 13, 51753, 51753], "temperature": 0.0, "avg_logprob": -0.14074763298034668, "compression_ratio": 1.780590717299578, "no_speech_prob": 7.527758498326875e-06}, {"id": 105, "seek": 52010, "start": 520.1, "end": 525.88, "text": " This is an artifact of the history of how NumPy and TensorFlow were created.", "tokens": [50364, 639, 307, 364, 34806, 295, 264, 2503, 295, 577, 22592, 47, 88, 293, 37624, 645, 2942, 13, 50653, 50653, 400, 7015, 11, 456, 366, 732, 2098, 295, 13460, 257, 8141, 300, 362, 668, 19453, 666, 613, 3652, 13, 51071, 51071, 400, 294, 1186, 11, 498, 291, 528, 281, 747, 257, 472, 11, 597, 307, 257, 40863, 293, 528, 281, 7620, 309, 646, 281, 51389, 51389, 22592, 47, 88, 10225, 11, 291, 393, 360, 370, 365, 341, 2445, 257, 472, 5893, 22592, 47, 88, 293, 309, 486, 747, 264, 912, 51693, 51693], "temperature": 0.0, "avg_logprob": -0.12371727728074597, "compression_ratio": 1.5866666666666667, "no_speech_prob": 4.222616098559229e-06}, {"id": 106, "seek": 52010, "start": 525.88, "end": 534.24, "text": " And unfortunately, there are two ways of representing a matrix that have been baked into these systems.", "tokens": [50364, 639, 307, 364, 34806, 295, 264, 2503, 295, 577, 22592, 47, 88, 293, 37624, 645, 2942, 13, 50653, 50653, 400, 7015, 11, 456, 366, 732, 2098, 295, 13460, 257, 8141, 300, 362, 668, 19453, 666, 613, 3652, 13, 51071, 51071, 400, 294, 1186, 11, 498, 291, 528, 281, 747, 257, 472, 11, 597, 307, 257, 40863, 293, 528, 281, 7620, 309, 646, 281, 51389, 51389, 22592, 47, 88, 10225, 11, 291, 393, 360, 370, 365, 341, 2445, 257, 472, 5893, 22592, 47, 88, 293, 309, 486, 747, 264, 912, 51693, 51693], "temperature": 0.0, "avg_logprob": -0.12371727728074597, "compression_ratio": 1.5866666666666667, "no_speech_prob": 4.222616098559229e-06}, {"id": 107, "seek": 52010, "start": 534.24, "end": 540.6, "text": " And in fact, if you want to take a one, which is a tensor and want to convert it back to", "tokens": [50364, 639, 307, 364, 34806, 295, 264, 2503, 295, 577, 22592, 47, 88, 293, 37624, 645, 2942, 13, 50653, 50653, 400, 7015, 11, 456, 366, 732, 2098, 295, 13460, 257, 8141, 300, 362, 668, 19453, 666, 613, 3652, 13, 51071, 51071, 400, 294, 1186, 11, 498, 291, 528, 281, 747, 257, 472, 11, 597, 307, 257, 40863, 293, 528, 281, 7620, 309, 646, 281, 51389, 51389, 22592, 47, 88, 10225, 11, 291, 393, 360, 370, 365, 341, 2445, 257, 472, 5893, 22592, 47, 88, 293, 309, 486, 747, 264, 912, 51693, 51693], "temperature": 0.0, "avg_logprob": -0.12371727728074597, "compression_ratio": 1.5866666666666667, "no_speech_prob": 4.222616098559229e-06}, {"id": 108, "seek": 52010, "start": 540.6, "end": 546.6800000000001, "text": " NumPy array, you can do so with this function a one dot NumPy and it will take the same", "tokens": [50364, 639, 307, 364, 34806, 295, 264, 2503, 295, 577, 22592, 47, 88, 293, 37624, 645, 2942, 13, 50653, 50653, 400, 7015, 11, 456, 366, 732, 2098, 295, 13460, 257, 8141, 300, 362, 668, 19453, 666, 613, 3652, 13, 51071, 51071, 400, 294, 1186, 11, 498, 291, 528, 281, 747, 257, 472, 11, 597, 307, 257, 40863, 293, 528, 281, 7620, 309, 646, 281, 51389, 51389, 22592, 47, 88, 10225, 11, 291, 393, 360, 370, 365, 341, 2445, 257, 472, 5893, 22592, 47, 88, 293, 309, 486, 747, 264, 912, 51693, 51693], "temperature": 0.0, "avg_logprob": -0.12371727728074597, "compression_ratio": 1.5866666666666667, "no_speech_prob": 4.222616098559229e-06}, {"id": 109, "seek": 54668, "start": 546.68, "end": 553.0799999999999, "text": " data and return it in the form of a NumPy array rather than in the form of a TensorFlow", "tokens": [50364, 1412, 293, 2736, 309, 294, 264, 1254, 295, 257, 22592, 47, 88, 10225, 2831, 813, 294, 264, 1254, 295, 257, 37624, 50684, 50684, 10225, 420, 37624, 8141, 13, 50776, 50776, 823, 718, 311, 747, 257, 574, 412, 437, 264, 2430, 763, 5598, 538, 264, 1150, 4583, 576, 574, 411, 13, 51028, 51028, 1692, 311, 264, 3089, 300, 321, 632, 490, 949, 13, 51134, 51134, 35166, 732, 307, 257, 18011, 4583, 365, 472, 4985, 293, 257, 2309, 935, 24433, 13, 51316, 51316, 400, 257, 732, 307, 40610, 538, 1940, 4583, 732, 293, 9275, 309, 281, 257, 472, 13, 51513, 51513, 407, 437, 307, 257, 732, 30, 51588, 51588], "temperature": 0.0, "avg_logprob": -0.1727961618965919, "compression_ratio": 1.684873949579832, "no_speech_prob": 8.800383511697873e-06}, {"id": 110, "seek": 54668, "start": 553.0799999999999, "end": 554.92, "text": " array or TensorFlow matrix.", "tokens": [50364, 1412, 293, 2736, 309, 294, 264, 1254, 295, 257, 22592, 47, 88, 10225, 2831, 813, 294, 264, 1254, 295, 257, 37624, 50684, 50684, 10225, 420, 37624, 8141, 13, 50776, 50776, 823, 718, 311, 747, 257, 574, 412, 437, 264, 2430, 763, 5598, 538, 264, 1150, 4583, 576, 574, 411, 13, 51028, 51028, 1692, 311, 264, 3089, 300, 321, 632, 490, 949, 13, 51134, 51134, 35166, 732, 307, 257, 18011, 4583, 365, 472, 4985, 293, 257, 2309, 935, 24433, 13, 51316, 51316, 400, 257, 732, 307, 40610, 538, 1940, 4583, 732, 293, 9275, 309, 281, 257, 472, 13, 51513, 51513, 407, 437, 307, 257, 732, 30, 51588, 51588], "temperature": 0.0, "avg_logprob": -0.1727961618965919, "compression_ratio": 1.684873949579832, "no_speech_prob": 8.800383511697873e-06}, {"id": 111, "seek": 54668, "start": 554.92, "end": 559.9599999999999, "text": " Now let's take a look at what the activations output by the second layer would look like.", "tokens": [50364, 1412, 293, 2736, 309, 294, 264, 1254, 295, 257, 22592, 47, 88, 10225, 2831, 813, 294, 264, 1254, 295, 257, 37624, 50684, 50684, 10225, 420, 37624, 8141, 13, 50776, 50776, 823, 718, 311, 747, 257, 574, 412, 437, 264, 2430, 763, 5598, 538, 264, 1150, 4583, 576, 574, 411, 13, 51028, 51028, 1692, 311, 264, 3089, 300, 321, 632, 490, 949, 13, 51134, 51134, 35166, 732, 307, 257, 18011, 4583, 365, 472, 4985, 293, 257, 2309, 935, 24433, 13, 51316, 51316, 400, 257, 732, 307, 40610, 538, 1940, 4583, 732, 293, 9275, 309, 281, 257, 472, 13, 51513, 51513, 407, 437, 307, 257, 732, 30, 51588, 51588], "temperature": 0.0, "avg_logprob": -0.1727961618965919, "compression_ratio": 1.684873949579832, "no_speech_prob": 8.800383511697873e-06}, {"id": 112, "seek": 54668, "start": 559.9599999999999, "end": 562.0799999999999, "text": " Here's the code that we had from before.", "tokens": [50364, 1412, 293, 2736, 309, 294, 264, 1254, 295, 257, 22592, 47, 88, 10225, 2831, 813, 294, 264, 1254, 295, 257, 37624, 50684, 50684, 10225, 420, 37624, 8141, 13, 50776, 50776, 823, 718, 311, 747, 257, 574, 412, 437, 264, 2430, 763, 5598, 538, 264, 1150, 4583, 576, 574, 411, 13, 51028, 51028, 1692, 311, 264, 3089, 300, 321, 632, 490, 949, 13, 51134, 51134, 35166, 732, 307, 257, 18011, 4583, 365, 472, 4985, 293, 257, 2309, 935, 24433, 13, 51316, 51316, 400, 257, 732, 307, 40610, 538, 1940, 4583, 732, 293, 9275, 309, 281, 257, 472, 13, 51513, 51513, 407, 437, 307, 257, 732, 30, 51588, 51588], "temperature": 0.0, "avg_logprob": -0.1727961618965919, "compression_ratio": 1.684873949579832, "no_speech_prob": 8.800383511697873e-06}, {"id": 113, "seek": 54668, "start": 562.0799999999999, "end": 565.7199999999999, "text": " Layer two is a dense layer with one unit and a six point activation.", "tokens": [50364, 1412, 293, 2736, 309, 294, 264, 1254, 295, 257, 22592, 47, 88, 10225, 2831, 813, 294, 264, 1254, 295, 257, 37624, 50684, 50684, 10225, 420, 37624, 8141, 13, 50776, 50776, 823, 718, 311, 747, 257, 574, 412, 437, 264, 2430, 763, 5598, 538, 264, 1150, 4583, 576, 574, 411, 13, 51028, 51028, 1692, 311, 264, 3089, 300, 321, 632, 490, 949, 13, 51134, 51134, 35166, 732, 307, 257, 18011, 4583, 365, 472, 4985, 293, 257, 2309, 935, 24433, 13, 51316, 51316, 400, 257, 732, 307, 40610, 538, 1940, 4583, 732, 293, 9275, 309, 281, 257, 472, 13, 51513, 51513, 407, 437, 307, 257, 732, 30, 51588, 51588], "temperature": 0.0, "avg_logprob": -0.1727961618965919, "compression_ratio": 1.684873949579832, "no_speech_prob": 8.800383511697873e-06}, {"id": 114, "seek": 54668, "start": 565.7199999999999, "end": 569.66, "text": " And a two is computed by taking layer two and applying it to a one.", "tokens": [50364, 1412, 293, 2736, 309, 294, 264, 1254, 295, 257, 22592, 47, 88, 10225, 2831, 813, 294, 264, 1254, 295, 257, 37624, 50684, 50684, 10225, 420, 37624, 8141, 13, 50776, 50776, 823, 718, 311, 747, 257, 574, 412, 437, 264, 2430, 763, 5598, 538, 264, 1150, 4583, 576, 574, 411, 13, 51028, 51028, 1692, 311, 264, 3089, 300, 321, 632, 490, 949, 13, 51134, 51134, 35166, 732, 307, 257, 18011, 4583, 365, 472, 4985, 293, 257, 2309, 935, 24433, 13, 51316, 51316, 400, 257, 732, 307, 40610, 538, 1940, 4583, 732, 293, 9275, 309, 281, 257, 472, 13, 51513, 51513, 407, 437, 307, 257, 732, 30, 51588, 51588], "temperature": 0.0, "avg_logprob": -0.1727961618965919, "compression_ratio": 1.684873949579832, "no_speech_prob": 8.800383511697873e-06}, {"id": 115, "seek": 54668, "start": 569.66, "end": 571.16, "text": " So what is a two?", "tokens": [50364, 1412, 293, 2736, 309, 294, 264, 1254, 295, 257, 22592, 47, 88, 10225, 2831, 813, 294, 264, 1254, 295, 257, 37624, 50684, 50684, 10225, 420, 37624, 8141, 13, 50776, 50776, 823, 718, 311, 747, 257, 574, 412, 437, 264, 2430, 763, 5598, 538, 264, 1150, 4583, 576, 574, 411, 13, 51028, 51028, 1692, 311, 264, 3089, 300, 321, 632, 490, 949, 13, 51134, 51134, 35166, 732, 307, 257, 18011, 4583, 365, 472, 4985, 293, 257, 2309, 935, 24433, 13, 51316, 51316, 400, 257, 732, 307, 40610, 538, 1940, 4583, 732, 293, 9275, 309, 281, 257, 472, 13, 51513, 51513, 407, 437, 307, 257, 732, 30, 51588, 51588], "temperature": 0.0, "avg_logprob": -0.1727961618965919, "compression_ratio": 1.684873949579832, "no_speech_prob": 8.800383511697873e-06}, {"id": 116, "seek": 57116, "start": 571.16, "end": 578.88, "text": " A two may be a number like 0.8 and technically this is a one by one matrix.", "tokens": [50364, 316, 732, 815, 312, 257, 1230, 411, 1958, 13, 23, 293, 12120, 341, 307, 257, 472, 538, 472, 8141, 13, 50750, 50750, 467, 311, 257, 568, 35, 10225, 365, 472, 5386, 293, 472, 7738, 13, 50948, 50948, 400, 370, 309, 311, 2681, 281, 341, 1230, 1958, 13, 23, 13, 51242, 51242, 400, 498, 291, 4482, 484, 257, 732, 11, 291, 536, 300, 309, 307, 257, 37624, 40863, 365, 445, 472, 4478, 11, 51580, 51580, 472, 1230, 1958, 13, 23, 13, 51676, 51676, 400, 309, 307, 257, 472, 538, 472, 8141, 13, 51838, 51838], "temperature": 0.0, "avg_logprob": -0.16865316692151522, "compression_ratio": 1.6480446927374302, "no_speech_prob": 1.363071714877151e-05}, {"id": 117, "seek": 57116, "start": 578.88, "end": 582.8399999999999, "text": " It's a 2D array with one row and one column.", "tokens": [50364, 316, 732, 815, 312, 257, 1230, 411, 1958, 13, 23, 293, 12120, 341, 307, 257, 472, 538, 472, 8141, 13, 50750, 50750, 467, 311, 257, 568, 35, 10225, 365, 472, 5386, 293, 472, 7738, 13, 50948, 50948, 400, 370, 309, 311, 2681, 281, 341, 1230, 1958, 13, 23, 13, 51242, 51242, 400, 498, 291, 4482, 484, 257, 732, 11, 291, 536, 300, 309, 307, 257, 37624, 40863, 365, 445, 472, 4478, 11, 51580, 51580, 472, 1230, 1958, 13, 23, 13, 51676, 51676, 400, 309, 307, 257, 472, 538, 472, 8141, 13, 51838, 51838], "temperature": 0.0, "avg_logprob": -0.16865316692151522, "compression_ratio": 1.6480446927374302, "no_speech_prob": 1.363071714877151e-05}, {"id": 118, "seek": 57116, "start": 582.8399999999999, "end": 588.7199999999999, "text": " And so it's equal to this number 0.8.", "tokens": [50364, 316, 732, 815, 312, 257, 1230, 411, 1958, 13, 23, 293, 12120, 341, 307, 257, 472, 538, 472, 8141, 13, 50750, 50750, 467, 311, 257, 568, 35, 10225, 365, 472, 5386, 293, 472, 7738, 13, 50948, 50948, 400, 370, 309, 311, 2681, 281, 341, 1230, 1958, 13, 23, 13, 51242, 51242, 400, 498, 291, 4482, 484, 257, 732, 11, 291, 536, 300, 309, 307, 257, 37624, 40863, 365, 445, 472, 4478, 11, 51580, 51580, 472, 1230, 1958, 13, 23, 13, 51676, 51676, 400, 309, 307, 257, 472, 538, 472, 8141, 13, 51838, 51838], "temperature": 0.0, "avg_logprob": -0.16865316692151522, "compression_ratio": 1.6480446927374302, "no_speech_prob": 1.363071714877151e-05}, {"id": 119, "seek": 57116, "start": 588.7199999999999, "end": 595.48, "text": " And if you print out a two, you see that it is a TensorFlow tensor with just one element,", "tokens": [50364, 316, 732, 815, 312, 257, 1230, 411, 1958, 13, 23, 293, 12120, 341, 307, 257, 472, 538, 472, 8141, 13, 50750, 50750, 467, 311, 257, 568, 35, 10225, 365, 472, 5386, 293, 472, 7738, 13, 50948, 50948, 400, 370, 309, 311, 2681, 281, 341, 1230, 1958, 13, 23, 13, 51242, 51242, 400, 498, 291, 4482, 484, 257, 732, 11, 291, 536, 300, 309, 307, 257, 37624, 40863, 365, 445, 472, 4478, 11, 51580, 51580, 472, 1230, 1958, 13, 23, 13, 51676, 51676, 400, 309, 307, 257, 472, 538, 472, 8141, 13, 51838, 51838], "temperature": 0.0, "avg_logprob": -0.16865316692151522, "compression_ratio": 1.6480446927374302, "no_speech_prob": 1.363071714877151e-05}, {"id": 120, "seek": 57116, "start": 595.48, "end": 597.4, "text": " one number 0.8.", "tokens": [50364, 316, 732, 815, 312, 257, 1230, 411, 1958, 13, 23, 293, 12120, 341, 307, 257, 472, 538, 472, 8141, 13, 50750, 50750, 467, 311, 257, 568, 35, 10225, 365, 472, 5386, 293, 472, 7738, 13, 50948, 50948, 400, 370, 309, 311, 2681, 281, 341, 1230, 1958, 13, 23, 13, 51242, 51242, 400, 498, 291, 4482, 484, 257, 732, 11, 291, 536, 300, 309, 307, 257, 37624, 40863, 365, 445, 472, 4478, 11, 51580, 51580, 472, 1230, 1958, 13, 23, 13, 51676, 51676, 400, 309, 307, 257, 472, 538, 472, 8141, 13, 51838, 51838], "temperature": 0.0, "avg_logprob": -0.16865316692151522, "compression_ratio": 1.6480446927374302, "no_speech_prob": 1.363071714877151e-05}, {"id": 121, "seek": 57116, "start": 597.4, "end": 600.64, "text": " And it is a one by one matrix.", "tokens": [50364, 316, 732, 815, 312, 257, 1230, 411, 1958, 13, 23, 293, 12120, 341, 307, 257, 472, 538, 472, 8141, 13, 50750, 50750, 467, 311, 257, 568, 35, 10225, 365, 472, 5386, 293, 472, 7738, 13, 50948, 50948, 400, 370, 309, 311, 2681, 281, 341, 1230, 1958, 13, 23, 13, 51242, 51242, 400, 498, 291, 4482, 484, 257, 732, 11, 291, 536, 300, 309, 307, 257, 37624, 40863, 365, 445, 472, 4478, 11, 51580, 51580, 472, 1230, 1958, 13, 23, 13, 51676, 51676, 400, 309, 307, 257, 472, 538, 472, 8141, 13, 51838, 51838], "temperature": 0.0, "avg_logprob": -0.16865316692151522, "compression_ratio": 1.6480446927374302, "no_speech_prob": 1.363071714877151e-05}, {"id": 122, "seek": 60064, "start": 600.64, "end": 608.76, "text": " Again it is a flow 32 decimal point number taking up 32 bits in computer memory.", "tokens": [50364, 3764, 309, 307, 257, 3095, 8858, 26601, 935, 1230, 1940, 493, 8858, 9239, 294, 3820, 4675, 13, 50770, 50770, 3443, 797, 291, 393, 7620, 490, 257, 37624, 40863, 281, 257, 22592, 47, 88, 8141, 1228, 257, 732, 5893, 22592, 47, 88, 51226, 51226, 293, 300, 486, 1261, 341, 646, 666, 257, 22592, 47, 88, 10225, 300, 1542, 411, 341, 13, 51478, 51478, 407, 300, 4696, 2709, 291, 257, 2020, 295, 577, 1412, 307, 10379, 294, 37624, 293, 294, 22592, 47, 88, 13, 51800, 51800], "temperature": 0.0, "avg_logprob": -0.11550622762635697, "compression_ratio": 1.5560747663551402, "no_speech_prob": 5.862607395101804e-06}, {"id": 123, "seek": 60064, "start": 608.76, "end": 617.88, "text": " Once again you can convert from a TensorFlow tensor to a NumPy matrix using a two dot NumPy", "tokens": [50364, 3764, 309, 307, 257, 3095, 8858, 26601, 935, 1230, 1940, 493, 8858, 9239, 294, 3820, 4675, 13, 50770, 50770, 3443, 797, 291, 393, 7620, 490, 257, 37624, 40863, 281, 257, 22592, 47, 88, 8141, 1228, 257, 732, 5893, 22592, 47, 88, 51226, 51226, 293, 300, 486, 1261, 341, 646, 666, 257, 22592, 47, 88, 10225, 300, 1542, 411, 341, 13, 51478, 51478, 407, 300, 4696, 2709, 291, 257, 2020, 295, 577, 1412, 307, 10379, 294, 37624, 293, 294, 22592, 47, 88, 13, 51800, 51800], "temperature": 0.0, "avg_logprob": -0.11550622762635697, "compression_ratio": 1.5560747663551402, "no_speech_prob": 5.862607395101804e-06}, {"id": 124, "seek": 60064, "start": 617.88, "end": 622.92, "text": " and that will turn this back into a NumPy array that looks like this.", "tokens": [50364, 3764, 309, 307, 257, 3095, 8858, 26601, 935, 1230, 1940, 493, 8858, 9239, 294, 3820, 4675, 13, 50770, 50770, 3443, 797, 291, 393, 7620, 490, 257, 37624, 40863, 281, 257, 22592, 47, 88, 8141, 1228, 257, 732, 5893, 22592, 47, 88, 51226, 51226, 293, 300, 486, 1261, 341, 646, 666, 257, 22592, 47, 88, 10225, 300, 1542, 411, 341, 13, 51478, 51478, 407, 300, 4696, 2709, 291, 257, 2020, 295, 577, 1412, 307, 10379, 294, 37624, 293, 294, 22592, 47, 88, 13, 51800, 51800], "temperature": 0.0, "avg_logprob": -0.11550622762635697, "compression_ratio": 1.5560747663551402, "no_speech_prob": 5.862607395101804e-06}, {"id": 125, "seek": 60064, "start": 622.92, "end": 629.36, "text": " So that hopefully gives you a sense of how data is represented in TensorFlow and in NumPy.", "tokens": [50364, 3764, 309, 307, 257, 3095, 8858, 26601, 935, 1230, 1940, 493, 8858, 9239, 294, 3820, 4675, 13, 50770, 50770, 3443, 797, 291, 393, 7620, 490, 257, 37624, 40863, 281, 257, 22592, 47, 88, 8141, 1228, 257, 732, 5893, 22592, 47, 88, 51226, 51226, 293, 300, 486, 1261, 341, 646, 666, 257, 22592, 47, 88, 10225, 300, 1542, 411, 341, 13, 51478, 51478, 407, 300, 4696, 2709, 291, 257, 2020, 295, 577, 1412, 307, 10379, 294, 37624, 293, 294, 22592, 47, 88, 13, 51800, 51800], "temperature": 0.0, "avg_logprob": -0.11550622762635697, "compression_ratio": 1.5560747663551402, "no_speech_prob": 5.862607395101804e-06}, {"id": 126, "seek": 62936, "start": 629.36, "end": 633.72, "text": " I'm used to loading data and manipulating data in NumPy.", "tokens": [50364, 286, 478, 1143, 281, 15114, 1412, 293, 40805, 1412, 294, 22592, 47, 88, 13, 50582, 50582, 583, 562, 291, 1320, 257, 22592, 47, 88, 10225, 666, 37624, 11, 37624, 5902, 281, 7620, 309, 281, 1080, 1065, 50818, 50818, 6920, 7877, 11, 264, 40863, 11, 293, 550, 9651, 19621, 1228, 10688, 830, 13, 51104, 51104, 400, 562, 291, 1401, 264, 1412, 646, 484, 11, 291, 393, 1066, 309, 382, 257, 40863, 420, 7620, 309, 646, 281, 51340, 51340, 257, 22592, 47, 88, 10225, 13, 51436, 51436, 286, 519, 309, 311, 257, 857, 17843, 300, 264, 2503, 295, 577, 613, 15148, 16693, 575, 4684, 505, 281, 51702, 51702], "temperature": 0.0, "avg_logprob": -0.1174817438478823, "compression_ratio": 1.6693548387096775, "no_speech_prob": 1.1726052662197617e-06}, {"id": 127, "seek": 62936, "start": 633.72, "end": 638.44, "text": " But when you pass a NumPy array into TensorFlow, TensorFlow likes to convert it to its own", "tokens": [50364, 286, 478, 1143, 281, 15114, 1412, 293, 40805, 1412, 294, 22592, 47, 88, 13, 50582, 50582, 583, 562, 291, 1320, 257, 22592, 47, 88, 10225, 666, 37624, 11, 37624, 5902, 281, 7620, 309, 281, 1080, 1065, 50818, 50818, 6920, 7877, 11, 264, 40863, 11, 293, 550, 9651, 19621, 1228, 10688, 830, 13, 51104, 51104, 400, 562, 291, 1401, 264, 1412, 646, 484, 11, 291, 393, 1066, 309, 382, 257, 40863, 420, 7620, 309, 646, 281, 51340, 51340, 257, 22592, 47, 88, 10225, 13, 51436, 51436, 286, 519, 309, 311, 257, 857, 17843, 300, 264, 2503, 295, 577, 613, 15148, 16693, 575, 4684, 505, 281, 51702, 51702], "temperature": 0.0, "avg_logprob": -0.1174817438478823, "compression_ratio": 1.6693548387096775, "no_speech_prob": 1.1726052662197617e-06}, {"id": 128, "seek": 62936, "start": 638.44, "end": 644.16, "text": " internal format, the tensor, and then operate efficiently using tensors.", "tokens": [50364, 286, 478, 1143, 281, 15114, 1412, 293, 40805, 1412, 294, 22592, 47, 88, 13, 50582, 50582, 583, 562, 291, 1320, 257, 22592, 47, 88, 10225, 666, 37624, 11, 37624, 5902, 281, 7620, 309, 281, 1080, 1065, 50818, 50818, 6920, 7877, 11, 264, 40863, 11, 293, 550, 9651, 19621, 1228, 10688, 830, 13, 51104, 51104, 400, 562, 291, 1401, 264, 1412, 646, 484, 11, 291, 393, 1066, 309, 382, 257, 40863, 420, 7620, 309, 646, 281, 51340, 51340, 257, 22592, 47, 88, 10225, 13, 51436, 51436, 286, 519, 309, 311, 257, 857, 17843, 300, 264, 2503, 295, 577, 613, 15148, 16693, 575, 4684, 505, 281, 51702, 51702], "temperature": 0.0, "avg_logprob": -0.1174817438478823, "compression_ratio": 1.6693548387096775, "no_speech_prob": 1.1726052662197617e-06}, {"id": 129, "seek": 62936, "start": 644.16, "end": 648.88, "text": " And when you read the data back out, you can keep it as a tensor or convert it back to", "tokens": [50364, 286, 478, 1143, 281, 15114, 1412, 293, 40805, 1412, 294, 22592, 47, 88, 13, 50582, 50582, 583, 562, 291, 1320, 257, 22592, 47, 88, 10225, 666, 37624, 11, 37624, 5902, 281, 7620, 309, 281, 1080, 1065, 50818, 50818, 6920, 7877, 11, 264, 40863, 11, 293, 550, 9651, 19621, 1228, 10688, 830, 13, 51104, 51104, 400, 562, 291, 1401, 264, 1412, 646, 484, 11, 291, 393, 1066, 309, 382, 257, 40863, 420, 7620, 309, 646, 281, 51340, 51340, 257, 22592, 47, 88, 10225, 13, 51436, 51436, 286, 519, 309, 311, 257, 857, 17843, 300, 264, 2503, 295, 577, 613, 15148, 16693, 575, 4684, 505, 281, 51702, 51702], "temperature": 0.0, "avg_logprob": -0.1174817438478823, "compression_ratio": 1.6693548387096775, "no_speech_prob": 1.1726052662197617e-06}, {"id": 130, "seek": 62936, "start": 648.88, "end": 650.8000000000001, "text": " a NumPy array.", "tokens": [50364, 286, 478, 1143, 281, 15114, 1412, 293, 40805, 1412, 294, 22592, 47, 88, 13, 50582, 50582, 583, 562, 291, 1320, 257, 22592, 47, 88, 10225, 666, 37624, 11, 37624, 5902, 281, 7620, 309, 281, 1080, 1065, 50818, 50818, 6920, 7877, 11, 264, 40863, 11, 293, 550, 9651, 19621, 1228, 10688, 830, 13, 51104, 51104, 400, 562, 291, 1401, 264, 1412, 646, 484, 11, 291, 393, 1066, 309, 382, 257, 40863, 420, 7620, 309, 646, 281, 51340, 51340, 257, 22592, 47, 88, 10225, 13, 51436, 51436, 286, 519, 309, 311, 257, 857, 17843, 300, 264, 2503, 295, 577, 613, 15148, 16693, 575, 4684, 505, 281, 51702, 51702], "temperature": 0.0, "avg_logprob": -0.1174817438478823, "compression_ratio": 1.6693548387096775, "no_speech_prob": 1.1726052662197617e-06}, {"id": 131, "seek": 62936, "start": 650.8000000000001, "end": 656.12, "text": " I think it's a bit unfortunate that the history of how these libraries evolve has led us to", "tokens": [50364, 286, 478, 1143, 281, 15114, 1412, 293, 40805, 1412, 294, 22592, 47, 88, 13, 50582, 50582, 583, 562, 291, 1320, 257, 22592, 47, 88, 10225, 666, 37624, 11, 37624, 5902, 281, 7620, 309, 281, 1080, 1065, 50818, 50818, 6920, 7877, 11, 264, 40863, 11, 293, 550, 9651, 19621, 1228, 10688, 830, 13, 51104, 51104, 400, 562, 291, 1401, 264, 1412, 646, 484, 11, 291, 393, 1066, 309, 382, 257, 40863, 420, 7620, 309, 646, 281, 51340, 51340, 257, 22592, 47, 88, 10225, 13, 51436, 51436, 286, 519, 309, 311, 257, 857, 17843, 300, 264, 2503, 295, 577, 613, 15148, 16693, 575, 4684, 505, 281, 51702, 51702], "temperature": 0.0, "avg_logprob": -0.1174817438478823, "compression_ratio": 1.6693548387096775, "no_speech_prob": 1.1726052662197617e-06}, {"id": 132, "seek": 65612, "start": 656.12, "end": 662.72, "text": " do this extra conversion work when actually the two libraries can work quite well together.", "tokens": [50364, 360, 341, 2857, 14298, 589, 562, 767, 264, 732, 15148, 393, 589, 1596, 731, 1214, 13, 50694, 50694, 583, 562, 291, 7620, 646, 293, 5220, 11, 1968, 291, 434, 1228, 257, 22592, 47, 88, 10225, 420, 257, 40863, 11, 309, 311, 50958, 50958, 445, 746, 281, 312, 3650, 295, 562, 291, 434, 3579, 3089, 13, 51122, 51122, 3087, 11, 718, 311, 747, 437, 321, 600, 3264, 293, 829, 309, 1214, 281, 767, 1322, 257, 18161, 3209, 13, 51394, 51394, 961, 311, 352, 536, 300, 294, 264, 958, 960, 13, 51480], "temperature": 0.0, "avg_logprob": -0.13055812794229257, "compression_ratio": 1.605263157894737, "no_speech_prob": 2.5455072318436578e-05}, {"id": 133, "seek": 65612, "start": 662.72, "end": 668.0, "text": " But when you convert back and forth, whether you're using a NumPy array or a tensor, it's", "tokens": [50364, 360, 341, 2857, 14298, 589, 562, 767, 264, 732, 15148, 393, 589, 1596, 731, 1214, 13, 50694, 50694, 583, 562, 291, 7620, 646, 293, 5220, 11, 1968, 291, 434, 1228, 257, 22592, 47, 88, 10225, 420, 257, 40863, 11, 309, 311, 50958, 50958, 445, 746, 281, 312, 3650, 295, 562, 291, 434, 3579, 3089, 13, 51122, 51122, 3087, 11, 718, 311, 747, 437, 321, 600, 3264, 293, 829, 309, 1214, 281, 767, 1322, 257, 18161, 3209, 13, 51394, 51394, 961, 311, 352, 536, 300, 294, 264, 958, 960, 13, 51480], "temperature": 0.0, "avg_logprob": -0.13055812794229257, "compression_ratio": 1.605263157894737, "no_speech_prob": 2.5455072318436578e-05}, {"id": 134, "seek": 65612, "start": 668.0, "end": 671.28, "text": " just something to be aware of when you're writing code.", "tokens": [50364, 360, 341, 2857, 14298, 589, 562, 767, 264, 732, 15148, 393, 589, 1596, 731, 1214, 13, 50694, 50694, 583, 562, 291, 7620, 646, 293, 5220, 11, 1968, 291, 434, 1228, 257, 22592, 47, 88, 10225, 420, 257, 40863, 11, 309, 311, 50958, 50958, 445, 746, 281, 312, 3650, 295, 562, 291, 434, 3579, 3089, 13, 51122, 51122, 3087, 11, 718, 311, 747, 437, 321, 600, 3264, 293, 829, 309, 1214, 281, 767, 1322, 257, 18161, 3209, 13, 51394, 51394, 961, 311, 352, 536, 300, 294, 264, 958, 960, 13, 51480], "temperature": 0.0, "avg_logprob": -0.13055812794229257, "compression_ratio": 1.605263157894737, "no_speech_prob": 2.5455072318436578e-05}, {"id": 135, "seek": 65612, "start": 671.28, "end": 676.72, "text": " Next, let's take what we've learned and put it together to actually build a neural network.", "tokens": [50364, 360, 341, 2857, 14298, 589, 562, 767, 264, 732, 15148, 393, 589, 1596, 731, 1214, 13, 50694, 50694, 583, 562, 291, 7620, 646, 293, 5220, 11, 1968, 291, 434, 1228, 257, 22592, 47, 88, 10225, 420, 257, 40863, 11, 309, 311, 50958, 50958, 445, 746, 281, 312, 3650, 295, 562, 291, 434, 3579, 3089, 13, 51122, 51122, 3087, 11, 718, 311, 747, 437, 321, 600, 3264, 293, 829, 309, 1214, 281, 767, 1322, 257, 18161, 3209, 13, 51394, 51394, 961, 311, 352, 536, 300, 294, 264, 958, 960, 13, 51480], "temperature": 0.0, "avg_logprob": -0.13055812794229257, "compression_ratio": 1.605263157894737, "no_speech_prob": 2.5455072318436578e-05}, {"id": 136, "seek": 67672, "start": 676.72, "end": 686.76, "text": " Let's go see that in the next video.", "tokens": [50364, 961, 311, 352, 536, 300, 294, 264, 958, 960, 13, 50866], "temperature": 0.0, "avg_logprob": -0.4425694392277644, "compression_ratio": 0.8571428571428571, "no_speech_prob": 0.00017641379963606596}], "language": "en", "video_id": "Q3cLU1trK_E", "entity": "ML Specialization, Andrew Ng (2022)"}}