{"video_id": "tVwV14YkbYs", "title": "Week 7 \u2013 Lecture: Energy based models and self-supervised learning", "description": "Course website: http://bit.ly/pDL-home\nPlaylist: http://bit.ly/pDL-YouTube\nSpeaker: Yann LeCun\nWeek 7: http://bit.ly/pDL-en-07\n\n0:00:00 \u2013 Week 7 \u2013 Lecture\n\nLECTURE Part A: http://bit.ly/pDL-en-07-1\nWe introduced the concept of the energy-based models and the intention for different approaches other than feed-forward networks. To solve the difficulty of the inference in EBM, latent variables are used to provide auxiliary information and enable multiple possible predictions. Finally, the EBM can generalize to probabilistic model with more flexible scoring functions.\n0:01:04 \u2013 Energy-based model concept\n0:15:04 \u2013 Latent-variable EBM: inference \n0:28:23 \u2013 EBM vs. probabilistic models\n\nLECTURE Part B: http://bit.ly/pDL-en-07-2\nWe discussed self-supervised learning, introduced how to train an Energy-based models, discussed Latent Variable EBM, specifically with an explained K-means example. We also introduced Contrastive Methods, explained a denoising autoencoder with a topographic map, the training process, and how it can be used, followed by an introduction to BERT. Finally, we talked about Contrastive Divergence, also explained using a topographic map.\n0:44:43 \u2013 Self-supervised learning\n1:05:57 \u2013 Training an Energy-Based Model\n1:19:27 \u2013 Latent Variable EBM, K-means example, Contrastive Methods", "author": "Alfredo Canziani", "keywords": ["Yann LeCun", "Deep Learning", "PyTorch", "NYU", "EBM", "Energy Based Models", "SSL", "Semi Supervised Learning", "LV", "Latent Variable"], "channel_url": "https://www.youtube.com/channel/UCupQLyNchb9-2Z5lmUOIijw", "length": 5839, "views": 25389, "publish_date": "11/02/2022", "timestamp": 1589500800, "entity": "Yann LeCun", "transcript": {"text": " Right, so we're going to talk about energy-based models, and it's basically a framework by which we can, through which we can express a lot of different learning algorithms. Not the ones that are kind of simple, like we've seen in supervised learning, but things that are a little more sophisticated, and it sort of encompasses also a lot of probabilistic methods, but it's a little simpler to understand, I think, than probabilistic methods. And probabilistic methods really are kind of a special case, if you want, of energy-based models. And I think it's kind of a framework that's a little sort of enlightening in the sense that it explains a lot of things that seem very different when you don't get this sort of unifying view of things. So what I'm going to talk about first applies equally well to supervised learning, what some people call unsupervised learning, or what I would call self-supervised learning, which I'll talk about a little bit today. And it's basically, we're going to talk about models that observe a set of variables X, and we're asking the model to predict a set of variables Y. And I'm not specifying that X is an image or whatever, and Y is a discrete variable, like for classification. Y could be like an entire view, and X could be an entire view, or X could be an image and Y a piece of text that describes it, or X could be a sentence in one language and Y a sentence in another language, X could be an entire text, and Y could be a simplified version of that text or an abstract. So it could be anything, really. I'm not kind of specifying necessarily here. But it comes from the fact that there's two issues with sort of feedforward models. Whether they are neural nets or something else doesn't matter. A model, a classical model, proceeds by doing a finite fixed number of calculations to produce an output. If you have a multilayer net, there is a fixed number of layers. Even if you have a recurrent net, there is some sort of limit to how many times you can unfold it. So it's basically a fixed amount of computation. But there are two issues for which this is not entirely appropriate. The first one, or two situations, the first situation is when computing the output requires some more complex calculation than just a bunch of weighted sums and non-linearity in a finite number, when the inference is complex. And the second situation is when we're trying to train the machine to produce not a single output but a possible set of outputs. So in the case of classification, we're actually training a machine to produce multiple outputs. We are training it to produce a separate score for every possible category that we have in our system. Ideally, the system would produce the best score for the correct class and infinitesimal scores for the other ones. In practice, when we run the output of a neural net through softmax, it produces the kind of scores and we just pick the one that has the highest score. But basically what we are telling the machine to do is produce a score for every category and then we'll pick the best. Now this is not possible when the output is continuous and high dimensional. So the output is, let's say, an image. We don't have softmaxes over images. We don't have a way of listing all possible images and then normalizing a distribution over them because it's high dimensional continuous space. Even if it were a low dimensional continuous space, it would not be possible. We would have to bin that continuous space into discrete bins and then do a softmax over that, but that doesn't work very well. It only works in low dimension. So when we have a high dimensional continuous space, we can do softmax. We can't ask the system to give us a score for all possible outputs. Similarly, even if it's discrete but potentially infinite, so things like we're producing text. Text is compositional and there is a very, very large number of possible texts over a given length and we can't just do a softmax over all possible texts. Same problem. So how do we represent a distribution or a bunch of scores over all possible texts in a compact form? That's where energy-based models come in or probabilistic models, so that matter, but energy-based models in particular. And the solution that energy-based models give us there is the idea that we're going to use an implicit function. In other words, we're not going to ask our system to produce a y. We're just going to ask it to tell us whether an x and a particular y we show it are compatible with each other. So is this text a good translation of that text? That sounds kind of weak, right? Because how are we going to come up with that text that our machine is comparing? But let's hold this for a bit. So we're going to use this function f of x, y. It's going to take an x and a y and it's going to tell us if those two values are compatible with each other or not. So is y a good label for the image x? Is y a good high resolution version of this low resolution image? If y a good translation of that sentence in German, etc. And so the inference procedure now is going to be given an x, find a y that produces a low value for which f of x, y produces a low value. In other words, find a y that's compatible with x. So search over possible y's for a value of y that produces a low value for f of x, y. So this is the idea of inference by minimizing some function. And pretty much every model probabilistic, non-probabilistic, whatever that people have thought about, can work this way. I mean except even classification, multi-class classification with neural nets or whatever, implicitly work by energy minimization by basically finding the class that has the best score which you can think of as the lowest energy. So basically we're going to try to find an output that satisfies a bunch of constraints and those constraints are implemented by this function f of x, y. And if you've heard of graphical models, digital networks, all that stuff, or even classical AI or SAT problems, they basically can all be formulated in those terms as finding the value of a set of variables that will minimize some function that measures their compatibility. So we're not talking about learning right now. We're just talking about inference. We're assuming this function f of x, y is given to you. We're going to talk about how we learn it a little later. Okay so the energy function is not what we minimize during learning. It's what we minimize during inference. So inference is computing y from x. So this energy function is scalar valued. It takes low values when y is compatible with x and higher values when y is not compatible with x. So you'd like this function to have a shape in such a way that for a given x, all the values of y that are compatible with this x have low energy and all the values that are not compatible with that given x have higher energy. And that's all you need because then the inference procedure is going to find the y check that written here, which is the value of y that minimizes f of x, y. It's not going to be the value, it's going to be a value because there might be multiple values. And your inference algorithm might actually go through multiple values or examine multiple values before giving you one or several. Okay let's take a very simple example in one dimension of scalar variables. So x here is a real value and y is a real value. And the blue dots here are data points. So what you want is if you want to capture the dependency between x and y in the data is that you would like an energy function that has either this shape or that shape or some other shape but which has a shape that in such a way that if you take a particular value of x, the value of y that has a lowest value is near the blue points, near the blue dots which are the data points. So a function like this captures the dependency between x and y. Now to do the inference of what is the best y for a given x, if you have a function like this you can use gradient descent. So if I give you an x to figure out what's the best value of y that corresponds to this x, you can start from some random y and then by gradient descent find the minimum of the function and you'll fall down to the blue beads here. Might be a little harder for this one but from the point of view of characterizing the dependency between those two variables, those two energy functions are just about as good as each other. But how would you make sure that y is a one-hot vector, like a classification? I'll come to this. The discrete case when y is discrete is the easy case, okay, and we've already talked about this and I'll kind of reformulate this in terms of energy in just a couple minutes. Okay, so a feedforward model is an explicit function in that it computes the prediction y from x but it can only make one prediction. We can cheat in the case of a discrete variable by putting out multiple outputs which correspond to a score for every possible classification. But in effect, but you can't use this trick for high dimensional continuous values or compositional values as I said earlier. So an energy-based model is really an implicit function. So remember, you know, in calculus when an implicit function you want the equation of a circle as a function of x and y. You can't write y as a function of x. You write an equation that says x squared plus y squared equals one and that gives you the unit circle. So x squared plus y squared minus one is an implicit function. And when you solve it equal to zero, you get the circle. So here's another example here. Again, scalar values for x and y and the black dots here are data points. So for the three value of x indicated by the red bar, there's multiple value of y that are compatible and some of them are actually sort of a continuum of values. So what we'd like our energy function to be is something that looks like this. It's basically here I'm sort of drawing the sort of level sets of that energy function. So it takes low energy on the data points and higher energy outside. This is kind of a slightly more complicated version of the little kind of 3D models that I showed earlier. And the question is how do we train a system so that it adopts, so that the energy function it computes actually has the proper shape? It's nice when y is continuous that f be smooth and differentiable so that we can use gradient based inference algorithms. So if we have a function like this and I give you a point x, y, you can, through gradient descent, you can find the point on the data manifold that is closest to it or something similar to that. If I give you a value for x, you can search by gradient descent along the y direction for a value that kind of minimizes it. So that's the inference algorithm. Well it's not an algorithm, it's really a prescription. Then the algorithm is how you do this minimization. And for that there's all kinds of different methods. Gradient based methods are one of them. There are all kinds of methods that are in the case where f is complicated, you may not have, it may not be possible to rely on such methods so you may have to use other tricks. In most cases though it simplifies. So just as an aside, for those of you who know what graphical models are, a graphical model is basically an energy based model where the energy function decomposes as a sum of energy terms and each energy term takes into account a subset of the variables that you're dealing with. So there would be kind of a collection of f's and some f's would take a subset of y, some f's would take a subset of x and y's, etc. And if they organize in a particular form then there are efficient inference algorithms to find the minimum of the sum of those terms with respect to the variable you're interested in inferring. So this is what belief propagation and all those algorithms do in graphical models. This is an aside, if you don't know what I'm talking about it doesn't matter. So as I said, the situations where you might want to use this is when inference basically is more complex than just running through a few layers of neural net. When the output is high dimensional and has structure like a sequence or an image or a sequence of images which is a video. When the output has compositional structure whether it's text, action sequences, things like that. Or when the output should result from sort of a long chain of reasoning. So it's not just, you know, I can just compute the output you need to kind of solve a constraint satisfaction problem to basically produce the output or do kind of long chains of reasoning. Okay, there's a particular type of energy-based models which is really where they start becoming interesting is energy-based model and involved latent variables. So an energy-based model that depends on latent variable, a latent variable EVM in this case would depend not just on the variable that you observe X and the variable you want to predict Y but also would depend on some extra variable Z that nobody tells you the value of. Okay? And the way you use this latent variable is that you build your model in such a way that it depends on the latent variable that if you knew the value of the latent variable the inference problem would become easier. So let's say you want to do handwriting recognition and I like this example which I told you about already. If you know where the characters are, reading this word becomes much easier. Okay? The main problem here in reading this word is not just to read the individual characters but to actually figure out where the characters are, like where one character ends, where the other one begins. And if I were to tell you that it would be much easier for you to read that word. In fact we're quite good at this so if you read this sequence of characters here in English, if you understand English you can probably parse it, you can probably figure out where the word boundaries are because you have this sort of high-level knowledge for where the words are in English. I do the same thing to you in French and you have no idea where the word boundaries are. Okay? So unless you speak French. So the word boundaries in this case and the character boundaries on top would be useful to solve the problem. It would allow you for example to, in the case of character recognition, to have individual character recognizers apply to each character but you don't know where they are so how do you solve that problem? So that's, that would be a useful latent variable. If I told you, so for speech recognition the problem is that you don't know where the boundaries between the words are, you don't know where the boundaries between the phonemes are either. Speech is very much like this continuous text, continuous speech. We can parse the words because we know where the words are, because we understand the language but someone speaking a language you don't understand you have a very faint idea of where the word boundaries are. Most of the time you can't. In languages where there is no stress, in English it's kind of easy because there's stress on the word so if you can figure out where the stress is you can probably figure out more or less where the word boundaries are. In French where there's no stress you can't, you have like no way of figuring out. Je peux dire une longue phrase en fran\u00e7ais, vous n'avez aucune id\u00e9e o\u00f9 sont les fronti\u00e8res entre les mots. So you know it's kind of a continuous string of phonemes and it's very hard to tell where the word boundaries are unless you know the language. So that would be a useful latent variable to have because if someone told you where those boundaries were then you would be able to do the task. So that's how you would use latent variables. And this word using latent variables has been used for decades in the context of speech recognition, in the context of natural language processing, in the context of character recognition as I said OCR and in a number of different other applications, particularly ones that involve sequences. But also in computer vision, so things like you know you want to kind of detect where a person is but you don't know how that person is dressed or what position that person is in, things like this. So you know those are variables that if you knew them would kind of help you solve the task although nowadays vision just works. Okay so if you have a latent variable model this is how you do inference. So you have a new energy function now it's called E not F, E of XYZ and to do inference you simultaneously minimize it with respect to Z and Y. Okay so you ask the system give me the combination of variables of Y and Z that minimize this energy function. I actually don't care about the values of Z I only care about the value of Y but I have to do this simultaneous minimization. Okay I'll give you some more concrete examples a little later. In fact that's equivalent to defining a new energy function F which I call F infinity here that only depends on X and Y. F infinity of XY is the min over Z of E of XYZ. You take a function of XYZ you find the minimum of this function over Z, Z now gets eliminated you get a function of X and Y. In practice you never do this but in practice you minimize with respect to Z and Y simultaneously because we don't know how to represent the function. But there is an alternative to this which is to define F here which I write F of beta or F index beta of XY as minus one over beta log sum or integral over Z of E to the minus beta E of XYZ. Now a little bit of computation will you will see that if you make beta go to infinity this kind of F beta converges to F infinity which is why I called it F infinity. And I went through this exercise a little earlier in the class. In this integral over Z if beta is very large the only term that is going to matter is the term E of XYZ that has the lowest value which is the one that has the lowest value over all possible values of Z right. Because all the other ones are going to be much bigger because beta is very very large. And so there value in the exponential is not going to count really the only one that's going to count is the one that has the lowest value. And so if you have only one term in there which is E of XYZ for the value of Z that produces the smallest value then the log cancels the exponential and the minus one over beta cancels the minus beta and your left which is min over Z of E of XYZ okay. So that's the limit that you see above. So if I define F of XY in this way and again then I'm back to the previous problem of just minimizing F of XY with respect to Y for doing inference. Okay so having a latent variable model doesn't make much of a difference you have an extra minimization with respect to the latent variable to do but other than that it's fine. So there is a big advantage also to allowing latent variables which is that by varying the latent variable over a set I can make the output the prediction of the system vary over a set as well. So here is a particular architecture here where X goes into what I call a predictor which is some sort of neural net it produces some representation feature representation of X and then X and Z the latent variable go into what I call here decoder which produces a prediction Y bar. Okay so prediction for the variable Y that is the one that we want to predict and our energy function here just compares Y bar and Y it's simply the distance between them. Okay you're familiar with this kind of diagram we talked about about them earlier. So if I choose to vary Z over a set let's say a two-dimensional square here symbolized by this gray diagram then the the prediction Y bar is going to vary also over a set in this case here some sort of ribbon two-dimensional ribbon and what that allows me to do is basically have a machine now that can produce multiple outputs. Okay by varying the latent variable I can have this machine produce multiple outputs not just one and that's crucial importance. Alright so let's say you're trying to do video prediction so there's many ways many reasons why you might want to do video prediction. One good reason is to build a very good video compression compression system for example. Another good reason is the video you're trying to predict is the video you are looking at from your windshield when you're driving a car and you'd like to be able to predict what cars around you are going to do this is what Fred was working on. And so it's very useful to be able to predict what's going to happen before it happens. In fact that's kind of the essence of intelligence really the ability to predict. Now you're looking at me right now just a minute you're looking at me right now I'm talking you have some idea of the word that is going to come out of my mouth in a few seconds you have some idea of what gesture I'm going to do you have some idea of what direction I'm going to move in but not a precise idea right. So if you train your own neural net to make a single prediction for what I'm going to look like two seconds from now there's no way you can make an accurate prediction. If you train yourself with least square okay if you train a commercial net or something to predict the view of me here with least square the best the system can do is produce a blurry image of me because it doesn't know if I'm going to move left or right doesn't know if my hands are going to be like this or like that and so it's going to produce the average of all the possible outcomes and that's going to be a blurry image okay. So it's very important that your predictor whatever it is be able to deal with uncertainty and be able to make multiple predictions and the way to parameterize the set of predictions is through a latent variable. I'm not yet talking about distributions or probabilistic modeling this is this is way before okay way before we're talking about this question there. Say again. Well so that is not a is not a parameter it's not a weight it's a value that changes for every sample right. So basically during training we haven't talked about training yet but during training I give you an X and a Y you find a Z that minimizes the current the energy function with the current values of the parameters of of those neural nets okay that's the best yes your best guess for what the value of Z is and then you feed that to some loss function that you're going to minimize with respect to the parameters of the network the loss function is not necessarily the average not necessarily the energy it might be something else okay. In fact most of the time is something else. So in that sense you you learn Z you infer Z okay you don't want to use the term learn because learning means you have one value of the variable you you you learn for a whole training set here for Z you have different value for every sample in your training set or every sample you test set for that matter okay. So they're not learned in that sense they're inferred. Yeah another example of this is is translation so translation is a is a is a big problem language translation because there is no single correct translation of a piece of text from one language to another usually there is a lot of different ways to express the same idea and and why would you pick one over the other and so it might be nice if there was some way of parameterizing all the possible translations that a system could produce that would correspond to a given text let's say in German that you want to translate into English there could be multiple translation in English are all correct and by varying some written variable you might you know vary the translation that is produced. Okay so now let's connect this with probabilistic probabilistic modeling there is a way of turning energies which you can think of as kind of negative scores if you want because low energy is good and high energy is bad to turn energies into probabilities and the way to turn energy into probabilities we talked about this already a little bit is to use what's called the Gibbs Boltzmann distribution so the the form of this you know goes back to classical statistical physics in the 19th century and the P of y given x is exponential minus beta where beta is some constant the energy of x and y and then you want to so that turns all those energies into positive numbers when we take the exponential of a number makes it positive and the minus sign is there to turn low energy into high probabilities and vice versa okay and I'm using this convention because this is what physicists have been using for the last century more century and a half. So taking exponentials you you turn the energies into positive numbers and then you normalize so you normalize in such a way that the the P of y x is a properly normalized distribution over y and to make it a properly distribution normalized distribution over y you divide by the integral or the sum if y is discrete over y of e to the minus beta f of x y which is the same thing as the top except you you integrate over all possible values of y. Now if you compute the integral of this over y is equal to one because obviously you get the integral on top integral at the bottom which is a constant and you get one okay so that confirms that this is kind of this has this satisfies the axioms or probability distributions that has to be positive numbers that integrate to one. There's a particular like there's many ways to turn a bunch of like a function into a function that integrates to one a positive function integrates to one what's this one has interesting properties which I'm not going to go through but corresponds to the so-called maximum entropy distribution. The beta parameter is kind of arbitrary it's the way you calibrate your probabilities as a function of your energy so the larger the beta the more so binary your your probability will be for a given energy function. Beta is very very large is basically just the the the e of x y that for the y that produces the lowest energy that will have high probability and everything else will have very low probability and for small beta for a for small beta then you get kind of a smoother distribution okay. Beta in physics term is akin to an inverse temperature okay so the beta goes to infinity is equal to zero temperature. Okay a little bit of math it's not that scary. To show you where the formula for f beta comes from that I talked about earlier. So let's go through this a little slowly here. The joint probability of p of y and z given x okay I apply the same Boltzmann Gibbs-Boltzmann distribution formula as I used before except now it's a joint distribution over y and z instead of just a distribution over y this is for a latent variable model okay. So it's e to the minus the energy of x y z and then I have to normalize I have to integrate in a denominator with respect to y and z so that I get a normalized distribution over the joint domain of y and z okay. So that's the formula at the top left. I can marginalize z so if I integrate p of y and z given x I integrate this over z I get just p of y okay that's the marginalization formula which is at the top right. And so now if I write p of y x is simply the integral over z of the one at the top left okay which is written in the second line. So at the top we have integral over z of e to the minus beta energy of x y z and at the bottom integral over y integral over z of e to the minus beta e to the x y z all right. Okay now I'm going to do something very sneaky and stupid which is that I'm going to take the log of this formula multiply by minus one over beta then multiply by minus beta and then take the exponential all of those things cancel out okay. The log cancels the exponential the minus one over beta cancels the minus beta right so I haven't done anything by doing this e to the minus beta times minus one over beta log I've done nothing because everything cancels okay. And I do the same at the bottom and what I see now is that the stuff in the bracket is the formula I wrote previously f beta of x y equals minus one over beta log sum over z integral over z of e to the minus beta e of x y z and so I can rewrite this horrible complicated formula here as e to the minus beta f beta of x y divided by integral over y of e to the minus beta f of x y. What does this all mean? It means that if you have a latent variable model and you want to eliminate the z variable the latent variable in a probabilistic correct way you just redefine the energy f as this as a function of e of x y z and you're done okay. You're done is a little bit of a shortcut because actually computing this can be very hard okay can be intractable in fact in most cases probably it's intractable. I am missing a minus in the denominator you are correct. Okay so the last few slides were to say if you have a latent variable that you minimize over inside of your model or if you have a latent variable that you want to marginalize over which is which you do by defining this new this energy function f this way and minimizing corresponds to the infinite beta limit of this formula it can be done. Okay I mean just look at the substitution in the second line okay the the last two terms in the second line the bracket I replaced by f beta of x y because and I just defined f beta of x y this way okay I just define it this way and if I define f of x y this way then p of y given x is just an application of the Gibbs-Wolff-Sman formula right and z has been kind of marginalized implicitly inside of of this okay. So physicists call this a free energy by the way which is why I call it f okay so E is the energy and f is a free energy. So the difference is in probabilistic models you basically don't have the choice of the objective function you're going to minimize and you have to stay true to the the sort of probabilistic framework in a sense that every object you manipulate has to be a normalized distribution which you may approximate using variational methods or whatever. Here I'm saying ultimately what you want to make you know what you want to do with those models is make decisions and if you're if you're if you build a system that drives a car and the system tells you you know I need to turn left with probability 0.8 or turn right with probability 0.2 you're going to turn left okay the the fact that the probabilities there are 0.2 and 0.8 doesn't matter what you want is make the decision that is the best right because you have to make a decision you're forced to make a decision. So if you want a system that so so probabilities are completely useless if you want to make decisions okay. If you want to combine the output of a automated system with another one for example a human or some other system and those systems haven't been trained together but they've been trained separately then what you want is calibrated scores so that you can combine the scores of the two systems to make a good decision and there is only one way to calibrate scores and is to kind of turn them into probabilities or other ways are either inferior or equivalent okay but if you're going to train a system end-to-end to make decisions then then then no then whatever scoring function you use is fine as long as it gives the best score to the decision that to the best decision. That gives you way more choices in how you handle the model way more choices of how you train it what objective function you use basically if you if you insist that your model be probabilistic you have to do maximum likelihood so basically you have to train your model in such a way that the probability it gives to the data you observe is maximum okay. The problem is that this is this can only be proven to work in the case where your model is correct and your model is never correct in a sense that you know there's this famous quip by the famous statistician box that said all models are wrong but some are useful. So probabilistic models particularly probabilistic model in high dimensional spaces and probabilistic models in communi-communitorial situations like text and things like this are all approximate models they're all wrong in a way and if you try to normalize them you make them more wrong so you're better off kind of not normalizing them. There's another point that's actually more important and I come back to this little diagram and had this one. So this is meant to be an energy function that captures the dependency between X and Y okay and it's it's like a mountain range if you want okay. The valleys are where the black dots are these are the data points and then there's kind of mountains all around. Now if you train a probabilistic model with this imagine that the points are actually on a thin manifold of infinitely and infinitely thin manifold okay. So the data distribution for the white dot for the black dots is actually a just a line okay is one line two lines three lines but they're lines they don't have any any width if you want. So if you train a probabilistic model on this your probabilistic model should give you your density model should tell you when you are on this manifold the the outputs should be infinite the density is infinite and just epsilon outside of it should be zero okay. That would be the correct model distribution of this distribution if it's a thin plate. Not only the output should be infinite but the integral of it should be one okay. It's very difficult to implement on a computer not only that it's basically impossible because let's say you want to compute this function through some sort of neural net your neural net will have to have infinite weights and infinite weights are calibrated in such a way that the integral of the outputs of that of that system over the entire domain is one. That's basically impossible you cannot have accurate probabilistic model the accurate correct probabilistic model for this particular data that I just told you is impossible. This is what maximum likelihood likelihood would want you to produce and there's no computer in the world that can compute this okay. So in fact it's not even interesting because imagine that you had a perfect density model for the density I just I just mentioned which is a thin plate in that xy space. You couldn't do inference if I give you a value of x and I ask you what's the best value of y you wouldn't be able to find it because all values of y except a set of zero probability have probability zero and it's just you know a few values like for example for this value of x there are three values that are possible okay and they are infinitely narrow and so you wouldn't be able to find them there's no inference algorithm that will allow you to find them because there are sort of there's just direct functions right how do you find them. So the only way you can find them is if you make it if you make your contrast function smooth and differentiable and then you know you can start from any point and by gradient descent you can find a good value for y for any value of x. But this is not going to be a good probabilistic model of the distribution if the distribution is of the type I mentioned okay. So here is a case where insisting to have a good probabilistic model actually is bad okay maximum likelihood sucks. So if you are true Bayesian you say oh but like you know you can correct this by having a strong prior where the prior says your density function has to be smooth and you know you can think of this as a prior so but everything you do in sort of Bayesian terms take the logarithm thereof forget about normalization and you get energy-based models. So energy-based models that have a regularizer which is additive to your energy function are completely equivalent to Bayesian models where the likelihood is exponential of the energy and now you get exponential one term in the energy you know times exponential regularizer and so it's equal to exponential energy plus regularizer and if you remove the exponential you have an energy-based model with an additive regularizer. So there is kind of a correspondence between you know probabilistic and Bayesian methods there but insisting that you do maximum likelihood is sometimes bad for you particularly in high dimensional spaces or combinatorial spaces where your probabilistic model is very wrong it's not very wrong in discrete distributions it's okay but in that case you know it's really wrong and all models are wrong. Okay so there is a form of learning and I'll come back to this to this at length in future lectures called self-supervised learning and it's really sort of encompasses first of all supervised learning but also kind of what people used to call unsupervised learning and a lot of things and I think it's the really the future of machine learning is in self-supervised learning and you start seeing this these days you know over the last year and a half there's been enormous progress in NLP because of systems like BERT and those systems are trained using self-supervised learning a particular form of self-supervised learning called DinoZing autoencoder which we'll talk about. There's been also quite a bit of progress over the last three months or so in using self-supervised learning to train systems to learn vision systems to learn features using you know a self-supervised pretext task and the purpose of self-supervised learning is to train a system to learn good representations of the input so that you can subsequently use those representations as input to a supervised task or reinforcement learning task or whatever. The thing is there is a lot more information that the system can use in the context of self-supervised learning so let me tell you what I mean by self-supervised learning. So self-supervised learning is that someone gives you a chunk of data and you're going to train a system to predict a piece of that data given another piece of that data. Okay so for example I give you a piece of video and ask you use the first half of the video and train a model to predict the second half of that video. Why would that be good? Why would that be good in the context of learning features for vision systems for example? If I train myself to predict what the world is going to look like, what my view of this room will look like if I shift my head a little bit to the left, the best explanation for how the view changes is that every point in space has a depth, has a distance from my eyes. Okay? If I infer somehow that every point has a distance from my eyes then I can very simply explain how the world changes when I move because things are closer, kind of have more parallax motion than things that are far and you get this sort of you know perspective distortion. And so there is this idea somehow that if I train a system to predict what it's going to look like if I move a camera, the system implicitly will run about depth. You will not have to be training it to predict depth in a supervised fashion. It will have to internally kind of discover that there is such a thing as depth if it wants to do a good job at that prediction. Which means you don't have to hardwire into the system that the world is three dimensional. It's going to learn this in minutes by just predicting how his view of the world changes when you move the camera. Now once the system has figured out that every point has a depth in the world, then the notion that there are distinct objects that are in front of the background immediately pops up because objects are things that move differently from things that are behind. Okay? There's another thing that pops up immediately which is the fact that objects that are not visible hidden by another one are still there. Okay? It's just that you don't see them because they are behind. But this concept that objects still exist when you don't see them is not completely obvious. You know babies learn this really really early but it's not clear exactly when because we can't measure that when they are very little. But they probably learn this very quick. Once you have identified this concept of objects perhaps you'll figure out that a lot of objects in the world don't move spontaneously. Okay? So there are inanimate objects. And then there are objects whose trajectories are not entirely predictable and those are animate objects. Or other types of objects that move in not entirely predictable ways like the waves on water but are not animate necessarily or like the leaves of a tree. And then after a while you also realize that objects that have predictable trajectories generally don't float in the air. If they are not supported they fall. Okay? So you can start learning about some intuitive physics, about gravity, about inertia. Babies learn this around the age of nine months. So this is not something you're born with. You kind of learn this around nine months. You as a baby you learn that gravity is a thing. Before that you don't know. So the motivation for self-supervised learning and this is one reason I think self-supervised learning is really the future of machine learning certainly and the future of AI. It's the fact that animals and humans seem to learn an enormous amount of background knowledge about the world just by observation by basically training themselves to predict. So one big question in AI, in fact the question I almost exclusively work on is how do we do this? Okay. We haven't found a complete answer yet. Right. So I give you a piece of data, let's say a video, and the machine is going to pretend there is a piece of that data that it doesn't see and then another piece that it sees and it's going to try to predict the piece that it doesn't see from the piece that it sees. Okay? So predict future frames in a video, predict missing words in a sentence, so I give you a sentence, I block some of the words and the system trains itself to predict the words that are missing. Or I show you a bunch of video and I block a piece of the frames or some of the frames, piece of the image for some of the frames. You know, predict the left half from the right half. You know, right now you only see my right side but even if you had never seen my left side you could more or less predict what I look like from the other side. Most people are more or less asymmetric. Except scary Hollywood characters. So one instance where star supervised learning has been unbelievably successful and it only happens over the last year and a half is text. So text uses a particular type of star supervised learning called denoising autoencoder. So you take a piece of text, you remove some of the words, typically 10, 15, 20 percent of the words. So you replace the token that indicates a word by basically blank. And then you train some giant neural net to predict the words that are missing. It's, the system cannot make an exact prediction about which words are missing and so you train it as a classifier by producing a big softmax factor for each word which corresponds to a probability distribution over words. Okay? And once you've trained this system you chop off the last layer and you use the second last layer as a representation of any text you feed it. There's a particular architecture of this network that makes it work well but it's irrelevant to the point that we're making right now. Those transformer networks that we talked about last week, a little bit. So, but it's a very simple task, a completion task, filling in the blanks, take a sentence, remove some of the words, train the system to predict the words that are missing. That works amazingly well. All the top NLP systems now that have the best performance on all the benchmarks basically are pre-trained using a method like this and the cool thing about it is that, you know, you have as much text as you want on the web to pre-train those systems. You don't need to label anything, it's very cheap. It's very expensive in terms of computation because those networks are enormous for them to work well. But it works really well. So immediately people try to kind of translate that success into a similar success for images. So let's say take an image, block out some pieces of it and then train some convolutional net or something to predict the missing pieces in the image. And the results have been extremely disappointing. It doesn't work really. I mean, it works well in the sense that the images get completed with sort of, you know, things that make sense. But then if you use the internal representation, learn this way, as input to a computer vision system, you can't beat a computer vision system that has been pre-trained supervised on ImageNet. So what's the difference? You know, why does it work for NLP and it doesn't work for images? And the difference is that NLP is discrete whereas images are continuous. People also try to do this for video. So same idea as BERT except replaced words by video frames. So feed a big video to a transformer-like system or something similar, remove some of the frames or blocks of frames and then train the system to predict the missing frames. And the features you get are not so great. So that's the difference is things seem to work in the discrete world. They don't seem to work in the continuous world. And the reason is because in discrete world we know how to represent uncertainty by big softmax vector over words. In continuous spaces we don't. So if I want to train a system to do video prediction, I don't know how to represent a probability distribution over multiple video frames. So here is another reason why we might want to use our supervised learning and deal with uncertainty. And again, this is what Alfredo is working on among others. It's the fact that we'd like to have, we'd like our machines to be able to kind of reason about the world, predict what's going to happen. So I told you before an example where to be able to build a machine that drives a car. It's probably a good idea to be able to predict what cars around you are going to do. Be able to predict what your car is going to do if you run, you know, if you're driving near a cliff and you turn the wheel to the right and you want to predict in advance that your car is going to run off the cliff and you don't. You can, if you can predict that, you're not going to do it. Okay? So if you have a good predictive model of the world, a system that will predict the next state of the world as a function of the current state of the world and the action you take, then you can do, you can act intelligently. Okay? Well, you need other components to act intelligently. But I'll come back to that. But again, this ability to predict is the essence of intelligence really. The fact that, you know, some animals are intelligent is because they really have a much better model of the world and they, as a consequence, are better at sort of acting on this world to kind of get the result they want. So the problem with the world is that the world is not deterministic. Or, I mean, maybe it is deterministic, but we can't predict exactly what's going to happen. So the fact that it is deterministic or not is irrelevant. Our brain have a limited capacity, our computers have a limited capacity, and we can't exactly predict what's going to happen. And so we need to be able to train our system, to train our brains, to train our AI systems, to predict in the presence of uncertainty. And that's the most difficult problem that we need to solve today to make significant progress in AI. How to train the system to make high-dimensional predictions under uncertainty and deal with this uncertainty. And as I said before, probabilistic models are basically hopeless. Okay, so let's take an example with video prediction. Here are four frames. What's the continuation of those frames? So it's a little hard to see that the little girl is about to, like, blow on her birthday cake. And if you train a neural net with least square to make predictions, so you train it on thousands of videos of this type, if not millions, this is the kind of prediction you get. Very blurry. Why? The system cannot predict exactly what's going to happen, so it predicts the average of all the possible futures, which is the best way to minimize the squared error. Okay? And if you want sort of a model version of this, let's say your entire training set consists of someone putting a pen on the table and letting it go, and the person always put the pen exactly at the same place the same way. But every time you do the experiment, the pen falls into a different direction. So basically X is the same for every training sample, but Y is different because the pen can fall in any direction, probably with a uniform distribution. So if you train a neural net to predict with least square, you'll get the average of all the possible predictions, which is a transparent pen all around the circle, which is not a good prediction. That's why you need latent variable models. Okay? So if you make a prediction by the system, but you have latent variables, which indicate what you don't know about the world. Okay? So X is what you know about the world. Here is the initial segment of the video of someone putting a pen. You know that when the person lifts the finger, the pen will fall, but you don't know in which direction. So what you want the system to tell you is the predictor here that goes from X to H. H should be a representation that tells you the pen is going to be on the table, but I can't tell you in which direction. And then Z will have the complementary variable. Here is the direction in which the pen actually fell. And then the combination of those two pieces of information, the stuff you can extract from the observation and the stuff you cannot, gives you the prediction Y bar, which hopefully is close to what actually occurs. Okay? So the way you use something like this, you don't use it for... I mean, if you want to use it to kind of rate a particular scenario, you give it X, you give it Y, and then you ask it what's the value of the Z variable that minimizes the prediction error in my model. And then the resulting prediction error is the energy and it's how you model rate the compatibility between X and Y. If you want to predict Ys, what you have to do is you observe X and then you kind of dream up a value of Y within a certain domain and that produces a Y bar. And then dream up another value of Z and that will produce another Y bar. And you can produce a whole set of Y bars by kind of drawing multiple values of Z within a set or within the distribution. Yes? Does the length of the video help? Because if you have like 10 frames, then these fewer possibilities of how the 11th frame will happen, then if you do first few... Well so if what you're predicting are the future frames and what you're observing are the past and current frame, like increasing... You mean increasing the past frames that you're looking at? A little bit, but you know after a while things are going to happen that really don't depend... I mean the information about what's going to happen in the future really is not present in the past frames. Yes? So in this particular case there would be variables that are necessary to make a good prediction, but the information is not present in X. Okay, so the question was, where's the role of Z really? Like you know does it implement the constraint between X and Y or something else? And in this particular example here that I showed, the latent variable... I showed several examples, right? One example I showed is character recognition. If you knew where the characters are then the task of recognizing the characters would be easier. And so by making the inference about where the characters are, you sort of help your system. You build a system in such a way that it can use that. In this particular case here it's different. Here the role of the latent variable is to basically parameterize the set of possible outputs that can occur. And in the end what you want is Z to contain the information about Y that is not present in X. Okay? So the information about where I'm going to move next, am I going to move left or right, this is not present in anything you can observe right now. It's inside my brain, you can tell. There are multiple ways of building this latent variable, no? Yes. I mean right now here I'm not assuming anything other than you know, pretox is a big neural net and decovet of H and Z is a big neural net. I'll show you some more animation about this latent variable in multiple traditions. Okay. So this is sort of an example, a visualization of an energy landscape where we've got a we've trained a neural net basically to compute an energy function. Here it's not a neural net, it's a very simple thing actually. To capture the dependency between two variables X and Y and the data points are along this little spiral here. So data points are kind of sampled uniformly along this spiral. And then we train a system to give low energy to those points and high energy to everything else. Now there's two forms. There is, this is sort of a conditional, you could call conditional energy based model where there is two sets of variables X and Y and you're trying to predict Y from X. But there's also another form of energy based model which are unconditional. There's only a Y, no X. Okay. So you're trying to predict the mutual dependencies between the various components of Y, the distribution of a Y if you want. But there's no X. Okay. So this is something you would want to use if you want to say do image generation unconditionally, right? Or you want to just, you know, model the mutual dependencies between things but you don't know which, you don't know at any point if you're going to be able to observe Y1 or Y2 or none of them. The math is the same really. Okay. So how are we going to train those energy based model? This is really where things become interesting. It's the question of training. So training should do something like the little animation at the top here. It should kind of shape the energy function because our machine now is computes an energy function as a function of X and Y. It should shape the energy function in such a way that the data points have lower energy than everything else. Okay. Because that's the way the inference is going to work. If the correct value of Y has lower energy than the incorrect values of Y then our inference algorithm that finds the value of Y that produces the lowest energy is going to work. Okay. So we need to shape the energy function so that it gives low energy to the good Y's for a given X and high energy to bad Y's for a given X. So the EPM is a function that goes from R2 to R which gives... It goes from R, I mean it goes from any domain you want to scalar. Yes. Okay. And the idea is then that the latent variable sort of shapes the level... Like I'm looking for a level curve that minimizes because the solution is no longer unique, right? Is C then sort of shaping the space around this level curve to make it more identifiable? Not necessarily. So this model actually is a latent variable model. In fact, most of you are probably very familiar with the energy... With the model is used here is k-means. So how is this produced? Okay. Let me delay this for a bit. Okay. But this is the energy surface of k-means which is a latent variable model. Let's keep the latent variable thing kind of aside for a minute. Just think of this as you have an energy F of XY and the fact that there may be underlying latent variable for now is irrelevant. Okay. There's two classes of methods to train energy-based models. And again, probabilistic methods are all kind of, you know, special cases within those. One class is called contrastive methods. And this idea is very natural. Take a training sample, X of XIYI, and change the parameters of the energy function so that its energy goes down. Okay. Easy enough. Conversely, take other points outside of the manifold of data. So have some process by which you pick for a given X, you pick a bad Y and then push that guy up. Okay. If you keep doing this with the last function that takes into account those different energies, then the energy function is going to take a shape such that the correct Y will have lower energy than the bad Ys. Okay. Keep pushing down on the good values of Y, keep pushing up on the bad values of Y. So those are called contrastive methods. And they all differ by how you pick the Ys that you push up. And they all differ by the last function you use to do this pushing up and pushing down. There's a second category of methods. And I call them architectural methods. In that case, you build the energy function, F of XY, so that the volume of low energy regions is limited or is minimized through regularization. So you build a model in such a way that whatever you push down on the energy of data points, the rest goes up more or less automatically because the volume of stuff that can take low energy is limited or minimized through some regularization. Okay. Those are very broad concepts. Okay. Yes. That's one set of techniques, but there's many. So there is a set of methods like score matching, for example, that says the gradient of the energy around the sample should be zero and the second derivative should be as large as possible. The trace of the Hessian should be large. And so basically you're telling it make every data point a minimum of the energy by making sure the energy curls up around every training sample. It's very, very hard to apply in practice because you have to compute the gradient with respect to the weights of the trace of the Hessian of the energy function with respect to the inputs. I mean, it's complete hell, but yeah. For simple models, PyTorch can do it. Yeah. Simple models. Like for linear models. But it's hell. I'd stay away from it. Okay. So there's a number of different strategies. Here it says seven strategies, but I kind of reorganize this into those two categories of contrastive methods and architectural methods. And there are kind of three subcategories, you know, in contrast even four subcategories in architectural. And there's some names of various algorithms here that you might recognize, some other that you may not recognize, which is okay. And I'm going to try to go through some of them. Now what I need to do is called score matching. Okay. Bear with me for just one second. There we go. Oops. Oops. Okay. So C1 contrastive subcategory 1, push down the energy of the atom. Okay. So C1 contrastive subcategory 1, push down the energy of data point, push up everywhere else. And this is what maximum likelihood does. And maximum likelihood pushes down the energy of data points to minus infinity and pushes up the energy of other points to plus infinity, which is the problem that we were just talking about earlier. And so here is what happens. This gives, both line distribution, that gives the likelihood of y given x, which is for a particular data point, yi, xi. It gives you the probability that your model gives to this particular value of yi for a given xi. And it's, you know, exponential minus beta the energy divided by exponential minus beta the energy integrated over all y's. Okay. So if you want to maximize, so let's say you have a bunch of data points, and you want to maximize, so here I'm not writing x because it doesn't matter, and you want to maximize the probability that your model gives to this particular value of y. You want to make the energy of this y small, which means you want to make the e to the minus beta the energy of this big. And you want to make the stuff at the bottom as small as possible. So instead of maximizing p of y, we're going to minimize minus log p of y. So minus log p of y, so if I take the log of this ratio, I'm going to get the difference of those two terms. The log of the difference, you know, the difference of the logs of those two terms. The log of the ratio is the difference of the logs, right? So I get log of e to the minus beta e of y, and then I guess I get minus log integral over y of e to the minus beta e of y. I take the negative of this because I want to minimize, okay, so negative log probability is what I want to minimize, and I get the last function here at the bottom. I divided everything by beta, which makes no difference as far as the minimum is concerned. Okay, so to go from the top formula to the bottom formula, you take minus log of the top formula and you divide by beta. So now we have a, that gives us a last function, and this last function when we minimize it says make the energy of the data point y as low as possible. E of y should be small. So I make the second term as small as possible, which means make the energies that are inside of this exponential minus as large as possible. So the second term is going to push up on the energy of every point, including the data point. Now if I compute the gradient of this objective function, so this is the probabilistic approach, okay, maximum likelihood. If I compute the gradient of this objective function, I get the gradient of the energy at the data point y, okay, minus this formula here, which is the expected value over y of the probability that my model gives to y that is given by the Gibbs-Wolff-Sprunen distribution, and that is used as a coefficient to weigh the gradient of the energy function at that location, okay. So this integral here, the second term, is basically an expected value of the gradient. I compute the gradient of the energy function at every point. I weigh every point by the probability that the model gives to that particular y, and I compute that weighted sum essentially. If y is discrete, this is a discrete sum. If y is continuous, it's an integral. So the first term, so now if I use this in a gradient, you know, a stochastic gradient algorithm, the first term is going to try to make the energy of my data point as small as possible, and the second term is going to push out the energy of every single point, every y, okay. And the problem is, can I compute this at all? Can I compute this integral? So an enormous chunk of publications in probabilistic modeling have to do with, how do you either compute this, estimate this, or approximate this? Because that integral is, in interesting cases, is intractable. Okay, if y is the space of images, I cannot compute an integral of all possible images. There's no way. Except if the energy function or the gradient of the energy function is very, very simple, okay. Most of the time it's not that simple. So if I use this model to capture the dependency of the world, it's not going to be that simple. It's going to be some big neural net. So this integral is going to be completely intractable. Now, there is a little bit of salvation in the fact that this is an expected value, and so to compute an approximation of an expected value, you can compute an average of a finite number of samples. So if I sample y's from this distribution, which is the distribution that my model gives to y, and I get the average of the gradient over those samples, I get a finite approximation of this. It's called Monte Carlo methods. Okay, it's called Monte Carlo approximation, invented by physicists when they were trying to build an atom bomb in the 40s. There are other methods that are based on variational methods. So I don't really know how to compute p. I can't compute this integral, p by another distribution q, for which I can't compute this average, let's say Gaussian or something. And then I try to make q as close to p as possible. That's called variational methods. Okay, you've probably heard that term many times. That's a basic idea of variational methods. You approximate an expectation over a distribution by replacing the distribution by something you can actually compute, and you try to make this computable distribution as close as possible to the real distribution using some measure, KL divergence. Right, so here is K-means. So K-means is a, you can think of K-means as an energy-based model. You can interpret K-means in terms of energy-based model. Is anyone okay with what K-means is? Have you forgotten what K-means is? Okay, so K-means is this very simple clustering algorithm where the energy function, if you've never heard of it, this is a way to explain K-means. The energy function is written at the top here. E of yz is y minus wz, where w is a matrix, and z is a set of one-hot vectors. Okay, so z is this discrete variable with K possible values, and it's a K-dimensional vector with one component equal to one and all the other ones equal to zero. Okay, so you multiply z by the matrix w, the effect is that what you get as this product is one of the columns of w. Okay, the column of w that gets multiplied by the component of z that's equal to one gets reproduced, and everything else is gone. Okay, so that product selects one column from w. The columns of w are called prototypes. Okay, and if I give you a y, the way you do inference is that you figure out which z, which of the K possible vectors of z, minimizes the reconstruction error, minimizes the square distance between the corresponding column of w and the data point that I'm looking at. And the energy is just a square distance between the two. Okay, now the energy function you see here represented in this chart, oops, right here, what you see here are kind of black blobs, and those correspond to quadratic wells around each of the prototypes of w. So the system here has been trained, and it placed the columns of w along the manifold of training samples, which is this spiral, that's where all the training samples are selected. And the way this is trained is very simple. You just minimize the expected, the average energy over a training set. Okay, so basically I give you a y, y is a training sample. You find the z that minimizes the energy, so you find the prototype that is closest to y, the column of w that's closest to y, and then you do one step of gradient descent, so you move that vector closer to y. Then you take another y, select which columns of w is closest to it, and move that column a little bit closer to y, and then you keep doing this. That's not exactly the K-means algorithm. This is the kind of stochastic gradient form of the K-means algorithm. The real K-means algorithm actually kind of does sort of coordinate descent, if you want, so it first goes through the entire training set and figures out for each data point which column of w is closest to it, and then after you've done this, you compute every data point, every column of w as the average of all the data points to which it's associated. And it goes a bit faster if you do it this way, as opposed to stochastic gradient. But the result is the same. In the end, you minimize the average of the energy over the training set. Okay, so that's an example. There was a question about latent variable earlier. That's an example of a latent variable model, very simple one, where the decoder is linear. There's no dependency on x, and what you're just trying to do is model the distribution over y. Here y is two-dimensional, and you're just trying to say, you know, if I know one value of y, can you tell me, if I know y1, can you tell me anything about the value of y2? And once you have this energy function, you can. I give you y1, you can predict what the value of y2 should be. I give you a random point, you can tell me what's the closest point on the data manifold by just searching for the closest prototype, basically. So k-means, that I just explained here, belongs to the architectural methods. It's not a contrastive method, as you can observe. I did not push up on the energy of anything, I just pushed down on the energy of stuff. The k-means is built in such a way that there is only k points in the space that can have zero energy, and everything else will have higher energy. Okay, it's just designed this way, right? So it's architectural in that sense. Once I've decided on k, I've limited the volume of space in y that can take low energy, because there's only k points that can have zero energy. Everything else grows quadratically as I move away from them. Now let's talk about, there's a bunch of other methods. These are my favorite methods. I think ultimately everybody will be using architectural methods. But right now the stuff that works in images is contrastive. Okay, so contrastive methods. I have data points. And currently my model computes an energy function, let's say that looks like this. So I'm drawing the contours of equal cost. Okay, it's like a topographic map. So obviously that model is bad, right, because it gives low energy to those points here. Those points have low energy and they should not. And then those points have high energy and they should not. So what should I do? So obviously if I take a training sample here, and I change the parameters of f of an x, y so that the energy goes down, it's probably going to move the function to have kind of lower values in that region. But that may not be sufficient because it could be that my energy function is parameterized in such a way that it could be flat, could be zero, everywhere. So I need to explicitly push up on other places. And so a good location to push up would be those red locations here. These are locations that my model gives low energy to, but should not have low energy. So let's say this is my training sample right now. Okay, the big black dot here, that's my training sample. One way I can train a contrastive system is by saying I'm going to push down on the energy of that point, and I'm going to perturb that point a little bit by corrupting it some way, adding noise to it, and I'll push up on the energy of a point that's nearby. Okay, and I'm going to do this multiple times. So if I do this sufficiently many times, eventually the energy function is going to curl up around every sample because I modify a sample and I push up, you know, I corrupt it a little bit, and I push up on the energy of that corrupted sample, the contrastive sample. So eventually the energy is going to take the right place. Something a little smarter, instead of sort of randomly perturbing the training sample by, you know, some perturbation around it, I'm going to use gradient descent to kind of go down in the energy surface, and then I'm going to get this point and push it up. Okay, that makes more sense, right, because I'm going for the jiggler here. You know, the system kind of finds a point that the system gives, that it gives low energy to currently, and it pushes up. Right, so the procedure is here is a training sample, move down in the energy surface, so find a value of y that has lower energy than the one you started from, and then that's a contrastive sample, push it up. Push down on the original sample, push up on this new sample you just got. Now this might be expensive, and your energy function might be complicated, it may have local minima, so here's another technique. The other technique is start from the same training sample, and imagine that this surface is like a, you know, like a smooth mountain range, and then give a random kick to this marble, think of it as a marble, you're going to give it a random kick in a random direction, and you're going to simulate this as a marble rolling down this energy surface. So let's say I'm going to kick it in this direction, it's going to go in this direction for a while, and then it's going to go down in the energy. After a while, cut it off, you get a point at the end of this trajectory, push it up. Okay, so I'm doing this very informally, but in fact there are. So depending on how you do this, here I'm explaining the principles of how those methods work, but in fact, if you are interested in probabilistic modeling, and what you're interested in is doing maximum likelihood, what you need to do is produce samples according to the probability your model gives to the samples, and there's ways to run those algorithms in such a way that the ratio of the probability with which you will pick two samples corresponds to the ratio of their probabilities given by the model, which is all you need. And that's essentially done by, you know, the details of how you implement those kind of trajectories, basically, and like the noise that you use to... So, okay, so let me give you names for this. Okay, the random noising corresponds to an algorithm called denoising autoencoder. And Alfredo is going to tell you more about this. The gradient descent and random kick versions, the random kick, that's called contrastive divergence, and there are a form of this for... And if you do a search through the space by kind of random perturbations, sort of trying to find low energy space with noise, it's a special case of Monte Carlo methods. And if it's a continuous trajectory, not a continuous, but if it's a trajectory, it could be discrete, it's called Markov chain Monte Carlo methods, or MCMC. And if it's in a continuous space where you use kind of this rolling ball with a random kick method, that's called Hamiltonian Monte Carlo. HNC, there's a question. No? Okay. Well, the time is late, let me just talk about denoising autoencoder. So what's a denoising autoencoder? It's a particular type of energy-based model where you start with a Y, so you only have Ys. So you start with Y, you correct it, so this is the little diagram that I showed earlier, you correct the sample, okay? You get another sample that I'm not going to call, and you pass this through an encoder, which is a neural net, and a decoder, which is another neural net, and then you compare the output, which is a reconstruction for Y, with Y. This is just in the classical form, this is the distance between Y and Y bar squared. And you see here, the network on the left is just some neural net that you train. The corruption is built by hand, it's not trained. So what does that do for you? This actually pushes out the energy of corrupted points. So here the energy is, so this is how you train the system, but the actual system doesn't have the corruption. You give it a Y, you run it through the encoder and the decoder, and measure the reconstruction error. Okay, so it's exactly the same diagram, except no corruption. So the corruption is for training. And this is how you use it. Okay, what does that do for you? You have space of Y, you have data points. Take a point Y and corrupt it. And now you train this neural net, this encoder-decoder, to basically reconstruct this corrupted point from the corrupted point to produce the original point, the original training point. So the neural net function is going to map this point to that point. Okay? What does that mean? That means when you plug a vector here Y, and you do this for every training sample and a large number of corruptions. Okay? What it means is that when you plug a point Y here on the input, and you measure its energy, which is a reconstruction error, this point, if it's on the manifold, if it's on the manifold of data, is going to be reconstructed as itself. Therefore, its energy here, which is a reconstruction error, will be zero. Okay? If it's trained properly. Because if you put on the input a point that is outside the manifold, it's going to get reconstructed as the closest point on the manifold, because it's been trained to do that. Therefore, the reconstruction error here will be this distance. Okay? What that means is now that the energy computed by this denousi-autoencoder is such that it grows quadratically as you move away from the manifold of data, if the thing is properly trained. Okay? So that's an example of contrastive methods, because you say on the manifold things should be zero, the reconstruction energy should be zero. Outside the manifold, the reconstruction energy should be the distance to the manifold. Okay? This is BERT. So BERT is trained this way, except the space is discrete, though combinatorial, because it's text. And the corruption technique consists in masking some of the words. And then the reconstruction consists in predicting the words that are missing. You can always copy the words that are not missing, so you don't need to do it. Okay? So it's a special case of denousi-autoencoder. It's actually called a masked autoencoder, because the type of corruption you do is masking pieces of the input. Okay? All right. Out of time, we'll talk about more of those techniques next time.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 5.28, "text": " Right, so we're going to talk about energy-based models, and it's basically a framework by", "tokens": [50364, 1779, 11, 370, 321, 434, 516, 281, 751, 466, 2281, 12, 6032, 5245, 11, 293, 309, 311, 1936, 257, 8388, 538, 50628, 50628, 597, 321, 393, 11, 807, 597, 321, 393, 5109, 257, 688, 295, 819, 2539, 14642, 13, 50901, 50901, 1726, 264, 2306, 300, 366, 733, 295, 2199, 11, 411, 321, 600, 1612, 294, 46533, 2539, 11, 457, 721, 51178, 51178, 300, 366, 257, 707, 544, 16950, 11, 293, 309, 1333, 295, 49866, 611, 257, 688, 295, 31959, 3142, 51434, 51434, 7150, 11, 457, 309, 311, 257, 707, 18587, 281, 1223, 11, 286, 519, 11, 813, 31959, 3142, 7150, 13, 51726, 51726], "temperature": 0.0, "avg_logprob": -0.17730909075055803, "compression_ratio": 1.7065637065637065, "no_speech_prob": 0.017414497211575508}, {"id": 1, "seek": 0, "start": 5.28, "end": 10.74, "text": " which we can, through which we can express a lot of different learning algorithms.", "tokens": [50364, 1779, 11, 370, 321, 434, 516, 281, 751, 466, 2281, 12, 6032, 5245, 11, 293, 309, 311, 1936, 257, 8388, 538, 50628, 50628, 597, 321, 393, 11, 807, 597, 321, 393, 5109, 257, 688, 295, 819, 2539, 14642, 13, 50901, 50901, 1726, 264, 2306, 300, 366, 733, 295, 2199, 11, 411, 321, 600, 1612, 294, 46533, 2539, 11, 457, 721, 51178, 51178, 300, 366, 257, 707, 544, 16950, 11, 293, 309, 1333, 295, 49866, 611, 257, 688, 295, 31959, 3142, 51434, 51434, 7150, 11, 457, 309, 311, 257, 707, 18587, 281, 1223, 11, 286, 519, 11, 813, 31959, 3142, 7150, 13, 51726, 51726], "temperature": 0.0, "avg_logprob": -0.17730909075055803, "compression_ratio": 1.7065637065637065, "no_speech_prob": 0.017414497211575508}, {"id": 2, "seek": 0, "start": 10.74, "end": 16.28, "text": " Not the ones that are kind of simple, like we've seen in supervised learning, but things", "tokens": [50364, 1779, 11, 370, 321, 434, 516, 281, 751, 466, 2281, 12, 6032, 5245, 11, 293, 309, 311, 1936, 257, 8388, 538, 50628, 50628, 597, 321, 393, 11, 807, 597, 321, 393, 5109, 257, 688, 295, 819, 2539, 14642, 13, 50901, 50901, 1726, 264, 2306, 300, 366, 733, 295, 2199, 11, 411, 321, 600, 1612, 294, 46533, 2539, 11, 457, 721, 51178, 51178, 300, 366, 257, 707, 544, 16950, 11, 293, 309, 1333, 295, 49866, 611, 257, 688, 295, 31959, 3142, 51434, 51434, 7150, 11, 457, 309, 311, 257, 707, 18587, 281, 1223, 11, 286, 519, 11, 813, 31959, 3142, 7150, 13, 51726, 51726], "temperature": 0.0, "avg_logprob": -0.17730909075055803, "compression_ratio": 1.7065637065637065, "no_speech_prob": 0.017414497211575508}, {"id": 3, "seek": 0, "start": 16.28, "end": 21.400000000000002, "text": " that are a little more sophisticated, and it sort of encompasses also a lot of probabilistic", "tokens": [50364, 1779, 11, 370, 321, 434, 516, 281, 751, 466, 2281, 12, 6032, 5245, 11, 293, 309, 311, 1936, 257, 8388, 538, 50628, 50628, 597, 321, 393, 11, 807, 597, 321, 393, 5109, 257, 688, 295, 819, 2539, 14642, 13, 50901, 50901, 1726, 264, 2306, 300, 366, 733, 295, 2199, 11, 411, 321, 600, 1612, 294, 46533, 2539, 11, 457, 721, 51178, 51178, 300, 366, 257, 707, 544, 16950, 11, 293, 309, 1333, 295, 49866, 611, 257, 688, 295, 31959, 3142, 51434, 51434, 7150, 11, 457, 309, 311, 257, 707, 18587, 281, 1223, 11, 286, 519, 11, 813, 31959, 3142, 7150, 13, 51726, 51726], "temperature": 0.0, "avg_logprob": -0.17730909075055803, "compression_ratio": 1.7065637065637065, "no_speech_prob": 0.017414497211575508}, {"id": 4, "seek": 0, "start": 21.400000000000002, "end": 27.240000000000002, "text": " methods, but it's a little simpler to understand, I think, than probabilistic methods.", "tokens": [50364, 1779, 11, 370, 321, 434, 516, 281, 751, 466, 2281, 12, 6032, 5245, 11, 293, 309, 311, 1936, 257, 8388, 538, 50628, 50628, 597, 321, 393, 11, 807, 597, 321, 393, 5109, 257, 688, 295, 819, 2539, 14642, 13, 50901, 50901, 1726, 264, 2306, 300, 366, 733, 295, 2199, 11, 411, 321, 600, 1612, 294, 46533, 2539, 11, 457, 721, 51178, 51178, 300, 366, 257, 707, 544, 16950, 11, 293, 309, 1333, 295, 49866, 611, 257, 688, 295, 31959, 3142, 51434, 51434, 7150, 11, 457, 309, 311, 257, 707, 18587, 281, 1223, 11, 286, 519, 11, 813, 31959, 3142, 7150, 13, 51726, 51726], "temperature": 0.0, "avg_logprob": -0.17730909075055803, "compression_ratio": 1.7065637065637065, "no_speech_prob": 0.017414497211575508}, {"id": 5, "seek": 2724, "start": 27.24, "end": 33.0, "text": " And probabilistic methods really are kind of a special case, if you want, of energy-based", "tokens": [50364, 400, 31959, 3142, 7150, 534, 366, 733, 295, 257, 2121, 1389, 11, 498, 291, 528, 11, 295, 2281, 12, 6032, 50652, 50652, 5245, 13, 50768, 50768, 400, 286, 519, 309, 311, 733, 295, 257, 8388, 300, 311, 257, 707, 1333, 295, 18690, 4559, 294, 264, 2020, 50952, 50952, 300, 309, 13948, 257, 688, 295, 721, 300, 1643, 588, 819, 562, 291, 500, 380, 483, 341, 1333, 51232, 51232, 295, 517, 5489, 1910, 295, 721, 13, 51452, 51452, 407, 437, 286, 478, 516, 281, 751, 466, 700, 13165, 12309, 731, 281, 46533, 2539, 11, 437, 51752, 51752], "temperature": 0.0, "avg_logprob": -0.09738722626043826, "compression_ratio": 1.6192468619246863, "no_speech_prob": 2.9742477636318654e-05}, {"id": 6, "seek": 2724, "start": 33.0, "end": 35.32, "text": " models.", "tokens": [50364, 400, 31959, 3142, 7150, 534, 366, 733, 295, 257, 2121, 1389, 11, 498, 291, 528, 11, 295, 2281, 12, 6032, 50652, 50652, 5245, 13, 50768, 50768, 400, 286, 519, 309, 311, 733, 295, 257, 8388, 300, 311, 257, 707, 1333, 295, 18690, 4559, 294, 264, 2020, 50952, 50952, 300, 309, 13948, 257, 688, 295, 721, 300, 1643, 588, 819, 562, 291, 500, 380, 483, 341, 1333, 51232, 51232, 295, 517, 5489, 1910, 295, 721, 13, 51452, 51452, 407, 437, 286, 478, 516, 281, 751, 466, 700, 13165, 12309, 731, 281, 46533, 2539, 11, 437, 51752, 51752], "temperature": 0.0, "avg_logprob": -0.09738722626043826, "compression_ratio": 1.6192468619246863, "no_speech_prob": 2.9742477636318654e-05}, {"id": 7, "seek": 2724, "start": 35.32, "end": 39.0, "text": " And I think it's kind of a framework that's a little sort of enlightening in the sense", "tokens": [50364, 400, 31959, 3142, 7150, 534, 366, 733, 295, 257, 2121, 1389, 11, 498, 291, 528, 11, 295, 2281, 12, 6032, 50652, 50652, 5245, 13, 50768, 50768, 400, 286, 519, 309, 311, 733, 295, 257, 8388, 300, 311, 257, 707, 1333, 295, 18690, 4559, 294, 264, 2020, 50952, 50952, 300, 309, 13948, 257, 688, 295, 721, 300, 1643, 588, 819, 562, 291, 500, 380, 483, 341, 1333, 51232, 51232, 295, 517, 5489, 1910, 295, 721, 13, 51452, 51452, 407, 437, 286, 478, 516, 281, 751, 466, 700, 13165, 12309, 731, 281, 46533, 2539, 11, 437, 51752, 51752], "temperature": 0.0, "avg_logprob": -0.09738722626043826, "compression_ratio": 1.6192468619246863, "no_speech_prob": 2.9742477636318654e-05}, {"id": 8, "seek": 2724, "start": 39.0, "end": 44.599999999999994, "text": " that it explains a lot of things that seem very different when you don't get this sort", "tokens": [50364, 400, 31959, 3142, 7150, 534, 366, 733, 295, 257, 2121, 1389, 11, 498, 291, 528, 11, 295, 2281, 12, 6032, 50652, 50652, 5245, 13, 50768, 50768, 400, 286, 519, 309, 311, 733, 295, 257, 8388, 300, 311, 257, 707, 1333, 295, 18690, 4559, 294, 264, 2020, 50952, 50952, 300, 309, 13948, 257, 688, 295, 721, 300, 1643, 588, 819, 562, 291, 500, 380, 483, 341, 1333, 51232, 51232, 295, 517, 5489, 1910, 295, 721, 13, 51452, 51452, 407, 437, 286, 478, 516, 281, 751, 466, 700, 13165, 12309, 731, 281, 46533, 2539, 11, 437, 51752, 51752], "temperature": 0.0, "avg_logprob": -0.09738722626043826, "compression_ratio": 1.6192468619246863, "no_speech_prob": 2.9742477636318654e-05}, {"id": 9, "seek": 2724, "start": 44.599999999999994, "end": 49.0, "text": " of unifying view of things.", "tokens": [50364, 400, 31959, 3142, 7150, 534, 366, 733, 295, 257, 2121, 1389, 11, 498, 291, 528, 11, 295, 2281, 12, 6032, 50652, 50652, 5245, 13, 50768, 50768, 400, 286, 519, 309, 311, 733, 295, 257, 8388, 300, 311, 257, 707, 1333, 295, 18690, 4559, 294, 264, 2020, 50952, 50952, 300, 309, 13948, 257, 688, 295, 721, 300, 1643, 588, 819, 562, 291, 500, 380, 483, 341, 1333, 51232, 51232, 295, 517, 5489, 1910, 295, 721, 13, 51452, 51452, 407, 437, 286, 478, 516, 281, 751, 466, 700, 13165, 12309, 731, 281, 46533, 2539, 11, 437, 51752, 51752], "temperature": 0.0, "avg_logprob": -0.09738722626043826, "compression_ratio": 1.6192468619246863, "no_speech_prob": 2.9742477636318654e-05}, {"id": 10, "seek": 2724, "start": 49.0, "end": 55.0, "text": " So what I'm going to talk about first applies equally well to supervised learning, what", "tokens": [50364, 400, 31959, 3142, 7150, 534, 366, 733, 295, 257, 2121, 1389, 11, 498, 291, 528, 11, 295, 2281, 12, 6032, 50652, 50652, 5245, 13, 50768, 50768, 400, 286, 519, 309, 311, 733, 295, 257, 8388, 300, 311, 257, 707, 1333, 295, 18690, 4559, 294, 264, 2020, 50952, 50952, 300, 309, 13948, 257, 688, 295, 721, 300, 1643, 588, 819, 562, 291, 500, 380, 483, 341, 1333, 51232, 51232, 295, 517, 5489, 1910, 295, 721, 13, 51452, 51452, 407, 437, 286, 478, 516, 281, 751, 466, 700, 13165, 12309, 731, 281, 46533, 2539, 11, 437, 51752, 51752], "temperature": 0.0, "avg_logprob": -0.09738722626043826, "compression_ratio": 1.6192468619246863, "no_speech_prob": 2.9742477636318654e-05}, {"id": 11, "seek": 5500, "start": 55.0, "end": 59.32, "text": " some people call unsupervised learning, or what I would call self-supervised learning,", "tokens": [50364, 512, 561, 818, 2693, 12879, 24420, 2539, 11, 420, 437, 286, 576, 818, 2698, 12, 48172, 24420, 2539, 11, 50580, 50580, 597, 286, 603, 751, 466, 257, 707, 857, 965, 13, 50740, 50740, 400, 309, 311, 1936, 11, 321, 434, 516, 281, 751, 466, 5245, 300, 11441, 257, 992, 295, 9102, 1783, 11, 51220, 51220, 293, 321, 434, 3365, 264, 2316, 281, 6069, 257, 992, 295, 9102, 398, 13, 51450, 51450, 400, 286, 478, 406, 1608, 5489, 300, 1783, 307, 364, 3256, 420, 2035, 11, 293, 398, 307, 257, 27706, 7006, 11, 51736, 51736, 411, 337, 21538, 13, 51847, 51847], "temperature": 0.0, "avg_logprob": -0.15183004678464404, "compression_ratio": 1.7309417040358743, "no_speech_prob": 2.075236443488393e-05}, {"id": 12, "seek": 5500, "start": 59.32, "end": 62.52, "text": " which I'll talk about a little bit today.", "tokens": [50364, 512, 561, 818, 2693, 12879, 24420, 2539, 11, 420, 437, 286, 576, 818, 2698, 12, 48172, 24420, 2539, 11, 50580, 50580, 597, 286, 603, 751, 466, 257, 707, 857, 965, 13, 50740, 50740, 400, 309, 311, 1936, 11, 321, 434, 516, 281, 751, 466, 5245, 300, 11441, 257, 992, 295, 9102, 1783, 11, 51220, 51220, 293, 321, 434, 3365, 264, 2316, 281, 6069, 257, 992, 295, 9102, 398, 13, 51450, 51450, 400, 286, 478, 406, 1608, 5489, 300, 1783, 307, 364, 3256, 420, 2035, 11, 293, 398, 307, 257, 27706, 7006, 11, 51736, 51736, 411, 337, 21538, 13, 51847, 51847], "temperature": 0.0, "avg_logprob": -0.15183004678464404, "compression_ratio": 1.7309417040358743, "no_speech_prob": 2.075236443488393e-05}, {"id": 13, "seek": 5500, "start": 62.52, "end": 72.12, "text": " And it's basically, we're going to talk about models that observe a set of variables X,", "tokens": [50364, 512, 561, 818, 2693, 12879, 24420, 2539, 11, 420, 437, 286, 576, 818, 2698, 12, 48172, 24420, 2539, 11, 50580, 50580, 597, 286, 603, 751, 466, 257, 707, 857, 965, 13, 50740, 50740, 400, 309, 311, 1936, 11, 321, 434, 516, 281, 751, 466, 5245, 300, 11441, 257, 992, 295, 9102, 1783, 11, 51220, 51220, 293, 321, 434, 3365, 264, 2316, 281, 6069, 257, 992, 295, 9102, 398, 13, 51450, 51450, 400, 286, 478, 406, 1608, 5489, 300, 1783, 307, 364, 3256, 420, 2035, 11, 293, 398, 307, 257, 27706, 7006, 11, 51736, 51736, 411, 337, 21538, 13, 51847, 51847], "temperature": 0.0, "avg_logprob": -0.15183004678464404, "compression_ratio": 1.7309417040358743, "no_speech_prob": 2.075236443488393e-05}, {"id": 14, "seek": 5500, "start": 72.12, "end": 76.72, "text": " and we're asking the model to predict a set of variables Y.", "tokens": [50364, 512, 561, 818, 2693, 12879, 24420, 2539, 11, 420, 437, 286, 576, 818, 2698, 12, 48172, 24420, 2539, 11, 50580, 50580, 597, 286, 603, 751, 466, 257, 707, 857, 965, 13, 50740, 50740, 400, 309, 311, 1936, 11, 321, 434, 516, 281, 751, 466, 5245, 300, 11441, 257, 992, 295, 9102, 1783, 11, 51220, 51220, 293, 321, 434, 3365, 264, 2316, 281, 6069, 257, 992, 295, 9102, 398, 13, 51450, 51450, 400, 286, 478, 406, 1608, 5489, 300, 1783, 307, 364, 3256, 420, 2035, 11, 293, 398, 307, 257, 27706, 7006, 11, 51736, 51736, 411, 337, 21538, 13, 51847, 51847], "temperature": 0.0, "avg_logprob": -0.15183004678464404, "compression_ratio": 1.7309417040358743, "no_speech_prob": 2.075236443488393e-05}, {"id": 15, "seek": 5500, "start": 76.72, "end": 82.44, "text": " And I'm not specifying that X is an image or whatever, and Y is a discrete variable,", "tokens": [50364, 512, 561, 818, 2693, 12879, 24420, 2539, 11, 420, 437, 286, 576, 818, 2698, 12, 48172, 24420, 2539, 11, 50580, 50580, 597, 286, 603, 751, 466, 257, 707, 857, 965, 13, 50740, 50740, 400, 309, 311, 1936, 11, 321, 434, 516, 281, 751, 466, 5245, 300, 11441, 257, 992, 295, 9102, 1783, 11, 51220, 51220, 293, 321, 434, 3365, 264, 2316, 281, 6069, 257, 992, 295, 9102, 398, 13, 51450, 51450, 400, 286, 478, 406, 1608, 5489, 300, 1783, 307, 364, 3256, 420, 2035, 11, 293, 398, 307, 257, 27706, 7006, 11, 51736, 51736, 411, 337, 21538, 13, 51847, 51847], "temperature": 0.0, "avg_logprob": -0.15183004678464404, "compression_ratio": 1.7309417040358743, "no_speech_prob": 2.075236443488393e-05}, {"id": 16, "seek": 5500, "start": 82.44, "end": 84.66, "text": " like for classification.", "tokens": [50364, 512, 561, 818, 2693, 12879, 24420, 2539, 11, 420, 437, 286, 576, 818, 2698, 12, 48172, 24420, 2539, 11, 50580, 50580, 597, 286, 603, 751, 466, 257, 707, 857, 965, 13, 50740, 50740, 400, 309, 311, 1936, 11, 321, 434, 516, 281, 751, 466, 5245, 300, 11441, 257, 992, 295, 9102, 1783, 11, 51220, 51220, 293, 321, 434, 3365, 264, 2316, 281, 6069, 257, 992, 295, 9102, 398, 13, 51450, 51450, 400, 286, 478, 406, 1608, 5489, 300, 1783, 307, 364, 3256, 420, 2035, 11, 293, 398, 307, 257, 27706, 7006, 11, 51736, 51736, 411, 337, 21538, 13, 51847, 51847], "temperature": 0.0, "avg_logprob": -0.15183004678464404, "compression_ratio": 1.7309417040358743, "no_speech_prob": 2.075236443488393e-05}, {"id": 17, "seek": 8466, "start": 84.66, "end": 90.58, "text": " Y could be like an entire view, and X could be an entire view, or X could be an image", "tokens": [50364, 398, 727, 312, 411, 364, 2302, 1910, 11, 293, 1783, 727, 312, 364, 2302, 1910, 11, 420, 1783, 727, 312, 364, 3256, 50660, 50660, 293, 398, 257, 2522, 295, 2487, 300, 15626, 309, 11, 420, 1783, 727, 312, 257, 8174, 294, 472, 2856, 293, 50907, 50907, 398, 257, 8174, 294, 1071, 2856, 11, 1783, 727, 312, 364, 2302, 2487, 11, 293, 398, 727, 312, 257, 26335, 51145, 51145, 3037, 295, 300, 2487, 420, 364, 12649, 13, 51262, 51262, 407, 309, 727, 312, 1340, 11, 534, 13, 51395, 51395, 286, 478, 406, 733, 295, 1608, 5489, 4725, 510, 13, 51678, 51678], "temperature": 0.0, "avg_logprob": -0.12425789178586473, "compression_ratio": 1.9329896907216495, "no_speech_prob": 3.216782715753652e-05}, {"id": 18, "seek": 8466, "start": 90.58, "end": 95.52, "text": " and Y a piece of text that describes it, or X could be a sentence in one language and", "tokens": [50364, 398, 727, 312, 411, 364, 2302, 1910, 11, 293, 1783, 727, 312, 364, 2302, 1910, 11, 420, 1783, 727, 312, 364, 3256, 50660, 50660, 293, 398, 257, 2522, 295, 2487, 300, 15626, 309, 11, 420, 1783, 727, 312, 257, 8174, 294, 472, 2856, 293, 50907, 50907, 398, 257, 8174, 294, 1071, 2856, 11, 1783, 727, 312, 364, 2302, 2487, 11, 293, 398, 727, 312, 257, 26335, 51145, 51145, 3037, 295, 300, 2487, 420, 364, 12649, 13, 51262, 51262, 407, 309, 727, 312, 1340, 11, 534, 13, 51395, 51395, 286, 478, 406, 733, 295, 1608, 5489, 4725, 510, 13, 51678, 51678], "temperature": 0.0, "avg_logprob": -0.12425789178586473, "compression_ratio": 1.9329896907216495, "no_speech_prob": 3.216782715753652e-05}, {"id": 19, "seek": 8466, "start": 95.52, "end": 100.28, "text": " Y a sentence in another language, X could be an entire text, and Y could be a simplified", "tokens": [50364, 398, 727, 312, 411, 364, 2302, 1910, 11, 293, 1783, 727, 312, 364, 2302, 1910, 11, 420, 1783, 727, 312, 364, 3256, 50660, 50660, 293, 398, 257, 2522, 295, 2487, 300, 15626, 309, 11, 420, 1783, 727, 312, 257, 8174, 294, 472, 2856, 293, 50907, 50907, 398, 257, 8174, 294, 1071, 2856, 11, 1783, 727, 312, 364, 2302, 2487, 11, 293, 398, 727, 312, 257, 26335, 51145, 51145, 3037, 295, 300, 2487, 420, 364, 12649, 13, 51262, 51262, 407, 309, 727, 312, 1340, 11, 534, 13, 51395, 51395, 286, 478, 406, 733, 295, 1608, 5489, 4725, 510, 13, 51678, 51678], "temperature": 0.0, "avg_logprob": -0.12425789178586473, "compression_ratio": 1.9329896907216495, "no_speech_prob": 3.216782715753652e-05}, {"id": 20, "seek": 8466, "start": 100.28, "end": 102.62, "text": " version of that text or an abstract.", "tokens": [50364, 398, 727, 312, 411, 364, 2302, 1910, 11, 293, 1783, 727, 312, 364, 2302, 1910, 11, 420, 1783, 727, 312, 364, 3256, 50660, 50660, 293, 398, 257, 2522, 295, 2487, 300, 15626, 309, 11, 420, 1783, 727, 312, 257, 8174, 294, 472, 2856, 293, 50907, 50907, 398, 257, 8174, 294, 1071, 2856, 11, 1783, 727, 312, 364, 2302, 2487, 11, 293, 398, 727, 312, 257, 26335, 51145, 51145, 3037, 295, 300, 2487, 420, 364, 12649, 13, 51262, 51262, 407, 309, 727, 312, 1340, 11, 534, 13, 51395, 51395, 286, 478, 406, 733, 295, 1608, 5489, 4725, 510, 13, 51678, 51678], "temperature": 0.0, "avg_logprob": -0.12425789178586473, "compression_ratio": 1.9329896907216495, "no_speech_prob": 3.216782715753652e-05}, {"id": 21, "seek": 8466, "start": 102.62, "end": 105.28, "text": " So it could be anything, really.", "tokens": [50364, 398, 727, 312, 411, 364, 2302, 1910, 11, 293, 1783, 727, 312, 364, 2302, 1910, 11, 420, 1783, 727, 312, 364, 3256, 50660, 50660, 293, 398, 257, 2522, 295, 2487, 300, 15626, 309, 11, 420, 1783, 727, 312, 257, 8174, 294, 472, 2856, 293, 50907, 50907, 398, 257, 8174, 294, 1071, 2856, 11, 1783, 727, 312, 364, 2302, 2487, 11, 293, 398, 727, 312, 257, 26335, 51145, 51145, 3037, 295, 300, 2487, 420, 364, 12649, 13, 51262, 51262, 407, 309, 727, 312, 1340, 11, 534, 13, 51395, 51395, 286, 478, 406, 733, 295, 1608, 5489, 4725, 510, 13, 51678, 51678], "temperature": 0.0, "avg_logprob": -0.12425789178586473, "compression_ratio": 1.9329896907216495, "no_speech_prob": 3.216782715753652e-05}, {"id": 22, "seek": 8466, "start": 105.28, "end": 110.94, "text": " I'm not kind of specifying necessarily here.", "tokens": [50364, 398, 727, 312, 411, 364, 2302, 1910, 11, 293, 1783, 727, 312, 364, 2302, 1910, 11, 420, 1783, 727, 312, 364, 3256, 50660, 50660, 293, 398, 257, 2522, 295, 2487, 300, 15626, 309, 11, 420, 1783, 727, 312, 257, 8174, 294, 472, 2856, 293, 50907, 50907, 398, 257, 8174, 294, 1071, 2856, 11, 1783, 727, 312, 364, 2302, 2487, 11, 293, 398, 727, 312, 257, 26335, 51145, 51145, 3037, 295, 300, 2487, 420, 364, 12649, 13, 51262, 51262, 407, 309, 727, 312, 1340, 11, 534, 13, 51395, 51395, 286, 478, 406, 733, 295, 1608, 5489, 4725, 510, 13, 51678, 51678], "temperature": 0.0, "avg_logprob": -0.12425789178586473, "compression_ratio": 1.9329896907216495, "no_speech_prob": 3.216782715753652e-05}, {"id": 23, "seek": 11094, "start": 110.94, "end": 116.88, "text": " But it comes from the fact that there's two issues with sort of feedforward models.", "tokens": [50364, 583, 309, 1487, 490, 264, 1186, 300, 456, 311, 732, 2663, 365, 1333, 295, 3154, 13305, 5245, 13, 50661, 50661, 8503, 436, 366, 18161, 36170, 420, 746, 1646, 1177, 380, 1871, 13, 50861, 50861, 316, 2316, 11, 257, 13735, 2316, 11, 32280, 538, 884, 257, 19362, 6806, 1230, 295, 20448, 281, 5258, 51383, 51383, 364, 5598, 13, 51433, 51433, 759, 291, 362, 257, 2120, 388, 11167, 2533, 11, 456, 307, 257, 6806, 1230, 295, 7914, 13, 51601, 51601, 2754, 498, 291, 362, 257, 18680, 1753, 2533, 11, 456, 307, 512, 1333, 295, 4948, 281, 577, 867, 1413, 291, 393, 51735, 51735, 17980, 309, 13, 51821, 51821], "temperature": 0.0, "avg_logprob": -0.14108433546843352, "compression_ratio": 1.664, "no_speech_prob": 1.7224076145794243e-05}, {"id": 24, "seek": 11094, "start": 116.88, "end": 120.88, "text": " Whether they are neural nets or something else doesn't matter.", "tokens": [50364, 583, 309, 1487, 490, 264, 1186, 300, 456, 311, 732, 2663, 365, 1333, 295, 3154, 13305, 5245, 13, 50661, 50661, 8503, 436, 366, 18161, 36170, 420, 746, 1646, 1177, 380, 1871, 13, 50861, 50861, 316, 2316, 11, 257, 13735, 2316, 11, 32280, 538, 884, 257, 19362, 6806, 1230, 295, 20448, 281, 5258, 51383, 51383, 364, 5598, 13, 51433, 51433, 759, 291, 362, 257, 2120, 388, 11167, 2533, 11, 456, 307, 257, 6806, 1230, 295, 7914, 13, 51601, 51601, 2754, 498, 291, 362, 257, 18680, 1753, 2533, 11, 456, 307, 512, 1333, 295, 4948, 281, 577, 867, 1413, 291, 393, 51735, 51735, 17980, 309, 13, 51821, 51821], "temperature": 0.0, "avg_logprob": -0.14108433546843352, "compression_ratio": 1.664, "no_speech_prob": 1.7224076145794243e-05}, {"id": 25, "seek": 11094, "start": 120.88, "end": 131.32, "text": " A model, a classical model, proceeds by doing a finite fixed number of calculations to produce", "tokens": [50364, 583, 309, 1487, 490, 264, 1186, 300, 456, 311, 732, 2663, 365, 1333, 295, 3154, 13305, 5245, 13, 50661, 50661, 8503, 436, 366, 18161, 36170, 420, 746, 1646, 1177, 380, 1871, 13, 50861, 50861, 316, 2316, 11, 257, 13735, 2316, 11, 32280, 538, 884, 257, 19362, 6806, 1230, 295, 20448, 281, 5258, 51383, 51383, 364, 5598, 13, 51433, 51433, 759, 291, 362, 257, 2120, 388, 11167, 2533, 11, 456, 307, 257, 6806, 1230, 295, 7914, 13, 51601, 51601, 2754, 498, 291, 362, 257, 18680, 1753, 2533, 11, 456, 307, 512, 1333, 295, 4948, 281, 577, 867, 1413, 291, 393, 51735, 51735, 17980, 309, 13, 51821, 51821], "temperature": 0.0, "avg_logprob": -0.14108433546843352, "compression_ratio": 1.664, "no_speech_prob": 1.7224076145794243e-05}, {"id": 26, "seek": 11094, "start": 131.32, "end": 132.32, "text": " an output.", "tokens": [50364, 583, 309, 1487, 490, 264, 1186, 300, 456, 311, 732, 2663, 365, 1333, 295, 3154, 13305, 5245, 13, 50661, 50661, 8503, 436, 366, 18161, 36170, 420, 746, 1646, 1177, 380, 1871, 13, 50861, 50861, 316, 2316, 11, 257, 13735, 2316, 11, 32280, 538, 884, 257, 19362, 6806, 1230, 295, 20448, 281, 5258, 51383, 51383, 364, 5598, 13, 51433, 51433, 759, 291, 362, 257, 2120, 388, 11167, 2533, 11, 456, 307, 257, 6806, 1230, 295, 7914, 13, 51601, 51601, 2754, 498, 291, 362, 257, 18680, 1753, 2533, 11, 456, 307, 512, 1333, 295, 4948, 281, 577, 867, 1413, 291, 393, 51735, 51735, 17980, 309, 13, 51821, 51821], "temperature": 0.0, "avg_logprob": -0.14108433546843352, "compression_ratio": 1.664, "no_speech_prob": 1.7224076145794243e-05}, {"id": 27, "seek": 11094, "start": 132.32, "end": 135.68, "text": " If you have a multilayer net, there is a fixed number of layers.", "tokens": [50364, 583, 309, 1487, 490, 264, 1186, 300, 456, 311, 732, 2663, 365, 1333, 295, 3154, 13305, 5245, 13, 50661, 50661, 8503, 436, 366, 18161, 36170, 420, 746, 1646, 1177, 380, 1871, 13, 50861, 50861, 316, 2316, 11, 257, 13735, 2316, 11, 32280, 538, 884, 257, 19362, 6806, 1230, 295, 20448, 281, 5258, 51383, 51383, 364, 5598, 13, 51433, 51433, 759, 291, 362, 257, 2120, 388, 11167, 2533, 11, 456, 307, 257, 6806, 1230, 295, 7914, 13, 51601, 51601, 2754, 498, 291, 362, 257, 18680, 1753, 2533, 11, 456, 307, 512, 1333, 295, 4948, 281, 577, 867, 1413, 291, 393, 51735, 51735, 17980, 309, 13, 51821, 51821], "temperature": 0.0, "avg_logprob": -0.14108433546843352, "compression_ratio": 1.664, "no_speech_prob": 1.7224076145794243e-05}, {"id": 28, "seek": 11094, "start": 135.68, "end": 138.36, "text": " Even if you have a recurrent net, there is some sort of limit to how many times you can", "tokens": [50364, 583, 309, 1487, 490, 264, 1186, 300, 456, 311, 732, 2663, 365, 1333, 295, 3154, 13305, 5245, 13, 50661, 50661, 8503, 436, 366, 18161, 36170, 420, 746, 1646, 1177, 380, 1871, 13, 50861, 50861, 316, 2316, 11, 257, 13735, 2316, 11, 32280, 538, 884, 257, 19362, 6806, 1230, 295, 20448, 281, 5258, 51383, 51383, 364, 5598, 13, 51433, 51433, 759, 291, 362, 257, 2120, 388, 11167, 2533, 11, 456, 307, 257, 6806, 1230, 295, 7914, 13, 51601, 51601, 2754, 498, 291, 362, 257, 18680, 1753, 2533, 11, 456, 307, 512, 1333, 295, 4948, 281, 577, 867, 1413, 291, 393, 51735, 51735, 17980, 309, 13, 51821, 51821], "temperature": 0.0, "avg_logprob": -0.14108433546843352, "compression_ratio": 1.664, "no_speech_prob": 1.7224076145794243e-05}, {"id": 29, "seek": 11094, "start": 138.36, "end": 140.07999999999998, "text": " unfold it.", "tokens": [50364, 583, 309, 1487, 490, 264, 1186, 300, 456, 311, 732, 2663, 365, 1333, 295, 3154, 13305, 5245, 13, 50661, 50661, 8503, 436, 366, 18161, 36170, 420, 746, 1646, 1177, 380, 1871, 13, 50861, 50861, 316, 2316, 11, 257, 13735, 2316, 11, 32280, 538, 884, 257, 19362, 6806, 1230, 295, 20448, 281, 5258, 51383, 51383, 364, 5598, 13, 51433, 51433, 759, 291, 362, 257, 2120, 388, 11167, 2533, 11, 456, 307, 257, 6806, 1230, 295, 7914, 13, 51601, 51601, 2754, 498, 291, 362, 257, 18680, 1753, 2533, 11, 456, 307, 512, 1333, 295, 4948, 281, 577, 867, 1413, 291, 393, 51735, 51735, 17980, 309, 13, 51821, 51821], "temperature": 0.0, "avg_logprob": -0.14108433546843352, "compression_ratio": 1.664, "no_speech_prob": 1.7224076145794243e-05}, {"id": 30, "seek": 14008, "start": 140.08, "end": 146.0, "text": " So it's basically a fixed amount of computation.", "tokens": [50364, 407, 309, 311, 1936, 257, 6806, 2372, 295, 24903, 13, 50660, 50660, 583, 456, 366, 732, 2663, 337, 597, 341, 307, 406, 7696, 6854, 13, 50842, 50842, 440, 700, 472, 11, 420, 732, 6851, 11, 264, 700, 2590, 307, 562, 15866, 264, 5598, 7029, 51082, 51082, 512, 544, 3997, 17108, 813, 445, 257, 3840, 295, 32807, 34499, 293, 2107, 12, 1889, 17409, 294, 51378, 51378, 257, 19362, 1230, 11, 562, 264, 38253, 307, 3997, 13, 51714, 51714], "temperature": 0.0, "avg_logprob": -0.15132427215576172, "compression_ratio": 1.573394495412844, "no_speech_prob": 1.1121242096123751e-05}, {"id": 31, "seek": 14008, "start": 146.0, "end": 149.64000000000001, "text": " But there are two issues for which this is not entirely appropriate.", "tokens": [50364, 407, 309, 311, 1936, 257, 6806, 2372, 295, 24903, 13, 50660, 50660, 583, 456, 366, 732, 2663, 337, 597, 341, 307, 406, 7696, 6854, 13, 50842, 50842, 440, 700, 472, 11, 420, 732, 6851, 11, 264, 700, 2590, 307, 562, 15866, 264, 5598, 7029, 51082, 51082, 512, 544, 3997, 17108, 813, 445, 257, 3840, 295, 32807, 34499, 293, 2107, 12, 1889, 17409, 294, 51378, 51378, 257, 19362, 1230, 11, 562, 264, 38253, 307, 3997, 13, 51714, 51714], "temperature": 0.0, "avg_logprob": -0.15132427215576172, "compression_ratio": 1.573394495412844, "no_speech_prob": 1.1121242096123751e-05}, {"id": 32, "seek": 14008, "start": 149.64000000000001, "end": 154.44, "text": " The first one, or two situations, the first situation is when computing the output requires", "tokens": [50364, 407, 309, 311, 1936, 257, 6806, 2372, 295, 24903, 13, 50660, 50660, 583, 456, 366, 732, 2663, 337, 597, 341, 307, 406, 7696, 6854, 13, 50842, 50842, 440, 700, 472, 11, 420, 732, 6851, 11, 264, 700, 2590, 307, 562, 15866, 264, 5598, 7029, 51082, 51082, 512, 544, 3997, 17108, 813, 445, 257, 3840, 295, 32807, 34499, 293, 2107, 12, 1889, 17409, 294, 51378, 51378, 257, 19362, 1230, 11, 562, 264, 38253, 307, 3997, 13, 51714, 51714], "temperature": 0.0, "avg_logprob": -0.15132427215576172, "compression_ratio": 1.573394495412844, "no_speech_prob": 1.1121242096123751e-05}, {"id": 33, "seek": 14008, "start": 154.44, "end": 160.36, "text": " some more complex calculation than just a bunch of weighted sums and non-linearity in", "tokens": [50364, 407, 309, 311, 1936, 257, 6806, 2372, 295, 24903, 13, 50660, 50660, 583, 456, 366, 732, 2663, 337, 597, 341, 307, 406, 7696, 6854, 13, 50842, 50842, 440, 700, 472, 11, 420, 732, 6851, 11, 264, 700, 2590, 307, 562, 15866, 264, 5598, 7029, 51082, 51082, 512, 544, 3997, 17108, 813, 445, 257, 3840, 295, 32807, 34499, 293, 2107, 12, 1889, 17409, 294, 51378, 51378, 257, 19362, 1230, 11, 562, 264, 38253, 307, 3997, 13, 51714, 51714], "temperature": 0.0, "avg_logprob": -0.15132427215576172, "compression_ratio": 1.573394495412844, "no_speech_prob": 1.1121242096123751e-05}, {"id": 34, "seek": 14008, "start": 160.36, "end": 167.08, "text": " a finite number, when the inference is complex.", "tokens": [50364, 407, 309, 311, 1936, 257, 6806, 2372, 295, 24903, 13, 50660, 50660, 583, 456, 366, 732, 2663, 337, 597, 341, 307, 406, 7696, 6854, 13, 50842, 50842, 440, 700, 472, 11, 420, 732, 6851, 11, 264, 700, 2590, 307, 562, 15866, 264, 5598, 7029, 51082, 51082, 512, 544, 3997, 17108, 813, 445, 257, 3840, 295, 32807, 34499, 293, 2107, 12, 1889, 17409, 294, 51378, 51378, 257, 19362, 1230, 11, 562, 264, 38253, 307, 3997, 13, 51714, 51714], "temperature": 0.0, "avg_logprob": -0.15132427215576172, "compression_ratio": 1.573394495412844, "no_speech_prob": 1.1121242096123751e-05}, {"id": 35, "seek": 16708, "start": 167.08, "end": 171.16000000000003, "text": " And the second situation is when we're trying to train the machine to produce not a single", "tokens": [50364, 400, 264, 1150, 2590, 307, 562, 321, 434, 1382, 281, 3847, 264, 3479, 281, 5258, 406, 257, 2167, 50568, 50568, 5598, 457, 257, 1944, 992, 295, 23930, 13, 50733, 50733, 407, 294, 264, 1389, 295, 21538, 11, 321, 434, 767, 3097, 257, 3479, 281, 5258, 3866, 23930, 13, 50924, 50924, 492, 366, 3097, 309, 281, 5258, 257, 4994, 6175, 337, 633, 1944, 7719, 300, 321, 362, 294, 51156, 51156, 527, 1185, 13, 51206, 51206, 40817, 11, 264, 1185, 576, 5258, 264, 1151, 6175, 337, 264, 3006, 1508, 293, 7193, 3324, 10650, 51552, 51552, 13444, 337, 264, 661, 2306, 13, 51652, 51652], "temperature": 0.0, "avg_logprob": -0.09501198888982385, "compression_ratio": 1.8271604938271604, "no_speech_prob": 9.079240953724366e-06}, {"id": 36, "seek": 16708, "start": 171.16000000000003, "end": 174.46, "text": " output but a possible set of outputs.", "tokens": [50364, 400, 264, 1150, 2590, 307, 562, 321, 434, 1382, 281, 3847, 264, 3479, 281, 5258, 406, 257, 2167, 50568, 50568, 5598, 457, 257, 1944, 992, 295, 23930, 13, 50733, 50733, 407, 294, 264, 1389, 295, 21538, 11, 321, 434, 767, 3097, 257, 3479, 281, 5258, 3866, 23930, 13, 50924, 50924, 492, 366, 3097, 309, 281, 5258, 257, 4994, 6175, 337, 633, 1944, 7719, 300, 321, 362, 294, 51156, 51156, 527, 1185, 13, 51206, 51206, 40817, 11, 264, 1185, 576, 5258, 264, 1151, 6175, 337, 264, 3006, 1508, 293, 7193, 3324, 10650, 51552, 51552, 13444, 337, 264, 661, 2306, 13, 51652, 51652], "temperature": 0.0, "avg_logprob": -0.09501198888982385, "compression_ratio": 1.8271604938271604, "no_speech_prob": 9.079240953724366e-06}, {"id": 37, "seek": 16708, "start": 174.46, "end": 178.28, "text": " So in the case of classification, we're actually training a machine to produce multiple outputs.", "tokens": [50364, 400, 264, 1150, 2590, 307, 562, 321, 434, 1382, 281, 3847, 264, 3479, 281, 5258, 406, 257, 2167, 50568, 50568, 5598, 457, 257, 1944, 992, 295, 23930, 13, 50733, 50733, 407, 294, 264, 1389, 295, 21538, 11, 321, 434, 767, 3097, 257, 3479, 281, 5258, 3866, 23930, 13, 50924, 50924, 492, 366, 3097, 309, 281, 5258, 257, 4994, 6175, 337, 633, 1944, 7719, 300, 321, 362, 294, 51156, 51156, 527, 1185, 13, 51206, 51206, 40817, 11, 264, 1185, 576, 5258, 264, 1151, 6175, 337, 264, 3006, 1508, 293, 7193, 3324, 10650, 51552, 51552, 13444, 337, 264, 661, 2306, 13, 51652, 51652], "temperature": 0.0, "avg_logprob": -0.09501198888982385, "compression_ratio": 1.8271604938271604, "no_speech_prob": 9.079240953724366e-06}, {"id": 38, "seek": 16708, "start": 178.28, "end": 182.92000000000002, "text": " We are training it to produce a separate score for every possible category that we have in", "tokens": [50364, 400, 264, 1150, 2590, 307, 562, 321, 434, 1382, 281, 3847, 264, 3479, 281, 5258, 406, 257, 2167, 50568, 50568, 5598, 457, 257, 1944, 992, 295, 23930, 13, 50733, 50733, 407, 294, 264, 1389, 295, 21538, 11, 321, 434, 767, 3097, 257, 3479, 281, 5258, 3866, 23930, 13, 50924, 50924, 492, 366, 3097, 309, 281, 5258, 257, 4994, 6175, 337, 633, 1944, 7719, 300, 321, 362, 294, 51156, 51156, 527, 1185, 13, 51206, 51206, 40817, 11, 264, 1185, 576, 5258, 264, 1151, 6175, 337, 264, 3006, 1508, 293, 7193, 3324, 10650, 51552, 51552, 13444, 337, 264, 661, 2306, 13, 51652, 51652], "temperature": 0.0, "avg_logprob": -0.09501198888982385, "compression_ratio": 1.8271604938271604, "no_speech_prob": 9.079240953724366e-06}, {"id": 39, "seek": 16708, "start": 182.92000000000002, "end": 183.92000000000002, "text": " our system.", "tokens": [50364, 400, 264, 1150, 2590, 307, 562, 321, 434, 1382, 281, 3847, 264, 3479, 281, 5258, 406, 257, 2167, 50568, 50568, 5598, 457, 257, 1944, 992, 295, 23930, 13, 50733, 50733, 407, 294, 264, 1389, 295, 21538, 11, 321, 434, 767, 3097, 257, 3479, 281, 5258, 3866, 23930, 13, 50924, 50924, 492, 366, 3097, 309, 281, 5258, 257, 4994, 6175, 337, 633, 1944, 7719, 300, 321, 362, 294, 51156, 51156, 527, 1185, 13, 51206, 51206, 40817, 11, 264, 1185, 576, 5258, 264, 1151, 6175, 337, 264, 3006, 1508, 293, 7193, 3324, 10650, 51552, 51552, 13444, 337, 264, 661, 2306, 13, 51652, 51652], "temperature": 0.0, "avg_logprob": -0.09501198888982385, "compression_ratio": 1.8271604938271604, "no_speech_prob": 9.079240953724366e-06}, {"id": 40, "seek": 16708, "start": 183.92000000000002, "end": 190.84, "text": " Ideally, the system would produce the best score for the correct class and infinitesimal", "tokens": [50364, 400, 264, 1150, 2590, 307, 562, 321, 434, 1382, 281, 3847, 264, 3479, 281, 5258, 406, 257, 2167, 50568, 50568, 5598, 457, 257, 1944, 992, 295, 23930, 13, 50733, 50733, 407, 294, 264, 1389, 295, 21538, 11, 321, 434, 767, 3097, 257, 3479, 281, 5258, 3866, 23930, 13, 50924, 50924, 492, 366, 3097, 309, 281, 5258, 257, 4994, 6175, 337, 633, 1944, 7719, 300, 321, 362, 294, 51156, 51156, 527, 1185, 13, 51206, 51206, 40817, 11, 264, 1185, 576, 5258, 264, 1151, 6175, 337, 264, 3006, 1508, 293, 7193, 3324, 10650, 51552, 51552, 13444, 337, 264, 661, 2306, 13, 51652, 51652], "temperature": 0.0, "avg_logprob": -0.09501198888982385, "compression_ratio": 1.8271604938271604, "no_speech_prob": 9.079240953724366e-06}, {"id": 41, "seek": 16708, "start": 190.84, "end": 192.84, "text": " scores for the other ones.", "tokens": [50364, 400, 264, 1150, 2590, 307, 562, 321, 434, 1382, 281, 3847, 264, 3479, 281, 5258, 406, 257, 2167, 50568, 50568, 5598, 457, 257, 1944, 992, 295, 23930, 13, 50733, 50733, 407, 294, 264, 1389, 295, 21538, 11, 321, 434, 767, 3097, 257, 3479, 281, 5258, 3866, 23930, 13, 50924, 50924, 492, 366, 3097, 309, 281, 5258, 257, 4994, 6175, 337, 633, 1944, 7719, 300, 321, 362, 294, 51156, 51156, 527, 1185, 13, 51206, 51206, 40817, 11, 264, 1185, 576, 5258, 264, 1151, 6175, 337, 264, 3006, 1508, 293, 7193, 3324, 10650, 51552, 51552, 13444, 337, 264, 661, 2306, 13, 51652, 51652], "temperature": 0.0, "avg_logprob": -0.09501198888982385, "compression_ratio": 1.8271604938271604, "no_speech_prob": 9.079240953724366e-06}, {"id": 42, "seek": 19284, "start": 192.84, "end": 198.18, "text": " In practice, when we run the output of a neural net through softmax, it produces the kind", "tokens": [50364, 682, 3124, 11, 562, 321, 1190, 264, 5598, 295, 257, 18161, 2533, 807, 2787, 41167, 11, 309, 14725, 264, 733, 50631, 50631, 295, 13444, 293, 321, 445, 1888, 264, 472, 300, 575, 264, 6343, 6175, 13, 50836, 50836, 583, 1936, 437, 321, 366, 3585, 264, 3479, 281, 360, 307, 5258, 257, 6175, 337, 633, 7719, 51076, 51076, 293, 550, 321, 603, 1888, 264, 1151, 13, 51250, 51250, 823, 341, 307, 406, 1944, 562, 264, 5598, 307, 10957, 293, 1090, 18795, 13, 51510, 51510, 407, 264, 5598, 307, 11, 718, 311, 584, 11, 364, 3256, 13, 51702, 51702, 492, 500, 380, 362, 2787, 41167, 279, 670, 5267, 13, 51834, 51834], "temperature": 0.0, "avg_logprob": -0.14858876477490673, "compression_ratio": 1.6732283464566928, "no_speech_prob": 2.078259967674967e-05}, {"id": 43, "seek": 19284, "start": 198.18, "end": 202.28, "text": " of scores and we just pick the one that has the highest score.", "tokens": [50364, 682, 3124, 11, 562, 321, 1190, 264, 5598, 295, 257, 18161, 2533, 807, 2787, 41167, 11, 309, 14725, 264, 733, 50631, 50631, 295, 13444, 293, 321, 445, 1888, 264, 472, 300, 575, 264, 6343, 6175, 13, 50836, 50836, 583, 1936, 437, 321, 366, 3585, 264, 3479, 281, 360, 307, 5258, 257, 6175, 337, 633, 7719, 51076, 51076, 293, 550, 321, 603, 1888, 264, 1151, 13, 51250, 51250, 823, 341, 307, 406, 1944, 562, 264, 5598, 307, 10957, 293, 1090, 18795, 13, 51510, 51510, 407, 264, 5598, 307, 11, 718, 311, 584, 11, 364, 3256, 13, 51702, 51702, 492, 500, 380, 362, 2787, 41167, 279, 670, 5267, 13, 51834, 51834], "temperature": 0.0, "avg_logprob": -0.14858876477490673, "compression_ratio": 1.6732283464566928, "no_speech_prob": 2.078259967674967e-05}, {"id": 44, "seek": 19284, "start": 202.28, "end": 207.08, "text": " But basically what we are telling the machine to do is produce a score for every category", "tokens": [50364, 682, 3124, 11, 562, 321, 1190, 264, 5598, 295, 257, 18161, 2533, 807, 2787, 41167, 11, 309, 14725, 264, 733, 50631, 50631, 295, 13444, 293, 321, 445, 1888, 264, 472, 300, 575, 264, 6343, 6175, 13, 50836, 50836, 583, 1936, 437, 321, 366, 3585, 264, 3479, 281, 360, 307, 5258, 257, 6175, 337, 633, 7719, 51076, 51076, 293, 550, 321, 603, 1888, 264, 1151, 13, 51250, 51250, 823, 341, 307, 406, 1944, 562, 264, 5598, 307, 10957, 293, 1090, 18795, 13, 51510, 51510, 407, 264, 5598, 307, 11, 718, 311, 584, 11, 364, 3256, 13, 51702, 51702, 492, 500, 380, 362, 2787, 41167, 279, 670, 5267, 13, 51834, 51834], "temperature": 0.0, "avg_logprob": -0.14858876477490673, "compression_ratio": 1.6732283464566928, "no_speech_prob": 2.078259967674967e-05}, {"id": 45, "seek": 19284, "start": 207.08, "end": 210.56, "text": " and then we'll pick the best.", "tokens": [50364, 682, 3124, 11, 562, 321, 1190, 264, 5598, 295, 257, 18161, 2533, 807, 2787, 41167, 11, 309, 14725, 264, 733, 50631, 50631, 295, 13444, 293, 321, 445, 1888, 264, 472, 300, 575, 264, 6343, 6175, 13, 50836, 50836, 583, 1936, 437, 321, 366, 3585, 264, 3479, 281, 360, 307, 5258, 257, 6175, 337, 633, 7719, 51076, 51076, 293, 550, 321, 603, 1888, 264, 1151, 13, 51250, 51250, 823, 341, 307, 406, 1944, 562, 264, 5598, 307, 10957, 293, 1090, 18795, 13, 51510, 51510, 407, 264, 5598, 307, 11, 718, 311, 584, 11, 364, 3256, 13, 51702, 51702, 492, 500, 380, 362, 2787, 41167, 279, 670, 5267, 13, 51834, 51834], "temperature": 0.0, "avg_logprob": -0.14858876477490673, "compression_ratio": 1.6732283464566928, "no_speech_prob": 2.078259967674967e-05}, {"id": 46, "seek": 19284, "start": 210.56, "end": 215.76, "text": " Now this is not possible when the output is continuous and high dimensional.", "tokens": [50364, 682, 3124, 11, 562, 321, 1190, 264, 5598, 295, 257, 18161, 2533, 807, 2787, 41167, 11, 309, 14725, 264, 733, 50631, 50631, 295, 13444, 293, 321, 445, 1888, 264, 472, 300, 575, 264, 6343, 6175, 13, 50836, 50836, 583, 1936, 437, 321, 366, 3585, 264, 3479, 281, 360, 307, 5258, 257, 6175, 337, 633, 7719, 51076, 51076, 293, 550, 321, 603, 1888, 264, 1151, 13, 51250, 51250, 823, 341, 307, 406, 1944, 562, 264, 5598, 307, 10957, 293, 1090, 18795, 13, 51510, 51510, 407, 264, 5598, 307, 11, 718, 311, 584, 11, 364, 3256, 13, 51702, 51702, 492, 500, 380, 362, 2787, 41167, 279, 670, 5267, 13, 51834, 51834], "temperature": 0.0, "avg_logprob": -0.14858876477490673, "compression_ratio": 1.6732283464566928, "no_speech_prob": 2.078259967674967e-05}, {"id": 47, "seek": 19284, "start": 215.76, "end": 219.6, "text": " So the output is, let's say, an image.", "tokens": [50364, 682, 3124, 11, 562, 321, 1190, 264, 5598, 295, 257, 18161, 2533, 807, 2787, 41167, 11, 309, 14725, 264, 733, 50631, 50631, 295, 13444, 293, 321, 445, 1888, 264, 472, 300, 575, 264, 6343, 6175, 13, 50836, 50836, 583, 1936, 437, 321, 366, 3585, 264, 3479, 281, 360, 307, 5258, 257, 6175, 337, 633, 7719, 51076, 51076, 293, 550, 321, 603, 1888, 264, 1151, 13, 51250, 51250, 823, 341, 307, 406, 1944, 562, 264, 5598, 307, 10957, 293, 1090, 18795, 13, 51510, 51510, 407, 264, 5598, 307, 11, 718, 311, 584, 11, 364, 3256, 13, 51702, 51702, 492, 500, 380, 362, 2787, 41167, 279, 670, 5267, 13, 51834, 51834], "temperature": 0.0, "avg_logprob": -0.14858876477490673, "compression_ratio": 1.6732283464566928, "no_speech_prob": 2.078259967674967e-05}, {"id": 48, "seek": 19284, "start": 219.6, "end": 222.24, "text": " We don't have softmaxes over images.", "tokens": [50364, 682, 3124, 11, 562, 321, 1190, 264, 5598, 295, 257, 18161, 2533, 807, 2787, 41167, 11, 309, 14725, 264, 733, 50631, 50631, 295, 13444, 293, 321, 445, 1888, 264, 472, 300, 575, 264, 6343, 6175, 13, 50836, 50836, 583, 1936, 437, 321, 366, 3585, 264, 3479, 281, 360, 307, 5258, 257, 6175, 337, 633, 7719, 51076, 51076, 293, 550, 321, 603, 1888, 264, 1151, 13, 51250, 51250, 823, 341, 307, 406, 1944, 562, 264, 5598, 307, 10957, 293, 1090, 18795, 13, 51510, 51510, 407, 264, 5598, 307, 11, 718, 311, 584, 11, 364, 3256, 13, 51702, 51702, 492, 500, 380, 362, 2787, 41167, 279, 670, 5267, 13, 51834, 51834], "temperature": 0.0, "avg_logprob": -0.14858876477490673, "compression_ratio": 1.6732283464566928, "no_speech_prob": 2.078259967674967e-05}, {"id": 49, "seek": 22224, "start": 222.24, "end": 228.16, "text": " We don't have a way of listing all possible images and then normalizing a distribution", "tokens": [50364, 492, 500, 380, 362, 257, 636, 295, 22161, 439, 1944, 5267, 293, 550, 2710, 3319, 257, 7316, 50660, 50660, 670, 552, 570, 309, 311, 1090, 18795, 10957, 1901, 13, 50796, 50796, 2754, 498, 309, 645, 257, 2295, 18795, 10957, 1901, 11, 309, 576, 406, 312, 1944, 13, 50954, 50954, 492, 576, 362, 281, 5171, 300, 10957, 1901, 666, 27706, 41275, 293, 550, 360, 257, 2787, 41167, 670, 51234, 51234, 300, 11, 457, 300, 1177, 380, 589, 588, 731, 13, 51398, 51398, 467, 787, 1985, 294, 2295, 10139, 13, 51556, 51556, 407, 562, 321, 362, 257, 1090, 18795, 10957, 1901, 11, 321, 393, 360, 2787, 41167, 13, 51751, 51751], "temperature": 0.0, "avg_logprob": -0.1548212398182262, "compression_ratio": 1.9156118143459915, "no_speech_prob": 2.2119804270914756e-05}, {"id": 50, "seek": 22224, "start": 228.16, "end": 230.88, "text": " over them because it's high dimensional continuous space.", "tokens": [50364, 492, 500, 380, 362, 257, 636, 295, 22161, 439, 1944, 5267, 293, 550, 2710, 3319, 257, 7316, 50660, 50660, 670, 552, 570, 309, 311, 1090, 18795, 10957, 1901, 13, 50796, 50796, 2754, 498, 309, 645, 257, 2295, 18795, 10957, 1901, 11, 309, 576, 406, 312, 1944, 13, 50954, 50954, 492, 576, 362, 281, 5171, 300, 10957, 1901, 666, 27706, 41275, 293, 550, 360, 257, 2787, 41167, 670, 51234, 51234, 300, 11, 457, 300, 1177, 380, 589, 588, 731, 13, 51398, 51398, 467, 787, 1985, 294, 2295, 10139, 13, 51556, 51556, 407, 562, 321, 362, 257, 1090, 18795, 10957, 1901, 11, 321, 393, 360, 2787, 41167, 13, 51751, 51751], "temperature": 0.0, "avg_logprob": -0.1548212398182262, "compression_ratio": 1.9156118143459915, "no_speech_prob": 2.2119804270914756e-05}, {"id": 51, "seek": 22224, "start": 230.88, "end": 234.04000000000002, "text": " Even if it were a low dimensional continuous space, it would not be possible.", "tokens": [50364, 492, 500, 380, 362, 257, 636, 295, 22161, 439, 1944, 5267, 293, 550, 2710, 3319, 257, 7316, 50660, 50660, 670, 552, 570, 309, 311, 1090, 18795, 10957, 1901, 13, 50796, 50796, 2754, 498, 309, 645, 257, 2295, 18795, 10957, 1901, 11, 309, 576, 406, 312, 1944, 13, 50954, 50954, 492, 576, 362, 281, 5171, 300, 10957, 1901, 666, 27706, 41275, 293, 550, 360, 257, 2787, 41167, 670, 51234, 51234, 300, 11, 457, 300, 1177, 380, 589, 588, 731, 13, 51398, 51398, 467, 787, 1985, 294, 2295, 10139, 13, 51556, 51556, 407, 562, 321, 362, 257, 1090, 18795, 10957, 1901, 11, 321, 393, 360, 2787, 41167, 13, 51751, 51751], "temperature": 0.0, "avg_logprob": -0.1548212398182262, "compression_ratio": 1.9156118143459915, "no_speech_prob": 2.2119804270914756e-05}, {"id": 52, "seek": 22224, "start": 234.04000000000002, "end": 239.64000000000001, "text": " We would have to bin that continuous space into discrete bins and then do a softmax over", "tokens": [50364, 492, 500, 380, 362, 257, 636, 295, 22161, 439, 1944, 5267, 293, 550, 2710, 3319, 257, 7316, 50660, 50660, 670, 552, 570, 309, 311, 1090, 18795, 10957, 1901, 13, 50796, 50796, 2754, 498, 309, 645, 257, 2295, 18795, 10957, 1901, 11, 309, 576, 406, 312, 1944, 13, 50954, 50954, 492, 576, 362, 281, 5171, 300, 10957, 1901, 666, 27706, 41275, 293, 550, 360, 257, 2787, 41167, 670, 51234, 51234, 300, 11, 457, 300, 1177, 380, 589, 588, 731, 13, 51398, 51398, 467, 787, 1985, 294, 2295, 10139, 13, 51556, 51556, 407, 562, 321, 362, 257, 1090, 18795, 10957, 1901, 11, 321, 393, 360, 2787, 41167, 13, 51751, 51751], "temperature": 0.0, "avg_logprob": -0.1548212398182262, "compression_ratio": 1.9156118143459915, "no_speech_prob": 2.2119804270914756e-05}, {"id": 53, "seek": 22224, "start": 239.64000000000001, "end": 242.92000000000002, "text": " that, but that doesn't work very well.", "tokens": [50364, 492, 500, 380, 362, 257, 636, 295, 22161, 439, 1944, 5267, 293, 550, 2710, 3319, 257, 7316, 50660, 50660, 670, 552, 570, 309, 311, 1090, 18795, 10957, 1901, 13, 50796, 50796, 2754, 498, 309, 645, 257, 2295, 18795, 10957, 1901, 11, 309, 576, 406, 312, 1944, 13, 50954, 50954, 492, 576, 362, 281, 5171, 300, 10957, 1901, 666, 27706, 41275, 293, 550, 360, 257, 2787, 41167, 670, 51234, 51234, 300, 11, 457, 300, 1177, 380, 589, 588, 731, 13, 51398, 51398, 467, 787, 1985, 294, 2295, 10139, 13, 51556, 51556, 407, 562, 321, 362, 257, 1090, 18795, 10957, 1901, 11, 321, 393, 360, 2787, 41167, 13, 51751, 51751], "temperature": 0.0, "avg_logprob": -0.1548212398182262, "compression_ratio": 1.9156118143459915, "no_speech_prob": 2.2119804270914756e-05}, {"id": 54, "seek": 22224, "start": 242.92000000000002, "end": 246.08, "text": " It only works in low dimension.", "tokens": [50364, 492, 500, 380, 362, 257, 636, 295, 22161, 439, 1944, 5267, 293, 550, 2710, 3319, 257, 7316, 50660, 50660, 670, 552, 570, 309, 311, 1090, 18795, 10957, 1901, 13, 50796, 50796, 2754, 498, 309, 645, 257, 2295, 18795, 10957, 1901, 11, 309, 576, 406, 312, 1944, 13, 50954, 50954, 492, 576, 362, 281, 5171, 300, 10957, 1901, 666, 27706, 41275, 293, 550, 360, 257, 2787, 41167, 670, 51234, 51234, 300, 11, 457, 300, 1177, 380, 589, 588, 731, 13, 51398, 51398, 467, 787, 1985, 294, 2295, 10139, 13, 51556, 51556, 407, 562, 321, 362, 257, 1090, 18795, 10957, 1901, 11, 321, 393, 360, 2787, 41167, 13, 51751, 51751], "temperature": 0.0, "avg_logprob": -0.1548212398182262, "compression_ratio": 1.9156118143459915, "no_speech_prob": 2.2119804270914756e-05}, {"id": 55, "seek": 22224, "start": 246.08, "end": 249.98000000000002, "text": " So when we have a high dimensional continuous space, we can do softmax.", "tokens": [50364, 492, 500, 380, 362, 257, 636, 295, 22161, 439, 1944, 5267, 293, 550, 2710, 3319, 257, 7316, 50660, 50660, 670, 552, 570, 309, 311, 1090, 18795, 10957, 1901, 13, 50796, 50796, 2754, 498, 309, 645, 257, 2295, 18795, 10957, 1901, 11, 309, 576, 406, 312, 1944, 13, 50954, 50954, 492, 576, 362, 281, 5171, 300, 10957, 1901, 666, 27706, 41275, 293, 550, 360, 257, 2787, 41167, 670, 51234, 51234, 300, 11, 457, 300, 1177, 380, 589, 588, 731, 13, 51398, 51398, 467, 787, 1985, 294, 2295, 10139, 13, 51556, 51556, 407, 562, 321, 362, 257, 1090, 18795, 10957, 1901, 11, 321, 393, 360, 2787, 41167, 13, 51751, 51751], "temperature": 0.0, "avg_logprob": -0.1548212398182262, "compression_ratio": 1.9156118143459915, "no_speech_prob": 2.2119804270914756e-05}, {"id": 56, "seek": 24998, "start": 249.98, "end": 253.28, "text": " We can't ask the system to give us a score for all possible outputs.", "tokens": [50364, 492, 393, 380, 1029, 264, 1185, 281, 976, 505, 257, 6175, 337, 439, 1944, 23930, 13, 50529, 50529, 13157, 11, 754, 498, 309, 311, 27706, 457, 7263, 13785, 11, 370, 721, 411, 321, 434, 10501, 2487, 13, 50831, 50831, 18643, 307, 10199, 2628, 293, 456, 307, 257, 588, 11, 588, 2416, 1230, 295, 1944, 15765, 670, 257, 51165, 51165, 2212, 4641, 293, 321, 393, 380, 445, 360, 257, 2787, 41167, 670, 439, 1944, 15765, 13, 51361, 51361, 10635, 1154, 13, 51411, 51411, 407, 577, 360, 321, 2906, 257, 7316, 420, 257, 3840, 295, 13444, 670, 439, 1944, 15765, 294, 51659, 51659, 257, 14679, 1254, 30, 51789, 51789], "temperature": 0.0, "avg_logprob": -0.13131733990590508, "compression_ratio": 1.69921875, "no_speech_prob": 1.4968062714615371e-05}, {"id": 57, "seek": 24998, "start": 253.28, "end": 259.32, "text": " Similarly, even if it's discrete but potentially infinite, so things like we're producing text.", "tokens": [50364, 492, 393, 380, 1029, 264, 1185, 281, 976, 505, 257, 6175, 337, 439, 1944, 23930, 13, 50529, 50529, 13157, 11, 754, 498, 309, 311, 27706, 457, 7263, 13785, 11, 370, 721, 411, 321, 434, 10501, 2487, 13, 50831, 50831, 18643, 307, 10199, 2628, 293, 456, 307, 257, 588, 11, 588, 2416, 1230, 295, 1944, 15765, 670, 257, 51165, 51165, 2212, 4641, 293, 321, 393, 380, 445, 360, 257, 2787, 41167, 670, 439, 1944, 15765, 13, 51361, 51361, 10635, 1154, 13, 51411, 51411, 407, 577, 360, 321, 2906, 257, 7316, 420, 257, 3840, 295, 13444, 670, 439, 1944, 15765, 294, 51659, 51659, 257, 14679, 1254, 30, 51789, 51789], "temperature": 0.0, "avg_logprob": -0.13131733990590508, "compression_ratio": 1.69921875, "no_speech_prob": 1.4968062714615371e-05}, {"id": 58, "seek": 24998, "start": 259.32, "end": 266.0, "text": " Text is compositional and there is a very, very large number of possible texts over a", "tokens": [50364, 492, 393, 380, 1029, 264, 1185, 281, 976, 505, 257, 6175, 337, 439, 1944, 23930, 13, 50529, 50529, 13157, 11, 754, 498, 309, 311, 27706, 457, 7263, 13785, 11, 370, 721, 411, 321, 434, 10501, 2487, 13, 50831, 50831, 18643, 307, 10199, 2628, 293, 456, 307, 257, 588, 11, 588, 2416, 1230, 295, 1944, 15765, 670, 257, 51165, 51165, 2212, 4641, 293, 321, 393, 380, 445, 360, 257, 2787, 41167, 670, 439, 1944, 15765, 13, 51361, 51361, 10635, 1154, 13, 51411, 51411, 407, 577, 360, 321, 2906, 257, 7316, 420, 257, 3840, 295, 13444, 670, 439, 1944, 15765, 294, 51659, 51659, 257, 14679, 1254, 30, 51789, 51789], "temperature": 0.0, "avg_logprob": -0.13131733990590508, "compression_ratio": 1.69921875, "no_speech_prob": 1.4968062714615371e-05}, {"id": 59, "seek": 24998, "start": 266.0, "end": 269.92, "text": " given length and we can't just do a softmax over all possible texts.", "tokens": [50364, 492, 393, 380, 1029, 264, 1185, 281, 976, 505, 257, 6175, 337, 439, 1944, 23930, 13, 50529, 50529, 13157, 11, 754, 498, 309, 311, 27706, 457, 7263, 13785, 11, 370, 721, 411, 321, 434, 10501, 2487, 13, 50831, 50831, 18643, 307, 10199, 2628, 293, 456, 307, 257, 588, 11, 588, 2416, 1230, 295, 1944, 15765, 670, 257, 51165, 51165, 2212, 4641, 293, 321, 393, 380, 445, 360, 257, 2787, 41167, 670, 439, 1944, 15765, 13, 51361, 51361, 10635, 1154, 13, 51411, 51411, 407, 577, 360, 321, 2906, 257, 7316, 420, 257, 3840, 295, 13444, 670, 439, 1944, 15765, 294, 51659, 51659, 257, 14679, 1254, 30, 51789, 51789], "temperature": 0.0, "avg_logprob": -0.13131733990590508, "compression_ratio": 1.69921875, "no_speech_prob": 1.4968062714615371e-05}, {"id": 60, "seek": 24998, "start": 269.92, "end": 270.92, "text": " Same problem.", "tokens": [50364, 492, 393, 380, 1029, 264, 1185, 281, 976, 505, 257, 6175, 337, 439, 1944, 23930, 13, 50529, 50529, 13157, 11, 754, 498, 309, 311, 27706, 457, 7263, 13785, 11, 370, 721, 411, 321, 434, 10501, 2487, 13, 50831, 50831, 18643, 307, 10199, 2628, 293, 456, 307, 257, 588, 11, 588, 2416, 1230, 295, 1944, 15765, 670, 257, 51165, 51165, 2212, 4641, 293, 321, 393, 380, 445, 360, 257, 2787, 41167, 670, 439, 1944, 15765, 13, 51361, 51361, 10635, 1154, 13, 51411, 51411, 407, 577, 360, 321, 2906, 257, 7316, 420, 257, 3840, 295, 13444, 670, 439, 1944, 15765, 294, 51659, 51659, 257, 14679, 1254, 30, 51789, 51789], "temperature": 0.0, "avg_logprob": -0.13131733990590508, "compression_ratio": 1.69921875, "no_speech_prob": 1.4968062714615371e-05}, {"id": 61, "seek": 24998, "start": 270.92, "end": 275.88, "text": " So how do we represent a distribution or a bunch of scores over all possible texts in", "tokens": [50364, 492, 393, 380, 1029, 264, 1185, 281, 976, 505, 257, 6175, 337, 439, 1944, 23930, 13, 50529, 50529, 13157, 11, 754, 498, 309, 311, 27706, 457, 7263, 13785, 11, 370, 721, 411, 321, 434, 10501, 2487, 13, 50831, 50831, 18643, 307, 10199, 2628, 293, 456, 307, 257, 588, 11, 588, 2416, 1230, 295, 1944, 15765, 670, 257, 51165, 51165, 2212, 4641, 293, 321, 393, 380, 445, 360, 257, 2787, 41167, 670, 439, 1944, 15765, 13, 51361, 51361, 10635, 1154, 13, 51411, 51411, 407, 577, 360, 321, 2906, 257, 7316, 420, 257, 3840, 295, 13444, 670, 439, 1944, 15765, 294, 51659, 51659, 257, 14679, 1254, 30, 51789, 51789], "temperature": 0.0, "avg_logprob": -0.13131733990590508, "compression_ratio": 1.69921875, "no_speech_prob": 1.4968062714615371e-05}, {"id": 62, "seek": 24998, "start": 275.88, "end": 278.48, "text": " a compact form?", "tokens": [50364, 492, 393, 380, 1029, 264, 1185, 281, 976, 505, 257, 6175, 337, 439, 1944, 23930, 13, 50529, 50529, 13157, 11, 754, 498, 309, 311, 27706, 457, 7263, 13785, 11, 370, 721, 411, 321, 434, 10501, 2487, 13, 50831, 50831, 18643, 307, 10199, 2628, 293, 456, 307, 257, 588, 11, 588, 2416, 1230, 295, 1944, 15765, 670, 257, 51165, 51165, 2212, 4641, 293, 321, 393, 380, 445, 360, 257, 2787, 41167, 670, 439, 1944, 15765, 13, 51361, 51361, 10635, 1154, 13, 51411, 51411, 407, 577, 360, 321, 2906, 257, 7316, 420, 257, 3840, 295, 13444, 670, 439, 1944, 15765, 294, 51659, 51659, 257, 14679, 1254, 30, 51789, 51789], "temperature": 0.0, "avg_logprob": -0.13131733990590508, "compression_ratio": 1.69921875, "no_speech_prob": 1.4968062714615371e-05}, {"id": 63, "seek": 27848, "start": 278.48, "end": 281.64000000000004, "text": " That's where energy-based models come in or probabilistic models, so that matter, but", "tokens": [50364, 663, 311, 689, 2281, 12, 6032, 5245, 808, 294, 420, 31959, 3142, 5245, 11, 370, 300, 1871, 11, 457, 50522, 50522, 2281, 12, 6032, 5245, 294, 1729, 13, 50654, 50654, 400, 264, 3827, 300, 2281, 12, 6032, 5245, 976, 505, 456, 307, 264, 1558, 300, 321, 434, 516, 50986, 50986, 281, 764, 364, 26947, 2445, 13, 51054, 51054, 682, 661, 2283, 11, 321, 434, 406, 516, 281, 1029, 527, 1185, 281, 5258, 257, 288, 13, 51297, 51297, 492, 434, 445, 516, 281, 1029, 309, 281, 980, 505, 1968, 364, 2031, 293, 257, 1729, 288, 321, 855, 309, 366, 18218, 51556, 51556, 365, 1184, 661, 13, 51614, 51614], "temperature": 0.0, "avg_logprob": -0.13646044424914439, "compression_ratio": 1.7725321888412018, "no_speech_prob": 3.6470046325121075e-05}, {"id": 64, "seek": 27848, "start": 281.64000000000004, "end": 284.28000000000003, "text": " energy-based models in particular.", "tokens": [50364, 663, 311, 689, 2281, 12, 6032, 5245, 808, 294, 420, 31959, 3142, 5245, 11, 370, 300, 1871, 11, 457, 50522, 50522, 2281, 12, 6032, 5245, 294, 1729, 13, 50654, 50654, 400, 264, 3827, 300, 2281, 12, 6032, 5245, 976, 505, 456, 307, 264, 1558, 300, 321, 434, 516, 50986, 50986, 281, 764, 364, 26947, 2445, 13, 51054, 51054, 682, 661, 2283, 11, 321, 434, 406, 516, 281, 1029, 527, 1185, 281, 5258, 257, 288, 13, 51297, 51297, 492, 434, 445, 516, 281, 1029, 309, 281, 980, 505, 1968, 364, 2031, 293, 257, 1729, 288, 321, 855, 309, 366, 18218, 51556, 51556, 365, 1184, 661, 13, 51614, 51614], "temperature": 0.0, "avg_logprob": -0.13646044424914439, "compression_ratio": 1.7725321888412018, "no_speech_prob": 3.6470046325121075e-05}, {"id": 65, "seek": 27848, "start": 284.28000000000003, "end": 290.92, "text": " And the solution that energy-based models give us there is the idea that we're going", "tokens": [50364, 663, 311, 689, 2281, 12, 6032, 5245, 808, 294, 420, 31959, 3142, 5245, 11, 370, 300, 1871, 11, 457, 50522, 50522, 2281, 12, 6032, 5245, 294, 1729, 13, 50654, 50654, 400, 264, 3827, 300, 2281, 12, 6032, 5245, 976, 505, 456, 307, 264, 1558, 300, 321, 434, 516, 50986, 50986, 281, 764, 364, 26947, 2445, 13, 51054, 51054, 682, 661, 2283, 11, 321, 434, 406, 516, 281, 1029, 527, 1185, 281, 5258, 257, 288, 13, 51297, 51297, 492, 434, 445, 516, 281, 1029, 309, 281, 980, 505, 1968, 364, 2031, 293, 257, 1729, 288, 321, 855, 309, 366, 18218, 51556, 51556, 365, 1184, 661, 13, 51614, 51614], "temperature": 0.0, "avg_logprob": -0.13646044424914439, "compression_ratio": 1.7725321888412018, "no_speech_prob": 3.6470046325121075e-05}, {"id": 66, "seek": 27848, "start": 290.92, "end": 292.28000000000003, "text": " to use an implicit function.", "tokens": [50364, 663, 311, 689, 2281, 12, 6032, 5245, 808, 294, 420, 31959, 3142, 5245, 11, 370, 300, 1871, 11, 457, 50522, 50522, 2281, 12, 6032, 5245, 294, 1729, 13, 50654, 50654, 400, 264, 3827, 300, 2281, 12, 6032, 5245, 976, 505, 456, 307, 264, 1558, 300, 321, 434, 516, 50986, 50986, 281, 764, 364, 26947, 2445, 13, 51054, 51054, 682, 661, 2283, 11, 321, 434, 406, 516, 281, 1029, 527, 1185, 281, 5258, 257, 288, 13, 51297, 51297, 492, 434, 445, 516, 281, 1029, 309, 281, 980, 505, 1968, 364, 2031, 293, 257, 1729, 288, 321, 855, 309, 366, 18218, 51556, 51556, 365, 1184, 661, 13, 51614, 51614], "temperature": 0.0, "avg_logprob": -0.13646044424914439, "compression_ratio": 1.7725321888412018, "no_speech_prob": 3.6470046325121075e-05}, {"id": 67, "seek": 27848, "start": 292.28000000000003, "end": 297.14000000000004, "text": " In other words, we're not going to ask our system to produce a y.", "tokens": [50364, 663, 311, 689, 2281, 12, 6032, 5245, 808, 294, 420, 31959, 3142, 5245, 11, 370, 300, 1871, 11, 457, 50522, 50522, 2281, 12, 6032, 5245, 294, 1729, 13, 50654, 50654, 400, 264, 3827, 300, 2281, 12, 6032, 5245, 976, 505, 456, 307, 264, 1558, 300, 321, 434, 516, 50986, 50986, 281, 764, 364, 26947, 2445, 13, 51054, 51054, 682, 661, 2283, 11, 321, 434, 406, 516, 281, 1029, 527, 1185, 281, 5258, 257, 288, 13, 51297, 51297, 492, 434, 445, 516, 281, 1029, 309, 281, 980, 505, 1968, 364, 2031, 293, 257, 1729, 288, 321, 855, 309, 366, 18218, 51556, 51556, 365, 1184, 661, 13, 51614, 51614], "temperature": 0.0, "avg_logprob": -0.13646044424914439, "compression_ratio": 1.7725321888412018, "no_speech_prob": 3.6470046325121075e-05}, {"id": 68, "seek": 27848, "start": 297.14000000000004, "end": 302.32, "text": " We're just going to ask it to tell us whether an x and a particular y we show it are compatible", "tokens": [50364, 663, 311, 689, 2281, 12, 6032, 5245, 808, 294, 420, 31959, 3142, 5245, 11, 370, 300, 1871, 11, 457, 50522, 50522, 2281, 12, 6032, 5245, 294, 1729, 13, 50654, 50654, 400, 264, 3827, 300, 2281, 12, 6032, 5245, 976, 505, 456, 307, 264, 1558, 300, 321, 434, 516, 50986, 50986, 281, 764, 364, 26947, 2445, 13, 51054, 51054, 682, 661, 2283, 11, 321, 434, 406, 516, 281, 1029, 527, 1185, 281, 5258, 257, 288, 13, 51297, 51297, 492, 434, 445, 516, 281, 1029, 309, 281, 980, 505, 1968, 364, 2031, 293, 257, 1729, 288, 321, 855, 309, 366, 18218, 51556, 51556, 365, 1184, 661, 13, 51614, 51614], "temperature": 0.0, "avg_logprob": -0.13646044424914439, "compression_ratio": 1.7725321888412018, "no_speech_prob": 3.6470046325121075e-05}, {"id": 69, "seek": 27848, "start": 302.32, "end": 303.48, "text": " with each other.", "tokens": [50364, 663, 311, 689, 2281, 12, 6032, 5245, 808, 294, 420, 31959, 3142, 5245, 11, 370, 300, 1871, 11, 457, 50522, 50522, 2281, 12, 6032, 5245, 294, 1729, 13, 50654, 50654, 400, 264, 3827, 300, 2281, 12, 6032, 5245, 976, 505, 456, 307, 264, 1558, 300, 321, 434, 516, 50986, 50986, 281, 764, 364, 26947, 2445, 13, 51054, 51054, 682, 661, 2283, 11, 321, 434, 406, 516, 281, 1029, 527, 1185, 281, 5258, 257, 288, 13, 51297, 51297, 492, 434, 445, 516, 281, 1029, 309, 281, 980, 505, 1968, 364, 2031, 293, 257, 1729, 288, 321, 855, 309, 366, 18218, 51556, 51556, 365, 1184, 661, 13, 51614, 51614], "temperature": 0.0, "avg_logprob": -0.13646044424914439, "compression_ratio": 1.7725321888412018, "no_speech_prob": 3.6470046325121075e-05}, {"id": 70, "seek": 30348, "start": 303.48, "end": 308.88, "text": " So is this text a good translation of that text?", "tokens": [50364, 407, 307, 341, 2487, 257, 665, 12853, 295, 300, 2487, 30, 50634, 50634, 663, 3263, 733, 295, 5336, 11, 558, 30, 50706, 50706, 1436, 577, 366, 321, 516, 281, 808, 493, 365, 300, 2487, 300, 527, 3479, 307, 15763, 30, 51018, 51018, 583, 718, 311, 1797, 341, 337, 257, 857, 13, 51318, 51318, 407, 321, 434, 516, 281, 764, 341, 2445, 283, 295, 2031, 11, 288, 13, 51476, 51476, 467, 311, 516, 281, 747, 364, 2031, 293, 257, 288, 293, 309, 311, 516, 281, 980, 505, 498, 729, 732, 4190, 366, 18218, 51718, 51718, 365, 1184, 661, 420, 406, 13, 51839, 51839], "temperature": 0.0, "avg_logprob": -0.1593021796299861, "compression_ratio": 1.6574074074074074, "no_speech_prob": 2.6680609153117985e-05}, {"id": 71, "seek": 30348, "start": 308.88, "end": 310.32, "text": " That sounds kind of weak, right?", "tokens": [50364, 407, 307, 341, 2487, 257, 665, 12853, 295, 300, 2487, 30, 50634, 50634, 663, 3263, 733, 295, 5336, 11, 558, 30, 50706, 50706, 1436, 577, 366, 321, 516, 281, 808, 493, 365, 300, 2487, 300, 527, 3479, 307, 15763, 30, 51018, 51018, 583, 718, 311, 1797, 341, 337, 257, 857, 13, 51318, 51318, 407, 321, 434, 516, 281, 764, 341, 2445, 283, 295, 2031, 11, 288, 13, 51476, 51476, 467, 311, 516, 281, 747, 364, 2031, 293, 257, 288, 293, 309, 311, 516, 281, 980, 505, 498, 729, 732, 4190, 366, 18218, 51718, 51718, 365, 1184, 661, 420, 406, 13, 51839, 51839], "temperature": 0.0, "avg_logprob": -0.1593021796299861, "compression_ratio": 1.6574074074074074, "no_speech_prob": 2.6680609153117985e-05}, {"id": 72, "seek": 30348, "start": 310.32, "end": 316.56, "text": " Because how are we going to come up with that text that our machine is comparing?", "tokens": [50364, 407, 307, 341, 2487, 257, 665, 12853, 295, 300, 2487, 30, 50634, 50634, 663, 3263, 733, 295, 5336, 11, 558, 30, 50706, 50706, 1436, 577, 366, 321, 516, 281, 808, 493, 365, 300, 2487, 300, 527, 3479, 307, 15763, 30, 51018, 51018, 583, 718, 311, 1797, 341, 337, 257, 857, 13, 51318, 51318, 407, 321, 434, 516, 281, 764, 341, 2445, 283, 295, 2031, 11, 288, 13, 51476, 51476, 467, 311, 516, 281, 747, 364, 2031, 293, 257, 288, 293, 309, 311, 516, 281, 980, 505, 498, 729, 732, 4190, 366, 18218, 51718, 51718, 365, 1184, 661, 420, 406, 13, 51839, 51839], "temperature": 0.0, "avg_logprob": -0.1593021796299861, "compression_ratio": 1.6574074074074074, "no_speech_prob": 2.6680609153117985e-05}, {"id": 73, "seek": 30348, "start": 316.56, "end": 322.56, "text": " But let's hold this for a bit.", "tokens": [50364, 407, 307, 341, 2487, 257, 665, 12853, 295, 300, 2487, 30, 50634, 50634, 663, 3263, 733, 295, 5336, 11, 558, 30, 50706, 50706, 1436, 577, 366, 321, 516, 281, 808, 493, 365, 300, 2487, 300, 527, 3479, 307, 15763, 30, 51018, 51018, 583, 718, 311, 1797, 341, 337, 257, 857, 13, 51318, 51318, 407, 321, 434, 516, 281, 764, 341, 2445, 283, 295, 2031, 11, 288, 13, 51476, 51476, 467, 311, 516, 281, 747, 364, 2031, 293, 257, 288, 293, 309, 311, 516, 281, 980, 505, 498, 729, 732, 4190, 366, 18218, 51718, 51718, 365, 1184, 661, 420, 406, 13, 51839, 51839], "temperature": 0.0, "avg_logprob": -0.1593021796299861, "compression_ratio": 1.6574074074074074, "no_speech_prob": 2.6680609153117985e-05}, {"id": 74, "seek": 30348, "start": 322.56, "end": 325.72, "text": " So we're going to use this function f of x, y.", "tokens": [50364, 407, 307, 341, 2487, 257, 665, 12853, 295, 300, 2487, 30, 50634, 50634, 663, 3263, 733, 295, 5336, 11, 558, 30, 50706, 50706, 1436, 577, 366, 321, 516, 281, 808, 493, 365, 300, 2487, 300, 527, 3479, 307, 15763, 30, 51018, 51018, 583, 718, 311, 1797, 341, 337, 257, 857, 13, 51318, 51318, 407, 321, 434, 516, 281, 764, 341, 2445, 283, 295, 2031, 11, 288, 13, 51476, 51476, 467, 311, 516, 281, 747, 364, 2031, 293, 257, 288, 293, 309, 311, 516, 281, 980, 505, 498, 729, 732, 4190, 366, 18218, 51718, 51718, 365, 1184, 661, 420, 406, 13, 51839, 51839], "temperature": 0.0, "avg_logprob": -0.1593021796299861, "compression_ratio": 1.6574074074074074, "no_speech_prob": 2.6680609153117985e-05}, {"id": 75, "seek": 30348, "start": 325.72, "end": 330.56, "text": " It's going to take an x and a y and it's going to tell us if those two values are compatible", "tokens": [50364, 407, 307, 341, 2487, 257, 665, 12853, 295, 300, 2487, 30, 50634, 50634, 663, 3263, 733, 295, 5336, 11, 558, 30, 50706, 50706, 1436, 577, 366, 321, 516, 281, 808, 493, 365, 300, 2487, 300, 527, 3479, 307, 15763, 30, 51018, 51018, 583, 718, 311, 1797, 341, 337, 257, 857, 13, 51318, 51318, 407, 321, 434, 516, 281, 764, 341, 2445, 283, 295, 2031, 11, 288, 13, 51476, 51476, 467, 311, 516, 281, 747, 364, 2031, 293, 257, 288, 293, 309, 311, 516, 281, 980, 505, 498, 729, 732, 4190, 366, 18218, 51718, 51718, 365, 1184, 661, 420, 406, 13, 51839, 51839], "temperature": 0.0, "avg_logprob": -0.1593021796299861, "compression_ratio": 1.6574074074074074, "no_speech_prob": 2.6680609153117985e-05}, {"id": 76, "seek": 30348, "start": 330.56, "end": 332.98, "text": " with each other or not.", "tokens": [50364, 407, 307, 341, 2487, 257, 665, 12853, 295, 300, 2487, 30, 50634, 50634, 663, 3263, 733, 295, 5336, 11, 558, 30, 50706, 50706, 1436, 577, 366, 321, 516, 281, 808, 493, 365, 300, 2487, 300, 527, 3479, 307, 15763, 30, 51018, 51018, 583, 718, 311, 1797, 341, 337, 257, 857, 13, 51318, 51318, 407, 321, 434, 516, 281, 764, 341, 2445, 283, 295, 2031, 11, 288, 13, 51476, 51476, 467, 311, 516, 281, 747, 364, 2031, 293, 257, 288, 293, 309, 311, 516, 281, 980, 505, 498, 729, 732, 4190, 366, 18218, 51718, 51718, 365, 1184, 661, 420, 406, 13, 51839, 51839], "temperature": 0.0, "avg_logprob": -0.1593021796299861, "compression_ratio": 1.6574074074074074, "no_speech_prob": 2.6680609153117985e-05}, {"id": 77, "seek": 33298, "start": 332.98, "end": 336.08000000000004, "text": " So is y a good label for the image x?", "tokens": [50364, 407, 307, 288, 257, 665, 7645, 337, 264, 3256, 2031, 30, 50519, 50519, 1119, 288, 257, 665, 1090, 8669, 3037, 295, 341, 2295, 8669, 3256, 30, 50838, 50838, 759, 288, 257, 665, 12853, 295, 300, 8174, 294, 6521, 11, 5183, 13, 51333, 51333, 400, 370, 264, 38253, 10747, 586, 307, 516, 281, 312, 2212, 364, 2031, 11, 915, 257, 288, 300, 14725, 257, 51583, 51583, 2295, 2158, 337, 597, 283, 295, 2031, 11, 288, 14725, 257, 2295, 2158, 13, 51751, 51751], "temperature": 0.0, "avg_logprob": -0.11647114121770284, "compression_ratio": 1.6611111111111112, "no_speech_prob": 7.070014362398069e-06}, {"id": 78, "seek": 33298, "start": 336.08000000000004, "end": 342.46000000000004, "text": " Is y a good high resolution version of this low resolution image?", "tokens": [50364, 407, 307, 288, 257, 665, 7645, 337, 264, 3256, 2031, 30, 50519, 50519, 1119, 288, 257, 665, 1090, 8669, 3037, 295, 341, 2295, 8669, 3256, 30, 50838, 50838, 759, 288, 257, 665, 12853, 295, 300, 8174, 294, 6521, 11, 5183, 13, 51333, 51333, 400, 370, 264, 38253, 10747, 586, 307, 516, 281, 312, 2212, 364, 2031, 11, 915, 257, 288, 300, 14725, 257, 51583, 51583, 2295, 2158, 337, 597, 283, 295, 2031, 11, 288, 14725, 257, 2295, 2158, 13, 51751, 51751], "temperature": 0.0, "avg_logprob": -0.11647114121770284, "compression_ratio": 1.6611111111111112, "no_speech_prob": 7.070014362398069e-06}, {"id": 79, "seek": 33298, "start": 342.46000000000004, "end": 352.36, "text": " If y a good translation of that sentence in German, etc.", "tokens": [50364, 407, 307, 288, 257, 665, 7645, 337, 264, 3256, 2031, 30, 50519, 50519, 1119, 288, 257, 665, 1090, 8669, 3037, 295, 341, 2295, 8669, 3256, 30, 50838, 50838, 759, 288, 257, 665, 12853, 295, 300, 8174, 294, 6521, 11, 5183, 13, 51333, 51333, 400, 370, 264, 38253, 10747, 586, 307, 516, 281, 312, 2212, 364, 2031, 11, 915, 257, 288, 300, 14725, 257, 51583, 51583, 2295, 2158, 337, 597, 283, 295, 2031, 11, 288, 14725, 257, 2295, 2158, 13, 51751, 51751], "temperature": 0.0, "avg_logprob": -0.11647114121770284, "compression_ratio": 1.6611111111111112, "no_speech_prob": 7.070014362398069e-06}, {"id": 80, "seek": 33298, "start": 352.36, "end": 357.36, "text": " And so the inference procedure now is going to be given an x, find a y that produces a", "tokens": [50364, 407, 307, 288, 257, 665, 7645, 337, 264, 3256, 2031, 30, 50519, 50519, 1119, 288, 257, 665, 1090, 8669, 3037, 295, 341, 2295, 8669, 3256, 30, 50838, 50838, 759, 288, 257, 665, 12853, 295, 300, 8174, 294, 6521, 11, 5183, 13, 51333, 51333, 400, 370, 264, 38253, 10747, 586, 307, 516, 281, 312, 2212, 364, 2031, 11, 915, 257, 288, 300, 14725, 257, 51583, 51583, 2295, 2158, 337, 597, 283, 295, 2031, 11, 288, 14725, 257, 2295, 2158, 13, 51751, 51751], "temperature": 0.0, "avg_logprob": -0.11647114121770284, "compression_ratio": 1.6611111111111112, "no_speech_prob": 7.070014362398069e-06}, {"id": 81, "seek": 33298, "start": 357.36, "end": 360.72, "text": " low value for which f of x, y produces a low value.", "tokens": [50364, 407, 307, 288, 257, 665, 7645, 337, 264, 3256, 2031, 30, 50519, 50519, 1119, 288, 257, 665, 1090, 8669, 3037, 295, 341, 2295, 8669, 3256, 30, 50838, 50838, 759, 288, 257, 665, 12853, 295, 300, 8174, 294, 6521, 11, 5183, 13, 51333, 51333, 400, 370, 264, 38253, 10747, 586, 307, 516, 281, 312, 2212, 364, 2031, 11, 915, 257, 288, 300, 14725, 257, 51583, 51583, 2295, 2158, 337, 597, 283, 295, 2031, 11, 288, 14725, 257, 2295, 2158, 13, 51751, 51751], "temperature": 0.0, "avg_logprob": -0.11647114121770284, "compression_ratio": 1.6611111111111112, "no_speech_prob": 7.070014362398069e-06}, {"id": 82, "seek": 36072, "start": 360.72, "end": 364.0, "text": " In other words, find a y that's compatible with x.", "tokens": [50364, 682, 661, 2283, 11, 915, 257, 288, 300, 311, 18218, 365, 2031, 13, 50528, 50528, 407, 3164, 670, 1944, 288, 311, 337, 257, 2158, 295, 288, 300, 14725, 257, 2295, 2158, 337, 283, 295, 2031, 11, 288, 13, 50998, 50998, 407, 341, 307, 264, 1558, 295, 38253, 538, 46608, 512, 2445, 13, 51212, 51212, 400, 1238, 709, 633, 2316, 31959, 3142, 11, 2107, 12, 41990, 5177, 3142, 11, 2035, 300, 561, 362, 51440, 51440, 1194, 466, 11, 393, 589, 341, 636, 13, 51550, 51550], "temperature": 0.0, "avg_logprob": -0.182637236839117, "compression_ratio": 1.5384615384615385, "no_speech_prob": 1.3418410162557848e-05}, {"id": 83, "seek": 36072, "start": 364.0, "end": 373.40000000000003, "text": " So search over possible y's for a value of y that produces a low value for f of x, y.", "tokens": [50364, 682, 661, 2283, 11, 915, 257, 288, 300, 311, 18218, 365, 2031, 13, 50528, 50528, 407, 3164, 670, 1944, 288, 311, 337, 257, 2158, 295, 288, 300, 14725, 257, 2295, 2158, 337, 283, 295, 2031, 11, 288, 13, 50998, 50998, 407, 341, 307, 264, 1558, 295, 38253, 538, 46608, 512, 2445, 13, 51212, 51212, 400, 1238, 709, 633, 2316, 31959, 3142, 11, 2107, 12, 41990, 5177, 3142, 11, 2035, 300, 561, 362, 51440, 51440, 1194, 466, 11, 393, 589, 341, 636, 13, 51550, 51550], "temperature": 0.0, "avg_logprob": -0.182637236839117, "compression_ratio": 1.5384615384615385, "no_speech_prob": 1.3418410162557848e-05}, {"id": 84, "seek": 36072, "start": 373.40000000000003, "end": 377.68, "text": " So this is the idea of inference by minimizing some function.", "tokens": [50364, 682, 661, 2283, 11, 915, 257, 288, 300, 311, 18218, 365, 2031, 13, 50528, 50528, 407, 3164, 670, 1944, 288, 311, 337, 257, 2158, 295, 288, 300, 14725, 257, 2295, 2158, 337, 283, 295, 2031, 11, 288, 13, 50998, 50998, 407, 341, 307, 264, 1558, 295, 38253, 538, 46608, 512, 2445, 13, 51212, 51212, 400, 1238, 709, 633, 2316, 31959, 3142, 11, 2107, 12, 41990, 5177, 3142, 11, 2035, 300, 561, 362, 51440, 51440, 1194, 466, 11, 393, 589, 341, 636, 13, 51550, 51550], "temperature": 0.0, "avg_logprob": -0.182637236839117, "compression_ratio": 1.5384615384615385, "no_speech_prob": 1.3418410162557848e-05}, {"id": 85, "seek": 36072, "start": 377.68, "end": 382.24, "text": " And pretty much every model probabilistic, non-probabilistic, whatever that people have", "tokens": [50364, 682, 661, 2283, 11, 915, 257, 288, 300, 311, 18218, 365, 2031, 13, 50528, 50528, 407, 3164, 670, 1944, 288, 311, 337, 257, 2158, 295, 288, 300, 14725, 257, 2295, 2158, 337, 283, 295, 2031, 11, 288, 13, 50998, 50998, 407, 341, 307, 264, 1558, 295, 38253, 538, 46608, 512, 2445, 13, 51212, 51212, 400, 1238, 709, 633, 2316, 31959, 3142, 11, 2107, 12, 41990, 5177, 3142, 11, 2035, 300, 561, 362, 51440, 51440, 1194, 466, 11, 393, 589, 341, 636, 13, 51550, 51550], "temperature": 0.0, "avg_logprob": -0.182637236839117, "compression_ratio": 1.5384615384615385, "no_speech_prob": 1.3418410162557848e-05}, {"id": 86, "seek": 36072, "start": 382.24, "end": 384.44000000000005, "text": " thought about, can work this way.", "tokens": [50364, 682, 661, 2283, 11, 915, 257, 288, 300, 311, 18218, 365, 2031, 13, 50528, 50528, 407, 3164, 670, 1944, 288, 311, 337, 257, 2158, 295, 288, 300, 14725, 257, 2295, 2158, 337, 283, 295, 2031, 11, 288, 13, 50998, 50998, 407, 341, 307, 264, 1558, 295, 38253, 538, 46608, 512, 2445, 13, 51212, 51212, 400, 1238, 709, 633, 2316, 31959, 3142, 11, 2107, 12, 41990, 5177, 3142, 11, 2035, 300, 561, 362, 51440, 51440, 1194, 466, 11, 393, 589, 341, 636, 13, 51550, 51550], "temperature": 0.0, "avg_logprob": -0.182637236839117, "compression_ratio": 1.5384615384615385, "no_speech_prob": 1.3418410162557848e-05}, {"id": 87, "seek": 38444, "start": 384.44, "end": 390.84, "text": " I mean except even classification, multi-class classification with neural nets or whatever,", "tokens": [50364, 286, 914, 3993, 754, 21538, 11, 4825, 12, 11665, 21538, 365, 18161, 36170, 420, 2035, 11, 50684, 50684, 26947, 356, 589, 538, 2281, 4464, 2144, 538, 1936, 5006, 264, 1508, 300, 575, 264, 1151, 51034, 51034, 6175, 597, 291, 393, 519, 295, 382, 264, 12437, 2281, 13, 51406, 51406, 407, 1936, 321, 434, 516, 281, 853, 281, 915, 364, 5598, 300, 44271, 257, 3840, 295, 18491, 51634, 51634], "temperature": 0.0, "avg_logprob": -0.1714033944266183, "compression_ratio": 1.606060606060606, "no_speech_prob": 1.2217808034620248e-05}, {"id": 88, "seek": 38444, "start": 390.84, "end": 397.84, "text": " implicitly work by energy minimization by basically finding the class that has the best", "tokens": [50364, 286, 914, 3993, 754, 21538, 11, 4825, 12, 11665, 21538, 365, 18161, 36170, 420, 2035, 11, 50684, 50684, 26947, 356, 589, 538, 2281, 4464, 2144, 538, 1936, 5006, 264, 1508, 300, 575, 264, 1151, 51034, 51034, 6175, 597, 291, 393, 519, 295, 382, 264, 12437, 2281, 13, 51406, 51406, 407, 1936, 321, 434, 516, 281, 853, 281, 915, 364, 5598, 300, 44271, 257, 3840, 295, 18491, 51634, 51634], "temperature": 0.0, "avg_logprob": -0.1714033944266183, "compression_ratio": 1.606060606060606, "no_speech_prob": 1.2217808034620248e-05}, {"id": 89, "seek": 38444, "start": 397.84, "end": 405.28, "text": " score which you can think of as the lowest energy.", "tokens": [50364, 286, 914, 3993, 754, 21538, 11, 4825, 12, 11665, 21538, 365, 18161, 36170, 420, 2035, 11, 50684, 50684, 26947, 356, 589, 538, 2281, 4464, 2144, 538, 1936, 5006, 264, 1508, 300, 575, 264, 1151, 51034, 51034, 6175, 597, 291, 393, 519, 295, 382, 264, 12437, 2281, 13, 51406, 51406, 407, 1936, 321, 434, 516, 281, 853, 281, 915, 364, 5598, 300, 44271, 257, 3840, 295, 18491, 51634, 51634], "temperature": 0.0, "avg_logprob": -0.1714033944266183, "compression_ratio": 1.606060606060606, "no_speech_prob": 1.2217808034620248e-05}, {"id": 90, "seek": 38444, "start": 405.28, "end": 409.84, "text": " So basically we're going to try to find an output that satisfies a bunch of constraints", "tokens": [50364, 286, 914, 3993, 754, 21538, 11, 4825, 12, 11665, 21538, 365, 18161, 36170, 420, 2035, 11, 50684, 50684, 26947, 356, 589, 538, 2281, 4464, 2144, 538, 1936, 5006, 264, 1508, 300, 575, 264, 1151, 51034, 51034, 6175, 597, 291, 393, 519, 295, 382, 264, 12437, 2281, 13, 51406, 51406, 407, 1936, 321, 434, 516, 281, 853, 281, 915, 364, 5598, 300, 44271, 257, 3840, 295, 18491, 51634, 51634], "temperature": 0.0, "avg_logprob": -0.1714033944266183, "compression_ratio": 1.606060606060606, "no_speech_prob": 1.2217808034620248e-05}, {"id": 91, "seek": 40984, "start": 409.84, "end": 414.76, "text": " and those constraints are implemented by this function f of x, y.", "tokens": [50364, 293, 729, 18491, 366, 12270, 538, 341, 2445, 283, 295, 2031, 11, 288, 13, 50610, 50610, 400, 498, 291, 600, 2198, 295, 35942, 5245, 11, 4562, 9590, 11, 439, 300, 1507, 11, 420, 754, 13735, 50872, 50872, 7318, 420, 31536, 2740, 11, 436, 1936, 393, 439, 312, 48936, 294, 729, 2115, 382, 5006, 264, 51222, 51222, 2158, 295, 257, 992, 295, 9102, 300, 486, 17522, 512, 2445, 300, 8000, 641, 34237, 13, 51626, 51626, 407, 321, 434, 406, 1417, 466, 2539, 558, 586, 13, 51730, 51730, 492, 434, 445, 1417, 466, 38253, 13, 51840, 51840], "temperature": 0.0, "avg_logprob": -0.15146636962890625, "compression_ratio": 1.593984962406015, "no_speech_prob": 1.9830786186503246e-05}, {"id": 92, "seek": 40984, "start": 414.76, "end": 420.0, "text": " And if you've heard of graphical models, digital networks, all that stuff, or even classical", "tokens": [50364, 293, 729, 18491, 366, 12270, 538, 341, 2445, 283, 295, 2031, 11, 288, 13, 50610, 50610, 400, 498, 291, 600, 2198, 295, 35942, 5245, 11, 4562, 9590, 11, 439, 300, 1507, 11, 420, 754, 13735, 50872, 50872, 7318, 420, 31536, 2740, 11, 436, 1936, 393, 439, 312, 48936, 294, 729, 2115, 382, 5006, 264, 51222, 51222, 2158, 295, 257, 992, 295, 9102, 300, 486, 17522, 512, 2445, 300, 8000, 641, 34237, 13, 51626, 51626, 407, 321, 434, 406, 1417, 466, 2539, 558, 586, 13, 51730, 51730, 492, 434, 445, 1417, 466, 38253, 13, 51840, 51840], "temperature": 0.0, "avg_logprob": -0.15146636962890625, "compression_ratio": 1.593984962406015, "no_speech_prob": 1.9830786186503246e-05}, {"id": 93, "seek": 40984, "start": 420.0, "end": 427.0, "text": " AI or SAT problems, they basically can all be formulated in those terms as finding the", "tokens": [50364, 293, 729, 18491, 366, 12270, 538, 341, 2445, 283, 295, 2031, 11, 288, 13, 50610, 50610, 400, 498, 291, 600, 2198, 295, 35942, 5245, 11, 4562, 9590, 11, 439, 300, 1507, 11, 420, 754, 13735, 50872, 50872, 7318, 420, 31536, 2740, 11, 436, 1936, 393, 439, 312, 48936, 294, 729, 2115, 382, 5006, 264, 51222, 51222, 2158, 295, 257, 992, 295, 9102, 300, 486, 17522, 512, 2445, 300, 8000, 641, 34237, 13, 51626, 51626, 407, 321, 434, 406, 1417, 466, 2539, 558, 586, 13, 51730, 51730, 492, 434, 445, 1417, 466, 38253, 13, 51840, 51840], "temperature": 0.0, "avg_logprob": -0.15146636962890625, "compression_ratio": 1.593984962406015, "no_speech_prob": 1.9830786186503246e-05}, {"id": 94, "seek": 40984, "start": 427.0, "end": 435.08, "text": " value of a set of variables that will minimize some function that measures their compatibility.", "tokens": [50364, 293, 729, 18491, 366, 12270, 538, 341, 2445, 283, 295, 2031, 11, 288, 13, 50610, 50610, 400, 498, 291, 600, 2198, 295, 35942, 5245, 11, 4562, 9590, 11, 439, 300, 1507, 11, 420, 754, 13735, 50872, 50872, 7318, 420, 31536, 2740, 11, 436, 1936, 393, 439, 312, 48936, 294, 729, 2115, 382, 5006, 264, 51222, 51222, 2158, 295, 257, 992, 295, 9102, 300, 486, 17522, 512, 2445, 300, 8000, 641, 34237, 13, 51626, 51626, 407, 321, 434, 406, 1417, 466, 2539, 558, 586, 13, 51730, 51730, 492, 434, 445, 1417, 466, 38253, 13, 51840, 51840], "temperature": 0.0, "avg_logprob": -0.15146636962890625, "compression_ratio": 1.593984962406015, "no_speech_prob": 1.9830786186503246e-05}, {"id": 95, "seek": 40984, "start": 435.08, "end": 437.15999999999997, "text": " So we're not talking about learning right now.", "tokens": [50364, 293, 729, 18491, 366, 12270, 538, 341, 2445, 283, 295, 2031, 11, 288, 13, 50610, 50610, 400, 498, 291, 600, 2198, 295, 35942, 5245, 11, 4562, 9590, 11, 439, 300, 1507, 11, 420, 754, 13735, 50872, 50872, 7318, 420, 31536, 2740, 11, 436, 1936, 393, 439, 312, 48936, 294, 729, 2115, 382, 5006, 264, 51222, 51222, 2158, 295, 257, 992, 295, 9102, 300, 486, 17522, 512, 2445, 300, 8000, 641, 34237, 13, 51626, 51626, 407, 321, 434, 406, 1417, 466, 2539, 558, 586, 13, 51730, 51730, 492, 434, 445, 1417, 466, 38253, 13, 51840, 51840], "temperature": 0.0, "avg_logprob": -0.15146636962890625, "compression_ratio": 1.593984962406015, "no_speech_prob": 1.9830786186503246e-05}, {"id": 96, "seek": 40984, "start": 437.15999999999997, "end": 439.35999999999996, "text": " We're just talking about inference.", "tokens": [50364, 293, 729, 18491, 366, 12270, 538, 341, 2445, 283, 295, 2031, 11, 288, 13, 50610, 50610, 400, 498, 291, 600, 2198, 295, 35942, 5245, 11, 4562, 9590, 11, 439, 300, 1507, 11, 420, 754, 13735, 50872, 50872, 7318, 420, 31536, 2740, 11, 436, 1936, 393, 439, 312, 48936, 294, 729, 2115, 382, 5006, 264, 51222, 51222, 2158, 295, 257, 992, 295, 9102, 300, 486, 17522, 512, 2445, 300, 8000, 641, 34237, 13, 51626, 51626, 407, 321, 434, 406, 1417, 466, 2539, 558, 586, 13, 51730, 51730, 492, 434, 445, 1417, 466, 38253, 13, 51840, 51840], "temperature": 0.0, "avg_logprob": -0.15146636962890625, "compression_ratio": 1.593984962406015, "no_speech_prob": 1.9830786186503246e-05}, {"id": 97, "seek": 43936, "start": 439.36, "end": 441.76, "text": " We're assuming this function f of x, y is given to you.", "tokens": [50364, 492, 434, 11926, 341, 2445, 283, 295, 2031, 11, 288, 307, 2212, 281, 291, 13, 50484, 50484, 492, 434, 516, 281, 751, 466, 577, 321, 1466, 309, 257, 707, 1780, 13, 50768, 50768, 1033, 370, 264, 2281, 2445, 307, 406, 437, 321, 17522, 1830, 2539, 13, 50956, 50956, 467, 311, 437, 321, 17522, 1830, 38253, 13, 51098, 51098, 407, 38253, 307, 15866, 288, 490, 2031, 13, 51368, 51368, 407, 341, 2281, 2445, 307, 39684, 22608, 13, 51506, 51506, 467, 2516, 2295, 4190, 562, 288, 307, 18218, 365, 2031, 293, 2946, 4190, 562, 288, 307, 406, 18218, 51738, 51738, 365, 2031, 13, 51804, 51804], "temperature": 0.0, "avg_logprob": -0.14680879683721634, "compression_ratio": 1.8472222222222223, "no_speech_prob": 1.834158319979906e-05}, {"id": 98, "seek": 43936, "start": 441.76, "end": 447.44, "text": " We're going to talk about how we learn it a little later.", "tokens": [50364, 492, 434, 11926, 341, 2445, 283, 295, 2031, 11, 288, 307, 2212, 281, 291, 13, 50484, 50484, 492, 434, 516, 281, 751, 466, 577, 321, 1466, 309, 257, 707, 1780, 13, 50768, 50768, 1033, 370, 264, 2281, 2445, 307, 406, 437, 321, 17522, 1830, 2539, 13, 50956, 50956, 467, 311, 437, 321, 17522, 1830, 38253, 13, 51098, 51098, 407, 38253, 307, 15866, 288, 490, 2031, 13, 51368, 51368, 407, 341, 2281, 2445, 307, 39684, 22608, 13, 51506, 51506, 467, 2516, 2295, 4190, 562, 288, 307, 18218, 365, 2031, 293, 2946, 4190, 562, 288, 307, 406, 18218, 51738, 51738, 365, 2031, 13, 51804, 51804], "temperature": 0.0, "avg_logprob": -0.14680879683721634, "compression_ratio": 1.8472222222222223, "no_speech_prob": 1.834158319979906e-05}, {"id": 99, "seek": 43936, "start": 447.44, "end": 451.2, "text": " Okay so the energy function is not what we minimize during learning.", "tokens": [50364, 492, 434, 11926, 341, 2445, 283, 295, 2031, 11, 288, 307, 2212, 281, 291, 13, 50484, 50484, 492, 434, 516, 281, 751, 466, 577, 321, 1466, 309, 257, 707, 1780, 13, 50768, 50768, 1033, 370, 264, 2281, 2445, 307, 406, 437, 321, 17522, 1830, 2539, 13, 50956, 50956, 467, 311, 437, 321, 17522, 1830, 38253, 13, 51098, 51098, 407, 38253, 307, 15866, 288, 490, 2031, 13, 51368, 51368, 407, 341, 2281, 2445, 307, 39684, 22608, 13, 51506, 51506, 467, 2516, 2295, 4190, 562, 288, 307, 18218, 365, 2031, 293, 2946, 4190, 562, 288, 307, 406, 18218, 51738, 51738, 365, 2031, 13, 51804, 51804], "temperature": 0.0, "avg_logprob": -0.14680879683721634, "compression_ratio": 1.8472222222222223, "no_speech_prob": 1.834158319979906e-05}, {"id": 100, "seek": 43936, "start": 451.2, "end": 454.04, "text": " It's what we minimize during inference.", "tokens": [50364, 492, 434, 11926, 341, 2445, 283, 295, 2031, 11, 288, 307, 2212, 281, 291, 13, 50484, 50484, 492, 434, 516, 281, 751, 466, 577, 321, 1466, 309, 257, 707, 1780, 13, 50768, 50768, 1033, 370, 264, 2281, 2445, 307, 406, 437, 321, 17522, 1830, 2539, 13, 50956, 50956, 467, 311, 437, 321, 17522, 1830, 38253, 13, 51098, 51098, 407, 38253, 307, 15866, 288, 490, 2031, 13, 51368, 51368, 407, 341, 2281, 2445, 307, 39684, 22608, 13, 51506, 51506, 467, 2516, 2295, 4190, 562, 288, 307, 18218, 365, 2031, 293, 2946, 4190, 562, 288, 307, 406, 18218, 51738, 51738, 365, 2031, 13, 51804, 51804], "temperature": 0.0, "avg_logprob": -0.14680879683721634, "compression_ratio": 1.8472222222222223, "no_speech_prob": 1.834158319979906e-05}, {"id": 101, "seek": 43936, "start": 454.04, "end": 459.44, "text": " So inference is computing y from x.", "tokens": [50364, 492, 434, 11926, 341, 2445, 283, 295, 2031, 11, 288, 307, 2212, 281, 291, 13, 50484, 50484, 492, 434, 516, 281, 751, 466, 577, 321, 1466, 309, 257, 707, 1780, 13, 50768, 50768, 1033, 370, 264, 2281, 2445, 307, 406, 437, 321, 17522, 1830, 2539, 13, 50956, 50956, 467, 311, 437, 321, 17522, 1830, 38253, 13, 51098, 51098, 407, 38253, 307, 15866, 288, 490, 2031, 13, 51368, 51368, 407, 341, 2281, 2445, 307, 39684, 22608, 13, 51506, 51506, 467, 2516, 2295, 4190, 562, 288, 307, 18218, 365, 2031, 293, 2946, 4190, 562, 288, 307, 406, 18218, 51738, 51738, 365, 2031, 13, 51804, 51804], "temperature": 0.0, "avg_logprob": -0.14680879683721634, "compression_ratio": 1.8472222222222223, "no_speech_prob": 1.834158319979906e-05}, {"id": 102, "seek": 43936, "start": 459.44, "end": 462.2, "text": " So this energy function is scalar valued.", "tokens": [50364, 492, 434, 11926, 341, 2445, 283, 295, 2031, 11, 288, 307, 2212, 281, 291, 13, 50484, 50484, 492, 434, 516, 281, 751, 466, 577, 321, 1466, 309, 257, 707, 1780, 13, 50768, 50768, 1033, 370, 264, 2281, 2445, 307, 406, 437, 321, 17522, 1830, 2539, 13, 50956, 50956, 467, 311, 437, 321, 17522, 1830, 38253, 13, 51098, 51098, 407, 38253, 307, 15866, 288, 490, 2031, 13, 51368, 51368, 407, 341, 2281, 2445, 307, 39684, 22608, 13, 51506, 51506, 467, 2516, 2295, 4190, 562, 288, 307, 18218, 365, 2031, 293, 2946, 4190, 562, 288, 307, 406, 18218, 51738, 51738, 365, 2031, 13, 51804, 51804], "temperature": 0.0, "avg_logprob": -0.14680879683721634, "compression_ratio": 1.8472222222222223, "no_speech_prob": 1.834158319979906e-05}, {"id": 103, "seek": 43936, "start": 462.2, "end": 466.84000000000003, "text": " It takes low values when y is compatible with x and higher values when y is not compatible", "tokens": [50364, 492, 434, 11926, 341, 2445, 283, 295, 2031, 11, 288, 307, 2212, 281, 291, 13, 50484, 50484, 492, 434, 516, 281, 751, 466, 577, 321, 1466, 309, 257, 707, 1780, 13, 50768, 50768, 1033, 370, 264, 2281, 2445, 307, 406, 437, 321, 17522, 1830, 2539, 13, 50956, 50956, 467, 311, 437, 321, 17522, 1830, 38253, 13, 51098, 51098, 407, 38253, 307, 15866, 288, 490, 2031, 13, 51368, 51368, 407, 341, 2281, 2445, 307, 39684, 22608, 13, 51506, 51506, 467, 2516, 2295, 4190, 562, 288, 307, 18218, 365, 2031, 293, 2946, 4190, 562, 288, 307, 406, 18218, 51738, 51738, 365, 2031, 13, 51804, 51804], "temperature": 0.0, "avg_logprob": -0.14680879683721634, "compression_ratio": 1.8472222222222223, "no_speech_prob": 1.834158319979906e-05}, {"id": 104, "seek": 43936, "start": 466.84000000000003, "end": 468.16, "text": " with x.", "tokens": [50364, 492, 434, 11926, 341, 2445, 283, 295, 2031, 11, 288, 307, 2212, 281, 291, 13, 50484, 50484, 492, 434, 516, 281, 751, 466, 577, 321, 1466, 309, 257, 707, 1780, 13, 50768, 50768, 1033, 370, 264, 2281, 2445, 307, 406, 437, 321, 17522, 1830, 2539, 13, 50956, 50956, 467, 311, 437, 321, 17522, 1830, 38253, 13, 51098, 51098, 407, 38253, 307, 15866, 288, 490, 2031, 13, 51368, 51368, 407, 341, 2281, 2445, 307, 39684, 22608, 13, 51506, 51506, 467, 2516, 2295, 4190, 562, 288, 307, 18218, 365, 2031, 293, 2946, 4190, 562, 288, 307, 406, 18218, 51738, 51738, 365, 2031, 13, 51804, 51804], "temperature": 0.0, "avg_logprob": -0.14680879683721634, "compression_ratio": 1.8472222222222223, "no_speech_prob": 1.834158319979906e-05}, {"id": 105, "seek": 46816, "start": 468.16, "end": 474.72, "text": " So you'd like this function to have a shape in such a way that for a given x, all the", "tokens": [50364, 407, 291, 1116, 411, 341, 2445, 281, 362, 257, 3909, 294, 1270, 257, 636, 300, 337, 257, 2212, 2031, 11, 439, 264, 50692, 50692, 4190, 295, 288, 300, 366, 18218, 365, 341, 2031, 362, 2295, 2281, 293, 439, 264, 4190, 300, 50882, 50882, 366, 406, 18218, 365, 300, 2212, 2031, 362, 2946, 2281, 13, 51086, 51086, 400, 300, 311, 439, 291, 643, 570, 550, 264, 38253, 10747, 307, 516, 281, 915, 264, 288, 1520, 300, 51458, 51458, 3720, 510, 11, 597, 307, 264, 2158, 295, 288, 300, 4464, 5660, 283, 295, 2031, 11, 288, 13, 51700, 51700], "temperature": 0.0, "avg_logprob": -0.13841987378669507, "compression_ratio": 1.742081447963801, "no_speech_prob": 1.1842557796626352e-05}, {"id": 106, "seek": 46816, "start": 474.72, "end": 478.52000000000004, "text": " values of y that are compatible with this x have low energy and all the values that", "tokens": [50364, 407, 291, 1116, 411, 341, 2445, 281, 362, 257, 3909, 294, 1270, 257, 636, 300, 337, 257, 2212, 2031, 11, 439, 264, 50692, 50692, 4190, 295, 288, 300, 366, 18218, 365, 341, 2031, 362, 2295, 2281, 293, 439, 264, 4190, 300, 50882, 50882, 366, 406, 18218, 365, 300, 2212, 2031, 362, 2946, 2281, 13, 51086, 51086, 400, 300, 311, 439, 291, 643, 570, 550, 264, 38253, 10747, 307, 516, 281, 915, 264, 288, 1520, 300, 51458, 51458, 3720, 510, 11, 597, 307, 264, 2158, 295, 288, 300, 4464, 5660, 283, 295, 2031, 11, 288, 13, 51700, 51700], "temperature": 0.0, "avg_logprob": -0.13841987378669507, "compression_ratio": 1.742081447963801, "no_speech_prob": 1.1842557796626352e-05}, {"id": 107, "seek": 46816, "start": 478.52000000000004, "end": 482.6, "text": " are not compatible with that given x have higher energy.", "tokens": [50364, 407, 291, 1116, 411, 341, 2445, 281, 362, 257, 3909, 294, 1270, 257, 636, 300, 337, 257, 2212, 2031, 11, 439, 264, 50692, 50692, 4190, 295, 288, 300, 366, 18218, 365, 341, 2031, 362, 2295, 2281, 293, 439, 264, 4190, 300, 50882, 50882, 366, 406, 18218, 365, 300, 2212, 2031, 362, 2946, 2281, 13, 51086, 51086, 400, 300, 311, 439, 291, 643, 570, 550, 264, 38253, 10747, 307, 516, 281, 915, 264, 288, 1520, 300, 51458, 51458, 3720, 510, 11, 597, 307, 264, 2158, 295, 288, 300, 4464, 5660, 283, 295, 2031, 11, 288, 13, 51700, 51700], "temperature": 0.0, "avg_logprob": -0.13841987378669507, "compression_ratio": 1.742081447963801, "no_speech_prob": 1.1842557796626352e-05}, {"id": 108, "seek": 46816, "start": 482.6, "end": 490.04, "text": " And that's all you need because then the inference procedure is going to find the y check that", "tokens": [50364, 407, 291, 1116, 411, 341, 2445, 281, 362, 257, 3909, 294, 1270, 257, 636, 300, 337, 257, 2212, 2031, 11, 439, 264, 50692, 50692, 4190, 295, 288, 300, 366, 18218, 365, 341, 2031, 362, 2295, 2281, 293, 439, 264, 4190, 300, 50882, 50882, 366, 406, 18218, 365, 300, 2212, 2031, 362, 2946, 2281, 13, 51086, 51086, 400, 300, 311, 439, 291, 643, 570, 550, 264, 38253, 10747, 307, 516, 281, 915, 264, 288, 1520, 300, 51458, 51458, 3720, 510, 11, 597, 307, 264, 2158, 295, 288, 300, 4464, 5660, 283, 295, 2031, 11, 288, 13, 51700, 51700], "temperature": 0.0, "avg_logprob": -0.13841987378669507, "compression_ratio": 1.742081447963801, "no_speech_prob": 1.1842557796626352e-05}, {"id": 109, "seek": 46816, "start": 490.04, "end": 494.88, "text": " written here, which is the value of y that minimizes f of x, y.", "tokens": [50364, 407, 291, 1116, 411, 341, 2445, 281, 362, 257, 3909, 294, 1270, 257, 636, 300, 337, 257, 2212, 2031, 11, 439, 264, 50692, 50692, 4190, 295, 288, 300, 366, 18218, 365, 341, 2031, 362, 2295, 2281, 293, 439, 264, 4190, 300, 50882, 50882, 366, 406, 18218, 365, 300, 2212, 2031, 362, 2946, 2281, 13, 51086, 51086, 400, 300, 311, 439, 291, 643, 570, 550, 264, 38253, 10747, 307, 516, 281, 915, 264, 288, 1520, 300, 51458, 51458, 3720, 510, 11, 597, 307, 264, 2158, 295, 288, 300, 4464, 5660, 283, 295, 2031, 11, 288, 13, 51700, 51700], "temperature": 0.0, "avg_logprob": -0.13841987378669507, "compression_ratio": 1.742081447963801, "no_speech_prob": 1.1842557796626352e-05}, {"id": 110, "seek": 49488, "start": 494.88, "end": 498.0, "text": " It's not going to be the value, it's going to be a value because there might be multiple", "tokens": [50364, 467, 311, 406, 516, 281, 312, 264, 2158, 11, 309, 311, 516, 281, 312, 257, 2158, 570, 456, 1062, 312, 3866, 50520, 50520, 4190, 13, 50570, 50570, 400, 428, 38253, 9284, 1062, 767, 352, 807, 3866, 4190, 420, 17496, 3866, 50780, 50780, 4190, 949, 2902, 291, 472, 420, 2940, 13, 51016, 51016, 1033, 718, 311, 747, 257, 588, 2199, 1365, 294, 472, 10139, 295, 39684, 9102, 13, 51432, 51432, 407, 2031, 510, 307, 257, 957, 2158, 293, 288, 307, 257, 957, 2158, 13, 51768, 51768], "temperature": 0.0, "avg_logprob": -0.16341148025688085, "compression_ratio": 1.7475247524752475, "no_speech_prob": 1.2605643860297278e-05}, {"id": 111, "seek": 49488, "start": 498.0, "end": 499.0, "text": " values.", "tokens": [50364, 467, 311, 406, 516, 281, 312, 264, 2158, 11, 309, 311, 516, 281, 312, 257, 2158, 570, 456, 1062, 312, 3866, 50520, 50520, 4190, 13, 50570, 50570, 400, 428, 38253, 9284, 1062, 767, 352, 807, 3866, 4190, 420, 17496, 3866, 50780, 50780, 4190, 949, 2902, 291, 472, 420, 2940, 13, 51016, 51016, 1033, 718, 311, 747, 257, 588, 2199, 1365, 294, 472, 10139, 295, 39684, 9102, 13, 51432, 51432, 407, 2031, 510, 307, 257, 957, 2158, 293, 288, 307, 257, 957, 2158, 13, 51768, 51768], "temperature": 0.0, "avg_logprob": -0.16341148025688085, "compression_ratio": 1.7475247524752475, "no_speech_prob": 1.2605643860297278e-05}, {"id": 112, "seek": 49488, "start": 499.0, "end": 503.2, "text": " And your inference algorithm might actually go through multiple values or examine multiple", "tokens": [50364, 467, 311, 406, 516, 281, 312, 264, 2158, 11, 309, 311, 516, 281, 312, 257, 2158, 570, 456, 1062, 312, 3866, 50520, 50520, 4190, 13, 50570, 50570, 400, 428, 38253, 9284, 1062, 767, 352, 807, 3866, 4190, 420, 17496, 3866, 50780, 50780, 4190, 949, 2902, 291, 472, 420, 2940, 13, 51016, 51016, 1033, 718, 311, 747, 257, 588, 2199, 1365, 294, 472, 10139, 295, 39684, 9102, 13, 51432, 51432, 407, 2031, 510, 307, 257, 957, 2158, 293, 288, 307, 257, 957, 2158, 13, 51768, 51768], "temperature": 0.0, "avg_logprob": -0.16341148025688085, "compression_ratio": 1.7475247524752475, "no_speech_prob": 1.2605643860297278e-05}, {"id": 113, "seek": 49488, "start": 503.2, "end": 507.92, "text": " values before giving you one or several.", "tokens": [50364, 467, 311, 406, 516, 281, 312, 264, 2158, 11, 309, 311, 516, 281, 312, 257, 2158, 570, 456, 1062, 312, 3866, 50520, 50520, 4190, 13, 50570, 50570, 400, 428, 38253, 9284, 1062, 767, 352, 807, 3866, 4190, 420, 17496, 3866, 50780, 50780, 4190, 949, 2902, 291, 472, 420, 2940, 13, 51016, 51016, 1033, 718, 311, 747, 257, 588, 2199, 1365, 294, 472, 10139, 295, 39684, 9102, 13, 51432, 51432, 407, 2031, 510, 307, 257, 957, 2158, 293, 288, 307, 257, 957, 2158, 13, 51768, 51768], "temperature": 0.0, "avg_logprob": -0.16341148025688085, "compression_ratio": 1.7475247524752475, "no_speech_prob": 1.2605643860297278e-05}, {"id": 114, "seek": 49488, "start": 507.92, "end": 516.24, "text": " Okay let's take a very simple example in one dimension of scalar variables.", "tokens": [50364, 467, 311, 406, 516, 281, 312, 264, 2158, 11, 309, 311, 516, 281, 312, 257, 2158, 570, 456, 1062, 312, 3866, 50520, 50520, 4190, 13, 50570, 50570, 400, 428, 38253, 9284, 1062, 767, 352, 807, 3866, 4190, 420, 17496, 3866, 50780, 50780, 4190, 949, 2902, 291, 472, 420, 2940, 13, 51016, 51016, 1033, 718, 311, 747, 257, 588, 2199, 1365, 294, 472, 10139, 295, 39684, 9102, 13, 51432, 51432, 407, 2031, 510, 307, 257, 957, 2158, 293, 288, 307, 257, 957, 2158, 13, 51768, 51768], "temperature": 0.0, "avg_logprob": -0.16341148025688085, "compression_ratio": 1.7475247524752475, "no_speech_prob": 1.2605643860297278e-05}, {"id": 115, "seek": 49488, "start": 516.24, "end": 522.96, "text": " So x here is a real value and y is a real value.", "tokens": [50364, 467, 311, 406, 516, 281, 312, 264, 2158, 11, 309, 311, 516, 281, 312, 257, 2158, 570, 456, 1062, 312, 3866, 50520, 50520, 4190, 13, 50570, 50570, 400, 428, 38253, 9284, 1062, 767, 352, 807, 3866, 4190, 420, 17496, 3866, 50780, 50780, 4190, 949, 2902, 291, 472, 420, 2940, 13, 51016, 51016, 1033, 718, 311, 747, 257, 588, 2199, 1365, 294, 472, 10139, 295, 39684, 9102, 13, 51432, 51432, 407, 2031, 510, 307, 257, 957, 2158, 293, 288, 307, 257, 957, 2158, 13, 51768, 51768], "temperature": 0.0, "avg_logprob": -0.16341148025688085, "compression_ratio": 1.7475247524752475, "no_speech_prob": 1.2605643860297278e-05}, {"id": 116, "seek": 52296, "start": 522.96, "end": 525.5600000000001, "text": " And the blue dots here are data points.", "tokens": [50364, 400, 264, 3344, 15026, 510, 366, 1412, 2793, 13, 50494, 50494, 407, 437, 291, 528, 307, 498, 291, 528, 281, 7983, 264, 33621, 1296, 2031, 293, 288, 294, 264, 1412, 50900, 50900, 307, 300, 291, 576, 411, 364, 2281, 2445, 300, 575, 2139, 341, 3909, 420, 300, 3909, 420, 51083, 51083, 512, 661, 3909, 457, 597, 575, 257, 3909, 300, 294, 1270, 257, 636, 300, 498, 291, 747, 257, 1729, 51352, 51352, 2158, 295, 2031, 11, 264, 2158, 295, 288, 300, 575, 257, 12437, 2158, 307, 2651, 264, 3344, 2793, 11, 2651, 264, 3344, 51568, 51568, 15026, 597, 366, 264, 1412, 2793, 13, 51720, 51720], "temperature": 0.0, "avg_logprob": -0.12698571035795123, "compression_ratio": 1.9136363636363636, "no_speech_prob": 1.1841803825518582e-05}, {"id": 117, "seek": 52296, "start": 525.5600000000001, "end": 533.6800000000001, "text": " So what you want is if you want to capture the dependency between x and y in the data", "tokens": [50364, 400, 264, 3344, 15026, 510, 366, 1412, 2793, 13, 50494, 50494, 407, 437, 291, 528, 307, 498, 291, 528, 281, 7983, 264, 33621, 1296, 2031, 293, 288, 294, 264, 1412, 50900, 50900, 307, 300, 291, 576, 411, 364, 2281, 2445, 300, 575, 2139, 341, 3909, 420, 300, 3909, 420, 51083, 51083, 512, 661, 3909, 457, 597, 575, 257, 3909, 300, 294, 1270, 257, 636, 300, 498, 291, 747, 257, 1729, 51352, 51352, 2158, 295, 2031, 11, 264, 2158, 295, 288, 300, 575, 257, 12437, 2158, 307, 2651, 264, 3344, 2793, 11, 2651, 264, 3344, 51568, 51568, 15026, 597, 366, 264, 1412, 2793, 13, 51720, 51720], "temperature": 0.0, "avg_logprob": -0.12698571035795123, "compression_ratio": 1.9136363636363636, "no_speech_prob": 1.1841803825518582e-05}, {"id": 118, "seek": 52296, "start": 533.6800000000001, "end": 537.34, "text": " is that you would like an energy function that has either this shape or that shape or", "tokens": [50364, 400, 264, 3344, 15026, 510, 366, 1412, 2793, 13, 50494, 50494, 407, 437, 291, 528, 307, 498, 291, 528, 281, 7983, 264, 33621, 1296, 2031, 293, 288, 294, 264, 1412, 50900, 50900, 307, 300, 291, 576, 411, 364, 2281, 2445, 300, 575, 2139, 341, 3909, 420, 300, 3909, 420, 51083, 51083, 512, 661, 3909, 457, 597, 575, 257, 3909, 300, 294, 1270, 257, 636, 300, 498, 291, 747, 257, 1729, 51352, 51352, 2158, 295, 2031, 11, 264, 2158, 295, 288, 300, 575, 257, 12437, 2158, 307, 2651, 264, 3344, 2793, 11, 2651, 264, 3344, 51568, 51568, 15026, 597, 366, 264, 1412, 2793, 13, 51720, 51720], "temperature": 0.0, "avg_logprob": -0.12698571035795123, "compression_ratio": 1.9136363636363636, "no_speech_prob": 1.1841803825518582e-05}, {"id": 119, "seek": 52296, "start": 537.34, "end": 542.72, "text": " some other shape but which has a shape that in such a way that if you take a particular", "tokens": [50364, 400, 264, 3344, 15026, 510, 366, 1412, 2793, 13, 50494, 50494, 407, 437, 291, 528, 307, 498, 291, 528, 281, 7983, 264, 33621, 1296, 2031, 293, 288, 294, 264, 1412, 50900, 50900, 307, 300, 291, 576, 411, 364, 2281, 2445, 300, 575, 2139, 341, 3909, 420, 300, 3909, 420, 51083, 51083, 512, 661, 3909, 457, 597, 575, 257, 3909, 300, 294, 1270, 257, 636, 300, 498, 291, 747, 257, 1729, 51352, 51352, 2158, 295, 2031, 11, 264, 2158, 295, 288, 300, 575, 257, 12437, 2158, 307, 2651, 264, 3344, 2793, 11, 2651, 264, 3344, 51568, 51568, 15026, 597, 366, 264, 1412, 2793, 13, 51720, 51720], "temperature": 0.0, "avg_logprob": -0.12698571035795123, "compression_ratio": 1.9136363636363636, "no_speech_prob": 1.1841803825518582e-05}, {"id": 120, "seek": 52296, "start": 542.72, "end": 547.0400000000001, "text": " value of x, the value of y that has a lowest value is near the blue points, near the blue", "tokens": [50364, 400, 264, 3344, 15026, 510, 366, 1412, 2793, 13, 50494, 50494, 407, 437, 291, 528, 307, 498, 291, 528, 281, 7983, 264, 33621, 1296, 2031, 293, 288, 294, 264, 1412, 50900, 50900, 307, 300, 291, 576, 411, 364, 2281, 2445, 300, 575, 2139, 341, 3909, 420, 300, 3909, 420, 51083, 51083, 512, 661, 3909, 457, 597, 575, 257, 3909, 300, 294, 1270, 257, 636, 300, 498, 291, 747, 257, 1729, 51352, 51352, 2158, 295, 2031, 11, 264, 2158, 295, 288, 300, 575, 257, 12437, 2158, 307, 2651, 264, 3344, 2793, 11, 2651, 264, 3344, 51568, 51568, 15026, 597, 366, 264, 1412, 2793, 13, 51720, 51720], "temperature": 0.0, "avg_logprob": -0.12698571035795123, "compression_ratio": 1.9136363636363636, "no_speech_prob": 1.1841803825518582e-05}, {"id": 121, "seek": 52296, "start": 547.0400000000001, "end": 550.08, "text": " dots which are the data points.", "tokens": [50364, 400, 264, 3344, 15026, 510, 366, 1412, 2793, 13, 50494, 50494, 407, 437, 291, 528, 307, 498, 291, 528, 281, 7983, 264, 33621, 1296, 2031, 293, 288, 294, 264, 1412, 50900, 50900, 307, 300, 291, 576, 411, 364, 2281, 2445, 300, 575, 2139, 341, 3909, 420, 300, 3909, 420, 51083, 51083, 512, 661, 3909, 457, 597, 575, 257, 3909, 300, 294, 1270, 257, 636, 300, 498, 291, 747, 257, 1729, 51352, 51352, 2158, 295, 2031, 11, 264, 2158, 295, 288, 300, 575, 257, 12437, 2158, 307, 2651, 264, 3344, 2793, 11, 2651, 264, 3344, 51568, 51568, 15026, 597, 366, 264, 1412, 2793, 13, 51720, 51720], "temperature": 0.0, "avg_logprob": -0.12698571035795123, "compression_ratio": 1.9136363636363636, "no_speech_prob": 1.1841803825518582e-05}, {"id": 122, "seek": 55008, "start": 550.08, "end": 554.84, "text": " So a function like this captures the dependency between x and y.", "tokens": [50364, 407, 257, 2445, 411, 341, 27986, 264, 33621, 1296, 2031, 293, 288, 13, 50602, 50602, 823, 281, 360, 264, 38253, 295, 437, 307, 264, 1151, 288, 337, 257, 2212, 2031, 11, 498, 291, 362, 257, 2445, 411, 50828, 50828, 341, 291, 393, 764, 16235, 23475, 13, 50908, 50908, 407, 498, 286, 976, 291, 364, 2031, 281, 2573, 484, 437, 311, 264, 1151, 2158, 295, 288, 300, 23249, 281, 341, 51144, 51144, 2031, 11, 291, 393, 722, 490, 512, 4974, 288, 293, 550, 538, 16235, 23475, 915, 264, 7285, 295, 264, 51386, 51386, 2445, 293, 291, 603, 2100, 760, 281, 264, 3344, 20369, 510, 13, 51534, 51534, 23964, 312, 257, 707, 6081, 337, 341, 472, 457, 490, 264, 935, 295, 1910, 295, 2517, 3319, 264, 51810, 51810], "temperature": 0.0, "avg_logprob": -0.11357071995735168, "compression_ratio": 1.7879858657243817, "no_speech_prob": 1.669943958404474e-05}, {"id": 123, "seek": 55008, "start": 554.84, "end": 559.36, "text": " Now to do the inference of what is the best y for a given x, if you have a function like", "tokens": [50364, 407, 257, 2445, 411, 341, 27986, 264, 33621, 1296, 2031, 293, 288, 13, 50602, 50602, 823, 281, 360, 264, 38253, 295, 437, 307, 264, 1151, 288, 337, 257, 2212, 2031, 11, 498, 291, 362, 257, 2445, 411, 50828, 50828, 341, 291, 393, 764, 16235, 23475, 13, 50908, 50908, 407, 498, 286, 976, 291, 364, 2031, 281, 2573, 484, 437, 311, 264, 1151, 2158, 295, 288, 300, 23249, 281, 341, 51144, 51144, 2031, 11, 291, 393, 722, 490, 512, 4974, 288, 293, 550, 538, 16235, 23475, 915, 264, 7285, 295, 264, 51386, 51386, 2445, 293, 291, 603, 2100, 760, 281, 264, 3344, 20369, 510, 13, 51534, 51534, 23964, 312, 257, 707, 6081, 337, 341, 472, 457, 490, 264, 935, 295, 1910, 295, 2517, 3319, 264, 51810, 51810], "temperature": 0.0, "avg_logprob": -0.11357071995735168, "compression_ratio": 1.7879858657243817, "no_speech_prob": 1.669943958404474e-05}, {"id": 124, "seek": 55008, "start": 559.36, "end": 560.96, "text": " this you can use gradient descent.", "tokens": [50364, 407, 257, 2445, 411, 341, 27986, 264, 33621, 1296, 2031, 293, 288, 13, 50602, 50602, 823, 281, 360, 264, 38253, 295, 437, 307, 264, 1151, 288, 337, 257, 2212, 2031, 11, 498, 291, 362, 257, 2445, 411, 50828, 50828, 341, 291, 393, 764, 16235, 23475, 13, 50908, 50908, 407, 498, 286, 976, 291, 364, 2031, 281, 2573, 484, 437, 311, 264, 1151, 2158, 295, 288, 300, 23249, 281, 341, 51144, 51144, 2031, 11, 291, 393, 722, 490, 512, 4974, 288, 293, 550, 538, 16235, 23475, 915, 264, 7285, 295, 264, 51386, 51386, 2445, 293, 291, 603, 2100, 760, 281, 264, 3344, 20369, 510, 13, 51534, 51534, 23964, 312, 257, 707, 6081, 337, 341, 472, 457, 490, 264, 935, 295, 1910, 295, 2517, 3319, 264, 51810, 51810], "temperature": 0.0, "avg_logprob": -0.11357071995735168, "compression_ratio": 1.7879858657243817, "no_speech_prob": 1.669943958404474e-05}, {"id": 125, "seek": 55008, "start": 560.96, "end": 565.6800000000001, "text": " So if I give you an x to figure out what's the best value of y that corresponds to this", "tokens": [50364, 407, 257, 2445, 411, 341, 27986, 264, 33621, 1296, 2031, 293, 288, 13, 50602, 50602, 823, 281, 360, 264, 38253, 295, 437, 307, 264, 1151, 288, 337, 257, 2212, 2031, 11, 498, 291, 362, 257, 2445, 411, 50828, 50828, 341, 291, 393, 764, 16235, 23475, 13, 50908, 50908, 407, 498, 286, 976, 291, 364, 2031, 281, 2573, 484, 437, 311, 264, 1151, 2158, 295, 288, 300, 23249, 281, 341, 51144, 51144, 2031, 11, 291, 393, 722, 490, 512, 4974, 288, 293, 550, 538, 16235, 23475, 915, 264, 7285, 295, 264, 51386, 51386, 2445, 293, 291, 603, 2100, 760, 281, 264, 3344, 20369, 510, 13, 51534, 51534, 23964, 312, 257, 707, 6081, 337, 341, 472, 457, 490, 264, 935, 295, 1910, 295, 2517, 3319, 264, 51810, 51810], "temperature": 0.0, "avg_logprob": -0.11357071995735168, "compression_ratio": 1.7879858657243817, "no_speech_prob": 1.669943958404474e-05}, {"id": 126, "seek": 55008, "start": 565.6800000000001, "end": 570.5200000000001, "text": " x, you can start from some random y and then by gradient descent find the minimum of the", "tokens": [50364, 407, 257, 2445, 411, 341, 27986, 264, 33621, 1296, 2031, 293, 288, 13, 50602, 50602, 823, 281, 360, 264, 38253, 295, 437, 307, 264, 1151, 288, 337, 257, 2212, 2031, 11, 498, 291, 362, 257, 2445, 411, 50828, 50828, 341, 291, 393, 764, 16235, 23475, 13, 50908, 50908, 407, 498, 286, 976, 291, 364, 2031, 281, 2573, 484, 437, 311, 264, 1151, 2158, 295, 288, 300, 23249, 281, 341, 51144, 51144, 2031, 11, 291, 393, 722, 490, 512, 4974, 288, 293, 550, 538, 16235, 23475, 915, 264, 7285, 295, 264, 51386, 51386, 2445, 293, 291, 603, 2100, 760, 281, 264, 3344, 20369, 510, 13, 51534, 51534, 23964, 312, 257, 707, 6081, 337, 341, 472, 457, 490, 264, 935, 295, 1910, 295, 2517, 3319, 264, 51810, 51810], "temperature": 0.0, "avg_logprob": -0.11357071995735168, "compression_ratio": 1.7879858657243817, "no_speech_prob": 1.669943958404474e-05}, {"id": 127, "seek": 55008, "start": 570.5200000000001, "end": 573.48, "text": " function and you'll fall down to the blue beads here.", "tokens": [50364, 407, 257, 2445, 411, 341, 27986, 264, 33621, 1296, 2031, 293, 288, 13, 50602, 50602, 823, 281, 360, 264, 38253, 295, 437, 307, 264, 1151, 288, 337, 257, 2212, 2031, 11, 498, 291, 362, 257, 2445, 411, 50828, 50828, 341, 291, 393, 764, 16235, 23475, 13, 50908, 50908, 407, 498, 286, 976, 291, 364, 2031, 281, 2573, 484, 437, 311, 264, 1151, 2158, 295, 288, 300, 23249, 281, 341, 51144, 51144, 2031, 11, 291, 393, 722, 490, 512, 4974, 288, 293, 550, 538, 16235, 23475, 915, 264, 7285, 295, 264, 51386, 51386, 2445, 293, 291, 603, 2100, 760, 281, 264, 3344, 20369, 510, 13, 51534, 51534, 23964, 312, 257, 707, 6081, 337, 341, 472, 457, 490, 264, 935, 295, 1910, 295, 2517, 3319, 264, 51810, 51810], "temperature": 0.0, "avg_logprob": -0.11357071995735168, "compression_ratio": 1.7879858657243817, "no_speech_prob": 1.669943958404474e-05}, {"id": 128, "seek": 55008, "start": 573.48, "end": 579.0, "text": " Might be a little harder for this one but from the point of view of characterizing the", "tokens": [50364, 407, 257, 2445, 411, 341, 27986, 264, 33621, 1296, 2031, 293, 288, 13, 50602, 50602, 823, 281, 360, 264, 38253, 295, 437, 307, 264, 1151, 288, 337, 257, 2212, 2031, 11, 498, 291, 362, 257, 2445, 411, 50828, 50828, 341, 291, 393, 764, 16235, 23475, 13, 50908, 50908, 407, 498, 286, 976, 291, 364, 2031, 281, 2573, 484, 437, 311, 264, 1151, 2158, 295, 288, 300, 23249, 281, 341, 51144, 51144, 2031, 11, 291, 393, 722, 490, 512, 4974, 288, 293, 550, 538, 16235, 23475, 915, 264, 7285, 295, 264, 51386, 51386, 2445, 293, 291, 603, 2100, 760, 281, 264, 3344, 20369, 510, 13, 51534, 51534, 23964, 312, 257, 707, 6081, 337, 341, 472, 457, 490, 264, 935, 295, 1910, 295, 2517, 3319, 264, 51810, 51810], "temperature": 0.0, "avg_logprob": -0.11357071995735168, "compression_ratio": 1.7879858657243817, "no_speech_prob": 1.669943958404474e-05}, {"id": 129, "seek": 57900, "start": 579.0, "end": 582.88, "text": " dependency between those two variables, those two energy functions are just about as good", "tokens": [50364, 33621, 1296, 729, 732, 9102, 11, 729, 732, 2281, 6828, 366, 445, 466, 382, 665, 50558, 50558, 382, 1184, 661, 13, 50608, 50608, 583, 577, 576, 291, 652, 988, 300, 288, 307, 257, 472, 12, 12194, 8062, 11, 411, 257, 21538, 30, 50962, 50962, 286, 603, 808, 281, 341, 13, 51314, 51314, 440, 27706, 1389, 562, 288, 307, 27706, 307, 264, 1858, 1389, 11, 1392, 11, 293, 321, 600, 1217, 2825, 51543, 51543, 466, 341, 293, 286, 603, 733, 295, 8290, 5256, 341, 294, 2115, 295, 2281, 294, 445, 257, 1916, 2077, 13, 51808, 51808], "temperature": 0.0, "avg_logprob": -0.25676925895140346, "compression_ratio": 1.575, "no_speech_prob": 1.3006249901081901e-05}, {"id": 130, "seek": 57900, "start": 582.88, "end": 583.88, "text": " as each other.", "tokens": [50364, 33621, 1296, 729, 732, 9102, 11, 729, 732, 2281, 6828, 366, 445, 466, 382, 665, 50558, 50558, 382, 1184, 661, 13, 50608, 50608, 583, 577, 576, 291, 652, 988, 300, 288, 307, 257, 472, 12, 12194, 8062, 11, 411, 257, 21538, 30, 50962, 50962, 286, 603, 808, 281, 341, 13, 51314, 51314, 440, 27706, 1389, 562, 288, 307, 27706, 307, 264, 1858, 1389, 11, 1392, 11, 293, 321, 600, 1217, 2825, 51543, 51543, 466, 341, 293, 286, 603, 733, 295, 8290, 5256, 341, 294, 2115, 295, 2281, 294, 445, 257, 1916, 2077, 13, 51808, 51808], "temperature": 0.0, "avg_logprob": -0.25676925895140346, "compression_ratio": 1.575, "no_speech_prob": 1.3006249901081901e-05}, {"id": 131, "seek": 57900, "start": 583.88, "end": 590.96, "text": " But how would you make sure that y is a one-hot vector, like a classification?", "tokens": [50364, 33621, 1296, 729, 732, 9102, 11, 729, 732, 2281, 6828, 366, 445, 466, 382, 665, 50558, 50558, 382, 1184, 661, 13, 50608, 50608, 583, 577, 576, 291, 652, 988, 300, 288, 307, 257, 472, 12, 12194, 8062, 11, 411, 257, 21538, 30, 50962, 50962, 286, 603, 808, 281, 341, 13, 51314, 51314, 440, 27706, 1389, 562, 288, 307, 27706, 307, 264, 1858, 1389, 11, 1392, 11, 293, 321, 600, 1217, 2825, 51543, 51543, 466, 341, 293, 286, 603, 733, 295, 8290, 5256, 341, 294, 2115, 295, 2281, 294, 445, 257, 1916, 2077, 13, 51808, 51808], "temperature": 0.0, "avg_logprob": -0.25676925895140346, "compression_ratio": 1.575, "no_speech_prob": 1.3006249901081901e-05}, {"id": 132, "seek": 57900, "start": 590.96, "end": 598.0, "text": " I'll come to this.", "tokens": [50364, 33621, 1296, 729, 732, 9102, 11, 729, 732, 2281, 6828, 366, 445, 466, 382, 665, 50558, 50558, 382, 1184, 661, 13, 50608, 50608, 583, 577, 576, 291, 652, 988, 300, 288, 307, 257, 472, 12, 12194, 8062, 11, 411, 257, 21538, 30, 50962, 50962, 286, 603, 808, 281, 341, 13, 51314, 51314, 440, 27706, 1389, 562, 288, 307, 27706, 307, 264, 1858, 1389, 11, 1392, 11, 293, 321, 600, 1217, 2825, 51543, 51543, 466, 341, 293, 286, 603, 733, 295, 8290, 5256, 341, 294, 2115, 295, 2281, 294, 445, 257, 1916, 2077, 13, 51808, 51808], "temperature": 0.0, "avg_logprob": -0.25676925895140346, "compression_ratio": 1.575, "no_speech_prob": 1.3006249901081901e-05}, {"id": 133, "seek": 57900, "start": 598.0, "end": 602.58, "text": " The discrete case when y is discrete is the easy case, okay, and we've already talked", "tokens": [50364, 33621, 1296, 729, 732, 9102, 11, 729, 732, 2281, 6828, 366, 445, 466, 382, 665, 50558, 50558, 382, 1184, 661, 13, 50608, 50608, 583, 577, 576, 291, 652, 988, 300, 288, 307, 257, 472, 12, 12194, 8062, 11, 411, 257, 21538, 30, 50962, 50962, 286, 603, 808, 281, 341, 13, 51314, 51314, 440, 27706, 1389, 562, 288, 307, 27706, 307, 264, 1858, 1389, 11, 1392, 11, 293, 321, 600, 1217, 2825, 51543, 51543, 466, 341, 293, 286, 603, 733, 295, 8290, 5256, 341, 294, 2115, 295, 2281, 294, 445, 257, 1916, 2077, 13, 51808, 51808], "temperature": 0.0, "avg_logprob": -0.25676925895140346, "compression_ratio": 1.575, "no_speech_prob": 1.3006249901081901e-05}, {"id": 134, "seek": 57900, "start": 602.58, "end": 607.88, "text": " about this and I'll kind of reformulate this in terms of energy in just a couple minutes.", "tokens": [50364, 33621, 1296, 729, 732, 9102, 11, 729, 732, 2281, 6828, 366, 445, 466, 382, 665, 50558, 50558, 382, 1184, 661, 13, 50608, 50608, 583, 577, 576, 291, 652, 988, 300, 288, 307, 257, 472, 12, 12194, 8062, 11, 411, 257, 21538, 30, 50962, 50962, 286, 603, 808, 281, 341, 13, 51314, 51314, 440, 27706, 1389, 562, 288, 307, 27706, 307, 264, 1858, 1389, 11, 1392, 11, 293, 321, 600, 1217, 2825, 51543, 51543, 466, 341, 293, 286, 603, 733, 295, 8290, 5256, 341, 294, 2115, 295, 2281, 294, 445, 257, 1916, 2077, 13, 51808, 51808], "temperature": 0.0, "avg_logprob": -0.25676925895140346, "compression_ratio": 1.575, "no_speech_prob": 1.3006249901081901e-05}, {"id": 135, "seek": 60788, "start": 607.88, "end": 616.08, "text": " Okay, so a feedforward model is an explicit function in that it computes the prediction", "tokens": [50364, 1033, 11, 370, 257, 3154, 13305, 2316, 307, 364, 13691, 2445, 294, 300, 309, 715, 1819, 264, 17630, 50774, 50774, 288, 490, 2031, 457, 309, 393, 787, 652, 472, 17630, 13, 50945, 50945, 492, 393, 17470, 294, 264, 1389, 295, 257, 27706, 7006, 538, 3372, 484, 3866, 23930, 597, 6805, 51191, 51191, 281, 257, 6175, 337, 633, 1944, 21538, 13, 51418, 51418, 583, 294, 1802, 11, 457, 291, 393, 380, 764, 341, 4282, 337, 1090, 18795, 10957, 4190, 420, 51636, 51636, 10199, 2628, 4190, 382, 286, 848, 3071, 13, 51848, 51848], "temperature": 0.0, "avg_logprob": -0.1261452192901283, "compression_ratio": 1.608, "no_speech_prob": 6.539215974044055e-06}, {"id": 136, "seek": 60788, "start": 616.08, "end": 619.5, "text": " y from x but it can only make one prediction.", "tokens": [50364, 1033, 11, 370, 257, 3154, 13305, 2316, 307, 364, 13691, 2445, 294, 300, 309, 715, 1819, 264, 17630, 50774, 50774, 288, 490, 2031, 457, 309, 393, 787, 652, 472, 17630, 13, 50945, 50945, 492, 393, 17470, 294, 264, 1389, 295, 257, 27706, 7006, 538, 3372, 484, 3866, 23930, 597, 6805, 51191, 51191, 281, 257, 6175, 337, 633, 1944, 21538, 13, 51418, 51418, 583, 294, 1802, 11, 457, 291, 393, 380, 764, 341, 4282, 337, 1090, 18795, 10957, 4190, 420, 51636, 51636, 10199, 2628, 4190, 382, 286, 848, 3071, 13, 51848, 51848], "temperature": 0.0, "avg_logprob": -0.1261452192901283, "compression_ratio": 1.608, "no_speech_prob": 6.539215974044055e-06}, {"id": 137, "seek": 60788, "start": 619.5, "end": 624.42, "text": " We can cheat in the case of a discrete variable by putting out multiple outputs which correspond", "tokens": [50364, 1033, 11, 370, 257, 3154, 13305, 2316, 307, 364, 13691, 2445, 294, 300, 309, 715, 1819, 264, 17630, 50774, 50774, 288, 490, 2031, 457, 309, 393, 787, 652, 472, 17630, 13, 50945, 50945, 492, 393, 17470, 294, 264, 1389, 295, 257, 27706, 7006, 538, 3372, 484, 3866, 23930, 597, 6805, 51191, 51191, 281, 257, 6175, 337, 633, 1944, 21538, 13, 51418, 51418, 583, 294, 1802, 11, 457, 291, 393, 380, 764, 341, 4282, 337, 1090, 18795, 10957, 4190, 420, 51636, 51636, 10199, 2628, 4190, 382, 286, 848, 3071, 13, 51848, 51848], "temperature": 0.0, "avg_logprob": -0.1261452192901283, "compression_ratio": 1.608, "no_speech_prob": 6.539215974044055e-06}, {"id": 138, "seek": 60788, "start": 624.42, "end": 628.96, "text": " to a score for every possible classification.", "tokens": [50364, 1033, 11, 370, 257, 3154, 13305, 2316, 307, 364, 13691, 2445, 294, 300, 309, 715, 1819, 264, 17630, 50774, 50774, 288, 490, 2031, 457, 309, 393, 787, 652, 472, 17630, 13, 50945, 50945, 492, 393, 17470, 294, 264, 1389, 295, 257, 27706, 7006, 538, 3372, 484, 3866, 23930, 597, 6805, 51191, 51191, 281, 257, 6175, 337, 633, 1944, 21538, 13, 51418, 51418, 583, 294, 1802, 11, 457, 291, 393, 380, 764, 341, 4282, 337, 1090, 18795, 10957, 4190, 420, 51636, 51636, 10199, 2628, 4190, 382, 286, 848, 3071, 13, 51848, 51848], "temperature": 0.0, "avg_logprob": -0.1261452192901283, "compression_ratio": 1.608, "no_speech_prob": 6.539215974044055e-06}, {"id": 139, "seek": 60788, "start": 628.96, "end": 633.32, "text": " But in effect, but you can't use this trick for high dimensional continuous values or", "tokens": [50364, 1033, 11, 370, 257, 3154, 13305, 2316, 307, 364, 13691, 2445, 294, 300, 309, 715, 1819, 264, 17630, 50774, 50774, 288, 490, 2031, 457, 309, 393, 787, 652, 472, 17630, 13, 50945, 50945, 492, 393, 17470, 294, 264, 1389, 295, 257, 27706, 7006, 538, 3372, 484, 3866, 23930, 597, 6805, 51191, 51191, 281, 257, 6175, 337, 633, 1944, 21538, 13, 51418, 51418, 583, 294, 1802, 11, 457, 291, 393, 380, 764, 341, 4282, 337, 1090, 18795, 10957, 4190, 420, 51636, 51636, 10199, 2628, 4190, 382, 286, 848, 3071, 13, 51848, 51848], "temperature": 0.0, "avg_logprob": -0.1261452192901283, "compression_ratio": 1.608, "no_speech_prob": 6.539215974044055e-06}, {"id": 140, "seek": 60788, "start": 633.32, "end": 637.56, "text": " compositional values as I said earlier.", "tokens": [50364, 1033, 11, 370, 257, 3154, 13305, 2316, 307, 364, 13691, 2445, 294, 300, 309, 715, 1819, 264, 17630, 50774, 50774, 288, 490, 2031, 457, 309, 393, 787, 652, 472, 17630, 13, 50945, 50945, 492, 393, 17470, 294, 264, 1389, 295, 257, 27706, 7006, 538, 3372, 484, 3866, 23930, 597, 6805, 51191, 51191, 281, 257, 6175, 337, 633, 1944, 21538, 13, 51418, 51418, 583, 294, 1802, 11, 457, 291, 393, 380, 764, 341, 4282, 337, 1090, 18795, 10957, 4190, 420, 51636, 51636, 10199, 2628, 4190, 382, 286, 848, 3071, 13, 51848, 51848], "temperature": 0.0, "avg_logprob": -0.1261452192901283, "compression_ratio": 1.608, "no_speech_prob": 6.539215974044055e-06}, {"id": 141, "seek": 63756, "start": 637.56, "end": 640.78, "text": " So an energy-based model is really an implicit function.", "tokens": [50364, 407, 364, 2281, 12, 6032, 2316, 307, 534, 364, 26947, 2445, 13, 50525, 50525, 407, 1604, 11, 291, 458, 11, 294, 33400, 562, 364, 26947, 2445, 291, 528, 264, 5367, 295, 50742, 50742, 257, 6329, 382, 257, 2445, 295, 2031, 293, 288, 13, 50878, 50878, 509, 393, 380, 2464, 288, 382, 257, 2445, 295, 2031, 13, 51000, 51000, 509, 2464, 364, 5367, 300, 1619, 2031, 8889, 1804, 288, 8889, 6915, 472, 293, 300, 2709, 291, 51258, 51258, 264, 4985, 6329, 13, 51387, 51387, 407, 2031, 8889, 1804, 288, 8889, 3175, 472, 307, 364, 26947, 2445, 13, 51752, 51752], "temperature": 0.0, "avg_logprob": -0.17062265396118165, "compression_ratio": 1.958974358974359, "no_speech_prob": 1.0449661203892902e-05}, {"id": 142, "seek": 63756, "start": 640.78, "end": 645.1199999999999, "text": " So remember, you know, in calculus when an implicit function you want the equation of", "tokens": [50364, 407, 364, 2281, 12, 6032, 2316, 307, 534, 364, 26947, 2445, 13, 50525, 50525, 407, 1604, 11, 291, 458, 11, 294, 33400, 562, 364, 26947, 2445, 291, 528, 264, 5367, 295, 50742, 50742, 257, 6329, 382, 257, 2445, 295, 2031, 293, 288, 13, 50878, 50878, 509, 393, 380, 2464, 288, 382, 257, 2445, 295, 2031, 13, 51000, 51000, 509, 2464, 364, 5367, 300, 1619, 2031, 8889, 1804, 288, 8889, 6915, 472, 293, 300, 2709, 291, 51258, 51258, 264, 4985, 6329, 13, 51387, 51387, 407, 2031, 8889, 1804, 288, 8889, 3175, 472, 307, 364, 26947, 2445, 13, 51752, 51752], "temperature": 0.0, "avg_logprob": -0.17062265396118165, "compression_ratio": 1.958974358974359, "no_speech_prob": 1.0449661203892902e-05}, {"id": 143, "seek": 63756, "start": 645.1199999999999, "end": 647.8399999999999, "text": " a circle as a function of x and y.", "tokens": [50364, 407, 364, 2281, 12, 6032, 2316, 307, 534, 364, 26947, 2445, 13, 50525, 50525, 407, 1604, 11, 291, 458, 11, 294, 33400, 562, 364, 26947, 2445, 291, 528, 264, 5367, 295, 50742, 50742, 257, 6329, 382, 257, 2445, 295, 2031, 293, 288, 13, 50878, 50878, 509, 393, 380, 2464, 288, 382, 257, 2445, 295, 2031, 13, 51000, 51000, 509, 2464, 364, 5367, 300, 1619, 2031, 8889, 1804, 288, 8889, 6915, 472, 293, 300, 2709, 291, 51258, 51258, 264, 4985, 6329, 13, 51387, 51387, 407, 2031, 8889, 1804, 288, 8889, 3175, 472, 307, 364, 26947, 2445, 13, 51752, 51752], "temperature": 0.0, "avg_logprob": -0.17062265396118165, "compression_ratio": 1.958974358974359, "no_speech_prob": 1.0449661203892902e-05}, {"id": 144, "seek": 63756, "start": 647.8399999999999, "end": 650.28, "text": " You can't write y as a function of x.", "tokens": [50364, 407, 364, 2281, 12, 6032, 2316, 307, 534, 364, 26947, 2445, 13, 50525, 50525, 407, 1604, 11, 291, 458, 11, 294, 33400, 562, 364, 26947, 2445, 291, 528, 264, 5367, 295, 50742, 50742, 257, 6329, 382, 257, 2445, 295, 2031, 293, 288, 13, 50878, 50878, 509, 393, 380, 2464, 288, 382, 257, 2445, 295, 2031, 13, 51000, 51000, 509, 2464, 364, 5367, 300, 1619, 2031, 8889, 1804, 288, 8889, 6915, 472, 293, 300, 2709, 291, 51258, 51258, 264, 4985, 6329, 13, 51387, 51387, 407, 2031, 8889, 1804, 288, 8889, 3175, 472, 307, 364, 26947, 2445, 13, 51752, 51752], "temperature": 0.0, "avg_logprob": -0.17062265396118165, "compression_ratio": 1.958974358974359, "no_speech_prob": 1.0449661203892902e-05}, {"id": 145, "seek": 63756, "start": 650.28, "end": 655.4399999999999, "text": " You write an equation that says x squared plus y squared equals one and that gives you", "tokens": [50364, 407, 364, 2281, 12, 6032, 2316, 307, 534, 364, 26947, 2445, 13, 50525, 50525, 407, 1604, 11, 291, 458, 11, 294, 33400, 562, 364, 26947, 2445, 291, 528, 264, 5367, 295, 50742, 50742, 257, 6329, 382, 257, 2445, 295, 2031, 293, 288, 13, 50878, 50878, 509, 393, 380, 2464, 288, 382, 257, 2445, 295, 2031, 13, 51000, 51000, 509, 2464, 364, 5367, 300, 1619, 2031, 8889, 1804, 288, 8889, 6915, 472, 293, 300, 2709, 291, 51258, 51258, 264, 4985, 6329, 13, 51387, 51387, 407, 2031, 8889, 1804, 288, 8889, 3175, 472, 307, 364, 26947, 2445, 13, 51752, 51752], "temperature": 0.0, "avg_logprob": -0.17062265396118165, "compression_ratio": 1.958974358974359, "no_speech_prob": 1.0449661203892902e-05}, {"id": 146, "seek": 63756, "start": 655.4399999999999, "end": 658.02, "text": " the unit circle.", "tokens": [50364, 407, 364, 2281, 12, 6032, 2316, 307, 534, 364, 26947, 2445, 13, 50525, 50525, 407, 1604, 11, 291, 458, 11, 294, 33400, 562, 364, 26947, 2445, 291, 528, 264, 5367, 295, 50742, 50742, 257, 6329, 382, 257, 2445, 295, 2031, 293, 288, 13, 50878, 50878, 509, 393, 380, 2464, 288, 382, 257, 2445, 295, 2031, 13, 51000, 51000, 509, 2464, 364, 5367, 300, 1619, 2031, 8889, 1804, 288, 8889, 6915, 472, 293, 300, 2709, 291, 51258, 51258, 264, 4985, 6329, 13, 51387, 51387, 407, 2031, 8889, 1804, 288, 8889, 3175, 472, 307, 364, 26947, 2445, 13, 51752, 51752], "temperature": 0.0, "avg_logprob": -0.17062265396118165, "compression_ratio": 1.958974358974359, "no_speech_prob": 1.0449661203892902e-05}, {"id": 147, "seek": 63756, "start": 658.02, "end": 665.3199999999999, "text": " So x squared plus y squared minus one is an implicit function.", "tokens": [50364, 407, 364, 2281, 12, 6032, 2316, 307, 534, 364, 26947, 2445, 13, 50525, 50525, 407, 1604, 11, 291, 458, 11, 294, 33400, 562, 364, 26947, 2445, 291, 528, 264, 5367, 295, 50742, 50742, 257, 6329, 382, 257, 2445, 295, 2031, 293, 288, 13, 50878, 50878, 509, 393, 380, 2464, 288, 382, 257, 2445, 295, 2031, 13, 51000, 51000, 509, 2464, 364, 5367, 300, 1619, 2031, 8889, 1804, 288, 8889, 6915, 472, 293, 300, 2709, 291, 51258, 51258, 264, 4985, 6329, 13, 51387, 51387, 407, 2031, 8889, 1804, 288, 8889, 3175, 472, 307, 364, 26947, 2445, 13, 51752, 51752], "temperature": 0.0, "avg_logprob": -0.17062265396118165, "compression_ratio": 1.958974358974359, "no_speech_prob": 1.0449661203892902e-05}, {"id": 148, "seek": 66532, "start": 665.32, "end": 674.5200000000001, "text": " And when you solve it equal to zero, you get the circle.", "tokens": [50364, 400, 562, 291, 5039, 309, 2681, 281, 4018, 11, 291, 483, 264, 6329, 13, 50824, 50824, 407, 510, 311, 1071, 1365, 510, 13, 50912, 50912, 3764, 11, 39684, 4190, 337, 2031, 293, 288, 293, 264, 2211, 15026, 510, 366, 1412, 2793, 13, 51286, 51286, 407, 337, 264, 1045, 2158, 295, 2031, 16176, 538, 264, 2182, 2159, 11, 456, 311, 3866, 2158, 295, 288, 300, 51608, 51608], "temperature": 0.0, "avg_logprob": -0.13886269401101506, "compression_ratio": 1.5182926829268293, "no_speech_prob": 4.5657443479285575e-06}, {"id": 149, "seek": 66532, "start": 674.5200000000001, "end": 676.2800000000001, "text": " So here's another example here.", "tokens": [50364, 400, 562, 291, 5039, 309, 2681, 281, 4018, 11, 291, 483, 264, 6329, 13, 50824, 50824, 407, 510, 311, 1071, 1365, 510, 13, 50912, 50912, 3764, 11, 39684, 4190, 337, 2031, 293, 288, 293, 264, 2211, 15026, 510, 366, 1412, 2793, 13, 51286, 51286, 407, 337, 264, 1045, 2158, 295, 2031, 16176, 538, 264, 2182, 2159, 11, 456, 311, 3866, 2158, 295, 288, 300, 51608, 51608], "temperature": 0.0, "avg_logprob": -0.13886269401101506, "compression_ratio": 1.5182926829268293, "no_speech_prob": 4.5657443479285575e-06}, {"id": 150, "seek": 66532, "start": 676.2800000000001, "end": 683.7600000000001, "text": " Again, scalar values for x and y and the black dots here are data points.", "tokens": [50364, 400, 562, 291, 5039, 309, 2681, 281, 4018, 11, 291, 483, 264, 6329, 13, 50824, 50824, 407, 510, 311, 1071, 1365, 510, 13, 50912, 50912, 3764, 11, 39684, 4190, 337, 2031, 293, 288, 293, 264, 2211, 15026, 510, 366, 1412, 2793, 13, 51286, 51286, 407, 337, 264, 1045, 2158, 295, 2031, 16176, 538, 264, 2182, 2159, 11, 456, 311, 3866, 2158, 295, 288, 300, 51608, 51608], "temperature": 0.0, "avg_logprob": -0.13886269401101506, "compression_ratio": 1.5182926829268293, "no_speech_prob": 4.5657443479285575e-06}, {"id": 151, "seek": 66532, "start": 683.7600000000001, "end": 690.2, "text": " So for the three value of x indicated by the red bar, there's multiple value of y that", "tokens": [50364, 400, 562, 291, 5039, 309, 2681, 281, 4018, 11, 291, 483, 264, 6329, 13, 50824, 50824, 407, 510, 311, 1071, 1365, 510, 13, 50912, 50912, 3764, 11, 39684, 4190, 337, 2031, 293, 288, 293, 264, 2211, 15026, 510, 366, 1412, 2793, 13, 51286, 51286, 407, 337, 264, 1045, 2158, 295, 2031, 16176, 538, 264, 2182, 2159, 11, 456, 311, 3866, 2158, 295, 288, 300, 51608, 51608], "temperature": 0.0, "avg_logprob": -0.13886269401101506, "compression_ratio": 1.5182926829268293, "no_speech_prob": 4.5657443479285575e-06}, {"id": 152, "seek": 69020, "start": 690.2, "end": 699.1600000000001, "text": " are compatible and some of them are actually sort of a continuum of values.", "tokens": [50364, 366, 18218, 293, 512, 295, 552, 366, 767, 1333, 295, 257, 36120, 295, 4190, 13, 50812, 50812, 407, 437, 321, 1116, 411, 527, 2281, 2445, 281, 312, 307, 746, 300, 1542, 411, 341, 13, 51036, 51036, 467, 311, 1936, 510, 286, 478, 1333, 295, 6316, 264, 1333, 295, 1496, 6352, 295, 300, 2281, 2445, 13, 51460, 51460, 407, 309, 2516, 2295, 2281, 322, 264, 1412, 2793, 293, 2946, 2281, 2380, 13, 51602, 51602], "temperature": 0.0, "avg_logprob": -0.13969802856445312, "compression_ratio": 1.6455026455026456, "no_speech_prob": 1.0782511708384845e-05}, {"id": 153, "seek": 69020, "start": 699.1600000000001, "end": 703.6400000000001, "text": " So what we'd like our energy function to be is something that looks like this.", "tokens": [50364, 366, 18218, 293, 512, 295, 552, 366, 767, 1333, 295, 257, 36120, 295, 4190, 13, 50812, 50812, 407, 437, 321, 1116, 411, 527, 2281, 2445, 281, 312, 307, 746, 300, 1542, 411, 341, 13, 51036, 51036, 467, 311, 1936, 510, 286, 478, 1333, 295, 6316, 264, 1333, 295, 1496, 6352, 295, 300, 2281, 2445, 13, 51460, 51460, 407, 309, 2516, 2295, 2281, 322, 264, 1412, 2793, 293, 2946, 2281, 2380, 13, 51602, 51602], "temperature": 0.0, "avg_logprob": -0.13969802856445312, "compression_ratio": 1.6455026455026456, "no_speech_prob": 1.0782511708384845e-05}, {"id": 154, "seek": 69020, "start": 703.6400000000001, "end": 712.12, "text": " It's basically here I'm sort of drawing the sort of level sets of that energy function.", "tokens": [50364, 366, 18218, 293, 512, 295, 552, 366, 767, 1333, 295, 257, 36120, 295, 4190, 13, 50812, 50812, 407, 437, 321, 1116, 411, 527, 2281, 2445, 281, 312, 307, 746, 300, 1542, 411, 341, 13, 51036, 51036, 467, 311, 1936, 510, 286, 478, 1333, 295, 6316, 264, 1333, 295, 1496, 6352, 295, 300, 2281, 2445, 13, 51460, 51460, 407, 309, 2516, 2295, 2281, 322, 264, 1412, 2793, 293, 2946, 2281, 2380, 13, 51602, 51602], "temperature": 0.0, "avg_logprob": -0.13969802856445312, "compression_ratio": 1.6455026455026456, "no_speech_prob": 1.0782511708384845e-05}, {"id": 155, "seek": 69020, "start": 712.12, "end": 714.96, "text": " So it takes low energy on the data points and higher energy outside.", "tokens": [50364, 366, 18218, 293, 512, 295, 552, 366, 767, 1333, 295, 257, 36120, 295, 4190, 13, 50812, 50812, 407, 437, 321, 1116, 411, 527, 2281, 2445, 281, 312, 307, 746, 300, 1542, 411, 341, 13, 51036, 51036, 467, 311, 1936, 510, 286, 478, 1333, 295, 6316, 264, 1333, 295, 1496, 6352, 295, 300, 2281, 2445, 13, 51460, 51460, 407, 309, 2516, 2295, 2281, 322, 264, 1412, 2793, 293, 2946, 2281, 2380, 13, 51602, 51602], "temperature": 0.0, "avg_logprob": -0.13969802856445312, "compression_ratio": 1.6455026455026456, "no_speech_prob": 1.0782511708384845e-05}, {"id": 156, "seek": 71496, "start": 714.96, "end": 721.36, "text": " This is kind of a slightly more complicated version of the little kind of 3D models that", "tokens": [50364, 639, 307, 733, 295, 257, 4748, 544, 6179, 3037, 295, 264, 707, 733, 295, 805, 35, 5245, 300, 50684, 50684, 286, 4712, 3071, 13, 50968, 50968, 400, 264, 1168, 307, 577, 360, 321, 3847, 257, 1185, 370, 300, 309, 22486, 1373, 11, 370, 300, 264, 2281, 2445, 51270, 51270, 309, 715, 1819, 767, 575, 264, 2296, 3909, 30, 51632, 51632], "temperature": 0.0, "avg_logprob": -0.17379873029647336, "compression_ratio": 1.4606060606060607, "no_speech_prob": 1.5206008356472012e-05}, {"id": 157, "seek": 71496, "start": 721.36, "end": 727.0400000000001, "text": " I showed earlier.", "tokens": [50364, 639, 307, 733, 295, 257, 4748, 544, 6179, 3037, 295, 264, 707, 733, 295, 805, 35, 5245, 300, 50684, 50684, 286, 4712, 3071, 13, 50968, 50968, 400, 264, 1168, 307, 577, 360, 321, 3847, 257, 1185, 370, 300, 309, 22486, 1373, 11, 370, 300, 264, 2281, 2445, 51270, 51270, 309, 715, 1819, 767, 575, 264, 2296, 3909, 30, 51632, 51632], "temperature": 0.0, "avg_logprob": -0.17379873029647336, "compression_ratio": 1.4606060606060607, "no_speech_prob": 1.5206008356472012e-05}, {"id": 158, "seek": 71496, "start": 727.0400000000001, "end": 733.08, "text": " And the question is how do we train a system so that it adopts, so that the energy function", "tokens": [50364, 639, 307, 733, 295, 257, 4748, 544, 6179, 3037, 295, 264, 707, 733, 295, 805, 35, 5245, 300, 50684, 50684, 286, 4712, 3071, 13, 50968, 50968, 400, 264, 1168, 307, 577, 360, 321, 3847, 257, 1185, 370, 300, 309, 22486, 1373, 11, 370, 300, 264, 2281, 2445, 51270, 51270, 309, 715, 1819, 767, 575, 264, 2296, 3909, 30, 51632, 51632], "temperature": 0.0, "avg_logprob": -0.17379873029647336, "compression_ratio": 1.4606060606060607, "no_speech_prob": 1.5206008356472012e-05}, {"id": 159, "seek": 71496, "start": 733.08, "end": 740.32, "text": " it computes actually has the proper shape?", "tokens": [50364, 639, 307, 733, 295, 257, 4748, 544, 6179, 3037, 295, 264, 707, 733, 295, 805, 35, 5245, 300, 50684, 50684, 286, 4712, 3071, 13, 50968, 50968, 400, 264, 1168, 307, 577, 360, 321, 3847, 257, 1185, 370, 300, 309, 22486, 1373, 11, 370, 300, 264, 2281, 2445, 51270, 51270, 309, 715, 1819, 767, 575, 264, 2296, 3909, 30, 51632, 51632], "temperature": 0.0, "avg_logprob": -0.17379873029647336, "compression_ratio": 1.4606060606060607, "no_speech_prob": 1.5206008356472012e-05}, {"id": 160, "seek": 74032, "start": 740.32, "end": 747.32, "text": " It's nice when y is continuous that f be smooth and differentiable so that we can use gradient", "tokens": [50364, 467, 311, 1481, 562, 288, 307, 10957, 300, 283, 312, 5508, 293, 819, 9364, 370, 300, 321, 393, 764, 16235, 50714, 50714, 2361, 38253, 14642, 13, 50782, 50782, 407, 498, 321, 362, 257, 2445, 411, 341, 293, 286, 976, 291, 257, 935, 2031, 11, 288, 11, 291, 393, 11, 807, 16235, 51012, 51012, 23475, 11, 291, 393, 915, 264, 935, 322, 264, 1412, 47138, 300, 307, 13699, 281, 309, 420, 746, 51194, 51194, 2531, 281, 300, 13, 51277, 51277, 759, 286, 976, 291, 257, 2158, 337, 2031, 11, 291, 393, 3164, 538, 16235, 23475, 2051, 264, 288, 3513, 51548, 51548, 337, 257, 2158, 300, 733, 295, 4464, 5660, 309, 13, 51646, 51646, 407, 300, 311, 264, 38253, 9284, 13, 51736, 51736], "temperature": 0.0, "avg_logprob": -0.14423775091403868, "compression_ratio": 1.8068181818181819, "no_speech_prob": 2.5065870431717485e-05}, {"id": 161, "seek": 74032, "start": 747.32, "end": 748.6800000000001, "text": " based inference algorithms.", "tokens": [50364, 467, 311, 1481, 562, 288, 307, 10957, 300, 283, 312, 5508, 293, 819, 9364, 370, 300, 321, 393, 764, 16235, 50714, 50714, 2361, 38253, 14642, 13, 50782, 50782, 407, 498, 321, 362, 257, 2445, 411, 341, 293, 286, 976, 291, 257, 935, 2031, 11, 288, 11, 291, 393, 11, 807, 16235, 51012, 51012, 23475, 11, 291, 393, 915, 264, 935, 322, 264, 1412, 47138, 300, 307, 13699, 281, 309, 420, 746, 51194, 51194, 2531, 281, 300, 13, 51277, 51277, 759, 286, 976, 291, 257, 2158, 337, 2031, 11, 291, 393, 3164, 538, 16235, 23475, 2051, 264, 288, 3513, 51548, 51548, 337, 257, 2158, 300, 733, 295, 4464, 5660, 309, 13, 51646, 51646, 407, 300, 311, 264, 38253, 9284, 13, 51736, 51736], "temperature": 0.0, "avg_logprob": -0.14423775091403868, "compression_ratio": 1.8068181818181819, "no_speech_prob": 2.5065870431717485e-05}, {"id": 162, "seek": 74032, "start": 748.6800000000001, "end": 753.2800000000001, "text": " So if we have a function like this and I give you a point x, y, you can, through gradient", "tokens": [50364, 467, 311, 1481, 562, 288, 307, 10957, 300, 283, 312, 5508, 293, 819, 9364, 370, 300, 321, 393, 764, 16235, 50714, 50714, 2361, 38253, 14642, 13, 50782, 50782, 407, 498, 321, 362, 257, 2445, 411, 341, 293, 286, 976, 291, 257, 935, 2031, 11, 288, 11, 291, 393, 11, 807, 16235, 51012, 51012, 23475, 11, 291, 393, 915, 264, 935, 322, 264, 1412, 47138, 300, 307, 13699, 281, 309, 420, 746, 51194, 51194, 2531, 281, 300, 13, 51277, 51277, 759, 286, 976, 291, 257, 2158, 337, 2031, 11, 291, 393, 3164, 538, 16235, 23475, 2051, 264, 288, 3513, 51548, 51548, 337, 257, 2158, 300, 733, 295, 4464, 5660, 309, 13, 51646, 51646, 407, 300, 311, 264, 38253, 9284, 13, 51736, 51736], "temperature": 0.0, "avg_logprob": -0.14423775091403868, "compression_ratio": 1.8068181818181819, "no_speech_prob": 2.5065870431717485e-05}, {"id": 163, "seek": 74032, "start": 753.2800000000001, "end": 756.9200000000001, "text": " descent, you can find the point on the data manifold that is closest to it or something", "tokens": [50364, 467, 311, 1481, 562, 288, 307, 10957, 300, 283, 312, 5508, 293, 819, 9364, 370, 300, 321, 393, 764, 16235, 50714, 50714, 2361, 38253, 14642, 13, 50782, 50782, 407, 498, 321, 362, 257, 2445, 411, 341, 293, 286, 976, 291, 257, 935, 2031, 11, 288, 11, 291, 393, 11, 807, 16235, 51012, 51012, 23475, 11, 291, 393, 915, 264, 935, 322, 264, 1412, 47138, 300, 307, 13699, 281, 309, 420, 746, 51194, 51194, 2531, 281, 300, 13, 51277, 51277, 759, 286, 976, 291, 257, 2158, 337, 2031, 11, 291, 393, 3164, 538, 16235, 23475, 2051, 264, 288, 3513, 51548, 51548, 337, 257, 2158, 300, 733, 295, 4464, 5660, 309, 13, 51646, 51646, 407, 300, 311, 264, 38253, 9284, 13, 51736, 51736], "temperature": 0.0, "avg_logprob": -0.14423775091403868, "compression_ratio": 1.8068181818181819, "no_speech_prob": 2.5065870431717485e-05}, {"id": 164, "seek": 74032, "start": 756.9200000000001, "end": 758.58, "text": " similar to that.", "tokens": [50364, 467, 311, 1481, 562, 288, 307, 10957, 300, 283, 312, 5508, 293, 819, 9364, 370, 300, 321, 393, 764, 16235, 50714, 50714, 2361, 38253, 14642, 13, 50782, 50782, 407, 498, 321, 362, 257, 2445, 411, 341, 293, 286, 976, 291, 257, 935, 2031, 11, 288, 11, 291, 393, 11, 807, 16235, 51012, 51012, 23475, 11, 291, 393, 915, 264, 935, 322, 264, 1412, 47138, 300, 307, 13699, 281, 309, 420, 746, 51194, 51194, 2531, 281, 300, 13, 51277, 51277, 759, 286, 976, 291, 257, 2158, 337, 2031, 11, 291, 393, 3164, 538, 16235, 23475, 2051, 264, 288, 3513, 51548, 51548, 337, 257, 2158, 300, 733, 295, 4464, 5660, 309, 13, 51646, 51646, 407, 300, 311, 264, 38253, 9284, 13, 51736, 51736], "temperature": 0.0, "avg_logprob": -0.14423775091403868, "compression_ratio": 1.8068181818181819, "no_speech_prob": 2.5065870431717485e-05}, {"id": 165, "seek": 74032, "start": 758.58, "end": 764.0, "text": " If I give you a value for x, you can search by gradient descent along the y direction", "tokens": [50364, 467, 311, 1481, 562, 288, 307, 10957, 300, 283, 312, 5508, 293, 819, 9364, 370, 300, 321, 393, 764, 16235, 50714, 50714, 2361, 38253, 14642, 13, 50782, 50782, 407, 498, 321, 362, 257, 2445, 411, 341, 293, 286, 976, 291, 257, 935, 2031, 11, 288, 11, 291, 393, 11, 807, 16235, 51012, 51012, 23475, 11, 291, 393, 915, 264, 935, 322, 264, 1412, 47138, 300, 307, 13699, 281, 309, 420, 746, 51194, 51194, 2531, 281, 300, 13, 51277, 51277, 759, 286, 976, 291, 257, 2158, 337, 2031, 11, 291, 393, 3164, 538, 16235, 23475, 2051, 264, 288, 3513, 51548, 51548, 337, 257, 2158, 300, 733, 295, 4464, 5660, 309, 13, 51646, 51646, 407, 300, 311, 264, 38253, 9284, 13, 51736, 51736], "temperature": 0.0, "avg_logprob": -0.14423775091403868, "compression_ratio": 1.8068181818181819, "no_speech_prob": 2.5065870431717485e-05}, {"id": 166, "seek": 74032, "start": 764.0, "end": 765.96, "text": " for a value that kind of minimizes it.", "tokens": [50364, 467, 311, 1481, 562, 288, 307, 10957, 300, 283, 312, 5508, 293, 819, 9364, 370, 300, 321, 393, 764, 16235, 50714, 50714, 2361, 38253, 14642, 13, 50782, 50782, 407, 498, 321, 362, 257, 2445, 411, 341, 293, 286, 976, 291, 257, 935, 2031, 11, 288, 11, 291, 393, 11, 807, 16235, 51012, 51012, 23475, 11, 291, 393, 915, 264, 935, 322, 264, 1412, 47138, 300, 307, 13699, 281, 309, 420, 746, 51194, 51194, 2531, 281, 300, 13, 51277, 51277, 759, 286, 976, 291, 257, 2158, 337, 2031, 11, 291, 393, 3164, 538, 16235, 23475, 2051, 264, 288, 3513, 51548, 51548, 337, 257, 2158, 300, 733, 295, 4464, 5660, 309, 13, 51646, 51646, 407, 300, 311, 264, 38253, 9284, 13, 51736, 51736], "temperature": 0.0, "avg_logprob": -0.14423775091403868, "compression_ratio": 1.8068181818181819, "no_speech_prob": 2.5065870431717485e-05}, {"id": 167, "seek": 74032, "start": 765.96, "end": 767.7600000000001, "text": " So that's the inference algorithm.", "tokens": [50364, 467, 311, 1481, 562, 288, 307, 10957, 300, 283, 312, 5508, 293, 819, 9364, 370, 300, 321, 393, 764, 16235, 50714, 50714, 2361, 38253, 14642, 13, 50782, 50782, 407, 498, 321, 362, 257, 2445, 411, 341, 293, 286, 976, 291, 257, 935, 2031, 11, 288, 11, 291, 393, 11, 807, 16235, 51012, 51012, 23475, 11, 291, 393, 915, 264, 935, 322, 264, 1412, 47138, 300, 307, 13699, 281, 309, 420, 746, 51194, 51194, 2531, 281, 300, 13, 51277, 51277, 759, 286, 976, 291, 257, 2158, 337, 2031, 11, 291, 393, 3164, 538, 16235, 23475, 2051, 264, 288, 3513, 51548, 51548, 337, 257, 2158, 300, 733, 295, 4464, 5660, 309, 13, 51646, 51646, 407, 300, 311, 264, 38253, 9284, 13, 51736, 51736], "temperature": 0.0, "avg_logprob": -0.14423775091403868, "compression_ratio": 1.8068181818181819, "no_speech_prob": 2.5065870431717485e-05}, {"id": 168, "seek": 76776, "start": 767.76, "end": 772.04, "text": " Well it's not an algorithm, it's really a prescription.", "tokens": [50364, 1042, 309, 311, 406, 364, 9284, 11, 309, 311, 534, 257, 22456, 13, 50578, 50578, 1396, 264, 9284, 307, 577, 291, 360, 341, 4464, 2144, 13, 50742, 50742, 400, 337, 300, 456, 311, 439, 3685, 295, 819, 7150, 13, 50892, 50892, 16710, 1196, 2361, 7150, 366, 472, 295, 552, 13, 51028, 51028, 821, 366, 439, 3685, 295, 7150, 300, 366, 294, 264, 1389, 689, 283, 307, 6179, 11, 291, 815, 406, 51310, 51310, 362, 11, 309, 815, 406, 312, 1944, 281, 10687, 322, 1270, 7150, 370, 291, 815, 362, 281, 764, 661, 11733, 13, 51828, 51828], "temperature": 0.0, "avg_logprob": -0.17888287135532924, "compression_ratio": 1.7104072398190044, "no_speech_prob": 2.8406311685102992e-05}, {"id": 169, "seek": 76776, "start": 772.04, "end": 775.3199999999999, "text": " Then the algorithm is how you do this minimization.", "tokens": [50364, 1042, 309, 311, 406, 364, 9284, 11, 309, 311, 534, 257, 22456, 13, 50578, 50578, 1396, 264, 9284, 307, 577, 291, 360, 341, 4464, 2144, 13, 50742, 50742, 400, 337, 300, 456, 311, 439, 3685, 295, 819, 7150, 13, 50892, 50892, 16710, 1196, 2361, 7150, 366, 472, 295, 552, 13, 51028, 51028, 821, 366, 439, 3685, 295, 7150, 300, 366, 294, 264, 1389, 689, 283, 307, 6179, 11, 291, 815, 406, 51310, 51310, 362, 11, 309, 815, 406, 312, 1944, 281, 10687, 322, 1270, 7150, 370, 291, 815, 362, 281, 764, 661, 11733, 13, 51828, 51828], "temperature": 0.0, "avg_logprob": -0.17888287135532924, "compression_ratio": 1.7104072398190044, "no_speech_prob": 2.8406311685102992e-05}, {"id": 170, "seek": 76776, "start": 775.3199999999999, "end": 778.3199999999999, "text": " And for that there's all kinds of different methods.", "tokens": [50364, 1042, 309, 311, 406, 364, 9284, 11, 309, 311, 534, 257, 22456, 13, 50578, 50578, 1396, 264, 9284, 307, 577, 291, 360, 341, 4464, 2144, 13, 50742, 50742, 400, 337, 300, 456, 311, 439, 3685, 295, 819, 7150, 13, 50892, 50892, 16710, 1196, 2361, 7150, 366, 472, 295, 552, 13, 51028, 51028, 821, 366, 439, 3685, 295, 7150, 300, 366, 294, 264, 1389, 689, 283, 307, 6179, 11, 291, 815, 406, 51310, 51310, 362, 11, 309, 815, 406, 312, 1944, 281, 10687, 322, 1270, 7150, 370, 291, 815, 362, 281, 764, 661, 11733, 13, 51828, 51828], "temperature": 0.0, "avg_logprob": -0.17888287135532924, "compression_ratio": 1.7104072398190044, "no_speech_prob": 2.8406311685102992e-05}, {"id": 171, "seek": 76776, "start": 778.3199999999999, "end": 781.04, "text": " Gradient based methods are one of them.", "tokens": [50364, 1042, 309, 311, 406, 364, 9284, 11, 309, 311, 534, 257, 22456, 13, 50578, 50578, 1396, 264, 9284, 307, 577, 291, 360, 341, 4464, 2144, 13, 50742, 50742, 400, 337, 300, 456, 311, 439, 3685, 295, 819, 7150, 13, 50892, 50892, 16710, 1196, 2361, 7150, 366, 472, 295, 552, 13, 51028, 51028, 821, 366, 439, 3685, 295, 7150, 300, 366, 294, 264, 1389, 689, 283, 307, 6179, 11, 291, 815, 406, 51310, 51310, 362, 11, 309, 815, 406, 312, 1944, 281, 10687, 322, 1270, 7150, 370, 291, 815, 362, 281, 764, 661, 11733, 13, 51828, 51828], "temperature": 0.0, "avg_logprob": -0.17888287135532924, "compression_ratio": 1.7104072398190044, "no_speech_prob": 2.8406311685102992e-05}, {"id": 172, "seek": 76776, "start": 781.04, "end": 786.68, "text": " There are all kinds of methods that are in the case where f is complicated, you may not", "tokens": [50364, 1042, 309, 311, 406, 364, 9284, 11, 309, 311, 534, 257, 22456, 13, 50578, 50578, 1396, 264, 9284, 307, 577, 291, 360, 341, 4464, 2144, 13, 50742, 50742, 400, 337, 300, 456, 311, 439, 3685, 295, 819, 7150, 13, 50892, 50892, 16710, 1196, 2361, 7150, 366, 472, 295, 552, 13, 51028, 51028, 821, 366, 439, 3685, 295, 7150, 300, 366, 294, 264, 1389, 689, 283, 307, 6179, 11, 291, 815, 406, 51310, 51310, 362, 11, 309, 815, 406, 312, 1944, 281, 10687, 322, 1270, 7150, 370, 291, 815, 362, 281, 764, 661, 11733, 13, 51828, 51828], "temperature": 0.0, "avg_logprob": -0.17888287135532924, "compression_ratio": 1.7104072398190044, "no_speech_prob": 2.8406311685102992e-05}, {"id": 173, "seek": 76776, "start": 786.68, "end": 797.04, "text": " have, it may not be possible to rely on such methods so you may have to use other tricks.", "tokens": [50364, 1042, 309, 311, 406, 364, 9284, 11, 309, 311, 534, 257, 22456, 13, 50578, 50578, 1396, 264, 9284, 307, 577, 291, 360, 341, 4464, 2144, 13, 50742, 50742, 400, 337, 300, 456, 311, 439, 3685, 295, 819, 7150, 13, 50892, 50892, 16710, 1196, 2361, 7150, 366, 472, 295, 552, 13, 51028, 51028, 821, 366, 439, 3685, 295, 7150, 300, 366, 294, 264, 1389, 689, 283, 307, 6179, 11, 291, 815, 406, 51310, 51310, 362, 11, 309, 815, 406, 312, 1944, 281, 10687, 322, 1270, 7150, 370, 291, 815, 362, 281, 764, 661, 11733, 13, 51828, 51828], "temperature": 0.0, "avg_logprob": -0.17888287135532924, "compression_ratio": 1.7104072398190044, "no_speech_prob": 2.8406311685102992e-05}, {"id": 174, "seek": 79704, "start": 797.04, "end": 800.8399999999999, "text": " In most cases though it simplifies.", "tokens": [50364, 682, 881, 3331, 1673, 309, 6883, 11221, 13, 50554, 50554, 407, 445, 382, 364, 7359, 11, 337, 729, 295, 291, 567, 458, 437, 35942, 5245, 366, 11, 257, 35942, 50748, 50748, 2316, 307, 1936, 364, 2281, 2361, 2316, 689, 264, 2281, 2445, 22867, 4201, 382, 257, 2408, 295, 51104, 51104, 2281, 2115, 293, 1184, 2281, 1433, 2516, 666, 2696, 257, 25993, 295, 264, 9102, 300, 291, 434, 51404, 51404, 6260, 365, 13, 51490, 51490, 407, 456, 576, 312, 733, 295, 257, 5765, 295, 283, 311, 293, 512, 283, 311, 576, 747, 257, 25993, 295, 288, 11, 512, 51820, 51820], "temperature": 0.0, "avg_logprob": -0.12196200909000812, "compression_ratio": 1.735042735042735, "no_speech_prob": 2.07814355235314e-05}, {"id": 175, "seek": 79704, "start": 800.8399999999999, "end": 804.7199999999999, "text": " So just as an aside, for those of you who know what graphical models are, a graphical", "tokens": [50364, 682, 881, 3331, 1673, 309, 6883, 11221, 13, 50554, 50554, 407, 445, 382, 364, 7359, 11, 337, 729, 295, 291, 567, 458, 437, 35942, 5245, 366, 11, 257, 35942, 50748, 50748, 2316, 307, 1936, 364, 2281, 2361, 2316, 689, 264, 2281, 2445, 22867, 4201, 382, 257, 2408, 295, 51104, 51104, 2281, 2115, 293, 1184, 2281, 1433, 2516, 666, 2696, 257, 25993, 295, 264, 9102, 300, 291, 434, 51404, 51404, 6260, 365, 13, 51490, 51490, 407, 456, 576, 312, 733, 295, 257, 5765, 295, 283, 311, 293, 512, 283, 311, 576, 747, 257, 25993, 295, 288, 11, 512, 51820, 51820], "temperature": 0.0, "avg_logprob": -0.12196200909000812, "compression_ratio": 1.735042735042735, "no_speech_prob": 2.07814355235314e-05}, {"id": 176, "seek": 79704, "start": 804.7199999999999, "end": 811.8399999999999, "text": " model is basically an energy based model where the energy function decomposes as a sum of", "tokens": [50364, 682, 881, 3331, 1673, 309, 6883, 11221, 13, 50554, 50554, 407, 445, 382, 364, 7359, 11, 337, 729, 295, 291, 567, 458, 437, 35942, 5245, 366, 11, 257, 35942, 50748, 50748, 2316, 307, 1936, 364, 2281, 2361, 2316, 689, 264, 2281, 2445, 22867, 4201, 382, 257, 2408, 295, 51104, 51104, 2281, 2115, 293, 1184, 2281, 1433, 2516, 666, 2696, 257, 25993, 295, 264, 9102, 300, 291, 434, 51404, 51404, 6260, 365, 13, 51490, 51490, 407, 456, 576, 312, 733, 295, 257, 5765, 295, 283, 311, 293, 512, 283, 311, 576, 747, 257, 25993, 295, 288, 11, 512, 51820, 51820], "temperature": 0.0, "avg_logprob": -0.12196200909000812, "compression_ratio": 1.735042735042735, "no_speech_prob": 2.07814355235314e-05}, {"id": 177, "seek": 79704, "start": 811.8399999999999, "end": 817.8399999999999, "text": " energy terms and each energy term takes into account a subset of the variables that you're", "tokens": [50364, 682, 881, 3331, 1673, 309, 6883, 11221, 13, 50554, 50554, 407, 445, 382, 364, 7359, 11, 337, 729, 295, 291, 567, 458, 437, 35942, 5245, 366, 11, 257, 35942, 50748, 50748, 2316, 307, 1936, 364, 2281, 2361, 2316, 689, 264, 2281, 2445, 22867, 4201, 382, 257, 2408, 295, 51104, 51104, 2281, 2115, 293, 1184, 2281, 1433, 2516, 666, 2696, 257, 25993, 295, 264, 9102, 300, 291, 434, 51404, 51404, 6260, 365, 13, 51490, 51490, 407, 456, 576, 312, 733, 295, 257, 5765, 295, 283, 311, 293, 512, 283, 311, 576, 747, 257, 25993, 295, 288, 11, 512, 51820, 51820], "temperature": 0.0, "avg_logprob": -0.12196200909000812, "compression_ratio": 1.735042735042735, "no_speech_prob": 2.07814355235314e-05}, {"id": 178, "seek": 79704, "start": 817.8399999999999, "end": 819.56, "text": " dealing with.", "tokens": [50364, 682, 881, 3331, 1673, 309, 6883, 11221, 13, 50554, 50554, 407, 445, 382, 364, 7359, 11, 337, 729, 295, 291, 567, 458, 437, 35942, 5245, 366, 11, 257, 35942, 50748, 50748, 2316, 307, 1936, 364, 2281, 2361, 2316, 689, 264, 2281, 2445, 22867, 4201, 382, 257, 2408, 295, 51104, 51104, 2281, 2115, 293, 1184, 2281, 1433, 2516, 666, 2696, 257, 25993, 295, 264, 9102, 300, 291, 434, 51404, 51404, 6260, 365, 13, 51490, 51490, 407, 456, 576, 312, 733, 295, 257, 5765, 295, 283, 311, 293, 512, 283, 311, 576, 747, 257, 25993, 295, 288, 11, 512, 51820, 51820], "temperature": 0.0, "avg_logprob": -0.12196200909000812, "compression_ratio": 1.735042735042735, "no_speech_prob": 2.07814355235314e-05}, {"id": 179, "seek": 79704, "start": 819.56, "end": 826.16, "text": " So there would be kind of a collection of f's and some f's would take a subset of y, some", "tokens": [50364, 682, 881, 3331, 1673, 309, 6883, 11221, 13, 50554, 50554, 407, 445, 382, 364, 7359, 11, 337, 729, 295, 291, 567, 458, 437, 35942, 5245, 366, 11, 257, 35942, 50748, 50748, 2316, 307, 1936, 364, 2281, 2361, 2316, 689, 264, 2281, 2445, 22867, 4201, 382, 257, 2408, 295, 51104, 51104, 2281, 2115, 293, 1184, 2281, 1433, 2516, 666, 2696, 257, 25993, 295, 264, 9102, 300, 291, 434, 51404, 51404, 6260, 365, 13, 51490, 51490, 407, 456, 576, 312, 733, 295, 257, 5765, 295, 283, 311, 293, 512, 283, 311, 576, 747, 257, 25993, 295, 288, 11, 512, 51820, 51820], "temperature": 0.0, "avg_logprob": -0.12196200909000812, "compression_ratio": 1.735042735042735, "no_speech_prob": 2.07814355235314e-05}, {"id": 180, "seek": 82616, "start": 826.16, "end": 829.52, "text": " f's would take a subset of x and y's, etc.", "tokens": [50364, 283, 311, 576, 747, 257, 25993, 295, 2031, 293, 288, 311, 11, 5183, 13, 50532, 50532, 400, 498, 436, 13859, 294, 257, 1729, 1254, 550, 456, 366, 7148, 38253, 14642, 50772, 50772, 281, 915, 264, 7285, 295, 264, 2408, 295, 729, 2115, 365, 3104, 281, 264, 7006, 291, 434, 3102, 50964, 50964, 294, 13596, 2937, 13, 51134, 51134, 407, 341, 307, 437, 7107, 38377, 293, 439, 729, 14642, 360, 294, 35942, 5245, 13, 51443, 51443, 639, 307, 364, 7359, 11, 498, 291, 500, 380, 458, 437, 286, 478, 1417, 466, 309, 1177, 380, 1871, 13, 51838, 51838], "temperature": 0.0, "avg_logprob": -0.17375946044921875, "compression_ratio": 1.5833333333333333, "no_speech_prob": 1.260383396584075e-05}, {"id": 181, "seek": 82616, "start": 829.52, "end": 834.3199999999999, "text": " And if they organize in a particular form then there are efficient inference algorithms", "tokens": [50364, 283, 311, 576, 747, 257, 25993, 295, 2031, 293, 288, 311, 11, 5183, 13, 50532, 50532, 400, 498, 436, 13859, 294, 257, 1729, 1254, 550, 456, 366, 7148, 38253, 14642, 50772, 50772, 281, 915, 264, 7285, 295, 264, 2408, 295, 729, 2115, 365, 3104, 281, 264, 7006, 291, 434, 3102, 50964, 50964, 294, 13596, 2937, 13, 51134, 51134, 407, 341, 307, 437, 7107, 38377, 293, 439, 729, 14642, 360, 294, 35942, 5245, 13, 51443, 51443, 639, 307, 364, 7359, 11, 498, 291, 500, 380, 458, 437, 286, 478, 1417, 466, 309, 1177, 380, 1871, 13, 51838, 51838], "temperature": 0.0, "avg_logprob": -0.17375946044921875, "compression_ratio": 1.5833333333333333, "no_speech_prob": 1.260383396584075e-05}, {"id": 182, "seek": 82616, "start": 834.3199999999999, "end": 838.16, "text": " to find the minimum of the sum of those terms with respect to the variable you're interested", "tokens": [50364, 283, 311, 576, 747, 257, 25993, 295, 2031, 293, 288, 311, 11, 5183, 13, 50532, 50532, 400, 498, 436, 13859, 294, 257, 1729, 1254, 550, 456, 366, 7148, 38253, 14642, 50772, 50772, 281, 915, 264, 7285, 295, 264, 2408, 295, 729, 2115, 365, 3104, 281, 264, 7006, 291, 434, 3102, 50964, 50964, 294, 13596, 2937, 13, 51134, 51134, 407, 341, 307, 437, 7107, 38377, 293, 439, 729, 14642, 360, 294, 35942, 5245, 13, 51443, 51443, 639, 307, 364, 7359, 11, 498, 291, 500, 380, 458, 437, 286, 478, 1417, 466, 309, 1177, 380, 1871, 13, 51838, 51838], "temperature": 0.0, "avg_logprob": -0.17375946044921875, "compression_ratio": 1.5833333333333333, "no_speech_prob": 1.260383396584075e-05}, {"id": 183, "seek": 82616, "start": 838.16, "end": 841.56, "text": " in inferring.", "tokens": [50364, 283, 311, 576, 747, 257, 25993, 295, 2031, 293, 288, 311, 11, 5183, 13, 50532, 50532, 400, 498, 436, 13859, 294, 257, 1729, 1254, 550, 456, 366, 7148, 38253, 14642, 50772, 50772, 281, 915, 264, 7285, 295, 264, 2408, 295, 729, 2115, 365, 3104, 281, 264, 7006, 291, 434, 3102, 50964, 50964, 294, 13596, 2937, 13, 51134, 51134, 407, 341, 307, 437, 7107, 38377, 293, 439, 729, 14642, 360, 294, 35942, 5245, 13, 51443, 51443, 639, 307, 364, 7359, 11, 498, 291, 500, 380, 458, 437, 286, 478, 1417, 466, 309, 1177, 380, 1871, 13, 51838, 51838], "temperature": 0.0, "avg_logprob": -0.17375946044921875, "compression_ratio": 1.5833333333333333, "no_speech_prob": 1.260383396584075e-05}, {"id": 184, "seek": 82616, "start": 841.56, "end": 847.74, "text": " So this is what belief propagation and all those algorithms do in graphical models.", "tokens": [50364, 283, 311, 576, 747, 257, 25993, 295, 2031, 293, 288, 311, 11, 5183, 13, 50532, 50532, 400, 498, 436, 13859, 294, 257, 1729, 1254, 550, 456, 366, 7148, 38253, 14642, 50772, 50772, 281, 915, 264, 7285, 295, 264, 2408, 295, 729, 2115, 365, 3104, 281, 264, 7006, 291, 434, 3102, 50964, 50964, 294, 13596, 2937, 13, 51134, 51134, 407, 341, 307, 437, 7107, 38377, 293, 439, 729, 14642, 360, 294, 35942, 5245, 13, 51443, 51443, 639, 307, 364, 7359, 11, 498, 291, 500, 380, 458, 437, 286, 478, 1417, 466, 309, 1177, 380, 1871, 13, 51838, 51838], "temperature": 0.0, "avg_logprob": -0.17375946044921875, "compression_ratio": 1.5833333333333333, "no_speech_prob": 1.260383396584075e-05}, {"id": 185, "seek": 82616, "start": 847.74, "end": 855.64, "text": " This is an aside, if you don't know what I'm talking about it doesn't matter.", "tokens": [50364, 283, 311, 576, 747, 257, 25993, 295, 2031, 293, 288, 311, 11, 5183, 13, 50532, 50532, 400, 498, 436, 13859, 294, 257, 1729, 1254, 550, 456, 366, 7148, 38253, 14642, 50772, 50772, 281, 915, 264, 7285, 295, 264, 2408, 295, 729, 2115, 365, 3104, 281, 264, 7006, 291, 434, 3102, 50964, 50964, 294, 13596, 2937, 13, 51134, 51134, 407, 341, 307, 437, 7107, 38377, 293, 439, 729, 14642, 360, 294, 35942, 5245, 13, 51443, 51443, 639, 307, 364, 7359, 11, 498, 291, 500, 380, 458, 437, 286, 478, 1417, 466, 309, 1177, 380, 1871, 13, 51838, 51838], "temperature": 0.0, "avg_logprob": -0.17375946044921875, "compression_ratio": 1.5833333333333333, "no_speech_prob": 1.260383396584075e-05}, {"id": 186, "seek": 85564, "start": 855.64, "end": 865.4, "text": " So as I said, the situations where you might want to use this is when inference basically", "tokens": [50364, 407, 382, 286, 848, 11, 264, 6851, 689, 291, 1062, 528, 281, 764, 341, 307, 562, 38253, 1936, 50852, 50852, 307, 544, 3997, 813, 445, 2614, 807, 257, 1326, 7914, 295, 18161, 2533, 13, 51138, 51138, 1133, 264, 5598, 307, 1090, 18795, 293, 575, 3877, 411, 257, 8310, 420, 364, 3256, 420, 257, 51412, 51412, 8310, 295, 5267, 597, 307, 257, 960, 13, 51540, 51540, 1133, 264, 5598, 575, 10199, 2628, 3877, 1968, 309, 311, 2487, 11, 3069, 22978, 11, 721, 51767, 51767], "temperature": 0.0, "avg_logprob": -0.16347797618192786, "compression_ratio": 1.6787330316742082, "no_speech_prob": 2.3535811124020256e-05}, {"id": 187, "seek": 85564, "start": 865.4, "end": 871.12, "text": " is more complex than just running through a few layers of neural net.", "tokens": [50364, 407, 382, 286, 848, 11, 264, 6851, 689, 291, 1062, 528, 281, 764, 341, 307, 562, 38253, 1936, 50852, 50852, 307, 544, 3997, 813, 445, 2614, 807, 257, 1326, 7914, 295, 18161, 2533, 13, 51138, 51138, 1133, 264, 5598, 307, 1090, 18795, 293, 575, 3877, 411, 257, 8310, 420, 364, 3256, 420, 257, 51412, 51412, 8310, 295, 5267, 597, 307, 257, 960, 13, 51540, 51540, 1133, 264, 5598, 575, 10199, 2628, 3877, 1968, 309, 311, 2487, 11, 3069, 22978, 11, 721, 51767, 51767], "temperature": 0.0, "avg_logprob": -0.16347797618192786, "compression_ratio": 1.6787330316742082, "no_speech_prob": 2.3535811124020256e-05}, {"id": 188, "seek": 85564, "start": 871.12, "end": 876.6, "text": " When the output is high dimensional and has structure like a sequence or an image or a", "tokens": [50364, 407, 382, 286, 848, 11, 264, 6851, 689, 291, 1062, 528, 281, 764, 341, 307, 562, 38253, 1936, 50852, 50852, 307, 544, 3997, 813, 445, 2614, 807, 257, 1326, 7914, 295, 18161, 2533, 13, 51138, 51138, 1133, 264, 5598, 307, 1090, 18795, 293, 575, 3877, 411, 257, 8310, 420, 364, 3256, 420, 257, 51412, 51412, 8310, 295, 5267, 597, 307, 257, 960, 13, 51540, 51540, 1133, 264, 5598, 575, 10199, 2628, 3877, 1968, 309, 311, 2487, 11, 3069, 22978, 11, 721, 51767, 51767], "temperature": 0.0, "avg_logprob": -0.16347797618192786, "compression_ratio": 1.6787330316742082, "no_speech_prob": 2.3535811124020256e-05}, {"id": 189, "seek": 85564, "start": 876.6, "end": 879.16, "text": " sequence of images which is a video.", "tokens": [50364, 407, 382, 286, 848, 11, 264, 6851, 689, 291, 1062, 528, 281, 764, 341, 307, 562, 38253, 1936, 50852, 50852, 307, 544, 3997, 813, 445, 2614, 807, 257, 1326, 7914, 295, 18161, 2533, 13, 51138, 51138, 1133, 264, 5598, 307, 1090, 18795, 293, 575, 3877, 411, 257, 8310, 420, 364, 3256, 420, 257, 51412, 51412, 8310, 295, 5267, 597, 307, 257, 960, 13, 51540, 51540, 1133, 264, 5598, 575, 10199, 2628, 3877, 1968, 309, 311, 2487, 11, 3069, 22978, 11, 721, 51767, 51767], "temperature": 0.0, "avg_logprob": -0.16347797618192786, "compression_ratio": 1.6787330316742082, "no_speech_prob": 2.3535811124020256e-05}, {"id": 190, "seek": 85564, "start": 879.16, "end": 883.7, "text": " When the output has compositional structure whether it's text, action sequences, things", "tokens": [50364, 407, 382, 286, 848, 11, 264, 6851, 689, 291, 1062, 528, 281, 764, 341, 307, 562, 38253, 1936, 50852, 50852, 307, 544, 3997, 813, 445, 2614, 807, 257, 1326, 7914, 295, 18161, 2533, 13, 51138, 51138, 1133, 264, 5598, 307, 1090, 18795, 293, 575, 3877, 411, 257, 8310, 420, 364, 3256, 420, 257, 51412, 51412, 8310, 295, 5267, 597, 307, 257, 960, 13, 51540, 51540, 1133, 264, 5598, 575, 10199, 2628, 3877, 1968, 309, 311, 2487, 11, 3069, 22978, 11, 721, 51767, 51767], "temperature": 0.0, "avg_logprob": -0.16347797618192786, "compression_ratio": 1.6787330316742082, "no_speech_prob": 2.3535811124020256e-05}, {"id": 191, "seek": 88370, "start": 883.7, "end": 886.2800000000001, "text": " like that.", "tokens": [50364, 411, 300, 13, 50493, 50493, 1610, 562, 264, 5598, 820, 1874, 490, 1333, 295, 257, 938, 5021, 295, 21577, 13, 50729, 50729, 407, 309, 311, 406, 445, 11, 291, 458, 11, 286, 393, 445, 14722, 264, 5598, 291, 643, 281, 733, 295, 5039, 257, 25534, 50953, 50953, 18715, 1154, 281, 1936, 5258, 264, 5598, 420, 360, 733, 295, 938, 12626, 295, 21577, 13, 51377, 51377], "temperature": 0.0, "avg_logprob": -0.193079293663822, "compression_ratio": 1.625, "no_speech_prob": 1.240939036506461e-05}, {"id": 192, "seek": 88370, "start": 886.2800000000001, "end": 891.0, "text": " Or when the output should result from sort of a long chain of reasoning.", "tokens": [50364, 411, 300, 13, 50493, 50493, 1610, 562, 264, 5598, 820, 1874, 490, 1333, 295, 257, 938, 5021, 295, 21577, 13, 50729, 50729, 407, 309, 311, 406, 445, 11, 291, 458, 11, 286, 393, 445, 14722, 264, 5598, 291, 643, 281, 733, 295, 5039, 257, 25534, 50953, 50953, 18715, 1154, 281, 1936, 5258, 264, 5598, 420, 360, 733, 295, 938, 12626, 295, 21577, 13, 51377, 51377], "temperature": 0.0, "avg_logprob": -0.193079293663822, "compression_ratio": 1.625, "no_speech_prob": 1.240939036506461e-05}, {"id": 193, "seek": 88370, "start": 891.0, "end": 895.48, "text": " So it's not just, you know, I can just compute the output you need to kind of solve a constraint", "tokens": [50364, 411, 300, 13, 50493, 50493, 1610, 562, 264, 5598, 820, 1874, 490, 1333, 295, 257, 938, 5021, 295, 21577, 13, 50729, 50729, 407, 309, 311, 406, 445, 11, 291, 458, 11, 286, 393, 445, 14722, 264, 5598, 291, 643, 281, 733, 295, 5039, 257, 25534, 50953, 50953, 18715, 1154, 281, 1936, 5258, 264, 5598, 420, 360, 733, 295, 938, 12626, 295, 21577, 13, 51377, 51377], "temperature": 0.0, "avg_logprob": -0.193079293663822, "compression_ratio": 1.625, "no_speech_prob": 1.240939036506461e-05}, {"id": 194, "seek": 88370, "start": 895.48, "end": 903.96, "text": " satisfaction problem to basically produce the output or do kind of long chains of reasoning.", "tokens": [50364, 411, 300, 13, 50493, 50493, 1610, 562, 264, 5598, 820, 1874, 490, 1333, 295, 257, 938, 5021, 295, 21577, 13, 50729, 50729, 407, 309, 311, 406, 445, 11, 291, 458, 11, 286, 393, 445, 14722, 264, 5598, 291, 643, 281, 733, 295, 5039, 257, 25534, 50953, 50953, 18715, 1154, 281, 1936, 5258, 264, 5598, 420, 360, 733, 295, 938, 12626, 295, 21577, 13, 51377, 51377], "temperature": 0.0, "avg_logprob": -0.193079293663822, "compression_ratio": 1.625, "no_speech_prob": 1.240939036506461e-05}, {"id": 195, "seek": 90396, "start": 903.96, "end": 915.24, "text": " Okay, there's a particular type of energy-based models which is really where they start becoming", "tokens": [50364, 1033, 11, 456, 311, 257, 1729, 2010, 295, 2281, 12, 6032, 5245, 597, 307, 534, 689, 436, 722, 5617, 50928, 50928, 1880, 307, 2281, 12, 6032, 2316, 293, 3288, 48994, 9102, 13, 51204, 51204, 407, 364, 2281, 12, 6032, 2316, 300, 5946, 322, 48994, 7006, 11, 257, 48994, 7006, 15733, 44, 294, 341, 1389, 51688, 51688], "temperature": 0.0, "avg_logprob": -0.28500737815067684, "compression_ratio": 1.6601307189542485, "no_speech_prob": 2.5855586500256322e-05}, {"id": 196, "seek": 90396, "start": 915.24, "end": 920.76, "text": " interesting is energy-based model and involved latent variables.", "tokens": [50364, 1033, 11, 456, 311, 257, 1729, 2010, 295, 2281, 12, 6032, 5245, 597, 307, 534, 689, 436, 722, 5617, 50928, 50928, 1880, 307, 2281, 12, 6032, 2316, 293, 3288, 48994, 9102, 13, 51204, 51204, 407, 364, 2281, 12, 6032, 2316, 300, 5946, 322, 48994, 7006, 11, 257, 48994, 7006, 15733, 44, 294, 341, 1389, 51688, 51688], "temperature": 0.0, "avg_logprob": -0.28500737815067684, "compression_ratio": 1.6601307189542485, "no_speech_prob": 2.5855586500256322e-05}, {"id": 197, "seek": 90396, "start": 920.76, "end": 930.44, "text": " So an energy-based model that depends on latent variable, a latent variable EVM in this case", "tokens": [50364, 1033, 11, 456, 311, 257, 1729, 2010, 295, 2281, 12, 6032, 5245, 597, 307, 534, 689, 436, 722, 5617, 50928, 50928, 1880, 307, 2281, 12, 6032, 2316, 293, 3288, 48994, 9102, 13, 51204, 51204, 407, 364, 2281, 12, 6032, 2316, 300, 5946, 322, 48994, 7006, 11, 257, 48994, 7006, 15733, 44, 294, 341, 1389, 51688, 51688], "temperature": 0.0, "avg_logprob": -0.28500737815067684, "compression_ratio": 1.6601307189542485, "no_speech_prob": 2.5855586500256322e-05}, {"id": 198, "seek": 93044, "start": 930.44, "end": 934.2, "text": " would depend not just on the variable that you observe X and the variable you want to", "tokens": [50364, 576, 5672, 406, 445, 322, 264, 7006, 300, 291, 11441, 1783, 293, 264, 7006, 291, 528, 281, 50552, 50552, 6069, 398, 457, 611, 576, 5672, 322, 512, 2857, 7006, 1176, 300, 5079, 5112, 291, 264, 2158, 50748, 50748, 295, 13, 50828, 50828, 1033, 30, 50924, 50924, 400, 264, 636, 291, 764, 341, 48994, 7006, 307, 300, 291, 1322, 428, 2316, 294, 1270, 257, 636, 300, 51314, 51314, 309, 5946, 322, 264, 48994, 7006, 300, 498, 291, 2586, 264, 2158, 295, 264, 48994, 7006, 51508, 51508, 264, 38253, 1154, 576, 1813, 3571, 13, 51702, 51702], "temperature": 0.0, "avg_logprob": -0.17243961493174234, "compression_ratio": 1.9047619047619047, "no_speech_prob": 7.070207175274845e-06}, {"id": 199, "seek": 93044, "start": 934.2, "end": 938.12, "text": " predict Y but also would depend on some extra variable Z that nobody tells you the value", "tokens": [50364, 576, 5672, 406, 445, 322, 264, 7006, 300, 291, 11441, 1783, 293, 264, 7006, 291, 528, 281, 50552, 50552, 6069, 398, 457, 611, 576, 5672, 322, 512, 2857, 7006, 1176, 300, 5079, 5112, 291, 264, 2158, 50748, 50748, 295, 13, 50828, 50828, 1033, 30, 50924, 50924, 400, 264, 636, 291, 764, 341, 48994, 7006, 307, 300, 291, 1322, 428, 2316, 294, 1270, 257, 636, 300, 51314, 51314, 309, 5946, 322, 264, 48994, 7006, 300, 498, 291, 2586, 264, 2158, 295, 264, 48994, 7006, 51508, 51508, 264, 38253, 1154, 576, 1813, 3571, 13, 51702, 51702], "temperature": 0.0, "avg_logprob": -0.17243961493174234, "compression_ratio": 1.9047619047619047, "no_speech_prob": 7.070207175274845e-06}, {"id": 200, "seek": 93044, "start": 938.12, "end": 939.72, "text": " of.", "tokens": [50364, 576, 5672, 406, 445, 322, 264, 7006, 300, 291, 11441, 1783, 293, 264, 7006, 291, 528, 281, 50552, 50552, 6069, 398, 457, 611, 576, 5672, 322, 512, 2857, 7006, 1176, 300, 5079, 5112, 291, 264, 2158, 50748, 50748, 295, 13, 50828, 50828, 1033, 30, 50924, 50924, 400, 264, 636, 291, 764, 341, 48994, 7006, 307, 300, 291, 1322, 428, 2316, 294, 1270, 257, 636, 300, 51314, 51314, 309, 5946, 322, 264, 48994, 7006, 300, 498, 291, 2586, 264, 2158, 295, 264, 48994, 7006, 51508, 51508, 264, 38253, 1154, 576, 1813, 3571, 13, 51702, 51702], "temperature": 0.0, "avg_logprob": -0.17243961493174234, "compression_ratio": 1.9047619047619047, "no_speech_prob": 7.070207175274845e-06}, {"id": 201, "seek": 93044, "start": 939.72, "end": 941.6400000000001, "text": " Okay?", "tokens": [50364, 576, 5672, 406, 445, 322, 264, 7006, 300, 291, 11441, 1783, 293, 264, 7006, 291, 528, 281, 50552, 50552, 6069, 398, 457, 611, 576, 5672, 322, 512, 2857, 7006, 1176, 300, 5079, 5112, 291, 264, 2158, 50748, 50748, 295, 13, 50828, 50828, 1033, 30, 50924, 50924, 400, 264, 636, 291, 764, 341, 48994, 7006, 307, 300, 291, 1322, 428, 2316, 294, 1270, 257, 636, 300, 51314, 51314, 309, 5946, 322, 264, 48994, 7006, 300, 498, 291, 2586, 264, 2158, 295, 264, 48994, 7006, 51508, 51508, 264, 38253, 1154, 576, 1813, 3571, 13, 51702, 51702], "temperature": 0.0, "avg_logprob": -0.17243961493174234, "compression_ratio": 1.9047619047619047, "no_speech_prob": 7.070207175274845e-06}, {"id": 202, "seek": 93044, "start": 941.6400000000001, "end": 949.44, "text": " And the way you use this latent variable is that you build your model in such a way that", "tokens": [50364, 576, 5672, 406, 445, 322, 264, 7006, 300, 291, 11441, 1783, 293, 264, 7006, 291, 528, 281, 50552, 50552, 6069, 398, 457, 611, 576, 5672, 322, 512, 2857, 7006, 1176, 300, 5079, 5112, 291, 264, 2158, 50748, 50748, 295, 13, 50828, 50828, 1033, 30, 50924, 50924, 400, 264, 636, 291, 764, 341, 48994, 7006, 307, 300, 291, 1322, 428, 2316, 294, 1270, 257, 636, 300, 51314, 51314, 309, 5946, 322, 264, 48994, 7006, 300, 498, 291, 2586, 264, 2158, 295, 264, 48994, 7006, 51508, 51508, 264, 38253, 1154, 576, 1813, 3571, 13, 51702, 51702], "temperature": 0.0, "avg_logprob": -0.17243961493174234, "compression_ratio": 1.9047619047619047, "no_speech_prob": 7.070207175274845e-06}, {"id": 203, "seek": 93044, "start": 949.44, "end": 953.32, "text": " it depends on the latent variable that if you knew the value of the latent variable", "tokens": [50364, 576, 5672, 406, 445, 322, 264, 7006, 300, 291, 11441, 1783, 293, 264, 7006, 291, 528, 281, 50552, 50552, 6069, 398, 457, 611, 576, 5672, 322, 512, 2857, 7006, 1176, 300, 5079, 5112, 291, 264, 2158, 50748, 50748, 295, 13, 50828, 50828, 1033, 30, 50924, 50924, 400, 264, 636, 291, 764, 341, 48994, 7006, 307, 300, 291, 1322, 428, 2316, 294, 1270, 257, 636, 300, 51314, 51314, 309, 5946, 322, 264, 48994, 7006, 300, 498, 291, 2586, 264, 2158, 295, 264, 48994, 7006, 51508, 51508, 264, 38253, 1154, 576, 1813, 3571, 13, 51702, 51702], "temperature": 0.0, "avg_logprob": -0.17243961493174234, "compression_ratio": 1.9047619047619047, "no_speech_prob": 7.070207175274845e-06}, {"id": 204, "seek": 93044, "start": 953.32, "end": 957.2, "text": " the inference problem would become easier.", "tokens": [50364, 576, 5672, 406, 445, 322, 264, 7006, 300, 291, 11441, 1783, 293, 264, 7006, 291, 528, 281, 50552, 50552, 6069, 398, 457, 611, 576, 5672, 322, 512, 2857, 7006, 1176, 300, 5079, 5112, 291, 264, 2158, 50748, 50748, 295, 13, 50828, 50828, 1033, 30, 50924, 50924, 400, 264, 636, 291, 764, 341, 48994, 7006, 307, 300, 291, 1322, 428, 2316, 294, 1270, 257, 636, 300, 51314, 51314, 309, 5946, 322, 264, 48994, 7006, 300, 498, 291, 2586, 264, 2158, 295, 264, 48994, 7006, 51508, 51508, 264, 38253, 1154, 576, 1813, 3571, 13, 51702, 51702], "temperature": 0.0, "avg_logprob": -0.17243961493174234, "compression_ratio": 1.9047619047619047, "no_speech_prob": 7.070207175274845e-06}, {"id": 205, "seek": 95720, "start": 957.2, "end": 963.1600000000001, "text": " So let's say you want to do handwriting recognition and I like this example which I told you about", "tokens": [50364, 407, 718, 311, 584, 291, 528, 281, 360, 39179, 11150, 293, 286, 411, 341, 1365, 597, 286, 1907, 291, 466, 50662, 50662, 1217, 13, 50728, 50728, 759, 291, 458, 689, 264, 4342, 366, 11, 3760, 341, 1349, 3643, 709, 3571, 13, 51000, 51000, 1033, 30, 51098, 51098, 440, 2135, 1154, 510, 294, 3760, 341, 1349, 307, 406, 445, 281, 1401, 264, 2609, 4342, 51274, 51274, 457, 281, 767, 2573, 484, 689, 264, 4342, 366, 11, 411, 689, 472, 2517, 5314, 11, 689, 51490, 51490, 264, 661, 472, 7338, 13, 51540, 51540], "temperature": 0.0, "avg_logprob": -0.14964109851467994, "compression_ratio": 1.7612612612612613, "no_speech_prob": 4.63771812064806e-06}, {"id": 206, "seek": 95720, "start": 963.1600000000001, "end": 964.48, "text": " already.", "tokens": [50364, 407, 718, 311, 584, 291, 528, 281, 360, 39179, 11150, 293, 286, 411, 341, 1365, 597, 286, 1907, 291, 466, 50662, 50662, 1217, 13, 50728, 50728, 759, 291, 458, 689, 264, 4342, 366, 11, 3760, 341, 1349, 3643, 709, 3571, 13, 51000, 51000, 1033, 30, 51098, 51098, 440, 2135, 1154, 510, 294, 3760, 341, 1349, 307, 406, 445, 281, 1401, 264, 2609, 4342, 51274, 51274, 457, 281, 767, 2573, 484, 689, 264, 4342, 366, 11, 411, 689, 472, 2517, 5314, 11, 689, 51490, 51490, 264, 661, 472, 7338, 13, 51540, 51540], "temperature": 0.0, "avg_logprob": -0.14964109851467994, "compression_ratio": 1.7612612612612613, "no_speech_prob": 4.63771812064806e-06}, {"id": 207, "seek": 95720, "start": 964.48, "end": 969.9200000000001, "text": " If you know where the characters are, reading this word becomes much easier.", "tokens": [50364, 407, 718, 311, 584, 291, 528, 281, 360, 39179, 11150, 293, 286, 411, 341, 1365, 597, 286, 1907, 291, 466, 50662, 50662, 1217, 13, 50728, 50728, 759, 291, 458, 689, 264, 4342, 366, 11, 3760, 341, 1349, 3643, 709, 3571, 13, 51000, 51000, 1033, 30, 51098, 51098, 440, 2135, 1154, 510, 294, 3760, 341, 1349, 307, 406, 445, 281, 1401, 264, 2609, 4342, 51274, 51274, 457, 281, 767, 2573, 484, 689, 264, 4342, 366, 11, 411, 689, 472, 2517, 5314, 11, 689, 51490, 51490, 264, 661, 472, 7338, 13, 51540, 51540], "temperature": 0.0, "avg_logprob": -0.14964109851467994, "compression_ratio": 1.7612612612612613, "no_speech_prob": 4.63771812064806e-06}, {"id": 208, "seek": 95720, "start": 969.9200000000001, "end": 971.88, "text": " Okay?", "tokens": [50364, 407, 718, 311, 584, 291, 528, 281, 360, 39179, 11150, 293, 286, 411, 341, 1365, 597, 286, 1907, 291, 466, 50662, 50662, 1217, 13, 50728, 50728, 759, 291, 458, 689, 264, 4342, 366, 11, 3760, 341, 1349, 3643, 709, 3571, 13, 51000, 51000, 1033, 30, 51098, 51098, 440, 2135, 1154, 510, 294, 3760, 341, 1349, 307, 406, 445, 281, 1401, 264, 2609, 4342, 51274, 51274, 457, 281, 767, 2573, 484, 689, 264, 4342, 366, 11, 411, 689, 472, 2517, 5314, 11, 689, 51490, 51490, 264, 661, 472, 7338, 13, 51540, 51540], "temperature": 0.0, "avg_logprob": -0.14964109851467994, "compression_ratio": 1.7612612612612613, "no_speech_prob": 4.63771812064806e-06}, {"id": 209, "seek": 95720, "start": 971.88, "end": 975.4000000000001, "text": " The main problem here in reading this word is not just to read the individual characters", "tokens": [50364, 407, 718, 311, 584, 291, 528, 281, 360, 39179, 11150, 293, 286, 411, 341, 1365, 597, 286, 1907, 291, 466, 50662, 50662, 1217, 13, 50728, 50728, 759, 291, 458, 689, 264, 4342, 366, 11, 3760, 341, 1349, 3643, 709, 3571, 13, 51000, 51000, 1033, 30, 51098, 51098, 440, 2135, 1154, 510, 294, 3760, 341, 1349, 307, 406, 445, 281, 1401, 264, 2609, 4342, 51274, 51274, 457, 281, 767, 2573, 484, 689, 264, 4342, 366, 11, 411, 689, 472, 2517, 5314, 11, 689, 51490, 51490, 264, 661, 472, 7338, 13, 51540, 51540], "temperature": 0.0, "avg_logprob": -0.14964109851467994, "compression_ratio": 1.7612612612612613, "no_speech_prob": 4.63771812064806e-06}, {"id": 210, "seek": 95720, "start": 975.4000000000001, "end": 979.72, "text": " but to actually figure out where the characters are, like where one character ends, where", "tokens": [50364, 407, 718, 311, 584, 291, 528, 281, 360, 39179, 11150, 293, 286, 411, 341, 1365, 597, 286, 1907, 291, 466, 50662, 50662, 1217, 13, 50728, 50728, 759, 291, 458, 689, 264, 4342, 366, 11, 3760, 341, 1349, 3643, 709, 3571, 13, 51000, 51000, 1033, 30, 51098, 51098, 440, 2135, 1154, 510, 294, 3760, 341, 1349, 307, 406, 445, 281, 1401, 264, 2609, 4342, 51274, 51274, 457, 281, 767, 2573, 484, 689, 264, 4342, 366, 11, 411, 689, 472, 2517, 5314, 11, 689, 51490, 51490, 264, 661, 472, 7338, 13, 51540, 51540], "temperature": 0.0, "avg_logprob": -0.14964109851467994, "compression_ratio": 1.7612612612612613, "no_speech_prob": 4.63771812064806e-06}, {"id": 211, "seek": 95720, "start": 979.72, "end": 980.72, "text": " the other one begins.", "tokens": [50364, 407, 718, 311, 584, 291, 528, 281, 360, 39179, 11150, 293, 286, 411, 341, 1365, 597, 286, 1907, 291, 466, 50662, 50662, 1217, 13, 50728, 50728, 759, 291, 458, 689, 264, 4342, 366, 11, 3760, 341, 1349, 3643, 709, 3571, 13, 51000, 51000, 1033, 30, 51098, 51098, 440, 2135, 1154, 510, 294, 3760, 341, 1349, 307, 406, 445, 281, 1401, 264, 2609, 4342, 51274, 51274, 457, 281, 767, 2573, 484, 689, 264, 4342, 366, 11, 411, 689, 472, 2517, 5314, 11, 689, 51490, 51490, 264, 661, 472, 7338, 13, 51540, 51540], "temperature": 0.0, "avg_logprob": -0.14964109851467994, "compression_ratio": 1.7612612612612613, "no_speech_prob": 4.63771812064806e-06}, {"id": 212, "seek": 98072, "start": 980.72, "end": 988.76, "text": " And if I were to tell you that it would be much easier for you to read that word.", "tokens": [50364, 400, 498, 286, 645, 281, 980, 291, 300, 309, 576, 312, 709, 3571, 337, 291, 281, 1401, 300, 1349, 13, 50766, 50766, 682, 1186, 321, 434, 1596, 665, 412, 341, 370, 498, 291, 1401, 341, 8310, 295, 4342, 510, 294, 3669, 11, 51044, 51044, 498, 291, 1223, 3669, 291, 393, 1391, 48377, 309, 11, 291, 393, 1391, 2573, 484, 689, 51204, 51204, 264, 1349, 13180, 366, 570, 291, 362, 341, 1333, 295, 1090, 12, 12418, 3601, 337, 689, 264, 51360, 51360, 2283, 366, 294, 3669, 13, 51484, 51484, 286, 360, 264, 912, 551, 281, 291, 294, 5522, 293, 291, 362, 572, 1558, 689, 264, 1349, 13180, 366, 13, 51726, 51726, 1033, 30, 51776, 51776], "temperature": 0.0, "avg_logprob": -0.1924924192757442, "compression_ratio": 1.82421875, "no_speech_prob": 1.8626889868755825e-05}, {"id": 213, "seek": 98072, "start": 988.76, "end": 994.32, "text": " In fact we're quite good at this so if you read this sequence of characters here in English,", "tokens": [50364, 400, 498, 286, 645, 281, 980, 291, 300, 309, 576, 312, 709, 3571, 337, 291, 281, 1401, 300, 1349, 13, 50766, 50766, 682, 1186, 321, 434, 1596, 665, 412, 341, 370, 498, 291, 1401, 341, 8310, 295, 4342, 510, 294, 3669, 11, 51044, 51044, 498, 291, 1223, 3669, 291, 393, 1391, 48377, 309, 11, 291, 393, 1391, 2573, 484, 689, 51204, 51204, 264, 1349, 13180, 366, 570, 291, 362, 341, 1333, 295, 1090, 12, 12418, 3601, 337, 689, 264, 51360, 51360, 2283, 366, 294, 3669, 13, 51484, 51484, 286, 360, 264, 912, 551, 281, 291, 294, 5522, 293, 291, 362, 572, 1558, 689, 264, 1349, 13180, 366, 13, 51726, 51726, 1033, 30, 51776, 51776], "temperature": 0.0, "avg_logprob": -0.1924924192757442, "compression_ratio": 1.82421875, "no_speech_prob": 1.8626889868755825e-05}, {"id": 214, "seek": 98072, "start": 994.32, "end": 997.52, "text": " if you understand English you can probably parse it, you can probably figure out where", "tokens": [50364, 400, 498, 286, 645, 281, 980, 291, 300, 309, 576, 312, 709, 3571, 337, 291, 281, 1401, 300, 1349, 13, 50766, 50766, 682, 1186, 321, 434, 1596, 665, 412, 341, 370, 498, 291, 1401, 341, 8310, 295, 4342, 510, 294, 3669, 11, 51044, 51044, 498, 291, 1223, 3669, 291, 393, 1391, 48377, 309, 11, 291, 393, 1391, 2573, 484, 689, 51204, 51204, 264, 1349, 13180, 366, 570, 291, 362, 341, 1333, 295, 1090, 12, 12418, 3601, 337, 689, 264, 51360, 51360, 2283, 366, 294, 3669, 13, 51484, 51484, 286, 360, 264, 912, 551, 281, 291, 294, 5522, 293, 291, 362, 572, 1558, 689, 264, 1349, 13180, 366, 13, 51726, 51726, 1033, 30, 51776, 51776], "temperature": 0.0, "avg_logprob": -0.1924924192757442, "compression_ratio": 1.82421875, "no_speech_prob": 1.8626889868755825e-05}, {"id": 215, "seek": 98072, "start": 997.52, "end": 1000.64, "text": " the word boundaries are because you have this sort of high-level knowledge for where the", "tokens": [50364, 400, 498, 286, 645, 281, 980, 291, 300, 309, 576, 312, 709, 3571, 337, 291, 281, 1401, 300, 1349, 13, 50766, 50766, 682, 1186, 321, 434, 1596, 665, 412, 341, 370, 498, 291, 1401, 341, 8310, 295, 4342, 510, 294, 3669, 11, 51044, 51044, 498, 291, 1223, 3669, 291, 393, 1391, 48377, 309, 11, 291, 393, 1391, 2573, 484, 689, 51204, 51204, 264, 1349, 13180, 366, 570, 291, 362, 341, 1333, 295, 1090, 12, 12418, 3601, 337, 689, 264, 51360, 51360, 2283, 366, 294, 3669, 13, 51484, 51484, 286, 360, 264, 912, 551, 281, 291, 294, 5522, 293, 291, 362, 572, 1558, 689, 264, 1349, 13180, 366, 13, 51726, 51726, 1033, 30, 51776, 51776], "temperature": 0.0, "avg_logprob": -0.1924924192757442, "compression_ratio": 1.82421875, "no_speech_prob": 1.8626889868755825e-05}, {"id": 216, "seek": 98072, "start": 1000.64, "end": 1003.12, "text": " words are in English.", "tokens": [50364, 400, 498, 286, 645, 281, 980, 291, 300, 309, 576, 312, 709, 3571, 337, 291, 281, 1401, 300, 1349, 13, 50766, 50766, 682, 1186, 321, 434, 1596, 665, 412, 341, 370, 498, 291, 1401, 341, 8310, 295, 4342, 510, 294, 3669, 11, 51044, 51044, 498, 291, 1223, 3669, 291, 393, 1391, 48377, 309, 11, 291, 393, 1391, 2573, 484, 689, 51204, 51204, 264, 1349, 13180, 366, 570, 291, 362, 341, 1333, 295, 1090, 12, 12418, 3601, 337, 689, 264, 51360, 51360, 2283, 366, 294, 3669, 13, 51484, 51484, 286, 360, 264, 912, 551, 281, 291, 294, 5522, 293, 291, 362, 572, 1558, 689, 264, 1349, 13180, 366, 13, 51726, 51726, 1033, 30, 51776, 51776], "temperature": 0.0, "avg_logprob": -0.1924924192757442, "compression_ratio": 1.82421875, "no_speech_prob": 1.8626889868755825e-05}, {"id": 217, "seek": 98072, "start": 1003.12, "end": 1007.96, "text": " I do the same thing to you in French and you have no idea where the word boundaries are.", "tokens": [50364, 400, 498, 286, 645, 281, 980, 291, 300, 309, 576, 312, 709, 3571, 337, 291, 281, 1401, 300, 1349, 13, 50766, 50766, 682, 1186, 321, 434, 1596, 665, 412, 341, 370, 498, 291, 1401, 341, 8310, 295, 4342, 510, 294, 3669, 11, 51044, 51044, 498, 291, 1223, 3669, 291, 393, 1391, 48377, 309, 11, 291, 393, 1391, 2573, 484, 689, 51204, 51204, 264, 1349, 13180, 366, 570, 291, 362, 341, 1333, 295, 1090, 12, 12418, 3601, 337, 689, 264, 51360, 51360, 2283, 366, 294, 3669, 13, 51484, 51484, 286, 360, 264, 912, 551, 281, 291, 294, 5522, 293, 291, 362, 572, 1558, 689, 264, 1349, 13180, 366, 13, 51726, 51726, 1033, 30, 51776, 51776], "temperature": 0.0, "avg_logprob": -0.1924924192757442, "compression_ratio": 1.82421875, "no_speech_prob": 1.8626889868755825e-05}, {"id": 218, "seek": 98072, "start": 1007.96, "end": 1008.96, "text": " Okay?", "tokens": [50364, 400, 498, 286, 645, 281, 980, 291, 300, 309, 576, 312, 709, 3571, 337, 291, 281, 1401, 300, 1349, 13, 50766, 50766, 682, 1186, 321, 434, 1596, 665, 412, 341, 370, 498, 291, 1401, 341, 8310, 295, 4342, 510, 294, 3669, 11, 51044, 51044, 498, 291, 1223, 3669, 291, 393, 1391, 48377, 309, 11, 291, 393, 1391, 2573, 484, 689, 51204, 51204, 264, 1349, 13180, 366, 570, 291, 362, 341, 1333, 295, 1090, 12, 12418, 3601, 337, 689, 264, 51360, 51360, 2283, 366, 294, 3669, 13, 51484, 51484, 286, 360, 264, 912, 551, 281, 291, 294, 5522, 293, 291, 362, 572, 1558, 689, 264, 1349, 13180, 366, 13, 51726, 51726, 1033, 30, 51776, 51776], "temperature": 0.0, "avg_logprob": -0.1924924192757442, "compression_ratio": 1.82421875, "no_speech_prob": 1.8626889868755825e-05}, {"id": 219, "seek": 100896, "start": 1008.96, "end": 1015.84, "text": " So unless you speak French.", "tokens": [50364, 407, 5969, 291, 1710, 5522, 13, 50708, 50708, 407, 264, 1349, 13180, 294, 341, 1389, 293, 264, 2517, 13180, 322, 1192, 576, 312, 4420, 51080, 51080, 281, 5039, 264, 1154, 13, 51214, 51214, 467, 576, 2089, 291, 337, 1365, 281, 11, 294, 264, 1389, 295, 2517, 11150, 11, 281, 362, 2609, 51494, 51494, 2517, 3068, 22525, 3079, 281, 1184, 2517, 457, 291, 500, 380, 458, 689, 436, 366, 370, 577, 360, 51684, 51684], "temperature": 0.0, "avg_logprob": -0.19329373677571615, "compression_ratio": 1.6614583333333333, "no_speech_prob": 7.758532774460036e-06}, {"id": 220, "seek": 100896, "start": 1015.84, "end": 1023.2800000000001, "text": " So the word boundaries in this case and the character boundaries on top would be useful", "tokens": [50364, 407, 5969, 291, 1710, 5522, 13, 50708, 50708, 407, 264, 1349, 13180, 294, 341, 1389, 293, 264, 2517, 13180, 322, 1192, 576, 312, 4420, 51080, 51080, 281, 5039, 264, 1154, 13, 51214, 51214, 467, 576, 2089, 291, 337, 1365, 281, 11, 294, 264, 1389, 295, 2517, 11150, 11, 281, 362, 2609, 51494, 51494, 2517, 3068, 22525, 3079, 281, 1184, 2517, 457, 291, 500, 380, 458, 689, 436, 366, 370, 577, 360, 51684, 51684], "temperature": 0.0, "avg_logprob": -0.19329373677571615, "compression_ratio": 1.6614583333333333, "no_speech_prob": 7.758532774460036e-06}, {"id": 221, "seek": 100896, "start": 1023.2800000000001, "end": 1025.96, "text": " to solve the problem.", "tokens": [50364, 407, 5969, 291, 1710, 5522, 13, 50708, 50708, 407, 264, 1349, 13180, 294, 341, 1389, 293, 264, 2517, 13180, 322, 1192, 576, 312, 4420, 51080, 51080, 281, 5039, 264, 1154, 13, 51214, 51214, 467, 576, 2089, 291, 337, 1365, 281, 11, 294, 264, 1389, 295, 2517, 11150, 11, 281, 362, 2609, 51494, 51494, 2517, 3068, 22525, 3079, 281, 1184, 2517, 457, 291, 500, 380, 458, 689, 436, 366, 370, 577, 360, 51684, 51684], "temperature": 0.0, "avg_logprob": -0.19329373677571615, "compression_ratio": 1.6614583333333333, "no_speech_prob": 7.758532774460036e-06}, {"id": 222, "seek": 100896, "start": 1025.96, "end": 1031.56, "text": " It would allow you for example to, in the case of character recognition, to have individual", "tokens": [50364, 407, 5969, 291, 1710, 5522, 13, 50708, 50708, 407, 264, 1349, 13180, 294, 341, 1389, 293, 264, 2517, 13180, 322, 1192, 576, 312, 4420, 51080, 51080, 281, 5039, 264, 1154, 13, 51214, 51214, 467, 576, 2089, 291, 337, 1365, 281, 11, 294, 264, 1389, 295, 2517, 11150, 11, 281, 362, 2609, 51494, 51494, 2517, 3068, 22525, 3079, 281, 1184, 2517, 457, 291, 500, 380, 458, 689, 436, 366, 370, 577, 360, 51684, 51684], "temperature": 0.0, "avg_logprob": -0.19329373677571615, "compression_ratio": 1.6614583333333333, "no_speech_prob": 7.758532774460036e-06}, {"id": 223, "seek": 100896, "start": 1031.56, "end": 1035.3600000000001, "text": " character recognizers apply to each character but you don't know where they are so how do", "tokens": [50364, 407, 5969, 291, 1710, 5522, 13, 50708, 50708, 407, 264, 1349, 13180, 294, 341, 1389, 293, 264, 2517, 13180, 322, 1192, 576, 312, 4420, 51080, 51080, 281, 5039, 264, 1154, 13, 51214, 51214, 467, 576, 2089, 291, 337, 1365, 281, 11, 294, 264, 1389, 295, 2517, 11150, 11, 281, 362, 2609, 51494, 51494, 2517, 3068, 22525, 3079, 281, 1184, 2517, 457, 291, 500, 380, 458, 689, 436, 366, 370, 577, 360, 51684, 51684], "temperature": 0.0, "avg_logprob": -0.19329373677571615, "compression_ratio": 1.6614583333333333, "no_speech_prob": 7.758532774460036e-06}, {"id": 224, "seek": 103536, "start": 1035.36, "end": 1040.08, "text": " you solve that problem?", "tokens": [50364, 291, 5039, 300, 1154, 30, 50600, 50600, 407, 300, 311, 11, 300, 576, 312, 257, 4420, 48994, 7006, 13, 50900, 50900, 759, 286, 1907, 291, 11, 370, 337, 6218, 11150, 264, 1154, 307, 300, 291, 500, 380, 458, 689, 264, 13180, 51362, 51362, 1296, 264, 2283, 366, 11, 291, 500, 380, 458, 689, 264, 13180, 1296, 264, 30754, 443, 279, 366, 2139, 13, 51546, 51546, 48385, 307, 588, 709, 411, 341, 10957, 2487, 11, 10957, 6218, 13, 51792, 51792], "temperature": 0.0, "avg_logprob": -0.13286393954430098, "compression_ratio": 1.7688172043010753, "no_speech_prob": 3.420441134949215e-05}, {"id": 225, "seek": 103536, "start": 1040.08, "end": 1046.08, "text": " So that's, that would be a useful latent variable.", "tokens": [50364, 291, 5039, 300, 1154, 30, 50600, 50600, 407, 300, 311, 11, 300, 576, 312, 257, 4420, 48994, 7006, 13, 50900, 50900, 759, 286, 1907, 291, 11, 370, 337, 6218, 11150, 264, 1154, 307, 300, 291, 500, 380, 458, 689, 264, 13180, 51362, 51362, 1296, 264, 2283, 366, 11, 291, 500, 380, 458, 689, 264, 13180, 1296, 264, 30754, 443, 279, 366, 2139, 13, 51546, 51546, 48385, 307, 588, 709, 411, 341, 10957, 2487, 11, 10957, 6218, 13, 51792, 51792], "temperature": 0.0, "avg_logprob": -0.13286393954430098, "compression_ratio": 1.7688172043010753, "no_speech_prob": 3.420441134949215e-05}, {"id": 226, "seek": 103536, "start": 1046.08, "end": 1055.32, "text": " If I told you, so for speech recognition the problem is that you don't know where the boundaries", "tokens": [50364, 291, 5039, 300, 1154, 30, 50600, 50600, 407, 300, 311, 11, 300, 576, 312, 257, 4420, 48994, 7006, 13, 50900, 50900, 759, 286, 1907, 291, 11, 370, 337, 6218, 11150, 264, 1154, 307, 300, 291, 500, 380, 458, 689, 264, 13180, 51362, 51362, 1296, 264, 2283, 366, 11, 291, 500, 380, 458, 689, 264, 13180, 1296, 264, 30754, 443, 279, 366, 2139, 13, 51546, 51546, 48385, 307, 588, 709, 411, 341, 10957, 2487, 11, 10957, 6218, 13, 51792, 51792], "temperature": 0.0, "avg_logprob": -0.13286393954430098, "compression_ratio": 1.7688172043010753, "no_speech_prob": 3.420441134949215e-05}, {"id": 227, "seek": 103536, "start": 1055.32, "end": 1059.0, "text": " between the words are, you don't know where the boundaries between the phonemes are either.", "tokens": [50364, 291, 5039, 300, 1154, 30, 50600, 50600, 407, 300, 311, 11, 300, 576, 312, 257, 4420, 48994, 7006, 13, 50900, 50900, 759, 286, 1907, 291, 11, 370, 337, 6218, 11150, 264, 1154, 307, 300, 291, 500, 380, 458, 689, 264, 13180, 51362, 51362, 1296, 264, 2283, 366, 11, 291, 500, 380, 458, 689, 264, 13180, 1296, 264, 30754, 443, 279, 366, 2139, 13, 51546, 51546, 48385, 307, 588, 709, 411, 341, 10957, 2487, 11, 10957, 6218, 13, 51792, 51792], "temperature": 0.0, "avg_logprob": -0.13286393954430098, "compression_ratio": 1.7688172043010753, "no_speech_prob": 3.420441134949215e-05}, {"id": 228, "seek": 103536, "start": 1059.0, "end": 1063.9199999999998, "text": " Speech is very much like this continuous text, continuous speech.", "tokens": [50364, 291, 5039, 300, 1154, 30, 50600, 50600, 407, 300, 311, 11, 300, 576, 312, 257, 4420, 48994, 7006, 13, 50900, 50900, 759, 286, 1907, 291, 11, 370, 337, 6218, 11150, 264, 1154, 307, 300, 291, 500, 380, 458, 689, 264, 13180, 51362, 51362, 1296, 264, 2283, 366, 11, 291, 500, 380, 458, 689, 264, 13180, 1296, 264, 30754, 443, 279, 366, 2139, 13, 51546, 51546, 48385, 307, 588, 709, 411, 341, 10957, 2487, 11, 10957, 6218, 13, 51792, 51792], "temperature": 0.0, "avg_logprob": -0.13286393954430098, "compression_ratio": 1.7688172043010753, "no_speech_prob": 3.420441134949215e-05}, {"id": 229, "seek": 106392, "start": 1063.92, "end": 1068.2, "text": " We can parse the words because we know where the words are, because we understand the language", "tokens": [50364, 492, 393, 48377, 264, 2283, 570, 321, 458, 689, 264, 2283, 366, 11, 570, 321, 1223, 264, 2856, 50578, 50578, 457, 1580, 4124, 257, 2856, 291, 500, 380, 1223, 291, 362, 257, 588, 21104, 1558, 295, 689, 50778, 50778, 264, 1349, 13180, 366, 13, 50828, 50828, 4534, 295, 264, 565, 291, 393, 380, 13, 50996, 50996, 682, 8650, 689, 456, 307, 572, 4244, 11, 294, 3669, 309, 311, 733, 295, 1858, 570, 456, 311, 51278, 51278, 4244, 322, 264, 1349, 370, 498, 291, 393, 2573, 484, 689, 264, 4244, 307, 291, 393, 1391, 2573, 51462, 51462, 484, 544, 420, 1570, 689, 264, 1349, 13180, 366, 13, 51562, 51562, 682, 5522, 689, 456, 311, 572, 4244, 291, 393, 380, 11, 291, 362, 411, 572, 636, 295, 15213, 484, 13, 51782, 51782], "temperature": 0.0, "avg_logprob": -0.1604588826497396, "compression_ratio": 2.0891472868217056, "no_speech_prob": 9.242283704224974e-05}, {"id": 230, "seek": 106392, "start": 1068.2, "end": 1072.2, "text": " but someone speaking a language you don't understand you have a very faint idea of where", "tokens": [50364, 492, 393, 48377, 264, 2283, 570, 321, 458, 689, 264, 2283, 366, 11, 570, 321, 1223, 264, 2856, 50578, 50578, 457, 1580, 4124, 257, 2856, 291, 500, 380, 1223, 291, 362, 257, 588, 21104, 1558, 295, 689, 50778, 50778, 264, 1349, 13180, 366, 13, 50828, 50828, 4534, 295, 264, 565, 291, 393, 380, 13, 50996, 50996, 682, 8650, 689, 456, 307, 572, 4244, 11, 294, 3669, 309, 311, 733, 295, 1858, 570, 456, 311, 51278, 51278, 4244, 322, 264, 1349, 370, 498, 291, 393, 2573, 484, 689, 264, 4244, 307, 291, 393, 1391, 2573, 51462, 51462, 484, 544, 420, 1570, 689, 264, 1349, 13180, 366, 13, 51562, 51562, 682, 5522, 689, 456, 311, 572, 4244, 291, 393, 380, 11, 291, 362, 411, 572, 636, 295, 15213, 484, 13, 51782, 51782], "temperature": 0.0, "avg_logprob": -0.1604588826497396, "compression_ratio": 2.0891472868217056, "no_speech_prob": 9.242283704224974e-05}, {"id": 231, "seek": 106392, "start": 1072.2, "end": 1073.2, "text": " the word boundaries are.", "tokens": [50364, 492, 393, 48377, 264, 2283, 570, 321, 458, 689, 264, 2283, 366, 11, 570, 321, 1223, 264, 2856, 50578, 50578, 457, 1580, 4124, 257, 2856, 291, 500, 380, 1223, 291, 362, 257, 588, 21104, 1558, 295, 689, 50778, 50778, 264, 1349, 13180, 366, 13, 50828, 50828, 4534, 295, 264, 565, 291, 393, 380, 13, 50996, 50996, 682, 8650, 689, 456, 307, 572, 4244, 11, 294, 3669, 309, 311, 733, 295, 1858, 570, 456, 311, 51278, 51278, 4244, 322, 264, 1349, 370, 498, 291, 393, 2573, 484, 689, 264, 4244, 307, 291, 393, 1391, 2573, 51462, 51462, 484, 544, 420, 1570, 689, 264, 1349, 13180, 366, 13, 51562, 51562, 682, 5522, 689, 456, 311, 572, 4244, 291, 393, 380, 11, 291, 362, 411, 572, 636, 295, 15213, 484, 13, 51782, 51782], "temperature": 0.0, "avg_logprob": -0.1604588826497396, "compression_ratio": 2.0891472868217056, "no_speech_prob": 9.242283704224974e-05}, {"id": 232, "seek": 106392, "start": 1073.2, "end": 1076.5600000000002, "text": " Most of the time you can't.", "tokens": [50364, 492, 393, 48377, 264, 2283, 570, 321, 458, 689, 264, 2283, 366, 11, 570, 321, 1223, 264, 2856, 50578, 50578, 457, 1580, 4124, 257, 2856, 291, 500, 380, 1223, 291, 362, 257, 588, 21104, 1558, 295, 689, 50778, 50778, 264, 1349, 13180, 366, 13, 50828, 50828, 4534, 295, 264, 565, 291, 393, 380, 13, 50996, 50996, 682, 8650, 689, 456, 307, 572, 4244, 11, 294, 3669, 309, 311, 733, 295, 1858, 570, 456, 311, 51278, 51278, 4244, 322, 264, 1349, 370, 498, 291, 393, 2573, 484, 689, 264, 4244, 307, 291, 393, 1391, 2573, 51462, 51462, 484, 544, 420, 1570, 689, 264, 1349, 13180, 366, 13, 51562, 51562, 682, 5522, 689, 456, 311, 572, 4244, 291, 393, 380, 11, 291, 362, 411, 572, 636, 295, 15213, 484, 13, 51782, 51782], "temperature": 0.0, "avg_logprob": -0.1604588826497396, "compression_ratio": 2.0891472868217056, "no_speech_prob": 9.242283704224974e-05}, {"id": 233, "seek": 106392, "start": 1076.5600000000002, "end": 1082.2, "text": " In languages where there is no stress, in English it's kind of easy because there's", "tokens": [50364, 492, 393, 48377, 264, 2283, 570, 321, 458, 689, 264, 2283, 366, 11, 570, 321, 1223, 264, 2856, 50578, 50578, 457, 1580, 4124, 257, 2856, 291, 500, 380, 1223, 291, 362, 257, 588, 21104, 1558, 295, 689, 50778, 50778, 264, 1349, 13180, 366, 13, 50828, 50828, 4534, 295, 264, 565, 291, 393, 380, 13, 50996, 50996, 682, 8650, 689, 456, 307, 572, 4244, 11, 294, 3669, 309, 311, 733, 295, 1858, 570, 456, 311, 51278, 51278, 4244, 322, 264, 1349, 370, 498, 291, 393, 2573, 484, 689, 264, 4244, 307, 291, 393, 1391, 2573, 51462, 51462, 484, 544, 420, 1570, 689, 264, 1349, 13180, 366, 13, 51562, 51562, 682, 5522, 689, 456, 311, 572, 4244, 291, 393, 380, 11, 291, 362, 411, 572, 636, 295, 15213, 484, 13, 51782, 51782], "temperature": 0.0, "avg_logprob": -0.1604588826497396, "compression_ratio": 2.0891472868217056, "no_speech_prob": 9.242283704224974e-05}, {"id": 234, "seek": 106392, "start": 1082.2, "end": 1085.88, "text": " stress on the word so if you can figure out where the stress is you can probably figure", "tokens": [50364, 492, 393, 48377, 264, 2283, 570, 321, 458, 689, 264, 2283, 366, 11, 570, 321, 1223, 264, 2856, 50578, 50578, 457, 1580, 4124, 257, 2856, 291, 500, 380, 1223, 291, 362, 257, 588, 21104, 1558, 295, 689, 50778, 50778, 264, 1349, 13180, 366, 13, 50828, 50828, 4534, 295, 264, 565, 291, 393, 380, 13, 50996, 50996, 682, 8650, 689, 456, 307, 572, 4244, 11, 294, 3669, 309, 311, 733, 295, 1858, 570, 456, 311, 51278, 51278, 4244, 322, 264, 1349, 370, 498, 291, 393, 2573, 484, 689, 264, 4244, 307, 291, 393, 1391, 2573, 51462, 51462, 484, 544, 420, 1570, 689, 264, 1349, 13180, 366, 13, 51562, 51562, 682, 5522, 689, 456, 311, 572, 4244, 291, 393, 380, 11, 291, 362, 411, 572, 636, 295, 15213, 484, 13, 51782, 51782], "temperature": 0.0, "avg_logprob": -0.1604588826497396, "compression_ratio": 2.0891472868217056, "no_speech_prob": 9.242283704224974e-05}, {"id": 235, "seek": 106392, "start": 1085.88, "end": 1087.88, "text": " out more or less where the word boundaries are.", "tokens": [50364, 492, 393, 48377, 264, 2283, 570, 321, 458, 689, 264, 2283, 366, 11, 570, 321, 1223, 264, 2856, 50578, 50578, 457, 1580, 4124, 257, 2856, 291, 500, 380, 1223, 291, 362, 257, 588, 21104, 1558, 295, 689, 50778, 50778, 264, 1349, 13180, 366, 13, 50828, 50828, 4534, 295, 264, 565, 291, 393, 380, 13, 50996, 50996, 682, 8650, 689, 456, 307, 572, 4244, 11, 294, 3669, 309, 311, 733, 295, 1858, 570, 456, 311, 51278, 51278, 4244, 322, 264, 1349, 370, 498, 291, 393, 2573, 484, 689, 264, 4244, 307, 291, 393, 1391, 2573, 51462, 51462, 484, 544, 420, 1570, 689, 264, 1349, 13180, 366, 13, 51562, 51562, 682, 5522, 689, 456, 311, 572, 4244, 291, 393, 380, 11, 291, 362, 411, 572, 636, 295, 15213, 484, 13, 51782, 51782], "temperature": 0.0, "avg_logprob": -0.1604588826497396, "compression_ratio": 2.0891472868217056, "no_speech_prob": 9.242283704224974e-05}, {"id": 236, "seek": 106392, "start": 1087.88, "end": 1092.28, "text": " In French where there's no stress you can't, you have like no way of figuring out.", "tokens": [50364, 492, 393, 48377, 264, 2283, 570, 321, 458, 689, 264, 2283, 366, 11, 570, 321, 1223, 264, 2856, 50578, 50578, 457, 1580, 4124, 257, 2856, 291, 500, 380, 1223, 291, 362, 257, 588, 21104, 1558, 295, 689, 50778, 50778, 264, 1349, 13180, 366, 13, 50828, 50828, 4534, 295, 264, 565, 291, 393, 380, 13, 50996, 50996, 682, 8650, 689, 456, 307, 572, 4244, 11, 294, 3669, 309, 311, 733, 295, 1858, 570, 456, 311, 51278, 51278, 4244, 322, 264, 1349, 370, 498, 291, 393, 2573, 484, 689, 264, 4244, 307, 291, 393, 1391, 2573, 51462, 51462, 484, 544, 420, 1570, 689, 264, 1349, 13180, 366, 13, 51562, 51562, 682, 5522, 689, 456, 311, 572, 4244, 291, 393, 380, 11, 291, 362, 411, 572, 636, 295, 15213, 484, 13, 51782, 51782], "temperature": 0.0, "avg_logprob": -0.1604588826497396, "compression_ratio": 2.0891472868217056, "no_speech_prob": 9.242283704224974e-05}, {"id": 237, "seek": 109228, "start": 1092.28, "end": 1098.0, "text": " Je peux dire une longue phrase en fran\u00e7ais, vous n'avez aucune id\u00e9e o\u00f9 sont les fronti\u00e8res", "tokens": [50364, 2588, 14844, 1264, 2251, 44445, 9535, 465, 21425, 11, 2630, 297, 6, 25975, 40076, 34832, 9068, 4900, 1512, 1868, 39408, 50650, 50650, 3962, 1512, 34009, 13, 50700, 50700, 407, 291, 458, 309, 311, 733, 295, 257, 10957, 6798, 295, 30754, 443, 279, 293, 309, 311, 588, 1152, 281, 980, 689, 51024, 51024, 264, 1349, 13180, 366, 5969, 291, 458, 264, 2856, 13, 51170, 51170, 407, 300, 576, 312, 257, 4420, 48994, 7006, 281, 362, 570, 498, 1580, 1907, 291, 689, 51384, 51384, 729, 13180, 645, 550, 291, 576, 312, 1075, 281, 360, 264, 5633, 13, 51596, 51596, 407, 300, 311, 577, 291, 576, 764, 48994, 9102, 13, 51780, 51780], "temperature": 0.0, "avg_logprob": -0.15550427823453336, "compression_ratio": 1.7093023255813953, "no_speech_prob": 0.0001119540465879254}, {"id": 238, "seek": 109228, "start": 1098.0, "end": 1099.0, "text": " entre les mots.", "tokens": [50364, 2588, 14844, 1264, 2251, 44445, 9535, 465, 21425, 11, 2630, 297, 6, 25975, 40076, 34832, 9068, 4900, 1512, 1868, 39408, 50650, 50650, 3962, 1512, 34009, 13, 50700, 50700, 407, 291, 458, 309, 311, 733, 295, 257, 10957, 6798, 295, 30754, 443, 279, 293, 309, 311, 588, 1152, 281, 980, 689, 51024, 51024, 264, 1349, 13180, 366, 5969, 291, 458, 264, 2856, 13, 51170, 51170, 407, 300, 576, 312, 257, 4420, 48994, 7006, 281, 362, 570, 498, 1580, 1907, 291, 689, 51384, 51384, 729, 13180, 645, 550, 291, 576, 312, 1075, 281, 360, 264, 5633, 13, 51596, 51596, 407, 300, 311, 577, 291, 576, 764, 48994, 9102, 13, 51780, 51780], "temperature": 0.0, "avg_logprob": -0.15550427823453336, "compression_ratio": 1.7093023255813953, "no_speech_prob": 0.0001119540465879254}, {"id": 239, "seek": 109228, "start": 1099.0, "end": 1105.48, "text": " So you know it's kind of a continuous string of phonemes and it's very hard to tell where", "tokens": [50364, 2588, 14844, 1264, 2251, 44445, 9535, 465, 21425, 11, 2630, 297, 6, 25975, 40076, 34832, 9068, 4900, 1512, 1868, 39408, 50650, 50650, 3962, 1512, 34009, 13, 50700, 50700, 407, 291, 458, 309, 311, 733, 295, 257, 10957, 6798, 295, 30754, 443, 279, 293, 309, 311, 588, 1152, 281, 980, 689, 51024, 51024, 264, 1349, 13180, 366, 5969, 291, 458, 264, 2856, 13, 51170, 51170, 407, 300, 576, 312, 257, 4420, 48994, 7006, 281, 362, 570, 498, 1580, 1907, 291, 689, 51384, 51384, 729, 13180, 645, 550, 291, 576, 312, 1075, 281, 360, 264, 5633, 13, 51596, 51596, 407, 300, 311, 577, 291, 576, 764, 48994, 9102, 13, 51780, 51780], "temperature": 0.0, "avg_logprob": -0.15550427823453336, "compression_ratio": 1.7093023255813953, "no_speech_prob": 0.0001119540465879254}, {"id": 240, "seek": 109228, "start": 1105.48, "end": 1108.3999999999999, "text": " the word boundaries are unless you know the language.", "tokens": [50364, 2588, 14844, 1264, 2251, 44445, 9535, 465, 21425, 11, 2630, 297, 6, 25975, 40076, 34832, 9068, 4900, 1512, 1868, 39408, 50650, 50650, 3962, 1512, 34009, 13, 50700, 50700, 407, 291, 458, 309, 311, 733, 295, 257, 10957, 6798, 295, 30754, 443, 279, 293, 309, 311, 588, 1152, 281, 980, 689, 51024, 51024, 264, 1349, 13180, 366, 5969, 291, 458, 264, 2856, 13, 51170, 51170, 407, 300, 576, 312, 257, 4420, 48994, 7006, 281, 362, 570, 498, 1580, 1907, 291, 689, 51384, 51384, 729, 13180, 645, 550, 291, 576, 312, 1075, 281, 360, 264, 5633, 13, 51596, 51596, 407, 300, 311, 577, 291, 576, 764, 48994, 9102, 13, 51780, 51780], "temperature": 0.0, "avg_logprob": -0.15550427823453336, "compression_ratio": 1.7093023255813953, "no_speech_prob": 0.0001119540465879254}, {"id": 241, "seek": 109228, "start": 1108.3999999999999, "end": 1112.68, "text": " So that would be a useful latent variable to have because if someone told you where", "tokens": [50364, 2588, 14844, 1264, 2251, 44445, 9535, 465, 21425, 11, 2630, 297, 6, 25975, 40076, 34832, 9068, 4900, 1512, 1868, 39408, 50650, 50650, 3962, 1512, 34009, 13, 50700, 50700, 407, 291, 458, 309, 311, 733, 295, 257, 10957, 6798, 295, 30754, 443, 279, 293, 309, 311, 588, 1152, 281, 980, 689, 51024, 51024, 264, 1349, 13180, 366, 5969, 291, 458, 264, 2856, 13, 51170, 51170, 407, 300, 576, 312, 257, 4420, 48994, 7006, 281, 362, 570, 498, 1580, 1907, 291, 689, 51384, 51384, 729, 13180, 645, 550, 291, 576, 312, 1075, 281, 360, 264, 5633, 13, 51596, 51596, 407, 300, 311, 577, 291, 576, 764, 48994, 9102, 13, 51780, 51780], "temperature": 0.0, "avg_logprob": -0.15550427823453336, "compression_ratio": 1.7093023255813953, "no_speech_prob": 0.0001119540465879254}, {"id": 242, "seek": 109228, "start": 1112.68, "end": 1116.92, "text": " those boundaries were then you would be able to do the task.", "tokens": [50364, 2588, 14844, 1264, 2251, 44445, 9535, 465, 21425, 11, 2630, 297, 6, 25975, 40076, 34832, 9068, 4900, 1512, 1868, 39408, 50650, 50650, 3962, 1512, 34009, 13, 50700, 50700, 407, 291, 458, 309, 311, 733, 295, 257, 10957, 6798, 295, 30754, 443, 279, 293, 309, 311, 588, 1152, 281, 980, 689, 51024, 51024, 264, 1349, 13180, 366, 5969, 291, 458, 264, 2856, 13, 51170, 51170, 407, 300, 576, 312, 257, 4420, 48994, 7006, 281, 362, 570, 498, 1580, 1907, 291, 689, 51384, 51384, 729, 13180, 645, 550, 291, 576, 312, 1075, 281, 360, 264, 5633, 13, 51596, 51596, 407, 300, 311, 577, 291, 576, 764, 48994, 9102, 13, 51780, 51780], "temperature": 0.0, "avg_logprob": -0.15550427823453336, "compression_ratio": 1.7093023255813953, "no_speech_prob": 0.0001119540465879254}, {"id": 243, "seek": 109228, "start": 1116.92, "end": 1120.6, "text": " So that's how you would use latent variables.", "tokens": [50364, 2588, 14844, 1264, 2251, 44445, 9535, 465, 21425, 11, 2630, 297, 6, 25975, 40076, 34832, 9068, 4900, 1512, 1868, 39408, 50650, 50650, 3962, 1512, 34009, 13, 50700, 50700, 407, 291, 458, 309, 311, 733, 295, 257, 10957, 6798, 295, 30754, 443, 279, 293, 309, 311, 588, 1152, 281, 980, 689, 51024, 51024, 264, 1349, 13180, 366, 5969, 291, 458, 264, 2856, 13, 51170, 51170, 407, 300, 576, 312, 257, 4420, 48994, 7006, 281, 362, 570, 498, 1580, 1907, 291, 689, 51384, 51384, 729, 13180, 645, 550, 291, 576, 312, 1075, 281, 360, 264, 5633, 13, 51596, 51596, 407, 300, 311, 577, 291, 576, 764, 48994, 9102, 13, 51780, 51780], "temperature": 0.0, "avg_logprob": -0.15550427823453336, "compression_ratio": 1.7093023255813953, "no_speech_prob": 0.0001119540465879254}, {"id": 244, "seek": 112060, "start": 1120.6, "end": 1126.84, "text": " And this word using latent variables has been used for decades in the context of speech", "tokens": [50364, 400, 341, 1349, 1228, 48994, 9102, 575, 668, 1143, 337, 7878, 294, 264, 4319, 295, 6218, 50676, 50676, 11150, 11, 294, 264, 4319, 295, 3303, 2856, 9007, 11, 294, 264, 4319, 295, 2517, 11150, 51006, 51006, 382, 286, 848, 422, 18547, 293, 294, 257, 1230, 295, 819, 661, 5821, 11, 4098, 2306, 300, 51500, 51500, 9494, 22978, 13, 51600, 51600], "temperature": 0.0, "avg_logprob": -0.1913857767658849, "compression_ratio": 1.5956284153005464, "no_speech_prob": 5.2644805691670626e-05}, {"id": 245, "seek": 112060, "start": 1126.84, "end": 1133.4399999999998, "text": " recognition, in the context of natural language processing, in the context of character recognition", "tokens": [50364, 400, 341, 1349, 1228, 48994, 9102, 575, 668, 1143, 337, 7878, 294, 264, 4319, 295, 6218, 50676, 50676, 11150, 11, 294, 264, 4319, 295, 3303, 2856, 9007, 11, 294, 264, 4319, 295, 2517, 11150, 51006, 51006, 382, 286, 848, 422, 18547, 293, 294, 257, 1230, 295, 819, 661, 5821, 11, 4098, 2306, 300, 51500, 51500, 9494, 22978, 13, 51600, 51600], "temperature": 0.0, "avg_logprob": -0.1913857767658849, "compression_ratio": 1.5956284153005464, "no_speech_prob": 5.2644805691670626e-05}, {"id": 246, "seek": 112060, "start": 1133.4399999999998, "end": 1143.32, "text": " as I said OCR and in a number of different other applications, particularly ones that", "tokens": [50364, 400, 341, 1349, 1228, 48994, 9102, 575, 668, 1143, 337, 7878, 294, 264, 4319, 295, 6218, 50676, 50676, 11150, 11, 294, 264, 4319, 295, 3303, 2856, 9007, 11, 294, 264, 4319, 295, 2517, 11150, 51006, 51006, 382, 286, 848, 422, 18547, 293, 294, 257, 1230, 295, 819, 661, 5821, 11, 4098, 2306, 300, 51500, 51500, 9494, 22978, 13, 51600, 51600], "temperature": 0.0, "avg_logprob": -0.1913857767658849, "compression_ratio": 1.5956284153005464, "no_speech_prob": 5.2644805691670626e-05}, {"id": 247, "seek": 112060, "start": 1143.32, "end": 1145.32, "text": " involve sequences.", "tokens": [50364, 400, 341, 1349, 1228, 48994, 9102, 575, 668, 1143, 337, 7878, 294, 264, 4319, 295, 6218, 50676, 50676, 11150, 11, 294, 264, 4319, 295, 3303, 2856, 9007, 11, 294, 264, 4319, 295, 2517, 11150, 51006, 51006, 382, 286, 848, 422, 18547, 293, 294, 257, 1230, 295, 819, 661, 5821, 11, 4098, 2306, 300, 51500, 51500, 9494, 22978, 13, 51600, 51600], "temperature": 0.0, "avg_logprob": -0.1913857767658849, "compression_ratio": 1.5956284153005464, "no_speech_prob": 5.2644805691670626e-05}, {"id": 248, "seek": 114532, "start": 1145.32, "end": 1157.48, "text": " But also in computer vision, so things like you know you want to kind of detect where", "tokens": [50364, 583, 611, 294, 3820, 5201, 11, 370, 721, 411, 291, 458, 291, 528, 281, 733, 295, 5531, 689, 50972, 50972, 257, 954, 307, 457, 291, 500, 380, 458, 577, 300, 954, 307, 12386, 420, 437, 2535, 300, 954, 307, 51476, 51476, 294, 11, 721, 411, 341, 13, 51526, 51526, 407, 291, 458, 729, 366, 9102, 300, 498, 291, 2586, 552, 576, 733, 295, 854, 291, 5039, 264, 51700, 51700], "temperature": 0.0, "avg_logprob": -0.1424276056423993, "compression_ratio": 1.6705882352941177, "no_speech_prob": 0.00011913727212231606}, {"id": 249, "seek": 114532, "start": 1157.48, "end": 1167.56, "text": " a person is but you don't know how that person is dressed or what position that person is", "tokens": [50364, 583, 611, 294, 3820, 5201, 11, 370, 721, 411, 291, 458, 291, 528, 281, 733, 295, 5531, 689, 50972, 50972, 257, 954, 307, 457, 291, 500, 380, 458, 577, 300, 954, 307, 12386, 420, 437, 2535, 300, 954, 307, 51476, 51476, 294, 11, 721, 411, 341, 13, 51526, 51526, 407, 291, 458, 729, 366, 9102, 300, 498, 291, 2586, 552, 576, 733, 295, 854, 291, 5039, 264, 51700, 51700], "temperature": 0.0, "avg_logprob": -0.1424276056423993, "compression_ratio": 1.6705882352941177, "no_speech_prob": 0.00011913727212231606}, {"id": 250, "seek": 114532, "start": 1167.56, "end": 1168.56, "text": " in, things like this.", "tokens": [50364, 583, 611, 294, 3820, 5201, 11, 370, 721, 411, 291, 458, 291, 528, 281, 733, 295, 5531, 689, 50972, 50972, 257, 954, 307, 457, 291, 500, 380, 458, 577, 300, 954, 307, 12386, 420, 437, 2535, 300, 954, 307, 51476, 51476, 294, 11, 721, 411, 341, 13, 51526, 51526, 407, 291, 458, 729, 366, 9102, 300, 498, 291, 2586, 552, 576, 733, 295, 854, 291, 5039, 264, 51700, 51700], "temperature": 0.0, "avg_logprob": -0.1424276056423993, "compression_ratio": 1.6705882352941177, "no_speech_prob": 0.00011913727212231606}, {"id": 251, "seek": 114532, "start": 1168.56, "end": 1172.04, "text": " So you know those are variables that if you knew them would kind of help you solve the", "tokens": [50364, 583, 611, 294, 3820, 5201, 11, 370, 721, 411, 291, 458, 291, 528, 281, 733, 295, 5531, 689, 50972, 50972, 257, 954, 307, 457, 291, 500, 380, 458, 577, 300, 954, 307, 12386, 420, 437, 2535, 300, 954, 307, 51476, 51476, 294, 11, 721, 411, 341, 13, 51526, 51526, 407, 291, 458, 729, 366, 9102, 300, 498, 291, 2586, 552, 576, 733, 295, 854, 291, 5039, 264, 51700, 51700], "temperature": 0.0, "avg_logprob": -0.1424276056423993, "compression_ratio": 1.6705882352941177, "no_speech_prob": 0.00011913727212231606}, {"id": 252, "seek": 117204, "start": 1172.04, "end": 1181.04, "text": " task although nowadays vision just works.", "tokens": [50364, 5633, 4878, 13434, 5201, 445, 1985, 13, 50814, 50814, 1033, 370, 498, 291, 362, 257, 48994, 7006, 2316, 341, 307, 577, 291, 360, 38253, 13, 51176, 51176, 407, 291, 362, 257, 777, 2281, 2445, 586, 309, 311, 1219, 462, 406, 479, 11, 462, 295, 48826, 57, 293, 281, 360, 38253, 51508, 51508, 291, 16561, 17522, 309, 365, 3104, 281, 1176, 293, 398, 13, 51681, 51681], "temperature": 0.0, "avg_logprob": -0.19358538157904326, "compression_ratio": 1.446927374301676, "no_speech_prob": 2.2824902771390043e-05}, {"id": 253, "seek": 117204, "start": 1181.04, "end": 1188.28, "text": " Okay so if you have a latent variable model this is how you do inference.", "tokens": [50364, 5633, 4878, 13434, 5201, 445, 1985, 13, 50814, 50814, 1033, 370, 498, 291, 362, 257, 48994, 7006, 2316, 341, 307, 577, 291, 360, 38253, 13, 51176, 51176, 407, 291, 362, 257, 777, 2281, 2445, 586, 309, 311, 1219, 462, 406, 479, 11, 462, 295, 48826, 57, 293, 281, 360, 38253, 51508, 51508, 291, 16561, 17522, 309, 365, 3104, 281, 1176, 293, 398, 13, 51681, 51681], "temperature": 0.0, "avg_logprob": -0.19358538157904326, "compression_ratio": 1.446927374301676, "no_speech_prob": 2.2824902771390043e-05}, {"id": 254, "seek": 117204, "start": 1188.28, "end": 1194.92, "text": " So you have a new energy function now it's called E not F, E of XYZ and to do inference", "tokens": [50364, 5633, 4878, 13434, 5201, 445, 1985, 13, 50814, 50814, 1033, 370, 498, 291, 362, 257, 48994, 7006, 2316, 341, 307, 577, 291, 360, 38253, 13, 51176, 51176, 407, 291, 362, 257, 777, 2281, 2445, 586, 309, 311, 1219, 462, 406, 479, 11, 462, 295, 48826, 57, 293, 281, 360, 38253, 51508, 51508, 291, 16561, 17522, 309, 365, 3104, 281, 1176, 293, 398, 13, 51681, 51681], "temperature": 0.0, "avg_logprob": -0.19358538157904326, "compression_ratio": 1.446927374301676, "no_speech_prob": 2.2824902771390043e-05}, {"id": 255, "seek": 117204, "start": 1194.92, "end": 1198.3799999999999, "text": " you simultaneously minimize it with respect to Z and Y.", "tokens": [50364, 5633, 4878, 13434, 5201, 445, 1985, 13, 50814, 50814, 1033, 370, 498, 291, 362, 257, 48994, 7006, 2316, 341, 307, 577, 291, 360, 38253, 13, 51176, 51176, 407, 291, 362, 257, 777, 2281, 2445, 586, 309, 311, 1219, 462, 406, 479, 11, 462, 295, 48826, 57, 293, 281, 360, 38253, 51508, 51508, 291, 16561, 17522, 309, 365, 3104, 281, 1176, 293, 398, 13, 51681, 51681], "temperature": 0.0, "avg_logprob": -0.19358538157904326, "compression_ratio": 1.446927374301676, "no_speech_prob": 2.2824902771390043e-05}, {"id": 256, "seek": 119838, "start": 1198.38, "end": 1203.5600000000002, "text": " Okay so you ask the system give me the combination of variables of Y and Z that minimize this", "tokens": [50364, 1033, 370, 291, 1029, 264, 1185, 976, 385, 264, 6562, 295, 9102, 295, 398, 293, 1176, 300, 17522, 341, 50623, 50623, 2281, 2445, 13, 50673, 50673, 286, 767, 500, 380, 1127, 466, 264, 4190, 295, 1176, 286, 787, 1127, 466, 264, 2158, 295, 398, 457, 286, 362, 50861, 50861, 281, 360, 341, 46218, 4464, 2144, 13, 51061, 51061, 1033, 286, 603, 976, 291, 512, 544, 9859, 5110, 257, 707, 1780, 13, 51583, 51583], "temperature": 0.0, "avg_logprob": -0.14071905771891277, "compression_ratio": 1.60752688172043, "no_speech_prob": 1.83407828444615e-05}, {"id": 257, "seek": 119838, "start": 1203.5600000000002, "end": 1204.5600000000002, "text": " energy function.", "tokens": [50364, 1033, 370, 291, 1029, 264, 1185, 976, 385, 264, 6562, 295, 9102, 295, 398, 293, 1176, 300, 17522, 341, 50623, 50623, 2281, 2445, 13, 50673, 50673, 286, 767, 500, 380, 1127, 466, 264, 4190, 295, 1176, 286, 787, 1127, 466, 264, 2158, 295, 398, 457, 286, 362, 50861, 50861, 281, 360, 341, 46218, 4464, 2144, 13, 51061, 51061, 1033, 286, 603, 976, 291, 512, 544, 9859, 5110, 257, 707, 1780, 13, 51583, 51583], "temperature": 0.0, "avg_logprob": -0.14071905771891277, "compression_ratio": 1.60752688172043, "no_speech_prob": 1.83407828444615e-05}, {"id": 258, "seek": 119838, "start": 1204.5600000000002, "end": 1208.3200000000002, "text": " I actually don't care about the values of Z I only care about the value of Y but I have", "tokens": [50364, 1033, 370, 291, 1029, 264, 1185, 976, 385, 264, 6562, 295, 9102, 295, 398, 293, 1176, 300, 17522, 341, 50623, 50623, 2281, 2445, 13, 50673, 50673, 286, 767, 500, 380, 1127, 466, 264, 4190, 295, 1176, 286, 787, 1127, 466, 264, 2158, 295, 398, 457, 286, 362, 50861, 50861, 281, 360, 341, 46218, 4464, 2144, 13, 51061, 51061, 1033, 286, 603, 976, 291, 512, 544, 9859, 5110, 257, 707, 1780, 13, 51583, 51583], "temperature": 0.0, "avg_logprob": -0.14071905771891277, "compression_ratio": 1.60752688172043, "no_speech_prob": 1.83407828444615e-05}, {"id": 259, "seek": 119838, "start": 1208.3200000000002, "end": 1212.3200000000002, "text": " to do this simultaneous minimization.", "tokens": [50364, 1033, 370, 291, 1029, 264, 1185, 976, 385, 264, 6562, 295, 9102, 295, 398, 293, 1176, 300, 17522, 341, 50623, 50623, 2281, 2445, 13, 50673, 50673, 286, 767, 500, 380, 1127, 466, 264, 4190, 295, 1176, 286, 787, 1127, 466, 264, 2158, 295, 398, 457, 286, 362, 50861, 50861, 281, 360, 341, 46218, 4464, 2144, 13, 51061, 51061, 1033, 286, 603, 976, 291, 512, 544, 9859, 5110, 257, 707, 1780, 13, 51583, 51583], "temperature": 0.0, "avg_logprob": -0.14071905771891277, "compression_ratio": 1.60752688172043, "no_speech_prob": 1.83407828444615e-05}, {"id": 260, "seek": 119838, "start": 1212.3200000000002, "end": 1222.7600000000002, "text": " Okay I'll give you some more concrete examples a little later.", "tokens": [50364, 1033, 370, 291, 1029, 264, 1185, 976, 385, 264, 6562, 295, 9102, 295, 398, 293, 1176, 300, 17522, 341, 50623, 50623, 2281, 2445, 13, 50673, 50673, 286, 767, 500, 380, 1127, 466, 264, 4190, 295, 1176, 286, 787, 1127, 466, 264, 2158, 295, 398, 457, 286, 362, 50861, 50861, 281, 360, 341, 46218, 4464, 2144, 13, 51061, 51061, 1033, 286, 603, 976, 291, 512, 544, 9859, 5110, 257, 707, 1780, 13, 51583, 51583], "temperature": 0.0, "avg_logprob": -0.14071905771891277, "compression_ratio": 1.60752688172043, "no_speech_prob": 1.83407828444615e-05}, {"id": 261, "seek": 122276, "start": 1222.76, "end": 1228.96, "text": " In fact that's equivalent to defining a new energy function F which I call F infinity", "tokens": [50364, 682, 1186, 300, 311, 10344, 281, 17827, 257, 777, 2281, 2445, 479, 597, 286, 818, 479, 13202, 50674, 50674, 510, 300, 787, 5946, 322, 1783, 293, 398, 13, 50766, 50766, 479, 13202, 295, 48826, 307, 264, 923, 670, 1176, 295, 462, 295, 48826, 57, 13, 51012, 51012, 509, 747, 257, 2445, 295, 48826, 57, 291, 915, 264, 7285, 295, 341, 2445, 670, 1176, 11, 1176, 586, 2170, 20308, 51290, 51290, 291, 483, 257, 2445, 295, 1783, 293, 398, 13, 51430, 51430, 682, 3124, 291, 1128, 360, 341, 457, 294, 3124, 291, 17522, 365, 3104, 281, 1176, 293, 398, 16561, 51718, 51718], "temperature": 0.0, "avg_logprob": -0.12164111276274746, "compression_ratio": 1.7422222222222221, "no_speech_prob": 2.3548809622297995e-05}, {"id": 262, "seek": 122276, "start": 1228.96, "end": 1230.8, "text": " here that only depends on X and Y.", "tokens": [50364, 682, 1186, 300, 311, 10344, 281, 17827, 257, 777, 2281, 2445, 479, 597, 286, 818, 479, 13202, 50674, 50674, 510, 300, 787, 5946, 322, 1783, 293, 398, 13, 50766, 50766, 479, 13202, 295, 48826, 307, 264, 923, 670, 1176, 295, 462, 295, 48826, 57, 13, 51012, 51012, 509, 747, 257, 2445, 295, 48826, 57, 291, 915, 264, 7285, 295, 341, 2445, 670, 1176, 11, 1176, 586, 2170, 20308, 51290, 51290, 291, 483, 257, 2445, 295, 1783, 293, 398, 13, 51430, 51430, 682, 3124, 291, 1128, 360, 341, 457, 294, 3124, 291, 17522, 365, 3104, 281, 1176, 293, 398, 16561, 51718, 51718], "temperature": 0.0, "avg_logprob": -0.12164111276274746, "compression_ratio": 1.7422222222222221, "no_speech_prob": 2.3548809622297995e-05}, {"id": 263, "seek": 122276, "start": 1230.8, "end": 1235.72, "text": " F infinity of XY is the min over Z of E of XYZ.", "tokens": [50364, 682, 1186, 300, 311, 10344, 281, 17827, 257, 777, 2281, 2445, 479, 597, 286, 818, 479, 13202, 50674, 50674, 510, 300, 787, 5946, 322, 1783, 293, 398, 13, 50766, 50766, 479, 13202, 295, 48826, 307, 264, 923, 670, 1176, 295, 462, 295, 48826, 57, 13, 51012, 51012, 509, 747, 257, 2445, 295, 48826, 57, 291, 915, 264, 7285, 295, 341, 2445, 670, 1176, 11, 1176, 586, 2170, 20308, 51290, 51290, 291, 483, 257, 2445, 295, 1783, 293, 398, 13, 51430, 51430, 682, 3124, 291, 1128, 360, 341, 457, 294, 3124, 291, 17522, 365, 3104, 281, 1176, 293, 398, 16561, 51718, 51718], "temperature": 0.0, "avg_logprob": -0.12164111276274746, "compression_ratio": 1.7422222222222221, "no_speech_prob": 2.3548809622297995e-05}, {"id": 264, "seek": 122276, "start": 1235.72, "end": 1241.28, "text": " You take a function of XYZ you find the minimum of this function over Z, Z now gets eliminated", "tokens": [50364, 682, 1186, 300, 311, 10344, 281, 17827, 257, 777, 2281, 2445, 479, 597, 286, 818, 479, 13202, 50674, 50674, 510, 300, 787, 5946, 322, 1783, 293, 398, 13, 50766, 50766, 479, 13202, 295, 48826, 307, 264, 923, 670, 1176, 295, 462, 295, 48826, 57, 13, 51012, 51012, 509, 747, 257, 2445, 295, 48826, 57, 291, 915, 264, 7285, 295, 341, 2445, 670, 1176, 11, 1176, 586, 2170, 20308, 51290, 51290, 291, 483, 257, 2445, 295, 1783, 293, 398, 13, 51430, 51430, 682, 3124, 291, 1128, 360, 341, 457, 294, 3124, 291, 17522, 365, 3104, 281, 1176, 293, 398, 16561, 51718, 51718], "temperature": 0.0, "avg_logprob": -0.12164111276274746, "compression_ratio": 1.7422222222222221, "no_speech_prob": 2.3548809622297995e-05}, {"id": 265, "seek": 122276, "start": 1241.28, "end": 1244.08, "text": " you get a function of X and Y.", "tokens": [50364, 682, 1186, 300, 311, 10344, 281, 17827, 257, 777, 2281, 2445, 479, 597, 286, 818, 479, 13202, 50674, 50674, 510, 300, 787, 5946, 322, 1783, 293, 398, 13, 50766, 50766, 479, 13202, 295, 48826, 307, 264, 923, 670, 1176, 295, 462, 295, 48826, 57, 13, 51012, 51012, 509, 747, 257, 2445, 295, 48826, 57, 291, 915, 264, 7285, 295, 341, 2445, 670, 1176, 11, 1176, 586, 2170, 20308, 51290, 51290, 291, 483, 257, 2445, 295, 1783, 293, 398, 13, 51430, 51430, 682, 3124, 291, 1128, 360, 341, 457, 294, 3124, 291, 17522, 365, 3104, 281, 1176, 293, 398, 16561, 51718, 51718], "temperature": 0.0, "avg_logprob": -0.12164111276274746, "compression_ratio": 1.7422222222222221, "no_speech_prob": 2.3548809622297995e-05}, {"id": 266, "seek": 122276, "start": 1244.08, "end": 1249.84, "text": " In practice you never do this but in practice you minimize with respect to Z and Y simultaneously", "tokens": [50364, 682, 1186, 300, 311, 10344, 281, 17827, 257, 777, 2281, 2445, 479, 597, 286, 818, 479, 13202, 50674, 50674, 510, 300, 787, 5946, 322, 1783, 293, 398, 13, 50766, 50766, 479, 13202, 295, 48826, 307, 264, 923, 670, 1176, 295, 462, 295, 48826, 57, 13, 51012, 51012, 509, 747, 257, 2445, 295, 48826, 57, 291, 915, 264, 7285, 295, 341, 2445, 670, 1176, 11, 1176, 586, 2170, 20308, 51290, 51290, 291, 483, 257, 2445, 295, 1783, 293, 398, 13, 51430, 51430, 682, 3124, 291, 1128, 360, 341, 457, 294, 3124, 291, 17522, 365, 3104, 281, 1176, 293, 398, 16561, 51718, 51718], "temperature": 0.0, "avg_logprob": -0.12164111276274746, "compression_ratio": 1.7422222222222221, "no_speech_prob": 2.3548809622297995e-05}, {"id": 267, "seek": 124984, "start": 1249.84, "end": 1255.04, "text": " because we don't know how to represent the function.", "tokens": [50364, 570, 321, 500, 380, 458, 577, 281, 2906, 264, 2445, 13, 50624, 50624, 583, 456, 307, 364, 8535, 281, 341, 597, 307, 281, 6964, 479, 510, 597, 286, 2464, 479, 295, 9861, 50963, 50963, 420, 479, 8186, 9861, 295, 48826, 382, 3175, 472, 670, 9861, 3565, 2408, 420, 11573, 670, 1176, 295, 462, 281, 264, 3175, 51491, 51491, 9861, 462, 295, 48826, 57, 13, 51634, 51634], "temperature": 0.0, "avg_logprob": -0.1337889503030216, "compression_ratio": 1.5379746835443038, "no_speech_prob": 1.1477319276309572e-05}, {"id": 268, "seek": 124984, "start": 1255.04, "end": 1261.82, "text": " But there is an alternative to this which is to define F here which I write F of beta", "tokens": [50364, 570, 321, 500, 380, 458, 577, 281, 2906, 264, 2445, 13, 50624, 50624, 583, 456, 307, 364, 8535, 281, 341, 597, 307, 281, 6964, 479, 510, 597, 286, 2464, 479, 295, 9861, 50963, 50963, 420, 479, 8186, 9861, 295, 48826, 382, 3175, 472, 670, 9861, 3565, 2408, 420, 11573, 670, 1176, 295, 462, 281, 264, 3175, 51491, 51491, 9861, 462, 295, 48826, 57, 13, 51634, 51634], "temperature": 0.0, "avg_logprob": -0.1337889503030216, "compression_ratio": 1.5379746835443038, "no_speech_prob": 1.1477319276309572e-05}, {"id": 269, "seek": 124984, "start": 1261.82, "end": 1272.3799999999999, "text": " or F index beta of XY as minus one over beta log sum or integral over Z of E to the minus", "tokens": [50364, 570, 321, 500, 380, 458, 577, 281, 2906, 264, 2445, 13, 50624, 50624, 583, 456, 307, 364, 8535, 281, 341, 597, 307, 281, 6964, 479, 510, 597, 286, 2464, 479, 295, 9861, 50963, 50963, 420, 479, 8186, 9861, 295, 48826, 382, 3175, 472, 670, 9861, 3565, 2408, 420, 11573, 670, 1176, 295, 462, 281, 264, 3175, 51491, 51491, 9861, 462, 295, 48826, 57, 13, 51634, 51634], "temperature": 0.0, "avg_logprob": -0.1337889503030216, "compression_ratio": 1.5379746835443038, "no_speech_prob": 1.1477319276309572e-05}, {"id": 270, "seek": 124984, "start": 1272.3799999999999, "end": 1275.24, "text": " beta E of XYZ.", "tokens": [50364, 570, 321, 500, 380, 458, 577, 281, 2906, 264, 2445, 13, 50624, 50624, 583, 456, 307, 364, 8535, 281, 341, 597, 307, 281, 6964, 479, 510, 597, 286, 2464, 479, 295, 9861, 50963, 50963, 420, 479, 8186, 9861, 295, 48826, 382, 3175, 472, 670, 9861, 3565, 2408, 420, 11573, 670, 1176, 295, 462, 281, 264, 3175, 51491, 51491, 9861, 462, 295, 48826, 57, 13, 51634, 51634], "temperature": 0.0, "avg_logprob": -0.1337889503030216, "compression_ratio": 1.5379746835443038, "no_speech_prob": 1.1477319276309572e-05}, {"id": 271, "seek": 127524, "start": 1275.24, "end": 1284.64, "text": " Now a little bit of computation will you will see that if you make beta go to infinity this", "tokens": [50364, 823, 257, 707, 857, 295, 24903, 486, 291, 486, 536, 300, 498, 291, 652, 9861, 352, 281, 13202, 341, 50834, 50834, 733, 295, 479, 9861, 9652, 2880, 281, 479, 13202, 597, 307, 983, 286, 1219, 309, 479, 13202, 13, 51150, 51150, 400, 286, 1437, 807, 341, 5380, 257, 707, 3071, 294, 264, 1508, 13, 51430, 51430, 682, 341, 11573, 670, 1176, 498, 9861, 307, 588, 2416, 264, 787, 1433, 300, 307, 516, 281, 1871, 307, 264, 51722, 51722], "temperature": 0.0, "avg_logprob": -0.13359436988830567, "compression_ratio": 1.6180904522613064, "no_speech_prob": 1.777758552634623e-05}, {"id": 272, "seek": 127524, "start": 1284.64, "end": 1290.96, "text": " kind of F beta converges to F infinity which is why I called it F infinity.", "tokens": [50364, 823, 257, 707, 857, 295, 24903, 486, 291, 486, 536, 300, 498, 291, 652, 9861, 352, 281, 13202, 341, 50834, 50834, 733, 295, 479, 9861, 9652, 2880, 281, 479, 13202, 597, 307, 983, 286, 1219, 309, 479, 13202, 13, 51150, 51150, 400, 286, 1437, 807, 341, 5380, 257, 707, 3071, 294, 264, 1508, 13, 51430, 51430, 682, 341, 11573, 670, 1176, 498, 9861, 307, 588, 2416, 264, 787, 1433, 300, 307, 516, 281, 1871, 307, 264, 51722, 51722], "temperature": 0.0, "avg_logprob": -0.13359436988830567, "compression_ratio": 1.6180904522613064, "no_speech_prob": 1.777758552634623e-05}, {"id": 273, "seek": 127524, "start": 1290.96, "end": 1296.56, "text": " And I went through this exercise a little earlier in the class.", "tokens": [50364, 823, 257, 707, 857, 295, 24903, 486, 291, 486, 536, 300, 498, 291, 652, 9861, 352, 281, 13202, 341, 50834, 50834, 733, 295, 479, 9861, 9652, 2880, 281, 479, 13202, 597, 307, 983, 286, 1219, 309, 479, 13202, 13, 51150, 51150, 400, 286, 1437, 807, 341, 5380, 257, 707, 3071, 294, 264, 1508, 13, 51430, 51430, 682, 341, 11573, 670, 1176, 498, 9861, 307, 588, 2416, 264, 787, 1433, 300, 307, 516, 281, 1871, 307, 264, 51722, 51722], "temperature": 0.0, "avg_logprob": -0.13359436988830567, "compression_ratio": 1.6180904522613064, "no_speech_prob": 1.777758552634623e-05}, {"id": 274, "seek": 127524, "start": 1296.56, "end": 1302.4, "text": " In this integral over Z if beta is very large the only term that is going to matter is the", "tokens": [50364, 823, 257, 707, 857, 295, 24903, 486, 291, 486, 536, 300, 498, 291, 652, 9861, 352, 281, 13202, 341, 50834, 50834, 733, 295, 479, 9861, 9652, 2880, 281, 479, 13202, 597, 307, 983, 286, 1219, 309, 479, 13202, 13, 51150, 51150, 400, 286, 1437, 807, 341, 5380, 257, 707, 3071, 294, 264, 1508, 13, 51430, 51430, 682, 341, 11573, 670, 1176, 498, 9861, 307, 588, 2416, 264, 787, 1433, 300, 307, 516, 281, 1871, 307, 264, 51722, 51722], "temperature": 0.0, "avg_logprob": -0.13359436988830567, "compression_ratio": 1.6180904522613064, "no_speech_prob": 1.777758552634623e-05}, {"id": 275, "seek": 130240, "start": 1302.4, "end": 1309.96, "text": " term E of XYZ that has the lowest value which is the one that has the lowest value over", "tokens": [50364, 1433, 462, 295, 48826, 57, 300, 575, 264, 12437, 2158, 597, 307, 264, 472, 300, 575, 264, 12437, 2158, 670, 50742, 50742, 439, 1944, 4190, 295, 1176, 558, 13, 50848, 50848, 1436, 439, 264, 661, 2306, 366, 516, 281, 312, 709, 3801, 570, 9861, 307, 588, 588, 2416, 13, 51014, 51014, 400, 370, 456, 2158, 294, 264, 21510, 307, 406, 516, 281, 1207, 534, 264, 787, 472, 300, 311, 51210, 51210, 516, 281, 1207, 307, 264, 472, 300, 575, 264, 12437, 2158, 13, 51434, 51434, 400, 370, 498, 291, 362, 787, 472, 1433, 294, 456, 597, 307, 462, 295, 48826, 57, 337, 264, 2158, 295, 1176, 300, 51732, 51732], "temperature": 0.0, "avg_logprob": -0.11028512318929036, "compression_ratio": 2.042654028436019, "no_speech_prob": 6.203033990459517e-05}, {"id": 276, "seek": 130240, "start": 1309.96, "end": 1312.0800000000002, "text": " all possible values of Z right.", "tokens": [50364, 1433, 462, 295, 48826, 57, 300, 575, 264, 12437, 2158, 597, 307, 264, 472, 300, 575, 264, 12437, 2158, 670, 50742, 50742, 439, 1944, 4190, 295, 1176, 558, 13, 50848, 50848, 1436, 439, 264, 661, 2306, 366, 516, 281, 312, 709, 3801, 570, 9861, 307, 588, 588, 2416, 13, 51014, 51014, 400, 370, 456, 2158, 294, 264, 21510, 307, 406, 516, 281, 1207, 534, 264, 787, 472, 300, 311, 51210, 51210, 516, 281, 1207, 307, 264, 472, 300, 575, 264, 12437, 2158, 13, 51434, 51434, 400, 370, 498, 291, 362, 787, 472, 1433, 294, 456, 597, 307, 462, 295, 48826, 57, 337, 264, 2158, 295, 1176, 300, 51732, 51732], "temperature": 0.0, "avg_logprob": -0.11028512318929036, "compression_ratio": 2.042654028436019, "no_speech_prob": 6.203033990459517e-05}, {"id": 277, "seek": 130240, "start": 1312.0800000000002, "end": 1315.4, "text": " Because all the other ones are going to be much bigger because beta is very very large.", "tokens": [50364, 1433, 462, 295, 48826, 57, 300, 575, 264, 12437, 2158, 597, 307, 264, 472, 300, 575, 264, 12437, 2158, 670, 50742, 50742, 439, 1944, 4190, 295, 1176, 558, 13, 50848, 50848, 1436, 439, 264, 661, 2306, 366, 516, 281, 312, 709, 3801, 570, 9861, 307, 588, 588, 2416, 13, 51014, 51014, 400, 370, 456, 2158, 294, 264, 21510, 307, 406, 516, 281, 1207, 534, 264, 787, 472, 300, 311, 51210, 51210, 516, 281, 1207, 307, 264, 472, 300, 575, 264, 12437, 2158, 13, 51434, 51434, 400, 370, 498, 291, 362, 787, 472, 1433, 294, 456, 597, 307, 462, 295, 48826, 57, 337, 264, 2158, 295, 1176, 300, 51732, 51732], "temperature": 0.0, "avg_logprob": -0.11028512318929036, "compression_ratio": 2.042654028436019, "no_speech_prob": 6.203033990459517e-05}, {"id": 278, "seek": 130240, "start": 1315.4, "end": 1319.3200000000002, "text": " And so there value in the exponential is not going to count really the only one that's", "tokens": [50364, 1433, 462, 295, 48826, 57, 300, 575, 264, 12437, 2158, 597, 307, 264, 472, 300, 575, 264, 12437, 2158, 670, 50742, 50742, 439, 1944, 4190, 295, 1176, 558, 13, 50848, 50848, 1436, 439, 264, 661, 2306, 366, 516, 281, 312, 709, 3801, 570, 9861, 307, 588, 588, 2416, 13, 51014, 51014, 400, 370, 456, 2158, 294, 264, 21510, 307, 406, 516, 281, 1207, 534, 264, 787, 472, 300, 311, 51210, 51210, 516, 281, 1207, 307, 264, 472, 300, 575, 264, 12437, 2158, 13, 51434, 51434, 400, 370, 498, 291, 362, 787, 472, 1433, 294, 456, 597, 307, 462, 295, 48826, 57, 337, 264, 2158, 295, 1176, 300, 51732, 51732], "temperature": 0.0, "avg_logprob": -0.11028512318929036, "compression_ratio": 2.042654028436019, "no_speech_prob": 6.203033990459517e-05}, {"id": 279, "seek": 130240, "start": 1319.3200000000002, "end": 1323.8000000000002, "text": " going to count is the one that has the lowest value.", "tokens": [50364, 1433, 462, 295, 48826, 57, 300, 575, 264, 12437, 2158, 597, 307, 264, 472, 300, 575, 264, 12437, 2158, 670, 50742, 50742, 439, 1944, 4190, 295, 1176, 558, 13, 50848, 50848, 1436, 439, 264, 661, 2306, 366, 516, 281, 312, 709, 3801, 570, 9861, 307, 588, 588, 2416, 13, 51014, 51014, 400, 370, 456, 2158, 294, 264, 21510, 307, 406, 516, 281, 1207, 534, 264, 787, 472, 300, 311, 51210, 51210, 516, 281, 1207, 307, 264, 472, 300, 575, 264, 12437, 2158, 13, 51434, 51434, 400, 370, 498, 291, 362, 787, 472, 1433, 294, 456, 597, 307, 462, 295, 48826, 57, 337, 264, 2158, 295, 1176, 300, 51732, 51732], "temperature": 0.0, "avg_logprob": -0.11028512318929036, "compression_ratio": 2.042654028436019, "no_speech_prob": 6.203033990459517e-05}, {"id": 280, "seek": 130240, "start": 1323.8000000000002, "end": 1329.76, "text": " And so if you have only one term in there which is E of XYZ for the value of Z that", "tokens": [50364, 1433, 462, 295, 48826, 57, 300, 575, 264, 12437, 2158, 597, 307, 264, 472, 300, 575, 264, 12437, 2158, 670, 50742, 50742, 439, 1944, 4190, 295, 1176, 558, 13, 50848, 50848, 1436, 439, 264, 661, 2306, 366, 516, 281, 312, 709, 3801, 570, 9861, 307, 588, 588, 2416, 13, 51014, 51014, 400, 370, 456, 2158, 294, 264, 21510, 307, 406, 516, 281, 1207, 534, 264, 787, 472, 300, 311, 51210, 51210, 516, 281, 1207, 307, 264, 472, 300, 575, 264, 12437, 2158, 13, 51434, 51434, 400, 370, 498, 291, 362, 787, 472, 1433, 294, 456, 597, 307, 462, 295, 48826, 57, 337, 264, 2158, 295, 1176, 300, 51732, 51732], "temperature": 0.0, "avg_logprob": -0.11028512318929036, "compression_ratio": 2.042654028436019, "no_speech_prob": 6.203033990459517e-05}, {"id": 281, "seek": 132976, "start": 1329.76, "end": 1335.8799999999999, "text": " produces the smallest value then the log cancels the exponential and the minus one over beta", "tokens": [50364, 14725, 264, 16998, 2158, 550, 264, 3565, 393, 66, 1625, 264, 21510, 293, 264, 3175, 472, 670, 9861, 50670, 50670, 393, 66, 1625, 264, 3175, 9861, 293, 428, 1411, 597, 307, 923, 670, 1176, 295, 462, 295, 48826, 57, 1392, 13, 50966, 50966, 407, 300, 311, 264, 4948, 300, 291, 536, 3673, 13, 51302, 51302, 407, 498, 286, 6964, 479, 295, 48826, 294, 341, 636, 293, 797, 550, 286, 478, 646, 281, 264, 3894, 1154, 295, 445, 51768, 51768], "temperature": 0.0, "avg_logprob": -0.11061469419502917, "compression_ratio": 1.5851063829787233, "no_speech_prob": 3.119722168776207e-05}, {"id": 282, "seek": 132976, "start": 1335.8799999999999, "end": 1341.8, "text": " cancels the minus beta and your left which is min over Z of E of XYZ okay.", "tokens": [50364, 14725, 264, 16998, 2158, 550, 264, 3565, 393, 66, 1625, 264, 21510, 293, 264, 3175, 472, 670, 9861, 50670, 50670, 393, 66, 1625, 264, 3175, 9861, 293, 428, 1411, 597, 307, 923, 670, 1176, 295, 462, 295, 48826, 57, 1392, 13, 50966, 50966, 407, 300, 311, 264, 4948, 300, 291, 536, 3673, 13, 51302, 51302, 407, 498, 286, 6964, 479, 295, 48826, 294, 341, 636, 293, 797, 550, 286, 478, 646, 281, 264, 3894, 1154, 295, 445, 51768, 51768], "temperature": 0.0, "avg_logprob": -0.11061469419502917, "compression_ratio": 1.5851063829787233, "no_speech_prob": 3.119722168776207e-05}, {"id": 283, "seek": 132976, "start": 1341.8, "end": 1348.52, "text": " So that's the limit that you see above.", "tokens": [50364, 14725, 264, 16998, 2158, 550, 264, 3565, 393, 66, 1625, 264, 21510, 293, 264, 3175, 472, 670, 9861, 50670, 50670, 393, 66, 1625, 264, 3175, 9861, 293, 428, 1411, 597, 307, 923, 670, 1176, 295, 462, 295, 48826, 57, 1392, 13, 50966, 50966, 407, 300, 311, 264, 4948, 300, 291, 536, 3673, 13, 51302, 51302, 407, 498, 286, 6964, 479, 295, 48826, 294, 341, 636, 293, 797, 550, 286, 478, 646, 281, 264, 3894, 1154, 295, 445, 51768, 51768], "temperature": 0.0, "avg_logprob": -0.11061469419502917, "compression_ratio": 1.5851063829787233, "no_speech_prob": 3.119722168776207e-05}, {"id": 284, "seek": 132976, "start": 1348.52, "end": 1357.84, "text": " So if I define F of XY in this way and again then I'm back to the previous problem of just", "tokens": [50364, 14725, 264, 16998, 2158, 550, 264, 3565, 393, 66, 1625, 264, 21510, 293, 264, 3175, 472, 670, 9861, 50670, 50670, 393, 66, 1625, 264, 3175, 9861, 293, 428, 1411, 597, 307, 923, 670, 1176, 295, 462, 295, 48826, 57, 1392, 13, 50966, 50966, 407, 300, 311, 264, 4948, 300, 291, 536, 3673, 13, 51302, 51302, 407, 498, 286, 6964, 479, 295, 48826, 294, 341, 636, 293, 797, 550, 286, 478, 646, 281, 264, 3894, 1154, 295, 445, 51768, 51768], "temperature": 0.0, "avg_logprob": -0.11061469419502917, "compression_ratio": 1.5851063829787233, "no_speech_prob": 3.119722168776207e-05}, {"id": 285, "seek": 135784, "start": 1357.84, "end": 1364.6, "text": " minimizing F of XY with respect to Y for doing inference.", "tokens": [50364, 46608, 479, 295, 48826, 365, 3104, 281, 398, 337, 884, 38253, 13, 50702, 50702, 1033, 370, 1419, 257, 48994, 7006, 2316, 1177, 380, 652, 709, 295, 257, 2649, 291, 362, 364, 2857, 50948, 50948, 4464, 2144, 365, 3104, 281, 264, 48994, 7006, 281, 360, 457, 661, 813, 300, 309, 311, 2489, 13, 51305, 51305, 407, 456, 307, 257, 955, 5002, 611, 281, 8293, 48994, 9102, 597, 307, 300, 538, 22984, 51664, 51664], "temperature": 0.0, "avg_logprob": -0.1072709624831741, "compression_ratio": 1.6546391752577319, "no_speech_prob": 7.646019184903707e-06}, {"id": 286, "seek": 135784, "start": 1364.6, "end": 1369.52, "text": " Okay so having a latent variable model doesn't make much of a difference you have an extra", "tokens": [50364, 46608, 479, 295, 48826, 365, 3104, 281, 398, 337, 884, 38253, 13, 50702, 50702, 1033, 370, 1419, 257, 48994, 7006, 2316, 1177, 380, 652, 709, 295, 257, 2649, 291, 362, 364, 2857, 50948, 50948, 4464, 2144, 365, 3104, 281, 264, 48994, 7006, 281, 360, 457, 661, 813, 300, 309, 311, 2489, 13, 51305, 51305, 407, 456, 307, 257, 955, 5002, 611, 281, 8293, 48994, 9102, 597, 307, 300, 538, 22984, 51664, 51664], "temperature": 0.0, "avg_logprob": -0.1072709624831741, "compression_ratio": 1.6546391752577319, "no_speech_prob": 7.646019184903707e-06}, {"id": 287, "seek": 135784, "start": 1369.52, "end": 1376.6599999999999, "text": " minimization with respect to the latent variable to do but other than that it's fine.", "tokens": [50364, 46608, 479, 295, 48826, 365, 3104, 281, 398, 337, 884, 38253, 13, 50702, 50702, 1033, 370, 1419, 257, 48994, 7006, 2316, 1177, 380, 652, 709, 295, 257, 2649, 291, 362, 364, 2857, 50948, 50948, 4464, 2144, 365, 3104, 281, 264, 48994, 7006, 281, 360, 457, 661, 813, 300, 309, 311, 2489, 13, 51305, 51305, 407, 456, 307, 257, 955, 5002, 611, 281, 8293, 48994, 9102, 597, 307, 300, 538, 22984, 51664, 51664], "temperature": 0.0, "avg_logprob": -0.1072709624831741, "compression_ratio": 1.6546391752577319, "no_speech_prob": 7.646019184903707e-06}, {"id": 288, "seek": 135784, "start": 1376.6599999999999, "end": 1383.84, "text": " So there is a big advantage also to allowing latent variables which is that by varying", "tokens": [50364, 46608, 479, 295, 48826, 365, 3104, 281, 398, 337, 884, 38253, 13, 50702, 50702, 1033, 370, 1419, 257, 48994, 7006, 2316, 1177, 380, 652, 709, 295, 257, 2649, 291, 362, 364, 2857, 50948, 50948, 4464, 2144, 365, 3104, 281, 264, 48994, 7006, 281, 360, 457, 661, 813, 300, 309, 311, 2489, 13, 51305, 51305, 407, 456, 307, 257, 955, 5002, 611, 281, 8293, 48994, 9102, 597, 307, 300, 538, 22984, 51664, 51664], "temperature": 0.0, "avg_logprob": -0.1072709624831741, "compression_ratio": 1.6546391752577319, "no_speech_prob": 7.646019184903707e-06}, {"id": 289, "seek": 138384, "start": 1383.84, "end": 1389.72, "text": " the latent variable over a set I can make the output the prediction of the system vary", "tokens": [50364, 264, 48994, 7006, 670, 257, 992, 286, 393, 652, 264, 5598, 264, 17630, 295, 264, 1185, 10559, 50658, 50658, 670, 257, 992, 382, 731, 13, 50802, 50802, 407, 510, 307, 257, 1729, 9482, 510, 689, 1783, 1709, 666, 437, 286, 818, 257, 6069, 284, 51098, 51098, 597, 307, 512, 1333, 295, 18161, 2533, 309, 14725, 512, 10290, 4111, 10290, 51296, 51296, 295, 1783, 293, 550, 1783, 293, 1176, 264, 48994, 7006, 352, 666, 437, 286, 818, 510, 979, 19866, 597, 14725, 51711, 51711, 257, 17630, 398, 2159, 13, 51822, 51822], "temperature": 0.0, "avg_logprob": -0.13077663338702658, "compression_ratio": 1.8653846153846154, "no_speech_prob": 9.515740202914458e-06}, {"id": 290, "seek": 138384, "start": 1389.72, "end": 1392.6, "text": " over a set as well.", "tokens": [50364, 264, 48994, 7006, 670, 257, 992, 286, 393, 652, 264, 5598, 264, 17630, 295, 264, 1185, 10559, 50658, 50658, 670, 257, 992, 382, 731, 13, 50802, 50802, 407, 510, 307, 257, 1729, 9482, 510, 689, 1783, 1709, 666, 437, 286, 818, 257, 6069, 284, 51098, 51098, 597, 307, 512, 1333, 295, 18161, 2533, 309, 14725, 512, 10290, 4111, 10290, 51296, 51296, 295, 1783, 293, 550, 1783, 293, 1176, 264, 48994, 7006, 352, 666, 437, 286, 818, 510, 979, 19866, 597, 14725, 51711, 51711, 257, 17630, 398, 2159, 13, 51822, 51822], "temperature": 0.0, "avg_logprob": -0.13077663338702658, "compression_ratio": 1.8653846153846154, "no_speech_prob": 9.515740202914458e-06}, {"id": 291, "seek": 138384, "start": 1392.6, "end": 1398.52, "text": " So here is a particular architecture here where X goes into what I call a predictor", "tokens": [50364, 264, 48994, 7006, 670, 257, 992, 286, 393, 652, 264, 5598, 264, 17630, 295, 264, 1185, 10559, 50658, 50658, 670, 257, 992, 382, 731, 13, 50802, 50802, 407, 510, 307, 257, 1729, 9482, 510, 689, 1783, 1709, 666, 437, 286, 818, 257, 6069, 284, 51098, 51098, 597, 307, 512, 1333, 295, 18161, 2533, 309, 14725, 512, 10290, 4111, 10290, 51296, 51296, 295, 1783, 293, 550, 1783, 293, 1176, 264, 48994, 7006, 352, 666, 437, 286, 818, 510, 979, 19866, 597, 14725, 51711, 51711, 257, 17630, 398, 2159, 13, 51822, 51822], "temperature": 0.0, "avg_logprob": -0.13077663338702658, "compression_ratio": 1.8653846153846154, "no_speech_prob": 9.515740202914458e-06}, {"id": 292, "seek": 138384, "start": 1398.52, "end": 1402.48, "text": " which is some sort of neural net it produces some representation feature representation", "tokens": [50364, 264, 48994, 7006, 670, 257, 992, 286, 393, 652, 264, 5598, 264, 17630, 295, 264, 1185, 10559, 50658, 50658, 670, 257, 992, 382, 731, 13, 50802, 50802, 407, 510, 307, 257, 1729, 9482, 510, 689, 1783, 1709, 666, 437, 286, 818, 257, 6069, 284, 51098, 51098, 597, 307, 512, 1333, 295, 18161, 2533, 309, 14725, 512, 10290, 4111, 10290, 51296, 51296, 295, 1783, 293, 550, 1783, 293, 1176, 264, 48994, 7006, 352, 666, 437, 286, 818, 510, 979, 19866, 597, 14725, 51711, 51711, 257, 17630, 398, 2159, 13, 51822, 51822], "temperature": 0.0, "avg_logprob": -0.13077663338702658, "compression_ratio": 1.8653846153846154, "no_speech_prob": 9.515740202914458e-06}, {"id": 293, "seek": 138384, "start": 1402.48, "end": 1410.78, "text": " of X and then X and Z the latent variable go into what I call here decoder which produces", "tokens": [50364, 264, 48994, 7006, 670, 257, 992, 286, 393, 652, 264, 5598, 264, 17630, 295, 264, 1185, 10559, 50658, 50658, 670, 257, 992, 382, 731, 13, 50802, 50802, 407, 510, 307, 257, 1729, 9482, 510, 689, 1783, 1709, 666, 437, 286, 818, 257, 6069, 284, 51098, 51098, 597, 307, 512, 1333, 295, 18161, 2533, 309, 14725, 512, 10290, 4111, 10290, 51296, 51296, 295, 1783, 293, 550, 1783, 293, 1176, 264, 48994, 7006, 352, 666, 437, 286, 818, 510, 979, 19866, 597, 14725, 51711, 51711, 257, 17630, 398, 2159, 13, 51822, 51822], "temperature": 0.0, "avg_logprob": -0.13077663338702658, "compression_ratio": 1.8653846153846154, "no_speech_prob": 9.515740202914458e-06}, {"id": 294, "seek": 138384, "start": 1410.78, "end": 1413.0, "text": " a prediction Y bar.", "tokens": [50364, 264, 48994, 7006, 670, 257, 992, 286, 393, 652, 264, 5598, 264, 17630, 295, 264, 1185, 10559, 50658, 50658, 670, 257, 992, 382, 731, 13, 50802, 50802, 407, 510, 307, 257, 1729, 9482, 510, 689, 1783, 1709, 666, 437, 286, 818, 257, 6069, 284, 51098, 51098, 597, 307, 512, 1333, 295, 18161, 2533, 309, 14725, 512, 10290, 4111, 10290, 51296, 51296, 295, 1783, 293, 550, 1783, 293, 1176, 264, 48994, 7006, 352, 666, 437, 286, 818, 510, 979, 19866, 597, 14725, 51711, 51711, 257, 17630, 398, 2159, 13, 51822, 51822], "temperature": 0.0, "avg_logprob": -0.13077663338702658, "compression_ratio": 1.8653846153846154, "no_speech_prob": 9.515740202914458e-06}, {"id": 295, "seek": 141300, "start": 1413.0, "end": 1418.16, "text": " Okay so prediction for the variable Y that is the one that we want to predict and our", "tokens": [50364, 1033, 370, 17630, 337, 264, 7006, 398, 300, 307, 264, 472, 300, 321, 528, 281, 6069, 293, 527, 50622, 50622, 2281, 2445, 510, 445, 38334, 398, 2159, 293, 398, 309, 311, 2935, 264, 4560, 1296, 552, 13, 50850, 50850, 1033, 291, 434, 4963, 365, 341, 733, 295, 10686, 321, 2825, 466, 466, 552, 3071, 13, 51088, 51088, 407, 498, 286, 2826, 281, 10559, 1176, 670, 257, 992, 718, 311, 584, 257, 732, 12, 18759, 3732, 510, 5986, 1602, 51400, 51400, 538, 341, 10855, 10686, 550, 264, 264, 17630, 398, 2159, 307, 516, 281, 10559, 611, 670, 257, 992, 294, 51772, 51772], "temperature": 0.0, "avg_logprob": -0.13379609006122478, "compression_ratio": 1.6784313725490196, "no_speech_prob": 2.1443862351588905e-05}, {"id": 296, "seek": 141300, "start": 1418.16, "end": 1422.72, "text": " energy function here just compares Y bar and Y it's simply the distance between them.", "tokens": [50364, 1033, 370, 17630, 337, 264, 7006, 398, 300, 307, 264, 472, 300, 321, 528, 281, 6069, 293, 527, 50622, 50622, 2281, 2445, 510, 445, 38334, 398, 2159, 293, 398, 309, 311, 2935, 264, 4560, 1296, 552, 13, 50850, 50850, 1033, 291, 434, 4963, 365, 341, 733, 295, 10686, 321, 2825, 466, 466, 552, 3071, 13, 51088, 51088, 407, 498, 286, 2826, 281, 10559, 1176, 670, 257, 992, 718, 311, 584, 257, 732, 12, 18759, 3732, 510, 5986, 1602, 51400, 51400, 538, 341, 10855, 10686, 550, 264, 264, 17630, 398, 2159, 307, 516, 281, 10559, 611, 670, 257, 992, 294, 51772, 51772], "temperature": 0.0, "avg_logprob": -0.13379609006122478, "compression_ratio": 1.6784313725490196, "no_speech_prob": 2.1443862351588905e-05}, {"id": 297, "seek": 141300, "start": 1422.72, "end": 1427.48, "text": " Okay you're familiar with this kind of diagram we talked about about them earlier.", "tokens": [50364, 1033, 370, 17630, 337, 264, 7006, 398, 300, 307, 264, 472, 300, 321, 528, 281, 6069, 293, 527, 50622, 50622, 2281, 2445, 510, 445, 38334, 398, 2159, 293, 398, 309, 311, 2935, 264, 4560, 1296, 552, 13, 50850, 50850, 1033, 291, 434, 4963, 365, 341, 733, 295, 10686, 321, 2825, 466, 466, 552, 3071, 13, 51088, 51088, 407, 498, 286, 2826, 281, 10559, 1176, 670, 257, 992, 718, 311, 584, 257, 732, 12, 18759, 3732, 510, 5986, 1602, 51400, 51400, 538, 341, 10855, 10686, 550, 264, 264, 17630, 398, 2159, 307, 516, 281, 10559, 611, 670, 257, 992, 294, 51772, 51772], "temperature": 0.0, "avg_logprob": -0.13379609006122478, "compression_ratio": 1.6784313725490196, "no_speech_prob": 2.1443862351588905e-05}, {"id": 298, "seek": 141300, "start": 1427.48, "end": 1433.72, "text": " So if I choose to vary Z over a set let's say a two-dimensional square here symbolized", "tokens": [50364, 1033, 370, 17630, 337, 264, 7006, 398, 300, 307, 264, 472, 300, 321, 528, 281, 6069, 293, 527, 50622, 50622, 2281, 2445, 510, 445, 38334, 398, 2159, 293, 398, 309, 311, 2935, 264, 4560, 1296, 552, 13, 50850, 50850, 1033, 291, 434, 4963, 365, 341, 733, 295, 10686, 321, 2825, 466, 466, 552, 3071, 13, 51088, 51088, 407, 498, 286, 2826, 281, 10559, 1176, 670, 257, 992, 718, 311, 584, 257, 732, 12, 18759, 3732, 510, 5986, 1602, 51400, 51400, 538, 341, 10855, 10686, 550, 264, 264, 17630, 398, 2159, 307, 516, 281, 10559, 611, 670, 257, 992, 294, 51772, 51772], "temperature": 0.0, "avg_logprob": -0.13379609006122478, "compression_ratio": 1.6784313725490196, "no_speech_prob": 2.1443862351588905e-05}, {"id": 299, "seek": 141300, "start": 1433.72, "end": 1441.16, "text": " by this gray diagram then the the prediction Y bar is going to vary also over a set in", "tokens": [50364, 1033, 370, 17630, 337, 264, 7006, 398, 300, 307, 264, 472, 300, 321, 528, 281, 6069, 293, 527, 50622, 50622, 2281, 2445, 510, 445, 38334, 398, 2159, 293, 398, 309, 311, 2935, 264, 4560, 1296, 552, 13, 50850, 50850, 1033, 291, 434, 4963, 365, 341, 733, 295, 10686, 321, 2825, 466, 466, 552, 3071, 13, 51088, 51088, 407, 498, 286, 2826, 281, 10559, 1176, 670, 257, 992, 718, 311, 584, 257, 732, 12, 18759, 3732, 510, 5986, 1602, 51400, 51400, 538, 341, 10855, 10686, 550, 264, 264, 17630, 398, 2159, 307, 516, 281, 10559, 611, 670, 257, 992, 294, 51772, 51772], "temperature": 0.0, "avg_logprob": -0.13379609006122478, "compression_ratio": 1.6784313725490196, "no_speech_prob": 2.1443862351588905e-05}, {"id": 300, "seek": 144116, "start": 1441.16, "end": 1448.4, "text": " this case here some sort of ribbon two-dimensional ribbon and what that allows me to do is basically", "tokens": [50364, 341, 1389, 510, 512, 1333, 295, 20921, 732, 12, 18759, 20921, 293, 437, 300, 4045, 385, 281, 360, 307, 1936, 50726, 50726, 362, 257, 3479, 586, 300, 393, 5258, 3866, 23930, 13, 50882, 50882, 1033, 538, 22984, 264, 48994, 7006, 286, 393, 362, 341, 3479, 5258, 3866, 23930, 51072, 51072, 406, 445, 472, 293, 300, 311, 11462, 7379, 13, 51604, 51604], "temperature": 0.0, "avg_logprob": -0.19753846668061756, "compression_ratio": 1.5810055865921788, "no_speech_prob": 2.7533700631465763e-05}, {"id": 301, "seek": 144116, "start": 1448.4, "end": 1451.52, "text": " have a machine now that can produce multiple outputs.", "tokens": [50364, 341, 1389, 510, 512, 1333, 295, 20921, 732, 12, 18759, 20921, 293, 437, 300, 4045, 385, 281, 360, 307, 1936, 50726, 50726, 362, 257, 3479, 586, 300, 393, 5258, 3866, 23930, 13, 50882, 50882, 1033, 538, 22984, 264, 48994, 7006, 286, 393, 362, 341, 3479, 5258, 3866, 23930, 51072, 51072, 406, 445, 472, 293, 300, 311, 11462, 7379, 13, 51604, 51604], "temperature": 0.0, "avg_logprob": -0.19753846668061756, "compression_ratio": 1.5810055865921788, "no_speech_prob": 2.7533700631465763e-05}, {"id": 302, "seek": 144116, "start": 1451.52, "end": 1455.3200000000002, "text": " Okay by varying the latent variable I can have this machine produce multiple outputs", "tokens": [50364, 341, 1389, 510, 512, 1333, 295, 20921, 732, 12, 18759, 20921, 293, 437, 300, 4045, 385, 281, 360, 307, 1936, 50726, 50726, 362, 257, 3479, 586, 300, 393, 5258, 3866, 23930, 13, 50882, 50882, 1033, 538, 22984, 264, 48994, 7006, 286, 393, 362, 341, 3479, 5258, 3866, 23930, 51072, 51072, 406, 445, 472, 293, 300, 311, 11462, 7379, 13, 51604, 51604], "temperature": 0.0, "avg_logprob": -0.19753846668061756, "compression_ratio": 1.5810055865921788, "no_speech_prob": 2.7533700631465763e-05}, {"id": 303, "seek": 144116, "start": 1455.3200000000002, "end": 1465.96, "text": " not just one and that's crucial importance.", "tokens": [50364, 341, 1389, 510, 512, 1333, 295, 20921, 732, 12, 18759, 20921, 293, 437, 300, 4045, 385, 281, 360, 307, 1936, 50726, 50726, 362, 257, 3479, 586, 300, 393, 5258, 3866, 23930, 13, 50882, 50882, 1033, 538, 22984, 264, 48994, 7006, 286, 393, 362, 341, 3479, 5258, 3866, 23930, 51072, 51072, 406, 445, 472, 293, 300, 311, 11462, 7379, 13, 51604, 51604], "temperature": 0.0, "avg_logprob": -0.19753846668061756, "compression_ratio": 1.5810055865921788, "no_speech_prob": 2.7533700631465763e-05}, {"id": 304, "seek": 146596, "start": 1465.96, "end": 1473.0, "text": " Alright so let's say you're trying to do video prediction so there's many ways many reasons", "tokens": [50364, 2798, 370, 718, 311, 584, 291, 434, 1382, 281, 360, 960, 17630, 370, 456, 311, 867, 2098, 867, 4112, 50716, 50716, 983, 291, 1062, 528, 281, 360, 960, 17630, 13, 50816, 50816, 1485, 665, 1778, 307, 281, 1322, 257, 588, 665, 960, 19355, 19355, 1185, 337, 1365, 13, 51076, 51076, 3996, 665, 1778, 307, 264, 960, 291, 434, 1382, 281, 6069, 307, 264, 960, 291, 366, 1237, 412, 51340, 51340, 490, 428, 39996, 562, 291, 434, 4840, 257, 1032, 293, 291, 1116, 411, 281, 312, 1075, 281, 6069, 437, 51496, 51496, 5163, 926, 291, 366, 516, 281, 360, 341, 307, 437, 10112, 390, 1364, 322, 13, 51740, 51740], "temperature": 0.0, "avg_logprob": -0.1256384936246005, "compression_ratio": 1.995744680851064, "no_speech_prob": 1.0782619028759655e-05}, {"id": 305, "seek": 146596, "start": 1473.0, "end": 1475.0, "text": " why you might want to do video prediction.", "tokens": [50364, 2798, 370, 718, 311, 584, 291, 434, 1382, 281, 360, 960, 17630, 370, 456, 311, 867, 2098, 867, 4112, 50716, 50716, 983, 291, 1062, 528, 281, 360, 960, 17630, 13, 50816, 50816, 1485, 665, 1778, 307, 281, 1322, 257, 588, 665, 960, 19355, 19355, 1185, 337, 1365, 13, 51076, 51076, 3996, 665, 1778, 307, 264, 960, 291, 434, 1382, 281, 6069, 307, 264, 960, 291, 366, 1237, 412, 51340, 51340, 490, 428, 39996, 562, 291, 434, 4840, 257, 1032, 293, 291, 1116, 411, 281, 312, 1075, 281, 6069, 437, 51496, 51496, 5163, 926, 291, 366, 516, 281, 360, 341, 307, 437, 10112, 390, 1364, 322, 13, 51740, 51740], "temperature": 0.0, "avg_logprob": -0.1256384936246005, "compression_ratio": 1.995744680851064, "no_speech_prob": 1.0782619028759655e-05}, {"id": 306, "seek": 146596, "start": 1475.0, "end": 1480.2, "text": " One good reason is to build a very good video compression compression system for example.", "tokens": [50364, 2798, 370, 718, 311, 584, 291, 434, 1382, 281, 360, 960, 17630, 370, 456, 311, 867, 2098, 867, 4112, 50716, 50716, 983, 291, 1062, 528, 281, 360, 960, 17630, 13, 50816, 50816, 1485, 665, 1778, 307, 281, 1322, 257, 588, 665, 960, 19355, 19355, 1185, 337, 1365, 13, 51076, 51076, 3996, 665, 1778, 307, 264, 960, 291, 434, 1382, 281, 6069, 307, 264, 960, 291, 366, 1237, 412, 51340, 51340, 490, 428, 39996, 562, 291, 434, 4840, 257, 1032, 293, 291, 1116, 411, 281, 312, 1075, 281, 6069, 437, 51496, 51496, 5163, 926, 291, 366, 516, 281, 360, 341, 307, 437, 10112, 390, 1364, 322, 13, 51740, 51740], "temperature": 0.0, "avg_logprob": -0.1256384936246005, "compression_ratio": 1.995744680851064, "no_speech_prob": 1.0782619028759655e-05}, {"id": 307, "seek": 146596, "start": 1480.2, "end": 1485.48, "text": " Another good reason is the video you're trying to predict is the video you are looking at", "tokens": [50364, 2798, 370, 718, 311, 584, 291, 434, 1382, 281, 360, 960, 17630, 370, 456, 311, 867, 2098, 867, 4112, 50716, 50716, 983, 291, 1062, 528, 281, 360, 960, 17630, 13, 50816, 50816, 1485, 665, 1778, 307, 281, 1322, 257, 588, 665, 960, 19355, 19355, 1185, 337, 1365, 13, 51076, 51076, 3996, 665, 1778, 307, 264, 960, 291, 434, 1382, 281, 6069, 307, 264, 960, 291, 366, 1237, 412, 51340, 51340, 490, 428, 39996, 562, 291, 434, 4840, 257, 1032, 293, 291, 1116, 411, 281, 312, 1075, 281, 6069, 437, 51496, 51496, 5163, 926, 291, 366, 516, 281, 360, 341, 307, 437, 10112, 390, 1364, 322, 13, 51740, 51740], "temperature": 0.0, "avg_logprob": -0.1256384936246005, "compression_ratio": 1.995744680851064, "no_speech_prob": 1.0782619028759655e-05}, {"id": 308, "seek": 146596, "start": 1485.48, "end": 1488.6000000000001, "text": " from your windshield when you're driving a car and you'd like to be able to predict what", "tokens": [50364, 2798, 370, 718, 311, 584, 291, 434, 1382, 281, 360, 960, 17630, 370, 456, 311, 867, 2098, 867, 4112, 50716, 50716, 983, 291, 1062, 528, 281, 360, 960, 17630, 13, 50816, 50816, 1485, 665, 1778, 307, 281, 1322, 257, 588, 665, 960, 19355, 19355, 1185, 337, 1365, 13, 51076, 51076, 3996, 665, 1778, 307, 264, 960, 291, 434, 1382, 281, 6069, 307, 264, 960, 291, 366, 1237, 412, 51340, 51340, 490, 428, 39996, 562, 291, 434, 4840, 257, 1032, 293, 291, 1116, 411, 281, 312, 1075, 281, 6069, 437, 51496, 51496, 5163, 926, 291, 366, 516, 281, 360, 341, 307, 437, 10112, 390, 1364, 322, 13, 51740, 51740], "temperature": 0.0, "avg_logprob": -0.1256384936246005, "compression_ratio": 1.995744680851064, "no_speech_prob": 1.0782619028759655e-05}, {"id": 309, "seek": 146596, "start": 1488.6000000000001, "end": 1493.48, "text": " cars around you are going to do this is what Fred was working on.", "tokens": [50364, 2798, 370, 718, 311, 584, 291, 434, 1382, 281, 360, 960, 17630, 370, 456, 311, 867, 2098, 867, 4112, 50716, 50716, 983, 291, 1062, 528, 281, 360, 960, 17630, 13, 50816, 50816, 1485, 665, 1778, 307, 281, 1322, 257, 588, 665, 960, 19355, 19355, 1185, 337, 1365, 13, 51076, 51076, 3996, 665, 1778, 307, 264, 960, 291, 434, 1382, 281, 6069, 307, 264, 960, 291, 366, 1237, 412, 51340, 51340, 490, 428, 39996, 562, 291, 434, 4840, 257, 1032, 293, 291, 1116, 411, 281, 312, 1075, 281, 6069, 437, 51496, 51496, 5163, 926, 291, 366, 516, 281, 360, 341, 307, 437, 10112, 390, 1364, 322, 13, 51740, 51740], "temperature": 0.0, "avg_logprob": -0.1256384936246005, "compression_ratio": 1.995744680851064, "no_speech_prob": 1.0782619028759655e-05}, {"id": 310, "seek": 149348, "start": 1493.48, "end": 1498.1200000000001, "text": " And so it's very useful to be able to predict what's going to happen before it happens.", "tokens": [50364, 400, 370, 309, 311, 588, 4420, 281, 312, 1075, 281, 6069, 437, 311, 516, 281, 1051, 949, 309, 2314, 13, 50596, 50596, 682, 1186, 300, 311, 733, 295, 264, 12801, 295, 7599, 534, 264, 3485, 281, 6069, 13, 50804, 50804, 823, 291, 434, 1237, 412, 385, 558, 586, 445, 257, 3456, 291, 434, 1237, 412, 385, 558, 586, 286, 478, 51132, 51132, 1417, 291, 362, 512, 1558, 295, 264, 1349, 300, 307, 516, 281, 808, 484, 295, 452, 4525, 294, 257, 1326, 51370, 51370, 3949, 291, 362, 512, 1558, 295, 437, 22252, 286, 478, 516, 281, 360, 291, 362, 512, 1558, 295, 437, 51584, 51584, 3513, 286, 478, 516, 281, 1286, 294, 457, 406, 257, 13600, 1558, 558, 13, 51744, 51744], "temperature": 0.0, "avg_logprob": -0.10523026939330062, "compression_ratio": 1.9918032786885247, "no_speech_prob": 4.132975300308317e-05}, {"id": 311, "seek": 149348, "start": 1498.1200000000001, "end": 1502.28, "text": " In fact that's kind of the essence of intelligence really the ability to predict.", "tokens": [50364, 400, 370, 309, 311, 588, 4420, 281, 312, 1075, 281, 6069, 437, 311, 516, 281, 1051, 949, 309, 2314, 13, 50596, 50596, 682, 1186, 300, 311, 733, 295, 264, 12801, 295, 7599, 534, 264, 3485, 281, 6069, 13, 50804, 50804, 823, 291, 434, 1237, 412, 385, 558, 586, 445, 257, 3456, 291, 434, 1237, 412, 385, 558, 586, 286, 478, 51132, 51132, 1417, 291, 362, 512, 1558, 295, 264, 1349, 300, 307, 516, 281, 808, 484, 295, 452, 4525, 294, 257, 1326, 51370, 51370, 3949, 291, 362, 512, 1558, 295, 437, 22252, 286, 478, 516, 281, 360, 291, 362, 512, 1558, 295, 437, 51584, 51584, 3513, 286, 478, 516, 281, 1286, 294, 457, 406, 257, 13600, 1558, 558, 13, 51744, 51744], "temperature": 0.0, "avg_logprob": -0.10523026939330062, "compression_ratio": 1.9918032786885247, "no_speech_prob": 4.132975300308317e-05}, {"id": 312, "seek": 149348, "start": 1502.28, "end": 1508.84, "text": " Now you're looking at me right now just a minute you're looking at me right now I'm", "tokens": [50364, 400, 370, 309, 311, 588, 4420, 281, 312, 1075, 281, 6069, 437, 311, 516, 281, 1051, 949, 309, 2314, 13, 50596, 50596, 682, 1186, 300, 311, 733, 295, 264, 12801, 295, 7599, 534, 264, 3485, 281, 6069, 13, 50804, 50804, 823, 291, 434, 1237, 412, 385, 558, 586, 445, 257, 3456, 291, 434, 1237, 412, 385, 558, 586, 286, 478, 51132, 51132, 1417, 291, 362, 512, 1558, 295, 264, 1349, 300, 307, 516, 281, 808, 484, 295, 452, 4525, 294, 257, 1326, 51370, 51370, 3949, 291, 362, 512, 1558, 295, 437, 22252, 286, 478, 516, 281, 360, 291, 362, 512, 1558, 295, 437, 51584, 51584, 3513, 286, 478, 516, 281, 1286, 294, 457, 406, 257, 13600, 1558, 558, 13, 51744, 51744], "temperature": 0.0, "avg_logprob": -0.10523026939330062, "compression_ratio": 1.9918032786885247, "no_speech_prob": 4.132975300308317e-05}, {"id": 313, "seek": 149348, "start": 1508.84, "end": 1513.6, "text": " talking you have some idea of the word that is going to come out of my mouth in a few", "tokens": [50364, 400, 370, 309, 311, 588, 4420, 281, 312, 1075, 281, 6069, 437, 311, 516, 281, 1051, 949, 309, 2314, 13, 50596, 50596, 682, 1186, 300, 311, 733, 295, 264, 12801, 295, 7599, 534, 264, 3485, 281, 6069, 13, 50804, 50804, 823, 291, 434, 1237, 412, 385, 558, 586, 445, 257, 3456, 291, 434, 1237, 412, 385, 558, 586, 286, 478, 51132, 51132, 1417, 291, 362, 512, 1558, 295, 264, 1349, 300, 307, 516, 281, 808, 484, 295, 452, 4525, 294, 257, 1326, 51370, 51370, 3949, 291, 362, 512, 1558, 295, 437, 22252, 286, 478, 516, 281, 360, 291, 362, 512, 1558, 295, 437, 51584, 51584, 3513, 286, 478, 516, 281, 1286, 294, 457, 406, 257, 13600, 1558, 558, 13, 51744, 51744], "temperature": 0.0, "avg_logprob": -0.10523026939330062, "compression_ratio": 1.9918032786885247, "no_speech_prob": 4.132975300308317e-05}, {"id": 314, "seek": 149348, "start": 1513.6, "end": 1517.88, "text": " seconds you have some idea of what gesture I'm going to do you have some idea of what", "tokens": [50364, 400, 370, 309, 311, 588, 4420, 281, 312, 1075, 281, 6069, 437, 311, 516, 281, 1051, 949, 309, 2314, 13, 50596, 50596, 682, 1186, 300, 311, 733, 295, 264, 12801, 295, 7599, 534, 264, 3485, 281, 6069, 13, 50804, 50804, 823, 291, 434, 1237, 412, 385, 558, 586, 445, 257, 3456, 291, 434, 1237, 412, 385, 558, 586, 286, 478, 51132, 51132, 1417, 291, 362, 512, 1558, 295, 264, 1349, 300, 307, 516, 281, 808, 484, 295, 452, 4525, 294, 257, 1326, 51370, 51370, 3949, 291, 362, 512, 1558, 295, 437, 22252, 286, 478, 516, 281, 360, 291, 362, 512, 1558, 295, 437, 51584, 51584, 3513, 286, 478, 516, 281, 1286, 294, 457, 406, 257, 13600, 1558, 558, 13, 51744, 51744], "temperature": 0.0, "avg_logprob": -0.10523026939330062, "compression_ratio": 1.9918032786885247, "no_speech_prob": 4.132975300308317e-05}, {"id": 315, "seek": 149348, "start": 1517.88, "end": 1521.08, "text": " direction I'm going to move in but not a precise idea right.", "tokens": [50364, 400, 370, 309, 311, 588, 4420, 281, 312, 1075, 281, 6069, 437, 311, 516, 281, 1051, 949, 309, 2314, 13, 50596, 50596, 682, 1186, 300, 311, 733, 295, 264, 12801, 295, 7599, 534, 264, 3485, 281, 6069, 13, 50804, 50804, 823, 291, 434, 1237, 412, 385, 558, 586, 445, 257, 3456, 291, 434, 1237, 412, 385, 558, 586, 286, 478, 51132, 51132, 1417, 291, 362, 512, 1558, 295, 264, 1349, 300, 307, 516, 281, 808, 484, 295, 452, 4525, 294, 257, 1326, 51370, 51370, 3949, 291, 362, 512, 1558, 295, 437, 22252, 286, 478, 516, 281, 360, 291, 362, 512, 1558, 295, 437, 51584, 51584, 3513, 286, 478, 516, 281, 1286, 294, 457, 406, 257, 13600, 1558, 558, 13, 51744, 51744], "temperature": 0.0, "avg_logprob": -0.10523026939330062, "compression_ratio": 1.9918032786885247, "no_speech_prob": 4.132975300308317e-05}, {"id": 316, "seek": 152108, "start": 1521.08, "end": 1525.3999999999999, "text": " So if you train your own neural net to make a single prediction for what I'm going to", "tokens": [50364, 407, 498, 291, 3847, 428, 1065, 18161, 2533, 281, 652, 257, 2167, 17630, 337, 437, 286, 478, 516, 281, 50580, 50580, 574, 411, 732, 3949, 490, 586, 456, 311, 572, 636, 291, 393, 652, 364, 8559, 17630, 13, 50874, 50874, 759, 291, 3847, 1803, 365, 1935, 3732, 1392, 498, 291, 3847, 257, 6841, 2533, 420, 746, 51072, 51072, 281, 6069, 264, 1910, 295, 385, 510, 365, 1935, 3732, 264, 1151, 264, 1185, 393, 360, 307, 5258, 51376, 51376, 257, 37644, 3256, 295, 385, 570, 309, 1177, 380, 458, 498, 286, 478, 516, 281, 1286, 1411, 420, 558, 1177, 380, 51566, 51566, 458, 498, 452, 2377, 366, 516, 281, 312, 411, 341, 420, 411, 300, 293, 370, 309, 311, 516, 281, 5258, 51778, 51778], "temperature": 0.0, "avg_logprob": -0.0927881088256836, "compression_ratio": 1.9471698113207547, "no_speech_prob": 2.0782572391908616e-05}, {"id": 317, "seek": 152108, "start": 1525.3999999999999, "end": 1531.28, "text": " look like two seconds from now there's no way you can make an accurate prediction.", "tokens": [50364, 407, 498, 291, 3847, 428, 1065, 18161, 2533, 281, 652, 257, 2167, 17630, 337, 437, 286, 478, 516, 281, 50580, 50580, 574, 411, 732, 3949, 490, 586, 456, 311, 572, 636, 291, 393, 652, 364, 8559, 17630, 13, 50874, 50874, 759, 291, 3847, 1803, 365, 1935, 3732, 1392, 498, 291, 3847, 257, 6841, 2533, 420, 746, 51072, 51072, 281, 6069, 264, 1910, 295, 385, 510, 365, 1935, 3732, 264, 1151, 264, 1185, 393, 360, 307, 5258, 51376, 51376, 257, 37644, 3256, 295, 385, 570, 309, 1177, 380, 458, 498, 286, 478, 516, 281, 1286, 1411, 420, 558, 1177, 380, 51566, 51566, 458, 498, 452, 2377, 366, 516, 281, 312, 411, 341, 420, 411, 300, 293, 370, 309, 311, 516, 281, 5258, 51778, 51778], "temperature": 0.0, "avg_logprob": -0.0927881088256836, "compression_ratio": 1.9471698113207547, "no_speech_prob": 2.0782572391908616e-05}, {"id": 318, "seek": 152108, "start": 1531.28, "end": 1535.24, "text": " If you train yourself with least square okay if you train a commercial net or something", "tokens": [50364, 407, 498, 291, 3847, 428, 1065, 18161, 2533, 281, 652, 257, 2167, 17630, 337, 437, 286, 478, 516, 281, 50580, 50580, 574, 411, 732, 3949, 490, 586, 456, 311, 572, 636, 291, 393, 652, 364, 8559, 17630, 13, 50874, 50874, 759, 291, 3847, 1803, 365, 1935, 3732, 1392, 498, 291, 3847, 257, 6841, 2533, 420, 746, 51072, 51072, 281, 6069, 264, 1910, 295, 385, 510, 365, 1935, 3732, 264, 1151, 264, 1185, 393, 360, 307, 5258, 51376, 51376, 257, 37644, 3256, 295, 385, 570, 309, 1177, 380, 458, 498, 286, 478, 516, 281, 1286, 1411, 420, 558, 1177, 380, 51566, 51566, 458, 498, 452, 2377, 366, 516, 281, 312, 411, 341, 420, 411, 300, 293, 370, 309, 311, 516, 281, 5258, 51778, 51778], "temperature": 0.0, "avg_logprob": -0.0927881088256836, "compression_ratio": 1.9471698113207547, "no_speech_prob": 2.0782572391908616e-05}, {"id": 319, "seek": 152108, "start": 1535.24, "end": 1541.32, "text": " to predict the view of me here with least square the best the system can do is produce", "tokens": [50364, 407, 498, 291, 3847, 428, 1065, 18161, 2533, 281, 652, 257, 2167, 17630, 337, 437, 286, 478, 516, 281, 50580, 50580, 574, 411, 732, 3949, 490, 586, 456, 311, 572, 636, 291, 393, 652, 364, 8559, 17630, 13, 50874, 50874, 759, 291, 3847, 1803, 365, 1935, 3732, 1392, 498, 291, 3847, 257, 6841, 2533, 420, 746, 51072, 51072, 281, 6069, 264, 1910, 295, 385, 510, 365, 1935, 3732, 264, 1151, 264, 1185, 393, 360, 307, 5258, 51376, 51376, 257, 37644, 3256, 295, 385, 570, 309, 1177, 380, 458, 498, 286, 478, 516, 281, 1286, 1411, 420, 558, 1177, 380, 51566, 51566, 458, 498, 452, 2377, 366, 516, 281, 312, 411, 341, 420, 411, 300, 293, 370, 309, 311, 516, 281, 5258, 51778, 51778], "temperature": 0.0, "avg_logprob": -0.0927881088256836, "compression_ratio": 1.9471698113207547, "no_speech_prob": 2.0782572391908616e-05}, {"id": 320, "seek": 152108, "start": 1541.32, "end": 1545.12, "text": " a blurry image of me because it doesn't know if I'm going to move left or right doesn't", "tokens": [50364, 407, 498, 291, 3847, 428, 1065, 18161, 2533, 281, 652, 257, 2167, 17630, 337, 437, 286, 478, 516, 281, 50580, 50580, 574, 411, 732, 3949, 490, 586, 456, 311, 572, 636, 291, 393, 652, 364, 8559, 17630, 13, 50874, 50874, 759, 291, 3847, 1803, 365, 1935, 3732, 1392, 498, 291, 3847, 257, 6841, 2533, 420, 746, 51072, 51072, 281, 6069, 264, 1910, 295, 385, 510, 365, 1935, 3732, 264, 1151, 264, 1185, 393, 360, 307, 5258, 51376, 51376, 257, 37644, 3256, 295, 385, 570, 309, 1177, 380, 458, 498, 286, 478, 516, 281, 1286, 1411, 420, 558, 1177, 380, 51566, 51566, 458, 498, 452, 2377, 366, 516, 281, 312, 411, 341, 420, 411, 300, 293, 370, 309, 311, 516, 281, 5258, 51778, 51778], "temperature": 0.0, "avg_logprob": -0.0927881088256836, "compression_ratio": 1.9471698113207547, "no_speech_prob": 2.0782572391908616e-05}, {"id": 321, "seek": 152108, "start": 1545.12, "end": 1549.36, "text": " know if my hands are going to be like this or like that and so it's going to produce", "tokens": [50364, 407, 498, 291, 3847, 428, 1065, 18161, 2533, 281, 652, 257, 2167, 17630, 337, 437, 286, 478, 516, 281, 50580, 50580, 574, 411, 732, 3949, 490, 586, 456, 311, 572, 636, 291, 393, 652, 364, 8559, 17630, 13, 50874, 50874, 759, 291, 3847, 1803, 365, 1935, 3732, 1392, 498, 291, 3847, 257, 6841, 2533, 420, 746, 51072, 51072, 281, 6069, 264, 1910, 295, 385, 510, 365, 1935, 3732, 264, 1151, 264, 1185, 393, 360, 307, 5258, 51376, 51376, 257, 37644, 3256, 295, 385, 570, 309, 1177, 380, 458, 498, 286, 478, 516, 281, 1286, 1411, 420, 558, 1177, 380, 51566, 51566, 458, 498, 452, 2377, 366, 516, 281, 312, 411, 341, 420, 411, 300, 293, 370, 309, 311, 516, 281, 5258, 51778, 51778], "temperature": 0.0, "avg_logprob": -0.0927881088256836, "compression_ratio": 1.9471698113207547, "no_speech_prob": 2.0782572391908616e-05}, {"id": 322, "seek": 154936, "start": 1549.36, "end": 1554.6399999999999, "text": " the average of all the possible outcomes and that's going to be a blurry image okay.", "tokens": [50364, 264, 4274, 295, 439, 264, 1944, 10070, 293, 300, 311, 516, 281, 312, 257, 37644, 3256, 1392, 13, 50628, 50628, 407, 309, 311, 588, 1021, 300, 428, 6069, 284, 2035, 309, 307, 312, 1075, 281, 2028, 365, 15697, 50862, 50862, 293, 312, 1075, 281, 652, 3866, 21264, 293, 264, 636, 281, 13075, 1125, 264, 992, 295, 21264, 51101, 51101, 307, 807, 257, 48994, 7006, 13, 51242, 51242, 286, 478, 406, 1939, 1417, 466, 37870, 420, 31959, 3142, 15983, 341, 307, 341, 307, 636, 51532, 51532, 949, 1392, 636, 949, 321, 434, 1417, 466, 341, 1168, 456, 13, 51692, 51692], "temperature": 0.0, "avg_logprob": -0.15144042213364403, "compression_ratio": 1.788, "no_speech_prob": 1.0129064321517944e-05}, {"id": 323, "seek": 154936, "start": 1554.6399999999999, "end": 1559.32, "text": " So it's very important that your predictor whatever it is be able to deal with uncertainty", "tokens": [50364, 264, 4274, 295, 439, 264, 1944, 10070, 293, 300, 311, 516, 281, 312, 257, 37644, 3256, 1392, 13, 50628, 50628, 407, 309, 311, 588, 1021, 300, 428, 6069, 284, 2035, 309, 307, 312, 1075, 281, 2028, 365, 15697, 50862, 50862, 293, 312, 1075, 281, 652, 3866, 21264, 293, 264, 636, 281, 13075, 1125, 264, 992, 295, 21264, 51101, 51101, 307, 807, 257, 48994, 7006, 13, 51242, 51242, 286, 478, 406, 1939, 1417, 466, 37870, 420, 31959, 3142, 15983, 341, 307, 341, 307, 636, 51532, 51532, 949, 1392, 636, 949, 321, 434, 1417, 466, 341, 1168, 456, 13, 51692, 51692], "temperature": 0.0, "avg_logprob": -0.15144042213364403, "compression_ratio": 1.788, "no_speech_prob": 1.0129064321517944e-05}, {"id": 324, "seek": 154936, "start": 1559.32, "end": 1564.1, "text": " and be able to make multiple predictions and the way to parameterize the set of predictions", "tokens": [50364, 264, 4274, 295, 439, 264, 1944, 10070, 293, 300, 311, 516, 281, 312, 257, 37644, 3256, 1392, 13, 50628, 50628, 407, 309, 311, 588, 1021, 300, 428, 6069, 284, 2035, 309, 307, 312, 1075, 281, 2028, 365, 15697, 50862, 50862, 293, 312, 1075, 281, 652, 3866, 21264, 293, 264, 636, 281, 13075, 1125, 264, 992, 295, 21264, 51101, 51101, 307, 807, 257, 48994, 7006, 13, 51242, 51242, 286, 478, 406, 1939, 1417, 466, 37870, 420, 31959, 3142, 15983, 341, 307, 341, 307, 636, 51532, 51532, 949, 1392, 636, 949, 321, 434, 1417, 466, 341, 1168, 456, 13, 51692, 51692], "temperature": 0.0, "avg_logprob": -0.15144042213364403, "compression_ratio": 1.788, "no_speech_prob": 1.0129064321517944e-05}, {"id": 325, "seek": 154936, "start": 1564.1, "end": 1566.9199999999998, "text": " is through a latent variable.", "tokens": [50364, 264, 4274, 295, 439, 264, 1944, 10070, 293, 300, 311, 516, 281, 312, 257, 37644, 3256, 1392, 13, 50628, 50628, 407, 309, 311, 588, 1021, 300, 428, 6069, 284, 2035, 309, 307, 312, 1075, 281, 2028, 365, 15697, 50862, 50862, 293, 312, 1075, 281, 652, 3866, 21264, 293, 264, 636, 281, 13075, 1125, 264, 992, 295, 21264, 51101, 51101, 307, 807, 257, 48994, 7006, 13, 51242, 51242, 286, 478, 406, 1939, 1417, 466, 37870, 420, 31959, 3142, 15983, 341, 307, 341, 307, 636, 51532, 51532, 949, 1392, 636, 949, 321, 434, 1417, 466, 341, 1168, 456, 13, 51692, 51692], "temperature": 0.0, "avg_logprob": -0.15144042213364403, "compression_ratio": 1.788, "no_speech_prob": 1.0129064321517944e-05}, {"id": 326, "seek": 154936, "start": 1566.9199999999998, "end": 1572.7199999999998, "text": " I'm not yet talking about distributions or probabilistic modeling this is this is way", "tokens": [50364, 264, 4274, 295, 439, 264, 1944, 10070, 293, 300, 311, 516, 281, 312, 257, 37644, 3256, 1392, 13, 50628, 50628, 407, 309, 311, 588, 1021, 300, 428, 6069, 284, 2035, 309, 307, 312, 1075, 281, 2028, 365, 15697, 50862, 50862, 293, 312, 1075, 281, 652, 3866, 21264, 293, 264, 636, 281, 13075, 1125, 264, 992, 295, 21264, 51101, 51101, 307, 807, 257, 48994, 7006, 13, 51242, 51242, 286, 478, 406, 1939, 1417, 466, 37870, 420, 31959, 3142, 15983, 341, 307, 341, 307, 636, 51532, 51532, 949, 1392, 636, 949, 321, 434, 1417, 466, 341, 1168, 456, 13, 51692, 51692], "temperature": 0.0, "avg_logprob": -0.15144042213364403, "compression_ratio": 1.788, "no_speech_prob": 1.0129064321517944e-05}, {"id": 327, "seek": 154936, "start": 1572.7199999999998, "end": 1575.9199999999998, "text": " before okay way before we're talking about this question there.", "tokens": [50364, 264, 4274, 295, 439, 264, 1944, 10070, 293, 300, 311, 516, 281, 312, 257, 37644, 3256, 1392, 13, 50628, 50628, 407, 309, 311, 588, 1021, 300, 428, 6069, 284, 2035, 309, 307, 312, 1075, 281, 2028, 365, 15697, 50862, 50862, 293, 312, 1075, 281, 652, 3866, 21264, 293, 264, 636, 281, 13075, 1125, 264, 992, 295, 21264, 51101, 51101, 307, 807, 257, 48994, 7006, 13, 51242, 51242, 286, 478, 406, 1939, 1417, 466, 37870, 420, 31959, 3142, 15983, 341, 307, 341, 307, 636, 51532, 51532, 949, 1392, 636, 949, 321, 434, 1417, 466, 341, 1168, 456, 13, 51692, 51692], "temperature": 0.0, "avg_logprob": -0.15144042213364403, "compression_ratio": 1.788, "no_speech_prob": 1.0129064321517944e-05}, {"id": 328, "seek": 157592, "start": 1575.92, "end": 1579.48, "text": " Say again.", "tokens": [50364, 6463, 797, 13, 50542, 50542, 1042, 370, 300, 307, 406, 257, 307, 406, 257, 13075, 309, 311, 406, 257, 3364, 309, 311, 257, 2158, 300, 2962, 337, 50950, 50950, 633, 6889, 558, 13, 51104, 51104, 407, 1936, 1830, 3097, 321, 2378, 380, 2825, 466, 3097, 1939, 457, 1830, 3097, 286, 976, 51424, 51424, 291, 364, 1783, 293, 257, 398, 291, 915, 257, 1176, 300, 4464, 5660, 264, 2190, 264, 2281, 2445, 365, 264, 2190, 51668, 51668], "temperature": 0.0, "avg_logprob": -0.24138230543870193, "compression_ratio": 1.6451612903225807, "no_speech_prob": 2.0459543520701118e-05}, {"id": 329, "seek": 157592, "start": 1579.48, "end": 1587.64, "text": " Well so that is not a is not a parameter it's not a weight it's a value that changes for", "tokens": [50364, 6463, 797, 13, 50542, 50542, 1042, 370, 300, 307, 406, 257, 307, 406, 257, 13075, 309, 311, 406, 257, 3364, 309, 311, 257, 2158, 300, 2962, 337, 50950, 50950, 633, 6889, 558, 13, 51104, 51104, 407, 1936, 1830, 3097, 321, 2378, 380, 2825, 466, 3097, 1939, 457, 1830, 3097, 286, 976, 51424, 51424, 291, 364, 1783, 293, 257, 398, 291, 915, 257, 1176, 300, 4464, 5660, 264, 2190, 264, 2281, 2445, 365, 264, 2190, 51668, 51668], "temperature": 0.0, "avg_logprob": -0.24138230543870193, "compression_ratio": 1.6451612903225807, "no_speech_prob": 2.0459543520701118e-05}, {"id": 330, "seek": 157592, "start": 1587.64, "end": 1590.72, "text": " every sample right.", "tokens": [50364, 6463, 797, 13, 50542, 50542, 1042, 370, 300, 307, 406, 257, 307, 406, 257, 13075, 309, 311, 406, 257, 3364, 309, 311, 257, 2158, 300, 2962, 337, 50950, 50950, 633, 6889, 558, 13, 51104, 51104, 407, 1936, 1830, 3097, 321, 2378, 380, 2825, 466, 3097, 1939, 457, 1830, 3097, 286, 976, 51424, 51424, 291, 364, 1783, 293, 257, 398, 291, 915, 257, 1176, 300, 4464, 5660, 264, 2190, 264, 2281, 2445, 365, 264, 2190, 51668, 51668], "temperature": 0.0, "avg_logprob": -0.24138230543870193, "compression_ratio": 1.6451612903225807, "no_speech_prob": 2.0459543520701118e-05}, {"id": 331, "seek": 157592, "start": 1590.72, "end": 1597.1200000000001, "text": " So basically during training we haven't talked about training yet but during training I give", "tokens": [50364, 6463, 797, 13, 50542, 50542, 1042, 370, 300, 307, 406, 257, 307, 406, 257, 13075, 309, 311, 406, 257, 3364, 309, 311, 257, 2158, 300, 2962, 337, 50950, 50950, 633, 6889, 558, 13, 51104, 51104, 407, 1936, 1830, 3097, 321, 2378, 380, 2825, 466, 3097, 1939, 457, 1830, 3097, 286, 976, 51424, 51424, 291, 364, 1783, 293, 257, 398, 291, 915, 257, 1176, 300, 4464, 5660, 264, 2190, 264, 2281, 2445, 365, 264, 2190, 51668, 51668], "temperature": 0.0, "avg_logprob": -0.24138230543870193, "compression_ratio": 1.6451612903225807, "no_speech_prob": 2.0459543520701118e-05}, {"id": 332, "seek": 157592, "start": 1597.1200000000001, "end": 1602.0, "text": " you an X and a Y you find a Z that minimizes the current the energy function with the current", "tokens": [50364, 6463, 797, 13, 50542, 50542, 1042, 370, 300, 307, 406, 257, 307, 406, 257, 13075, 309, 311, 406, 257, 3364, 309, 311, 257, 2158, 300, 2962, 337, 50950, 50950, 633, 6889, 558, 13, 51104, 51104, 407, 1936, 1830, 3097, 321, 2378, 380, 2825, 466, 3097, 1939, 457, 1830, 3097, 286, 976, 51424, 51424, 291, 364, 1783, 293, 257, 398, 291, 915, 257, 1176, 300, 4464, 5660, 264, 2190, 264, 2281, 2445, 365, 264, 2190, 51668, 51668], "temperature": 0.0, "avg_logprob": -0.24138230543870193, "compression_ratio": 1.6451612903225807, "no_speech_prob": 2.0459543520701118e-05}, {"id": 333, "seek": 160200, "start": 1602.0, "end": 1608.0, "text": " values of the parameters of of those neural nets okay that's the best yes your best guess", "tokens": [50364, 4190, 295, 264, 9834, 295, 295, 729, 18161, 36170, 1392, 300, 311, 264, 1151, 2086, 428, 1151, 2041, 50664, 50664, 337, 437, 264, 2158, 295, 1176, 307, 293, 550, 291, 3154, 300, 281, 512, 4470, 2445, 300, 291, 434, 516, 51006, 51006, 281, 17522, 365, 3104, 281, 264, 9834, 295, 264, 3209, 264, 4470, 2445, 307, 406, 4725, 51198, 51198, 264, 4274, 406, 4725, 264, 2281, 309, 1062, 312, 746, 1646, 1392, 13, 51398, 51398, 682, 1186, 881, 295, 264, 565, 307, 746, 1646, 13, 51620, 51620], "temperature": 0.0, "avg_logprob": -0.17487506652146242, "compression_ratio": 1.8309859154929577, "no_speech_prob": 1.723042078083381e-05}, {"id": 334, "seek": 160200, "start": 1608.0, "end": 1614.84, "text": " for what the value of Z is and then you feed that to some loss function that you're going", "tokens": [50364, 4190, 295, 264, 9834, 295, 295, 729, 18161, 36170, 1392, 300, 311, 264, 1151, 2086, 428, 1151, 2041, 50664, 50664, 337, 437, 264, 2158, 295, 1176, 307, 293, 550, 291, 3154, 300, 281, 512, 4470, 2445, 300, 291, 434, 516, 51006, 51006, 281, 17522, 365, 3104, 281, 264, 9834, 295, 264, 3209, 264, 4470, 2445, 307, 406, 4725, 51198, 51198, 264, 4274, 406, 4725, 264, 2281, 309, 1062, 312, 746, 1646, 1392, 13, 51398, 51398, 682, 1186, 881, 295, 264, 565, 307, 746, 1646, 13, 51620, 51620], "temperature": 0.0, "avg_logprob": -0.17487506652146242, "compression_ratio": 1.8309859154929577, "no_speech_prob": 1.723042078083381e-05}, {"id": 335, "seek": 160200, "start": 1614.84, "end": 1618.68, "text": " to minimize with respect to the parameters of the network the loss function is not necessarily", "tokens": [50364, 4190, 295, 264, 9834, 295, 295, 729, 18161, 36170, 1392, 300, 311, 264, 1151, 2086, 428, 1151, 2041, 50664, 50664, 337, 437, 264, 2158, 295, 1176, 307, 293, 550, 291, 3154, 300, 281, 512, 4470, 2445, 300, 291, 434, 516, 51006, 51006, 281, 17522, 365, 3104, 281, 264, 9834, 295, 264, 3209, 264, 4470, 2445, 307, 406, 4725, 51198, 51198, 264, 4274, 406, 4725, 264, 2281, 309, 1062, 312, 746, 1646, 1392, 13, 51398, 51398, 682, 1186, 881, 295, 264, 565, 307, 746, 1646, 13, 51620, 51620], "temperature": 0.0, "avg_logprob": -0.17487506652146242, "compression_ratio": 1.8309859154929577, "no_speech_prob": 1.723042078083381e-05}, {"id": 336, "seek": 160200, "start": 1618.68, "end": 1622.68, "text": " the average not necessarily the energy it might be something else okay.", "tokens": [50364, 4190, 295, 264, 9834, 295, 295, 729, 18161, 36170, 1392, 300, 311, 264, 1151, 2086, 428, 1151, 2041, 50664, 50664, 337, 437, 264, 2158, 295, 1176, 307, 293, 550, 291, 3154, 300, 281, 512, 4470, 2445, 300, 291, 434, 516, 51006, 51006, 281, 17522, 365, 3104, 281, 264, 9834, 295, 264, 3209, 264, 4470, 2445, 307, 406, 4725, 51198, 51198, 264, 4274, 406, 4725, 264, 2281, 309, 1062, 312, 746, 1646, 1392, 13, 51398, 51398, 682, 1186, 881, 295, 264, 565, 307, 746, 1646, 13, 51620, 51620], "temperature": 0.0, "avg_logprob": -0.17487506652146242, "compression_ratio": 1.8309859154929577, "no_speech_prob": 1.723042078083381e-05}, {"id": 337, "seek": 160200, "start": 1622.68, "end": 1627.12, "text": " In fact most of the time is something else.", "tokens": [50364, 4190, 295, 264, 9834, 295, 295, 729, 18161, 36170, 1392, 300, 311, 264, 1151, 2086, 428, 1151, 2041, 50664, 50664, 337, 437, 264, 2158, 295, 1176, 307, 293, 550, 291, 3154, 300, 281, 512, 4470, 2445, 300, 291, 434, 516, 51006, 51006, 281, 17522, 365, 3104, 281, 264, 9834, 295, 264, 3209, 264, 4470, 2445, 307, 406, 4725, 51198, 51198, 264, 4274, 406, 4725, 264, 2281, 309, 1062, 312, 746, 1646, 1392, 13, 51398, 51398, 682, 1186, 881, 295, 264, 565, 307, 746, 1646, 13, 51620, 51620], "temperature": 0.0, "avg_logprob": -0.17487506652146242, "compression_ratio": 1.8309859154929577, "no_speech_prob": 1.723042078083381e-05}, {"id": 338, "seek": 162712, "start": 1627.12, "end": 1632.4799999999998, "text": " So in that sense you you learn Z you infer Z okay you don't want to use the term learn", "tokens": [50364, 407, 294, 300, 2020, 291, 291, 1466, 1176, 291, 13596, 1176, 1392, 291, 500, 380, 528, 281, 764, 264, 1433, 1466, 50632, 50632, 570, 2539, 1355, 291, 362, 472, 2158, 295, 264, 7006, 291, 291, 291, 1466, 337, 257, 1379, 50986, 50986, 3097, 992, 510, 337, 1176, 291, 362, 819, 2158, 337, 633, 6889, 294, 428, 3097, 992, 51204, 51204, 420, 633, 6889, 291, 1500, 992, 337, 300, 1871, 1392, 13, 51394, 51394], "temperature": 0.0, "avg_logprob": -0.18455754597981772, "compression_ratio": 1.8245614035087718, "no_speech_prob": 1.2604925359482877e-05}, {"id": 339, "seek": 162712, "start": 1632.4799999999998, "end": 1639.56, "text": " because learning means you have one value of the variable you you you learn for a whole", "tokens": [50364, 407, 294, 300, 2020, 291, 291, 1466, 1176, 291, 13596, 1176, 1392, 291, 500, 380, 528, 281, 764, 264, 1433, 1466, 50632, 50632, 570, 2539, 1355, 291, 362, 472, 2158, 295, 264, 7006, 291, 291, 291, 1466, 337, 257, 1379, 50986, 50986, 3097, 992, 510, 337, 1176, 291, 362, 819, 2158, 337, 633, 6889, 294, 428, 3097, 992, 51204, 51204, 420, 633, 6889, 291, 1500, 992, 337, 300, 1871, 1392, 13, 51394, 51394], "temperature": 0.0, "avg_logprob": -0.18455754597981772, "compression_ratio": 1.8245614035087718, "no_speech_prob": 1.2604925359482877e-05}, {"id": 340, "seek": 162712, "start": 1639.56, "end": 1643.9199999999998, "text": " training set here for Z you have different value for every sample in your training set", "tokens": [50364, 407, 294, 300, 2020, 291, 291, 1466, 1176, 291, 13596, 1176, 1392, 291, 500, 380, 528, 281, 764, 264, 1433, 1466, 50632, 50632, 570, 2539, 1355, 291, 362, 472, 2158, 295, 264, 7006, 291, 291, 291, 1466, 337, 257, 1379, 50986, 50986, 3097, 992, 510, 337, 1176, 291, 362, 819, 2158, 337, 633, 6889, 294, 428, 3097, 992, 51204, 51204, 420, 633, 6889, 291, 1500, 992, 337, 300, 1871, 1392, 13, 51394, 51394], "temperature": 0.0, "avg_logprob": -0.18455754597981772, "compression_ratio": 1.8245614035087718, "no_speech_prob": 1.2604925359482877e-05}, {"id": 341, "seek": 162712, "start": 1643.9199999999998, "end": 1647.7199999999998, "text": " or every sample you test set for that matter okay.", "tokens": [50364, 407, 294, 300, 2020, 291, 291, 1466, 1176, 291, 13596, 1176, 1392, 291, 500, 380, 528, 281, 764, 264, 1433, 1466, 50632, 50632, 570, 2539, 1355, 291, 362, 472, 2158, 295, 264, 7006, 291, 291, 291, 1466, 337, 257, 1379, 50986, 50986, 3097, 992, 510, 337, 1176, 291, 362, 819, 2158, 337, 633, 6889, 294, 428, 3097, 992, 51204, 51204, 420, 633, 6889, 291, 1500, 992, 337, 300, 1871, 1392, 13, 51394, 51394], "temperature": 0.0, "avg_logprob": -0.18455754597981772, "compression_ratio": 1.8245614035087718, "no_speech_prob": 1.2604925359482877e-05}, {"id": 342, "seek": 164772, "start": 1647.72, "end": 1657.52, "text": " So they're not learned in that sense they're inferred.", "tokens": [50364, 407, 436, 434, 406, 3264, 294, 300, 2020, 436, 434, 13596, 986, 13, 50854, 50854, 865, 1071, 1365, 295, 341, 307, 307, 12853, 370, 12853, 307, 257, 307, 257, 307, 257, 955, 1154, 51318, 51318, 2856, 12853, 570, 456, 307, 572, 2167, 3006, 12853, 295, 257, 2522, 295, 2487, 490, 51586, 51586, 472, 2856, 281, 1071, 2673, 456, 307, 257, 688, 295, 819, 2098, 281, 5109, 264, 912, 51816, 51816], "temperature": 0.0, "avg_logprob": -0.13719789187113443, "compression_ratio": 1.7877094972067038, "no_speech_prob": 8.139334568113554e-06}, {"id": 343, "seek": 164772, "start": 1657.52, "end": 1666.8, "text": " Yeah another example of this is is translation so translation is a is a is a big problem", "tokens": [50364, 407, 436, 434, 406, 3264, 294, 300, 2020, 436, 434, 13596, 986, 13, 50854, 50854, 865, 1071, 1365, 295, 341, 307, 307, 12853, 370, 12853, 307, 257, 307, 257, 307, 257, 955, 1154, 51318, 51318, 2856, 12853, 570, 456, 307, 572, 2167, 3006, 12853, 295, 257, 2522, 295, 2487, 490, 51586, 51586, 472, 2856, 281, 1071, 2673, 456, 307, 257, 688, 295, 819, 2098, 281, 5109, 264, 912, 51816, 51816], "temperature": 0.0, "avg_logprob": -0.13719789187113443, "compression_ratio": 1.7877094972067038, "no_speech_prob": 8.139334568113554e-06}, {"id": 344, "seek": 164772, "start": 1666.8, "end": 1672.16, "text": " language translation because there is no single correct translation of a piece of text from", "tokens": [50364, 407, 436, 434, 406, 3264, 294, 300, 2020, 436, 434, 13596, 986, 13, 50854, 50854, 865, 1071, 1365, 295, 341, 307, 307, 12853, 370, 12853, 307, 257, 307, 257, 307, 257, 955, 1154, 51318, 51318, 2856, 12853, 570, 456, 307, 572, 2167, 3006, 12853, 295, 257, 2522, 295, 2487, 490, 51586, 51586, 472, 2856, 281, 1071, 2673, 456, 307, 257, 688, 295, 819, 2098, 281, 5109, 264, 912, 51816, 51816], "temperature": 0.0, "avg_logprob": -0.13719789187113443, "compression_ratio": 1.7877094972067038, "no_speech_prob": 8.139334568113554e-06}, {"id": 345, "seek": 164772, "start": 1672.16, "end": 1676.76, "text": " one language to another usually there is a lot of different ways to express the same", "tokens": [50364, 407, 436, 434, 406, 3264, 294, 300, 2020, 436, 434, 13596, 986, 13, 50854, 50854, 865, 1071, 1365, 295, 341, 307, 307, 12853, 370, 12853, 307, 257, 307, 257, 307, 257, 955, 1154, 51318, 51318, 2856, 12853, 570, 456, 307, 572, 2167, 3006, 12853, 295, 257, 2522, 295, 2487, 490, 51586, 51586, 472, 2856, 281, 1071, 2673, 456, 307, 257, 688, 295, 819, 2098, 281, 5109, 264, 912, 51816, 51816], "temperature": 0.0, "avg_logprob": -0.13719789187113443, "compression_ratio": 1.7877094972067038, "no_speech_prob": 8.139334568113554e-06}, {"id": 346, "seek": 167676, "start": 1676.76, "end": 1685.64, "text": " idea and and why would you pick one over the other and so it might be nice if there was", "tokens": [50364, 1558, 293, 293, 983, 576, 291, 1888, 472, 670, 264, 661, 293, 370, 309, 1062, 312, 1481, 498, 456, 390, 50808, 50808, 512, 636, 295, 13075, 3319, 439, 264, 1944, 37578, 300, 257, 1185, 727, 5258, 300, 51036, 51036, 576, 6805, 281, 257, 2212, 2487, 718, 311, 584, 294, 6521, 300, 291, 528, 281, 13799, 666, 51250, 51250, 3669, 456, 727, 312, 3866, 12853, 294, 3669, 366, 439, 3006, 293, 538, 22984, 51480, 51480, 512, 3720, 7006, 291, 1062, 291, 458, 10559, 264, 12853, 300, 307, 7126, 13, 51804, 51804], "temperature": 0.0, "avg_logprob": -0.10725731435029404, "compression_ratio": 1.7759336099585061, "no_speech_prob": 5.3068299166625366e-05}, {"id": 347, "seek": 167676, "start": 1685.64, "end": 1690.2, "text": " some way of parameterizing all the possible translations that a system could produce that", "tokens": [50364, 1558, 293, 293, 983, 576, 291, 1888, 472, 670, 264, 661, 293, 370, 309, 1062, 312, 1481, 498, 456, 390, 50808, 50808, 512, 636, 295, 13075, 3319, 439, 264, 1944, 37578, 300, 257, 1185, 727, 5258, 300, 51036, 51036, 576, 6805, 281, 257, 2212, 2487, 718, 311, 584, 294, 6521, 300, 291, 528, 281, 13799, 666, 51250, 51250, 3669, 456, 727, 312, 3866, 12853, 294, 3669, 366, 439, 3006, 293, 538, 22984, 51480, 51480, 512, 3720, 7006, 291, 1062, 291, 458, 10559, 264, 12853, 300, 307, 7126, 13, 51804, 51804], "temperature": 0.0, "avg_logprob": -0.10725731435029404, "compression_ratio": 1.7759336099585061, "no_speech_prob": 5.3068299166625366e-05}, {"id": 348, "seek": 167676, "start": 1690.2, "end": 1694.48, "text": " would correspond to a given text let's say in German that you want to translate into", "tokens": [50364, 1558, 293, 293, 983, 576, 291, 1888, 472, 670, 264, 661, 293, 370, 309, 1062, 312, 1481, 498, 456, 390, 50808, 50808, 512, 636, 295, 13075, 3319, 439, 264, 1944, 37578, 300, 257, 1185, 727, 5258, 300, 51036, 51036, 576, 6805, 281, 257, 2212, 2487, 718, 311, 584, 294, 6521, 300, 291, 528, 281, 13799, 666, 51250, 51250, 3669, 456, 727, 312, 3866, 12853, 294, 3669, 366, 439, 3006, 293, 538, 22984, 51480, 51480, 512, 3720, 7006, 291, 1062, 291, 458, 10559, 264, 12853, 300, 307, 7126, 13, 51804, 51804], "temperature": 0.0, "avg_logprob": -0.10725731435029404, "compression_ratio": 1.7759336099585061, "no_speech_prob": 5.3068299166625366e-05}, {"id": 349, "seek": 167676, "start": 1694.48, "end": 1699.08, "text": " English there could be multiple translation in English are all correct and by varying", "tokens": [50364, 1558, 293, 293, 983, 576, 291, 1888, 472, 670, 264, 661, 293, 370, 309, 1062, 312, 1481, 498, 456, 390, 50808, 50808, 512, 636, 295, 13075, 3319, 439, 264, 1944, 37578, 300, 257, 1185, 727, 5258, 300, 51036, 51036, 576, 6805, 281, 257, 2212, 2487, 718, 311, 584, 294, 6521, 300, 291, 528, 281, 13799, 666, 51250, 51250, 3669, 456, 727, 312, 3866, 12853, 294, 3669, 366, 439, 3006, 293, 538, 22984, 51480, 51480, 512, 3720, 7006, 291, 1062, 291, 458, 10559, 264, 12853, 300, 307, 7126, 13, 51804, 51804], "temperature": 0.0, "avg_logprob": -0.10725731435029404, "compression_ratio": 1.7759336099585061, "no_speech_prob": 5.3068299166625366e-05}, {"id": 350, "seek": 167676, "start": 1699.08, "end": 1705.56, "text": " some written variable you might you know vary the translation that is produced.", "tokens": [50364, 1558, 293, 293, 983, 576, 291, 1888, 472, 670, 264, 661, 293, 370, 309, 1062, 312, 1481, 498, 456, 390, 50808, 50808, 512, 636, 295, 13075, 3319, 439, 264, 1944, 37578, 300, 257, 1185, 727, 5258, 300, 51036, 51036, 576, 6805, 281, 257, 2212, 2487, 718, 311, 584, 294, 6521, 300, 291, 528, 281, 13799, 666, 51250, 51250, 3669, 456, 727, 312, 3866, 12853, 294, 3669, 366, 439, 3006, 293, 538, 22984, 51480, 51480, 512, 3720, 7006, 291, 1062, 291, 458, 10559, 264, 12853, 300, 307, 7126, 13, 51804, 51804], "temperature": 0.0, "avg_logprob": -0.10725731435029404, "compression_ratio": 1.7759336099585061, "no_speech_prob": 5.3068299166625366e-05}, {"id": 351, "seek": 170556, "start": 1705.56, "end": 1713.8799999999999, "text": " Okay so now let's connect this with probabilistic probabilistic modeling there is a way of turning", "tokens": [50364, 1033, 370, 586, 718, 311, 1745, 341, 365, 31959, 3142, 31959, 3142, 15983, 456, 307, 257, 636, 295, 6246, 50780, 50780, 25737, 597, 291, 393, 519, 295, 382, 733, 295, 3671, 13444, 498, 291, 528, 570, 2295, 2281, 51106, 51106, 307, 665, 293, 1090, 2281, 307, 1578, 281, 1261, 25737, 666, 33783, 293, 264, 636, 281, 1261, 2281, 51458, 51458, 666, 33783, 321, 2825, 466, 341, 1217, 257, 707, 857, 307, 281, 764, 437, 311, 1219, 264, 30199, 51660, 51660], "temperature": 0.0, "avg_logprob": -0.11758957839593655, "compression_ratio": 1.821256038647343, "no_speech_prob": 7.249060581671074e-05}, {"id": 352, "seek": 170556, "start": 1713.8799999999999, "end": 1720.3999999999999, "text": " energies which you can think of as kind of negative scores if you want because low energy", "tokens": [50364, 1033, 370, 586, 718, 311, 1745, 341, 365, 31959, 3142, 31959, 3142, 15983, 456, 307, 257, 636, 295, 6246, 50780, 50780, 25737, 597, 291, 393, 519, 295, 382, 733, 295, 3671, 13444, 498, 291, 528, 570, 2295, 2281, 51106, 51106, 307, 665, 293, 1090, 2281, 307, 1578, 281, 1261, 25737, 666, 33783, 293, 264, 636, 281, 1261, 2281, 51458, 51458, 666, 33783, 321, 2825, 466, 341, 1217, 257, 707, 857, 307, 281, 764, 437, 311, 1219, 264, 30199, 51660, 51660], "temperature": 0.0, "avg_logprob": -0.11758957839593655, "compression_ratio": 1.821256038647343, "no_speech_prob": 7.249060581671074e-05}, {"id": 353, "seek": 170556, "start": 1720.3999999999999, "end": 1727.44, "text": " is good and high energy is bad to turn energies into probabilities and the way to turn energy", "tokens": [50364, 1033, 370, 586, 718, 311, 1745, 341, 365, 31959, 3142, 31959, 3142, 15983, 456, 307, 257, 636, 295, 6246, 50780, 50780, 25737, 597, 291, 393, 519, 295, 382, 733, 295, 3671, 13444, 498, 291, 528, 570, 2295, 2281, 51106, 51106, 307, 665, 293, 1090, 2281, 307, 1578, 281, 1261, 25737, 666, 33783, 293, 264, 636, 281, 1261, 2281, 51458, 51458, 666, 33783, 321, 2825, 466, 341, 1217, 257, 707, 857, 307, 281, 764, 437, 311, 1219, 264, 30199, 51660, 51660], "temperature": 0.0, "avg_logprob": -0.11758957839593655, "compression_ratio": 1.821256038647343, "no_speech_prob": 7.249060581671074e-05}, {"id": 354, "seek": 170556, "start": 1727.44, "end": 1731.48, "text": " into probabilities we talked about this already a little bit is to use what's called the Gibbs", "tokens": [50364, 1033, 370, 586, 718, 311, 1745, 341, 365, 31959, 3142, 31959, 3142, 15983, 456, 307, 257, 636, 295, 6246, 50780, 50780, 25737, 597, 291, 393, 519, 295, 382, 733, 295, 3671, 13444, 498, 291, 528, 570, 2295, 2281, 51106, 51106, 307, 665, 293, 1090, 2281, 307, 1578, 281, 1261, 25737, 666, 33783, 293, 264, 636, 281, 1261, 2281, 51458, 51458, 666, 33783, 321, 2825, 466, 341, 1217, 257, 707, 857, 307, 281, 764, 437, 311, 1219, 264, 30199, 51660, 51660], "temperature": 0.0, "avg_logprob": -0.11758957839593655, "compression_ratio": 1.821256038647343, "no_speech_prob": 7.249060581671074e-05}, {"id": 355, "seek": 173148, "start": 1731.48, "end": 1737.92, "text": " Boltzmann distribution so the the form of this you know goes back to classical statistical", "tokens": [50364, 37884, 89, 14912, 7316, 370, 264, 264, 1254, 295, 341, 291, 458, 1709, 646, 281, 13735, 22820, 50686, 50686, 10649, 294, 264, 1294, 392, 4901, 293, 264, 430, 295, 288, 2212, 2031, 307, 21510, 3175, 9861, 689, 9861, 51174, 51174, 307, 512, 5754, 264, 2281, 295, 2031, 293, 288, 293, 550, 291, 528, 281, 370, 300, 4523, 439, 729, 25737, 51554, 51554, 666, 3353, 3547, 562, 321, 747, 264, 21510, 295, 257, 1230, 1669, 309, 3353, 293, 264, 3175, 51815, 51815], "temperature": 0.0, "avg_logprob": -0.14731425549610552, "compression_ratio": 1.7102803738317758, "no_speech_prob": 5.6481309002265334e-05}, {"id": 356, "seek": 173148, "start": 1737.92, "end": 1747.68, "text": " physics in the 19th century and the P of y given x is exponential minus beta where beta", "tokens": [50364, 37884, 89, 14912, 7316, 370, 264, 264, 1254, 295, 341, 291, 458, 1709, 646, 281, 13735, 22820, 50686, 50686, 10649, 294, 264, 1294, 392, 4901, 293, 264, 430, 295, 288, 2212, 2031, 307, 21510, 3175, 9861, 689, 9861, 51174, 51174, 307, 512, 5754, 264, 2281, 295, 2031, 293, 288, 293, 550, 291, 528, 281, 370, 300, 4523, 439, 729, 25737, 51554, 51554, 666, 3353, 3547, 562, 321, 747, 264, 21510, 295, 257, 1230, 1669, 309, 3353, 293, 264, 3175, 51815, 51815], "temperature": 0.0, "avg_logprob": -0.14731425549610552, "compression_ratio": 1.7102803738317758, "no_speech_prob": 5.6481309002265334e-05}, {"id": 357, "seek": 173148, "start": 1747.68, "end": 1755.28, "text": " is some constant the energy of x and y and then you want to so that turns all those energies", "tokens": [50364, 37884, 89, 14912, 7316, 370, 264, 264, 1254, 295, 341, 291, 458, 1709, 646, 281, 13735, 22820, 50686, 50686, 10649, 294, 264, 1294, 392, 4901, 293, 264, 430, 295, 288, 2212, 2031, 307, 21510, 3175, 9861, 689, 9861, 51174, 51174, 307, 512, 5754, 264, 2281, 295, 2031, 293, 288, 293, 550, 291, 528, 281, 370, 300, 4523, 439, 729, 25737, 51554, 51554, 666, 3353, 3547, 562, 321, 747, 264, 21510, 295, 257, 1230, 1669, 309, 3353, 293, 264, 3175, 51815, 51815], "temperature": 0.0, "avg_logprob": -0.14731425549610552, "compression_ratio": 1.7102803738317758, "no_speech_prob": 5.6481309002265334e-05}, {"id": 358, "seek": 173148, "start": 1755.28, "end": 1760.5, "text": " into positive numbers when we take the exponential of a number makes it positive and the minus", "tokens": [50364, 37884, 89, 14912, 7316, 370, 264, 264, 1254, 295, 341, 291, 458, 1709, 646, 281, 13735, 22820, 50686, 50686, 10649, 294, 264, 1294, 392, 4901, 293, 264, 430, 295, 288, 2212, 2031, 307, 21510, 3175, 9861, 689, 9861, 51174, 51174, 307, 512, 5754, 264, 2281, 295, 2031, 293, 288, 293, 550, 291, 528, 281, 370, 300, 4523, 439, 729, 25737, 51554, 51554, 666, 3353, 3547, 562, 321, 747, 264, 21510, 295, 257, 1230, 1669, 309, 3353, 293, 264, 3175, 51815, 51815], "temperature": 0.0, "avg_logprob": -0.14731425549610552, "compression_ratio": 1.7102803738317758, "no_speech_prob": 5.6481309002265334e-05}, {"id": 359, "seek": 176050, "start": 1760.5, "end": 1767.52, "text": " sign is there to turn low energy into high probabilities and vice versa okay and I'm", "tokens": [50364, 1465, 307, 456, 281, 1261, 2295, 2281, 666, 1090, 33783, 293, 11964, 25650, 1392, 293, 286, 478, 50715, 50715, 1228, 341, 10286, 570, 341, 307, 437, 48716, 362, 668, 1228, 337, 264, 1036, 4901, 50975, 50975, 544, 4901, 293, 257, 1922, 13, 51237, 51237, 407, 1940, 21510, 82, 291, 291, 1261, 264, 25737, 666, 3353, 3547, 293, 550, 291, 2710, 1125, 51575, 51575, 370, 291, 2710, 1125, 294, 1270, 257, 636, 300, 264, 264, 430, 295, 288, 2031, 307, 257, 6108, 48704, 7316, 51793, 51793], "temperature": 0.0, "avg_logprob": -0.115286268036941, "compression_ratio": 1.6594827586206897, "no_speech_prob": 3.7851889373996528e-06}, {"id": 360, "seek": 176050, "start": 1767.52, "end": 1772.72, "text": " using this convention because this is what physicists have been using for the last century", "tokens": [50364, 1465, 307, 456, 281, 1261, 2295, 2281, 666, 1090, 33783, 293, 11964, 25650, 1392, 293, 286, 478, 50715, 50715, 1228, 341, 10286, 570, 341, 307, 437, 48716, 362, 668, 1228, 337, 264, 1036, 4901, 50975, 50975, 544, 4901, 293, 257, 1922, 13, 51237, 51237, 407, 1940, 21510, 82, 291, 291, 1261, 264, 25737, 666, 3353, 3547, 293, 550, 291, 2710, 1125, 51575, 51575, 370, 291, 2710, 1125, 294, 1270, 257, 636, 300, 264, 264, 430, 295, 288, 2031, 307, 257, 6108, 48704, 7316, 51793, 51793], "temperature": 0.0, "avg_logprob": -0.115286268036941, "compression_ratio": 1.6594827586206897, "no_speech_prob": 3.7851889373996528e-06}, {"id": 361, "seek": 176050, "start": 1772.72, "end": 1777.96, "text": " more century and a half.", "tokens": [50364, 1465, 307, 456, 281, 1261, 2295, 2281, 666, 1090, 33783, 293, 11964, 25650, 1392, 293, 286, 478, 50715, 50715, 1228, 341, 10286, 570, 341, 307, 437, 48716, 362, 668, 1228, 337, 264, 1036, 4901, 50975, 50975, 544, 4901, 293, 257, 1922, 13, 51237, 51237, 407, 1940, 21510, 82, 291, 291, 1261, 264, 25737, 666, 3353, 3547, 293, 550, 291, 2710, 1125, 51575, 51575, 370, 291, 2710, 1125, 294, 1270, 257, 636, 300, 264, 264, 430, 295, 288, 2031, 307, 257, 6108, 48704, 7316, 51793, 51793], "temperature": 0.0, "avg_logprob": -0.115286268036941, "compression_ratio": 1.6594827586206897, "no_speech_prob": 3.7851889373996528e-06}, {"id": 362, "seek": 176050, "start": 1777.96, "end": 1784.72, "text": " So taking exponentials you you turn the energies into positive numbers and then you normalize", "tokens": [50364, 1465, 307, 456, 281, 1261, 2295, 2281, 666, 1090, 33783, 293, 11964, 25650, 1392, 293, 286, 478, 50715, 50715, 1228, 341, 10286, 570, 341, 307, 437, 48716, 362, 668, 1228, 337, 264, 1036, 4901, 50975, 50975, 544, 4901, 293, 257, 1922, 13, 51237, 51237, 407, 1940, 21510, 82, 291, 291, 1261, 264, 25737, 666, 3353, 3547, 293, 550, 291, 2710, 1125, 51575, 51575, 370, 291, 2710, 1125, 294, 1270, 257, 636, 300, 264, 264, 430, 295, 288, 2031, 307, 257, 6108, 48704, 7316, 51793, 51793], "temperature": 0.0, "avg_logprob": -0.115286268036941, "compression_ratio": 1.6594827586206897, "no_speech_prob": 3.7851889373996528e-06}, {"id": 363, "seek": 176050, "start": 1784.72, "end": 1789.08, "text": " so you normalize in such a way that the the P of y x is a properly normalized distribution", "tokens": [50364, 1465, 307, 456, 281, 1261, 2295, 2281, 666, 1090, 33783, 293, 11964, 25650, 1392, 293, 286, 478, 50715, 50715, 1228, 341, 10286, 570, 341, 307, 437, 48716, 362, 668, 1228, 337, 264, 1036, 4901, 50975, 50975, 544, 4901, 293, 257, 1922, 13, 51237, 51237, 407, 1940, 21510, 82, 291, 291, 1261, 264, 25737, 666, 3353, 3547, 293, 550, 291, 2710, 1125, 51575, 51575, 370, 291, 2710, 1125, 294, 1270, 257, 636, 300, 264, 264, 430, 295, 288, 2031, 307, 257, 6108, 48704, 7316, 51793, 51793], "temperature": 0.0, "avg_logprob": -0.115286268036941, "compression_ratio": 1.6594827586206897, "no_speech_prob": 3.7851889373996528e-06}, {"id": 364, "seek": 178908, "start": 1789.08, "end": 1794.9199999999998, "text": " over y and to make it a properly distribution normalized distribution over y you divide by", "tokens": [50364, 670, 288, 293, 281, 652, 309, 257, 6108, 7316, 48704, 7316, 670, 288, 291, 9845, 538, 50656, 50656, 264, 11573, 420, 264, 2408, 498, 288, 307, 27706, 670, 288, 295, 308, 281, 264, 3175, 9861, 283, 295, 2031, 288, 597, 307, 50936, 50936, 264, 912, 551, 382, 264, 1192, 3993, 291, 291, 13365, 670, 439, 1944, 4190, 295, 288, 13, 823, 498, 291, 51438, 51438, 14722, 264, 11573, 295, 341, 670, 288, 307, 2681, 281, 472, 570, 2745, 291, 483, 264, 11573, 51646, 51646], "temperature": 0.0, "avg_logprob": -0.11826273452403933, "compression_ratio": 1.7707317073170732, "no_speech_prob": 1.4284725693869404e-05}, {"id": 365, "seek": 178908, "start": 1794.9199999999998, "end": 1800.52, "text": " the integral or the sum if y is discrete over y of e to the minus beta f of x y which is", "tokens": [50364, 670, 288, 293, 281, 652, 309, 257, 6108, 7316, 48704, 7316, 670, 288, 291, 9845, 538, 50656, 50656, 264, 11573, 420, 264, 2408, 498, 288, 307, 27706, 670, 288, 295, 308, 281, 264, 3175, 9861, 283, 295, 2031, 288, 597, 307, 50936, 50936, 264, 912, 551, 382, 264, 1192, 3993, 291, 291, 13365, 670, 439, 1944, 4190, 295, 288, 13, 823, 498, 291, 51438, 51438, 14722, 264, 11573, 295, 341, 670, 288, 307, 2681, 281, 472, 570, 2745, 291, 483, 264, 11573, 51646, 51646], "temperature": 0.0, "avg_logprob": -0.11826273452403933, "compression_ratio": 1.7707317073170732, "no_speech_prob": 1.4284725693869404e-05}, {"id": 366, "seek": 178908, "start": 1800.52, "end": 1810.56, "text": " the same thing as the top except you you integrate over all possible values of y. Now if you", "tokens": [50364, 670, 288, 293, 281, 652, 309, 257, 6108, 7316, 48704, 7316, 670, 288, 291, 9845, 538, 50656, 50656, 264, 11573, 420, 264, 2408, 498, 288, 307, 27706, 670, 288, 295, 308, 281, 264, 3175, 9861, 283, 295, 2031, 288, 597, 307, 50936, 50936, 264, 912, 551, 382, 264, 1192, 3993, 291, 291, 13365, 670, 439, 1944, 4190, 295, 288, 13, 823, 498, 291, 51438, 51438, 14722, 264, 11573, 295, 341, 670, 288, 307, 2681, 281, 472, 570, 2745, 291, 483, 264, 11573, 51646, 51646], "temperature": 0.0, "avg_logprob": -0.11826273452403933, "compression_ratio": 1.7707317073170732, "no_speech_prob": 1.4284725693869404e-05}, {"id": 367, "seek": 178908, "start": 1810.56, "end": 1814.72, "text": " compute the integral of this over y is equal to one because obviously you get the integral", "tokens": [50364, 670, 288, 293, 281, 652, 309, 257, 6108, 7316, 48704, 7316, 670, 288, 291, 9845, 538, 50656, 50656, 264, 11573, 420, 264, 2408, 498, 288, 307, 27706, 670, 288, 295, 308, 281, 264, 3175, 9861, 283, 295, 2031, 288, 597, 307, 50936, 50936, 264, 912, 551, 382, 264, 1192, 3993, 291, 291, 13365, 670, 439, 1944, 4190, 295, 288, 13, 823, 498, 291, 51438, 51438, 14722, 264, 11573, 295, 341, 670, 288, 307, 2681, 281, 472, 570, 2745, 291, 483, 264, 11573, 51646, 51646], "temperature": 0.0, "avg_logprob": -0.11826273452403933, "compression_ratio": 1.7707317073170732, "no_speech_prob": 1.4284725693869404e-05}, {"id": 368, "seek": 181472, "start": 1814.72, "end": 1820.72, "text": " on top integral at the bottom which is a constant and you get one okay so that confirms that", "tokens": [50364, 322, 1192, 11573, 412, 264, 2767, 597, 307, 257, 5754, 293, 291, 483, 472, 1392, 370, 300, 39982, 300, 50664, 50664, 341, 307, 733, 295, 341, 575, 341, 44271, 264, 6360, 72, 4785, 420, 8482, 37870, 300, 575, 50962, 50962, 281, 312, 3353, 3547, 300, 13365, 281, 472, 13, 51342, 51342, 821, 311, 257, 1729, 411, 456, 311, 867, 2098, 281, 1261, 257, 3840, 295, 411, 257, 2445, 666, 257, 51572, 51572, 2445, 300, 3572, 1024, 281, 472, 257, 3353, 2445, 3572, 1024, 281, 472, 437, 311, 341, 472, 51803, 51803], "temperature": 0.0, "avg_logprob": -0.14170502078148625, "compression_ratio": 1.8472222222222223, "no_speech_prob": 2.4060682335402817e-06}, {"id": 369, "seek": 181472, "start": 1820.72, "end": 1826.68, "text": " this is kind of this has this satisfies the axioms or probability distributions that has", "tokens": [50364, 322, 1192, 11573, 412, 264, 2767, 597, 307, 257, 5754, 293, 291, 483, 472, 1392, 370, 300, 39982, 300, 50664, 50664, 341, 307, 733, 295, 341, 575, 341, 44271, 264, 6360, 72, 4785, 420, 8482, 37870, 300, 575, 50962, 50962, 281, 312, 3353, 3547, 300, 13365, 281, 472, 13, 51342, 51342, 821, 311, 257, 1729, 411, 456, 311, 867, 2098, 281, 1261, 257, 3840, 295, 411, 257, 2445, 666, 257, 51572, 51572, 2445, 300, 3572, 1024, 281, 472, 257, 3353, 2445, 3572, 1024, 281, 472, 437, 311, 341, 472, 51803, 51803], "temperature": 0.0, "avg_logprob": -0.14170502078148625, "compression_ratio": 1.8472222222222223, "no_speech_prob": 2.4060682335402817e-06}, {"id": 370, "seek": 181472, "start": 1826.68, "end": 1834.28, "text": " to be positive numbers that integrate to one.", "tokens": [50364, 322, 1192, 11573, 412, 264, 2767, 597, 307, 257, 5754, 293, 291, 483, 472, 1392, 370, 300, 39982, 300, 50664, 50664, 341, 307, 733, 295, 341, 575, 341, 44271, 264, 6360, 72, 4785, 420, 8482, 37870, 300, 575, 50962, 50962, 281, 312, 3353, 3547, 300, 13365, 281, 472, 13, 51342, 51342, 821, 311, 257, 1729, 411, 456, 311, 867, 2098, 281, 1261, 257, 3840, 295, 411, 257, 2445, 666, 257, 51572, 51572, 2445, 300, 3572, 1024, 281, 472, 257, 3353, 2445, 3572, 1024, 281, 472, 437, 311, 341, 472, 51803, 51803], "temperature": 0.0, "avg_logprob": -0.14170502078148625, "compression_ratio": 1.8472222222222223, "no_speech_prob": 2.4060682335402817e-06}, {"id": 371, "seek": 181472, "start": 1834.28, "end": 1838.88, "text": " There's a particular like there's many ways to turn a bunch of like a function into a", "tokens": [50364, 322, 1192, 11573, 412, 264, 2767, 597, 307, 257, 5754, 293, 291, 483, 472, 1392, 370, 300, 39982, 300, 50664, 50664, 341, 307, 733, 295, 341, 575, 341, 44271, 264, 6360, 72, 4785, 420, 8482, 37870, 300, 575, 50962, 50962, 281, 312, 3353, 3547, 300, 13365, 281, 472, 13, 51342, 51342, 821, 311, 257, 1729, 411, 456, 311, 867, 2098, 281, 1261, 257, 3840, 295, 411, 257, 2445, 666, 257, 51572, 51572, 2445, 300, 3572, 1024, 281, 472, 257, 3353, 2445, 3572, 1024, 281, 472, 437, 311, 341, 472, 51803, 51803], "temperature": 0.0, "avg_logprob": -0.14170502078148625, "compression_ratio": 1.8472222222222223, "no_speech_prob": 2.4060682335402817e-06}, {"id": 372, "seek": 181472, "start": 1838.88, "end": 1843.5, "text": " function that integrates to one a positive function integrates to one what's this one", "tokens": [50364, 322, 1192, 11573, 412, 264, 2767, 597, 307, 257, 5754, 293, 291, 483, 472, 1392, 370, 300, 39982, 300, 50664, 50664, 341, 307, 733, 295, 341, 575, 341, 44271, 264, 6360, 72, 4785, 420, 8482, 37870, 300, 575, 50962, 50962, 281, 312, 3353, 3547, 300, 13365, 281, 472, 13, 51342, 51342, 821, 311, 257, 1729, 411, 456, 311, 867, 2098, 281, 1261, 257, 3840, 295, 411, 257, 2445, 666, 257, 51572, 51572, 2445, 300, 3572, 1024, 281, 472, 257, 3353, 2445, 3572, 1024, 281, 472, 437, 311, 341, 472, 51803, 51803], "temperature": 0.0, "avg_logprob": -0.14170502078148625, "compression_ratio": 1.8472222222222223, "no_speech_prob": 2.4060682335402817e-06}, {"id": 373, "seek": 184350, "start": 1843.5, "end": 1849.0, "text": " has interesting properties which I'm not going to go through but corresponds to the so-called", "tokens": [50364, 575, 1880, 7221, 597, 286, 478, 406, 516, 281, 352, 807, 457, 23249, 281, 264, 370, 12, 11880, 50639, 50639, 6674, 30867, 7316, 13, 50869, 50869, 440, 9861, 13075, 307, 733, 295, 23211, 309, 311, 264, 636, 291, 21583, 4404, 428, 33783, 382, 51147, 51147, 257, 2445, 295, 428, 2281, 370, 264, 4833, 264, 9861, 264, 544, 370, 17434, 428, 428, 8482, 51455, 51455, 486, 312, 337, 257, 2212, 2281, 2445, 13, 51559, 51559], "temperature": 0.0, "avg_logprob": -0.19636728889063784, "compression_ratio": 1.6376811594202898, "no_speech_prob": 9.36809738050215e-06}, {"id": 374, "seek": 184350, "start": 1849.0, "end": 1853.6, "text": " maximum entropy distribution.", "tokens": [50364, 575, 1880, 7221, 597, 286, 478, 406, 516, 281, 352, 807, 457, 23249, 281, 264, 370, 12, 11880, 50639, 50639, 6674, 30867, 7316, 13, 50869, 50869, 440, 9861, 13075, 307, 733, 295, 23211, 309, 311, 264, 636, 291, 21583, 4404, 428, 33783, 382, 51147, 51147, 257, 2445, 295, 428, 2281, 370, 264, 4833, 264, 9861, 264, 544, 370, 17434, 428, 428, 8482, 51455, 51455, 486, 312, 337, 257, 2212, 2281, 2445, 13, 51559, 51559], "temperature": 0.0, "avg_logprob": -0.19636728889063784, "compression_ratio": 1.6376811594202898, "no_speech_prob": 9.36809738050215e-06}, {"id": 375, "seek": 184350, "start": 1853.6, "end": 1859.16, "text": " The beta parameter is kind of arbitrary it's the way you calibrate your probabilities as", "tokens": [50364, 575, 1880, 7221, 597, 286, 478, 406, 516, 281, 352, 807, 457, 23249, 281, 264, 370, 12, 11880, 50639, 50639, 6674, 30867, 7316, 13, 50869, 50869, 440, 9861, 13075, 307, 733, 295, 23211, 309, 311, 264, 636, 291, 21583, 4404, 428, 33783, 382, 51147, 51147, 257, 2445, 295, 428, 2281, 370, 264, 4833, 264, 9861, 264, 544, 370, 17434, 428, 428, 8482, 51455, 51455, 486, 312, 337, 257, 2212, 2281, 2445, 13, 51559, 51559], "temperature": 0.0, "avg_logprob": -0.19636728889063784, "compression_ratio": 1.6376811594202898, "no_speech_prob": 9.36809738050215e-06}, {"id": 376, "seek": 184350, "start": 1859.16, "end": 1865.32, "text": " a function of your energy so the larger the beta the more so binary your your probability", "tokens": [50364, 575, 1880, 7221, 597, 286, 478, 406, 516, 281, 352, 807, 457, 23249, 281, 264, 370, 12, 11880, 50639, 50639, 6674, 30867, 7316, 13, 50869, 50869, 440, 9861, 13075, 307, 733, 295, 23211, 309, 311, 264, 636, 291, 21583, 4404, 428, 33783, 382, 51147, 51147, 257, 2445, 295, 428, 2281, 370, 264, 4833, 264, 9861, 264, 544, 370, 17434, 428, 428, 8482, 51455, 51455, 486, 312, 337, 257, 2212, 2281, 2445, 13, 51559, 51559], "temperature": 0.0, "avg_logprob": -0.19636728889063784, "compression_ratio": 1.6376811594202898, "no_speech_prob": 9.36809738050215e-06}, {"id": 377, "seek": 184350, "start": 1865.32, "end": 1867.4, "text": " will be for a given energy function.", "tokens": [50364, 575, 1880, 7221, 597, 286, 478, 406, 516, 281, 352, 807, 457, 23249, 281, 264, 370, 12, 11880, 50639, 50639, 6674, 30867, 7316, 13, 50869, 50869, 440, 9861, 13075, 307, 733, 295, 23211, 309, 311, 264, 636, 291, 21583, 4404, 428, 33783, 382, 51147, 51147, 257, 2445, 295, 428, 2281, 370, 264, 4833, 264, 9861, 264, 544, 370, 17434, 428, 428, 8482, 51455, 51455, 486, 312, 337, 257, 2212, 2281, 2445, 13, 51559, 51559], "temperature": 0.0, "avg_logprob": -0.19636728889063784, "compression_ratio": 1.6376811594202898, "no_speech_prob": 9.36809738050215e-06}, {"id": 378, "seek": 186740, "start": 1867.4, "end": 1876.96, "text": " Beta is very very large is basically just the the the e of x y that for the y that produces", "tokens": [50364, 33286, 307, 588, 588, 2416, 307, 1936, 445, 264, 264, 264, 308, 295, 2031, 288, 300, 337, 264, 288, 300, 14725, 50842, 50842, 264, 12437, 2281, 300, 486, 362, 1090, 8482, 293, 1203, 1646, 486, 362, 588, 2295, 8482, 51056, 51056, 293, 337, 1359, 9861, 337, 257, 337, 1359, 9861, 550, 291, 483, 733, 295, 257, 28640, 7316, 1392, 13, 51442, 51442, 33286, 294, 10649, 1433, 307, 47540, 281, 364, 17340, 4292, 1392, 370, 264, 9861, 1709, 281, 13202, 51770, 51770], "temperature": 0.0, "avg_logprob": -0.1444695369306817, "compression_ratio": 1.7799043062200957, "no_speech_prob": 9.223097549693193e-06}, {"id": 379, "seek": 186740, "start": 1876.96, "end": 1881.24, "text": " the lowest energy that will have high probability and everything else will have very low probability", "tokens": [50364, 33286, 307, 588, 588, 2416, 307, 1936, 445, 264, 264, 264, 308, 295, 2031, 288, 300, 337, 264, 288, 300, 14725, 50842, 50842, 264, 12437, 2281, 300, 486, 362, 1090, 8482, 293, 1203, 1646, 486, 362, 588, 2295, 8482, 51056, 51056, 293, 337, 1359, 9861, 337, 257, 337, 1359, 9861, 550, 291, 483, 733, 295, 257, 28640, 7316, 1392, 13, 51442, 51442, 33286, 294, 10649, 1433, 307, 47540, 281, 364, 17340, 4292, 1392, 370, 264, 9861, 1709, 281, 13202, 51770, 51770], "temperature": 0.0, "avg_logprob": -0.1444695369306817, "compression_ratio": 1.7799043062200957, "no_speech_prob": 9.223097549693193e-06}, {"id": 380, "seek": 186740, "start": 1881.24, "end": 1888.96, "text": " and for small beta for a for small beta then you get kind of a smoother distribution okay.", "tokens": [50364, 33286, 307, 588, 588, 2416, 307, 1936, 445, 264, 264, 264, 308, 295, 2031, 288, 300, 337, 264, 288, 300, 14725, 50842, 50842, 264, 12437, 2281, 300, 486, 362, 1090, 8482, 293, 1203, 1646, 486, 362, 588, 2295, 8482, 51056, 51056, 293, 337, 1359, 9861, 337, 257, 337, 1359, 9861, 550, 291, 483, 733, 295, 257, 28640, 7316, 1392, 13, 51442, 51442, 33286, 294, 10649, 1433, 307, 47540, 281, 364, 17340, 4292, 1392, 370, 264, 9861, 1709, 281, 13202, 51770, 51770], "temperature": 0.0, "avg_logprob": -0.1444695369306817, "compression_ratio": 1.7799043062200957, "no_speech_prob": 9.223097549693193e-06}, {"id": 381, "seek": 186740, "start": 1888.96, "end": 1895.52, "text": " Beta in physics term is akin to an inverse temperature okay so the beta goes to infinity", "tokens": [50364, 33286, 307, 588, 588, 2416, 307, 1936, 445, 264, 264, 264, 308, 295, 2031, 288, 300, 337, 264, 288, 300, 14725, 50842, 50842, 264, 12437, 2281, 300, 486, 362, 1090, 8482, 293, 1203, 1646, 486, 362, 588, 2295, 8482, 51056, 51056, 293, 337, 1359, 9861, 337, 257, 337, 1359, 9861, 550, 291, 483, 733, 295, 257, 28640, 7316, 1392, 13, 51442, 51442, 33286, 294, 10649, 1433, 307, 47540, 281, 364, 17340, 4292, 1392, 370, 264, 9861, 1709, 281, 13202, 51770, 51770], "temperature": 0.0, "avg_logprob": -0.1444695369306817, "compression_ratio": 1.7799043062200957, "no_speech_prob": 9.223097549693193e-06}, {"id": 382, "seek": 189552, "start": 1895.52, "end": 1905.32, "text": " is equal to zero temperature.", "tokens": [50364, 307, 2681, 281, 4018, 4292, 13, 50854, 50854, 1033, 257, 707, 857, 295, 5221, 309, 311, 406, 300, 6958, 13, 51114, 51114, 1407, 855, 291, 689, 264, 8513, 337, 283, 9861, 1487, 490, 300, 286, 2825, 466, 3071, 13, 51560, 51560], "temperature": 0.0, "avg_logprob": -0.13047630842341934, "compression_ratio": 1.2868852459016393, "no_speech_prob": 1.2410164345055819e-05}, {"id": 383, "seek": 189552, "start": 1905.32, "end": 1910.52, "text": " Okay a little bit of math it's not that scary.", "tokens": [50364, 307, 2681, 281, 4018, 4292, 13, 50854, 50854, 1033, 257, 707, 857, 295, 5221, 309, 311, 406, 300, 6958, 13, 51114, 51114, 1407, 855, 291, 689, 264, 8513, 337, 283, 9861, 1487, 490, 300, 286, 2825, 466, 3071, 13, 51560, 51560], "temperature": 0.0, "avg_logprob": -0.13047630842341934, "compression_ratio": 1.2868852459016393, "no_speech_prob": 1.2410164345055819e-05}, {"id": 384, "seek": 189552, "start": 1910.52, "end": 1919.44, "text": " To show you where the formula for f beta comes from that I talked about earlier.", "tokens": [50364, 307, 2681, 281, 4018, 4292, 13, 50854, 50854, 1033, 257, 707, 857, 295, 5221, 309, 311, 406, 300, 6958, 13, 51114, 51114, 1407, 855, 291, 689, 264, 8513, 337, 283, 9861, 1487, 490, 300, 286, 2825, 466, 3071, 13, 51560, 51560], "temperature": 0.0, "avg_logprob": -0.13047630842341934, "compression_ratio": 1.2868852459016393, "no_speech_prob": 1.2410164345055819e-05}, {"id": 385, "seek": 191944, "start": 1919.44, "end": 1927.64, "text": " So let's go through this a little slowly here.", "tokens": [50364, 407, 718, 311, 352, 807, 341, 257, 707, 5692, 510, 13, 50774, 50774, 440, 7225, 8482, 295, 280, 295, 288, 293, 710, 2212, 2031, 1392, 286, 3079, 264, 912, 37884, 89, 14912, 30199, 12, 33, 4837, 89, 14912, 51110, 51110, 7316, 8513, 382, 286, 1143, 949, 3993, 586, 309, 311, 257, 7225, 7316, 670, 288, 293, 710, 51410, 51410, 2602, 295, 445, 257, 7316, 670, 288, 341, 307, 337, 257, 48994, 7006, 2316, 1392, 13, 51686, 51686], "temperature": 0.0, "avg_logprob": -0.16160205647915224, "compression_ratio": 1.5714285714285714, "no_speech_prob": 7.410797024931526e-06}, {"id": 386, "seek": 191944, "start": 1927.64, "end": 1934.3600000000001, "text": " The joint probability of p of y and z given x okay I apply the same Boltzmann Gibbs-Boltzmann", "tokens": [50364, 407, 718, 311, 352, 807, 341, 257, 707, 5692, 510, 13, 50774, 50774, 440, 7225, 8482, 295, 280, 295, 288, 293, 710, 2212, 2031, 1392, 286, 3079, 264, 912, 37884, 89, 14912, 30199, 12, 33, 4837, 89, 14912, 51110, 51110, 7316, 8513, 382, 286, 1143, 949, 3993, 586, 309, 311, 257, 7225, 7316, 670, 288, 293, 710, 51410, 51410, 2602, 295, 445, 257, 7316, 670, 288, 341, 307, 337, 257, 48994, 7006, 2316, 1392, 13, 51686, 51686], "temperature": 0.0, "avg_logprob": -0.16160205647915224, "compression_ratio": 1.5714285714285714, "no_speech_prob": 7.410797024931526e-06}, {"id": 387, "seek": 191944, "start": 1934.3600000000001, "end": 1940.3600000000001, "text": " distribution formula as I used before except now it's a joint distribution over y and z", "tokens": [50364, 407, 718, 311, 352, 807, 341, 257, 707, 5692, 510, 13, 50774, 50774, 440, 7225, 8482, 295, 280, 295, 288, 293, 710, 2212, 2031, 1392, 286, 3079, 264, 912, 37884, 89, 14912, 30199, 12, 33, 4837, 89, 14912, 51110, 51110, 7316, 8513, 382, 286, 1143, 949, 3993, 586, 309, 311, 257, 7225, 7316, 670, 288, 293, 710, 51410, 51410, 2602, 295, 445, 257, 7316, 670, 288, 341, 307, 337, 257, 48994, 7006, 2316, 1392, 13, 51686, 51686], "temperature": 0.0, "avg_logprob": -0.16160205647915224, "compression_ratio": 1.5714285714285714, "no_speech_prob": 7.410797024931526e-06}, {"id": 388, "seek": 191944, "start": 1940.3600000000001, "end": 1945.88, "text": " instead of just a distribution over y this is for a latent variable model okay.", "tokens": [50364, 407, 718, 311, 352, 807, 341, 257, 707, 5692, 510, 13, 50774, 50774, 440, 7225, 8482, 295, 280, 295, 288, 293, 710, 2212, 2031, 1392, 286, 3079, 264, 912, 37884, 89, 14912, 30199, 12, 33, 4837, 89, 14912, 51110, 51110, 7316, 8513, 382, 286, 1143, 949, 3993, 586, 309, 311, 257, 7225, 7316, 670, 288, 293, 710, 51410, 51410, 2602, 295, 445, 257, 7316, 670, 288, 341, 307, 337, 257, 48994, 7006, 2316, 1392, 13, 51686, 51686], "temperature": 0.0, "avg_logprob": -0.16160205647915224, "compression_ratio": 1.5714285714285714, "no_speech_prob": 7.410797024931526e-06}, {"id": 389, "seek": 194588, "start": 1945.88, "end": 1951.5200000000002, "text": " So it's e to the minus the energy of x y z and then I have to normalize I have to integrate", "tokens": [50364, 407, 309, 311, 308, 281, 264, 3175, 264, 2281, 295, 2031, 288, 710, 293, 550, 286, 362, 281, 2710, 1125, 286, 362, 281, 13365, 50646, 50646, 294, 257, 20687, 365, 3104, 281, 288, 293, 710, 370, 300, 286, 483, 257, 48704, 7316, 670, 264, 50910, 50910, 7225, 9274, 295, 288, 293, 710, 1392, 13, 51082, 51082, 407, 300, 311, 264, 8513, 412, 264, 1192, 1411, 13, 51294, 51294, 286, 393, 16885, 1125, 710, 370, 498, 286, 13365, 280, 295, 288, 293, 710, 2212, 2031, 286, 13365, 341, 670, 710, 286, 51614, 51614], "temperature": 0.0, "avg_logprob": -0.13309678625553212, "compression_ratio": 1.7268041237113403, "no_speech_prob": 1.0615050086926203e-05}, {"id": 390, "seek": 194588, "start": 1951.5200000000002, "end": 1956.8000000000002, "text": " in a denominator with respect to y and z so that I get a normalized distribution over the", "tokens": [50364, 407, 309, 311, 308, 281, 264, 3175, 264, 2281, 295, 2031, 288, 710, 293, 550, 286, 362, 281, 2710, 1125, 286, 362, 281, 13365, 50646, 50646, 294, 257, 20687, 365, 3104, 281, 288, 293, 710, 370, 300, 286, 483, 257, 48704, 7316, 670, 264, 50910, 50910, 7225, 9274, 295, 288, 293, 710, 1392, 13, 51082, 51082, 407, 300, 311, 264, 8513, 412, 264, 1192, 1411, 13, 51294, 51294, 286, 393, 16885, 1125, 710, 370, 498, 286, 13365, 280, 295, 288, 293, 710, 2212, 2031, 286, 13365, 341, 670, 710, 286, 51614, 51614], "temperature": 0.0, "avg_logprob": -0.13309678625553212, "compression_ratio": 1.7268041237113403, "no_speech_prob": 1.0615050086926203e-05}, {"id": 391, "seek": 194588, "start": 1956.8000000000002, "end": 1960.24, "text": " joint domain of y and z okay.", "tokens": [50364, 407, 309, 311, 308, 281, 264, 3175, 264, 2281, 295, 2031, 288, 710, 293, 550, 286, 362, 281, 2710, 1125, 286, 362, 281, 13365, 50646, 50646, 294, 257, 20687, 365, 3104, 281, 288, 293, 710, 370, 300, 286, 483, 257, 48704, 7316, 670, 264, 50910, 50910, 7225, 9274, 295, 288, 293, 710, 1392, 13, 51082, 51082, 407, 300, 311, 264, 8513, 412, 264, 1192, 1411, 13, 51294, 51294, 286, 393, 16885, 1125, 710, 370, 498, 286, 13365, 280, 295, 288, 293, 710, 2212, 2031, 286, 13365, 341, 670, 710, 286, 51614, 51614], "temperature": 0.0, "avg_logprob": -0.13309678625553212, "compression_ratio": 1.7268041237113403, "no_speech_prob": 1.0615050086926203e-05}, {"id": 392, "seek": 194588, "start": 1960.24, "end": 1964.48, "text": " So that's the formula at the top left.", "tokens": [50364, 407, 309, 311, 308, 281, 264, 3175, 264, 2281, 295, 2031, 288, 710, 293, 550, 286, 362, 281, 2710, 1125, 286, 362, 281, 13365, 50646, 50646, 294, 257, 20687, 365, 3104, 281, 288, 293, 710, 370, 300, 286, 483, 257, 48704, 7316, 670, 264, 50910, 50910, 7225, 9274, 295, 288, 293, 710, 1392, 13, 51082, 51082, 407, 300, 311, 264, 8513, 412, 264, 1192, 1411, 13, 51294, 51294, 286, 393, 16885, 1125, 710, 370, 498, 286, 13365, 280, 295, 288, 293, 710, 2212, 2031, 286, 13365, 341, 670, 710, 286, 51614, 51614], "temperature": 0.0, "avg_logprob": -0.13309678625553212, "compression_ratio": 1.7268041237113403, "no_speech_prob": 1.0615050086926203e-05}, {"id": 393, "seek": 194588, "start": 1964.48, "end": 1970.88, "text": " I can marginalize z so if I integrate p of y and z given x I integrate this over z I", "tokens": [50364, 407, 309, 311, 308, 281, 264, 3175, 264, 2281, 295, 2031, 288, 710, 293, 550, 286, 362, 281, 2710, 1125, 286, 362, 281, 13365, 50646, 50646, 294, 257, 20687, 365, 3104, 281, 288, 293, 710, 370, 300, 286, 483, 257, 48704, 7316, 670, 264, 50910, 50910, 7225, 9274, 295, 288, 293, 710, 1392, 13, 51082, 51082, 407, 300, 311, 264, 8513, 412, 264, 1192, 1411, 13, 51294, 51294, 286, 393, 16885, 1125, 710, 370, 498, 286, 13365, 280, 295, 288, 293, 710, 2212, 2031, 286, 13365, 341, 670, 710, 286, 51614, 51614], "temperature": 0.0, "avg_logprob": -0.13309678625553212, "compression_ratio": 1.7268041237113403, "no_speech_prob": 1.0615050086926203e-05}, {"id": 394, "seek": 197088, "start": 1970.88, "end": 1978.88, "text": " get just p of y okay that's the marginalization formula which is at the top right.", "tokens": [50364, 483, 445, 280, 295, 288, 1392, 300, 311, 264, 16885, 2144, 8513, 597, 307, 412, 264, 1192, 558, 13, 50764, 50764, 400, 370, 586, 498, 286, 2464, 280, 295, 288, 2031, 307, 2935, 264, 11573, 670, 710, 295, 264, 472, 412, 264, 1192, 1411, 51032, 51032, 1392, 597, 307, 3720, 294, 264, 1150, 1622, 13, 51232, 51232, 407, 412, 264, 1192, 321, 362, 11573, 670, 710, 295, 308, 281, 264, 3175, 9861, 2281, 295, 2031, 288, 710, 293, 412, 264, 51446, 51446, 2767, 11573, 670, 288, 11573, 670, 710, 295, 308, 281, 264, 3175, 9861, 308, 281, 264, 2031, 288, 710, 439, 558, 13, 51786, 51786], "temperature": 0.0, "avg_logprob": -0.10446827499954789, "compression_ratio": 1.9695431472081217, "no_speech_prob": 6.144051440060139e-06}, {"id": 395, "seek": 197088, "start": 1978.88, "end": 1984.24, "text": " And so now if I write p of y x is simply the integral over z of the one at the top left", "tokens": [50364, 483, 445, 280, 295, 288, 1392, 300, 311, 264, 16885, 2144, 8513, 597, 307, 412, 264, 1192, 558, 13, 50764, 50764, 400, 370, 586, 498, 286, 2464, 280, 295, 288, 2031, 307, 2935, 264, 11573, 670, 710, 295, 264, 472, 412, 264, 1192, 1411, 51032, 51032, 1392, 597, 307, 3720, 294, 264, 1150, 1622, 13, 51232, 51232, 407, 412, 264, 1192, 321, 362, 11573, 670, 710, 295, 308, 281, 264, 3175, 9861, 2281, 295, 2031, 288, 710, 293, 412, 264, 51446, 51446, 2767, 11573, 670, 288, 11573, 670, 710, 295, 308, 281, 264, 3175, 9861, 308, 281, 264, 2031, 288, 710, 439, 558, 13, 51786, 51786], "temperature": 0.0, "avg_logprob": -0.10446827499954789, "compression_ratio": 1.9695431472081217, "no_speech_prob": 6.144051440060139e-06}, {"id": 396, "seek": 197088, "start": 1984.24, "end": 1988.24, "text": " okay which is written in the second line.", "tokens": [50364, 483, 445, 280, 295, 288, 1392, 300, 311, 264, 16885, 2144, 8513, 597, 307, 412, 264, 1192, 558, 13, 50764, 50764, 400, 370, 586, 498, 286, 2464, 280, 295, 288, 2031, 307, 2935, 264, 11573, 670, 710, 295, 264, 472, 412, 264, 1192, 1411, 51032, 51032, 1392, 597, 307, 3720, 294, 264, 1150, 1622, 13, 51232, 51232, 407, 412, 264, 1192, 321, 362, 11573, 670, 710, 295, 308, 281, 264, 3175, 9861, 2281, 295, 2031, 288, 710, 293, 412, 264, 51446, 51446, 2767, 11573, 670, 288, 11573, 670, 710, 295, 308, 281, 264, 3175, 9861, 308, 281, 264, 2031, 288, 710, 439, 558, 13, 51786, 51786], "temperature": 0.0, "avg_logprob": -0.10446827499954789, "compression_ratio": 1.9695431472081217, "no_speech_prob": 6.144051440060139e-06}, {"id": 397, "seek": 197088, "start": 1988.24, "end": 1992.5200000000002, "text": " So at the top we have integral over z of e to the minus beta energy of x y z and at the", "tokens": [50364, 483, 445, 280, 295, 288, 1392, 300, 311, 264, 16885, 2144, 8513, 597, 307, 412, 264, 1192, 558, 13, 50764, 50764, 400, 370, 586, 498, 286, 2464, 280, 295, 288, 2031, 307, 2935, 264, 11573, 670, 710, 295, 264, 472, 412, 264, 1192, 1411, 51032, 51032, 1392, 597, 307, 3720, 294, 264, 1150, 1622, 13, 51232, 51232, 407, 412, 264, 1192, 321, 362, 11573, 670, 710, 295, 308, 281, 264, 3175, 9861, 2281, 295, 2031, 288, 710, 293, 412, 264, 51446, 51446, 2767, 11573, 670, 288, 11573, 670, 710, 295, 308, 281, 264, 3175, 9861, 308, 281, 264, 2031, 288, 710, 439, 558, 13, 51786, 51786], "temperature": 0.0, "avg_logprob": -0.10446827499954789, "compression_ratio": 1.9695431472081217, "no_speech_prob": 6.144051440060139e-06}, {"id": 398, "seek": 197088, "start": 1992.5200000000002, "end": 1999.3200000000002, "text": " bottom integral over y integral over z of e to the minus beta e to the x y z all right.", "tokens": [50364, 483, 445, 280, 295, 288, 1392, 300, 311, 264, 16885, 2144, 8513, 597, 307, 412, 264, 1192, 558, 13, 50764, 50764, 400, 370, 586, 498, 286, 2464, 280, 295, 288, 2031, 307, 2935, 264, 11573, 670, 710, 295, 264, 472, 412, 264, 1192, 1411, 51032, 51032, 1392, 597, 307, 3720, 294, 264, 1150, 1622, 13, 51232, 51232, 407, 412, 264, 1192, 321, 362, 11573, 670, 710, 295, 308, 281, 264, 3175, 9861, 2281, 295, 2031, 288, 710, 293, 412, 264, 51446, 51446, 2767, 11573, 670, 288, 11573, 670, 710, 295, 308, 281, 264, 3175, 9861, 308, 281, 264, 2031, 288, 710, 439, 558, 13, 51786, 51786], "temperature": 0.0, "avg_logprob": -0.10446827499954789, "compression_ratio": 1.9695431472081217, "no_speech_prob": 6.144051440060139e-06}, {"id": 399, "seek": 199932, "start": 1999.32, "end": 2005.6399999999999, "text": " Okay now I'm going to do something very sneaky and stupid which is that I'm going to take", "tokens": [50364, 1033, 586, 286, 478, 516, 281, 360, 746, 588, 39518, 293, 6631, 597, 307, 300, 286, 478, 516, 281, 747, 50680, 50680, 264, 3565, 295, 341, 8513, 12972, 538, 3175, 472, 670, 9861, 550, 12972, 538, 3175, 9861, 50974, 50974, 293, 550, 747, 264, 21510, 439, 295, 729, 721, 10373, 484, 1392, 13, 51174, 51174, 440, 3565, 393, 66, 1625, 264, 21510, 264, 3175, 472, 670, 9861, 393, 66, 1625, 264, 3175, 9861, 558, 51390, 51390, 370, 286, 2378, 380, 1096, 1340, 538, 884, 341, 308, 281, 264, 3175, 9861, 1413, 3175, 472, 670, 9861, 51696, 51696], "temperature": 0.0, "avg_logprob": -0.10181835444286616, "compression_ratio": 2.0097560975609756, "no_speech_prob": 1.7230535377166234e-05}, {"id": 400, "seek": 199932, "start": 2005.6399999999999, "end": 2011.52, "text": " the log of this formula multiply by minus one over beta then multiply by minus beta", "tokens": [50364, 1033, 586, 286, 478, 516, 281, 360, 746, 588, 39518, 293, 6631, 597, 307, 300, 286, 478, 516, 281, 747, 50680, 50680, 264, 3565, 295, 341, 8513, 12972, 538, 3175, 472, 670, 9861, 550, 12972, 538, 3175, 9861, 50974, 50974, 293, 550, 747, 264, 21510, 439, 295, 729, 721, 10373, 484, 1392, 13, 51174, 51174, 440, 3565, 393, 66, 1625, 264, 21510, 264, 3175, 472, 670, 9861, 393, 66, 1625, 264, 3175, 9861, 558, 51390, 51390, 370, 286, 2378, 380, 1096, 1340, 538, 884, 341, 308, 281, 264, 3175, 9861, 1413, 3175, 472, 670, 9861, 51696, 51696], "temperature": 0.0, "avg_logprob": -0.10181835444286616, "compression_ratio": 2.0097560975609756, "no_speech_prob": 1.7230535377166234e-05}, {"id": 401, "seek": 199932, "start": 2011.52, "end": 2015.52, "text": " and then take the exponential all of those things cancel out okay.", "tokens": [50364, 1033, 586, 286, 478, 516, 281, 360, 746, 588, 39518, 293, 6631, 597, 307, 300, 286, 478, 516, 281, 747, 50680, 50680, 264, 3565, 295, 341, 8513, 12972, 538, 3175, 472, 670, 9861, 550, 12972, 538, 3175, 9861, 50974, 50974, 293, 550, 747, 264, 21510, 439, 295, 729, 721, 10373, 484, 1392, 13, 51174, 51174, 440, 3565, 393, 66, 1625, 264, 21510, 264, 3175, 472, 670, 9861, 393, 66, 1625, 264, 3175, 9861, 558, 51390, 51390, 370, 286, 2378, 380, 1096, 1340, 538, 884, 341, 308, 281, 264, 3175, 9861, 1413, 3175, 472, 670, 9861, 51696, 51696], "temperature": 0.0, "avg_logprob": -0.10181835444286616, "compression_ratio": 2.0097560975609756, "no_speech_prob": 1.7230535377166234e-05}, {"id": 402, "seek": 199932, "start": 2015.52, "end": 2019.84, "text": " The log cancels the exponential the minus one over beta cancels the minus beta right", "tokens": [50364, 1033, 586, 286, 478, 516, 281, 360, 746, 588, 39518, 293, 6631, 597, 307, 300, 286, 478, 516, 281, 747, 50680, 50680, 264, 3565, 295, 341, 8513, 12972, 538, 3175, 472, 670, 9861, 550, 12972, 538, 3175, 9861, 50974, 50974, 293, 550, 747, 264, 21510, 439, 295, 729, 721, 10373, 484, 1392, 13, 51174, 51174, 440, 3565, 393, 66, 1625, 264, 21510, 264, 3175, 472, 670, 9861, 393, 66, 1625, 264, 3175, 9861, 558, 51390, 51390, 370, 286, 2378, 380, 1096, 1340, 538, 884, 341, 308, 281, 264, 3175, 9861, 1413, 3175, 472, 670, 9861, 51696, 51696], "temperature": 0.0, "avg_logprob": -0.10181835444286616, "compression_ratio": 2.0097560975609756, "no_speech_prob": 1.7230535377166234e-05}, {"id": 403, "seek": 199932, "start": 2019.84, "end": 2025.96, "text": " so I haven't done anything by doing this e to the minus beta times minus one over beta", "tokens": [50364, 1033, 586, 286, 478, 516, 281, 360, 746, 588, 39518, 293, 6631, 597, 307, 300, 286, 478, 516, 281, 747, 50680, 50680, 264, 3565, 295, 341, 8513, 12972, 538, 3175, 472, 670, 9861, 550, 12972, 538, 3175, 9861, 50974, 50974, 293, 550, 747, 264, 21510, 439, 295, 729, 721, 10373, 484, 1392, 13, 51174, 51174, 440, 3565, 393, 66, 1625, 264, 21510, 264, 3175, 472, 670, 9861, 393, 66, 1625, 264, 3175, 9861, 558, 51390, 51390, 370, 286, 2378, 380, 1096, 1340, 538, 884, 341, 308, 281, 264, 3175, 9861, 1413, 3175, 472, 670, 9861, 51696, 51696], "temperature": 0.0, "avg_logprob": -0.10181835444286616, "compression_ratio": 2.0097560975609756, "no_speech_prob": 1.7230535377166234e-05}, {"id": 404, "seek": 202596, "start": 2025.96, "end": 2030.88, "text": " log I've done nothing because everything cancels okay.", "tokens": [50364, 3565, 286, 600, 1096, 1825, 570, 1203, 393, 66, 1625, 1392, 13, 50610, 50610, 400, 286, 360, 264, 912, 412, 264, 2767, 293, 437, 286, 536, 586, 307, 300, 264, 1507, 294, 264, 16904, 307, 51104, 51104, 264, 8513, 286, 4114, 8046, 283, 9861, 295, 2031, 288, 6915, 3175, 472, 670, 9861, 3565, 2408, 670, 51368, 51368, 710, 11573, 670, 710, 295, 308, 281, 264, 3175, 9861, 308, 295, 2031, 288, 710, 293, 370, 286, 393, 28132, 341, 9263, 51682, 51682], "temperature": 0.0, "avg_logprob": -0.13882863377950277, "compression_ratio": 1.6134020618556701, "no_speech_prob": 1.4285006727732252e-05}, {"id": 405, "seek": 202596, "start": 2030.88, "end": 2040.76, "text": " And I do the same at the bottom and what I see now is that the stuff in the bracket is", "tokens": [50364, 3565, 286, 600, 1096, 1825, 570, 1203, 393, 66, 1625, 1392, 13, 50610, 50610, 400, 286, 360, 264, 912, 412, 264, 2767, 293, 437, 286, 536, 586, 307, 300, 264, 1507, 294, 264, 16904, 307, 51104, 51104, 264, 8513, 286, 4114, 8046, 283, 9861, 295, 2031, 288, 6915, 3175, 472, 670, 9861, 3565, 2408, 670, 51368, 51368, 710, 11573, 670, 710, 295, 308, 281, 264, 3175, 9861, 308, 295, 2031, 288, 710, 293, 370, 286, 393, 28132, 341, 9263, 51682, 51682], "temperature": 0.0, "avg_logprob": -0.13882863377950277, "compression_ratio": 1.6134020618556701, "no_speech_prob": 1.4285006727732252e-05}, {"id": 406, "seek": 202596, "start": 2040.76, "end": 2046.04, "text": " the formula I wrote previously f beta of x y equals minus one over beta log sum over", "tokens": [50364, 3565, 286, 600, 1096, 1825, 570, 1203, 393, 66, 1625, 1392, 13, 50610, 50610, 400, 286, 360, 264, 912, 412, 264, 2767, 293, 437, 286, 536, 586, 307, 300, 264, 1507, 294, 264, 16904, 307, 51104, 51104, 264, 8513, 286, 4114, 8046, 283, 9861, 295, 2031, 288, 6915, 3175, 472, 670, 9861, 3565, 2408, 670, 51368, 51368, 710, 11573, 670, 710, 295, 308, 281, 264, 3175, 9861, 308, 295, 2031, 288, 710, 293, 370, 286, 393, 28132, 341, 9263, 51682, 51682], "temperature": 0.0, "avg_logprob": -0.13882863377950277, "compression_ratio": 1.6134020618556701, "no_speech_prob": 1.4285006727732252e-05}, {"id": 407, "seek": 202596, "start": 2046.04, "end": 2052.32, "text": " z integral over z of e to the minus beta e of x y z and so I can rewrite this horrible", "tokens": [50364, 3565, 286, 600, 1096, 1825, 570, 1203, 393, 66, 1625, 1392, 13, 50610, 50610, 400, 286, 360, 264, 912, 412, 264, 2767, 293, 437, 286, 536, 586, 307, 300, 264, 1507, 294, 264, 16904, 307, 51104, 51104, 264, 8513, 286, 4114, 8046, 283, 9861, 295, 2031, 288, 6915, 3175, 472, 670, 9861, 3565, 2408, 670, 51368, 51368, 710, 11573, 670, 710, 295, 308, 281, 264, 3175, 9861, 308, 295, 2031, 288, 710, 293, 370, 286, 393, 28132, 341, 9263, 51682, 51682], "temperature": 0.0, "avg_logprob": -0.13882863377950277, "compression_ratio": 1.6134020618556701, "no_speech_prob": 1.4285006727732252e-05}, {"id": 408, "seek": 205232, "start": 2052.32, "end": 2059.6000000000004, "text": " complicated formula here as e to the minus beta f beta of x y divided by integral over", "tokens": [50364, 6179, 8513, 510, 382, 308, 281, 264, 3175, 9861, 283, 9861, 295, 2031, 288, 6666, 538, 11573, 670, 50728, 50728, 288, 295, 308, 281, 264, 3175, 9861, 283, 295, 2031, 288, 13, 50900, 50900, 708, 775, 341, 439, 914, 30, 50950, 50950, 467, 1355, 300, 498, 291, 362, 257, 48994, 7006, 2316, 293, 291, 528, 281, 13819, 264, 710, 7006, 51282, 51282, 264, 48994, 7006, 294, 257, 31959, 3142, 3006, 636, 291, 445, 38818, 533, 264, 2281, 283, 382, 341, 51796, 51796], "temperature": 0.0, "avg_logprob": -0.08652170499165852, "compression_ratio": 1.6855670103092784, "no_speech_prob": 9.515964848105796e-06}, {"id": 409, "seek": 205232, "start": 2059.6000000000004, "end": 2063.04, "text": " y of e to the minus beta f of x y.", "tokens": [50364, 6179, 8513, 510, 382, 308, 281, 264, 3175, 9861, 283, 9861, 295, 2031, 288, 6666, 538, 11573, 670, 50728, 50728, 288, 295, 308, 281, 264, 3175, 9861, 283, 295, 2031, 288, 13, 50900, 50900, 708, 775, 341, 439, 914, 30, 50950, 50950, 467, 1355, 300, 498, 291, 362, 257, 48994, 7006, 2316, 293, 291, 528, 281, 13819, 264, 710, 7006, 51282, 51282, 264, 48994, 7006, 294, 257, 31959, 3142, 3006, 636, 291, 445, 38818, 533, 264, 2281, 283, 382, 341, 51796, 51796], "temperature": 0.0, "avg_logprob": -0.08652170499165852, "compression_ratio": 1.6855670103092784, "no_speech_prob": 9.515964848105796e-06}, {"id": 410, "seek": 205232, "start": 2063.04, "end": 2064.04, "text": " What does this all mean?", "tokens": [50364, 6179, 8513, 510, 382, 308, 281, 264, 3175, 9861, 283, 9861, 295, 2031, 288, 6666, 538, 11573, 670, 50728, 50728, 288, 295, 308, 281, 264, 3175, 9861, 283, 295, 2031, 288, 13, 50900, 50900, 708, 775, 341, 439, 914, 30, 50950, 50950, 467, 1355, 300, 498, 291, 362, 257, 48994, 7006, 2316, 293, 291, 528, 281, 13819, 264, 710, 7006, 51282, 51282, 264, 48994, 7006, 294, 257, 31959, 3142, 3006, 636, 291, 445, 38818, 533, 264, 2281, 283, 382, 341, 51796, 51796], "temperature": 0.0, "avg_logprob": -0.08652170499165852, "compression_ratio": 1.6855670103092784, "no_speech_prob": 9.515964848105796e-06}, {"id": 411, "seek": 205232, "start": 2064.04, "end": 2070.6800000000003, "text": " It means that if you have a latent variable model and you want to eliminate the z variable", "tokens": [50364, 6179, 8513, 510, 382, 308, 281, 264, 3175, 9861, 283, 9861, 295, 2031, 288, 6666, 538, 11573, 670, 50728, 50728, 288, 295, 308, 281, 264, 3175, 9861, 283, 295, 2031, 288, 13, 50900, 50900, 708, 775, 341, 439, 914, 30, 50950, 50950, 467, 1355, 300, 498, 291, 362, 257, 48994, 7006, 2316, 293, 291, 528, 281, 13819, 264, 710, 7006, 51282, 51282, 264, 48994, 7006, 294, 257, 31959, 3142, 3006, 636, 291, 445, 38818, 533, 264, 2281, 283, 382, 341, 51796, 51796], "temperature": 0.0, "avg_logprob": -0.08652170499165852, "compression_ratio": 1.6855670103092784, "no_speech_prob": 9.515964848105796e-06}, {"id": 412, "seek": 205232, "start": 2070.6800000000003, "end": 2080.96, "text": " the latent variable in a probabilistic correct way you just redefine the energy f as this", "tokens": [50364, 6179, 8513, 510, 382, 308, 281, 264, 3175, 9861, 283, 9861, 295, 2031, 288, 6666, 538, 11573, 670, 50728, 50728, 288, 295, 308, 281, 264, 3175, 9861, 283, 295, 2031, 288, 13, 50900, 50900, 708, 775, 341, 439, 914, 30, 50950, 50950, 467, 1355, 300, 498, 291, 362, 257, 48994, 7006, 2316, 293, 291, 528, 281, 13819, 264, 710, 7006, 51282, 51282, 264, 48994, 7006, 294, 257, 31959, 3142, 3006, 636, 291, 445, 38818, 533, 264, 2281, 283, 382, 341, 51796, 51796], "temperature": 0.0, "avg_logprob": -0.08652170499165852, "compression_ratio": 1.6855670103092784, "no_speech_prob": 9.515964848105796e-06}, {"id": 413, "seek": 208096, "start": 2080.96, "end": 2088.52, "text": " as a function of e of x y z and you're done okay.", "tokens": [50364, 382, 257, 2445, 295, 308, 295, 2031, 288, 710, 293, 291, 434, 1096, 1392, 13, 50742, 50742, 509, 434, 1096, 307, 257, 707, 857, 295, 257, 24822, 570, 767, 15866, 341, 393, 312, 588, 51072, 51072, 1152, 1392, 393, 312, 560, 1897, 712, 294, 1186, 294, 881, 3331, 1391, 309, 311, 560, 1897, 712, 13, 51490, 51490], "temperature": 0.0, "avg_logprob": -0.2019484730090125, "compression_ratio": 1.5106382978723405, "no_speech_prob": 2.6687204808695242e-05}, {"id": 414, "seek": 208096, "start": 2088.52, "end": 2095.12, "text": " You're done is a little bit of a shortcut because actually computing this can be very", "tokens": [50364, 382, 257, 2445, 295, 308, 295, 2031, 288, 710, 293, 291, 434, 1096, 1392, 13, 50742, 50742, 509, 434, 1096, 307, 257, 707, 857, 295, 257, 24822, 570, 767, 15866, 341, 393, 312, 588, 51072, 51072, 1152, 1392, 393, 312, 560, 1897, 712, 294, 1186, 294, 881, 3331, 1391, 309, 311, 560, 1897, 712, 13, 51490, 51490], "temperature": 0.0, "avg_logprob": -0.2019484730090125, "compression_ratio": 1.5106382978723405, "no_speech_prob": 2.6687204808695242e-05}, {"id": 415, "seek": 208096, "start": 2095.12, "end": 2103.48, "text": " hard okay can be intractable in fact in most cases probably it's intractable.", "tokens": [50364, 382, 257, 2445, 295, 308, 295, 2031, 288, 710, 293, 291, 434, 1096, 1392, 13, 50742, 50742, 509, 434, 1096, 307, 257, 707, 857, 295, 257, 24822, 570, 767, 15866, 341, 393, 312, 588, 51072, 51072, 1152, 1392, 393, 312, 560, 1897, 712, 294, 1186, 294, 881, 3331, 1391, 309, 311, 560, 1897, 712, 13, 51490, 51490], "temperature": 0.0, "avg_logprob": -0.2019484730090125, "compression_ratio": 1.5106382978723405, "no_speech_prob": 2.6687204808695242e-05}, {"id": 416, "seek": 210348, "start": 2103.48, "end": 2115.52, "text": " I am missing a minus in the denominator you are correct.", "tokens": [50364, 286, 669, 5361, 257, 3175, 294, 264, 20687, 291, 366, 3006, 13, 50966, 50966, 1033, 370, 264, 1036, 1326, 9788, 645, 281, 584, 498, 291, 362, 257, 48994, 7006, 300, 291, 17522, 51236, 51236, 670, 1854, 295, 428, 2316, 420, 498, 291, 362, 257, 48994, 7006, 300, 291, 528, 281, 16885, 1125, 51466, 51466], "temperature": 0.0, "avg_logprob": -0.09074521916253227, "compression_ratio": 1.6571428571428573, "no_speech_prob": 5.682067694579018e-06}, {"id": 417, "seek": 210348, "start": 2115.52, "end": 2120.92, "text": " Okay so the last few slides were to say if you have a latent variable that you minimize", "tokens": [50364, 286, 669, 5361, 257, 3175, 294, 264, 20687, 291, 366, 3006, 13, 50966, 50966, 1033, 370, 264, 1036, 1326, 9788, 645, 281, 584, 498, 291, 362, 257, 48994, 7006, 300, 291, 17522, 51236, 51236, 670, 1854, 295, 428, 2316, 420, 498, 291, 362, 257, 48994, 7006, 300, 291, 528, 281, 16885, 1125, 51466, 51466], "temperature": 0.0, "avg_logprob": -0.09074521916253227, "compression_ratio": 1.6571428571428573, "no_speech_prob": 5.682067694579018e-06}, {"id": 418, "seek": 210348, "start": 2120.92, "end": 2125.52, "text": " over inside of your model or if you have a latent variable that you want to marginalize", "tokens": [50364, 286, 669, 5361, 257, 3175, 294, 264, 20687, 291, 366, 3006, 13, 50966, 50966, 1033, 370, 264, 1036, 1326, 9788, 645, 281, 584, 498, 291, 362, 257, 48994, 7006, 300, 291, 17522, 51236, 51236, 670, 1854, 295, 428, 2316, 420, 498, 291, 362, 257, 48994, 7006, 300, 291, 528, 281, 16885, 1125, 51466, 51466], "temperature": 0.0, "avg_logprob": -0.09074521916253227, "compression_ratio": 1.6571428571428573, "no_speech_prob": 5.682067694579018e-06}, {"id": 419, "seek": 212552, "start": 2125.52, "end": 2135.2, "text": " over which is which you do by defining this new this energy function f this way and minimizing", "tokens": [50364, 670, 597, 307, 597, 291, 360, 538, 17827, 341, 777, 341, 2281, 2445, 283, 341, 636, 293, 46608, 50848, 50848, 23249, 281, 264, 13785, 9861, 4948, 295, 341, 8513, 309, 393, 312, 1096, 13, 51202], "temperature": 0.0, "avg_logprob": -0.22440925804344383, "compression_ratio": 1.4224137931034482, "no_speech_prob": 1.2217812582093757e-05}, {"id": 420, "seek": 213520, "start": 2135.2, "end": 2159.0, "text": " corresponds to the infinite beta limit of this formula it can be done.", "tokens": [50364, 23249, 281, 264, 13785, 9861, 4948, 295, 341, 8513, 309, 393, 312, 1096, 13, 51554, 51554, 1033, 286, 914, 445, 574, 412, 264, 35827, 294, 264, 1150, 1622, 1392, 264, 264, 1036, 732, 2115, 51780, 51780], "temperature": 0.0, "avg_logprob": -0.12412832912645842, "compression_ratio": 1.3361344537815125, "no_speech_prob": 1.520445312053198e-05}, {"id": 421, "seek": 213520, "start": 2159.0, "end": 2163.52, "text": " Okay I mean just look at the substitution in the second line okay the the last two terms", "tokens": [50364, 23249, 281, 264, 13785, 9861, 4948, 295, 341, 8513, 309, 393, 312, 1096, 13, 51554, 51554, 1033, 286, 914, 445, 574, 412, 264, 35827, 294, 264, 1150, 1622, 1392, 264, 264, 1036, 732, 2115, 51780, 51780], "temperature": 0.0, "avg_logprob": -0.12412832912645842, "compression_ratio": 1.3361344537815125, "no_speech_prob": 1.520445312053198e-05}, {"id": 422, "seek": 216352, "start": 2163.52, "end": 2169.36, "text": " in the second line the bracket I replaced by f beta of x y because and I just defined", "tokens": [50364, 294, 264, 1150, 1622, 264, 16904, 286, 10772, 538, 283, 9861, 295, 2031, 288, 570, 293, 286, 445, 7642, 50656, 50656, 283, 9861, 295, 2031, 288, 341, 636, 1392, 286, 445, 6964, 309, 341, 636, 293, 498, 286, 6964, 283, 295, 2031, 288, 341, 51104, 51104, 636, 550, 280, 295, 288, 2212, 2031, 307, 445, 364, 3861, 295, 264, 30199, 12, 54, 401, 602, 12, 50, 1601, 8513, 558, 293, 51468, 51468, 710, 575, 668, 733, 295, 32522, 26947, 356, 1854, 295, 295, 341, 1392, 13, 51750, 51750], "temperature": 0.0, "avg_logprob": -0.22741436428493925, "compression_ratio": 1.6581632653061225, "no_speech_prob": 7.411025762849022e-06}, {"id": 423, "seek": 216352, "start": 2169.36, "end": 2178.32, "text": " f beta of x y this way okay I just define it this way and if I define f of x y this", "tokens": [50364, 294, 264, 1150, 1622, 264, 16904, 286, 10772, 538, 283, 9861, 295, 2031, 288, 570, 293, 286, 445, 7642, 50656, 50656, 283, 9861, 295, 2031, 288, 341, 636, 1392, 286, 445, 6964, 309, 341, 636, 293, 498, 286, 6964, 283, 295, 2031, 288, 341, 51104, 51104, 636, 550, 280, 295, 288, 2212, 2031, 307, 445, 364, 3861, 295, 264, 30199, 12, 54, 401, 602, 12, 50, 1601, 8513, 558, 293, 51468, 51468, 710, 575, 668, 733, 295, 32522, 26947, 356, 1854, 295, 295, 341, 1392, 13, 51750, 51750], "temperature": 0.0, "avg_logprob": -0.22741436428493925, "compression_ratio": 1.6581632653061225, "no_speech_prob": 7.411025762849022e-06}, {"id": 424, "seek": 216352, "start": 2178.32, "end": 2185.6, "text": " way then p of y given x is just an application of the Gibbs-Wolff-Sman formula right and", "tokens": [50364, 294, 264, 1150, 1622, 264, 16904, 286, 10772, 538, 283, 9861, 295, 2031, 288, 570, 293, 286, 445, 7642, 50656, 50656, 283, 9861, 295, 2031, 288, 341, 636, 1392, 286, 445, 6964, 309, 341, 636, 293, 498, 286, 6964, 283, 295, 2031, 288, 341, 51104, 51104, 636, 550, 280, 295, 288, 2212, 2031, 307, 445, 364, 3861, 295, 264, 30199, 12, 54, 401, 602, 12, 50, 1601, 8513, 558, 293, 51468, 51468, 710, 575, 668, 733, 295, 32522, 26947, 356, 1854, 295, 295, 341, 1392, 13, 51750, 51750], "temperature": 0.0, "avg_logprob": -0.22741436428493925, "compression_ratio": 1.6581632653061225, "no_speech_prob": 7.411025762849022e-06}, {"id": 425, "seek": 216352, "start": 2185.6, "end": 2191.24, "text": " z has been kind of marginalized implicitly inside of of this okay.", "tokens": [50364, 294, 264, 1150, 1622, 264, 16904, 286, 10772, 538, 283, 9861, 295, 2031, 288, 570, 293, 286, 445, 7642, 50656, 50656, 283, 9861, 295, 2031, 288, 341, 636, 1392, 286, 445, 6964, 309, 341, 636, 293, 498, 286, 6964, 283, 295, 2031, 288, 341, 51104, 51104, 636, 550, 280, 295, 288, 2212, 2031, 307, 445, 364, 3861, 295, 264, 30199, 12, 54, 401, 602, 12, 50, 1601, 8513, 558, 293, 51468, 51468, 710, 575, 668, 733, 295, 32522, 26947, 356, 1854, 295, 295, 341, 1392, 13, 51750, 51750], "temperature": 0.0, "avg_logprob": -0.22741436428493925, "compression_ratio": 1.6581632653061225, "no_speech_prob": 7.411025762849022e-06}, {"id": 426, "seek": 219124, "start": 2191.24, "end": 2195.9599999999996, "text": " So physicists call this a free energy by the way which is why I call it f okay so E is", "tokens": [50364, 407, 48716, 818, 341, 257, 1737, 2281, 538, 264, 636, 597, 307, 983, 286, 818, 309, 283, 1392, 370, 462, 307, 50600, 50600, 264, 2281, 293, 283, 307, 257, 1737, 2281, 13, 51558, 51558], "temperature": 0.0, "avg_logprob": -0.2011540730794271, "compression_ratio": 1.3296703296703296, "no_speech_prob": 4.2634586861822754e-05}, {"id": 427, "seek": 219124, "start": 2195.9599999999996, "end": 2215.12, "text": " the energy and f is a free energy.", "tokens": [50364, 407, 48716, 818, 341, 257, 1737, 2281, 538, 264, 636, 597, 307, 983, 286, 818, 309, 283, 1392, 370, 462, 307, 50600, 50600, 264, 2281, 293, 283, 307, 257, 1737, 2281, 13, 51558, 51558], "temperature": 0.0, "avg_logprob": -0.2011540730794271, "compression_ratio": 1.3296703296703296, "no_speech_prob": 4.2634586861822754e-05}, {"id": 428, "seek": 221512, "start": 2215.12, "end": 2224.0, "text": " So the difference is in probabilistic models you basically don't have the choice of the", "tokens": [50364, 407, 264, 2649, 307, 294, 31959, 3142, 5245, 291, 1936, 500, 380, 362, 264, 3922, 295, 264, 50808, 50808, 10024, 2445, 291, 434, 516, 281, 17522, 293, 291, 362, 281, 1754, 2074, 281, 264, 264, 1333, 51148, 51148, 295, 31959, 3142, 8388, 294, 257, 2020, 300, 633, 2657, 291, 20459, 575, 281, 312, 257, 48704, 51366, 51366, 7316, 597, 291, 815, 30874, 1228, 3034, 1478, 7150, 420, 2035, 13, 51634, 51634], "temperature": 0.0, "avg_logprob": -0.10368543128444724, "compression_ratio": 1.619718309859155, "no_speech_prob": 3.2885461678233696e-06}, {"id": 429, "seek": 221512, "start": 2224.0, "end": 2230.7999999999997, "text": " objective function you're going to minimize and you have to stay true to the the sort", "tokens": [50364, 407, 264, 2649, 307, 294, 31959, 3142, 5245, 291, 1936, 500, 380, 362, 264, 3922, 295, 264, 50808, 50808, 10024, 2445, 291, 434, 516, 281, 17522, 293, 291, 362, 281, 1754, 2074, 281, 264, 264, 1333, 51148, 51148, 295, 31959, 3142, 8388, 294, 257, 2020, 300, 633, 2657, 291, 20459, 575, 281, 312, 257, 48704, 51366, 51366, 7316, 597, 291, 815, 30874, 1228, 3034, 1478, 7150, 420, 2035, 13, 51634, 51634], "temperature": 0.0, "avg_logprob": -0.10368543128444724, "compression_ratio": 1.619718309859155, "no_speech_prob": 3.2885461678233696e-06}, {"id": 430, "seek": 221512, "start": 2230.7999999999997, "end": 2235.16, "text": " of probabilistic framework in a sense that every object you manipulate has to be a normalized", "tokens": [50364, 407, 264, 2649, 307, 294, 31959, 3142, 5245, 291, 1936, 500, 380, 362, 264, 3922, 295, 264, 50808, 50808, 10024, 2445, 291, 434, 516, 281, 17522, 293, 291, 362, 281, 1754, 2074, 281, 264, 264, 1333, 51148, 51148, 295, 31959, 3142, 8388, 294, 257, 2020, 300, 633, 2657, 291, 20459, 575, 281, 312, 257, 48704, 51366, 51366, 7316, 597, 291, 815, 30874, 1228, 3034, 1478, 7150, 420, 2035, 13, 51634, 51634], "temperature": 0.0, "avg_logprob": -0.10368543128444724, "compression_ratio": 1.619718309859155, "no_speech_prob": 3.2885461678233696e-06}, {"id": 431, "seek": 221512, "start": 2235.16, "end": 2240.52, "text": " distribution which you may approximate using variational methods or whatever.", "tokens": [50364, 407, 264, 2649, 307, 294, 31959, 3142, 5245, 291, 1936, 500, 380, 362, 264, 3922, 295, 264, 50808, 50808, 10024, 2445, 291, 434, 516, 281, 17522, 293, 291, 362, 281, 1754, 2074, 281, 264, 264, 1333, 51148, 51148, 295, 31959, 3142, 8388, 294, 257, 2020, 300, 633, 2657, 291, 20459, 575, 281, 312, 257, 48704, 51366, 51366, 7316, 597, 291, 815, 30874, 1228, 3034, 1478, 7150, 420, 2035, 13, 51634, 51634], "temperature": 0.0, "avg_logprob": -0.10368543128444724, "compression_ratio": 1.619718309859155, "no_speech_prob": 3.2885461678233696e-06}, {"id": 432, "seek": 224052, "start": 2240.52, "end": 2245.2, "text": " Here I'm saying ultimately what you want to make you know what you want to do with those", "tokens": [50364, 1692, 286, 478, 1566, 6284, 437, 291, 528, 281, 652, 291, 458, 437, 291, 528, 281, 360, 365, 729, 50598, 50598, 5245, 307, 652, 5327, 293, 498, 291, 434, 498, 291, 434, 498, 291, 1322, 257, 1185, 300, 11754, 257, 50872, 50872, 1032, 293, 264, 1185, 5112, 291, 291, 458, 286, 643, 281, 1261, 1411, 365, 8482, 1958, 13, 23, 420, 1261, 51228, 51228, 558, 365, 8482, 1958, 13, 17, 291, 434, 516, 281, 1261, 1411, 1392, 264, 264, 1186, 300, 264, 33783, 51572, 51572, 456, 366, 1958, 13, 17, 293, 1958, 13, 23, 1177, 380, 1871, 437, 291, 528, 307, 652, 264, 3537, 300, 307, 264, 51824, 51824], "temperature": 0.0, "avg_logprob": -0.12472238626566019, "compression_ratio": 1.9553571428571428, "no_speech_prob": 1.5688776329625398e-05}, {"id": 433, "seek": 224052, "start": 2245.2, "end": 2250.68, "text": " models is make decisions and if you're if you're if you build a system that drives a", "tokens": [50364, 1692, 286, 478, 1566, 6284, 437, 291, 528, 281, 652, 291, 458, 437, 291, 528, 281, 360, 365, 729, 50598, 50598, 5245, 307, 652, 5327, 293, 498, 291, 434, 498, 291, 434, 498, 291, 1322, 257, 1185, 300, 11754, 257, 50872, 50872, 1032, 293, 264, 1185, 5112, 291, 291, 458, 286, 643, 281, 1261, 1411, 365, 8482, 1958, 13, 23, 420, 1261, 51228, 51228, 558, 365, 8482, 1958, 13, 17, 291, 434, 516, 281, 1261, 1411, 1392, 264, 264, 1186, 300, 264, 33783, 51572, 51572, 456, 366, 1958, 13, 17, 293, 1958, 13, 23, 1177, 380, 1871, 437, 291, 528, 307, 652, 264, 3537, 300, 307, 264, 51824, 51824], "temperature": 0.0, "avg_logprob": -0.12472238626566019, "compression_ratio": 1.9553571428571428, "no_speech_prob": 1.5688776329625398e-05}, {"id": 434, "seek": 224052, "start": 2250.68, "end": 2257.8, "text": " car and the system tells you you know I need to turn left with probability 0.8 or turn", "tokens": [50364, 1692, 286, 478, 1566, 6284, 437, 291, 528, 281, 652, 291, 458, 437, 291, 528, 281, 360, 365, 729, 50598, 50598, 5245, 307, 652, 5327, 293, 498, 291, 434, 498, 291, 434, 498, 291, 1322, 257, 1185, 300, 11754, 257, 50872, 50872, 1032, 293, 264, 1185, 5112, 291, 291, 458, 286, 643, 281, 1261, 1411, 365, 8482, 1958, 13, 23, 420, 1261, 51228, 51228, 558, 365, 8482, 1958, 13, 17, 291, 434, 516, 281, 1261, 1411, 1392, 264, 264, 1186, 300, 264, 33783, 51572, 51572, 456, 366, 1958, 13, 17, 293, 1958, 13, 23, 1177, 380, 1871, 437, 291, 528, 307, 652, 264, 3537, 300, 307, 264, 51824, 51824], "temperature": 0.0, "avg_logprob": -0.12472238626566019, "compression_ratio": 1.9553571428571428, "no_speech_prob": 1.5688776329625398e-05}, {"id": 435, "seek": 224052, "start": 2257.8, "end": 2264.68, "text": " right with probability 0.2 you're going to turn left okay the the fact that the probabilities", "tokens": [50364, 1692, 286, 478, 1566, 6284, 437, 291, 528, 281, 652, 291, 458, 437, 291, 528, 281, 360, 365, 729, 50598, 50598, 5245, 307, 652, 5327, 293, 498, 291, 434, 498, 291, 434, 498, 291, 1322, 257, 1185, 300, 11754, 257, 50872, 50872, 1032, 293, 264, 1185, 5112, 291, 291, 458, 286, 643, 281, 1261, 1411, 365, 8482, 1958, 13, 23, 420, 1261, 51228, 51228, 558, 365, 8482, 1958, 13, 17, 291, 434, 516, 281, 1261, 1411, 1392, 264, 264, 1186, 300, 264, 33783, 51572, 51572, 456, 366, 1958, 13, 17, 293, 1958, 13, 23, 1177, 380, 1871, 437, 291, 528, 307, 652, 264, 3537, 300, 307, 264, 51824, 51824], "temperature": 0.0, "avg_logprob": -0.12472238626566019, "compression_ratio": 1.9553571428571428, "no_speech_prob": 1.5688776329625398e-05}, {"id": 436, "seek": 224052, "start": 2264.68, "end": 2269.72, "text": " there are 0.2 and 0.8 doesn't matter what you want is make the decision that is the", "tokens": [50364, 1692, 286, 478, 1566, 6284, 437, 291, 528, 281, 652, 291, 458, 437, 291, 528, 281, 360, 365, 729, 50598, 50598, 5245, 307, 652, 5327, 293, 498, 291, 434, 498, 291, 434, 498, 291, 1322, 257, 1185, 300, 11754, 257, 50872, 50872, 1032, 293, 264, 1185, 5112, 291, 291, 458, 286, 643, 281, 1261, 1411, 365, 8482, 1958, 13, 23, 420, 1261, 51228, 51228, 558, 365, 8482, 1958, 13, 17, 291, 434, 516, 281, 1261, 1411, 1392, 264, 264, 1186, 300, 264, 33783, 51572, 51572, 456, 366, 1958, 13, 17, 293, 1958, 13, 23, 1177, 380, 1871, 437, 291, 528, 307, 652, 264, 3537, 300, 307, 264, 51824, 51824], "temperature": 0.0, "avg_logprob": -0.12472238626566019, "compression_ratio": 1.9553571428571428, "no_speech_prob": 1.5688776329625398e-05}, {"id": 437, "seek": 226972, "start": 2269.72, "end": 2274.56, "text": " best right because you have to make a decision you're forced to make a decision.", "tokens": [50364, 1151, 558, 570, 291, 362, 281, 652, 257, 3537, 291, 434, 7579, 281, 652, 257, 3537, 13, 50606, 50606, 407, 498, 291, 528, 257, 1185, 300, 370, 370, 33783, 366, 2584, 14115, 498, 291, 528, 281, 652, 50844, 50844, 5327, 1392, 13, 50964, 50964, 759, 291, 528, 281, 10432, 264, 5598, 295, 257, 18473, 1185, 365, 1071, 472, 337, 1365, 257, 1952, 51258, 51258, 420, 512, 661, 1185, 293, 729, 3652, 2378, 380, 668, 8895, 1214, 457, 436, 600, 668, 8895, 51492, 51492, 14759, 550, 437, 291, 528, 307, 21583, 5468, 13444, 370, 300, 291, 393, 10432, 264, 13444, 51670, 51670], "temperature": 0.0, "avg_logprob": -0.09446141326311723, "compression_ratio": 1.8739837398373984, "no_speech_prob": 4.0057591832010075e-05}, {"id": 438, "seek": 226972, "start": 2274.56, "end": 2279.3199999999997, "text": " So if you want a system that so so probabilities are completely useless if you want to make", "tokens": [50364, 1151, 558, 570, 291, 362, 281, 652, 257, 3537, 291, 434, 7579, 281, 652, 257, 3537, 13, 50606, 50606, 407, 498, 291, 528, 257, 1185, 300, 370, 370, 33783, 366, 2584, 14115, 498, 291, 528, 281, 652, 50844, 50844, 5327, 1392, 13, 50964, 50964, 759, 291, 528, 281, 10432, 264, 5598, 295, 257, 18473, 1185, 365, 1071, 472, 337, 1365, 257, 1952, 51258, 51258, 420, 512, 661, 1185, 293, 729, 3652, 2378, 380, 668, 8895, 1214, 457, 436, 600, 668, 8895, 51492, 51492, 14759, 550, 437, 291, 528, 307, 21583, 5468, 13444, 370, 300, 291, 393, 10432, 264, 13444, 51670, 51670], "temperature": 0.0, "avg_logprob": -0.09446141326311723, "compression_ratio": 1.8739837398373984, "no_speech_prob": 4.0057591832010075e-05}, {"id": 439, "seek": 226972, "start": 2279.3199999999997, "end": 2281.72, "text": " decisions okay.", "tokens": [50364, 1151, 558, 570, 291, 362, 281, 652, 257, 3537, 291, 434, 7579, 281, 652, 257, 3537, 13, 50606, 50606, 407, 498, 291, 528, 257, 1185, 300, 370, 370, 33783, 366, 2584, 14115, 498, 291, 528, 281, 652, 50844, 50844, 5327, 1392, 13, 50964, 50964, 759, 291, 528, 281, 10432, 264, 5598, 295, 257, 18473, 1185, 365, 1071, 472, 337, 1365, 257, 1952, 51258, 51258, 420, 512, 661, 1185, 293, 729, 3652, 2378, 380, 668, 8895, 1214, 457, 436, 600, 668, 8895, 51492, 51492, 14759, 550, 437, 291, 528, 307, 21583, 5468, 13444, 370, 300, 291, 393, 10432, 264, 13444, 51670, 51670], "temperature": 0.0, "avg_logprob": -0.09446141326311723, "compression_ratio": 1.8739837398373984, "no_speech_prob": 4.0057591832010075e-05}, {"id": 440, "seek": 226972, "start": 2281.72, "end": 2287.6, "text": " If you want to combine the output of a automated system with another one for example a human", "tokens": [50364, 1151, 558, 570, 291, 362, 281, 652, 257, 3537, 291, 434, 7579, 281, 652, 257, 3537, 13, 50606, 50606, 407, 498, 291, 528, 257, 1185, 300, 370, 370, 33783, 366, 2584, 14115, 498, 291, 528, 281, 652, 50844, 50844, 5327, 1392, 13, 50964, 50964, 759, 291, 528, 281, 10432, 264, 5598, 295, 257, 18473, 1185, 365, 1071, 472, 337, 1365, 257, 1952, 51258, 51258, 420, 512, 661, 1185, 293, 729, 3652, 2378, 380, 668, 8895, 1214, 457, 436, 600, 668, 8895, 51492, 51492, 14759, 550, 437, 291, 528, 307, 21583, 5468, 13444, 370, 300, 291, 393, 10432, 264, 13444, 51670, 51670], "temperature": 0.0, "avg_logprob": -0.09446141326311723, "compression_ratio": 1.8739837398373984, "no_speech_prob": 4.0057591832010075e-05}, {"id": 441, "seek": 226972, "start": 2287.6, "end": 2292.2799999999997, "text": " or some other system and those systems haven't been trained together but they've been trained", "tokens": [50364, 1151, 558, 570, 291, 362, 281, 652, 257, 3537, 291, 434, 7579, 281, 652, 257, 3537, 13, 50606, 50606, 407, 498, 291, 528, 257, 1185, 300, 370, 370, 33783, 366, 2584, 14115, 498, 291, 528, 281, 652, 50844, 50844, 5327, 1392, 13, 50964, 50964, 759, 291, 528, 281, 10432, 264, 5598, 295, 257, 18473, 1185, 365, 1071, 472, 337, 1365, 257, 1952, 51258, 51258, 420, 512, 661, 1185, 293, 729, 3652, 2378, 380, 668, 8895, 1214, 457, 436, 600, 668, 8895, 51492, 51492, 14759, 550, 437, 291, 528, 307, 21583, 5468, 13444, 370, 300, 291, 393, 10432, 264, 13444, 51670, 51670], "temperature": 0.0, "avg_logprob": -0.09446141326311723, "compression_ratio": 1.8739837398373984, "no_speech_prob": 4.0057591832010075e-05}, {"id": 442, "seek": 226972, "start": 2292.2799999999997, "end": 2295.8399999999997, "text": " separately then what you want is calibrated scores so that you can combine the scores", "tokens": [50364, 1151, 558, 570, 291, 362, 281, 652, 257, 3537, 291, 434, 7579, 281, 652, 257, 3537, 13, 50606, 50606, 407, 498, 291, 528, 257, 1185, 300, 370, 370, 33783, 366, 2584, 14115, 498, 291, 528, 281, 652, 50844, 50844, 5327, 1392, 13, 50964, 50964, 759, 291, 528, 281, 10432, 264, 5598, 295, 257, 18473, 1185, 365, 1071, 472, 337, 1365, 257, 1952, 51258, 51258, 420, 512, 661, 1185, 293, 729, 3652, 2378, 380, 668, 8895, 1214, 457, 436, 600, 668, 8895, 51492, 51492, 14759, 550, 437, 291, 528, 307, 21583, 5468, 13444, 370, 300, 291, 393, 10432, 264, 13444, 51670, 51670], "temperature": 0.0, "avg_logprob": -0.09446141326311723, "compression_ratio": 1.8739837398373984, "no_speech_prob": 4.0057591832010075e-05}, {"id": 443, "seek": 229584, "start": 2295.84, "end": 2300.2400000000002, "text": " of the two systems to make a good decision and there is only one way to calibrate scores", "tokens": [50364, 295, 264, 732, 3652, 281, 652, 257, 665, 3537, 293, 456, 307, 787, 472, 636, 281, 21583, 4404, 13444, 50584, 50584, 293, 307, 281, 733, 295, 1261, 552, 666, 33783, 420, 661, 2098, 366, 2139, 24249, 420, 10344, 50804, 50804, 1392, 457, 498, 291, 434, 516, 281, 3847, 257, 1185, 917, 12, 1353, 12, 521, 281, 652, 5327, 550, 550, 550, 51184, 51184, 572, 550, 2035, 22358, 2445, 291, 764, 307, 2489, 382, 938, 382, 309, 2709, 264, 1151, 6175, 51530, 51530, 281, 264, 3537, 300, 281, 264, 1151, 3537, 13, 51718, 51718], "temperature": 0.0, "avg_logprob": -0.1605418556614926, "compression_ratio": 1.7847533632286996, "no_speech_prob": 1.1473910490167327e-05}, {"id": 444, "seek": 229584, "start": 2300.2400000000002, "end": 2304.6400000000003, "text": " and is to kind of turn them into probabilities or other ways are either inferior or equivalent", "tokens": [50364, 295, 264, 732, 3652, 281, 652, 257, 665, 3537, 293, 456, 307, 787, 472, 636, 281, 21583, 4404, 13444, 50584, 50584, 293, 307, 281, 733, 295, 1261, 552, 666, 33783, 420, 661, 2098, 366, 2139, 24249, 420, 10344, 50804, 50804, 1392, 457, 498, 291, 434, 516, 281, 3847, 257, 1185, 917, 12, 1353, 12, 521, 281, 652, 5327, 550, 550, 550, 51184, 51184, 572, 550, 2035, 22358, 2445, 291, 764, 307, 2489, 382, 938, 382, 309, 2709, 264, 1151, 6175, 51530, 51530, 281, 264, 3537, 300, 281, 264, 1151, 3537, 13, 51718, 51718], "temperature": 0.0, "avg_logprob": -0.1605418556614926, "compression_ratio": 1.7847533632286996, "no_speech_prob": 1.1473910490167327e-05}, {"id": 445, "seek": 229584, "start": 2304.6400000000003, "end": 2312.2400000000002, "text": " okay but if you're going to train a system end-to-end to make decisions then then then", "tokens": [50364, 295, 264, 732, 3652, 281, 652, 257, 665, 3537, 293, 456, 307, 787, 472, 636, 281, 21583, 4404, 13444, 50584, 50584, 293, 307, 281, 733, 295, 1261, 552, 666, 33783, 420, 661, 2098, 366, 2139, 24249, 420, 10344, 50804, 50804, 1392, 457, 498, 291, 434, 516, 281, 3847, 257, 1185, 917, 12, 1353, 12, 521, 281, 652, 5327, 550, 550, 550, 51184, 51184, 572, 550, 2035, 22358, 2445, 291, 764, 307, 2489, 382, 938, 382, 309, 2709, 264, 1151, 6175, 51530, 51530, 281, 264, 3537, 300, 281, 264, 1151, 3537, 13, 51718, 51718], "temperature": 0.0, "avg_logprob": -0.1605418556614926, "compression_ratio": 1.7847533632286996, "no_speech_prob": 1.1473910490167327e-05}, {"id": 446, "seek": 229584, "start": 2312.2400000000002, "end": 2319.1600000000003, "text": " no then whatever scoring function you use is fine as long as it gives the best score", "tokens": [50364, 295, 264, 732, 3652, 281, 652, 257, 665, 3537, 293, 456, 307, 787, 472, 636, 281, 21583, 4404, 13444, 50584, 50584, 293, 307, 281, 733, 295, 1261, 552, 666, 33783, 420, 661, 2098, 366, 2139, 24249, 420, 10344, 50804, 50804, 1392, 457, 498, 291, 434, 516, 281, 3847, 257, 1185, 917, 12, 1353, 12, 521, 281, 652, 5327, 550, 550, 550, 51184, 51184, 572, 550, 2035, 22358, 2445, 291, 764, 307, 2489, 382, 938, 382, 309, 2709, 264, 1151, 6175, 51530, 51530, 281, 264, 3537, 300, 281, 264, 1151, 3537, 13, 51718, 51718], "temperature": 0.0, "avg_logprob": -0.1605418556614926, "compression_ratio": 1.7847533632286996, "no_speech_prob": 1.1473910490167327e-05}, {"id": 447, "seek": 229584, "start": 2319.1600000000003, "end": 2322.92, "text": " to the decision that to the best decision.", "tokens": [50364, 295, 264, 732, 3652, 281, 652, 257, 665, 3537, 293, 456, 307, 787, 472, 636, 281, 21583, 4404, 13444, 50584, 50584, 293, 307, 281, 733, 295, 1261, 552, 666, 33783, 420, 661, 2098, 366, 2139, 24249, 420, 10344, 50804, 50804, 1392, 457, 498, 291, 434, 516, 281, 3847, 257, 1185, 917, 12, 1353, 12, 521, 281, 652, 5327, 550, 550, 550, 51184, 51184, 572, 550, 2035, 22358, 2445, 291, 764, 307, 2489, 382, 938, 382, 309, 2709, 264, 1151, 6175, 51530, 51530, 281, 264, 3537, 300, 281, 264, 1151, 3537, 13, 51718, 51718], "temperature": 0.0, "avg_logprob": -0.1605418556614926, "compression_ratio": 1.7847533632286996, "no_speech_prob": 1.1473910490167327e-05}, {"id": 448, "seek": 232292, "start": 2322.92, "end": 2329.08, "text": " That gives you way more choices in how you handle the model way more choices of how you", "tokens": [50364, 663, 2709, 291, 636, 544, 7994, 294, 577, 291, 4813, 264, 2316, 636, 544, 7994, 295, 577, 291, 50672, 50672, 3847, 309, 437, 10024, 2445, 291, 764, 1936, 498, 291, 498, 291, 13466, 300, 428, 2316, 312, 31959, 3142, 50990, 50990, 291, 362, 281, 360, 6674, 22119, 370, 1936, 291, 362, 281, 3847, 428, 2316, 294, 1270, 257, 636, 51204, 51204, 300, 264, 8482, 309, 2709, 281, 264, 1412, 291, 11441, 307, 6674, 1392, 13, 51514, 51514, 440, 1154, 307, 300, 341, 307, 341, 393, 787, 312, 12785, 281, 589, 294, 264, 1389, 689, 428, 2316, 51728, 51728], "temperature": 0.0, "avg_logprob": -0.09790306091308594, "compression_ratio": 1.947136563876652, "no_speech_prob": 1.4284311873780098e-05}, {"id": 449, "seek": 232292, "start": 2329.08, "end": 2335.44, "text": " train it what objective function you use basically if you if you insist that your model be probabilistic", "tokens": [50364, 663, 2709, 291, 636, 544, 7994, 294, 577, 291, 4813, 264, 2316, 636, 544, 7994, 295, 577, 291, 50672, 50672, 3847, 309, 437, 10024, 2445, 291, 764, 1936, 498, 291, 498, 291, 13466, 300, 428, 2316, 312, 31959, 3142, 50990, 50990, 291, 362, 281, 360, 6674, 22119, 370, 1936, 291, 362, 281, 3847, 428, 2316, 294, 1270, 257, 636, 51204, 51204, 300, 264, 8482, 309, 2709, 281, 264, 1412, 291, 11441, 307, 6674, 1392, 13, 51514, 51514, 440, 1154, 307, 300, 341, 307, 341, 393, 787, 312, 12785, 281, 589, 294, 264, 1389, 689, 428, 2316, 51728, 51728], "temperature": 0.0, "avg_logprob": -0.09790306091308594, "compression_ratio": 1.947136563876652, "no_speech_prob": 1.4284311873780098e-05}, {"id": 450, "seek": 232292, "start": 2335.44, "end": 2339.7200000000003, "text": " you have to do maximum likelihood so basically you have to train your model in such a way", "tokens": [50364, 663, 2709, 291, 636, 544, 7994, 294, 577, 291, 4813, 264, 2316, 636, 544, 7994, 295, 577, 291, 50672, 50672, 3847, 309, 437, 10024, 2445, 291, 764, 1936, 498, 291, 498, 291, 13466, 300, 428, 2316, 312, 31959, 3142, 50990, 50990, 291, 362, 281, 360, 6674, 22119, 370, 1936, 291, 362, 281, 3847, 428, 2316, 294, 1270, 257, 636, 51204, 51204, 300, 264, 8482, 309, 2709, 281, 264, 1412, 291, 11441, 307, 6674, 1392, 13, 51514, 51514, 440, 1154, 307, 300, 341, 307, 341, 393, 787, 312, 12785, 281, 589, 294, 264, 1389, 689, 428, 2316, 51728, 51728], "temperature": 0.0, "avg_logprob": -0.09790306091308594, "compression_ratio": 1.947136563876652, "no_speech_prob": 1.4284311873780098e-05}, {"id": 451, "seek": 232292, "start": 2339.7200000000003, "end": 2345.92, "text": " that the probability it gives to the data you observe is maximum okay.", "tokens": [50364, 663, 2709, 291, 636, 544, 7994, 294, 577, 291, 4813, 264, 2316, 636, 544, 7994, 295, 577, 291, 50672, 50672, 3847, 309, 437, 10024, 2445, 291, 764, 1936, 498, 291, 498, 291, 13466, 300, 428, 2316, 312, 31959, 3142, 50990, 50990, 291, 362, 281, 360, 6674, 22119, 370, 1936, 291, 362, 281, 3847, 428, 2316, 294, 1270, 257, 636, 51204, 51204, 300, 264, 8482, 309, 2709, 281, 264, 1412, 291, 11441, 307, 6674, 1392, 13, 51514, 51514, 440, 1154, 307, 300, 341, 307, 341, 393, 787, 312, 12785, 281, 589, 294, 264, 1389, 689, 428, 2316, 51728, 51728], "temperature": 0.0, "avg_logprob": -0.09790306091308594, "compression_ratio": 1.947136563876652, "no_speech_prob": 1.4284311873780098e-05}, {"id": 452, "seek": 232292, "start": 2345.92, "end": 2350.2000000000003, "text": " The problem is that this is this can only be proven to work in the case where your model", "tokens": [50364, 663, 2709, 291, 636, 544, 7994, 294, 577, 291, 4813, 264, 2316, 636, 544, 7994, 295, 577, 291, 50672, 50672, 3847, 309, 437, 10024, 2445, 291, 764, 1936, 498, 291, 498, 291, 13466, 300, 428, 2316, 312, 31959, 3142, 50990, 50990, 291, 362, 281, 360, 6674, 22119, 370, 1936, 291, 362, 281, 3847, 428, 2316, 294, 1270, 257, 636, 51204, 51204, 300, 264, 8482, 309, 2709, 281, 264, 1412, 291, 11441, 307, 6674, 1392, 13, 51514, 51514, 440, 1154, 307, 300, 341, 307, 341, 393, 787, 312, 12785, 281, 589, 294, 264, 1389, 689, 428, 2316, 51728, 51728], "temperature": 0.0, "avg_logprob": -0.09790306091308594, "compression_ratio": 1.947136563876652, "no_speech_prob": 1.4284311873780098e-05}, {"id": 453, "seek": 235020, "start": 2350.2, "end": 2355.16, "text": " is correct and your model is never correct in a sense that you know there's this famous", "tokens": [50364, 307, 3006, 293, 428, 2316, 307, 1128, 3006, 294, 257, 2020, 300, 291, 458, 456, 311, 341, 4618, 50612, 50612, 421, 647, 538, 264, 4618, 29588, 952, 2424, 300, 848, 439, 5245, 366, 2085, 457, 512, 366, 4420, 13, 50978, 50978, 407, 31959, 3142, 5245, 4098, 31959, 3142, 2316, 294, 1090, 18795, 7673, 293, 31959, 3142, 51176, 51176, 5245, 294, 1199, 72, 12, 25451, 3029, 831, 6851, 411, 2487, 293, 721, 411, 341, 366, 439, 30874, 51384, 51384, 5245, 436, 434, 439, 2085, 294, 257, 636, 293, 498, 291, 853, 281, 2710, 1125, 552, 291, 652, 552, 544, 2085, 51717, 51717], "temperature": 0.0, "avg_logprob": -0.18603073046045396, "compression_ratio": 1.889795918367347, "no_speech_prob": 7.766494491079357e-06}, {"id": 454, "seek": 235020, "start": 2355.16, "end": 2362.48, "text": " quip by the famous statistician box that said all models are wrong but some are useful.", "tokens": [50364, 307, 3006, 293, 428, 2316, 307, 1128, 3006, 294, 257, 2020, 300, 291, 458, 456, 311, 341, 4618, 50612, 50612, 421, 647, 538, 264, 4618, 29588, 952, 2424, 300, 848, 439, 5245, 366, 2085, 457, 512, 366, 4420, 13, 50978, 50978, 407, 31959, 3142, 5245, 4098, 31959, 3142, 2316, 294, 1090, 18795, 7673, 293, 31959, 3142, 51176, 51176, 5245, 294, 1199, 72, 12, 25451, 3029, 831, 6851, 411, 2487, 293, 721, 411, 341, 366, 439, 30874, 51384, 51384, 5245, 436, 434, 439, 2085, 294, 257, 636, 293, 498, 291, 853, 281, 2710, 1125, 552, 291, 652, 552, 544, 2085, 51717, 51717], "temperature": 0.0, "avg_logprob": -0.18603073046045396, "compression_ratio": 1.889795918367347, "no_speech_prob": 7.766494491079357e-06}, {"id": 455, "seek": 235020, "start": 2362.48, "end": 2366.4399999999996, "text": " So probabilistic models particularly probabilistic model in high dimensional spaces and probabilistic", "tokens": [50364, 307, 3006, 293, 428, 2316, 307, 1128, 3006, 294, 257, 2020, 300, 291, 458, 456, 311, 341, 4618, 50612, 50612, 421, 647, 538, 264, 4618, 29588, 952, 2424, 300, 848, 439, 5245, 366, 2085, 457, 512, 366, 4420, 13, 50978, 50978, 407, 31959, 3142, 5245, 4098, 31959, 3142, 2316, 294, 1090, 18795, 7673, 293, 31959, 3142, 51176, 51176, 5245, 294, 1199, 72, 12, 25451, 3029, 831, 6851, 411, 2487, 293, 721, 411, 341, 366, 439, 30874, 51384, 51384, 5245, 436, 434, 439, 2085, 294, 257, 636, 293, 498, 291, 853, 281, 2710, 1125, 552, 291, 652, 552, 544, 2085, 51717, 51717], "temperature": 0.0, "avg_logprob": -0.18603073046045396, "compression_ratio": 1.889795918367347, "no_speech_prob": 7.766494491079357e-06}, {"id": 456, "seek": 235020, "start": 2366.4399999999996, "end": 2370.6, "text": " models in communi-communitorial situations like text and things like this are all approximate", "tokens": [50364, 307, 3006, 293, 428, 2316, 307, 1128, 3006, 294, 257, 2020, 300, 291, 458, 456, 311, 341, 4618, 50612, 50612, 421, 647, 538, 264, 4618, 29588, 952, 2424, 300, 848, 439, 5245, 366, 2085, 457, 512, 366, 4420, 13, 50978, 50978, 407, 31959, 3142, 5245, 4098, 31959, 3142, 2316, 294, 1090, 18795, 7673, 293, 31959, 3142, 51176, 51176, 5245, 294, 1199, 72, 12, 25451, 3029, 831, 6851, 411, 2487, 293, 721, 411, 341, 366, 439, 30874, 51384, 51384, 5245, 436, 434, 439, 2085, 294, 257, 636, 293, 498, 291, 853, 281, 2710, 1125, 552, 291, 652, 552, 544, 2085, 51717, 51717], "temperature": 0.0, "avg_logprob": -0.18603073046045396, "compression_ratio": 1.889795918367347, "no_speech_prob": 7.766494491079357e-06}, {"id": 457, "seek": 235020, "start": 2370.6, "end": 2377.2599999999998, "text": " models they're all wrong in a way and if you try to normalize them you make them more wrong", "tokens": [50364, 307, 3006, 293, 428, 2316, 307, 1128, 3006, 294, 257, 2020, 300, 291, 458, 456, 311, 341, 4618, 50612, 50612, 421, 647, 538, 264, 4618, 29588, 952, 2424, 300, 848, 439, 5245, 366, 2085, 457, 512, 366, 4420, 13, 50978, 50978, 407, 31959, 3142, 5245, 4098, 31959, 3142, 2316, 294, 1090, 18795, 7673, 293, 31959, 3142, 51176, 51176, 5245, 294, 1199, 72, 12, 25451, 3029, 831, 6851, 411, 2487, 293, 721, 411, 341, 366, 439, 30874, 51384, 51384, 5245, 436, 434, 439, 2085, 294, 257, 636, 293, 498, 291, 853, 281, 2710, 1125, 552, 291, 652, 552, 544, 2085, 51717, 51717], "temperature": 0.0, "avg_logprob": -0.18603073046045396, "compression_ratio": 1.889795918367347, "no_speech_prob": 7.766494491079357e-06}, {"id": 458, "seek": 237726, "start": 2377.26, "end": 2380.6800000000003, "text": " so you're better off kind of not normalizing them.", "tokens": [50364, 370, 291, 434, 1101, 766, 733, 295, 406, 2710, 3319, 552, 13, 50535, 50535, 821, 311, 1071, 935, 300, 311, 767, 544, 1021, 293, 286, 808, 646, 281, 341, 707, 10686, 51043, 51043, 293, 632, 341, 472, 13, 51319, 51319, 407, 341, 307, 4140, 281, 312, 364, 2281, 2445, 300, 27986, 264, 33621, 1296, 1783, 293, 51548, 51548, 398, 1392, 293, 309, 311, 309, 311, 411, 257, 6937, 3613, 498, 291, 528, 1392, 13, 51841, 51841], "temperature": 0.0, "avg_logprob": -0.1497663473471617, "compression_ratio": 1.5223880597014925, "no_speech_prob": 1.3629750355903525e-05}, {"id": 459, "seek": 237726, "start": 2380.6800000000003, "end": 2390.84, "text": " There's another point that's actually more important and I come back to this little diagram", "tokens": [50364, 370, 291, 434, 1101, 766, 733, 295, 406, 2710, 3319, 552, 13, 50535, 50535, 821, 311, 1071, 935, 300, 311, 767, 544, 1021, 293, 286, 808, 646, 281, 341, 707, 10686, 51043, 51043, 293, 632, 341, 472, 13, 51319, 51319, 407, 341, 307, 4140, 281, 312, 364, 2281, 2445, 300, 27986, 264, 33621, 1296, 1783, 293, 51548, 51548, 398, 1392, 293, 309, 311, 309, 311, 411, 257, 6937, 3613, 498, 291, 528, 1392, 13, 51841, 51841], "temperature": 0.0, "avg_logprob": -0.1497663473471617, "compression_ratio": 1.5223880597014925, "no_speech_prob": 1.3629750355903525e-05}, {"id": 460, "seek": 237726, "start": 2390.84, "end": 2396.36, "text": " and had this one.", "tokens": [50364, 370, 291, 434, 1101, 766, 733, 295, 406, 2710, 3319, 552, 13, 50535, 50535, 821, 311, 1071, 935, 300, 311, 767, 544, 1021, 293, 286, 808, 646, 281, 341, 707, 10686, 51043, 51043, 293, 632, 341, 472, 13, 51319, 51319, 407, 341, 307, 4140, 281, 312, 364, 2281, 2445, 300, 27986, 264, 33621, 1296, 1783, 293, 51548, 51548, 398, 1392, 293, 309, 311, 309, 311, 411, 257, 6937, 3613, 498, 291, 528, 1392, 13, 51841, 51841], "temperature": 0.0, "avg_logprob": -0.1497663473471617, "compression_ratio": 1.5223880597014925, "no_speech_prob": 1.3629750355903525e-05}, {"id": 461, "seek": 237726, "start": 2396.36, "end": 2400.94, "text": " So this is meant to be an energy function that captures the dependency between X and", "tokens": [50364, 370, 291, 434, 1101, 766, 733, 295, 406, 2710, 3319, 552, 13, 50535, 50535, 821, 311, 1071, 935, 300, 311, 767, 544, 1021, 293, 286, 808, 646, 281, 341, 707, 10686, 51043, 51043, 293, 632, 341, 472, 13, 51319, 51319, 407, 341, 307, 4140, 281, 312, 364, 2281, 2445, 300, 27986, 264, 33621, 1296, 1783, 293, 51548, 51548, 398, 1392, 293, 309, 311, 309, 311, 411, 257, 6937, 3613, 498, 291, 528, 1392, 13, 51841, 51841], "temperature": 0.0, "avg_logprob": -0.1497663473471617, "compression_ratio": 1.5223880597014925, "no_speech_prob": 1.3629750355903525e-05}, {"id": 462, "seek": 237726, "start": 2400.94, "end": 2406.8, "text": " Y okay and it's it's like a mountain range if you want okay.", "tokens": [50364, 370, 291, 434, 1101, 766, 733, 295, 406, 2710, 3319, 552, 13, 50535, 50535, 821, 311, 1071, 935, 300, 311, 767, 544, 1021, 293, 286, 808, 646, 281, 341, 707, 10686, 51043, 51043, 293, 632, 341, 472, 13, 51319, 51319, 407, 341, 307, 4140, 281, 312, 364, 2281, 2445, 300, 27986, 264, 33621, 1296, 1783, 293, 51548, 51548, 398, 1392, 293, 309, 311, 309, 311, 411, 257, 6937, 3613, 498, 291, 528, 1392, 13, 51841, 51841], "temperature": 0.0, "avg_logprob": -0.1497663473471617, "compression_ratio": 1.5223880597014925, "no_speech_prob": 1.3629750355903525e-05}, {"id": 463, "seek": 240680, "start": 2406.8, "end": 2411.8, "text": " The valleys are where the black dots are these are the data points and then there's kind", "tokens": [50364, 440, 45614, 366, 689, 264, 2211, 15026, 366, 613, 366, 264, 1412, 2793, 293, 550, 456, 311, 733, 50614, 50614, 295, 10233, 439, 926, 13, 50740, 50740, 823, 498, 291, 3847, 257, 31959, 3142, 2316, 365, 341, 3811, 300, 264, 2793, 366, 767, 50956, 50956, 322, 257, 5862, 47138, 295, 36227, 293, 36227, 5862, 47138, 1392, 13, 51219, 51219, 407, 264, 1412, 7316, 337, 264, 2418, 5893, 337, 264, 2211, 15026, 307, 767, 257, 445, 257, 1622, 51588, 51588, 1392, 307, 472, 1622, 732, 3876, 1045, 3876, 457, 436, 434, 3876, 436, 500, 380, 362, 604, 604, 11402, 51839, 51839], "temperature": 0.0, "avg_logprob": -0.14198612699321672, "compression_ratio": 1.8493723849372385, "no_speech_prob": 6.961293820495484e-06}, {"id": 464, "seek": 240680, "start": 2411.8, "end": 2414.32, "text": " of mountains all around.", "tokens": [50364, 440, 45614, 366, 689, 264, 2211, 15026, 366, 613, 366, 264, 1412, 2793, 293, 550, 456, 311, 733, 50614, 50614, 295, 10233, 439, 926, 13, 50740, 50740, 823, 498, 291, 3847, 257, 31959, 3142, 2316, 365, 341, 3811, 300, 264, 2793, 366, 767, 50956, 50956, 322, 257, 5862, 47138, 295, 36227, 293, 36227, 5862, 47138, 1392, 13, 51219, 51219, 407, 264, 1412, 7316, 337, 264, 2418, 5893, 337, 264, 2211, 15026, 307, 767, 257, 445, 257, 1622, 51588, 51588, 1392, 307, 472, 1622, 732, 3876, 1045, 3876, 457, 436, 434, 3876, 436, 500, 380, 362, 604, 604, 11402, 51839, 51839], "temperature": 0.0, "avg_logprob": -0.14198612699321672, "compression_ratio": 1.8493723849372385, "no_speech_prob": 6.961293820495484e-06}, {"id": 465, "seek": 240680, "start": 2414.32, "end": 2418.6400000000003, "text": " Now if you train a probabilistic model with this imagine that the points are actually", "tokens": [50364, 440, 45614, 366, 689, 264, 2211, 15026, 366, 613, 366, 264, 1412, 2793, 293, 550, 456, 311, 733, 50614, 50614, 295, 10233, 439, 926, 13, 50740, 50740, 823, 498, 291, 3847, 257, 31959, 3142, 2316, 365, 341, 3811, 300, 264, 2793, 366, 767, 50956, 50956, 322, 257, 5862, 47138, 295, 36227, 293, 36227, 5862, 47138, 1392, 13, 51219, 51219, 407, 264, 1412, 7316, 337, 264, 2418, 5893, 337, 264, 2211, 15026, 307, 767, 257, 445, 257, 1622, 51588, 51588, 1392, 307, 472, 1622, 732, 3876, 1045, 3876, 457, 436, 434, 3876, 436, 500, 380, 362, 604, 604, 11402, 51839, 51839], "temperature": 0.0, "avg_logprob": -0.14198612699321672, "compression_ratio": 1.8493723849372385, "no_speech_prob": 6.961293820495484e-06}, {"id": 466, "seek": 240680, "start": 2418.6400000000003, "end": 2423.9, "text": " on a thin manifold of infinitely and infinitely thin manifold okay.", "tokens": [50364, 440, 45614, 366, 689, 264, 2211, 15026, 366, 613, 366, 264, 1412, 2793, 293, 550, 456, 311, 733, 50614, 50614, 295, 10233, 439, 926, 13, 50740, 50740, 823, 498, 291, 3847, 257, 31959, 3142, 2316, 365, 341, 3811, 300, 264, 2793, 366, 767, 50956, 50956, 322, 257, 5862, 47138, 295, 36227, 293, 36227, 5862, 47138, 1392, 13, 51219, 51219, 407, 264, 1412, 7316, 337, 264, 2418, 5893, 337, 264, 2211, 15026, 307, 767, 257, 445, 257, 1622, 51588, 51588, 1392, 307, 472, 1622, 732, 3876, 1045, 3876, 457, 436, 434, 3876, 436, 500, 380, 362, 604, 604, 11402, 51839, 51839], "temperature": 0.0, "avg_logprob": -0.14198612699321672, "compression_ratio": 1.8493723849372385, "no_speech_prob": 6.961293820495484e-06}, {"id": 467, "seek": 240680, "start": 2423.9, "end": 2431.28, "text": " So the data distribution for the white dot for the black dots is actually a just a line", "tokens": [50364, 440, 45614, 366, 689, 264, 2211, 15026, 366, 613, 366, 264, 1412, 2793, 293, 550, 456, 311, 733, 50614, 50614, 295, 10233, 439, 926, 13, 50740, 50740, 823, 498, 291, 3847, 257, 31959, 3142, 2316, 365, 341, 3811, 300, 264, 2793, 366, 767, 50956, 50956, 322, 257, 5862, 47138, 295, 36227, 293, 36227, 5862, 47138, 1392, 13, 51219, 51219, 407, 264, 1412, 7316, 337, 264, 2418, 5893, 337, 264, 2211, 15026, 307, 767, 257, 445, 257, 1622, 51588, 51588, 1392, 307, 472, 1622, 732, 3876, 1045, 3876, 457, 436, 434, 3876, 436, 500, 380, 362, 604, 604, 11402, 51839, 51839], "temperature": 0.0, "avg_logprob": -0.14198612699321672, "compression_ratio": 1.8493723849372385, "no_speech_prob": 6.961293820495484e-06}, {"id": 468, "seek": 240680, "start": 2431.28, "end": 2436.3, "text": " okay is one line two lines three lines but they're lines they don't have any any width", "tokens": [50364, 440, 45614, 366, 689, 264, 2211, 15026, 366, 613, 366, 264, 1412, 2793, 293, 550, 456, 311, 733, 50614, 50614, 295, 10233, 439, 926, 13, 50740, 50740, 823, 498, 291, 3847, 257, 31959, 3142, 2316, 365, 341, 3811, 300, 264, 2793, 366, 767, 50956, 50956, 322, 257, 5862, 47138, 295, 36227, 293, 36227, 5862, 47138, 1392, 13, 51219, 51219, 407, 264, 1412, 7316, 337, 264, 2418, 5893, 337, 264, 2211, 15026, 307, 767, 257, 445, 257, 1622, 51588, 51588, 1392, 307, 472, 1622, 732, 3876, 1045, 3876, 457, 436, 434, 3876, 436, 500, 380, 362, 604, 604, 11402, 51839, 51839], "temperature": 0.0, "avg_logprob": -0.14198612699321672, "compression_ratio": 1.8493723849372385, "no_speech_prob": 6.961293820495484e-06}, {"id": 469, "seek": 243630, "start": 2436.3, "end": 2437.3, "text": " if you want.", "tokens": [50364, 498, 291, 528, 13, 50414, 50414, 407, 498, 291, 3847, 257, 31959, 3142, 2316, 322, 341, 428, 31959, 3142, 2316, 820, 976, 291, 428, 50585, 50585, 10305, 2316, 820, 980, 291, 562, 291, 366, 322, 341, 47138, 264, 264, 23930, 820, 312, 50909, 50909, 13785, 264, 10305, 307, 13785, 293, 445, 17889, 2380, 295, 309, 820, 312, 4018, 1392, 13, 51327, 51327, 663, 576, 312, 264, 3006, 2316, 7316, 295, 341, 7316, 498, 309, 311, 257, 5862, 5924, 13, 51617, 51617], "temperature": 0.0, "avg_logprob": -0.1732673070516931, "compression_ratio": 1.8615384615384616, "no_speech_prob": 1.8339891539653763e-05}, {"id": 470, "seek": 243630, "start": 2437.3, "end": 2440.7200000000003, "text": " So if you train a probabilistic model on this your probabilistic model should give you your", "tokens": [50364, 498, 291, 528, 13, 50414, 50414, 407, 498, 291, 3847, 257, 31959, 3142, 2316, 322, 341, 428, 31959, 3142, 2316, 820, 976, 291, 428, 50585, 50585, 10305, 2316, 820, 980, 291, 562, 291, 366, 322, 341, 47138, 264, 264, 23930, 820, 312, 50909, 50909, 13785, 264, 10305, 307, 13785, 293, 445, 17889, 2380, 295, 309, 820, 312, 4018, 1392, 13, 51327, 51327, 663, 576, 312, 264, 3006, 2316, 7316, 295, 341, 7316, 498, 309, 311, 257, 5862, 5924, 13, 51617, 51617], "temperature": 0.0, "avg_logprob": -0.1732673070516931, "compression_ratio": 1.8615384615384616, "no_speech_prob": 1.8339891539653763e-05}, {"id": 471, "seek": 243630, "start": 2440.7200000000003, "end": 2447.2000000000003, "text": " density model should tell you when you are on this manifold the the outputs should be", "tokens": [50364, 498, 291, 528, 13, 50414, 50414, 407, 498, 291, 3847, 257, 31959, 3142, 2316, 322, 341, 428, 31959, 3142, 2316, 820, 976, 291, 428, 50585, 50585, 10305, 2316, 820, 980, 291, 562, 291, 366, 322, 341, 47138, 264, 264, 23930, 820, 312, 50909, 50909, 13785, 264, 10305, 307, 13785, 293, 445, 17889, 2380, 295, 309, 820, 312, 4018, 1392, 13, 51327, 51327, 663, 576, 312, 264, 3006, 2316, 7316, 295, 341, 7316, 498, 309, 311, 257, 5862, 5924, 13, 51617, 51617], "temperature": 0.0, "avg_logprob": -0.1732673070516931, "compression_ratio": 1.8615384615384616, "no_speech_prob": 1.8339891539653763e-05}, {"id": 472, "seek": 243630, "start": 2447.2000000000003, "end": 2455.5600000000004, "text": " infinite the density is infinite and just epsilon outside of it should be zero okay.", "tokens": [50364, 498, 291, 528, 13, 50414, 50414, 407, 498, 291, 3847, 257, 31959, 3142, 2316, 322, 341, 428, 31959, 3142, 2316, 820, 976, 291, 428, 50585, 50585, 10305, 2316, 820, 980, 291, 562, 291, 366, 322, 341, 47138, 264, 264, 23930, 820, 312, 50909, 50909, 13785, 264, 10305, 307, 13785, 293, 445, 17889, 2380, 295, 309, 820, 312, 4018, 1392, 13, 51327, 51327, 663, 576, 312, 264, 3006, 2316, 7316, 295, 341, 7316, 498, 309, 311, 257, 5862, 5924, 13, 51617, 51617], "temperature": 0.0, "avg_logprob": -0.1732673070516931, "compression_ratio": 1.8615384615384616, "no_speech_prob": 1.8339891539653763e-05}, {"id": 473, "seek": 243630, "start": 2455.5600000000004, "end": 2461.36, "text": " That would be the correct model distribution of this distribution if it's a thin plate.", "tokens": [50364, 498, 291, 528, 13, 50414, 50414, 407, 498, 291, 3847, 257, 31959, 3142, 2316, 322, 341, 428, 31959, 3142, 2316, 820, 976, 291, 428, 50585, 50585, 10305, 2316, 820, 980, 291, 562, 291, 366, 322, 341, 47138, 264, 264, 23930, 820, 312, 50909, 50909, 13785, 264, 10305, 307, 13785, 293, 445, 17889, 2380, 295, 309, 820, 312, 4018, 1392, 13, 51327, 51327, 663, 576, 312, 264, 3006, 2316, 7316, 295, 341, 7316, 498, 309, 311, 257, 5862, 5924, 13, 51617, 51617], "temperature": 0.0, "avg_logprob": -0.1732673070516931, "compression_ratio": 1.8615384615384616, "no_speech_prob": 1.8339891539653763e-05}, {"id": 474, "seek": 246136, "start": 2461.36, "end": 2469.08, "text": " Not only the output should be infinite but the integral of it should be one okay.", "tokens": [50364, 1726, 787, 264, 5598, 820, 312, 13785, 457, 264, 11573, 295, 309, 820, 312, 472, 1392, 13, 50750, 50750, 467, 311, 588, 2252, 281, 4445, 322, 257, 3820, 406, 787, 300, 309, 311, 1936, 6243, 570, 51016, 51016, 718, 311, 584, 291, 528, 281, 14722, 341, 2445, 807, 512, 1333, 295, 18161, 2533, 428, 18161, 51226, 51226, 2533, 486, 362, 281, 362, 13785, 17443, 293, 13785, 17443, 366, 21583, 5468, 294, 1270, 257, 51406, 51406, 636, 300, 264, 11573, 295, 264, 23930, 295, 300, 295, 300, 1185, 670, 264, 2302, 9274, 307, 472, 13, 51684, 51684], "temperature": 0.0, "avg_logprob": -0.1544706967412209, "compression_ratio": 1.8410041841004183, "no_speech_prob": 2.3920942112454213e-05}, {"id": 475, "seek": 246136, "start": 2469.08, "end": 2474.4, "text": " It's very difficult to implement on a computer not only that it's basically impossible because", "tokens": [50364, 1726, 787, 264, 5598, 820, 312, 13785, 457, 264, 11573, 295, 309, 820, 312, 472, 1392, 13, 50750, 50750, 467, 311, 588, 2252, 281, 4445, 322, 257, 3820, 406, 787, 300, 309, 311, 1936, 6243, 570, 51016, 51016, 718, 311, 584, 291, 528, 281, 14722, 341, 2445, 807, 512, 1333, 295, 18161, 2533, 428, 18161, 51226, 51226, 2533, 486, 362, 281, 362, 13785, 17443, 293, 13785, 17443, 366, 21583, 5468, 294, 1270, 257, 51406, 51406, 636, 300, 264, 11573, 295, 264, 23930, 295, 300, 295, 300, 1185, 670, 264, 2302, 9274, 307, 472, 13, 51684, 51684], "temperature": 0.0, "avg_logprob": -0.1544706967412209, "compression_ratio": 1.8410041841004183, "no_speech_prob": 2.3920942112454213e-05}, {"id": 476, "seek": 246136, "start": 2474.4, "end": 2478.6, "text": " let's say you want to compute this function through some sort of neural net your neural", "tokens": [50364, 1726, 787, 264, 5598, 820, 312, 13785, 457, 264, 11573, 295, 309, 820, 312, 472, 1392, 13, 50750, 50750, 467, 311, 588, 2252, 281, 4445, 322, 257, 3820, 406, 787, 300, 309, 311, 1936, 6243, 570, 51016, 51016, 718, 311, 584, 291, 528, 281, 14722, 341, 2445, 807, 512, 1333, 295, 18161, 2533, 428, 18161, 51226, 51226, 2533, 486, 362, 281, 362, 13785, 17443, 293, 13785, 17443, 366, 21583, 5468, 294, 1270, 257, 51406, 51406, 636, 300, 264, 11573, 295, 264, 23930, 295, 300, 295, 300, 1185, 670, 264, 2302, 9274, 307, 472, 13, 51684, 51684], "temperature": 0.0, "avg_logprob": -0.1544706967412209, "compression_ratio": 1.8410041841004183, "no_speech_prob": 2.3920942112454213e-05}, {"id": 477, "seek": 246136, "start": 2478.6, "end": 2482.2000000000003, "text": " net will have to have infinite weights and infinite weights are calibrated in such a", "tokens": [50364, 1726, 787, 264, 5598, 820, 312, 13785, 457, 264, 11573, 295, 309, 820, 312, 472, 1392, 13, 50750, 50750, 467, 311, 588, 2252, 281, 4445, 322, 257, 3820, 406, 787, 300, 309, 311, 1936, 6243, 570, 51016, 51016, 718, 311, 584, 291, 528, 281, 14722, 341, 2445, 807, 512, 1333, 295, 18161, 2533, 428, 18161, 51226, 51226, 2533, 486, 362, 281, 362, 13785, 17443, 293, 13785, 17443, 366, 21583, 5468, 294, 1270, 257, 51406, 51406, 636, 300, 264, 11573, 295, 264, 23930, 295, 300, 295, 300, 1185, 670, 264, 2302, 9274, 307, 472, 13, 51684, 51684], "temperature": 0.0, "avg_logprob": -0.1544706967412209, "compression_ratio": 1.8410041841004183, "no_speech_prob": 2.3920942112454213e-05}, {"id": 478, "seek": 246136, "start": 2482.2000000000003, "end": 2487.76, "text": " way that the integral of the outputs of that of that system over the entire domain is one.", "tokens": [50364, 1726, 787, 264, 5598, 820, 312, 13785, 457, 264, 11573, 295, 309, 820, 312, 472, 1392, 13, 50750, 50750, 467, 311, 588, 2252, 281, 4445, 322, 257, 3820, 406, 787, 300, 309, 311, 1936, 6243, 570, 51016, 51016, 718, 311, 584, 291, 528, 281, 14722, 341, 2445, 807, 512, 1333, 295, 18161, 2533, 428, 18161, 51226, 51226, 2533, 486, 362, 281, 362, 13785, 17443, 293, 13785, 17443, 366, 21583, 5468, 294, 1270, 257, 51406, 51406, 636, 300, 264, 11573, 295, 264, 23930, 295, 300, 295, 300, 1185, 670, 264, 2302, 9274, 307, 472, 13, 51684, 51684], "temperature": 0.0, "avg_logprob": -0.1544706967412209, "compression_ratio": 1.8410041841004183, "no_speech_prob": 2.3920942112454213e-05}, {"id": 479, "seek": 248776, "start": 2487.76, "end": 2492.1200000000003, "text": " That's basically impossible you cannot have accurate probabilistic model the accurate", "tokens": [50364, 663, 311, 1936, 6243, 291, 2644, 362, 8559, 31959, 3142, 2316, 264, 8559, 50582, 50582, 3006, 31959, 3142, 2316, 337, 341, 1729, 1412, 300, 286, 445, 1907, 291, 307, 6243, 13, 50984, 50984, 639, 307, 437, 6674, 22119, 22119, 576, 528, 291, 281, 5258, 293, 456, 311, 572, 3820, 51234, 51234, 294, 264, 1002, 300, 393, 14722, 341, 1392, 13, 51472, 51472, 407, 294, 1186, 309, 311, 406, 754, 1880, 570, 3811, 300, 291, 632, 257, 2176, 10305, 2316, 51706, 51706], "temperature": 0.0, "avg_logprob": -0.12994704189070735, "compression_ratio": 1.7081545064377683, "no_speech_prob": 1.2217392395541538e-05}, {"id": 480, "seek": 248776, "start": 2492.1200000000003, "end": 2500.1600000000003, "text": " correct probabilistic model for this particular data that I just told you is impossible.", "tokens": [50364, 663, 311, 1936, 6243, 291, 2644, 362, 8559, 31959, 3142, 2316, 264, 8559, 50582, 50582, 3006, 31959, 3142, 2316, 337, 341, 1729, 1412, 300, 286, 445, 1907, 291, 307, 6243, 13, 50984, 50984, 639, 307, 437, 6674, 22119, 22119, 576, 528, 291, 281, 5258, 293, 456, 311, 572, 3820, 51234, 51234, 294, 264, 1002, 300, 393, 14722, 341, 1392, 13, 51472, 51472, 407, 294, 1186, 309, 311, 406, 754, 1880, 570, 3811, 300, 291, 632, 257, 2176, 10305, 2316, 51706, 51706], "temperature": 0.0, "avg_logprob": -0.12994704189070735, "compression_ratio": 1.7081545064377683, "no_speech_prob": 1.2217392395541538e-05}, {"id": 481, "seek": 248776, "start": 2500.1600000000003, "end": 2505.1600000000003, "text": " This is what maximum likelihood likelihood would want you to produce and there's no computer", "tokens": [50364, 663, 311, 1936, 6243, 291, 2644, 362, 8559, 31959, 3142, 2316, 264, 8559, 50582, 50582, 3006, 31959, 3142, 2316, 337, 341, 1729, 1412, 300, 286, 445, 1907, 291, 307, 6243, 13, 50984, 50984, 639, 307, 437, 6674, 22119, 22119, 576, 528, 291, 281, 5258, 293, 456, 311, 572, 3820, 51234, 51234, 294, 264, 1002, 300, 393, 14722, 341, 1392, 13, 51472, 51472, 407, 294, 1186, 309, 311, 406, 754, 1880, 570, 3811, 300, 291, 632, 257, 2176, 10305, 2316, 51706, 51706], "temperature": 0.0, "avg_logprob": -0.12994704189070735, "compression_ratio": 1.7081545064377683, "no_speech_prob": 1.2217392395541538e-05}, {"id": 482, "seek": 248776, "start": 2505.1600000000003, "end": 2509.92, "text": " in the world that can compute this okay.", "tokens": [50364, 663, 311, 1936, 6243, 291, 2644, 362, 8559, 31959, 3142, 2316, 264, 8559, 50582, 50582, 3006, 31959, 3142, 2316, 337, 341, 1729, 1412, 300, 286, 445, 1907, 291, 307, 6243, 13, 50984, 50984, 639, 307, 437, 6674, 22119, 22119, 576, 528, 291, 281, 5258, 293, 456, 311, 572, 3820, 51234, 51234, 294, 264, 1002, 300, 393, 14722, 341, 1392, 13, 51472, 51472, 407, 294, 1186, 309, 311, 406, 754, 1880, 570, 3811, 300, 291, 632, 257, 2176, 10305, 2316, 51706, 51706], "temperature": 0.0, "avg_logprob": -0.12994704189070735, "compression_ratio": 1.7081545064377683, "no_speech_prob": 1.2217392395541538e-05}, {"id": 483, "seek": 248776, "start": 2509.92, "end": 2514.6000000000004, "text": " So in fact it's not even interesting because imagine that you had a perfect density model", "tokens": [50364, 663, 311, 1936, 6243, 291, 2644, 362, 8559, 31959, 3142, 2316, 264, 8559, 50582, 50582, 3006, 31959, 3142, 2316, 337, 341, 1729, 1412, 300, 286, 445, 1907, 291, 307, 6243, 13, 50984, 50984, 639, 307, 437, 6674, 22119, 22119, 576, 528, 291, 281, 5258, 293, 456, 311, 572, 3820, 51234, 51234, 294, 264, 1002, 300, 393, 14722, 341, 1392, 13, 51472, 51472, 407, 294, 1186, 309, 311, 406, 754, 1880, 570, 3811, 300, 291, 632, 257, 2176, 10305, 2316, 51706, 51706], "temperature": 0.0, "avg_logprob": -0.12994704189070735, "compression_ratio": 1.7081545064377683, "no_speech_prob": 1.2217392395541538e-05}, {"id": 484, "seek": 251460, "start": 2514.6, "end": 2526.2799999999997, "text": " for the density I just I just mentioned which is a thin plate in that xy space.", "tokens": [50364, 337, 264, 10305, 286, 445, 286, 445, 2835, 597, 307, 257, 5862, 5924, 294, 300, 2031, 88, 1901, 13, 50948, 50948, 509, 2809, 380, 360, 38253, 498, 286, 976, 291, 257, 2158, 295, 2031, 293, 286, 1029, 291, 437, 311, 264, 1151, 2158, 51276, 51276, 295, 288, 291, 2759, 380, 312, 1075, 281, 915, 309, 570, 439, 4190, 295, 288, 3993, 257, 992, 295, 4018, 8482, 51826, 51826], "temperature": 0.0, "avg_logprob": -0.17618183408464705, "compression_ratio": 1.5411764705882354, "no_speech_prob": 7.182261470006779e-06}, {"id": 485, "seek": 251460, "start": 2526.2799999999997, "end": 2532.8399999999997, "text": " You couldn't do inference if I give you a value of x and I ask you what's the best value", "tokens": [50364, 337, 264, 10305, 286, 445, 286, 445, 2835, 597, 307, 257, 5862, 5924, 294, 300, 2031, 88, 1901, 13, 50948, 50948, 509, 2809, 380, 360, 38253, 498, 286, 976, 291, 257, 2158, 295, 2031, 293, 286, 1029, 291, 437, 311, 264, 1151, 2158, 51276, 51276, 295, 288, 291, 2759, 380, 312, 1075, 281, 915, 309, 570, 439, 4190, 295, 288, 3993, 257, 992, 295, 4018, 8482, 51826, 51826], "temperature": 0.0, "avg_logprob": -0.17618183408464705, "compression_ratio": 1.5411764705882354, "no_speech_prob": 7.182261470006779e-06}, {"id": 486, "seek": 251460, "start": 2532.8399999999997, "end": 2543.8399999999997, "text": " of y you wouldn't be able to find it because all values of y except a set of zero probability", "tokens": [50364, 337, 264, 10305, 286, 445, 286, 445, 2835, 597, 307, 257, 5862, 5924, 294, 300, 2031, 88, 1901, 13, 50948, 50948, 509, 2809, 380, 360, 38253, 498, 286, 976, 291, 257, 2158, 295, 2031, 293, 286, 1029, 291, 437, 311, 264, 1151, 2158, 51276, 51276, 295, 288, 291, 2759, 380, 312, 1075, 281, 915, 309, 570, 439, 4190, 295, 288, 3993, 257, 992, 295, 4018, 8482, 51826, 51826], "temperature": 0.0, "avg_logprob": -0.17618183408464705, "compression_ratio": 1.5411764705882354, "no_speech_prob": 7.182261470006779e-06}, {"id": 487, "seek": 254384, "start": 2543.84, "end": 2549.8, "text": " have probability zero and it's just you know a few values like for example for this value", "tokens": [50364, 362, 8482, 4018, 293, 309, 311, 445, 291, 458, 257, 1326, 4190, 411, 337, 1365, 337, 341, 2158, 50662, 50662, 295, 2031, 456, 366, 1045, 4190, 300, 366, 1944, 1392, 293, 436, 366, 36227, 9432, 293, 370, 50950, 50950, 291, 2759, 380, 312, 1075, 281, 915, 552, 456, 311, 572, 38253, 9284, 300, 486, 2089, 291, 51126, 51126, 281, 915, 552, 570, 456, 366, 1333, 295, 456, 311, 445, 2047, 6828, 558, 577, 360, 291, 915, 51572, 51572], "temperature": 0.0, "avg_logprob": -0.16437474489212037, "compression_ratio": 1.7184466019417475, "no_speech_prob": 2.5861396352411248e-05}, {"id": 488, "seek": 254384, "start": 2549.8, "end": 2555.56, "text": " of x there are three values that are possible okay and they are infinitely narrow and so", "tokens": [50364, 362, 8482, 4018, 293, 309, 311, 445, 291, 458, 257, 1326, 4190, 411, 337, 1365, 337, 341, 2158, 50662, 50662, 295, 2031, 456, 366, 1045, 4190, 300, 366, 1944, 1392, 293, 436, 366, 36227, 9432, 293, 370, 50950, 50950, 291, 2759, 380, 312, 1075, 281, 915, 552, 456, 311, 572, 38253, 9284, 300, 486, 2089, 291, 51126, 51126, 281, 915, 552, 570, 456, 366, 1333, 295, 456, 311, 445, 2047, 6828, 558, 577, 360, 291, 915, 51572, 51572], "temperature": 0.0, "avg_logprob": -0.16437474489212037, "compression_ratio": 1.7184466019417475, "no_speech_prob": 2.5861396352411248e-05}, {"id": 489, "seek": 254384, "start": 2555.56, "end": 2559.08, "text": " you wouldn't be able to find them there's no inference algorithm that will allow you", "tokens": [50364, 362, 8482, 4018, 293, 309, 311, 445, 291, 458, 257, 1326, 4190, 411, 337, 1365, 337, 341, 2158, 50662, 50662, 295, 2031, 456, 366, 1045, 4190, 300, 366, 1944, 1392, 293, 436, 366, 36227, 9432, 293, 370, 50950, 50950, 291, 2759, 380, 312, 1075, 281, 915, 552, 456, 311, 572, 38253, 9284, 300, 486, 2089, 291, 51126, 51126, 281, 915, 552, 570, 456, 366, 1333, 295, 456, 311, 445, 2047, 6828, 558, 577, 360, 291, 915, 51572, 51572], "temperature": 0.0, "avg_logprob": -0.16437474489212037, "compression_ratio": 1.7184466019417475, "no_speech_prob": 2.5861396352411248e-05}, {"id": 490, "seek": 254384, "start": 2559.08, "end": 2568.0, "text": " to find them because there are sort of there's just direct functions right how do you find", "tokens": [50364, 362, 8482, 4018, 293, 309, 311, 445, 291, 458, 257, 1326, 4190, 411, 337, 1365, 337, 341, 2158, 50662, 50662, 295, 2031, 456, 366, 1045, 4190, 300, 366, 1944, 1392, 293, 436, 366, 36227, 9432, 293, 370, 50950, 50950, 291, 2759, 380, 312, 1075, 281, 915, 552, 456, 311, 572, 38253, 9284, 300, 486, 2089, 291, 51126, 51126, 281, 915, 552, 570, 456, 366, 1333, 295, 456, 311, 445, 2047, 6828, 558, 577, 360, 291, 915, 51572, 51572], "temperature": 0.0, "avg_logprob": -0.16437474489212037, "compression_ratio": 1.7184466019417475, "no_speech_prob": 2.5861396352411248e-05}, {"id": 491, "seek": 256800, "start": 2568.0, "end": 2576.88, "text": " them. So the only way you can find them is if you make it if you make your contrast function", "tokens": [50364, 552, 13, 407, 264, 787, 636, 291, 393, 915, 552, 307, 498, 291, 652, 309, 498, 291, 652, 428, 8712, 2445, 50808, 50808, 5508, 293, 819, 9364, 293, 550, 291, 458, 291, 393, 722, 490, 604, 935, 293, 538, 16235, 51004, 51004, 23475, 291, 393, 915, 257, 665, 2158, 337, 288, 337, 604, 2158, 295, 2031, 13, 51226, 51226, 583, 341, 307, 406, 516, 281, 312, 257, 665, 31959, 3142, 2316, 295, 264, 7316, 498, 264, 7316, 51426, 51426, 307, 295, 264, 2010, 286, 2835, 1392, 13, 407, 510, 307, 257, 1389, 689, 13466, 278, 281, 362, 257, 665, 31959, 3142, 51802, 51802], "temperature": 0.0, "avg_logprob": -0.11768417358398438, "compression_ratio": 1.8620689655172413, "no_speech_prob": 7.2958378041221295e-06}, {"id": 492, "seek": 256800, "start": 2576.88, "end": 2580.8, "text": " smooth and differentiable and then you know you can start from any point and by gradient", "tokens": [50364, 552, 13, 407, 264, 787, 636, 291, 393, 915, 552, 307, 498, 291, 652, 309, 498, 291, 652, 428, 8712, 2445, 50808, 50808, 5508, 293, 819, 9364, 293, 550, 291, 458, 291, 393, 722, 490, 604, 935, 293, 538, 16235, 51004, 51004, 23475, 291, 393, 915, 257, 665, 2158, 337, 288, 337, 604, 2158, 295, 2031, 13, 51226, 51226, 583, 341, 307, 406, 516, 281, 312, 257, 665, 31959, 3142, 2316, 295, 264, 7316, 498, 264, 7316, 51426, 51426, 307, 295, 264, 2010, 286, 2835, 1392, 13, 407, 510, 307, 257, 1389, 689, 13466, 278, 281, 362, 257, 665, 31959, 3142, 51802, 51802], "temperature": 0.0, "avg_logprob": -0.11768417358398438, "compression_ratio": 1.8620689655172413, "no_speech_prob": 7.2958378041221295e-06}, {"id": 493, "seek": 256800, "start": 2580.8, "end": 2585.24, "text": " descent you can find a good value for y for any value of x.", "tokens": [50364, 552, 13, 407, 264, 787, 636, 291, 393, 915, 552, 307, 498, 291, 652, 309, 498, 291, 652, 428, 8712, 2445, 50808, 50808, 5508, 293, 819, 9364, 293, 550, 291, 458, 291, 393, 722, 490, 604, 935, 293, 538, 16235, 51004, 51004, 23475, 291, 393, 915, 257, 665, 2158, 337, 288, 337, 604, 2158, 295, 2031, 13, 51226, 51226, 583, 341, 307, 406, 516, 281, 312, 257, 665, 31959, 3142, 2316, 295, 264, 7316, 498, 264, 7316, 51426, 51426, 307, 295, 264, 2010, 286, 2835, 1392, 13, 407, 510, 307, 257, 1389, 689, 13466, 278, 281, 362, 257, 665, 31959, 3142, 51802, 51802], "temperature": 0.0, "avg_logprob": -0.11768417358398438, "compression_ratio": 1.8620689655172413, "no_speech_prob": 7.2958378041221295e-06}, {"id": 494, "seek": 256800, "start": 2585.24, "end": 2589.24, "text": " But this is not going to be a good probabilistic model of the distribution if the distribution", "tokens": [50364, 552, 13, 407, 264, 787, 636, 291, 393, 915, 552, 307, 498, 291, 652, 309, 498, 291, 652, 428, 8712, 2445, 50808, 50808, 5508, 293, 819, 9364, 293, 550, 291, 458, 291, 393, 722, 490, 604, 935, 293, 538, 16235, 51004, 51004, 23475, 291, 393, 915, 257, 665, 2158, 337, 288, 337, 604, 2158, 295, 2031, 13, 51226, 51226, 583, 341, 307, 406, 516, 281, 312, 257, 665, 31959, 3142, 2316, 295, 264, 7316, 498, 264, 7316, 51426, 51426, 307, 295, 264, 2010, 286, 2835, 1392, 13, 407, 510, 307, 257, 1389, 689, 13466, 278, 281, 362, 257, 665, 31959, 3142, 51802, 51802], "temperature": 0.0, "avg_logprob": -0.11768417358398438, "compression_ratio": 1.8620689655172413, "no_speech_prob": 7.2958378041221295e-06}, {"id": 495, "seek": 256800, "start": 2589.24, "end": 2596.76, "text": " is of the type I mentioned okay. So here is a case where insisting to have a good probabilistic", "tokens": [50364, 552, 13, 407, 264, 787, 636, 291, 393, 915, 552, 307, 498, 291, 652, 309, 498, 291, 652, 428, 8712, 2445, 50808, 50808, 5508, 293, 819, 9364, 293, 550, 291, 458, 291, 393, 722, 490, 604, 935, 293, 538, 16235, 51004, 51004, 23475, 291, 393, 915, 257, 665, 2158, 337, 288, 337, 604, 2158, 295, 2031, 13, 51226, 51226, 583, 341, 307, 406, 516, 281, 312, 257, 665, 31959, 3142, 2316, 295, 264, 7316, 498, 264, 7316, 51426, 51426, 307, 295, 264, 2010, 286, 2835, 1392, 13, 407, 510, 307, 257, 1389, 689, 13466, 278, 281, 362, 257, 665, 31959, 3142, 51802, 51802], "temperature": 0.0, "avg_logprob": -0.11768417358398438, "compression_ratio": 1.8620689655172413, "no_speech_prob": 7.2958378041221295e-06}, {"id": 496, "seek": 259676, "start": 2596.76, "end": 2603.0400000000004, "text": " model actually is bad okay maximum likelihood sucks. So if you are true Bayesian you say", "tokens": [50364, 2316, 767, 307, 1578, 1392, 6674, 22119, 15846, 13, 407, 498, 291, 366, 2074, 7840, 42434, 291, 584, 50678, 50678, 1954, 457, 411, 291, 458, 291, 393, 3006, 341, 538, 1419, 257, 2068, 4059, 689, 264, 4059, 1619, 51008, 51008, 428, 10305, 2445, 575, 281, 312, 5508, 293, 291, 458, 291, 393, 519, 295, 341, 382, 257, 4059, 51310, 51310, 370, 457, 1203, 291, 360, 294, 1333, 295, 7840, 42434, 2115, 747, 264, 41473, 32674, 456, 2670, 2870, 466, 51639, 51639], "temperature": 0.0, "avg_logprob": -0.10966863976903708, "compression_ratio": 1.6842105263157894, "no_speech_prob": 1.184241318696877e-05}, {"id": 497, "seek": 259676, "start": 2603.0400000000004, "end": 2609.6400000000003, "text": " oh but like you know you can correct this by having a strong prior where the prior says", "tokens": [50364, 2316, 767, 307, 1578, 1392, 6674, 22119, 15846, 13, 407, 498, 291, 366, 2074, 7840, 42434, 291, 584, 50678, 50678, 1954, 457, 411, 291, 458, 291, 393, 3006, 341, 538, 1419, 257, 2068, 4059, 689, 264, 4059, 1619, 51008, 51008, 428, 10305, 2445, 575, 281, 312, 5508, 293, 291, 458, 291, 393, 519, 295, 341, 382, 257, 4059, 51310, 51310, 370, 457, 1203, 291, 360, 294, 1333, 295, 7840, 42434, 2115, 747, 264, 41473, 32674, 456, 2670, 2870, 466, 51639, 51639], "temperature": 0.0, "avg_logprob": -0.10966863976903708, "compression_ratio": 1.6842105263157894, "no_speech_prob": 1.184241318696877e-05}, {"id": 498, "seek": 259676, "start": 2609.6400000000003, "end": 2615.6800000000003, "text": " your density function has to be smooth and you know you can think of this as a prior", "tokens": [50364, 2316, 767, 307, 1578, 1392, 6674, 22119, 15846, 13, 407, 498, 291, 366, 2074, 7840, 42434, 291, 584, 50678, 50678, 1954, 457, 411, 291, 458, 291, 393, 3006, 341, 538, 1419, 257, 2068, 4059, 689, 264, 4059, 1619, 51008, 51008, 428, 10305, 2445, 575, 281, 312, 5508, 293, 291, 458, 291, 393, 519, 295, 341, 382, 257, 4059, 51310, 51310, 370, 457, 1203, 291, 360, 294, 1333, 295, 7840, 42434, 2115, 747, 264, 41473, 32674, 456, 2670, 2870, 466, 51639, 51639], "temperature": 0.0, "avg_logprob": -0.10966863976903708, "compression_ratio": 1.6842105263157894, "no_speech_prob": 1.184241318696877e-05}, {"id": 499, "seek": 259676, "start": 2615.6800000000003, "end": 2622.26, "text": " so but everything you do in sort of Bayesian terms take the logarithm thereof forget about", "tokens": [50364, 2316, 767, 307, 1578, 1392, 6674, 22119, 15846, 13, 407, 498, 291, 366, 2074, 7840, 42434, 291, 584, 50678, 50678, 1954, 457, 411, 291, 458, 291, 393, 3006, 341, 538, 1419, 257, 2068, 4059, 689, 264, 4059, 1619, 51008, 51008, 428, 10305, 2445, 575, 281, 312, 5508, 293, 291, 458, 291, 393, 519, 295, 341, 382, 257, 4059, 51310, 51310, 370, 457, 1203, 291, 360, 294, 1333, 295, 7840, 42434, 2115, 747, 264, 41473, 32674, 456, 2670, 2870, 466, 51639, 51639], "temperature": 0.0, "avg_logprob": -0.10966863976903708, "compression_ratio": 1.6842105263157894, "no_speech_prob": 1.184241318696877e-05}, {"id": 500, "seek": 262226, "start": 2622.26, "end": 2627.48, "text": " normalization and you get energy-based models. So energy-based models that have a regularizer", "tokens": [50364, 2710, 2144, 293, 291, 483, 2281, 12, 6032, 5245, 13, 407, 2281, 12, 6032, 5245, 300, 362, 257, 3890, 6545, 50625, 50625, 597, 307, 45558, 281, 428, 2281, 2445, 366, 2584, 10344, 281, 7840, 42434, 5245, 50904, 50904, 689, 264, 22119, 307, 21510, 295, 264, 2281, 293, 586, 291, 483, 21510, 472, 1433, 51282, 51282, 294, 264, 2281, 291, 458, 1413, 21510, 3890, 6545, 293, 370, 309, 311, 2681, 281, 21510, 2281, 1804, 51571, 51571, 3890, 6545, 293, 498, 291, 4159, 264, 21510, 291, 362, 364, 2281, 12, 6032, 2316, 365, 364, 45558, 51767, 51767], "temperature": 0.0, "avg_logprob": -0.12108032973771243, "compression_ratio": 2.076923076923077, "no_speech_prob": 8.397265446546953e-06}, {"id": 501, "seek": 262226, "start": 2627.48, "end": 2633.0600000000004, "text": " which is additive to your energy function are completely equivalent to Bayesian models", "tokens": [50364, 2710, 2144, 293, 291, 483, 2281, 12, 6032, 5245, 13, 407, 2281, 12, 6032, 5245, 300, 362, 257, 3890, 6545, 50625, 50625, 597, 307, 45558, 281, 428, 2281, 2445, 366, 2584, 10344, 281, 7840, 42434, 5245, 50904, 50904, 689, 264, 22119, 307, 21510, 295, 264, 2281, 293, 586, 291, 483, 21510, 472, 1433, 51282, 51282, 294, 264, 2281, 291, 458, 1413, 21510, 3890, 6545, 293, 370, 309, 311, 2681, 281, 21510, 2281, 1804, 51571, 51571, 3890, 6545, 293, 498, 291, 4159, 264, 21510, 291, 362, 364, 2281, 12, 6032, 2316, 365, 364, 45558, 51767, 51767], "temperature": 0.0, "avg_logprob": -0.12108032973771243, "compression_ratio": 2.076923076923077, "no_speech_prob": 8.397265446546953e-06}, {"id": 502, "seek": 262226, "start": 2633.0600000000004, "end": 2640.6200000000003, "text": " where the likelihood is exponential of the energy and now you get exponential one term", "tokens": [50364, 2710, 2144, 293, 291, 483, 2281, 12, 6032, 5245, 13, 407, 2281, 12, 6032, 5245, 300, 362, 257, 3890, 6545, 50625, 50625, 597, 307, 45558, 281, 428, 2281, 2445, 366, 2584, 10344, 281, 7840, 42434, 5245, 50904, 50904, 689, 264, 22119, 307, 21510, 295, 264, 2281, 293, 586, 291, 483, 21510, 472, 1433, 51282, 51282, 294, 264, 2281, 291, 458, 1413, 21510, 3890, 6545, 293, 370, 309, 311, 2681, 281, 21510, 2281, 1804, 51571, 51571, 3890, 6545, 293, 498, 291, 4159, 264, 21510, 291, 362, 364, 2281, 12, 6032, 2316, 365, 364, 45558, 51767, 51767], "temperature": 0.0, "avg_logprob": -0.12108032973771243, "compression_ratio": 2.076923076923077, "no_speech_prob": 8.397265446546953e-06}, {"id": 503, "seek": 262226, "start": 2640.6200000000003, "end": 2646.4, "text": " in the energy you know times exponential regularizer and so it's equal to exponential energy plus", "tokens": [50364, 2710, 2144, 293, 291, 483, 2281, 12, 6032, 5245, 13, 407, 2281, 12, 6032, 5245, 300, 362, 257, 3890, 6545, 50625, 50625, 597, 307, 45558, 281, 428, 2281, 2445, 366, 2584, 10344, 281, 7840, 42434, 5245, 50904, 50904, 689, 264, 22119, 307, 21510, 295, 264, 2281, 293, 586, 291, 483, 21510, 472, 1433, 51282, 51282, 294, 264, 2281, 291, 458, 1413, 21510, 3890, 6545, 293, 370, 309, 311, 2681, 281, 21510, 2281, 1804, 51571, 51571, 3890, 6545, 293, 498, 291, 4159, 264, 21510, 291, 362, 364, 2281, 12, 6032, 2316, 365, 364, 45558, 51767, 51767], "temperature": 0.0, "avg_logprob": -0.12108032973771243, "compression_ratio": 2.076923076923077, "no_speech_prob": 8.397265446546953e-06}, {"id": 504, "seek": 262226, "start": 2646.4, "end": 2650.32, "text": " regularizer and if you remove the exponential you have an energy-based model with an additive", "tokens": [50364, 2710, 2144, 293, 291, 483, 2281, 12, 6032, 5245, 13, 407, 2281, 12, 6032, 5245, 300, 362, 257, 3890, 6545, 50625, 50625, 597, 307, 45558, 281, 428, 2281, 2445, 366, 2584, 10344, 281, 7840, 42434, 5245, 50904, 50904, 689, 264, 22119, 307, 21510, 295, 264, 2281, 293, 586, 291, 483, 21510, 472, 1433, 51282, 51282, 294, 264, 2281, 291, 458, 1413, 21510, 3890, 6545, 293, 370, 309, 311, 2681, 281, 21510, 2281, 1804, 51571, 51571, 3890, 6545, 293, 498, 291, 4159, 264, 21510, 291, 362, 364, 2281, 12, 6032, 2316, 365, 364, 45558, 51767, 51767], "temperature": 0.0, "avg_logprob": -0.12108032973771243, "compression_ratio": 2.076923076923077, "no_speech_prob": 8.397265446546953e-06}, {"id": 505, "seek": 265032, "start": 2650.32, "end": 2657.04, "text": " regularizer. So there is kind of a correspondence between you know probabilistic and Bayesian", "tokens": [50364, 3890, 6545, 13, 407, 456, 307, 733, 295, 257, 38135, 1296, 291, 458, 31959, 3142, 293, 7840, 42434, 50700, 50700, 7150, 456, 457, 13466, 278, 300, 291, 360, 6674, 22119, 307, 2171, 1578, 337, 291, 4098, 51000, 51000, 294, 1090, 18795, 7673, 420, 2512, 31927, 831, 7673, 689, 428, 31959, 3142, 2316, 307, 588, 51286, 51286, 2085, 309, 311, 406, 588, 2085, 294, 27706, 37870, 309, 311, 1392, 457, 294, 300, 1389, 291, 458, 309, 311, 534, 51618, 51618], "temperature": 0.0, "avg_logprob": -0.13174769319133994, "compression_ratio": 1.6888888888888889, "no_speech_prob": 1.1478286978672259e-05}, {"id": 506, "seek": 265032, "start": 2657.04, "end": 2663.04, "text": " methods there but insisting that you do maximum likelihood is sometimes bad for you particularly", "tokens": [50364, 3890, 6545, 13, 407, 456, 307, 733, 295, 257, 38135, 1296, 291, 458, 31959, 3142, 293, 7840, 42434, 50700, 50700, 7150, 456, 457, 13466, 278, 300, 291, 360, 6674, 22119, 307, 2171, 1578, 337, 291, 4098, 51000, 51000, 294, 1090, 18795, 7673, 420, 2512, 31927, 831, 7673, 689, 428, 31959, 3142, 2316, 307, 588, 51286, 51286, 2085, 309, 311, 406, 588, 2085, 294, 27706, 37870, 309, 311, 1392, 457, 294, 300, 1389, 291, 458, 309, 311, 534, 51618, 51618], "temperature": 0.0, "avg_logprob": -0.13174769319133994, "compression_ratio": 1.6888888888888889, "no_speech_prob": 1.1478286978672259e-05}, {"id": 507, "seek": 265032, "start": 2663.04, "end": 2668.76, "text": " in high dimensional spaces or combinatorial spaces where your probabilistic model is very", "tokens": [50364, 3890, 6545, 13, 407, 456, 307, 733, 295, 257, 38135, 1296, 291, 458, 31959, 3142, 293, 7840, 42434, 50700, 50700, 7150, 456, 457, 13466, 278, 300, 291, 360, 6674, 22119, 307, 2171, 1578, 337, 291, 4098, 51000, 51000, 294, 1090, 18795, 7673, 420, 2512, 31927, 831, 7673, 689, 428, 31959, 3142, 2316, 307, 588, 51286, 51286, 2085, 309, 311, 406, 588, 2085, 294, 27706, 37870, 309, 311, 1392, 457, 294, 300, 1389, 291, 458, 309, 311, 534, 51618, 51618], "temperature": 0.0, "avg_logprob": -0.13174769319133994, "compression_ratio": 1.6888888888888889, "no_speech_prob": 1.1478286978672259e-05}, {"id": 508, "seek": 265032, "start": 2668.76, "end": 2675.4, "text": " wrong it's not very wrong in discrete distributions it's okay but in that case you know it's really", "tokens": [50364, 3890, 6545, 13, 407, 456, 307, 733, 295, 257, 38135, 1296, 291, 458, 31959, 3142, 293, 7840, 42434, 50700, 50700, 7150, 456, 457, 13466, 278, 300, 291, 360, 6674, 22119, 307, 2171, 1578, 337, 291, 4098, 51000, 51000, 294, 1090, 18795, 7673, 420, 2512, 31927, 831, 7673, 689, 428, 31959, 3142, 2316, 307, 588, 51286, 51286, 2085, 309, 311, 406, 588, 2085, 294, 27706, 37870, 309, 311, 1392, 457, 294, 300, 1389, 291, 458, 309, 311, 534, 51618, 51618], "temperature": 0.0, "avg_logprob": -0.13174769319133994, "compression_ratio": 1.6888888888888889, "no_speech_prob": 1.1478286978672259e-05}, {"id": 509, "seek": 267540, "start": 2675.4, "end": 2688.8, "text": " wrong and all models are wrong. Okay so there is a form of learning and I'll come back to", "tokens": [50364, 2085, 293, 439, 5245, 366, 2085, 13, 1033, 370, 456, 307, 257, 1254, 295, 2539, 293, 286, 603, 808, 646, 281, 51034, 51034, 341, 281, 341, 412, 4641, 294, 2027, 16564, 1219, 2698, 12, 48172, 24420, 2539, 293, 309, 311, 534, 51326, 51326, 1333, 295, 49866, 700, 295, 439, 46533, 2539, 457, 611, 733, 295, 437, 561, 1143, 51602, 51602, 281, 818, 2693, 12879, 24420, 2539, 293, 257, 688, 295, 721, 293, 286, 519, 309, 311, 264, 534, 264, 2027, 51842, 51842], "temperature": 0.0, "avg_logprob": -0.17055600030081614, "compression_ratio": 1.792929292929293, "no_speech_prob": 7.886066669016145e-06}, {"id": 510, "seek": 267540, "start": 2688.8, "end": 2694.64, "text": " this to this at length in future lectures called self-supervised learning and it's really", "tokens": [50364, 2085, 293, 439, 5245, 366, 2085, 13, 1033, 370, 456, 307, 257, 1254, 295, 2539, 293, 286, 603, 808, 646, 281, 51034, 51034, 341, 281, 341, 412, 4641, 294, 2027, 16564, 1219, 2698, 12, 48172, 24420, 2539, 293, 309, 311, 534, 51326, 51326, 1333, 295, 49866, 700, 295, 439, 46533, 2539, 457, 611, 733, 295, 437, 561, 1143, 51602, 51602, 281, 818, 2693, 12879, 24420, 2539, 293, 257, 688, 295, 721, 293, 286, 519, 309, 311, 264, 534, 264, 2027, 51842, 51842], "temperature": 0.0, "avg_logprob": -0.17055600030081614, "compression_ratio": 1.792929292929293, "no_speech_prob": 7.886066669016145e-06}, {"id": 511, "seek": 267540, "start": 2694.64, "end": 2700.1600000000003, "text": " sort of encompasses first of all supervised learning but also kind of what people used", "tokens": [50364, 2085, 293, 439, 5245, 366, 2085, 13, 1033, 370, 456, 307, 257, 1254, 295, 2539, 293, 286, 603, 808, 646, 281, 51034, 51034, 341, 281, 341, 412, 4641, 294, 2027, 16564, 1219, 2698, 12, 48172, 24420, 2539, 293, 309, 311, 534, 51326, 51326, 1333, 295, 49866, 700, 295, 439, 46533, 2539, 457, 611, 733, 295, 437, 561, 1143, 51602, 51602, 281, 818, 2693, 12879, 24420, 2539, 293, 257, 688, 295, 721, 293, 286, 519, 309, 311, 264, 534, 264, 2027, 51842, 51842], "temperature": 0.0, "avg_logprob": -0.17055600030081614, "compression_ratio": 1.792929292929293, "no_speech_prob": 7.886066669016145e-06}, {"id": 512, "seek": 267540, "start": 2700.1600000000003, "end": 2704.96, "text": " to call unsupervised learning and a lot of things and I think it's the really the future", "tokens": [50364, 2085, 293, 439, 5245, 366, 2085, 13, 1033, 370, 456, 307, 257, 1254, 295, 2539, 293, 286, 603, 808, 646, 281, 51034, 51034, 341, 281, 341, 412, 4641, 294, 2027, 16564, 1219, 2698, 12, 48172, 24420, 2539, 293, 309, 311, 534, 51326, 51326, 1333, 295, 49866, 700, 295, 439, 46533, 2539, 457, 611, 733, 295, 437, 561, 1143, 51602, 51602, 281, 818, 2693, 12879, 24420, 2539, 293, 257, 688, 295, 721, 293, 286, 519, 309, 311, 264, 534, 264, 2027, 51842, 51842], "temperature": 0.0, "avg_logprob": -0.17055600030081614, "compression_ratio": 1.792929292929293, "no_speech_prob": 7.886066669016145e-06}, {"id": 513, "seek": 270496, "start": 2704.96, "end": 2710.28, "text": " of machine learning is in self-supervised learning and you start seeing this these days", "tokens": [50364, 295, 3479, 2539, 307, 294, 2698, 12, 48172, 24420, 2539, 293, 291, 722, 2577, 341, 613, 1708, 50630, 50630, 291, 458, 670, 264, 1036, 1064, 293, 257, 1922, 456, 311, 668, 11322, 4205, 294, 426, 45196, 570, 295, 3652, 50945, 50945, 411, 363, 31479, 293, 729, 3652, 366, 8895, 1228, 2698, 12, 48172, 24420, 2539, 257, 1729, 1254, 51239, 51239, 295, 2698, 12, 48172, 24420, 2539, 1219, 413, 2982, 57, 278, 8399, 22660, 19866, 597, 321, 603, 751, 466, 13, 821, 311, 51474, 51474, 668, 611, 1596, 257, 857, 295, 4205, 670, 264, 1036, 1045, 2493, 420, 370, 294, 1228, 2698, 12, 48172, 24420, 51702, 51702], "temperature": 0.0, "avg_logprob": -0.14949720877188225, "compression_ratio": 1.8448979591836734, "no_speech_prob": 2.282450623170007e-05}, {"id": 514, "seek": 270496, "start": 2710.28, "end": 2716.58, "text": " you know over the last year and a half there's been enormous progress in NLP because of systems", "tokens": [50364, 295, 3479, 2539, 307, 294, 2698, 12, 48172, 24420, 2539, 293, 291, 722, 2577, 341, 613, 1708, 50630, 50630, 291, 458, 670, 264, 1036, 1064, 293, 257, 1922, 456, 311, 668, 11322, 4205, 294, 426, 45196, 570, 295, 3652, 50945, 50945, 411, 363, 31479, 293, 729, 3652, 366, 8895, 1228, 2698, 12, 48172, 24420, 2539, 257, 1729, 1254, 51239, 51239, 295, 2698, 12, 48172, 24420, 2539, 1219, 413, 2982, 57, 278, 8399, 22660, 19866, 597, 321, 603, 751, 466, 13, 821, 311, 51474, 51474, 668, 611, 1596, 257, 857, 295, 4205, 670, 264, 1036, 1045, 2493, 420, 370, 294, 1228, 2698, 12, 48172, 24420, 51702, 51702], "temperature": 0.0, "avg_logprob": -0.14949720877188225, "compression_ratio": 1.8448979591836734, "no_speech_prob": 2.282450623170007e-05}, {"id": 515, "seek": 270496, "start": 2716.58, "end": 2722.46, "text": " like BERT and those systems are trained using self-supervised learning a particular form", "tokens": [50364, 295, 3479, 2539, 307, 294, 2698, 12, 48172, 24420, 2539, 293, 291, 722, 2577, 341, 613, 1708, 50630, 50630, 291, 458, 670, 264, 1036, 1064, 293, 257, 1922, 456, 311, 668, 11322, 4205, 294, 426, 45196, 570, 295, 3652, 50945, 50945, 411, 363, 31479, 293, 729, 3652, 366, 8895, 1228, 2698, 12, 48172, 24420, 2539, 257, 1729, 1254, 51239, 51239, 295, 2698, 12, 48172, 24420, 2539, 1219, 413, 2982, 57, 278, 8399, 22660, 19866, 597, 321, 603, 751, 466, 13, 821, 311, 51474, 51474, 668, 611, 1596, 257, 857, 295, 4205, 670, 264, 1036, 1045, 2493, 420, 370, 294, 1228, 2698, 12, 48172, 24420, 51702, 51702], "temperature": 0.0, "avg_logprob": -0.14949720877188225, "compression_ratio": 1.8448979591836734, "no_speech_prob": 2.282450623170007e-05}, {"id": 516, "seek": 270496, "start": 2722.46, "end": 2727.16, "text": " of self-supervised learning called DinoZing autoencoder which we'll talk about. There's", "tokens": [50364, 295, 3479, 2539, 307, 294, 2698, 12, 48172, 24420, 2539, 293, 291, 722, 2577, 341, 613, 1708, 50630, 50630, 291, 458, 670, 264, 1036, 1064, 293, 257, 1922, 456, 311, 668, 11322, 4205, 294, 426, 45196, 570, 295, 3652, 50945, 50945, 411, 363, 31479, 293, 729, 3652, 366, 8895, 1228, 2698, 12, 48172, 24420, 2539, 257, 1729, 1254, 51239, 51239, 295, 2698, 12, 48172, 24420, 2539, 1219, 413, 2982, 57, 278, 8399, 22660, 19866, 597, 321, 603, 751, 466, 13, 821, 311, 51474, 51474, 668, 611, 1596, 257, 857, 295, 4205, 670, 264, 1036, 1045, 2493, 420, 370, 294, 1228, 2698, 12, 48172, 24420, 51702, 51702], "temperature": 0.0, "avg_logprob": -0.14949720877188225, "compression_ratio": 1.8448979591836734, "no_speech_prob": 2.282450623170007e-05}, {"id": 517, "seek": 270496, "start": 2727.16, "end": 2731.7200000000003, "text": " been also quite a bit of progress over the last three months or so in using self-supervised", "tokens": [50364, 295, 3479, 2539, 307, 294, 2698, 12, 48172, 24420, 2539, 293, 291, 722, 2577, 341, 613, 1708, 50630, 50630, 291, 458, 670, 264, 1036, 1064, 293, 257, 1922, 456, 311, 668, 11322, 4205, 294, 426, 45196, 570, 295, 3652, 50945, 50945, 411, 363, 31479, 293, 729, 3652, 366, 8895, 1228, 2698, 12, 48172, 24420, 2539, 257, 1729, 1254, 51239, 51239, 295, 2698, 12, 48172, 24420, 2539, 1219, 413, 2982, 57, 278, 8399, 22660, 19866, 597, 321, 603, 751, 466, 13, 821, 311, 51474, 51474, 668, 611, 1596, 257, 857, 295, 4205, 670, 264, 1036, 1045, 2493, 420, 370, 294, 1228, 2698, 12, 48172, 24420, 51702, 51702], "temperature": 0.0, "avg_logprob": -0.14949720877188225, "compression_ratio": 1.8448979591836734, "no_speech_prob": 2.282450623170007e-05}, {"id": 518, "seek": 273172, "start": 2731.72, "end": 2738.9199999999996, "text": " learning to train systems to learn vision systems to learn features using you know a", "tokens": [50364, 2539, 281, 3847, 3652, 281, 1466, 5201, 3652, 281, 1466, 4122, 1228, 291, 458, 257, 50724, 50724, 2698, 12, 48172, 24420, 659, 25111, 5633, 293, 264, 4334, 295, 2698, 12, 48172, 24420, 2539, 307, 281, 3847, 257, 51146, 51146, 1185, 281, 1466, 665, 33358, 295, 264, 4846, 370, 300, 291, 393, 26514, 764, 729, 51388, 51388, 33358, 382, 4846, 281, 257, 46533, 5633, 420, 29280, 2539, 5633, 420, 2035, 13, 51730, 51730], "temperature": 0.0, "avg_logprob": -0.15704742637840477, "compression_ratio": 1.9553072625698324, "no_speech_prob": 3.022824603249319e-05}, {"id": 519, "seek": 273172, "start": 2738.9199999999996, "end": 2747.3599999999997, "text": " self-supervised pretext task and the purpose of self-supervised learning is to train a", "tokens": [50364, 2539, 281, 3847, 3652, 281, 1466, 5201, 3652, 281, 1466, 4122, 1228, 291, 458, 257, 50724, 50724, 2698, 12, 48172, 24420, 659, 25111, 5633, 293, 264, 4334, 295, 2698, 12, 48172, 24420, 2539, 307, 281, 3847, 257, 51146, 51146, 1185, 281, 1466, 665, 33358, 295, 264, 4846, 370, 300, 291, 393, 26514, 764, 729, 51388, 51388, 33358, 382, 4846, 281, 257, 46533, 5633, 420, 29280, 2539, 5633, 420, 2035, 13, 51730, 51730], "temperature": 0.0, "avg_logprob": -0.15704742637840477, "compression_ratio": 1.9553072625698324, "no_speech_prob": 3.022824603249319e-05}, {"id": 520, "seek": 273172, "start": 2747.3599999999997, "end": 2752.2, "text": " system to learn good representations of the input so that you can subsequently use those", "tokens": [50364, 2539, 281, 3847, 3652, 281, 1466, 5201, 3652, 281, 1466, 4122, 1228, 291, 458, 257, 50724, 50724, 2698, 12, 48172, 24420, 659, 25111, 5633, 293, 264, 4334, 295, 2698, 12, 48172, 24420, 2539, 307, 281, 3847, 257, 51146, 51146, 1185, 281, 1466, 665, 33358, 295, 264, 4846, 370, 300, 291, 393, 26514, 764, 729, 51388, 51388, 33358, 382, 4846, 281, 257, 46533, 5633, 420, 29280, 2539, 5633, 420, 2035, 13, 51730, 51730], "temperature": 0.0, "avg_logprob": -0.15704742637840477, "compression_ratio": 1.9553072625698324, "no_speech_prob": 3.022824603249319e-05}, {"id": 521, "seek": 273172, "start": 2752.2, "end": 2759.04, "text": " representations as input to a supervised task or reinforcement learning task or whatever.", "tokens": [50364, 2539, 281, 3847, 3652, 281, 1466, 5201, 3652, 281, 1466, 4122, 1228, 291, 458, 257, 50724, 50724, 2698, 12, 48172, 24420, 659, 25111, 5633, 293, 264, 4334, 295, 2698, 12, 48172, 24420, 2539, 307, 281, 3847, 257, 51146, 51146, 1185, 281, 1466, 665, 33358, 295, 264, 4846, 370, 300, 291, 393, 26514, 764, 729, 51388, 51388, 33358, 382, 4846, 281, 257, 46533, 5633, 420, 29280, 2539, 5633, 420, 2035, 13, 51730, 51730], "temperature": 0.0, "avg_logprob": -0.15704742637840477, "compression_ratio": 1.9553072625698324, "no_speech_prob": 3.022824603249319e-05}, {"id": 522, "seek": 275904, "start": 2759.04, "end": 2762.84, "text": " The thing is there is a lot more information that the system can use in the context of", "tokens": [50364, 440, 551, 307, 456, 307, 257, 688, 544, 1589, 300, 264, 1185, 393, 764, 294, 264, 4319, 295, 50554, 50554, 2698, 12, 48172, 24420, 2539, 370, 718, 385, 980, 291, 437, 286, 914, 538, 2698, 12, 48172, 24420, 2539, 13, 407, 50830, 50830, 2698, 12, 48172, 24420, 2539, 307, 300, 1580, 2709, 291, 257, 16635, 295, 1412, 293, 291, 434, 516, 281, 3847, 51066, 51066, 257, 1185, 281, 6069, 257, 2522, 295, 300, 1412, 2212, 1071, 2522, 295, 300, 1412, 13, 1033, 370, 337, 1365, 51462, 51462, 286, 976, 291, 257, 2522, 295, 960, 293, 1029, 291, 764, 264, 700, 1922, 295, 264, 960, 293, 3847, 257, 2316, 51844, 51844], "temperature": 0.0, "avg_logprob": -0.11247192961829049, "compression_ratio": 1.9316239316239316, "no_speech_prob": 3.3183980121975765e-05}, {"id": 523, "seek": 275904, "start": 2762.84, "end": 2768.36, "text": " self-supervised learning so let me tell you what I mean by self-supervised learning. So", "tokens": [50364, 440, 551, 307, 456, 307, 257, 688, 544, 1589, 300, 264, 1185, 393, 764, 294, 264, 4319, 295, 50554, 50554, 2698, 12, 48172, 24420, 2539, 370, 718, 385, 980, 291, 437, 286, 914, 538, 2698, 12, 48172, 24420, 2539, 13, 407, 50830, 50830, 2698, 12, 48172, 24420, 2539, 307, 300, 1580, 2709, 291, 257, 16635, 295, 1412, 293, 291, 434, 516, 281, 3847, 51066, 51066, 257, 1185, 281, 6069, 257, 2522, 295, 300, 1412, 2212, 1071, 2522, 295, 300, 1412, 13, 1033, 370, 337, 1365, 51462, 51462, 286, 976, 291, 257, 2522, 295, 960, 293, 1029, 291, 764, 264, 700, 1922, 295, 264, 960, 293, 3847, 257, 2316, 51844, 51844], "temperature": 0.0, "avg_logprob": -0.11247192961829049, "compression_ratio": 1.9316239316239316, "no_speech_prob": 3.3183980121975765e-05}, {"id": 524, "seek": 275904, "start": 2768.36, "end": 2773.08, "text": " self-supervised learning is that someone gives you a chunk of data and you're going to train", "tokens": [50364, 440, 551, 307, 456, 307, 257, 688, 544, 1589, 300, 264, 1185, 393, 764, 294, 264, 4319, 295, 50554, 50554, 2698, 12, 48172, 24420, 2539, 370, 718, 385, 980, 291, 437, 286, 914, 538, 2698, 12, 48172, 24420, 2539, 13, 407, 50830, 50830, 2698, 12, 48172, 24420, 2539, 307, 300, 1580, 2709, 291, 257, 16635, 295, 1412, 293, 291, 434, 516, 281, 3847, 51066, 51066, 257, 1185, 281, 6069, 257, 2522, 295, 300, 1412, 2212, 1071, 2522, 295, 300, 1412, 13, 1033, 370, 337, 1365, 51462, 51462, 286, 976, 291, 257, 2522, 295, 960, 293, 1029, 291, 764, 264, 700, 1922, 295, 264, 960, 293, 3847, 257, 2316, 51844, 51844], "temperature": 0.0, "avg_logprob": -0.11247192961829049, "compression_ratio": 1.9316239316239316, "no_speech_prob": 3.3183980121975765e-05}, {"id": 525, "seek": 275904, "start": 2773.08, "end": 2781.0, "text": " a system to predict a piece of that data given another piece of that data. Okay so for example", "tokens": [50364, 440, 551, 307, 456, 307, 257, 688, 544, 1589, 300, 264, 1185, 393, 764, 294, 264, 4319, 295, 50554, 50554, 2698, 12, 48172, 24420, 2539, 370, 718, 385, 980, 291, 437, 286, 914, 538, 2698, 12, 48172, 24420, 2539, 13, 407, 50830, 50830, 2698, 12, 48172, 24420, 2539, 307, 300, 1580, 2709, 291, 257, 16635, 295, 1412, 293, 291, 434, 516, 281, 3847, 51066, 51066, 257, 1185, 281, 6069, 257, 2522, 295, 300, 1412, 2212, 1071, 2522, 295, 300, 1412, 13, 1033, 370, 337, 1365, 51462, 51462, 286, 976, 291, 257, 2522, 295, 960, 293, 1029, 291, 764, 264, 700, 1922, 295, 264, 960, 293, 3847, 257, 2316, 51844, 51844], "temperature": 0.0, "avg_logprob": -0.11247192961829049, "compression_ratio": 1.9316239316239316, "no_speech_prob": 3.3183980121975765e-05}, {"id": 526, "seek": 275904, "start": 2781.0, "end": 2788.64, "text": " I give you a piece of video and ask you use the first half of the video and train a model", "tokens": [50364, 440, 551, 307, 456, 307, 257, 688, 544, 1589, 300, 264, 1185, 393, 764, 294, 264, 4319, 295, 50554, 50554, 2698, 12, 48172, 24420, 2539, 370, 718, 385, 980, 291, 437, 286, 914, 538, 2698, 12, 48172, 24420, 2539, 13, 407, 50830, 50830, 2698, 12, 48172, 24420, 2539, 307, 300, 1580, 2709, 291, 257, 16635, 295, 1412, 293, 291, 434, 516, 281, 3847, 51066, 51066, 257, 1185, 281, 6069, 257, 2522, 295, 300, 1412, 2212, 1071, 2522, 295, 300, 1412, 13, 1033, 370, 337, 1365, 51462, 51462, 286, 976, 291, 257, 2522, 295, 960, 293, 1029, 291, 764, 264, 700, 1922, 295, 264, 960, 293, 3847, 257, 2316, 51844, 51844], "temperature": 0.0, "avg_logprob": -0.11247192961829049, "compression_ratio": 1.9316239316239316, "no_speech_prob": 3.3183980121975765e-05}, {"id": 527, "seek": 278864, "start": 2788.64, "end": 2796.48, "text": " to predict the second half of that video. Why would that be good? Why would that be", "tokens": [50364, 281, 6069, 264, 1150, 1922, 295, 300, 960, 13, 1545, 576, 300, 312, 665, 30, 1545, 576, 300, 312, 50756, 50756, 665, 294, 264, 4319, 295, 2539, 4122, 337, 5201, 3652, 337, 1365, 30, 759, 286, 3847, 2059, 51314, 51314, 281, 6069, 437, 264, 1002, 307, 516, 281, 574, 411, 11, 437, 452, 1910, 295, 341, 1808, 486, 574, 51512, 51512], "temperature": 0.0, "avg_logprob": -0.0932061028858972, "compression_ratio": 1.5987654320987654, "no_speech_prob": 3.645664401119575e-05}, {"id": 528, "seek": 278864, "start": 2796.48, "end": 2807.64, "text": " good in the context of learning features for vision systems for example? If I train myself", "tokens": [50364, 281, 6069, 264, 1150, 1922, 295, 300, 960, 13, 1545, 576, 300, 312, 665, 30, 1545, 576, 300, 312, 50756, 50756, 665, 294, 264, 4319, 295, 2539, 4122, 337, 5201, 3652, 337, 1365, 30, 759, 286, 3847, 2059, 51314, 51314, 281, 6069, 437, 264, 1002, 307, 516, 281, 574, 411, 11, 437, 452, 1910, 295, 341, 1808, 486, 574, 51512, 51512], "temperature": 0.0, "avg_logprob": -0.0932061028858972, "compression_ratio": 1.5987654320987654, "no_speech_prob": 3.645664401119575e-05}, {"id": 529, "seek": 278864, "start": 2807.64, "end": 2811.6, "text": " to predict what the world is going to look like, what my view of this room will look", "tokens": [50364, 281, 6069, 264, 1150, 1922, 295, 300, 960, 13, 1545, 576, 300, 312, 665, 30, 1545, 576, 300, 312, 50756, 50756, 665, 294, 264, 4319, 295, 2539, 4122, 337, 5201, 3652, 337, 1365, 30, 759, 286, 3847, 2059, 51314, 51314, 281, 6069, 437, 264, 1002, 307, 516, 281, 574, 411, 11, 437, 452, 1910, 295, 341, 1808, 486, 574, 51512, 51512], "temperature": 0.0, "avg_logprob": -0.0932061028858972, "compression_ratio": 1.5987654320987654, "no_speech_prob": 3.645664401119575e-05}, {"id": 530, "seek": 281160, "start": 2811.6, "end": 2819.52, "text": " like if I shift my head a little bit to the left, the best explanation for how the view", "tokens": [50364, 411, 498, 286, 5513, 452, 1378, 257, 707, 857, 281, 264, 1411, 11, 264, 1151, 10835, 337, 577, 264, 1910, 50760, 50760, 2962, 307, 300, 633, 935, 294, 1901, 575, 257, 7161, 11, 575, 257, 4560, 490, 452, 2575, 13, 1033, 30, 51338, 51338, 759, 286, 13596, 6063, 300, 633, 935, 575, 257, 4560, 490, 452, 2575, 550, 286, 393, 588, 2935, 51552, 51552, 2903, 577, 264, 1002, 2962, 562, 286, 1286, 570, 721, 366, 4966, 11, 733, 295, 362, 544, 51768, 51768], "temperature": 0.0, "avg_logprob": -0.1334351707907284, "compression_ratio": 1.7128712871287128, "no_speech_prob": 9.817298632697202e-06}, {"id": 531, "seek": 281160, "start": 2819.52, "end": 2831.08, "text": " changes is that every point in space has a depth, has a distance from my eyes. Okay?", "tokens": [50364, 411, 498, 286, 5513, 452, 1378, 257, 707, 857, 281, 264, 1411, 11, 264, 1151, 10835, 337, 577, 264, 1910, 50760, 50760, 2962, 307, 300, 633, 935, 294, 1901, 575, 257, 7161, 11, 575, 257, 4560, 490, 452, 2575, 13, 1033, 30, 51338, 51338, 759, 286, 13596, 6063, 300, 633, 935, 575, 257, 4560, 490, 452, 2575, 550, 286, 393, 588, 2935, 51552, 51552, 2903, 577, 264, 1002, 2962, 562, 286, 1286, 570, 721, 366, 4966, 11, 733, 295, 362, 544, 51768, 51768], "temperature": 0.0, "avg_logprob": -0.1334351707907284, "compression_ratio": 1.7128712871287128, "no_speech_prob": 9.817298632697202e-06}, {"id": 532, "seek": 281160, "start": 2831.08, "end": 2835.36, "text": " If I infer somehow that every point has a distance from my eyes then I can very simply", "tokens": [50364, 411, 498, 286, 5513, 452, 1378, 257, 707, 857, 281, 264, 1411, 11, 264, 1151, 10835, 337, 577, 264, 1910, 50760, 50760, 2962, 307, 300, 633, 935, 294, 1901, 575, 257, 7161, 11, 575, 257, 4560, 490, 452, 2575, 13, 1033, 30, 51338, 51338, 759, 286, 13596, 6063, 300, 633, 935, 575, 257, 4560, 490, 452, 2575, 550, 286, 393, 588, 2935, 51552, 51552, 2903, 577, 264, 1002, 2962, 562, 286, 1286, 570, 721, 366, 4966, 11, 733, 295, 362, 544, 51768, 51768], "temperature": 0.0, "avg_logprob": -0.1334351707907284, "compression_ratio": 1.7128712871287128, "no_speech_prob": 9.817298632697202e-06}, {"id": 533, "seek": 281160, "start": 2835.36, "end": 2839.68, "text": " explain how the world changes when I move because things are closer, kind of have more", "tokens": [50364, 411, 498, 286, 5513, 452, 1378, 257, 707, 857, 281, 264, 1411, 11, 264, 1151, 10835, 337, 577, 264, 1910, 50760, 50760, 2962, 307, 300, 633, 935, 294, 1901, 575, 257, 7161, 11, 575, 257, 4560, 490, 452, 2575, 13, 1033, 30, 51338, 51338, 759, 286, 13596, 6063, 300, 633, 935, 575, 257, 4560, 490, 452, 2575, 550, 286, 393, 588, 2935, 51552, 51552, 2903, 577, 264, 1002, 2962, 562, 286, 1286, 570, 721, 366, 4966, 11, 733, 295, 362, 544, 51768, 51768], "temperature": 0.0, "avg_logprob": -0.1334351707907284, "compression_ratio": 1.7128712871287128, "no_speech_prob": 9.817298632697202e-06}, {"id": 534, "seek": 283968, "start": 2839.68, "end": 2843.72, "text": " parallax motion than things that are far and you get this sort of you know perspective", "tokens": [50364, 8069, 2797, 5394, 813, 721, 300, 366, 1400, 293, 291, 483, 341, 1333, 295, 291, 458, 4585, 50566, 50566, 28426, 13, 400, 370, 456, 307, 341, 1558, 6063, 300, 498, 286, 3847, 257, 1185, 281, 6069, 437, 309, 311, 51248, 51248, 516, 281, 574, 411, 498, 286, 1286, 257, 2799, 11, 264, 1185, 26947, 356, 486, 1190, 466, 7161, 13, 509, 51480, 51480, 486, 406, 362, 281, 312, 3097, 309, 281, 6069, 7161, 294, 257, 46533, 6700, 13, 467, 486, 362, 51785, 51785], "temperature": 0.0, "avg_logprob": -0.16753155203426587, "compression_ratio": 1.6296296296296295, "no_speech_prob": 1.722916931612417e-05}, {"id": 535, "seek": 283968, "start": 2843.72, "end": 2857.3599999999997, "text": " distortion. And so there is this idea somehow that if I train a system to predict what it's", "tokens": [50364, 8069, 2797, 5394, 813, 721, 300, 366, 1400, 293, 291, 483, 341, 1333, 295, 291, 458, 4585, 50566, 50566, 28426, 13, 400, 370, 456, 307, 341, 1558, 6063, 300, 498, 286, 3847, 257, 1185, 281, 6069, 437, 309, 311, 51248, 51248, 516, 281, 574, 411, 498, 286, 1286, 257, 2799, 11, 264, 1185, 26947, 356, 486, 1190, 466, 7161, 13, 509, 51480, 51480, 486, 406, 362, 281, 312, 3097, 309, 281, 6069, 7161, 294, 257, 46533, 6700, 13, 467, 486, 362, 51785, 51785], "temperature": 0.0, "avg_logprob": -0.16753155203426587, "compression_ratio": 1.6296296296296295, "no_speech_prob": 1.722916931612417e-05}, {"id": 536, "seek": 283968, "start": 2857.3599999999997, "end": 2862.0, "text": " going to look like if I move a camera, the system implicitly will run about depth. You", "tokens": [50364, 8069, 2797, 5394, 813, 721, 300, 366, 1400, 293, 291, 483, 341, 1333, 295, 291, 458, 4585, 50566, 50566, 28426, 13, 400, 370, 456, 307, 341, 1558, 6063, 300, 498, 286, 3847, 257, 1185, 281, 6069, 437, 309, 311, 51248, 51248, 516, 281, 574, 411, 498, 286, 1286, 257, 2799, 11, 264, 1185, 26947, 356, 486, 1190, 466, 7161, 13, 509, 51480, 51480, 486, 406, 362, 281, 312, 3097, 309, 281, 6069, 7161, 294, 257, 46533, 6700, 13, 467, 486, 362, 51785, 51785], "temperature": 0.0, "avg_logprob": -0.16753155203426587, "compression_ratio": 1.6296296296296295, "no_speech_prob": 1.722916931612417e-05}, {"id": 537, "seek": 283968, "start": 2862.0, "end": 2868.1, "text": " will not have to be training it to predict depth in a supervised fashion. It will have", "tokens": [50364, 8069, 2797, 5394, 813, 721, 300, 366, 1400, 293, 291, 483, 341, 1333, 295, 291, 458, 4585, 50566, 50566, 28426, 13, 400, 370, 456, 307, 341, 1558, 6063, 300, 498, 286, 3847, 257, 1185, 281, 6069, 437, 309, 311, 51248, 51248, 516, 281, 574, 411, 498, 286, 1286, 257, 2799, 11, 264, 1185, 26947, 356, 486, 1190, 466, 7161, 13, 509, 51480, 51480, 486, 406, 362, 281, 312, 3097, 309, 281, 6069, 7161, 294, 257, 46533, 6700, 13, 467, 486, 362, 51785, 51785], "temperature": 0.0, "avg_logprob": -0.16753155203426587, "compression_ratio": 1.6296296296296295, "no_speech_prob": 1.722916931612417e-05}, {"id": 538, "seek": 286810, "start": 2868.1, "end": 2873.64, "text": " to internally kind of discover that there is such a thing as depth if it wants to do", "tokens": [50364, 281, 19501, 733, 295, 4411, 300, 456, 307, 1270, 257, 551, 382, 7161, 498, 309, 2738, 281, 360, 50641, 50641, 257, 665, 1691, 412, 300, 17630, 13, 3013, 1355, 291, 500, 380, 362, 281, 1152, 42689, 666, 264, 1185, 51039, 51039, 300, 264, 1002, 307, 1045, 18795, 13, 467, 311, 516, 281, 1466, 341, 294, 2077, 538, 445, 32884, 51253, 51253, 577, 702, 1910, 295, 264, 1002, 2962, 562, 291, 1286, 264, 2799, 13, 823, 1564, 264, 1185, 575, 8932, 51519, 51519], "temperature": 0.0, "avg_logprob": -0.14280993597848074, "compression_ratio": 1.6238532110091743, "no_speech_prob": 1.7229453078471124e-05}, {"id": 539, "seek": 286810, "start": 2873.64, "end": 2881.6, "text": " a good job at that prediction. Which means you don't have to hardwire into the system", "tokens": [50364, 281, 19501, 733, 295, 4411, 300, 456, 307, 1270, 257, 551, 382, 7161, 498, 309, 2738, 281, 360, 50641, 50641, 257, 665, 1691, 412, 300, 17630, 13, 3013, 1355, 291, 500, 380, 362, 281, 1152, 42689, 666, 264, 1185, 51039, 51039, 300, 264, 1002, 307, 1045, 18795, 13, 467, 311, 516, 281, 1466, 341, 294, 2077, 538, 445, 32884, 51253, 51253, 577, 702, 1910, 295, 264, 1002, 2962, 562, 291, 1286, 264, 2799, 13, 823, 1564, 264, 1185, 575, 8932, 51519, 51519], "temperature": 0.0, "avg_logprob": -0.14280993597848074, "compression_ratio": 1.6238532110091743, "no_speech_prob": 1.7229453078471124e-05}, {"id": 540, "seek": 286810, "start": 2881.6, "end": 2885.88, "text": " that the world is three dimensional. It's going to learn this in minutes by just predicting", "tokens": [50364, 281, 19501, 733, 295, 4411, 300, 456, 307, 1270, 257, 551, 382, 7161, 498, 309, 2738, 281, 360, 50641, 50641, 257, 665, 1691, 412, 300, 17630, 13, 3013, 1355, 291, 500, 380, 362, 281, 1152, 42689, 666, 264, 1185, 51039, 51039, 300, 264, 1002, 307, 1045, 18795, 13, 467, 311, 516, 281, 1466, 341, 294, 2077, 538, 445, 32884, 51253, 51253, 577, 702, 1910, 295, 264, 1002, 2962, 562, 291, 1286, 264, 2799, 13, 823, 1564, 264, 1185, 575, 8932, 51519, 51519], "temperature": 0.0, "avg_logprob": -0.14280993597848074, "compression_ratio": 1.6238532110091743, "no_speech_prob": 1.7229453078471124e-05}, {"id": 541, "seek": 286810, "start": 2885.88, "end": 2891.2, "text": " how his view of the world changes when you move the camera. Now once the system has figured", "tokens": [50364, 281, 19501, 733, 295, 4411, 300, 456, 307, 1270, 257, 551, 382, 7161, 498, 309, 2738, 281, 360, 50641, 50641, 257, 665, 1691, 412, 300, 17630, 13, 3013, 1355, 291, 500, 380, 362, 281, 1152, 42689, 666, 264, 1185, 51039, 51039, 300, 264, 1002, 307, 1045, 18795, 13, 467, 311, 516, 281, 1466, 341, 294, 2077, 538, 445, 32884, 51253, 51253, 577, 702, 1910, 295, 264, 1002, 2962, 562, 291, 1286, 264, 2799, 13, 823, 1564, 264, 1185, 575, 8932, 51519, 51519], "temperature": 0.0, "avg_logprob": -0.14280993597848074, "compression_ratio": 1.6238532110091743, "no_speech_prob": 1.7229453078471124e-05}, {"id": 542, "seek": 289120, "start": 2891.2, "end": 2899.7999999999997, "text": " out that every point has a depth in the world, then the notion that there are distinct objects", "tokens": [50364, 484, 300, 633, 935, 575, 257, 7161, 294, 264, 1002, 11, 550, 264, 10710, 300, 456, 366, 10644, 6565, 50794, 50794, 300, 366, 294, 1868, 295, 264, 3678, 4258, 16795, 493, 570, 6565, 366, 721, 300, 1286, 51112, 51112, 7614, 490, 721, 300, 366, 2261, 13, 1033, 30, 821, 311, 1071, 551, 300, 16795, 493, 4258, 51484, 51484], "temperature": 0.0, "avg_logprob": -0.1325833559036255, "compression_ratio": 1.6432748538011697, "no_speech_prob": 7.765978807583451e-06}, {"id": 543, "seek": 289120, "start": 2899.7999999999997, "end": 2906.16, "text": " that are in front of the background immediately pops up because objects are things that move", "tokens": [50364, 484, 300, 633, 935, 575, 257, 7161, 294, 264, 1002, 11, 550, 264, 10710, 300, 456, 366, 10644, 6565, 50794, 50794, 300, 366, 294, 1868, 295, 264, 3678, 4258, 16795, 493, 570, 6565, 366, 721, 300, 1286, 51112, 51112, 7614, 490, 721, 300, 366, 2261, 13, 1033, 30, 821, 311, 1071, 551, 300, 16795, 493, 4258, 51484, 51484], "temperature": 0.0, "avg_logprob": -0.1325833559036255, "compression_ratio": 1.6432748538011697, "no_speech_prob": 7.765978807583451e-06}, {"id": 544, "seek": 289120, "start": 2906.16, "end": 2913.6, "text": " differently from things that are behind. Okay? There's another thing that pops up immediately", "tokens": [50364, 484, 300, 633, 935, 575, 257, 7161, 294, 264, 1002, 11, 550, 264, 10710, 300, 456, 366, 10644, 6565, 50794, 50794, 300, 366, 294, 1868, 295, 264, 3678, 4258, 16795, 493, 570, 6565, 366, 721, 300, 1286, 51112, 51112, 7614, 490, 721, 300, 366, 2261, 13, 1033, 30, 821, 311, 1071, 551, 300, 16795, 493, 4258, 51484, 51484], "temperature": 0.0, "avg_logprob": -0.1325833559036255, "compression_ratio": 1.6432748538011697, "no_speech_prob": 7.765978807583451e-06}, {"id": 545, "seek": 291360, "start": 2913.6, "end": 2921.6, "text": " which is the fact that objects that are not visible hidden by another one are still there.", "tokens": [50364, 597, 307, 264, 1186, 300, 6565, 300, 366, 406, 8974, 7633, 538, 1071, 472, 366, 920, 456, 13, 50764, 50764, 1033, 30, 467, 311, 445, 300, 291, 500, 380, 536, 552, 570, 436, 366, 2261, 13, 583, 341, 3410, 300, 6565, 51118, 51118, 920, 2514, 562, 291, 500, 380, 536, 552, 307, 406, 2584, 6322, 13, 509, 458, 10917, 1466, 51380, 51380, 341, 534, 534, 2440, 457, 309, 311, 406, 1850, 2293, 562, 570, 321, 393, 380, 3481, 300, 51612, 51612], "temperature": 0.0, "avg_logprob": -0.17190420771219644, "compression_ratio": 1.676056338028169, "no_speech_prob": 1.4060822650208138e-05}, {"id": 546, "seek": 291360, "start": 2921.6, "end": 2928.68, "text": " Okay? It's just that you don't see them because they are behind. But this concept that objects", "tokens": [50364, 597, 307, 264, 1186, 300, 6565, 300, 366, 406, 8974, 7633, 538, 1071, 472, 366, 920, 456, 13, 50764, 50764, 1033, 30, 467, 311, 445, 300, 291, 500, 380, 536, 552, 570, 436, 366, 2261, 13, 583, 341, 3410, 300, 6565, 51118, 51118, 920, 2514, 562, 291, 500, 380, 536, 552, 307, 406, 2584, 6322, 13, 509, 458, 10917, 1466, 51380, 51380, 341, 534, 534, 2440, 457, 309, 311, 406, 1850, 2293, 562, 570, 321, 393, 380, 3481, 300, 51612, 51612], "temperature": 0.0, "avg_logprob": -0.17190420771219644, "compression_ratio": 1.676056338028169, "no_speech_prob": 1.4060822650208138e-05}, {"id": 547, "seek": 291360, "start": 2928.68, "end": 2933.92, "text": " still exist when you don't see them is not completely obvious. You know babies learn", "tokens": [50364, 597, 307, 264, 1186, 300, 6565, 300, 366, 406, 8974, 7633, 538, 1071, 472, 366, 920, 456, 13, 50764, 50764, 1033, 30, 467, 311, 445, 300, 291, 500, 380, 536, 552, 570, 436, 366, 2261, 13, 583, 341, 3410, 300, 6565, 51118, 51118, 920, 2514, 562, 291, 500, 380, 536, 552, 307, 406, 2584, 6322, 13, 509, 458, 10917, 1466, 51380, 51380, 341, 534, 534, 2440, 457, 309, 311, 406, 1850, 2293, 562, 570, 321, 393, 380, 3481, 300, 51612, 51612], "temperature": 0.0, "avg_logprob": -0.17190420771219644, "compression_ratio": 1.676056338028169, "no_speech_prob": 1.4060822650208138e-05}, {"id": 548, "seek": 291360, "start": 2933.92, "end": 2938.56, "text": " this really really early but it's not clear exactly when because we can't measure that", "tokens": [50364, 597, 307, 264, 1186, 300, 6565, 300, 366, 406, 8974, 7633, 538, 1071, 472, 366, 920, 456, 13, 50764, 50764, 1033, 30, 467, 311, 445, 300, 291, 500, 380, 536, 552, 570, 436, 366, 2261, 13, 583, 341, 3410, 300, 6565, 51118, 51118, 920, 2514, 562, 291, 500, 380, 536, 552, 307, 406, 2584, 6322, 13, 509, 458, 10917, 1466, 51380, 51380, 341, 534, 534, 2440, 457, 309, 311, 406, 1850, 2293, 562, 570, 321, 393, 380, 3481, 300, 51612, 51612], "temperature": 0.0, "avg_logprob": -0.17190420771219644, "compression_ratio": 1.676056338028169, "no_speech_prob": 1.4060822650208138e-05}, {"id": 549, "seek": 293856, "start": 2938.56, "end": 2948.56, "text": " when they are very little. But they probably learn this very quick. Once you have identified", "tokens": [50364, 562, 436, 366, 588, 707, 13, 583, 436, 1391, 1466, 341, 588, 1702, 13, 3443, 291, 362, 9234, 50864, 50864, 341, 3410, 295, 6565, 4317, 291, 603, 2573, 484, 300, 257, 688, 295, 6565, 294, 264, 1002, 500, 380, 51208, 51208, 1286, 47632, 13, 1033, 30, 407, 456, 366, 33113, 2905, 6565, 13, 400, 550, 456, 366, 6565, 6104, 51474, 51474, 18257, 2083, 366, 406, 7696, 27737, 293, 729, 366, 36439, 6565, 13, 1610, 661, 3467, 51822, 51822], "temperature": 0.0, "avg_logprob": -0.11581501960754395, "compression_ratio": 1.6759259259259258, "no_speech_prob": 1.5685640391893685e-05}, {"id": 550, "seek": 293856, "start": 2948.56, "end": 2955.44, "text": " this concept of objects perhaps you'll figure out that a lot of objects in the world don't", "tokens": [50364, 562, 436, 366, 588, 707, 13, 583, 436, 1391, 1466, 341, 588, 1702, 13, 3443, 291, 362, 9234, 50864, 50864, 341, 3410, 295, 6565, 4317, 291, 603, 2573, 484, 300, 257, 688, 295, 6565, 294, 264, 1002, 500, 380, 51208, 51208, 1286, 47632, 13, 1033, 30, 407, 456, 366, 33113, 2905, 6565, 13, 400, 550, 456, 366, 6565, 6104, 51474, 51474, 18257, 2083, 366, 406, 7696, 27737, 293, 729, 366, 36439, 6565, 13, 1610, 661, 3467, 51822, 51822], "temperature": 0.0, "avg_logprob": -0.11581501960754395, "compression_ratio": 1.6759259259259258, "no_speech_prob": 1.5685640391893685e-05}, {"id": 551, "seek": 293856, "start": 2955.44, "end": 2960.7599999999998, "text": " move spontaneously. Okay? So there are inanimate objects. And then there are objects whose", "tokens": [50364, 562, 436, 366, 588, 707, 13, 583, 436, 1391, 1466, 341, 588, 1702, 13, 3443, 291, 362, 9234, 50864, 50864, 341, 3410, 295, 6565, 4317, 291, 603, 2573, 484, 300, 257, 688, 295, 6565, 294, 264, 1002, 500, 380, 51208, 51208, 1286, 47632, 13, 1033, 30, 407, 456, 366, 33113, 2905, 6565, 13, 400, 550, 456, 366, 6565, 6104, 51474, 51474, 18257, 2083, 366, 406, 7696, 27737, 293, 729, 366, 36439, 6565, 13, 1610, 661, 3467, 51822, 51822], "temperature": 0.0, "avg_logprob": -0.11581501960754395, "compression_ratio": 1.6759259259259258, "no_speech_prob": 1.5685640391893685e-05}, {"id": 552, "seek": 293856, "start": 2960.7599999999998, "end": 2967.72, "text": " trajectories are not entirely predictable and those are animate objects. Or other types", "tokens": [50364, 562, 436, 366, 588, 707, 13, 583, 436, 1391, 1466, 341, 588, 1702, 13, 3443, 291, 362, 9234, 50864, 50864, 341, 3410, 295, 6565, 4317, 291, 603, 2573, 484, 300, 257, 688, 295, 6565, 294, 264, 1002, 500, 380, 51208, 51208, 1286, 47632, 13, 1033, 30, 407, 456, 366, 33113, 2905, 6565, 13, 400, 550, 456, 366, 6565, 6104, 51474, 51474, 18257, 2083, 366, 406, 7696, 27737, 293, 729, 366, 36439, 6565, 13, 1610, 661, 3467, 51822, 51822], "temperature": 0.0, "avg_logprob": -0.11581501960754395, "compression_ratio": 1.6759259259259258, "no_speech_prob": 1.5685640391893685e-05}, {"id": 553, "seek": 296772, "start": 2967.72, "end": 2975.16, "text": " of objects that move in not entirely predictable ways like the waves on water but are not animate", "tokens": [50364, 295, 6565, 300, 1286, 294, 406, 7696, 27737, 2098, 411, 264, 9417, 322, 1281, 457, 366, 406, 36439, 50736, 50736, 4725, 420, 411, 264, 5510, 295, 257, 4230, 13, 400, 550, 934, 257, 1339, 291, 611, 4325, 300, 51228, 51228, 6565, 300, 362, 27737, 18257, 2083, 5101, 500, 380, 15706, 294, 264, 1988, 13, 759, 436, 51486, 51486, 366, 406, 8104, 436, 2100, 13, 1033, 30, 407, 291, 393, 722, 2539, 466, 512, 21769, 10649, 11, 51760, 51760], "temperature": 0.0, "avg_logprob": -0.1710807204246521, "compression_ratio": 1.6216216216216217, "no_speech_prob": 7.645727237104438e-06}, {"id": 554, "seek": 296772, "start": 2975.16, "end": 2985.0, "text": " necessarily or like the leaves of a tree. And then after a while you also realize that", "tokens": [50364, 295, 6565, 300, 1286, 294, 406, 7696, 27737, 2098, 411, 264, 9417, 322, 1281, 457, 366, 406, 36439, 50736, 50736, 4725, 420, 411, 264, 5510, 295, 257, 4230, 13, 400, 550, 934, 257, 1339, 291, 611, 4325, 300, 51228, 51228, 6565, 300, 362, 27737, 18257, 2083, 5101, 500, 380, 15706, 294, 264, 1988, 13, 759, 436, 51486, 51486, 366, 406, 8104, 436, 2100, 13, 1033, 30, 407, 291, 393, 722, 2539, 466, 512, 21769, 10649, 11, 51760, 51760], "temperature": 0.0, "avg_logprob": -0.1710807204246521, "compression_ratio": 1.6216216216216217, "no_speech_prob": 7.645727237104438e-06}, {"id": 555, "seek": 296772, "start": 2985.0, "end": 2990.16, "text": " objects that have predictable trajectories generally don't float in the air. If they", "tokens": [50364, 295, 6565, 300, 1286, 294, 406, 7696, 27737, 2098, 411, 264, 9417, 322, 1281, 457, 366, 406, 36439, 50736, 50736, 4725, 420, 411, 264, 5510, 295, 257, 4230, 13, 400, 550, 934, 257, 1339, 291, 611, 4325, 300, 51228, 51228, 6565, 300, 362, 27737, 18257, 2083, 5101, 500, 380, 15706, 294, 264, 1988, 13, 759, 436, 51486, 51486, 366, 406, 8104, 436, 2100, 13, 1033, 30, 407, 291, 393, 722, 2539, 466, 512, 21769, 10649, 11, 51760, 51760], "temperature": 0.0, "avg_logprob": -0.1710807204246521, "compression_ratio": 1.6216216216216217, "no_speech_prob": 7.645727237104438e-06}, {"id": 556, "seek": 296772, "start": 2990.16, "end": 2995.64, "text": " are not supported they fall. Okay? So you can start learning about some intuitive physics,", "tokens": [50364, 295, 6565, 300, 1286, 294, 406, 7696, 27737, 2098, 411, 264, 9417, 322, 1281, 457, 366, 406, 36439, 50736, 50736, 4725, 420, 411, 264, 5510, 295, 257, 4230, 13, 400, 550, 934, 257, 1339, 291, 611, 4325, 300, 51228, 51228, 6565, 300, 362, 27737, 18257, 2083, 5101, 500, 380, 15706, 294, 264, 1988, 13, 759, 436, 51486, 51486, 366, 406, 8104, 436, 2100, 13, 1033, 30, 407, 291, 393, 722, 2539, 466, 512, 21769, 10649, 11, 51760, 51760], "temperature": 0.0, "avg_logprob": -0.1710807204246521, "compression_ratio": 1.6216216216216217, "no_speech_prob": 7.645727237104438e-06}, {"id": 557, "seek": 299564, "start": 2995.64, "end": 3000.8399999999997, "text": " about gravity, about inertia. Babies learn this around the age of nine months. So this", "tokens": [50364, 466, 12110, 11, 466, 37234, 13, 15820, 530, 1466, 341, 926, 264, 3205, 295, 4949, 2493, 13, 407, 341, 50624, 50624, 307, 406, 746, 291, 434, 4232, 365, 13, 509, 733, 295, 1466, 341, 926, 4949, 2493, 13, 509, 382, 257, 50866, 50866, 3186, 291, 1466, 300, 12110, 307, 257, 551, 13, 4546, 300, 291, 500, 380, 458, 13, 407, 264, 12335, 337, 51344, 51344, 2698, 12, 48172, 24420, 2539, 293, 341, 307, 472, 1778, 286, 519, 2698, 12, 48172, 24420, 2539, 307, 534, 51570, 51570], "temperature": 0.0, "avg_logprob": -0.17050053856589578, "compression_ratio": 1.7878787878787878, "no_speech_prob": 2.2111926227808e-05}, {"id": 558, "seek": 299564, "start": 3000.8399999999997, "end": 3005.68, "text": " is not something you're born with. You kind of learn this around nine months. You as a", "tokens": [50364, 466, 12110, 11, 466, 37234, 13, 15820, 530, 1466, 341, 926, 264, 3205, 295, 4949, 2493, 13, 407, 341, 50624, 50624, 307, 406, 746, 291, 434, 4232, 365, 13, 509, 733, 295, 1466, 341, 926, 4949, 2493, 13, 509, 382, 257, 50866, 50866, 3186, 291, 1466, 300, 12110, 307, 257, 551, 13, 4546, 300, 291, 500, 380, 458, 13, 407, 264, 12335, 337, 51344, 51344, 2698, 12, 48172, 24420, 2539, 293, 341, 307, 472, 1778, 286, 519, 2698, 12, 48172, 24420, 2539, 307, 534, 51570, 51570], "temperature": 0.0, "avg_logprob": -0.17050053856589578, "compression_ratio": 1.7878787878787878, "no_speech_prob": 2.2111926227808e-05}, {"id": 559, "seek": 299564, "start": 3005.68, "end": 3015.24, "text": " baby you learn that gravity is a thing. Before that you don't know. So the motivation for", "tokens": [50364, 466, 12110, 11, 466, 37234, 13, 15820, 530, 1466, 341, 926, 264, 3205, 295, 4949, 2493, 13, 407, 341, 50624, 50624, 307, 406, 746, 291, 434, 4232, 365, 13, 509, 733, 295, 1466, 341, 926, 4949, 2493, 13, 509, 382, 257, 50866, 50866, 3186, 291, 1466, 300, 12110, 307, 257, 551, 13, 4546, 300, 291, 500, 380, 458, 13, 407, 264, 12335, 337, 51344, 51344, 2698, 12, 48172, 24420, 2539, 293, 341, 307, 472, 1778, 286, 519, 2698, 12, 48172, 24420, 2539, 307, 534, 51570, 51570], "temperature": 0.0, "avg_logprob": -0.17050053856589578, "compression_ratio": 1.7878787878787878, "no_speech_prob": 2.2111926227808e-05}, {"id": 560, "seek": 299564, "start": 3015.24, "end": 3019.7599999999998, "text": " self-supervised learning and this is one reason I think self-supervised learning is really", "tokens": [50364, 466, 12110, 11, 466, 37234, 13, 15820, 530, 1466, 341, 926, 264, 3205, 295, 4949, 2493, 13, 407, 341, 50624, 50624, 307, 406, 746, 291, 434, 4232, 365, 13, 509, 733, 295, 1466, 341, 926, 4949, 2493, 13, 509, 382, 257, 50866, 50866, 3186, 291, 1466, 300, 12110, 307, 257, 551, 13, 4546, 300, 291, 500, 380, 458, 13, 407, 264, 12335, 337, 51344, 51344, 2698, 12, 48172, 24420, 2539, 293, 341, 307, 472, 1778, 286, 519, 2698, 12, 48172, 24420, 2539, 307, 534, 51570, 51570], "temperature": 0.0, "avg_logprob": -0.17050053856589578, "compression_ratio": 1.7878787878787878, "no_speech_prob": 2.2111926227808e-05}, {"id": 561, "seek": 301976, "start": 3019.76, "end": 3026.0, "text": " the future of machine learning certainly and the future of AI. It's the fact that animals", "tokens": [50364, 264, 2027, 295, 3479, 2539, 3297, 293, 264, 2027, 295, 7318, 13, 467, 311, 264, 1186, 300, 4882, 50676, 50676, 293, 6255, 1643, 281, 1466, 364, 11322, 2372, 295, 3678, 3601, 466, 264, 1002, 445, 50826, 50826, 538, 14816, 538, 1936, 3097, 2969, 281, 6069, 13, 407, 472, 955, 1168, 294, 7318, 11, 294, 51142, 51142, 1186, 264, 1168, 286, 1920, 20638, 589, 322, 307, 577, 360, 321, 360, 341, 30, 1033, 13, 492, 2378, 380, 51464, 51464], "temperature": 0.0, "avg_logprob": -0.14261171817779542, "compression_ratio": 1.5526315789473684, "no_speech_prob": 1.0780588127090596e-05}, {"id": 562, "seek": 301976, "start": 3026.0, "end": 3029.0, "text": " and humans seem to learn an enormous amount of background knowledge about the world just", "tokens": [50364, 264, 2027, 295, 3479, 2539, 3297, 293, 264, 2027, 295, 7318, 13, 467, 311, 264, 1186, 300, 4882, 50676, 50676, 293, 6255, 1643, 281, 1466, 364, 11322, 2372, 295, 3678, 3601, 466, 264, 1002, 445, 50826, 50826, 538, 14816, 538, 1936, 3097, 2969, 281, 6069, 13, 407, 472, 955, 1168, 294, 7318, 11, 294, 51142, 51142, 1186, 264, 1168, 286, 1920, 20638, 589, 322, 307, 577, 360, 321, 360, 341, 30, 1033, 13, 492, 2378, 380, 51464, 51464], "temperature": 0.0, "avg_logprob": -0.14261171817779542, "compression_ratio": 1.5526315789473684, "no_speech_prob": 1.0780588127090596e-05}, {"id": 563, "seek": 301976, "start": 3029.0, "end": 3035.32, "text": " by observation by basically training themselves to predict. So one big question in AI, in", "tokens": [50364, 264, 2027, 295, 3479, 2539, 3297, 293, 264, 2027, 295, 7318, 13, 467, 311, 264, 1186, 300, 4882, 50676, 50676, 293, 6255, 1643, 281, 1466, 364, 11322, 2372, 295, 3678, 3601, 466, 264, 1002, 445, 50826, 50826, 538, 14816, 538, 1936, 3097, 2969, 281, 6069, 13, 407, 472, 955, 1168, 294, 7318, 11, 294, 51142, 51142, 1186, 264, 1168, 286, 1920, 20638, 589, 322, 307, 577, 360, 321, 360, 341, 30, 1033, 13, 492, 2378, 380, 51464, 51464], "temperature": 0.0, "avg_logprob": -0.14261171817779542, "compression_ratio": 1.5526315789473684, "no_speech_prob": 1.0780588127090596e-05}, {"id": 564, "seek": 301976, "start": 3035.32, "end": 3041.76, "text": " fact the question I almost exclusively work on is how do we do this? Okay. We haven't", "tokens": [50364, 264, 2027, 295, 3479, 2539, 3297, 293, 264, 2027, 295, 7318, 13, 467, 311, 264, 1186, 300, 4882, 50676, 50676, 293, 6255, 1643, 281, 1466, 364, 11322, 2372, 295, 3678, 3601, 466, 264, 1002, 445, 50826, 50826, 538, 14816, 538, 1936, 3097, 2969, 281, 6069, 13, 407, 472, 955, 1168, 294, 7318, 11, 294, 51142, 51142, 1186, 264, 1168, 286, 1920, 20638, 589, 322, 307, 577, 360, 321, 360, 341, 30, 1033, 13, 492, 2378, 380, 51464, 51464], "temperature": 0.0, "avg_logprob": -0.14261171817779542, "compression_ratio": 1.5526315789473684, "no_speech_prob": 1.0780588127090596e-05}, {"id": 565, "seek": 304176, "start": 3041.76, "end": 3051.76, "text": " found a complete answer yet. Right. So I give you a piece of data, let's say a video, and", "tokens": [50364, 1352, 257, 3566, 1867, 1939, 13, 1779, 13, 407, 286, 976, 291, 257, 2522, 295, 1412, 11, 718, 311, 584, 257, 960, 11, 293, 50864, 50864, 264, 3479, 307, 516, 281, 11865, 456, 307, 257, 2522, 295, 300, 1412, 300, 309, 1177, 380, 536, 293, 51104, 51104, 550, 1071, 2522, 300, 309, 8194, 293, 309, 311, 516, 281, 853, 281, 6069, 264, 2522, 300, 309, 1177, 380, 51268, 51268, 536, 490, 264, 2522, 300, 309, 8194, 13, 1033, 30, 407, 6069, 2027, 12083, 294, 257, 960, 11, 6069, 51602, 51602], "temperature": 0.0, "avg_logprob": -0.14418601989746094, "compression_ratio": 1.8518518518518519, "no_speech_prob": 2.4293636670336127e-05}, {"id": 566, "seek": 304176, "start": 3051.76, "end": 3056.5600000000004, "text": " the machine is going to pretend there is a piece of that data that it doesn't see and", "tokens": [50364, 1352, 257, 3566, 1867, 1939, 13, 1779, 13, 407, 286, 976, 291, 257, 2522, 295, 1412, 11, 718, 311, 584, 257, 960, 11, 293, 50864, 50864, 264, 3479, 307, 516, 281, 11865, 456, 307, 257, 2522, 295, 300, 1412, 300, 309, 1177, 380, 536, 293, 51104, 51104, 550, 1071, 2522, 300, 309, 8194, 293, 309, 311, 516, 281, 853, 281, 6069, 264, 2522, 300, 309, 1177, 380, 51268, 51268, 536, 490, 264, 2522, 300, 309, 8194, 13, 1033, 30, 407, 6069, 2027, 12083, 294, 257, 960, 11, 6069, 51602, 51602], "temperature": 0.0, "avg_logprob": -0.14418601989746094, "compression_ratio": 1.8518518518518519, "no_speech_prob": 2.4293636670336127e-05}, {"id": 567, "seek": 304176, "start": 3056.5600000000004, "end": 3059.84, "text": " then another piece that it sees and it's going to try to predict the piece that it doesn't", "tokens": [50364, 1352, 257, 3566, 1867, 1939, 13, 1779, 13, 407, 286, 976, 291, 257, 2522, 295, 1412, 11, 718, 311, 584, 257, 960, 11, 293, 50864, 50864, 264, 3479, 307, 516, 281, 11865, 456, 307, 257, 2522, 295, 300, 1412, 300, 309, 1177, 380, 536, 293, 51104, 51104, 550, 1071, 2522, 300, 309, 8194, 293, 309, 311, 516, 281, 853, 281, 6069, 264, 2522, 300, 309, 1177, 380, 51268, 51268, 536, 490, 264, 2522, 300, 309, 8194, 13, 1033, 30, 407, 6069, 2027, 12083, 294, 257, 960, 11, 6069, 51602, 51602], "temperature": 0.0, "avg_logprob": -0.14418601989746094, "compression_ratio": 1.8518518518518519, "no_speech_prob": 2.4293636670336127e-05}, {"id": 568, "seek": 304176, "start": 3059.84, "end": 3066.5200000000004, "text": " see from the piece that it sees. Okay? So predict future frames in a video, predict", "tokens": [50364, 1352, 257, 3566, 1867, 1939, 13, 1779, 13, 407, 286, 976, 291, 257, 2522, 295, 1412, 11, 718, 311, 584, 257, 960, 11, 293, 50864, 50864, 264, 3479, 307, 516, 281, 11865, 456, 307, 257, 2522, 295, 300, 1412, 300, 309, 1177, 380, 536, 293, 51104, 51104, 550, 1071, 2522, 300, 309, 8194, 293, 309, 311, 516, 281, 853, 281, 6069, 264, 2522, 300, 309, 1177, 380, 51268, 51268, 536, 490, 264, 2522, 300, 309, 8194, 13, 1033, 30, 407, 6069, 2027, 12083, 294, 257, 960, 11, 6069, 51602, 51602], "temperature": 0.0, "avg_logprob": -0.14418601989746094, "compression_ratio": 1.8518518518518519, "no_speech_prob": 2.4293636670336127e-05}, {"id": 569, "seek": 306652, "start": 3066.52, "end": 3073.12, "text": " missing words in a sentence, so I give you a sentence, I block some of the words and", "tokens": [50364, 5361, 2283, 294, 257, 8174, 11, 370, 286, 976, 291, 257, 8174, 11, 286, 3461, 512, 295, 264, 2283, 293, 50694, 50694, 264, 1185, 16329, 2564, 281, 6069, 264, 2283, 300, 366, 5361, 13, 1610, 286, 855, 291, 257, 3840, 295, 50952, 50952, 960, 293, 286, 3461, 257, 2522, 295, 264, 12083, 420, 512, 295, 264, 12083, 11, 2522, 295, 264, 3256, 337, 51214, 51214, 512, 295, 264, 12083, 13, 509, 458, 11, 6069, 264, 1411, 1922, 490, 264, 558, 1922, 13, 509, 458, 11, 558, 51452, 51452, 586, 291, 787, 536, 452, 558, 1252, 457, 754, 498, 291, 632, 1128, 1612, 452, 1411, 1252, 291, 727, 51598, 51598, 544, 420, 1570, 6069, 437, 286, 574, 411, 490, 264, 661, 1252, 13, 4534, 561, 366, 544, 420, 1570, 51778, 51778], "temperature": 0.0, "avg_logprob": -0.1899301644527551, "compression_ratio": 2.0193798449612403, "no_speech_prob": 4.68194302811753e-05}, {"id": 570, "seek": 306652, "start": 3073.12, "end": 3078.28, "text": " the system trains itself to predict the words that are missing. Or I show you a bunch of", "tokens": [50364, 5361, 2283, 294, 257, 8174, 11, 370, 286, 976, 291, 257, 8174, 11, 286, 3461, 512, 295, 264, 2283, 293, 50694, 50694, 264, 1185, 16329, 2564, 281, 6069, 264, 2283, 300, 366, 5361, 13, 1610, 286, 855, 291, 257, 3840, 295, 50952, 50952, 960, 293, 286, 3461, 257, 2522, 295, 264, 12083, 420, 512, 295, 264, 12083, 11, 2522, 295, 264, 3256, 337, 51214, 51214, 512, 295, 264, 12083, 13, 509, 458, 11, 6069, 264, 1411, 1922, 490, 264, 558, 1922, 13, 509, 458, 11, 558, 51452, 51452, 586, 291, 787, 536, 452, 558, 1252, 457, 754, 498, 291, 632, 1128, 1612, 452, 1411, 1252, 291, 727, 51598, 51598, 544, 420, 1570, 6069, 437, 286, 574, 411, 490, 264, 661, 1252, 13, 4534, 561, 366, 544, 420, 1570, 51778, 51778], "temperature": 0.0, "avg_logprob": -0.1899301644527551, "compression_ratio": 2.0193798449612403, "no_speech_prob": 4.68194302811753e-05}, {"id": 571, "seek": 306652, "start": 3078.28, "end": 3083.52, "text": " video and I block a piece of the frames or some of the frames, piece of the image for", "tokens": [50364, 5361, 2283, 294, 257, 8174, 11, 370, 286, 976, 291, 257, 8174, 11, 286, 3461, 512, 295, 264, 2283, 293, 50694, 50694, 264, 1185, 16329, 2564, 281, 6069, 264, 2283, 300, 366, 5361, 13, 1610, 286, 855, 291, 257, 3840, 295, 50952, 50952, 960, 293, 286, 3461, 257, 2522, 295, 264, 12083, 420, 512, 295, 264, 12083, 11, 2522, 295, 264, 3256, 337, 51214, 51214, 512, 295, 264, 12083, 13, 509, 458, 11, 6069, 264, 1411, 1922, 490, 264, 558, 1922, 13, 509, 458, 11, 558, 51452, 51452, 586, 291, 787, 536, 452, 558, 1252, 457, 754, 498, 291, 632, 1128, 1612, 452, 1411, 1252, 291, 727, 51598, 51598, 544, 420, 1570, 6069, 437, 286, 574, 411, 490, 264, 661, 1252, 13, 4534, 561, 366, 544, 420, 1570, 51778, 51778], "temperature": 0.0, "avg_logprob": -0.1899301644527551, "compression_ratio": 2.0193798449612403, "no_speech_prob": 4.68194302811753e-05}, {"id": 572, "seek": 306652, "start": 3083.52, "end": 3088.28, "text": " some of the frames. You know, predict the left half from the right half. You know, right", "tokens": [50364, 5361, 2283, 294, 257, 8174, 11, 370, 286, 976, 291, 257, 8174, 11, 286, 3461, 512, 295, 264, 2283, 293, 50694, 50694, 264, 1185, 16329, 2564, 281, 6069, 264, 2283, 300, 366, 5361, 13, 1610, 286, 855, 291, 257, 3840, 295, 50952, 50952, 960, 293, 286, 3461, 257, 2522, 295, 264, 12083, 420, 512, 295, 264, 12083, 11, 2522, 295, 264, 3256, 337, 51214, 51214, 512, 295, 264, 12083, 13, 509, 458, 11, 6069, 264, 1411, 1922, 490, 264, 558, 1922, 13, 509, 458, 11, 558, 51452, 51452, 586, 291, 787, 536, 452, 558, 1252, 457, 754, 498, 291, 632, 1128, 1612, 452, 1411, 1252, 291, 727, 51598, 51598, 544, 420, 1570, 6069, 437, 286, 574, 411, 490, 264, 661, 1252, 13, 4534, 561, 366, 544, 420, 1570, 51778, 51778], "temperature": 0.0, "avg_logprob": -0.1899301644527551, "compression_ratio": 2.0193798449612403, "no_speech_prob": 4.68194302811753e-05}, {"id": 573, "seek": 306652, "start": 3088.28, "end": 3091.2, "text": " now you only see my right side but even if you had never seen my left side you could", "tokens": [50364, 5361, 2283, 294, 257, 8174, 11, 370, 286, 976, 291, 257, 8174, 11, 286, 3461, 512, 295, 264, 2283, 293, 50694, 50694, 264, 1185, 16329, 2564, 281, 6069, 264, 2283, 300, 366, 5361, 13, 1610, 286, 855, 291, 257, 3840, 295, 50952, 50952, 960, 293, 286, 3461, 257, 2522, 295, 264, 12083, 420, 512, 295, 264, 12083, 11, 2522, 295, 264, 3256, 337, 51214, 51214, 512, 295, 264, 12083, 13, 509, 458, 11, 6069, 264, 1411, 1922, 490, 264, 558, 1922, 13, 509, 458, 11, 558, 51452, 51452, 586, 291, 787, 536, 452, 558, 1252, 457, 754, 498, 291, 632, 1128, 1612, 452, 1411, 1252, 291, 727, 51598, 51598, 544, 420, 1570, 6069, 437, 286, 574, 411, 490, 264, 661, 1252, 13, 4534, 561, 366, 544, 420, 1570, 51778, 51778], "temperature": 0.0, "avg_logprob": -0.1899301644527551, "compression_ratio": 2.0193798449612403, "no_speech_prob": 4.68194302811753e-05}, {"id": 574, "seek": 306652, "start": 3091.2, "end": 3094.8, "text": " more or less predict what I look like from the other side. Most people are more or less", "tokens": [50364, 5361, 2283, 294, 257, 8174, 11, 370, 286, 976, 291, 257, 8174, 11, 286, 3461, 512, 295, 264, 2283, 293, 50694, 50694, 264, 1185, 16329, 2564, 281, 6069, 264, 2283, 300, 366, 5361, 13, 1610, 286, 855, 291, 257, 3840, 295, 50952, 50952, 960, 293, 286, 3461, 257, 2522, 295, 264, 12083, 420, 512, 295, 264, 12083, 11, 2522, 295, 264, 3256, 337, 51214, 51214, 512, 295, 264, 12083, 13, 509, 458, 11, 6069, 264, 1411, 1922, 490, 264, 558, 1922, 13, 509, 458, 11, 558, 51452, 51452, 586, 291, 787, 536, 452, 558, 1252, 457, 754, 498, 291, 632, 1128, 1612, 452, 1411, 1252, 291, 727, 51598, 51598, 544, 420, 1570, 6069, 437, 286, 574, 411, 490, 264, 661, 1252, 13, 4534, 561, 366, 544, 420, 1570, 51778, 51778], "temperature": 0.0, "avg_logprob": -0.1899301644527551, "compression_ratio": 2.0193798449612403, "no_speech_prob": 4.68194302811753e-05}, {"id": 575, "seek": 309480, "start": 3094.8, "end": 3106.84, "text": " asymmetric. Except scary Hollywood characters. So one instance where star supervised learning", "tokens": [50364, 37277, 17475, 13, 16192, 6958, 11628, 4342, 13, 407, 472, 5197, 689, 3543, 46533, 2539, 50966, 50966, 575, 668, 43593, 4406, 293, 309, 787, 2314, 670, 264, 1036, 1064, 293, 257, 1922, 307, 2487, 13, 51534, 51534, 407, 2487, 4960, 257, 1729, 2010, 295, 3543, 46533, 2539, 1219, 1441, 78, 3436, 8399, 22660, 19866, 13, 407, 51714, 51714], "temperature": 0.0, "avg_logprob": -0.22137873967488605, "compression_ratio": 1.5649717514124293, "no_speech_prob": 1.3842150110576767e-05}, {"id": 576, "seek": 309480, "start": 3106.84, "end": 3118.2000000000003, "text": " has been unbelievably successful and it only happens over the last year and a half is text.", "tokens": [50364, 37277, 17475, 13, 16192, 6958, 11628, 4342, 13, 407, 472, 5197, 689, 3543, 46533, 2539, 50966, 50966, 575, 668, 43593, 4406, 293, 309, 787, 2314, 670, 264, 1036, 1064, 293, 257, 1922, 307, 2487, 13, 51534, 51534, 407, 2487, 4960, 257, 1729, 2010, 295, 3543, 46533, 2539, 1219, 1441, 78, 3436, 8399, 22660, 19866, 13, 407, 51714, 51714], "temperature": 0.0, "avg_logprob": -0.22137873967488605, "compression_ratio": 1.5649717514124293, "no_speech_prob": 1.3842150110576767e-05}, {"id": 577, "seek": 309480, "start": 3118.2000000000003, "end": 3121.8, "text": " So text uses a particular type of star supervised learning called denoising autoencoder. So", "tokens": [50364, 37277, 17475, 13, 16192, 6958, 11628, 4342, 13, 407, 472, 5197, 689, 3543, 46533, 2539, 50966, 50966, 575, 668, 43593, 4406, 293, 309, 787, 2314, 670, 264, 1036, 1064, 293, 257, 1922, 307, 2487, 13, 51534, 51534, 407, 2487, 4960, 257, 1729, 2010, 295, 3543, 46533, 2539, 1219, 1441, 78, 3436, 8399, 22660, 19866, 13, 407, 51714, 51714], "temperature": 0.0, "avg_logprob": -0.22137873967488605, "compression_ratio": 1.5649717514124293, "no_speech_prob": 1.3842150110576767e-05}, {"id": 578, "seek": 312180, "start": 3121.8, "end": 3128.6000000000004, "text": " you take a piece of text, you remove some of the words, typically 10, 15, 20 percent", "tokens": [50364, 291, 747, 257, 2522, 295, 2487, 11, 291, 4159, 512, 295, 264, 2283, 11, 5850, 1266, 11, 2119, 11, 945, 3043, 50704, 50704, 295, 264, 2283, 13, 407, 291, 7406, 264, 14862, 300, 16203, 257, 1349, 538, 1936, 8247, 13, 400, 550, 51056, 51056, 291, 3847, 512, 7410, 18161, 2533, 281, 6069, 264, 2283, 300, 366, 5361, 13, 467, 311, 11, 264, 1185, 51394, 51394, 2644, 652, 364, 1900, 17630, 466, 597, 2283, 366, 5361, 293, 370, 291, 3847, 309, 382, 257, 51624, 51624, 1508, 9902, 538, 10501, 257, 955, 2787, 41167, 5952, 337, 1184, 1349, 597, 23249, 281, 257, 8482, 51860, 51860], "temperature": 0.0, "avg_logprob": -0.12856963929675874, "compression_ratio": 1.6973180076628354, "no_speech_prob": 1.89192815014394e-05}, {"id": 579, "seek": 312180, "start": 3128.6000000000004, "end": 3135.6400000000003, "text": " of the words. So you replace the token that indicates a word by basically blank. And then", "tokens": [50364, 291, 747, 257, 2522, 295, 2487, 11, 291, 4159, 512, 295, 264, 2283, 11, 5850, 1266, 11, 2119, 11, 945, 3043, 50704, 50704, 295, 264, 2283, 13, 407, 291, 7406, 264, 14862, 300, 16203, 257, 1349, 538, 1936, 8247, 13, 400, 550, 51056, 51056, 291, 3847, 512, 7410, 18161, 2533, 281, 6069, 264, 2283, 300, 366, 5361, 13, 467, 311, 11, 264, 1185, 51394, 51394, 2644, 652, 364, 1900, 17630, 466, 597, 2283, 366, 5361, 293, 370, 291, 3847, 309, 382, 257, 51624, 51624, 1508, 9902, 538, 10501, 257, 955, 2787, 41167, 5952, 337, 1184, 1349, 597, 23249, 281, 257, 8482, 51860, 51860], "temperature": 0.0, "avg_logprob": -0.12856963929675874, "compression_ratio": 1.6973180076628354, "no_speech_prob": 1.89192815014394e-05}, {"id": 580, "seek": 312180, "start": 3135.6400000000003, "end": 3142.4, "text": " you train some giant neural net to predict the words that are missing. It's, the system", "tokens": [50364, 291, 747, 257, 2522, 295, 2487, 11, 291, 4159, 512, 295, 264, 2283, 11, 5850, 1266, 11, 2119, 11, 945, 3043, 50704, 50704, 295, 264, 2283, 13, 407, 291, 7406, 264, 14862, 300, 16203, 257, 1349, 538, 1936, 8247, 13, 400, 550, 51056, 51056, 291, 3847, 512, 7410, 18161, 2533, 281, 6069, 264, 2283, 300, 366, 5361, 13, 467, 311, 11, 264, 1185, 51394, 51394, 2644, 652, 364, 1900, 17630, 466, 597, 2283, 366, 5361, 293, 370, 291, 3847, 309, 382, 257, 51624, 51624, 1508, 9902, 538, 10501, 257, 955, 2787, 41167, 5952, 337, 1184, 1349, 597, 23249, 281, 257, 8482, 51860, 51860], "temperature": 0.0, "avg_logprob": -0.12856963929675874, "compression_ratio": 1.6973180076628354, "no_speech_prob": 1.89192815014394e-05}, {"id": 581, "seek": 312180, "start": 3142.4, "end": 3147.0, "text": " cannot make an exact prediction about which words are missing and so you train it as a", "tokens": [50364, 291, 747, 257, 2522, 295, 2487, 11, 291, 4159, 512, 295, 264, 2283, 11, 5850, 1266, 11, 2119, 11, 945, 3043, 50704, 50704, 295, 264, 2283, 13, 407, 291, 7406, 264, 14862, 300, 16203, 257, 1349, 538, 1936, 8247, 13, 400, 550, 51056, 51056, 291, 3847, 512, 7410, 18161, 2533, 281, 6069, 264, 2283, 300, 366, 5361, 13, 467, 311, 11, 264, 1185, 51394, 51394, 2644, 652, 364, 1900, 17630, 466, 597, 2283, 366, 5361, 293, 370, 291, 3847, 309, 382, 257, 51624, 51624, 1508, 9902, 538, 10501, 257, 955, 2787, 41167, 5952, 337, 1184, 1349, 597, 23249, 281, 257, 8482, 51860, 51860], "temperature": 0.0, "avg_logprob": -0.12856963929675874, "compression_ratio": 1.6973180076628354, "no_speech_prob": 1.89192815014394e-05}, {"id": 582, "seek": 312180, "start": 3147.0, "end": 3151.7200000000003, "text": " classifier by producing a big softmax factor for each word which corresponds to a probability", "tokens": [50364, 291, 747, 257, 2522, 295, 2487, 11, 291, 4159, 512, 295, 264, 2283, 11, 5850, 1266, 11, 2119, 11, 945, 3043, 50704, 50704, 295, 264, 2283, 13, 407, 291, 7406, 264, 14862, 300, 16203, 257, 1349, 538, 1936, 8247, 13, 400, 550, 51056, 51056, 291, 3847, 512, 7410, 18161, 2533, 281, 6069, 264, 2283, 300, 366, 5361, 13, 467, 311, 11, 264, 1185, 51394, 51394, 2644, 652, 364, 1900, 17630, 466, 597, 2283, 366, 5361, 293, 370, 291, 3847, 309, 382, 257, 51624, 51624, 1508, 9902, 538, 10501, 257, 955, 2787, 41167, 5952, 337, 1184, 1349, 597, 23249, 281, 257, 8482, 51860, 51860], "temperature": 0.0, "avg_logprob": -0.12856963929675874, "compression_ratio": 1.6973180076628354, "no_speech_prob": 1.89192815014394e-05}, {"id": 583, "seek": 315172, "start": 3151.72, "end": 3163.68, "text": " distribution over words. Okay? And once you've trained this system you chop off the last", "tokens": [50364, 7316, 670, 2283, 13, 1033, 30, 400, 1564, 291, 600, 8895, 341, 1185, 291, 7931, 766, 264, 1036, 50962, 50962, 4583, 293, 291, 764, 264, 1150, 1036, 4583, 382, 257, 10290, 295, 604, 2487, 291, 3154, 309, 13, 51188, 51188, 821, 311, 257, 1729, 9482, 295, 341, 3209, 300, 1669, 309, 589, 731, 457, 309, 311, 28682, 51510, 51510, 281, 264, 935, 300, 321, 434, 1455, 558, 586, 13, 3950, 31782, 9590, 300, 321, 2825, 51784, 51784], "temperature": 0.0, "avg_logprob": -0.15502218656902073, "compression_ratio": 1.5954545454545455, "no_speech_prob": 5.304532533045858e-05}, {"id": 584, "seek": 315172, "start": 3163.68, "end": 3168.2, "text": " layer and you use the second last layer as a representation of any text you feed it.", "tokens": [50364, 7316, 670, 2283, 13, 1033, 30, 400, 1564, 291, 600, 8895, 341, 1185, 291, 7931, 766, 264, 1036, 50962, 50962, 4583, 293, 291, 764, 264, 1150, 1036, 4583, 382, 257, 10290, 295, 604, 2487, 291, 3154, 309, 13, 51188, 51188, 821, 311, 257, 1729, 9482, 295, 341, 3209, 300, 1669, 309, 589, 731, 457, 309, 311, 28682, 51510, 51510, 281, 264, 935, 300, 321, 434, 1455, 558, 586, 13, 3950, 31782, 9590, 300, 321, 2825, 51784, 51784], "temperature": 0.0, "avg_logprob": -0.15502218656902073, "compression_ratio": 1.5954545454545455, "no_speech_prob": 5.304532533045858e-05}, {"id": 585, "seek": 315172, "start": 3168.2, "end": 3174.64, "text": " There's a particular architecture of this network that makes it work well but it's irrelevant", "tokens": [50364, 7316, 670, 2283, 13, 1033, 30, 400, 1564, 291, 600, 8895, 341, 1185, 291, 7931, 766, 264, 1036, 50962, 50962, 4583, 293, 291, 764, 264, 1150, 1036, 4583, 382, 257, 10290, 295, 604, 2487, 291, 3154, 309, 13, 51188, 51188, 821, 311, 257, 1729, 9482, 295, 341, 3209, 300, 1669, 309, 589, 731, 457, 309, 311, 28682, 51510, 51510, 281, 264, 935, 300, 321, 434, 1455, 558, 586, 13, 3950, 31782, 9590, 300, 321, 2825, 51784, 51784], "temperature": 0.0, "avg_logprob": -0.15502218656902073, "compression_ratio": 1.5954545454545455, "no_speech_prob": 5.304532533045858e-05}, {"id": 586, "seek": 315172, "start": 3174.64, "end": 3180.12, "text": " to the point that we're making right now. Those transformer networks that we talked", "tokens": [50364, 7316, 670, 2283, 13, 1033, 30, 400, 1564, 291, 600, 8895, 341, 1185, 291, 7931, 766, 264, 1036, 50962, 50962, 4583, 293, 291, 764, 264, 1150, 1036, 4583, 382, 257, 10290, 295, 604, 2487, 291, 3154, 309, 13, 51188, 51188, 821, 311, 257, 1729, 9482, 295, 341, 3209, 300, 1669, 309, 589, 731, 457, 309, 311, 28682, 51510, 51510, 281, 264, 935, 300, 321, 434, 1455, 558, 586, 13, 3950, 31782, 9590, 300, 321, 2825, 51784, 51784], "temperature": 0.0, "avg_logprob": -0.15502218656902073, "compression_ratio": 1.5954545454545455, "no_speech_prob": 5.304532533045858e-05}, {"id": 587, "seek": 318012, "start": 3180.12, "end": 3185.44, "text": " about last week, a little bit. So, but it's a very simple task, a completion task, filling", "tokens": [50364, 466, 1036, 1243, 11, 257, 707, 857, 13, 407, 11, 457, 309, 311, 257, 588, 2199, 5633, 11, 257, 19372, 5633, 11, 10623, 50630, 50630, 294, 264, 8247, 82, 11, 747, 257, 8174, 11, 4159, 512, 295, 264, 2283, 11, 3847, 264, 1185, 281, 6069, 50800, 50800, 264, 2283, 300, 366, 5361, 13, 663, 1985, 31762, 731, 13, 1057, 264, 1192, 426, 45196, 3652, 586, 300, 362, 51322, 51322, 264, 1151, 3389, 322, 439, 264, 43751, 1936, 366, 659, 12, 17227, 2001, 1228, 257, 3170, 411, 51502, 51502, 341, 293, 264, 1627, 551, 466, 309, 307, 300, 11, 291, 458, 11, 291, 362, 382, 709, 2487, 382, 291, 528, 51788, 51788], "temperature": 0.0, "avg_logprob": -0.12905498099538076, "compression_ratio": 1.669172932330827, "no_speech_prob": 2.2826257918495685e-05}, {"id": 588, "seek": 318012, "start": 3185.44, "end": 3188.8399999999997, "text": " in the blanks, take a sentence, remove some of the words, train the system to predict", "tokens": [50364, 466, 1036, 1243, 11, 257, 707, 857, 13, 407, 11, 457, 309, 311, 257, 588, 2199, 5633, 11, 257, 19372, 5633, 11, 10623, 50630, 50630, 294, 264, 8247, 82, 11, 747, 257, 8174, 11, 4159, 512, 295, 264, 2283, 11, 3847, 264, 1185, 281, 6069, 50800, 50800, 264, 2283, 300, 366, 5361, 13, 663, 1985, 31762, 731, 13, 1057, 264, 1192, 426, 45196, 3652, 586, 300, 362, 51322, 51322, 264, 1151, 3389, 322, 439, 264, 43751, 1936, 366, 659, 12, 17227, 2001, 1228, 257, 3170, 411, 51502, 51502, 341, 293, 264, 1627, 551, 466, 309, 307, 300, 11, 291, 458, 11, 291, 362, 382, 709, 2487, 382, 291, 528, 51788, 51788], "temperature": 0.0, "avg_logprob": -0.12905498099538076, "compression_ratio": 1.669172932330827, "no_speech_prob": 2.2826257918495685e-05}, {"id": 589, "seek": 318012, "start": 3188.8399999999997, "end": 3199.2799999999997, "text": " the words that are missing. That works amazingly well. All the top NLP systems now that have", "tokens": [50364, 466, 1036, 1243, 11, 257, 707, 857, 13, 407, 11, 457, 309, 311, 257, 588, 2199, 5633, 11, 257, 19372, 5633, 11, 10623, 50630, 50630, 294, 264, 8247, 82, 11, 747, 257, 8174, 11, 4159, 512, 295, 264, 2283, 11, 3847, 264, 1185, 281, 6069, 50800, 50800, 264, 2283, 300, 366, 5361, 13, 663, 1985, 31762, 731, 13, 1057, 264, 1192, 426, 45196, 3652, 586, 300, 362, 51322, 51322, 264, 1151, 3389, 322, 439, 264, 43751, 1936, 366, 659, 12, 17227, 2001, 1228, 257, 3170, 411, 51502, 51502, 341, 293, 264, 1627, 551, 466, 309, 307, 300, 11, 291, 458, 11, 291, 362, 382, 709, 2487, 382, 291, 528, 51788, 51788], "temperature": 0.0, "avg_logprob": -0.12905498099538076, "compression_ratio": 1.669172932330827, "no_speech_prob": 2.2826257918495685e-05}, {"id": 590, "seek": 318012, "start": 3199.2799999999997, "end": 3202.88, "text": " the best performance on all the benchmarks basically are pre-trained using a method like", "tokens": [50364, 466, 1036, 1243, 11, 257, 707, 857, 13, 407, 11, 457, 309, 311, 257, 588, 2199, 5633, 11, 257, 19372, 5633, 11, 10623, 50630, 50630, 294, 264, 8247, 82, 11, 747, 257, 8174, 11, 4159, 512, 295, 264, 2283, 11, 3847, 264, 1185, 281, 6069, 50800, 50800, 264, 2283, 300, 366, 5361, 13, 663, 1985, 31762, 731, 13, 1057, 264, 1192, 426, 45196, 3652, 586, 300, 362, 51322, 51322, 264, 1151, 3389, 322, 439, 264, 43751, 1936, 366, 659, 12, 17227, 2001, 1228, 257, 3170, 411, 51502, 51502, 341, 293, 264, 1627, 551, 466, 309, 307, 300, 11, 291, 458, 11, 291, 362, 382, 709, 2487, 382, 291, 528, 51788, 51788], "temperature": 0.0, "avg_logprob": -0.12905498099538076, "compression_ratio": 1.669172932330827, "no_speech_prob": 2.2826257918495685e-05}, {"id": 591, "seek": 318012, "start": 3202.88, "end": 3208.6, "text": " this and the cool thing about it is that, you know, you have as much text as you want", "tokens": [50364, 466, 1036, 1243, 11, 257, 707, 857, 13, 407, 11, 457, 309, 311, 257, 588, 2199, 5633, 11, 257, 19372, 5633, 11, 10623, 50630, 50630, 294, 264, 8247, 82, 11, 747, 257, 8174, 11, 4159, 512, 295, 264, 2283, 11, 3847, 264, 1185, 281, 6069, 50800, 50800, 264, 2283, 300, 366, 5361, 13, 663, 1985, 31762, 731, 13, 1057, 264, 1192, 426, 45196, 3652, 586, 300, 362, 51322, 51322, 264, 1151, 3389, 322, 439, 264, 43751, 1936, 366, 659, 12, 17227, 2001, 1228, 257, 3170, 411, 51502, 51502, 341, 293, 264, 1627, 551, 466, 309, 307, 300, 11, 291, 458, 11, 291, 362, 382, 709, 2487, 382, 291, 528, 51788, 51788], "temperature": 0.0, "avg_logprob": -0.12905498099538076, "compression_ratio": 1.669172932330827, "no_speech_prob": 2.2826257918495685e-05}, {"id": 592, "seek": 320860, "start": 3208.6, "end": 3212.72, "text": " on the web to pre-train those systems. You don't need to label anything, it's very cheap.", "tokens": [50364, 322, 264, 3670, 281, 659, 12, 83, 7146, 729, 3652, 13, 509, 500, 380, 643, 281, 7645, 1340, 11, 309, 311, 588, 7084, 13, 50570, 50570, 467, 311, 588, 5124, 294, 2115, 295, 24903, 570, 729, 9590, 366, 11322, 337, 552, 50736, 50736, 281, 589, 731, 13, 583, 309, 1985, 534, 731, 13, 407, 4258, 561, 853, 281, 733, 295, 13799, 51060, 51060, 300, 2245, 666, 257, 2531, 2245, 337, 5267, 13, 407, 718, 311, 584, 747, 364, 3256, 11, 3461, 484, 512, 51516, 51516], "temperature": 0.0, "avg_logprob": -0.12299317327038996, "compression_ratio": 1.5822222222222222, "no_speech_prob": 2.6682824682211503e-05}, {"id": 593, "seek": 320860, "start": 3212.72, "end": 3216.04, "text": " It's very expensive in terms of computation because those networks are enormous for them", "tokens": [50364, 322, 264, 3670, 281, 659, 12, 83, 7146, 729, 3652, 13, 509, 500, 380, 643, 281, 7645, 1340, 11, 309, 311, 588, 7084, 13, 50570, 50570, 467, 311, 588, 5124, 294, 2115, 295, 24903, 570, 729, 9590, 366, 11322, 337, 552, 50736, 50736, 281, 589, 731, 13, 583, 309, 1985, 534, 731, 13, 407, 4258, 561, 853, 281, 733, 295, 13799, 51060, 51060, 300, 2245, 666, 257, 2531, 2245, 337, 5267, 13, 407, 718, 311, 584, 747, 364, 3256, 11, 3461, 484, 512, 51516, 51516], "temperature": 0.0, "avg_logprob": -0.12299317327038996, "compression_ratio": 1.5822222222222222, "no_speech_prob": 2.6682824682211503e-05}, {"id": 594, "seek": 320860, "start": 3216.04, "end": 3222.52, "text": " to work well. But it works really well. So immediately people try to kind of translate", "tokens": [50364, 322, 264, 3670, 281, 659, 12, 83, 7146, 729, 3652, 13, 509, 500, 380, 643, 281, 7645, 1340, 11, 309, 311, 588, 7084, 13, 50570, 50570, 467, 311, 588, 5124, 294, 2115, 295, 24903, 570, 729, 9590, 366, 11322, 337, 552, 50736, 50736, 281, 589, 731, 13, 583, 309, 1985, 534, 731, 13, 407, 4258, 561, 853, 281, 733, 295, 13799, 51060, 51060, 300, 2245, 666, 257, 2531, 2245, 337, 5267, 13, 407, 718, 311, 584, 747, 364, 3256, 11, 3461, 484, 512, 51516, 51516], "temperature": 0.0, "avg_logprob": -0.12299317327038996, "compression_ratio": 1.5822222222222222, "no_speech_prob": 2.6682824682211503e-05}, {"id": 595, "seek": 320860, "start": 3222.52, "end": 3231.64, "text": " that success into a similar success for images. So let's say take an image, block out some", "tokens": [50364, 322, 264, 3670, 281, 659, 12, 83, 7146, 729, 3652, 13, 509, 500, 380, 643, 281, 7645, 1340, 11, 309, 311, 588, 7084, 13, 50570, 50570, 467, 311, 588, 5124, 294, 2115, 295, 24903, 570, 729, 9590, 366, 11322, 337, 552, 50736, 50736, 281, 589, 731, 13, 583, 309, 1985, 534, 731, 13, 407, 4258, 561, 853, 281, 733, 295, 13799, 51060, 51060, 300, 2245, 666, 257, 2531, 2245, 337, 5267, 13, 407, 718, 311, 584, 747, 364, 3256, 11, 3461, 484, 512, 51516, 51516], "temperature": 0.0, "avg_logprob": -0.12299317327038996, "compression_ratio": 1.5822222222222222, "no_speech_prob": 2.6682824682211503e-05}, {"id": 596, "seek": 323164, "start": 3231.64, "end": 3239.08, "text": " pieces of it and then train some convolutional net or something to predict the missing pieces", "tokens": [50364, 3755, 295, 309, 293, 550, 3847, 512, 45216, 304, 2533, 420, 746, 281, 6069, 264, 5361, 3755, 50736, 50736, 294, 264, 3256, 13, 400, 264, 3542, 362, 668, 4664, 25054, 13, 467, 1177, 380, 589, 534, 13, 286, 914, 11, 51228, 51228, 309, 1985, 731, 294, 264, 2020, 300, 264, 5267, 483, 7365, 365, 1333, 295, 11, 291, 458, 11, 721, 51454, 51454, 300, 652, 2020, 13, 583, 550, 498, 291, 764, 264, 6920, 10290, 11, 1466, 341, 636, 11, 382, 4846, 281, 51748, 51748], "temperature": 0.0, "avg_logprob": -0.14653308912255297, "compression_ratio": 1.617391304347826, "no_speech_prob": 1.1121940588054713e-05}, {"id": 597, "seek": 323164, "start": 3239.08, "end": 3248.92, "text": " in the image. And the results have been extremely disappointing. It doesn't work really. I mean,", "tokens": [50364, 3755, 295, 309, 293, 550, 3847, 512, 45216, 304, 2533, 420, 746, 281, 6069, 264, 5361, 3755, 50736, 50736, 294, 264, 3256, 13, 400, 264, 3542, 362, 668, 4664, 25054, 13, 467, 1177, 380, 589, 534, 13, 286, 914, 11, 51228, 51228, 309, 1985, 731, 294, 264, 2020, 300, 264, 5267, 483, 7365, 365, 1333, 295, 11, 291, 458, 11, 721, 51454, 51454, 300, 652, 2020, 13, 583, 550, 498, 291, 764, 264, 6920, 10290, 11, 1466, 341, 636, 11, 382, 4846, 281, 51748, 51748], "temperature": 0.0, "avg_logprob": -0.14653308912255297, "compression_ratio": 1.617391304347826, "no_speech_prob": 1.1121940588054713e-05}, {"id": 598, "seek": 323164, "start": 3248.92, "end": 3253.44, "text": " it works well in the sense that the images get completed with sort of, you know, things", "tokens": [50364, 3755, 295, 309, 293, 550, 3847, 512, 45216, 304, 2533, 420, 746, 281, 6069, 264, 5361, 3755, 50736, 50736, 294, 264, 3256, 13, 400, 264, 3542, 362, 668, 4664, 25054, 13, 467, 1177, 380, 589, 534, 13, 286, 914, 11, 51228, 51228, 309, 1985, 731, 294, 264, 2020, 300, 264, 5267, 483, 7365, 365, 1333, 295, 11, 291, 458, 11, 721, 51454, 51454, 300, 652, 2020, 13, 583, 550, 498, 291, 764, 264, 6920, 10290, 11, 1466, 341, 636, 11, 382, 4846, 281, 51748, 51748], "temperature": 0.0, "avg_logprob": -0.14653308912255297, "compression_ratio": 1.617391304347826, "no_speech_prob": 1.1121940588054713e-05}, {"id": 599, "seek": 323164, "start": 3253.44, "end": 3259.3199999999997, "text": " that make sense. But then if you use the internal representation, learn this way, as input to", "tokens": [50364, 3755, 295, 309, 293, 550, 3847, 512, 45216, 304, 2533, 420, 746, 281, 6069, 264, 5361, 3755, 50736, 50736, 294, 264, 3256, 13, 400, 264, 3542, 362, 668, 4664, 25054, 13, 467, 1177, 380, 589, 534, 13, 286, 914, 11, 51228, 51228, 309, 1985, 731, 294, 264, 2020, 300, 264, 5267, 483, 7365, 365, 1333, 295, 11, 291, 458, 11, 721, 51454, 51454, 300, 652, 2020, 13, 583, 550, 498, 291, 764, 264, 6920, 10290, 11, 1466, 341, 636, 11, 382, 4846, 281, 51748, 51748], "temperature": 0.0, "avg_logprob": -0.14653308912255297, "compression_ratio": 1.617391304347826, "no_speech_prob": 1.1121940588054713e-05}, {"id": 600, "seek": 325932, "start": 3259.32, "end": 3264.4, "text": " a computer vision system, you can't beat a computer vision system that has been pre-trained", "tokens": [50364, 257, 3820, 5201, 1185, 11, 291, 393, 380, 4224, 257, 3820, 5201, 1185, 300, 575, 668, 659, 12, 17227, 2001, 50618, 50618, 46533, 322, 29903, 31890, 13, 407, 437, 311, 264, 2649, 30, 509, 458, 11, 983, 775, 309, 589, 337, 426, 45196, 293, 309, 51234, 51234, 1177, 380, 589, 337, 5267, 30, 400, 264, 2649, 307, 300, 426, 45196, 307, 27706, 9735, 5267, 366, 51526, 51526, 10957, 13, 3432, 611, 853, 281, 360, 341, 337, 960, 13, 407, 912, 1558, 382, 363, 31479, 3993, 10772, 51814, 51814], "temperature": 0.0, "avg_logprob": -0.13735232883029513, "compression_ratio": 1.579646017699115, "no_speech_prob": 1.2802614946849644e-05}, {"id": 601, "seek": 325932, "start": 3264.4, "end": 3276.7200000000003, "text": " supervised on ImageNet. So what's the difference? You know, why does it work for NLP and it", "tokens": [50364, 257, 3820, 5201, 1185, 11, 291, 393, 380, 4224, 257, 3820, 5201, 1185, 300, 575, 668, 659, 12, 17227, 2001, 50618, 50618, 46533, 322, 29903, 31890, 13, 407, 437, 311, 264, 2649, 30, 509, 458, 11, 983, 775, 309, 589, 337, 426, 45196, 293, 309, 51234, 51234, 1177, 380, 589, 337, 5267, 30, 400, 264, 2649, 307, 300, 426, 45196, 307, 27706, 9735, 5267, 366, 51526, 51526, 10957, 13, 3432, 611, 853, 281, 360, 341, 337, 960, 13, 407, 912, 1558, 382, 363, 31479, 3993, 10772, 51814, 51814], "temperature": 0.0, "avg_logprob": -0.13735232883029513, "compression_ratio": 1.579646017699115, "no_speech_prob": 1.2802614946849644e-05}, {"id": 602, "seek": 325932, "start": 3276.7200000000003, "end": 3282.56, "text": " doesn't work for images? And the difference is that NLP is discrete whereas images are", "tokens": [50364, 257, 3820, 5201, 1185, 11, 291, 393, 380, 4224, 257, 3820, 5201, 1185, 300, 575, 668, 659, 12, 17227, 2001, 50618, 50618, 46533, 322, 29903, 31890, 13, 407, 437, 311, 264, 2649, 30, 509, 458, 11, 983, 775, 309, 589, 337, 426, 45196, 293, 309, 51234, 51234, 1177, 380, 589, 337, 5267, 30, 400, 264, 2649, 307, 300, 426, 45196, 307, 27706, 9735, 5267, 366, 51526, 51526, 10957, 13, 3432, 611, 853, 281, 360, 341, 337, 960, 13, 407, 912, 1558, 382, 363, 31479, 3993, 10772, 51814, 51814], "temperature": 0.0, "avg_logprob": -0.13735232883029513, "compression_ratio": 1.579646017699115, "no_speech_prob": 1.2802614946849644e-05}, {"id": 603, "seek": 325932, "start": 3282.56, "end": 3288.32, "text": " continuous. People also try to do this for video. So same idea as BERT except replaced", "tokens": [50364, 257, 3820, 5201, 1185, 11, 291, 393, 380, 4224, 257, 3820, 5201, 1185, 300, 575, 668, 659, 12, 17227, 2001, 50618, 50618, 46533, 322, 29903, 31890, 13, 407, 437, 311, 264, 2649, 30, 509, 458, 11, 983, 775, 309, 589, 337, 426, 45196, 293, 309, 51234, 51234, 1177, 380, 589, 337, 5267, 30, 400, 264, 2649, 307, 300, 426, 45196, 307, 27706, 9735, 5267, 366, 51526, 51526, 10957, 13, 3432, 611, 853, 281, 360, 341, 337, 960, 13, 407, 912, 1558, 382, 363, 31479, 3993, 10772, 51814, 51814], "temperature": 0.0, "avg_logprob": -0.13735232883029513, "compression_ratio": 1.579646017699115, "no_speech_prob": 1.2802614946849644e-05}, {"id": 604, "seek": 328832, "start": 3288.32, "end": 3295.1600000000003, "text": " words by video frames. So feed a big video to a transformer-like system or something", "tokens": [50364, 2283, 538, 960, 12083, 13, 407, 3154, 257, 955, 960, 281, 257, 31782, 12, 4092, 1185, 420, 746, 50706, 50706, 2531, 11, 4159, 512, 295, 264, 12083, 420, 8474, 295, 12083, 293, 550, 3847, 264, 1185, 281, 6069, 50992, 50992, 264, 5361, 12083, 13, 400, 264, 4122, 291, 483, 366, 406, 370, 869, 13, 407, 300, 311, 264, 2649, 51466, 51466, 307, 721, 1643, 281, 589, 294, 264, 27706, 1002, 13, 814, 500, 380, 1643, 281, 589, 294, 264, 10957, 51730, 51730], "temperature": 0.0, "avg_logprob": -0.12449735686892555, "compression_ratio": 1.7170731707317073, "no_speech_prob": 2.1442683646455407e-05}, {"id": 605, "seek": 328832, "start": 3295.1600000000003, "end": 3300.88, "text": " similar, remove some of the frames or blocks of frames and then train the system to predict", "tokens": [50364, 2283, 538, 960, 12083, 13, 407, 3154, 257, 955, 960, 281, 257, 31782, 12, 4092, 1185, 420, 746, 50706, 50706, 2531, 11, 4159, 512, 295, 264, 12083, 420, 8474, 295, 12083, 293, 550, 3847, 264, 1185, 281, 6069, 50992, 50992, 264, 5361, 12083, 13, 400, 264, 4122, 291, 483, 366, 406, 370, 869, 13, 407, 300, 311, 264, 2649, 51466, 51466, 307, 721, 1643, 281, 589, 294, 264, 27706, 1002, 13, 814, 500, 380, 1643, 281, 589, 294, 264, 10957, 51730, 51730], "temperature": 0.0, "avg_logprob": -0.12449735686892555, "compression_ratio": 1.7170731707317073, "no_speech_prob": 2.1442683646455407e-05}, {"id": 606, "seek": 328832, "start": 3300.88, "end": 3310.36, "text": " the missing frames. And the features you get are not so great. So that's the difference", "tokens": [50364, 2283, 538, 960, 12083, 13, 407, 3154, 257, 955, 960, 281, 257, 31782, 12, 4092, 1185, 420, 746, 50706, 50706, 2531, 11, 4159, 512, 295, 264, 12083, 420, 8474, 295, 12083, 293, 550, 3847, 264, 1185, 281, 6069, 50992, 50992, 264, 5361, 12083, 13, 400, 264, 4122, 291, 483, 366, 406, 370, 869, 13, 407, 300, 311, 264, 2649, 51466, 51466, 307, 721, 1643, 281, 589, 294, 264, 27706, 1002, 13, 814, 500, 380, 1643, 281, 589, 294, 264, 10957, 51730, 51730], "temperature": 0.0, "avg_logprob": -0.12449735686892555, "compression_ratio": 1.7170731707317073, "no_speech_prob": 2.1442683646455407e-05}, {"id": 607, "seek": 328832, "start": 3310.36, "end": 3315.6400000000003, "text": " is things seem to work in the discrete world. They don't seem to work in the continuous", "tokens": [50364, 2283, 538, 960, 12083, 13, 407, 3154, 257, 955, 960, 281, 257, 31782, 12, 4092, 1185, 420, 746, 50706, 50706, 2531, 11, 4159, 512, 295, 264, 12083, 420, 8474, 295, 12083, 293, 550, 3847, 264, 1185, 281, 6069, 50992, 50992, 264, 5361, 12083, 13, 400, 264, 4122, 291, 483, 366, 406, 370, 869, 13, 407, 300, 311, 264, 2649, 51466, 51466, 307, 721, 1643, 281, 589, 294, 264, 27706, 1002, 13, 814, 500, 380, 1643, 281, 589, 294, 264, 10957, 51730, 51730], "temperature": 0.0, "avg_logprob": -0.12449735686892555, "compression_ratio": 1.7170731707317073, "no_speech_prob": 2.1442683646455407e-05}, {"id": 608, "seek": 331564, "start": 3315.64, "end": 3325.3199999999997, "text": " world. And the reason is because in discrete world we know how to represent uncertainty", "tokens": [50364, 1002, 13, 400, 264, 1778, 307, 570, 294, 27706, 1002, 321, 458, 577, 281, 2906, 15697, 50848, 50848, 538, 955, 2787, 41167, 8062, 670, 2283, 13, 682, 10957, 7673, 321, 500, 380, 13, 407, 498, 286, 528, 281, 3847, 257, 1185, 51278, 51278, 281, 360, 960, 17630, 11, 286, 500, 380, 458, 577, 281, 2906, 257, 8482, 7316, 670, 51699, 51699], "temperature": 0.0, "avg_logprob": -0.1259273196023608, "compression_ratio": 1.5371428571428571, "no_speech_prob": 1.0449202818563208e-05}, {"id": 609, "seek": 331564, "start": 3325.3199999999997, "end": 3333.92, "text": " by big softmax vector over words. In continuous spaces we don't. So if I want to train a system", "tokens": [50364, 1002, 13, 400, 264, 1778, 307, 570, 294, 27706, 1002, 321, 458, 577, 281, 2906, 15697, 50848, 50848, 538, 955, 2787, 41167, 8062, 670, 2283, 13, 682, 10957, 7673, 321, 500, 380, 13, 407, 498, 286, 528, 281, 3847, 257, 1185, 51278, 51278, 281, 360, 960, 17630, 11, 286, 500, 380, 458, 577, 281, 2906, 257, 8482, 7316, 670, 51699, 51699], "temperature": 0.0, "avg_logprob": -0.1259273196023608, "compression_ratio": 1.5371428571428571, "no_speech_prob": 1.0449202818563208e-05}, {"id": 610, "seek": 331564, "start": 3333.92, "end": 3342.3399999999997, "text": " to do video prediction, I don't know how to represent a probability distribution over", "tokens": [50364, 1002, 13, 400, 264, 1778, 307, 570, 294, 27706, 1002, 321, 458, 577, 281, 2906, 15697, 50848, 50848, 538, 955, 2787, 41167, 8062, 670, 2283, 13, 682, 10957, 7673, 321, 500, 380, 13, 407, 498, 286, 528, 281, 3847, 257, 1185, 51278, 51278, 281, 360, 960, 17630, 11, 286, 500, 380, 458, 577, 281, 2906, 257, 8482, 7316, 670, 51699, 51699], "temperature": 0.0, "avg_logprob": -0.1259273196023608, "compression_ratio": 1.5371428571428571, "no_speech_prob": 1.0449202818563208e-05}, {"id": 611, "seek": 334234, "start": 3342.34, "end": 3355.32, "text": " multiple video frames. So here is another reason why we might want to use our supervised", "tokens": [50364, 3866, 960, 12083, 13, 407, 510, 307, 1071, 1778, 983, 321, 1062, 528, 281, 764, 527, 46533, 51013, 51013, 2539, 293, 2028, 365, 15697, 13, 400, 797, 11, 341, 307, 437, 28327, 78, 307, 1364, 322, 3654, 2357, 13, 51361, 51361, 467, 311, 264, 1186, 300, 321, 1116, 411, 281, 362, 11, 321, 1116, 411, 527, 8379, 281, 312, 1075, 281, 733, 295, 1778, 51601, 51601, 466, 264, 1002, 11, 6069, 437, 311, 516, 281, 1051, 13, 407, 286, 1907, 291, 949, 364, 1365, 689, 281, 312, 51833, 51833], "temperature": 0.0, "avg_logprob": -0.13282496064573854, "compression_ratio": 1.581896551724138, "no_speech_prob": 3.0695962777826935e-05}, {"id": 612, "seek": 334234, "start": 3355.32, "end": 3362.28, "text": " learning and deal with uncertainty. And again, this is what Alfredo is working on among others.", "tokens": [50364, 3866, 960, 12083, 13, 407, 510, 307, 1071, 1778, 983, 321, 1062, 528, 281, 764, 527, 46533, 51013, 51013, 2539, 293, 2028, 365, 15697, 13, 400, 797, 11, 341, 307, 437, 28327, 78, 307, 1364, 322, 3654, 2357, 13, 51361, 51361, 467, 311, 264, 1186, 300, 321, 1116, 411, 281, 362, 11, 321, 1116, 411, 527, 8379, 281, 312, 1075, 281, 733, 295, 1778, 51601, 51601, 466, 264, 1002, 11, 6069, 437, 311, 516, 281, 1051, 13, 407, 286, 1907, 291, 949, 364, 1365, 689, 281, 312, 51833, 51833], "temperature": 0.0, "avg_logprob": -0.13282496064573854, "compression_ratio": 1.581896551724138, "no_speech_prob": 3.0695962777826935e-05}, {"id": 613, "seek": 334234, "start": 3362.28, "end": 3367.08, "text": " It's the fact that we'd like to have, we'd like our machines to be able to kind of reason", "tokens": [50364, 3866, 960, 12083, 13, 407, 510, 307, 1071, 1778, 983, 321, 1062, 528, 281, 764, 527, 46533, 51013, 51013, 2539, 293, 2028, 365, 15697, 13, 400, 797, 11, 341, 307, 437, 28327, 78, 307, 1364, 322, 3654, 2357, 13, 51361, 51361, 467, 311, 264, 1186, 300, 321, 1116, 411, 281, 362, 11, 321, 1116, 411, 527, 8379, 281, 312, 1075, 281, 733, 295, 1778, 51601, 51601, 466, 264, 1002, 11, 6069, 437, 311, 516, 281, 1051, 13, 407, 286, 1907, 291, 949, 364, 1365, 689, 281, 312, 51833, 51833], "temperature": 0.0, "avg_logprob": -0.13282496064573854, "compression_ratio": 1.581896551724138, "no_speech_prob": 3.0695962777826935e-05}, {"id": 614, "seek": 334234, "start": 3367.08, "end": 3371.7200000000003, "text": " about the world, predict what's going to happen. So I told you before an example where to be", "tokens": [50364, 3866, 960, 12083, 13, 407, 510, 307, 1071, 1778, 983, 321, 1062, 528, 281, 764, 527, 46533, 51013, 51013, 2539, 293, 2028, 365, 15697, 13, 400, 797, 11, 341, 307, 437, 28327, 78, 307, 1364, 322, 3654, 2357, 13, 51361, 51361, 467, 311, 264, 1186, 300, 321, 1116, 411, 281, 362, 11, 321, 1116, 411, 527, 8379, 281, 312, 1075, 281, 733, 295, 1778, 51601, 51601, 466, 264, 1002, 11, 6069, 437, 311, 516, 281, 1051, 13, 407, 286, 1907, 291, 949, 364, 1365, 689, 281, 312, 51833, 51833], "temperature": 0.0, "avg_logprob": -0.13282496064573854, "compression_ratio": 1.581896551724138, "no_speech_prob": 3.0695962777826935e-05}, {"id": 615, "seek": 337172, "start": 3371.72, "end": 3375.8799999999997, "text": " able to build a machine that drives a car. It's probably a good idea to be able to predict", "tokens": [50364, 1075, 281, 1322, 257, 3479, 300, 11754, 257, 1032, 13, 467, 311, 1391, 257, 665, 1558, 281, 312, 1075, 281, 6069, 50572, 50572, 437, 5163, 926, 291, 366, 516, 281, 360, 13, 879, 1075, 281, 6069, 437, 428, 1032, 307, 516, 281, 360, 498, 50888, 50888, 291, 1190, 11, 291, 458, 11, 498, 291, 434, 4840, 2651, 257, 22316, 293, 291, 1261, 264, 5589, 281, 264, 558, 51044, 51044, 293, 291, 528, 281, 6069, 294, 7295, 300, 428, 1032, 307, 516, 281, 1190, 766, 264, 22316, 293, 291, 51200, 51200, 500, 380, 13, 509, 393, 11, 498, 291, 393, 6069, 300, 11, 291, 434, 406, 516, 281, 360, 309, 13, 1033, 30, 407, 498, 291, 362, 257, 51490, 51490, 665, 35521, 2316, 295, 264, 1002, 11, 257, 1185, 300, 486, 6069, 264, 958, 1785, 295, 264, 1002, 51696, 51696], "temperature": 0.0, "avg_logprob": -0.12356180502167831, "compression_ratio": 2.0381679389312977, "no_speech_prob": 4.682196959038265e-05}, {"id": 616, "seek": 337172, "start": 3375.8799999999997, "end": 3382.2, "text": " what cars around you are going to do. Be able to predict what your car is going to do if", "tokens": [50364, 1075, 281, 1322, 257, 3479, 300, 11754, 257, 1032, 13, 467, 311, 1391, 257, 665, 1558, 281, 312, 1075, 281, 6069, 50572, 50572, 437, 5163, 926, 291, 366, 516, 281, 360, 13, 879, 1075, 281, 6069, 437, 428, 1032, 307, 516, 281, 360, 498, 50888, 50888, 291, 1190, 11, 291, 458, 11, 498, 291, 434, 4840, 2651, 257, 22316, 293, 291, 1261, 264, 5589, 281, 264, 558, 51044, 51044, 293, 291, 528, 281, 6069, 294, 7295, 300, 428, 1032, 307, 516, 281, 1190, 766, 264, 22316, 293, 291, 51200, 51200, 500, 380, 13, 509, 393, 11, 498, 291, 393, 6069, 300, 11, 291, 434, 406, 516, 281, 360, 309, 13, 1033, 30, 407, 498, 291, 362, 257, 51490, 51490, 665, 35521, 2316, 295, 264, 1002, 11, 257, 1185, 300, 486, 6069, 264, 958, 1785, 295, 264, 1002, 51696, 51696], "temperature": 0.0, "avg_logprob": -0.12356180502167831, "compression_ratio": 2.0381679389312977, "no_speech_prob": 4.682196959038265e-05}, {"id": 617, "seek": 337172, "start": 3382.2, "end": 3385.3199999999997, "text": " you run, you know, if you're driving near a cliff and you turn the wheel to the right", "tokens": [50364, 1075, 281, 1322, 257, 3479, 300, 11754, 257, 1032, 13, 467, 311, 1391, 257, 665, 1558, 281, 312, 1075, 281, 6069, 50572, 50572, 437, 5163, 926, 291, 366, 516, 281, 360, 13, 879, 1075, 281, 6069, 437, 428, 1032, 307, 516, 281, 360, 498, 50888, 50888, 291, 1190, 11, 291, 458, 11, 498, 291, 434, 4840, 2651, 257, 22316, 293, 291, 1261, 264, 5589, 281, 264, 558, 51044, 51044, 293, 291, 528, 281, 6069, 294, 7295, 300, 428, 1032, 307, 516, 281, 1190, 766, 264, 22316, 293, 291, 51200, 51200, 500, 380, 13, 509, 393, 11, 498, 291, 393, 6069, 300, 11, 291, 434, 406, 516, 281, 360, 309, 13, 1033, 30, 407, 498, 291, 362, 257, 51490, 51490, 665, 35521, 2316, 295, 264, 1002, 11, 257, 1185, 300, 486, 6069, 264, 958, 1785, 295, 264, 1002, 51696, 51696], "temperature": 0.0, "avg_logprob": -0.12356180502167831, "compression_ratio": 2.0381679389312977, "no_speech_prob": 4.682196959038265e-05}, {"id": 618, "seek": 337172, "start": 3385.3199999999997, "end": 3388.4399999999996, "text": " and you want to predict in advance that your car is going to run off the cliff and you", "tokens": [50364, 1075, 281, 1322, 257, 3479, 300, 11754, 257, 1032, 13, 467, 311, 1391, 257, 665, 1558, 281, 312, 1075, 281, 6069, 50572, 50572, 437, 5163, 926, 291, 366, 516, 281, 360, 13, 879, 1075, 281, 6069, 437, 428, 1032, 307, 516, 281, 360, 498, 50888, 50888, 291, 1190, 11, 291, 458, 11, 498, 291, 434, 4840, 2651, 257, 22316, 293, 291, 1261, 264, 5589, 281, 264, 558, 51044, 51044, 293, 291, 528, 281, 6069, 294, 7295, 300, 428, 1032, 307, 516, 281, 1190, 766, 264, 22316, 293, 291, 51200, 51200, 500, 380, 13, 509, 393, 11, 498, 291, 393, 6069, 300, 11, 291, 434, 406, 516, 281, 360, 309, 13, 1033, 30, 407, 498, 291, 362, 257, 51490, 51490, 665, 35521, 2316, 295, 264, 1002, 11, 257, 1185, 300, 486, 6069, 264, 958, 1785, 295, 264, 1002, 51696, 51696], "temperature": 0.0, "avg_logprob": -0.12356180502167831, "compression_ratio": 2.0381679389312977, "no_speech_prob": 4.682196959038265e-05}, {"id": 619, "seek": 337172, "start": 3388.4399999999996, "end": 3394.24, "text": " don't. You can, if you can predict that, you're not going to do it. Okay? So if you have a", "tokens": [50364, 1075, 281, 1322, 257, 3479, 300, 11754, 257, 1032, 13, 467, 311, 1391, 257, 665, 1558, 281, 312, 1075, 281, 6069, 50572, 50572, 437, 5163, 926, 291, 366, 516, 281, 360, 13, 879, 1075, 281, 6069, 437, 428, 1032, 307, 516, 281, 360, 498, 50888, 50888, 291, 1190, 11, 291, 458, 11, 498, 291, 434, 4840, 2651, 257, 22316, 293, 291, 1261, 264, 5589, 281, 264, 558, 51044, 51044, 293, 291, 528, 281, 6069, 294, 7295, 300, 428, 1032, 307, 516, 281, 1190, 766, 264, 22316, 293, 291, 51200, 51200, 500, 380, 13, 509, 393, 11, 498, 291, 393, 6069, 300, 11, 291, 434, 406, 516, 281, 360, 309, 13, 1033, 30, 407, 498, 291, 362, 257, 51490, 51490, 665, 35521, 2316, 295, 264, 1002, 11, 257, 1185, 300, 486, 6069, 264, 958, 1785, 295, 264, 1002, 51696, 51696], "temperature": 0.0, "avg_logprob": -0.12356180502167831, "compression_ratio": 2.0381679389312977, "no_speech_prob": 4.682196959038265e-05}, {"id": 620, "seek": 337172, "start": 3394.24, "end": 3398.3599999999997, "text": " good predictive model of the world, a system that will predict the next state of the world", "tokens": [50364, 1075, 281, 1322, 257, 3479, 300, 11754, 257, 1032, 13, 467, 311, 1391, 257, 665, 1558, 281, 312, 1075, 281, 6069, 50572, 50572, 437, 5163, 926, 291, 366, 516, 281, 360, 13, 879, 1075, 281, 6069, 437, 428, 1032, 307, 516, 281, 360, 498, 50888, 50888, 291, 1190, 11, 291, 458, 11, 498, 291, 434, 4840, 2651, 257, 22316, 293, 291, 1261, 264, 5589, 281, 264, 558, 51044, 51044, 293, 291, 528, 281, 6069, 294, 7295, 300, 428, 1032, 307, 516, 281, 1190, 766, 264, 22316, 293, 291, 51200, 51200, 500, 380, 13, 509, 393, 11, 498, 291, 393, 6069, 300, 11, 291, 434, 406, 516, 281, 360, 309, 13, 1033, 30, 407, 498, 291, 362, 257, 51490, 51490, 665, 35521, 2316, 295, 264, 1002, 11, 257, 1185, 300, 486, 6069, 264, 958, 1785, 295, 264, 1002, 51696, 51696], "temperature": 0.0, "avg_logprob": -0.12356180502167831, "compression_ratio": 2.0381679389312977, "no_speech_prob": 4.682196959038265e-05}, {"id": 621, "seek": 339836, "start": 3398.36, "end": 3403.08, "text": " as a function of the current state of the world and the action you take, then you can", "tokens": [50364, 382, 257, 2445, 295, 264, 2190, 1785, 295, 264, 1002, 293, 264, 3069, 291, 747, 11, 550, 291, 393, 50600, 50600, 360, 11, 291, 393, 605, 5613, 2276, 13, 1033, 30, 1042, 11, 291, 643, 661, 6677, 281, 605, 5613, 2276, 13, 51050, 51050, 583, 286, 603, 808, 646, 281, 300, 13, 583, 797, 11, 341, 3485, 281, 6069, 307, 264, 12801, 295, 7599, 51472, 51472, 534, 13, 440, 1186, 300, 11, 291, 458, 11, 512, 4882, 366, 13232, 307, 570, 436, 534, 362, 51728, 51728], "temperature": 0.0, "avg_logprob": -0.12490020015022972, "compression_ratio": 1.7307692307692308, "no_speech_prob": 1.0782682693388779e-05}, {"id": 622, "seek": 339836, "start": 3403.08, "end": 3412.08, "text": " do, you can act intelligently. Okay? Well, you need other components to act intelligently.", "tokens": [50364, 382, 257, 2445, 295, 264, 2190, 1785, 295, 264, 1002, 293, 264, 3069, 291, 747, 11, 550, 291, 393, 50600, 50600, 360, 11, 291, 393, 605, 5613, 2276, 13, 1033, 30, 1042, 11, 291, 643, 661, 6677, 281, 605, 5613, 2276, 13, 51050, 51050, 583, 286, 603, 808, 646, 281, 300, 13, 583, 797, 11, 341, 3485, 281, 6069, 307, 264, 12801, 295, 7599, 51472, 51472, 534, 13, 440, 1186, 300, 11, 291, 458, 11, 512, 4882, 366, 13232, 307, 570, 436, 534, 362, 51728, 51728], "temperature": 0.0, "avg_logprob": -0.12490020015022972, "compression_ratio": 1.7307692307692308, "no_speech_prob": 1.0782682693388779e-05}, {"id": 623, "seek": 339836, "start": 3412.08, "end": 3420.52, "text": " But I'll come back to that. But again, this ability to predict is the essence of intelligence", "tokens": [50364, 382, 257, 2445, 295, 264, 2190, 1785, 295, 264, 1002, 293, 264, 3069, 291, 747, 11, 550, 291, 393, 50600, 50600, 360, 11, 291, 393, 605, 5613, 2276, 13, 1033, 30, 1042, 11, 291, 643, 661, 6677, 281, 605, 5613, 2276, 13, 51050, 51050, 583, 286, 603, 808, 646, 281, 300, 13, 583, 797, 11, 341, 3485, 281, 6069, 307, 264, 12801, 295, 7599, 51472, 51472, 534, 13, 440, 1186, 300, 11, 291, 458, 11, 512, 4882, 366, 13232, 307, 570, 436, 534, 362, 51728, 51728], "temperature": 0.0, "avg_logprob": -0.12490020015022972, "compression_ratio": 1.7307692307692308, "no_speech_prob": 1.0782682693388779e-05}, {"id": 624, "seek": 339836, "start": 3420.52, "end": 3425.6400000000003, "text": " really. The fact that, you know, some animals are intelligent is because they really have", "tokens": [50364, 382, 257, 2445, 295, 264, 2190, 1785, 295, 264, 1002, 293, 264, 3069, 291, 747, 11, 550, 291, 393, 50600, 50600, 360, 11, 291, 393, 605, 5613, 2276, 13, 1033, 30, 1042, 11, 291, 643, 661, 6677, 281, 605, 5613, 2276, 13, 51050, 51050, 583, 286, 603, 808, 646, 281, 300, 13, 583, 797, 11, 341, 3485, 281, 6069, 307, 264, 12801, 295, 7599, 51472, 51472, 534, 13, 440, 1186, 300, 11, 291, 458, 11, 512, 4882, 366, 13232, 307, 570, 436, 534, 362, 51728, 51728], "temperature": 0.0, "avg_logprob": -0.12490020015022972, "compression_ratio": 1.7307692307692308, "no_speech_prob": 1.0782682693388779e-05}, {"id": 625, "seek": 342564, "start": 3425.64, "end": 3431.56, "text": " a much better model of the world and they, as a consequence, are better at sort of acting", "tokens": [50364, 257, 709, 1101, 2316, 295, 264, 1002, 293, 436, 11, 382, 257, 18326, 11, 366, 1101, 412, 1333, 295, 6577, 50660, 50660, 322, 341, 1002, 281, 733, 295, 483, 264, 1874, 436, 528, 13, 407, 264, 1154, 365, 264, 1002, 307, 300, 51034, 51034, 264, 1002, 307, 406, 15957, 3142, 13, 1610, 11, 286, 914, 11, 1310, 309, 307, 15957, 3142, 11, 457, 321, 393, 380, 6069, 51268, 51268, 2293, 437, 311, 516, 281, 1051, 13, 407, 264, 1186, 300, 309, 307, 15957, 3142, 420, 406, 307, 28682, 13, 51568, 51568, 2621, 3567, 362, 257, 5567, 6042, 11, 527, 10807, 362, 257, 5567, 6042, 11, 293, 321, 393, 380, 2293, 51790, 51790], "temperature": 0.0, "avg_logprob": -0.1300386294983981, "compression_ratio": 1.8461538461538463, "no_speech_prob": 7.182708941400051e-06}, {"id": 626, "seek": 342564, "start": 3431.56, "end": 3439.04, "text": " on this world to kind of get the result they want. So the problem with the world is that", "tokens": [50364, 257, 709, 1101, 2316, 295, 264, 1002, 293, 436, 11, 382, 257, 18326, 11, 366, 1101, 412, 1333, 295, 6577, 50660, 50660, 322, 341, 1002, 281, 733, 295, 483, 264, 1874, 436, 528, 13, 407, 264, 1154, 365, 264, 1002, 307, 300, 51034, 51034, 264, 1002, 307, 406, 15957, 3142, 13, 1610, 11, 286, 914, 11, 1310, 309, 307, 15957, 3142, 11, 457, 321, 393, 380, 6069, 51268, 51268, 2293, 437, 311, 516, 281, 1051, 13, 407, 264, 1186, 300, 309, 307, 15957, 3142, 420, 406, 307, 28682, 13, 51568, 51568, 2621, 3567, 362, 257, 5567, 6042, 11, 527, 10807, 362, 257, 5567, 6042, 11, 293, 321, 393, 380, 2293, 51790, 51790], "temperature": 0.0, "avg_logprob": -0.1300386294983981, "compression_ratio": 1.8461538461538463, "no_speech_prob": 7.182708941400051e-06}, {"id": 627, "seek": 342564, "start": 3439.04, "end": 3443.72, "text": " the world is not deterministic. Or, I mean, maybe it is deterministic, but we can't predict", "tokens": [50364, 257, 709, 1101, 2316, 295, 264, 1002, 293, 436, 11, 382, 257, 18326, 11, 366, 1101, 412, 1333, 295, 6577, 50660, 50660, 322, 341, 1002, 281, 733, 295, 483, 264, 1874, 436, 528, 13, 407, 264, 1154, 365, 264, 1002, 307, 300, 51034, 51034, 264, 1002, 307, 406, 15957, 3142, 13, 1610, 11, 286, 914, 11, 1310, 309, 307, 15957, 3142, 11, 457, 321, 393, 380, 6069, 51268, 51268, 2293, 437, 311, 516, 281, 1051, 13, 407, 264, 1186, 300, 309, 307, 15957, 3142, 420, 406, 307, 28682, 13, 51568, 51568, 2621, 3567, 362, 257, 5567, 6042, 11, 527, 10807, 362, 257, 5567, 6042, 11, 293, 321, 393, 380, 2293, 51790, 51790], "temperature": 0.0, "avg_logprob": -0.1300386294983981, "compression_ratio": 1.8461538461538463, "no_speech_prob": 7.182708941400051e-06}, {"id": 628, "seek": 342564, "start": 3443.72, "end": 3449.72, "text": " exactly what's going to happen. So the fact that it is deterministic or not is irrelevant.", "tokens": [50364, 257, 709, 1101, 2316, 295, 264, 1002, 293, 436, 11, 382, 257, 18326, 11, 366, 1101, 412, 1333, 295, 6577, 50660, 50660, 322, 341, 1002, 281, 733, 295, 483, 264, 1874, 436, 528, 13, 407, 264, 1154, 365, 264, 1002, 307, 300, 51034, 51034, 264, 1002, 307, 406, 15957, 3142, 13, 1610, 11, 286, 914, 11, 1310, 309, 307, 15957, 3142, 11, 457, 321, 393, 380, 6069, 51268, 51268, 2293, 437, 311, 516, 281, 1051, 13, 407, 264, 1186, 300, 309, 307, 15957, 3142, 420, 406, 307, 28682, 13, 51568, 51568, 2621, 3567, 362, 257, 5567, 6042, 11, 527, 10807, 362, 257, 5567, 6042, 11, 293, 321, 393, 380, 2293, 51790, 51790], "temperature": 0.0, "avg_logprob": -0.1300386294983981, "compression_ratio": 1.8461538461538463, "no_speech_prob": 7.182708941400051e-06}, {"id": 629, "seek": 342564, "start": 3449.72, "end": 3454.16, "text": " Our brain have a limited capacity, our computers have a limited capacity, and we can't exactly", "tokens": [50364, 257, 709, 1101, 2316, 295, 264, 1002, 293, 436, 11, 382, 257, 18326, 11, 366, 1101, 412, 1333, 295, 6577, 50660, 50660, 322, 341, 1002, 281, 733, 295, 483, 264, 1874, 436, 528, 13, 407, 264, 1154, 365, 264, 1002, 307, 300, 51034, 51034, 264, 1002, 307, 406, 15957, 3142, 13, 1610, 11, 286, 914, 11, 1310, 309, 307, 15957, 3142, 11, 457, 321, 393, 380, 6069, 51268, 51268, 2293, 437, 311, 516, 281, 1051, 13, 407, 264, 1186, 300, 309, 307, 15957, 3142, 420, 406, 307, 28682, 13, 51568, 51568, 2621, 3567, 362, 257, 5567, 6042, 11, 527, 10807, 362, 257, 5567, 6042, 11, 293, 321, 393, 380, 2293, 51790, 51790], "temperature": 0.0, "avg_logprob": -0.1300386294983981, "compression_ratio": 1.8461538461538463, "no_speech_prob": 7.182708941400051e-06}, {"id": 630, "seek": 345416, "start": 3454.16, "end": 3459.7999999999997, "text": " predict what's going to happen. And so we need to be able to train our system, to train", "tokens": [50364, 6069, 437, 311, 516, 281, 1051, 13, 400, 370, 321, 643, 281, 312, 1075, 281, 3847, 527, 1185, 11, 281, 3847, 50646, 50646, 527, 15442, 11, 281, 3847, 527, 7318, 3652, 11, 281, 6069, 294, 264, 6814, 295, 15697, 13, 400, 300, 311, 50934, 50934, 264, 881, 2252, 1154, 300, 321, 643, 281, 5039, 965, 281, 652, 4776, 4205, 294, 51284, 51284, 7318, 13, 1012, 281, 3847, 264, 1185, 281, 652, 1090, 12, 18759, 21264, 833, 15697, 293, 2028, 365, 51556, 51556], "temperature": 0.0, "avg_logprob": -0.12295769509815034, "compression_ratio": 1.81, "no_speech_prob": 2.586303889984265e-05}, {"id": 631, "seek": 345416, "start": 3459.7999999999997, "end": 3465.56, "text": " our brains, to train our AI systems, to predict in the presence of uncertainty. And that's", "tokens": [50364, 6069, 437, 311, 516, 281, 1051, 13, 400, 370, 321, 643, 281, 312, 1075, 281, 3847, 527, 1185, 11, 281, 3847, 50646, 50646, 527, 15442, 11, 281, 3847, 527, 7318, 3652, 11, 281, 6069, 294, 264, 6814, 295, 15697, 13, 400, 300, 311, 50934, 50934, 264, 881, 2252, 1154, 300, 321, 643, 281, 5039, 965, 281, 652, 4776, 4205, 294, 51284, 51284, 7318, 13, 1012, 281, 3847, 264, 1185, 281, 652, 1090, 12, 18759, 21264, 833, 15697, 293, 2028, 365, 51556, 51556], "temperature": 0.0, "avg_logprob": -0.12295769509815034, "compression_ratio": 1.81, "no_speech_prob": 2.586303889984265e-05}, {"id": 632, "seek": 345416, "start": 3465.56, "end": 3472.56, "text": " the most difficult problem that we need to solve today to make significant progress in", "tokens": [50364, 6069, 437, 311, 516, 281, 1051, 13, 400, 370, 321, 643, 281, 312, 1075, 281, 3847, 527, 1185, 11, 281, 3847, 50646, 50646, 527, 15442, 11, 281, 3847, 527, 7318, 3652, 11, 281, 6069, 294, 264, 6814, 295, 15697, 13, 400, 300, 311, 50934, 50934, 264, 881, 2252, 1154, 300, 321, 643, 281, 5039, 965, 281, 652, 4776, 4205, 294, 51284, 51284, 7318, 13, 1012, 281, 3847, 264, 1185, 281, 652, 1090, 12, 18759, 21264, 833, 15697, 293, 2028, 365, 51556, 51556], "temperature": 0.0, "avg_logprob": -0.12295769509815034, "compression_ratio": 1.81, "no_speech_prob": 2.586303889984265e-05}, {"id": 633, "seek": 345416, "start": 3472.56, "end": 3478.0, "text": " AI. How to train the system to make high-dimensional predictions under uncertainty and deal with", "tokens": [50364, 6069, 437, 311, 516, 281, 1051, 13, 400, 370, 321, 643, 281, 312, 1075, 281, 3847, 527, 1185, 11, 281, 3847, 50646, 50646, 527, 15442, 11, 281, 3847, 527, 7318, 3652, 11, 281, 6069, 294, 264, 6814, 295, 15697, 13, 400, 300, 311, 50934, 50934, 264, 881, 2252, 1154, 300, 321, 643, 281, 5039, 965, 281, 652, 4776, 4205, 294, 51284, 51284, 7318, 13, 1012, 281, 3847, 264, 1185, 281, 652, 1090, 12, 18759, 21264, 833, 15697, 293, 2028, 365, 51556, 51556], "temperature": 0.0, "avg_logprob": -0.12295769509815034, "compression_ratio": 1.81, "no_speech_prob": 2.586303889984265e-05}, {"id": 634, "seek": 347800, "start": 3478.0, "end": 3495.48, "text": " this uncertainty. And as I said before, probabilistic models are basically hopeless. Okay, so let's", "tokens": [50364, 341, 15697, 13, 400, 382, 286, 848, 949, 11, 31959, 3142, 5245, 366, 1936, 27317, 13, 1033, 11, 370, 718, 311, 51238, 51238, 747, 364, 1365, 365, 960, 17630, 13, 1692, 366, 1451, 12083, 13, 708, 311, 264, 29357, 295, 51528, 51528, 729, 12083, 30, 407, 309, 311, 257, 707, 1152, 281, 536, 300, 264, 707, 2013, 307, 466, 281, 11, 411, 11, 6327, 51760, 51760], "temperature": 0.0, "avg_logprob": -0.16134891790502212, "compression_ratio": 1.4397905759162304, "no_speech_prob": 3.0237955797929317e-05}, {"id": 635, "seek": 347800, "start": 3495.48, "end": 3501.28, "text": " take an example with video prediction. Here are four frames. What's the continuation of", "tokens": [50364, 341, 15697, 13, 400, 382, 286, 848, 949, 11, 31959, 3142, 5245, 366, 1936, 27317, 13, 1033, 11, 370, 718, 311, 51238, 51238, 747, 364, 1365, 365, 960, 17630, 13, 1692, 366, 1451, 12083, 13, 708, 311, 264, 29357, 295, 51528, 51528, 729, 12083, 30, 407, 309, 311, 257, 707, 1152, 281, 536, 300, 264, 707, 2013, 307, 466, 281, 11, 411, 11, 6327, 51760, 51760], "temperature": 0.0, "avg_logprob": -0.16134891790502212, "compression_ratio": 1.4397905759162304, "no_speech_prob": 3.0237955797929317e-05}, {"id": 636, "seek": 347800, "start": 3501.28, "end": 3505.92, "text": " those frames? So it's a little hard to see that the little girl is about to, like, blow", "tokens": [50364, 341, 15697, 13, 400, 382, 286, 848, 949, 11, 31959, 3142, 5245, 366, 1936, 27317, 13, 1033, 11, 370, 718, 311, 51238, 51238, 747, 364, 1365, 365, 960, 17630, 13, 1692, 366, 1451, 12083, 13, 708, 311, 264, 29357, 295, 51528, 51528, 729, 12083, 30, 407, 309, 311, 257, 707, 1152, 281, 536, 300, 264, 707, 2013, 307, 466, 281, 11, 411, 11, 6327, 51760, 51760], "temperature": 0.0, "avg_logprob": -0.16134891790502212, "compression_ratio": 1.4397905759162304, "no_speech_prob": 3.0237955797929317e-05}, {"id": 637, "seek": 350592, "start": 3505.92, "end": 3514.16, "text": " on her birthday cake. And if you train a neural net with least square to make predictions,", "tokens": [50364, 322, 720, 6154, 5908, 13, 400, 498, 291, 3847, 257, 18161, 2533, 365, 1935, 3732, 281, 652, 21264, 11, 50776, 50776, 370, 291, 3847, 309, 322, 5383, 295, 2145, 295, 341, 2010, 11, 498, 406, 6803, 11, 341, 307, 264, 733, 50984, 50984, 295, 17630, 291, 483, 13, 4372, 37644, 13, 1545, 30, 440, 1185, 2644, 6069, 2293, 437, 311, 516, 51234, 51234, 281, 1051, 11, 370, 309, 6069, 82, 264, 4274, 295, 439, 264, 1944, 26071, 11, 597, 307, 264, 1151, 636, 51414, 51414, 281, 17522, 264, 8889, 6713, 13, 1033, 30, 400, 498, 291, 528, 1333, 295, 257, 2316, 3037, 295, 341, 11, 51778, 51778], "temperature": 0.0, "avg_logprob": -0.10819060649346868, "compression_ratio": 1.6666666666666667, "no_speech_prob": 1.3844047316524666e-05}, {"id": 638, "seek": 350592, "start": 3514.16, "end": 3518.32, "text": " so you train it on thousands of videos of this type, if not millions, this is the kind", "tokens": [50364, 322, 720, 6154, 5908, 13, 400, 498, 291, 3847, 257, 18161, 2533, 365, 1935, 3732, 281, 652, 21264, 11, 50776, 50776, 370, 291, 3847, 309, 322, 5383, 295, 2145, 295, 341, 2010, 11, 498, 406, 6803, 11, 341, 307, 264, 733, 50984, 50984, 295, 17630, 291, 483, 13, 4372, 37644, 13, 1545, 30, 440, 1185, 2644, 6069, 2293, 437, 311, 516, 51234, 51234, 281, 1051, 11, 370, 309, 6069, 82, 264, 4274, 295, 439, 264, 1944, 26071, 11, 597, 307, 264, 1151, 636, 51414, 51414, 281, 17522, 264, 8889, 6713, 13, 1033, 30, 400, 498, 291, 528, 1333, 295, 257, 2316, 3037, 295, 341, 11, 51778, 51778], "temperature": 0.0, "avg_logprob": -0.10819060649346868, "compression_ratio": 1.6666666666666667, "no_speech_prob": 1.3844047316524666e-05}, {"id": 639, "seek": 350592, "start": 3518.32, "end": 3523.32, "text": " of prediction you get. Very blurry. Why? The system cannot predict exactly what's going", "tokens": [50364, 322, 720, 6154, 5908, 13, 400, 498, 291, 3847, 257, 18161, 2533, 365, 1935, 3732, 281, 652, 21264, 11, 50776, 50776, 370, 291, 3847, 309, 322, 5383, 295, 2145, 295, 341, 2010, 11, 498, 406, 6803, 11, 341, 307, 264, 733, 50984, 50984, 295, 17630, 291, 483, 13, 4372, 37644, 13, 1545, 30, 440, 1185, 2644, 6069, 2293, 437, 311, 516, 51234, 51234, 281, 1051, 11, 370, 309, 6069, 82, 264, 4274, 295, 439, 264, 1944, 26071, 11, 597, 307, 264, 1151, 636, 51414, 51414, 281, 17522, 264, 8889, 6713, 13, 1033, 30, 400, 498, 291, 528, 1333, 295, 257, 2316, 3037, 295, 341, 11, 51778, 51778], "temperature": 0.0, "avg_logprob": -0.10819060649346868, "compression_ratio": 1.6666666666666667, "no_speech_prob": 1.3844047316524666e-05}, {"id": 640, "seek": 350592, "start": 3523.32, "end": 3526.92, "text": " to happen, so it predicts the average of all the possible futures, which is the best way", "tokens": [50364, 322, 720, 6154, 5908, 13, 400, 498, 291, 3847, 257, 18161, 2533, 365, 1935, 3732, 281, 652, 21264, 11, 50776, 50776, 370, 291, 3847, 309, 322, 5383, 295, 2145, 295, 341, 2010, 11, 498, 406, 6803, 11, 341, 307, 264, 733, 50984, 50984, 295, 17630, 291, 483, 13, 4372, 37644, 13, 1545, 30, 440, 1185, 2644, 6069, 2293, 437, 311, 516, 51234, 51234, 281, 1051, 11, 370, 309, 6069, 82, 264, 4274, 295, 439, 264, 1944, 26071, 11, 597, 307, 264, 1151, 636, 51414, 51414, 281, 17522, 264, 8889, 6713, 13, 1033, 30, 400, 498, 291, 528, 1333, 295, 257, 2316, 3037, 295, 341, 11, 51778, 51778], "temperature": 0.0, "avg_logprob": -0.10819060649346868, "compression_ratio": 1.6666666666666667, "no_speech_prob": 1.3844047316524666e-05}, {"id": 641, "seek": 350592, "start": 3526.92, "end": 3534.2000000000003, "text": " to minimize the squared error. Okay? And if you want sort of a model version of this,", "tokens": [50364, 322, 720, 6154, 5908, 13, 400, 498, 291, 3847, 257, 18161, 2533, 365, 1935, 3732, 281, 652, 21264, 11, 50776, 50776, 370, 291, 3847, 309, 322, 5383, 295, 2145, 295, 341, 2010, 11, 498, 406, 6803, 11, 341, 307, 264, 733, 50984, 50984, 295, 17630, 291, 483, 13, 4372, 37644, 13, 1545, 30, 440, 1185, 2644, 6069, 2293, 437, 311, 516, 51234, 51234, 281, 1051, 11, 370, 309, 6069, 82, 264, 4274, 295, 439, 264, 1944, 26071, 11, 597, 307, 264, 1151, 636, 51414, 51414, 281, 17522, 264, 8889, 6713, 13, 1033, 30, 400, 498, 291, 528, 1333, 295, 257, 2316, 3037, 295, 341, 11, 51778, 51778], "temperature": 0.0, "avg_logprob": -0.10819060649346868, "compression_ratio": 1.6666666666666667, "no_speech_prob": 1.3844047316524666e-05}, {"id": 642, "seek": 353420, "start": 3534.2, "end": 3539.0, "text": " let's say your entire training set consists of someone putting a pen on the table and", "tokens": [50364, 718, 311, 584, 428, 2302, 3097, 992, 14689, 295, 1580, 3372, 257, 3435, 322, 264, 3199, 293, 50604, 50604, 8295, 309, 352, 11, 293, 264, 954, 1009, 829, 264, 3435, 2293, 412, 264, 912, 1081, 264, 912, 636, 13, 50972, 50972, 583, 633, 565, 291, 360, 264, 5120, 11, 264, 3435, 8804, 666, 257, 819, 3513, 13, 407, 1936, 51278, 51278, 1783, 307, 264, 912, 337, 633, 3097, 6889, 11, 457, 398, 307, 819, 570, 264, 3435, 393, 2100, 294, 51550, 51550, 604, 3513, 11, 1391, 365, 257, 9452, 7316, 13, 407, 498, 291, 3847, 257, 18161, 2533, 281, 6069, 365, 51828, 51828], "temperature": 0.0, "avg_logprob": -0.1324211211431594, "compression_ratio": 1.7976190476190477, "no_speech_prob": 9.515868441667408e-06}, {"id": 643, "seek": 353420, "start": 3539.0, "end": 3546.3599999999997, "text": " letting it go, and the person always put the pen exactly at the same place the same way.", "tokens": [50364, 718, 311, 584, 428, 2302, 3097, 992, 14689, 295, 1580, 3372, 257, 3435, 322, 264, 3199, 293, 50604, 50604, 8295, 309, 352, 11, 293, 264, 954, 1009, 829, 264, 3435, 2293, 412, 264, 912, 1081, 264, 912, 636, 13, 50972, 50972, 583, 633, 565, 291, 360, 264, 5120, 11, 264, 3435, 8804, 666, 257, 819, 3513, 13, 407, 1936, 51278, 51278, 1783, 307, 264, 912, 337, 633, 3097, 6889, 11, 457, 398, 307, 819, 570, 264, 3435, 393, 2100, 294, 51550, 51550, 604, 3513, 11, 1391, 365, 257, 9452, 7316, 13, 407, 498, 291, 3847, 257, 18161, 2533, 281, 6069, 365, 51828, 51828], "temperature": 0.0, "avg_logprob": -0.1324211211431594, "compression_ratio": 1.7976190476190477, "no_speech_prob": 9.515868441667408e-06}, {"id": 644, "seek": 353420, "start": 3546.3599999999997, "end": 3552.48, "text": " But every time you do the experiment, the pen falls into a different direction. So basically", "tokens": [50364, 718, 311, 584, 428, 2302, 3097, 992, 14689, 295, 1580, 3372, 257, 3435, 322, 264, 3199, 293, 50604, 50604, 8295, 309, 352, 11, 293, 264, 954, 1009, 829, 264, 3435, 2293, 412, 264, 912, 1081, 264, 912, 636, 13, 50972, 50972, 583, 633, 565, 291, 360, 264, 5120, 11, 264, 3435, 8804, 666, 257, 819, 3513, 13, 407, 1936, 51278, 51278, 1783, 307, 264, 912, 337, 633, 3097, 6889, 11, 457, 398, 307, 819, 570, 264, 3435, 393, 2100, 294, 51550, 51550, 604, 3513, 11, 1391, 365, 257, 9452, 7316, 13, 407, 498, 291, 3847, 257, 18161, 2533, 281, 6069, 365, 51828, 51828], "temperature": 0.0, "avg_logprob": -0.1324211211431594, "compression_ratio": 1.7976190476190477, "no_speech_prob": 9.515868441667408e-06}, {"id": 645, "seek": 353420, "start": 3552.48, "end": 3557.9199999999996, "text": " X is the same for every training sample, but Y is different because the pen can fall in", "tokens": [50364, 718, 311, 584, 428, 2302, 3097, 992, 14689, 295, 1580, 3372, 257, 3435, 322, 264, 3199, 293, 50604, 50604, 8295, 309, 352, 11, 293, 264, 954, 1009, 829, 264, 3435, 2293, 412, 264, 912, 1081, 264, 912, 636, 13, 50972, 50972, 583, 633, 565, 291, 360, 264, 5120, 11, 264, 3435, 8804, 666, 257, 819, 3513, 13, 407, 1936, 51278, 51278, 1783, 307, 264, 912, 337, 633, 3097, 6889, 11, 457, 398, 307, 819, 570, 264, 3435, 393, 2100, 294, 51550, 51550, 604, 3513, 11, 1391, 365, 257, 9452, 7316, 13, 407, 498, 291, 3847, 257, 18161, 2533, 281, 6069, 365, 51828, 51828], "temperature": 0.0, "avg_logprob": -0.1324211211431594, "compression_ratio": 1.7976190476190477, "no_speech_prob": 9.515868441667408e-06}, {"id": 646, "seek": 353420, "start": 3557.9199999999996, "end": 3563.48, "text": " any direction, probably with a uniform distribution. So if you train a neural net to predict with", "tokens": [50364, 718, 311, 584, 428, 2302, 3097, 992, 14689, 295, 1580, 3372, 257, 3435, 322, 264, 3199, 293, 50604, 50604, 8295, 309, 352, 11, 293, 264, 954, 1009, 829, 264, 3435, 2293, 412, 264, 912, 1081, 264, 912, 636, 13, 50972, 50972, 583, 633, 565, 291, 360, 264, 5120, 11, 264, 3435, 8804, 666, 257, 819, 3513, 13, 407, 1936, 51278, 51278, 1783, 307, 264, 912, 337, 633, 3097, 6889, 11, 457, 398, 307, 819, 570, 264, 3435, 393, 2100, 294, 51550, 51550, 604, 3513, 11, 1391, 365, 257, 9452, 7316, 13, 407, 498, 291, 3847, 257, 18161, 2533, 281, 6069, 365, 51828, 51828], "temperature": 0.0, "avg_logprob": -0.1324211211431594, "compression_ratio": 1.7976190476190477, "no_speech_prob": 9.515868441667408e-06}, {"id": 647, "seek": 356348, "start": 3563.48, "end": 3567.92, "text": " least square, you'll get the average of all the possible predictions, which is a transparent", "tokens": [50364, 1935, 3732, 11, 291, 603, 483, 264, 4274, 295, 439, 264, 1944, 21264, 11, 597, 307, 257, 12737, 50586, 50586, 3435, 439, 926, 264, 6329, 11, 597, 307, 406, 257, 665, 17630, 13, 663, 311, 983, 291, 643, 48994, 51022, 51022, 7006, 5245, 13, 1033, 30, 407, 498, 291, 652, 257, 17630, 538, 264, 1185, 11, 457, 291, 362, 48994, 9102, 11, 51560, 51560, 597, 13330, 437, 291, 500, 380, 458, 466, 264, 1002, 13, 1033, 30, 407, 1783, 307, 437, 291, 458, 466, 264, 51788, 51788], "temperature": 0.0, "avg_logprob": -0.10828004258402278, "compression_ratio": 1.7464114832535884, "no_speech_prob": 6.747950465069152e-06}, {"id": 648, "seek": 356348, "start": 3567.92, "end": 3576.64, "text": " pen all around the circle, which is not a good prediction. That's why you need latent", "tokens": [50364, 1935, 3732, 11, 291, 603, 483, 264, 4274, 295, 439, 264, 1944, 21264, 11, 597, 307, 257, 12737, 50586, 50586, 3435, 439, 926, 264, 6329, 11, 597, 307, 406, 257, 665, 17630, 13, 663, 311, 983, 291, 643, 48994, 51022, 51022, 7006, 5245, 13, 1033, 30, 407, 498, 291, 652, 257, 17630, 538, 264, 1185, 11, 457, 291, 362, 48994, 9102, 11, 51560, 51560, 597, 13330, 437, 291, 500, 380, 458, 466, 264, 1002, 13, 1033, 30, 407, 1783, 307, 437, 291, 458, 466, 264, 51788, 51788], "temperature": 0.0, "avg_logprob": -0.10828004258402278, "compression_ratio": 1.7464114832535884, "no_speech_prob": 6.747950465069152e-06}, {"id": 649, "seek": 356348, "start": 3576.64, "end": 3587.4, "text": " variable models. Okay? So if you make a prediction by the system, but you have latent variables,", "tokens": [50364, 1935, 3732, 11, 291, 603, 483, 264, 4274, 295, 439, 264, 1944, 21264, 11, 597, 307, 257, 12737, 50586, 50586, 3435, 439, 926, 264, 6329, 11, 597, 307, 406, 257, 665, 17630, 13, 663, 311, 983, 291, 643, 48994, 51022, 51022, 7006, 5245, 13, 1033, 30, 407, 498, 291, 652, 257, 17630, 538, 264, 1185, 11, 457, 291, 362, 48994, 9102, 11, 51560, 51560, 597, 13330, 437, 291, 500, 380, 458, 466, 264, 1002, 13, 1033, 30, 407, 1783, 307, 437, 291, 458, 466, 264, 51788, 51788], "temperature": 0.0, "avg_logprob": -0.10828004258402278, "compression_ratio": 1.7464114832535884, "no_speech_prob": 6.747950465069152e-06}, {"id": 650, "seek": 356348, "start": 3587.4, "end": 3591.96, "text": " which indicate what you don't know about the world. Okay? So X is what you know about the", "tokens": [50364, 1935, 3732, 11, 291, 603, 483, 264, 4274, 295, 439, 264, 1944, 21264, 11, 597, 307, 257, 12737, 50586, 50586, 3435, 439, 926, 264, 6329, 11, 597, 307, 406, 257, 665, 17630, 13, 663, 311, 983, 291, 643, 48994, 51022, 51022, 7006, 5245, 13, 1033, 30, 407, 498, 291, 652, 257, 17630, 538, 264, 1185, 11, 457, 291, 362, 48994, 9102, 11, 51560, 51560, 597, 13330, 437, 291, 500, 380, 458, 466, 264, 1002, 13, 1033, 30, 407, 1783, 307, 437, 291, 458, 466, 264, 51788, 51788], "temperature": 0.0, "avg_logprob": -0.10828004258402278, "compression_ratio": 1.7464114832535884, "no_speech_prob": 6.747950465069152e-06}, {"id": 651, "seek": 359196, "start": 3591.96, "end": 3599.8, "text": " world. Here is the initial segment of the video of someone putting a pen. You know that", "tokens": [50364, 1002, 13, 1692, 307, 264, 5883, 9469, 295, 264, 960, 295, 1580, 3372, 257, 3435, 13, 509, 458, 300, 50756, 50756, 562, 264, 954, 30501, 264, 5984, 11, 264, 3435, 486, 2100, 11, 457, 291, 500, 380, 458, 294, 597, 3513, 13, 50966, 50966, 407, 437, 291, 528, 264, 1185, 281, 980, 291, 307, 264, 6069, 284, 510, 300, 1709, 490, 1783, 281, 389, 13, 51232, 51232, 389, 820, 312, 257, 10290, 300, 5112, 291, 264, 3435, 307, 516, 281, 312, 322, 264, 3199, 11, 457, 286, 51486, 51486, 393, 380, 980, 291, 294, 597, 3513, 13, 400, 550, 1176, 486, 362, 264, 40705, 7006, 13, 1692, 51710, 51710], "temperature": 0.0, "avg_logprob": -0.08595635869481542, "compression_ratio": 1.71875, "no_speech_prob": 2.0784582375199534e-05}, {"id": 652, "seek": 359196, "start": 3599.8, "end": 3604.0, "text": " when the person lifts the finger, the pen will fall, but you don't know in which direction.", "tokens": [50364, 1002, 13, 1692, 307, 264, 5883, 9469, 295, 264, 960, 295, 1580, 3372, 257, 3435, 13, 509, 458, 300, 50756, 50756, 562, 264, 954, 30501, 264, 5984, 11, 264, 3435, 486, 2100, 11, 457, 291, 500, 380, 458, 294, 597, 3513, 13, 50966, 50966, 407, 437, 291, 528, 264, 1185, 281, 980, 291, 307, 264, 6069, 284, 510, 300, 1709, 490, 1783, 281, 389, 13, 51232, 51232, 389, 820, 312, 257, 10290, 300, 5112, 291, 264, 3435, 307, 516, 281, 312, 322, 264, 3199, 11, 457, 286, 51486, 51486, 393, 380, 980, 291, 294, 597, 3513, 13, 400, 550, 1176, 486, 362, 264, 40705, 7006, 13, 1692, 51710, 51710], "temperature": 0.0, "avg_logprob": -0.08595635869481542, "compression_ratio": 1.71875, "no_speech_prob": 2.0784582375199534e-05}, {"id": 653, "seek": 359196, "start": 3604.0, "end": 3609.32, "text": " So what you want the system to tell you is the predictor here that goes from X to H.", "tokens": [50364, 1002, 13, 1692, 307, 264, 5883, 9469, 295, 264, 960, 295, 1580, 3372, 257, 3435, 13, 509, 458, 300, 50756, 50756, 562, 264, 954, 30501, 264, 5984, 11, 264, 3435, 486, 2100, 11, 457, 291, 500, 380, 458, 294, 597, 3513, 13, 50966, 50966, 407, 437, 291, 528, 264, 1185, 281, 980, 291, 307, 264, 6069, 284, 510, 300, 1709, 490, 1783, 281, 389, 13, 51232, 51232, 389, 820, 312, 257, 10290, 300, 5112, 291, 264, 3435, 307, 516, 281, 312, 322, 264, 3199, 11, 457, 286, 51486, 51486, 393, 380, 980, 291, 294, 597, 3513, 13, 400, 550, 1176, 486, 362, 264, 40705, 7006, 13, 1692, 51710, 51710], "temperature": 0.0, "avg_logprob": -0.08595635869481542, "compression_ratio": 1.71875, "no_speech_prob": 2.0784582375199534e-05}, {"id": 654, "seek": 359196, "start": 3609.32, "end": 3614.4, "text": " H should be a representation that tells you the pen is going to be on the table, but I", "tokens": [50364, 1002, 13, 1692, 307, 264, 5883, 9469, 295, 264, 960, 295, 1580, 3372, 257, 3435, 13, 509, 458, 300, 50756, 50756, 562, 264, 954, 30501, 264, 5984, 11, 264, 3435, 486, 2100, 11, 457, 291, 500, 380, 458, 294, 597, 3513, 13, 50966, 50966, 407, 437, 291, 528, 264, 1185, 281, 980, 291, 307, 264, 6069, 284, 510, 300, 1709, 490, 1783, 281, 389, 13, 51232, 51232, 389, 820, 312, 257, 10290, 300, 5112, 291, 264, 3435, 307, 516, 281, 312, 322, 264, 3199, 11, 457, 286, 51486, 51486, 393, 380, 980, 291, 294, 597, 3513, 13, 400, 550, 1176, 486, 362, 264, 40705, 7006, 13, 1692, 51710, 51710], "temperature": 0.0, "avg_logprob": -0.08595635869481542, "compression_ratio": 1.71875, "no_speech_prob": 2.0784582375199534e-05}, {"id": 655, "seek": 359196, "start": 3614.4, "end": 3618.88, "text": " can't tell you in which direction. And then Z will have the complementary variable. Here", "tokens": [50364, 1002, 13, 1692, 307, 264, 5883, 9469, 295, 264, 960, 295, 1580, 3372, 257, 3435, 13, 509, 458, 300, 50756, 50756, 562, 264, 954, 30501, 264, 5984, 11, 264, 3435, 486, 2100, 11, 457, 291, 500, 380, 458, 294, 597, 3513, 13, 50966, 50966, 407, 437, 291, 528, 264, 1185, 281, 980, 291, 307, 264, 6069, 284, 510, 300, 1709, 490, 1783, 281, 389, 13, 51232, 51232, 389, 820, 312, 257, 10290, 300, 5112, 291, 264, 3435, 307, 516, 281, 312, 322, 264, 3199, 11, 457, 286, 51486, 51486, 393, 380, 980, 291, 294, 597, 3513, 13, 400, 550, 1176, 486, 362, 264, 40705, 7006, 13, 1692, 51710, 51710], "temperature": 0.0, "avg_logprob": -0.08595635869481542, "compression_ratio": 1.71875, "no_speech_prob": 2.0784582375199534e-05}, {"id": 656, "seek": 361888, "start": 3618.88, "end": 3622.96, "text": " is the direction in which the pen actually fell. And then the combination of those two", "tokens": [50364, 307, 264, 3513, 294, 597, 264, 3435, 767, 5696, 13, 400, 550, 264, 6562, 295, 729, 732, 50568, 50568, 3755, 295, 1589, 11, 264, 1507, 291, 393, 8947, 490, 264, 14816, 293, 264, 1507, 291, 2644, 11, 50788, 50788, 2709, 291, 264, 17630, 398, 2159, 11, 597, 4696, 307, 1998, 281, 437, 767, 11843, 13, 1033, 30, 407, 51296, 51296, 264, 636, 291, 764, 746, 411, 341, 11, 291, 500, 380, 764, 309, 337, 485, 286, 914, 11, 498, 291, 528, 281, 764, 309, 51758, 51758], "temperature": 0.0, "avg_logprob": -0.1254879669709639, "compression_ratio": 1.6774193548387097, "no_speech_prob": 9.223279448633548e-06}, {"id": 657, "seek": 361888, "start": 3622.96, "end": 3627.36, "text": " pieces of information, the stuff you can extract from the observation and the stuff you cannot,", "tokens": [50364, 307, 264, 3513, 294, 597, 264, 3435, 767, 5696, 13, 400, 550, 264, 6562, 295, 729, 732, 50568, 50568, 3755, 295, 1589, 11, 264, 1507, 291, 393, 8947, 490, 264, 14816, 293, 264, 1507, 291, 2644, 11, 50788, 50788, 2709, 291, 264, 17630, 398, 2159, 11, 597, 4696, 307, 1998, 281, 437, 767, 11843, 13, 1033, 30, 407, 51296, 51296, 264, 636, 291, 764, 746, 411, 341, 11, 291, 500, 380, 764, 309, 337, 485, 286, 914, 11, 498, 291, 528, 281, 764, 309, 51758, 51758], "temperature": 0.0, "avg_logprob": -0.1254879669709639, "compression_ratio": 1.6774193548387097, "no_speech_prob": 9.223279448633548e-06}, {"id": 658, "seek": 361888, "start": 3627.36, "end": 3637.52, "text": " gives you the prediction Y bar, which hopefully is close to what actually occurs. Okay? So", "tokens": [50364, 307, 264, 3513, 294, 597, 264, 3435, 767, 5696, 13, 400, 550, 264, 6562, 295, 729, 732, 50568, 50568, 3755, 295, 1589, 11, 264, 1507, 291, 393, 8947, 490, 264, 14816, 293, 264, 1507, 291, 2644, 11, 50788, 50788, 2709, 291, 264, 17630, 398, 2159, 11, 597, 4696, 307, 1998, 281, 437, 767, 11843, 13, 1033, 30, 407, 51296, 51296, 264, 636, 291, 764, 746, 411, 341, 11, 291, 500, 380, 764, 309, 337, 485, 286, 914, 11, 498, 291, 528, 281, 764, 309, 51758, 51758], "temperature": 0.0, "avg_logprob": -0.1254879669709639, "compression_ratio": 1.6774193548387097, "no_speech_prob": 9.223279448633548e-06}, {"id": 659, "seek": 361888, "start": 3637.52, "end": 3646.76, "text": " the way you use something like this, you don't use it for... I mean, if you want to use it", "tokens": [50364, 307, 264, 3513, 294, 597, 264, 3435, 767, 5696, 13, 400, 550, 264, 6562, 295, 729, 732, 50568, 50568, 3755, 295, 1589, 11, 264, 1507, 291, 393, 8947, 490, 264, 14816, 293, 264, 1507, 291, 2644, 11, 50788, 50788, 2709, 291, 264, 17630, 398, 2159, 11, 597, 4696, 307, 1998, 281, 437, 767, 11843, 13, 1033, 30, 407, 51296, 51296, 264, 636, 291, 764, 746, 411, 341, 11, 291, 500, 380, 764, 309, 337, 485, 286, 914, 11, 498, 291, 528, 281, 764, 309, 51758, 51758], "temperature": 0.0, "avg_logprob": -0.1254879669709639, "compression_ratio": 1.6774193548387097, "no_speech_prob": 9.223279448633548e-06}, {"id": 660, "seek": 364676, "start": 3646.76, "end": 3654.2400000000002, "text": " to kind of rate a particular scenario, you give it X, you give it Y, and then you ask", "tokens": [50364, 281, 733, 295, 3314, 257, 1729, 9005, 11, 291, 976, 309, 1783, 11, 291, 976, 309, 398, 11, 293, 550, 291, 1029, 50738, 50738, 309, 437, 311, 264, 2158, 295, 264, 1176, 7006, 300, 4464, 5660, 264, 17630, 6713, 294, 452, 2316, 13, 51134, 51134, 400, 550, 264, 16505, 17630, 6713, 307, 264, 2281, 293, 309, 311, 577, 291, 2316, 3314, 264, 51420, 51420], "temperature": 0.0, "avg_logprob": -0.0934542381402218, "compression_ratio": 1.6226415094339623, "no_speech_prob": 1.3005825167056173e-05}, {"id": 661, "seek": 364676, "start": 3654.2400000000002, "end": 3662.1600000000003, "text": " it what's the value of the Z variable that minimizes the prediction error in my model.", "tokens": [50364, 281, 733, 295, 3314, 257, 1729, 9005, 11, 291, 976, 309, 1783, 11, 291, 976, 309, 398, 11, 293, 550, 291, 1029, 50738, 50738, 309, 437, 311, 264, 2158, 295, 264, 1176, 7006, 300, 4464, 5660, 264, 17630, 6713, 294, 452, 2316, 13, 51134, 51134, 400, 550, 264, 16505, 17630, 6713, 307, 264, 2281, 293, 309, 311, 577, 291, 2316, 3314, 264, 51420, 51420], "temperature": 0.0, "avg_logprob": -0.0934542381402218, "compression_ratio": 1.6226415094339623, "no_speech_prob": 1.3005825167056173e-05}, {"id": 662, "seek": 364676, "start": 3662.1600000000003, "end": 3667.88, "text": " And then the resulting prediction error is the energy and it's how you model rate the", "tokens": [50364, 281, 733, 295, 3314, 257, 1729, 9005, 11, 291, 976, 309, 1783, 11, 291, 976, 309, 398, 11, 293, 550, 291, 1029, 50738, 50738, 309, 437, 311, 264, 2158, 295, 264, 1176, 7006, 300, 4464, 5660, 264, 17630, 6713, 294, 452, 2316, 13, 51134, 51134, 400, 550, 264, 16505, 17630, 6713, 307, 264, 2281, 293, 309, 311, 577, 291, 2316, 3314, 264, 51420, 51420], "temperature": 0.0, "avg_logprob": -0.0934542381402218, "compression_ratio": 1.6226415094339623, "no_speech_prob": 1.3005825167056173e-05}, {"id": 663, "seek": 366788, "start": 3667.88, "end": 3676.8, "text": " compatibility between X and Y. If you want to predict Ys, what you have to do is you", "tokens": [50364, 34237, 1296, 1783, 293, 398, 13, 759, 291, 528, 281, 6069, 398, 82, 11, 437, 291, 362, 281, 360, 307, 291, 50810, 50810, 11441, 1783, 293, 550, 291, 733, 295, 3055, 493, 257, 2158, 295, 398, 1951, 257, 1629, 9274, 293, 300, 51132, 51132, 14725, 257, 398, 2159, 13, 400, 550, 3055, 493, 1071, 2158, 295, 1176, 293, 300, 486, 5258, 1071, 398, 51462, 51462, 2159, 13, 400, 291, 393, 5258, 257, 1379, 992, 295, 398, 10228, 538, 733, 295, 6316, 3866, 4190, 295, 51724, 51724], "temperature": 0.0, "avg_logprob": -0.09173501621593129, "compression_ratio": 1.7628865979381443, "no_speech_prob": 1.221864567924058e-05}, {"id": 664, "seek": 366788, "start": 3676.8, "end": 3683.2400000000002, "text": " observe X and then you kind of dream up a value of Y within a certain domain and that", "tokens": [50364, 34237, 1296, 1783, 293, 398, 13, 759, 291, 528, 281, 6069, 398, 82, 11, 437, 291, 362, 281, 360, 307, 291, 50810, 50810, 11441, 1783, 293, 550, 291, 733, 295, 3055, 493, 257, 2158, 295, 398, 1951, 257, 1629, 9274, 293, 300, 51132, 51132, 14725, 257, 398, 2159, 13, 400, 550, 3055, 493, 1071, 2158, 295, 1176, 293, 300, 486, 5258, 1071, 398, 51462, 51462, 2159, 13, 400, 291, 393, 5258, 257, 1379, 992, 295, 398, 10228, 538, 733, 295, 6316, 3866, 4190, 295, 51724, 51724], "temperature": 0.0, "avg_logprob": -0.09173501621593129, "compression_ratio": 1.7628865979381443, "no_speech_prob": 1.221864567924058e-05}, {"id": 665, "seek": 366788, "start": 3683.2400000000002, "end": 3689.84, "text": " produces a Y bar. And then dream up another value of Z and that will produce another Y", "tokens": [50364, 34237, 1296, 1783, 293, 398, 13, 759, 291, 528, 281, 6069, 398, 82, 11, 437, 291, 362, 281, 360, 307, 291, 50810, 50810, 11441, 1783, 293, 550, 291, 733, 295, 3055, 493, 257, 2158, 295, 398, 1951, 257, 1629, 9274, 293, 300, 51132, 51132, 14725, 257, 398, 2159, 13, 400, 550, 3055, 493, 1071, 2158, 295, 1176, 293, 300, 486, 5258, 1071, 398, 51462, 51462, 2159, 13, 400, 291, 393, 5258, 257, 1379, 992, 295, 398, 10228, 538, 733, 295, 6316, 3866, 4190, 295, 51724, 51724], "temperature": 0.0, "avg_logprob": -0.09173501621593129, "compression_ratio": 1.7628865979381443, "no_speech_prob": 1.221864567924058e-05}, {"id": 666, "seek": 366788, "start": 3689.84, "end": 3695.08, "text": " bar. And you can produce a whole set of Y bars by kind of drawing multiple values of", "tokens": [50364, 34237, 1296, 1783, 293, 398, 13, 759, 291, 528, 281, 6069, 398, 82, 11, 437, 291, 362, 281, 360, 307, 291, 50810, 50810, 11441, 1783, 293, 550, 291, 733, 295, 3055, 493, 257, 2158, 295, 398, 1951, 257, 1629, 9274, 293, 300, 51132, 51132, 14725, 257, 398, 2159, 13, 400, 550, 3055, 493, 1071, 2158, 295, 1176, 293, 300, 486, 5258, 1071, 398, 51462, 51462, 2159, 13, 400, 291, 393, 5258, 257, 1379, 992, 295, 398, 10228, 538, 733, 295, 6316, 3866, 4190, 295, 51724, 51724], "temperature": 0.0, "avg_logprob": -0.09173501621593129, "compression_ratio": 1.7628865979381443, "no_speech_prob": 1.221864567924058e-05}, {"id": 667, "seek": 369508, "start": 3695.08, "end": 3700.08, "text": " Z within a set or within the distribution. Yes?", "tokens": [50364, 1176, 1951, 257, 992, 420, 1951, 264, 7316, 13, 1079, 30, 50614, 50614, 4402, 264, 4641, 295, 264, 960, 854, 30, 1436, 498, 291, 362, 411, 1266, 12083, 11, 550, 613, 13366, 51014, 51014, 12178, 295, 577, 264, 2975, 392, 3920, 486, 1051, 11, 550, 498, 291, 360, 700, 1326, 485, 51276, 51276, 1042, 370, 498, 437, 291, 434, 32884, 366, 264, 2027, 12083, 293, 437, 291, 434, 22107, 366, 51446, 51446, 264, 1791, 293, 2190, 3920, 11, 411, 5662, 485, 509, 914, 5662, 264, 1791, 12083, 300, 291, 434, 51756, 51756], "temperature": 0.0, "avg_logprob": -0.3634080683931391, "compression_ratio": 1.7236842105263157, "no_speech_prob": 2.7532383683137596e-05}, {"id": 668, "seek": 369508, "start": 3700.08, "end": 3708.08, "text": " Does the length of the video help? Because if you have like 10 frames, then these fewer", "tokens": [50364, 1176, 1951, 257, 992, 420, 1951, 264, 7316, 13, 1079, 30, 50614, 50614, 4402, 264, 4641, 295, 264, 960, 854, 30, 1436, 498, 291, 362, 411, 1266, 12083, 11, 550, 613, 13366, 51014, 51014, 12178, 295, 577, 264, 2975, 392, 3920, 486, 1051, 11, 550, 498, 291, 360, 700, 1326, 485, 51276, 51276, 1042, 370, 498, 437, 291, 434, 32884, 366, 264, 2027, 12083, 293, 437, 291, 434, 22107, 366, 51446, 51446, 264, 1791, 293, 2190, 3920, 11, 411, 5662, 485, 509, 914, 5662, 264, 1791, 12083, 300, 291, 434, 51756, 51756], "temperature": 0.0, "avg_logprob": -0.3634080683931391, "compression_ratio": 1.7236842105263157, "no_speech_prob": 2.7532383683137596e-05}, {"id": 669, "seek": 369508, "start": 3708.08, "end": 3713.3199999999997, "text": " possibilities of how the 11th frame will happen, then if you do first few...", "tokens": [50364, 1176, 1951, 257, 992, 420, 1951, 264, 7316, 13, 1079, 30, 50614, 50614, 4402, 264, 4641, 295, 264, 960, 854, 30, 1436, 498, 291, 362, 411, 1266, 12083, 11, 550, 613, 13366, 51014, 51014, 12178, 295, 577, 264, 2975, 392, 3920, 486, 1051, 11, 550, 498, 291, 360, 700, 1326, 485, 51276, 51276, 1042, 370, 498, 437, 291, 434, 32884, 366, 264, 2027, 12083, 293, 437, 291, 434, 22107, 366, 51446, 51446, 264, 1791, 293, 2190, 3920, 11, 411, 5662, 485, 509, 914, 5662, 264, 1791, 12083, 300, 291, 434, 51756, 51756], "temperature": 0.0, "avg_logprob": -0.3634080683931391, "compression_ratio": 1.7236842105263157, "no_speech_prob": 2.7532383683137596e-05}, {"id": 670, "seek": 369508, "start": 3713.3199999999997, "end": 3716.72, "text": " Well so if what you're predicting are the future frames and what you're observing are", "tokens": [50364, 1176, 1951, 257, 992, 420, 1951, 264, 7316, 13, 1079, 30, 50614, 50614, 4402, 264, 4641, 295, 264, 960, 854, 30, 1436, 498, 291, 362, 411, 1266, 12083, 11, 550, 613, 13366, 51014, 51014, 12178, 295, 577, 264, 2975, 392, 3920, 486, 1051, 11, 550, 498, 291, 360, 700, 1326, 485, 51276, 51276, 1042, 370, 498, 437, 291, 434, 32884, 366, 264, 2027, 12083, 293, 437, 291, 434, 22107, 366, 51446, 51446, 264, 1791, 293, 2190, 3920, 11, 411, 5662, 485, 509, 914, 5662, 264, 1791, 12083, 300, 291, 434, 51756, 51756], "temperature": 0.0, "avg_logprob": -0.3634080683931391, "compression_ratio": 1.7236842105263157, "no_speech_prob": 2.7532383683137596e-05}, {"id": 671, "seek": 369508, "start": 3716.72, "end": 3722.92, "text": " the past and current frame, like increasing... You mean increasing the past frames that you're", "tokens": [50364, 1176, 1951, 257, 992, 420, 1951, 264, 7316, 13, 1079, 30, 50614, 50614, 4402, 264, 4641, 295, 264, 960, 854, 30, 1436, 498, 291, 362, 411, 1266, 12083, 11, 550, 613, 13366, 51014, 51014, 12178, 295, 577, 264, 2975, 392, 3920, 486, 1051, 11, 550, 498, 291, 360, 700, 1326, 485, 51276, 51276, 1042, 370, 498, 437, 291, 434, 32884, 366, 264, 2027, 12083, 293, 437, 291, 434, 22107, 366, 51446, 51446, 264, 1791, 293, 2190, 3920, 11, 411, 5662, 485, 509, 914, 5662, 264, 1791, 12083, 300, 291, 434, 51756, 51756], "temperature": 0.0, "avg_logprob": -0.3634080683931391, "compression_ratio": 1.7236842105263157, "no_speech_prob": 2.7532383683137596e-05}, {"id": 672, "seek": 372292, "start": 3722.92, "end": 3727.28, "text": " looking at? A little bit, but you know after a while things are going to happen that really", "tokens": [50364, 1237, 412, 30, 316, 707, 857, 11, 457, 291, 458, 934, 257, 1339, 721, 366, 516, 281, 1051, 300, 534, 50582, 50582, 500, 380, 5672, 485, 286, 914, 264, 1589, 466, 437, 311, 516, 281, 1051, 294, 264, 2027, 534, 50774, 50774, 307, 406, 1974, 294, 264, 1791, 12083, 13, 1079, 30, 51024, 51024], "temperature": 0.0, "avg_logprob": -0.19727631977626256, "compression_ratio": 1.4666666666666666, "no_speech_prob": 6.603689689654857e-05}, {"id": 673, "seek": 372292, "start": 3727.28, "end": 3731.12, "text": " don't depend... I mean the information about what's going to happen in the future really", "tokens": [50364, 1237, 412, 30, 316, 707, 857, 11, 457, 291, 458, 934, 257, 1339, 721, 366, 516, 281, 1051, 300, 534, 50582, 50582, 500, 380, 5672, 485, 286, 914, 264, 1589, 466, 437, 311, 516, 281, 1051, 294, 264, 2027, 534, 50774, 50774, 307, 406, 1974, 294, 264, 1791, 12083, 13, 1079, 30, 51024, 51024], "temperature": 0.0, "avg_logprob": -0.19727631977626256, "compression_ratio": 1.4666666666666666, "no_speech_prob": 6.603689689654857e-05}, {"id": 674, "seek": 372292, "start": 3731.12, "end": 3736.12, "text": " is not present in the past frames. Yes?", "tokens": [50364, 1237, 412, 30, 316, 707, 857, 11, 457, 291, 458, 934, 257, 1339, 721, 366, 516, 281, 1051, 300, 534, 50582, 50582, 500, 380, 5672, 485, 286, 914, 264, 1589, 466, 437, 311, 516, 281, 1051, 294, 264, 2027, 534, 50774, 50774, 307, 406, 1974, 294, 264, 1791, 12083, 13, 1079, 30, 51024, 51024], "temperature": 0.0, "avg_logprob": -0.19727631977626256, "compression_ratio": 1.4666666666666666, "no_speech_prob": 6.603689689654857e-05}, {"id": 675, "seek": 373612, "start": 3736.12, "end": 3757.04, "text": " So in this particular case there would be variables that are necessary to make a good", "tokens": [50364, 407, 294, 341, 1729, 1389, 456, 576, 312, 9102, 300, 366, 4818, 281, 652, 257, 665, 51410, 51410, 17630, 11, 457, 264, 1589, 307, 406, 1974, 294, 1783, 13, 51664, 51664], "temperature": 0.0, "avg_logprob": -0.27974643129290955, "compression_ratio": 1.2660550458715596, "no_speech_prob": 0.0001792789262253791}, {"id": 676, "seek": 373612, "start": 3757.04, "end": 3762.12, "text": " prediction, but the information is not present in X.", "tokens": [50364, 407, 294, 341, 1729, 1389, 456, 576, 312, 9102, 300, 366, 4818, 281, 652, 257, 665, 51410, 51410, 17630, 11, 457, 264, 1589, 307, 406, 1974, 294, 1783, 13, 51664, 51664], "temperature": 0.0, "avg_logprob": -0.27974643129290955, "compression_ratio": 1.2660550458715596, "no_speech_prob": 0.0001792789262253791}, {"id": 677, "seek": 376212, "start": 3762.12, "end": 3768.7599999999998, "text": " Okay, so the question was, where's the role of Z really? Like you know does it implement", "tokens": [50364, 1033, 11, 370, 264, 1168, 390, 11, 689, 311, 264, 3090, 295, 1176, 534, 30, 1743, 291, 458, 775, 309, 4445, 50696, 50696, 264, 25534, 1296, 1783, 293, 398, 420, 746, 1646, 30, 400, 294, 341, 1729, 1365, 510, 50940, 50940, 300, 286, 4712, 11, 264, 48994, 7006, 485, 286, 4712, 2940, 5110, 11, 558, 30, 1485, 1365, 286, 4712, 51148, 51148, 307, 2517, 11150, 13, 759, 291, 2586, 689, 264, 4342, 366, 550, 264, 5633, 295, 18538, 51368, 51368, 264, 4342, 576, 312, 3571, 13, 400, 370, 538, 1455, 264, 38253, 466, 689, 264, 4342, 51534, 51534], "temperature": 0.0, "avg_logprob": -0.17581707000732422, "compression_ratio": 1.7403100775193798, "no_speech_prob": 4.538168286671862e-05}, {"id": 678, "seek": 376212, "start": 3768.7599999999998, "end": 3773.64, "text": " the constraint between X and Y or something else? And in this particular example here", "tokens": [50364, 1033, 11, 370, 264, 1168, 390, 11, 689, 311, 264, 3090, 295, 1176, 534, 30, 1743, 291, 458, 775, 309, 4445, 50696, 50696, 264, 25534, 1296, 1783, 293, 398, 420, 746, 1646, 30, 400, 294, 341, 1729, 1365, 510, 50940, 50940, 300, 286, 4712, 11, 264, 48994, 7006, 485, 286, 4712, 2940, 5110, 11, 558, 30, 1485, 1365, 286, 4712, 51148, 51148, 307, 2517, 11150, 13, 759, 291, 2586, 689, 264, 4342, 366, 550, 264, 5633, 295, 18538, 51368, 51368, 264, 4342, 576, 312, 3571, 13, 400, 370, 538, 1455, 264, 38253, 466, 689, 264, 4342, 51534, 51534], "temperature": 0.0, "avg_logprob": -0.17581707000732422, "compression_ratio": 1.7403100775193798, "no_speech_prob": 4.538168286671862e-05}, {"id": 679, "seek": 376212, "start": 3773.64, "end": 3777.7999999999997, "text": " that I showed, the latent variable... I showed several examples, right? One example I showed", "tokens": [50364, 1033, 11, 370, 264, 1168, 390, 11, 689, 311, 264, 3090, 295, 1176, 534, 30, 1743, 291, 458, 775, 309, 4445, 50696, 50696, 264, 25534, 1296, 1783, 293, 398, 420, 746, 1646, 30, 400, 294, 341, 1729, 1365, 510, 50940, 50940, 300, 286, 4712, 11, 264, 48994, 7006, 485, 286, 4712, 2940, 5110, 11, 558, 30, 1485, 1365, 286, 4712, 51148, 51148, 307, 2517, 11150, 13, 759, 291, 2586, 689, 264, 4342, 366, 550, 264, 5633, 295, 18538, 51368, 51368, 264, 4342, 576, 312, 3571, 13, 400, 370, 538, 1455, 264, 38253, 466, 689, 264, 4342, 51534, 51534], "temperature": 0.0, "avg_logprob": -0.17581707000732422, "compression_ratio": 1.7403100775193798, "no_speech_prob": 4.538168286671862e-05}, {"id": 680, "seek": 376212, "start": 3777.7999999999997, "end": 3782.2, "text": " is character recognition. If you knew where the characters are then the task of recognizing", "tokens": [50364, 1033, 11, 370, 264, 1168, 390, 11, 689, 311, 264, 3090, 295, 1176, 534, 30, 1743, 291, 458, 775, 309, 4445, 50696, 50696, 264, 25534, 1296, 1783, 293, 398, 420, 746, 1646, 30, 400, 294, 341, 1729, 1365, 510, 50940, 50940, 300, 286, 4712, 11, 264, 48994, 7006, 485, 286, 4712, 2940, 5110, 11, 558, 30, 1485, 1365, 286, 4712, 51148, 51148, 307, 2517, 11150, 13, 759, 291, 2586, 689, 264, 4342, 366, 550, 264, 5633, 295, 18538, 51368, 51368, 264, 4342, 576, 312, 3571, 13, 400, 370, 538, 1455, 264, 38253, 466, 689, 264, 4342, 51534, 51534], "temperature": 0.0, "avg_logprob": -0.17581707000732422, "compression_ratio": 1.7403100775193798, "no_speech_prob": 4.538168286671862e-05}, {"id": 681, "seek": 376212, "start": 3782.2, "end": 3785.52, "text": " the characters would be easier. And so by making the inference about where the characters", "tokens": [50364, 1033, 11, 370, 264, 1168, 390, 11, 689, 311, 264, 3090, 295, 1176, 534, 30, 1743, 291, 458, 775, 309, 4445, 50696, 50696, 264, 25534, 1296, 1783, 293, 398, 420, 746, 1646, 30, 400, 294, 341, 1729, 1365, 510, 50940, 50940, 300, 286, 4712, 11, 264, 48994, 7006, 485, 286, 4712, 2940, 5110, 11, 558, 30, 1485, 1365, 286, 4712, 51148, 51148, 307, 2517, 11150, 13, 759, 291, 2586, 689, 264, 4342, 366, 550, 264, 5633, 295, 18538, 51368, 51368, 264, 4342, 576, 312, 3571, 13, 400, 370, 538, 1455, 264, 38253, 466, 689, 264, 4342, 51534, 51534], "temperature": 0.0, "avg_logprob": -0.17581707000732422, "compression_ratio": 1.7403100775193798, "no_speech_prob": 4.538168286671862e-05}, {"id": 682, "seek": 378552, "start": 3785.52, "end": 3794.24, "text": " are, you sort of help your system. You build a system in such a way that it can use that.", "tokens": [50364, 366, 11, 291, 1333, 295, 854, 428, 1185, 13, 509, 1322, 257, 1185, 294, 1270, 257, 636, 300, 309, 393, 764, 300, 13, 50800, 50800, 682, 341, 1729, 1389, 510, 309, 311, 819, 13, 1692, 264, 3090, 295, 264, 48994, 7006, 307, 281, 50956, 50956, 1936, 13075, 1125, 264, 992, 295, 1944, 23930, 300, 393, 5160, 13, 400, 294, 264, 917, 437, 51236, 51236, 291, 528, 307, 1176, 281, 5304, 264, 1589, 466, 398, 300, 307, 406, 1974, 294, 1783, 13, 1033, 30, 407, 264, 1589, 51852, 51852], "temperature": 0.0, "avg_logprob": -0.11194292704264323, "compression_ratio": 1.6106194690265487, "no_speech_prob": 2.144030440831557e-05}, {"id": 683, "seek": 378552, "start": 3794.24, "end": 3797.36, "text": " In this particular case here it's different. Here the role of the latent variable is to", "tokens": [50364, 366, 11, 291, 1333, 295, 854, 428, 1185, 13, 509, 1322, 257, 1185, 294, 1270, 257, 636, 300, 309, 393, 764, 300, 13, 50800, 50800, 682, 341, 1729, 1389, 510, 309, 311, 819, 13, 1692, 264, 3090, 295, 264, 48994, 7006, 307, 281, 50956, 50956, 1936, 13075, 1125, 264, 992, 295, 1944, 23930, 300, 393, 5160, 13, 400, 294, 264, 917, 437, 51236, 51236, 291, 528, 307, 1176, 281, 5304, 264, 1589, 466, 398, 300, 307, 406, 1974, 294, 1783, 13, 1033, 30, 407, 264, 1589, 51852, 51852], "temperature": 0.0, "avg_logprob": -0.11194292704264323, "compression_ratio": 1.6106194690265487, "no_speech_prob": 2.144030440831557e-05}, {"id": 684, "seek": 378552, "start": 3797.36, "end": 3802.96, "text": " basically parameterize the set of possible outputs that can occur. And in the end what", "tokens": [50364, 366, 11, 291, 1333, 295, 854, 428, 1185, 13, 509, 1322, 257, 1185, 294, 1270, 257, 636, 300, 309, 393, 764, 300, 13, 50800, 50800, 682, 341, 1729, 1389, 510, 309, 311, 819, 13, 1692, 264, 3090, 295, 264, 48994, 7006, 307, 281, 50956, 50956, 1936, 13075, 1125, 264, 992, 295, 1944, 23930, 300, 393, 5160, 13, 400, 294, 264, 917, 437, 51236, 51236, 291, 528, 307, 1176, 281, 5304, 264, 1589, 466, 398, 300, 307, 406, 1974, 294, 1783, 13, 1033, 30, 407, 264, 1589, 51852, 51852], "temperature": 0.0, "avg_logprob": -0.11194292704264323, "compression_ratio": 1.6106194690265487, "no_speech_prob": 2.144030440831557e-05}, {"id": 685, "seek": 378552, "start": 3802.96, "end": 3815.28, "text": " you want is Z to contain the information about Y that is not present in X. Okay? So the information", "tokens": [50364, 366, 11, 291, 1333, 295, 854, 428, 1185, 13, 509, 1322, 257, 1185, 294, 1270, 257, 636, 300, 309, 393, 764, 300, 13, 50800, 50800, 682, 341, 1729, 1389, 510, 309, 311, 819, 13, 1692, 264, 3090, 295, 264, 48994, 7006, 307, 281, 50956, 50956, 1936, 13075, 1125, 264, 992, 295, 1944, 23930, 300, 393, 5160, 13, 400, 294, 264, 917, 437, 51236, 51236, 291, 528, 307, 1176, 281, 5304, 264, 1589, 466, 398, 300, 307, 406, 1974, 294, 1783, 13, 1033, 30, 407, 264, 1589, 51852, 51852], "temperature": 0.0, "avg_logprob": -0.11194292704264323, "compression_ratio": 1.6106194690265487, "no_speech_prob": 2.144030440831557e-05}, {"id": 686, "seek": 381528, "start": 3815.28, "end": 3820.6800000000003, "text": " about where I'm going to move next, am I going to move left or right, this is not present", "tokens": [50364, 466, 689, 286, 478, 516, 281, 1286, 958, 11, 669, 286, 516, 281, 1286, 1411, 420, 558, 11, 341, 307, 406, 1974, 50634, 50634, 294, 1340, 291, 393, 11441, 558, 586, 13, 467, 311, 1854, 452, 3567, 11, 291, 393, 980, 13, 50916, 50916, 821, 366, 3866, 2098, 295, 2390, 341, 48994, 7006, 11, 572, 30, 51230, 51230, 1079, 13, 286, 914, 558, 586, 510, 286, 478, 406, 11926, 1340, 661, 813, 291, 458, 11, 659, 1353, 87, 307, 257, 51488, 51488, 955, 18161, 2533, 293, 979, 5179, 302, 295, 389, 293, 1176, 307, 257, 955, 18161, 2533, 13, 51682, 51682], "temperature": 0.0, "avg_logprob": -0.31767243320502125, "compression_ratio": 1.6940639269406392, "no_speech_prob": 5.4755328164901584e-05}, {"id": 687, "seek": 381528, "start": 3820.6800000000003, "end": 3826.32, "text": " in anything you can observe right now. It's inside my brain, you can tell.", "tokens": [50364, 466, 689, 286, 478, 516, 281, 1286, 958, 11, 669, 286, 516, 281, 1286, 1411, 420, 558, 11, 341, 307, 406, 1974, 50634, 50634, 294, 1340, 291, 393, 11441, 558, 586, 13, 467, 311, 1854, 452, 3567, 11, 291, 393, 980, 13, 50916, 50916, 821, 366, 3866, 2098, 295, 2390, 341, 48994, 7006, 11, 572, 30, 51230, 51230, 1079, 13, 286, 914, 558, 586, 510, 286, 478, 406, 11926, 1340, 661, 813, 291, 458, 11, 659, 1353, 87, 307, 257, 51488, 51488, 955, 18161, 2533, 293, 979, 5179, 302, 295, 389, 293, 1176, 307, 257, 955, 18161, 2533, 13, 51682, 51682], "temperature": 0.0, "avg_logprob": -0.31767243320502125, "compression_ratio": 1.6940639269406392, "no_speech_prob": 5.4755328164901584e-05}, {"id": 688, "seek": 381528, "start": 3826.32, "end": 3832.6000000000004, "text": " There are multiple ways of building this latent variable, no?", "tokens": [50364, 466, 689, 286, 478, 516, 281, 1286, 958, 11, 669, 286, 516, 281, 1286, 1411, 420, 558, 11, 341, 307, 406, 1974, 50634, 50634, 294, 1340, 291, 393, 11441, 558, 586, 13, 467, 311, 1854, 452, 3567, 11, 291, 393, 980, 13, 50916, 50916, 821, 366, 3866, 2098, 295, 2390, 341, 48994, 7006, 11, 572, 30, 51230, 51230, 1079, 13, 286, 914, 558, 586, 510, 286, 478, 406, 11926, 1340, 661, 813, 291, 458, 11, 659, 1353, 87, 307, 257, 51488, 51488, 955, 18161, 2533, 293, 979, 5179, 302, 295, 389, 293, 1176, 307, 257, 955, 18161, 2533, 13, 51682, 51682], "temperature": 0.0, "avg_logprob": -0.31767243320502125, "compression_ratio": 1.6940639269406392, "no_speech_prob": 5.4755328164901584e-05}, {"id": 689, "seek": 381528, "start": 3832.6000000000004, "end": 3837.76, "text": " Yes. I mean right now here I'm not assuming anything other than you know, pretox is a", "tokens": [50364, 466, 689, 286, 478, 516, 281, 1286, 958, 11, 669, 286, 516, 281, 1286, 1411, 420, 558, 11, 341, 307, 406, 1974, 50634, 50634, 294, 1340, 291, 393, 11441, 558, 586, 13, 467, 311, 1854, 452, 3567, 11, 291, 393, 980, 13, 50916, 50916, 821, 366, 3866, 2098, 295, 2390, 341, 48994, 7006, 11, 572, 30, 51230, 51230, 1079, 13, 286, 914, 558, 586, 510, 286, 478, 406, 11926, 1340, 661, 813, 291, 458, 11, 659, 1353, 87, 307, 257, 51488, 51488, 955, 18161, 2533, 293, 979, 5179, 302, 295, 389, 293, 1176, 307, 257, 955, 18161, 2533, 13, 51682, 51682], "temperature": 0.0, "avg_logprob": -0.31767243320502125, "compression_ratio": 1.6940639269406392, "no_speech_prob": 5.4755328164901584e-05}, {"id": 690, "seek": 381528, "start": 3837.76, "end": 3841.6400000000003, "text": " big neural net and decovet of H and Z is a big neural net.", "tokens": [50364, 466, 689, 286, 478, 516, 281, 1286, 958, 11, 669, 286, 516, 281, 1286, 1411, 420, 558, 11, 341, 307, 406, 1974, 50634, 50634, 294, 1340, 291, 393, 11441, 558, 586, 13, 467, 311, 1854, 452, 3567, 11, 291, 393, 980, 13, 50916, 50916, 821, 366, 3866, 2098, 295, 2390, 341, 48994, 7006, 11, 572, 30, 51230, 51230, 1079, 13, 286, 914, 558, 586, 510, 286, 478, 406, 11926, 1340, 661, 813, 291, 458, 11, 659, 1353, 87, 307, 257, 51488, 51488, 955, 18161, 2533, 293, 979, 5179, 302, 295, 389, 293, 1176, 307, 257, 955, 18161, 2533, 13, 51682, 51682], "temperature": 0.0, "avg_logprob": -0.31767243320502125, "compression_ratio": 1.6940639269406392, "no_speech_prob": 5.4755328164901584e-05}, {"id": 691, "seek": 384164, "start": 3841.64, "end": 3858.64, "text": " I'll show you some more animation about this latent variable in multiple traditions.", "tokens": [50364, 286, 603, 855, 291, 512, 544, 9603, 466, 341, 48994, 7006, 294, 3866, 15643, 13, 51214, 51214, 1033, 13, 407, 341, 307, 1333, 295, 364, 1365, 11, 257, 25801, 295, 364, 2281, 9661, 689, 321, 600, 658, 257, 51862, 51862], "temperature": 0.0, "avg_logprob": -0.4819252377464658, "compression_ratio": 1.3185185185185184, "no_speech_prob": 0.00010520743671804667}, {"id": 692, "seek": 384164, "start": 3858.64, "end": 3871.6, "text": " Okay. So this is sort of an example, a visualization of an energy landscape where we've got a", "tokens": [50364, 286, 603, 855, 291, 512, 544, 9603, 466, 341, 48994, 7006, 294, 3866, 15643, 13, 51214, 51214, 1033, 13, 407, 341, 307, 1333, 295, 364, 1365, 11, 257, 25801, 295, 364, 2281, 9661, 689, 321, 600, 658, 257, 51862, 51862], "temperature": 0.0, "avg_logprob": -0.4819252377464658, "compression_ratio": 1.3185185185185184, "no_speech_prob": 0.00010520743671804667}, {"id": 693, "seek": 387160, "start": 3871.6, "end": 3876.48, "text": " we've trained a neural net basically to compute an energy function. Here it's not a neural", "tokens": [50364, 321, 600, 8895, 257, 18161, 2533, 1936, 281, 14722, 364, 2281, 2445, 13, 1692, 309, 311, 406, 257, 18161, 50608, 50608, 2533, 11, 309, 311, 257, 588, 2199, 551, 767, 13, 1407, 7983, 264, 33621, 1296, 732, 9102, 50924, 50924, 1783, 293, 398, 293, 264, 1412, 2793, 366, 2051, 341, 707, 25165, 510, 13, 407, 1412, 2793, 366, 733, 51129, 51129, 295, 3247, 15551, 48806, 2051, 341, 25165, 13, 400, 550, 321, 3847, 257, 1185, 281, 976, 2295, 2281, 51378, 51378], "temperature": 0.0, "avg_logprob": -0.15157130827386694, "compression_ratio": 1.6175115207373272, "no_speech_prob": 2.0139297703281045e-05}, {"id": 694, "seek": 387160, "start": 3876.48, "end": 3882.7999999999997, "text": " net, it's a very simple thing actually. To capture the dependency between two variables", "tokens": [50364, 321, 600, 8895, 257, 18161, 2533, 1936, 281, 14722, 364, 2281, 2445, 13, 1692, 309, 311, 406, 257, 18161, 50608, 50608, 2533, 11, 309, 311, 257, 588, 2199, 551, 767, 13, 1407, 7983, 264, 33621, 1296, 732, 9102, 50924, 50924, 1783, 293, 398, 293, 264, 1412, 2793, 366, 2051, 341, 707, 25165, 510, 13, 407, 1412, 2793, 366, 733, 51129, 51129, 295, 3247, 15551, 48806, 2051, 341, 25165, 13, 400, 550, 321, 3847, 257, 1185, 281, 976, 2295, 2281, 51378, 51378], "temperature": 0.0, "avg_logprob": -0.15157130827386694, "compression_ratio": 1.6175115207373272, "no_speech_prob": 2.0139297703281045e-05}, {"id": 695, "seek": 387160, "start": 3882.7999999999997, "end": 3886.9, "text": " X and Y and the data points are along this little spiral here. So data points are kind", "tokens": [50364, 321, 600, 8895, 257, 18161, 2533, 1936, 281, 14722, 364, 2281, 2445, 13, 1692, 309, 311, 406, 257, 18161, 50608, 50608, 2533, 11, 309, 311, 257, 588, 2199, 551, 767, 13, 1407, 7983, 264, 33621, 1296, 732, 9102, 50924, 50924, 1783, 293, 398, 293, 264, 1412, 2793, 366, 2051, 341, 707, 25165, 510, 13, 407, 1412, 2793, 366, 733, 51129, 51129, 295, 3247, 15551, 48806, 2051, 341, 25165, 13, 400, 550, 321, 3847, 257, 1185, 281, 976, 2295, 2281, 51378, 51378], "temperature": 0.0, "avg_logprob": -0.15157130827386694, "compression_ratio": 1.6175115207373272, "no_speech_prob": 2.0139297703281045e-05}, {"id": 696, "seek": 387160, "start": 3886.9, "end": 3891.88, "text": " of sampled uniformly along this spiral. And then we train a system to give low energy", "tokens": [50364, 321, 600, 8895, 257, 18161, 2533, 1936, 281, 14722, 364, 2281, 2445, 13, 1692, 309, 311, 406, 257, 18161, 50608, 50608, 2533, 11, 309, 311, 257, 588, 2199, 551, 767, 13, 1407, 7983, 264, 33621, 1296, 732, 9102, 50924, 50924, 1783, 293, 398, 293, 264, 1412, 2793, 366, 2051, 341, 707, 25165, 510, 13, 407, 1412, 2793, 366, 733, 51129, 51129, 295, 3247, 15551, 48806, 2051, 341, 25165, 13, 400, 550, 321, 3847, 257, 1185, 281, 976, 2295, 2281, 51378, 51378], "temperature": 0.0, "avg_logprob": -0.15157130827386694, "compression_ratio": 1.6175115207373272, "no_speech_prob": 2.0139297703281045e-05}, {"id": 697, "seek": 389188, "start": 3891.88, "end": 3903.32, "text": " to those points and high energy to everything else.", "tokens": [50364, 281, 729, 2793, 293, 1090, 2281, 281, 1203, 1646, 13, 50936, 50936, 823, 456, 311, 732, 6422, 13, 821, 307, 11, 341, 307, 1333, 295, 257, 27708, 11, 291, 727, 818, 27708, 51204, 51204, 2281, 2361, 2316, 689, 456, 307, 732, 6352, 295, 9102, 1783, 293, 398, 293, 291, 434, 1382, 281, 51528, 51528, 6069, 398, 490, 1783, 13, 583, 456, 311, 611, 1071, 1254, 295, 2281, 2361, 2316, 597, 366, 47916, 13, 51824, 51824], "temperature": 0.0, "avg_logprob": -0.19147818429129465, "compression_ratio": 1.6428571428571428, "no_speech_prob": 5.2551840781234205e-06}, {"id": 698, "seek": 389188, "start": 3903.32, "end": 3908.6800000000003, "text": " Now there's two forms. There is, this is sort of a conditional, you could call conditional", "tokens": [50364, 281, 729, 2793, 293, 1090, 2281, 281, 1203, 1646, 13, 50936, 50936, 823, 456, 311, 732, 6422, 13, 821, 307, 11, 341, 307, 1333, 295, 257, 27708, 11, 291, 727, 818, 27708, 51204, 51204, 2281, 2361, 2316, 689, 456, 307, 732, 6352, 295, 9102, 1783, 293, 398, 293, 291, 434, 1382, 281, 51528, 51528, 6069, 398, 490, 1783, 13, 583, 456, 311, 611, 1071, 1254, 295, 2281, 2361, 2316, 597, 366, 47916, 13, 51824, 51824], "temperature": 0.0, "avg_logprob": -0.19147818429129465, "compression_ratio": 1.6428571428571428, "no_speech_prob": 5.2551840781234205e-06}, {"id": 699, "seek": 389188, "start": 3908.6800000000003, "end": 3915.1600000000003, "text": " energy based model where there is two sets of variables X and Y and you're trying to", "tokens": [50364, 281, 729, 2793, 293, 1090, 2281, 281, 1203, 1646, 13, 50936, 50936, 823, 456, 311, 732, 6422, 13, 821, 307, 11, 341, 307, 1333, 295, 257, 27708, 11, 291, 727, 818, 27708, 51204, 51204, 2281, 2361, 2316, 689, 456, 307, 732, 6352, 295, 9102, 1783, 293, 398, 293, 291, 434, 1382, 281, 51528, 51528, 6069, 398, 490, 1783, 13, 583, 456, 311, 611, 1071, 1254, 295, 2281, 2361, 2316, 597, 366, 47916, 13, 51824, 51824], "temperature": 0.0, "avg_logprob": -0.19147818429129465, "compression_ratio": 1.6428571428571428, "no_speech_prob": 5.2551840781234205e-06}, {"id": 700, "seek": 389188, "start": 3915.1600000000003, "end": 3921.08, "text": " predict Y from X. But there's also another form of energy based model which are unconditional.", "tokens": [50364, 281, 729, 2793, 293, 1090, 2281, 281, 1203, 1646, 13, 50936, 50936, 823, 456, 311, 732, 6422, 13, 821, 307, 11, 341, 307, 1333, 295, 257, 27708, 11, 291, 727, 818, 27708, 51204, 51204, 2281, 2361, 2316, 689, 456, 307, 732, 6352, 295, 9102, 1783, 293, 398, 293, 291, 434, 1382, 281, 51528, 51528, 6069, 398, 490, 1783, 13, 583, 456, 311, 611, 1071, 1254, 295, 2281, 2361, 2316, 597, 366, 47916, 13, 51824, 51824], "temperature": 0.0, "avg_logprob": -0.19147818429129465, "compression_ratio": 1.6428571428571428, "no_speech_prob": 5.2551840781234205e-06}, {"id": 701, "seek": 392108, "start": 3921.08, "end": 3926.6, "text": " There's only a Y, no X. Okay. So you're trying to predict the mutual dependencies between", "tokens": [50364, 821, 311, 787, 257, 398, 11, 572, 1783, 13, 1033, 13, 407, 291, 434, 1382, 281, 6069, 264, 16917, 36606, 1296, 50640, 50640, 264, 3683, 6677, 295, 398, 11, 264, 7316, 295, 257, 398, 498, 291, 528, 13, 583, 456, 311, 572, 1783, 13, 1033, 13, 50978, 50978, 407, 341, 307, 746, 291, 576, 528, 281, 764, 498, 291, 528, 281, 584, 360, 3256, 5125, 34959, 15899, 11, 51258, 51258, 558, 30, 1610, 291, 528, 281, 445, 11, 291, 458, 11, 2316, 264, 16917, 36606, 1296, 721, 457, 51692, 51692], "temperature": 0.0, "avg_logprob": -0.17371052244435187, "compression_ratio": 1.721698113207547, "no_speech_prob": 1.0446875421621371e-05}, {"id": 702, "seek": 392108, "start": 3926.6, "end": 3933.36, "text": " the various components of Y, the distribution of a Y if you want. But there's no X. Okay.", "tokens": [50364, 821, 311, 787, 257, 398, 11, 572, 1783, 13, 1033, 13, 407, 291, 434, 1382, 281, 6069, 264, 16917, 36606, 1296, 50640, 50640, 264, 3683, 6677, 295, 398, 11, 264, 7316, 295, 257, 398, 498, 291, 528, 13, 583, 456, 311, 572, 1783, 13, 1033, 13, 50978, 50978, 407, 341, 307, 746, 291, 576, 528, 281, 764, 498, 291, 528, 281, 584, 360, 3256, 5125, 34959, 15899, 11, 51258, 51258, 558, 30, 1610, 291, 528, 281, 445, 11, 291, 458, 11, 2316, 264, 16917, 36606, 1296, 721, 457, 51692, 51692], "temperature": 0.0, "avg_logprob": -0.17371052244435187, "compression_ratio": 1.721698113207547, "no_speech_prob": 1.0446875421621371e-05}, {"id": 703, "seek": 392108, "start": 3933.36, "end": 3938.96, "text": " So this is something you would want to use if you want to say do image generation unconditionally,", "tokens": [50364, 821, 311, 787, 257, 398, 11, 572, 1783, 13, 1033, 13, 407, 291, 434, 1382, 281, 6069, 264, 16917, 36606, 1296, 50640, 50640, 264, 3683, 6677, 295, 398, 11, 264, 7316, 295, 257, 398, 498, 291, 528, 13, 583, 456, 311, 572, 1783, 13, 1033, 13, 50978, 50978, 407, 341, 307, 746, 291, 576, 528, 281, 764, 498, 291, 528, 281, 584, 360, 3256, 5125, 34959, 15899, 11, 51258, 51258, 558, 30, 1610, 291, 528, 281, 445, 11, 291, 458, 11, 2316, 264, 16917, 36606, 1296, 721, 457, 51692, 51692], "temperature": 0.0, "avg_logprob": -0.17371052244435187, "compression_ratio": 1.721698113207547, "no_speech_prob": 1.0446875421621371e-05}, {"id": 704, "seek": 392108, "start": 3938.96, "end": 3947.64, "text": " right? Or you want to just, you know, model the mutual dependencies between things but", "tokens": [50364, 821, 311, 787, 257, 398, 11, 572, 1783, 13, 1033, 13, 407, 291, 434, 1382, 281, 6069, 264, 16917, 36606, 1296, 50640, 50640, 264, 3683, 6677, 295, 398, 11, 264, 7316, 295, 257, 398, 498, 291, 528, 13, 583, 456, 311, 572, 1783, 13, 1033, 13, 50978, 50978, 407, 341, 307, 746, 291, 576, 528, 281, 764, 498, 291, 528, 281, 584, 360, 3256, 5125, 34959, 15899, 11, 51258, 51258, 558, 30, 1610, 291, 528, 281, 445, 11, 291, 458, 11, 2316, 264, 16917, 36606, 1296, 721, 457, 51692, 51692], "temperature": 0.0, "avg_logprob": -0.17371052244435187, "compression_ratio": 1.721698113207547, "no_speech_prob": 1.0446875421621371e-05}, {"id": 705, "seek": 394764, "start": 3947.64, "end": 3951.3199999999997, "text": " you don't know which, you don't know at any point if you're going to be able to observe", "tokens": [50364, 291, 500, 380, 458, 597, 11, 291, 500, 380, 458, 412, 604, 935, 498, 291, 434, 516, 281, 312, 1075, 281, 11441, 50548, 50548, 398, 16, 420, 398, 17, 420, 6022, 295, 552, 13, 440, 5221, 307, 264, 912, 534, 13, 1033, 13, 407, 577, 366, 321, 516, 281, 51336, 51336, 3847, 729, 2281, 2361, 2316, 30, 639, 307, 534, 689, 721, 1813, 1880, 13, 467, 311, 264, 51590, 51590, 1168, 295, 3097, 13, 407, 3097, 820, 360, 746, 411, 264, 707, 9603, 412, 264, 51844, 51844], "temperature": 0.0, "avg_logprob": -0.11815808328349939, "compression_ratio": 1.591743119266055, "no_speech_prob": 1.184224947792245e-05}, {"id": 706, "seek": 394764, "start": 3951.3199999999997, "end": 3967.08, "text": " Y1 or Y2 or none of them. The math is the same really. Okay. So how are we going to", "tokens": [50364, 291, 500, 380, 458, 597, 11, 291, 500, 380, 458, 412, 604, 935, 498, 291, 434, 516, 281, 312, 1075, 281, 11441, 50548, 50548, 398, 16, 420, 398, 17, 420, 6022, 295, 552, 13, 440, 5221, 307, 264, 912, 534, 13, 1033, 13, 407, 577, 366, 321, 516, 281, 51336, 51336, 3847, 729, 2281, 2361, 2316, 30, 639, 307, 534, 689, 721, 1813, 1880, 13, 467, 311, 264, 51590, 51590, 1168, 295, 3097, 13, 407, 3097, 820, 360, 746, 411, 264, 707, 9603, 412, 264, 51844, 51844], "temperature": 0.0, "avg_logprob": -0.11815808328349939, "compression_ratio": 1.591743119266055, "no_speech_prob": 1.184224947792245e-05}, {"id": 707, "seek": 394764, "start": 3967.08, "end": 3972.16, "text": " train those energy based model? This is really where things become interesting. It's the", "tokens": [50364, 291, 500, 380, 458, 597, 11, 291, 500, 380, 458, 412, 604, 935, 498, 291, 434, 516, 281, 312, 1075, 281, 11441, 50548, 50548, 398, 16, 420, 398, 17, 420, 6022, 295, 552, 13, 440, 5221, 307, 264, 912, 534, 13, 1033, 13, 407, 577, 366, 321, 516, 281, 51336, 51336, 3847, 729, 2281, 2361, 2316, 30, 639, 307, 534, 689, 721, 1813, 1880, 13, 467, 311, 264, 51590, 51590, 1168, 295, 3097, 13, 407, 3097, 820, 360, 746, 411, 264, 707, 9603, 412, 264, 51844, 51844], "temperature": 0.0, "avg_logprob": -0.11815808328349939, "compression_ratio": 1.591743119266055, "no_speech_prob": 1.184224947792245e-05}, {"id": 708, "seek": 394764, "start": 3972.16, "end": 3977.24, "text": " question of training. So training should do something like the little animation at the", "tokens": [50364, 291, 500, 380, 458, 597, 11, 291, 500, 380, 458, 412, 604, 935, 498, 291, 434, 516, 281, 312, 1075, 281, 11441, 50548, 50548, 398, 16, 420, 398, 17, 420, 6022, 295, 552, 13, 440, 5221, 307, 264, 912, 534, 13, 1033, 13, 407, 577, 366, 321, 516, 281, 51336, 51336, 3847, 729, 2281, 2361, 2316, 30, 639, 307, 534, 689, 721, 1813, 1880, 13, 467, 311, 264, 51590, 51590, 1168, 295, 3097, 13, 407, 3097, 820, 360, 746, 411, 264, 707, 9603, 412, 264, 51844, 51844], "temperature": 0.0, "avg_logprob": -0.11815808328349939, "compression_ratio": 1.591743119266055, "no_speech_prob": 1.184224947792245e-05}, {"id": 709, "seek": 397724, "start": 3977.24, "end": 3982.08, "text": " top here. It should kind of shape the energy function because our machine now is computes", "tokens": [50364, 1192, 510, 13, 467, 820, 733, 295, 3909, 264, 2281, 2445, 570, 527, 3479, 586, 307, 715, 1819, 50606, 50606, 364, 2281, 2445, 382, 257, 2445, 295, 1783, 293, 398, 13, 467, 820, 3909, 264, 2281, 2445, 294, 50804, 50804, 1270, 257, 636, 300, 264, 1412, 2793, 362, 3126, 2281, 813, 1203, 1646, 13, 1033, 13, 1436, 51120, 51120, 300, 311, 264, 636, 264, 38253, 307, 516, 281, 589, 13, 759, 264, 3006, 2158, 295, 398, 575, 3126, 2281, 51478, 51478, 813, 264, 18424, 4190, 295, 398, 550, 527, 38253, 9284, 300, 10704, 264, 2158, 295, 398, 300, 14725, 51704, 51704], "temperature": 0.0, "avg_logprob": -0.11506068590775277, "compression_ratio": 1.9270386266094421, "no_speech_prob": 1.777779107214883e-05}, {"id": 710, "seek": 397724, "start": 3982.08, "end": 3986.04, "text": " an energy function as a function of X and Y. It should shape the energy function in", "tokens": [50364, 1192, 510, 13, 467, 820, 733, 295, 3909, 264, 2281, 2445, 570, 527, 3479, 586, 307, 715, 1819, 50606, 50606, 364, 2281, 2445, 382, 257, 2445, 295, 1783, 293, 398, 13, 467, 820, 3909, 264, 2281, 2445, 294, 50804, 50804, 1270, 257, 636, 300, 264, 1412, 2793, 362, 3126, 2281, 813, 1203, 1646, 13, 1033, 13, 1436, 51120, 51120, 300, 311, 264, 636, 264, 38253, 307, 516, 281, 589, 13, 759, 264, 3006, 2158, 295, 398, 575, 3126, 2281, 51478, 51478, 813, 264, 18424, 4190, 295, 398, 550, 527, 38253, 9284, 300, 10704, 264, 2158, 295, 398, 300, 14725, 51704, 51704], "temperature": 0.0, "avg_logprob": -0.11506068590775277, "compression_ratio": 1.9270386266094421, "no_speech_prob": 1.777779107214883e-05}, {"id": 711, "seek": 397724, "start": 3986.04, "end": 3992.3599999999997, "text": " such a way that the data points have lower energy than everything else. Okay. Because", "tokens": [50364, 1192, 510, 13, 467, 820, 733, 295, 3909, 264, 2281, 2445, 570, 527, 3479, 586, 307, 715, 1819, 50606, 50606, 364, 2281, 2445, 382, 257, 2445, 295, 1783, 293, 398, 13, 467, 820, 3909, 264, 2281, 2445, 294, 50804, 50804, 1270, 257, 636, 300, 264, 1412, 2793, 362, 3126, 2281, 813, 1203, 1646, 13, 1033, 13, 1436, 51120, 51120, 300, 311, 264, 636, 264, 38253, 307, 516, 281, 589, 13, 759, 264, 3006, 2158, 295, 398, 575, 3126, 2281, 51478, 51478, 813, 264, 18424, 4190, 295, 398, 550, 527, 38253, 9284, 300, 10704, 264, 2158, 295, 398, 300, 14725, 51704, 51704], "temperature": 0.0, "avg_logprob": -0.11506068590775277, "compression_ratio": 1.9270386266094421, "no_speech_prob": 1.777779107214883e-05}, {"id": 712, "seek": 397724, "start": 3992.3599999999997, "end": 3999.52, "text": " that's the way the inference is going to work. If the correct value of Y has lower energy", "tokens": [50364, 1192, 510, 13, 467, 820, 733, 295, 3909, 264, 2281, 2445, 570, 527, 3479, 586, 307, 715, 1819, 50606, 50606, 364, 2281, 2445, 382, 257, 2445, 295, 1783, 293, 398, 13, 467, 820, 3909, 264, 2281, 2445, 294, 50804, 50804, 1270, 257, 636, 300, 264, 1412, 2793, 362, 3126, 2281, 813, 1203, 1646, 13, 1033, 13, 1436, 51120, 51120, 300, 311, 264, 636, 264, 38253, 307, 516, 281, 589, 13, 759, 264, 3006, 2158, 295, 398, 575, 3126, 2281, 51478, 51478, 813, 264, 18424, 4190, 295, 398, 550, 527, 38253, 9284, 300, 10704, 264, 2158, 295, 398, 300, 14725, 51704, 51704], "temperature": 0.0, "avg_logprob": -0.11506068590775277, "compression_ratio": 1.9270386266094421, "no_speech_prob": 1.777779107214883e-05}, {"id": 713, "seek": 397724, "start": 3999.52, "end": 4004.04, "text": " than the incorrect values of Y then our inference algorithm that finds the value of Y that produces", "tokens": [50364, 1192, 510, 13, 467, 820, 733, 295, 3909, 264, 2281, 2445, 570, 527, 3479, 586, 307, 715, 1819, 50606, 50606, 364, 2281, 2445, 382, 257, 2445, 295, 1783, 293, 398, 13, 467, 820, 3909, 264, 2281, 2445, 294, 50804, 50804, 1270, 257, 636, 300, 264, 1412, 2793, 362, 3126, 2281, 813, 1203, 1646, 13, 1033, 13, 1436, 51120, 51120, 300, 311, 264, 636, 264, 38253, 307, 516, 281, 589, 13, 759, 264, 3006, 2158, 295, 398, 575, 3126, 2281, 51478, 51478, 813, 264, 18424, 4190, 295, 398, 550, 527, 38253, 9284, 300, 10704, 264, 2158, 295, 398, 300, 14725, 51704, 51704], "temperature": 0.0, "avg_logprob": -0.11506068590775277, "compression_ratio": 1.9270386266094421, "no_speech_prob": 1.777779107214883e-05}, {"id": 714, "seek": 400404, "start": 4004.04, "end": 4008.4, "text": " the lowest energy is going to work. Okay. So we need to shape the energy function so", "tokens": [50364, 264, 12437, 2281, 307, 516, 281, 589, 13, 1033, 13, 407, 321, 643, 281, 3909, 264, 2281, 2445, 370, 50582, 50582, 300, 309, 2709, 2295, 2281, 281, 264, 665, 398, 311, 337, 257, 2212, 1783, 293, 1090, 2281, 281, 1578, 398, 311, 337, 257, 50848, 50848, 2212, 1783, 13, 50898, 50898, 407, 264, 462, 18819, 307, 257, 2445, 300, 1709, 490, 497, 17, 281, 497, 597, 2709, 485, 51322, 51322, 467, 1709, 490, 497, 11, 286, 914, 309, 1709, 490, 604, 9274, 291, 528, 281, 39684, 13, 1079, 13, 51522, 51522], "temperature": 0.0, "avg_logprob": -0.1991582480810022, "compression_ratio": 1.6544502617801047, "no_speech_prob": 9.223156666848809e-06}, {"id": 715, "seek": 400404, "start": 4008.4, "end": 4013.72, "text": " that it gives low energy to the good Y's for a given X and high energy to bad Y's for a", "tokens": [50364, 264, 12437, 2281, 307, 516, 281, 589, 13, 1033, 13, 407, 321, 643, 281, 3909, 264, 2281, 2445, 370, 50582, 50582, 300, 309, 2709, 2295, 2281, 281, 264, 665, 398, 311, 337, 257, 2212, 1783, 293, 1090, 2281, 281, 1578, 398, 311, 337, 257, 50848, 50848, 2212, 1783, 13, 50898, 50898, 407, 264, 462, 18819, 307, 257, 2445, 300, 1709, 490, 497, 17, 281, 497, 597, 2709, 485, 51322, 51322, 467, 1709, 490, 497, 11, 286, 914, 309, 1709, 490, 604, 9274, 291, 528, 281, 39684, 13, 1079, 13, 51522, 51522], "temperature": 0.0, "avg_logprob": -0.1991582480810022, "compression_ratio": 1.6544502617801047, "no_speech_prob": 9.223156666848809e-06}, {"id": 716, "seek": 400404, "start": 4013.72, "end": 4014.72, "text": " given X.", "tokens": [50364, 264, 12437, 2281, 307, 516, 281, 589, 13, 1033, 13, 407, 321, 643, 281, 3909, 264, 2281, 2445, 370, 50582, 50582, 300, 309, 2709, 2295, 2281, 281, 264, 665, 398, 311, 337, 257, 2212, 1783, 293, 1090, 2281, 281, 1578, 398, 311, 337, 257, 50848, 50848, 2212, 1783, 13, 50898, 50898, 407, 264, 462, 18819, 307, 257, 2445, 300, 1709, 490, 497, 17, 281, 497, 597, 2709, 485, 51322, 51322, 467, 1709, 490, 497, 11, 286, 914, 309, 1709, 490, 604, 9274, 291, 528, 281, 39684, 13, 1079, 13, 51522, 51522], "temperature": 0.0, "avg_logprob": -0.1991582480810022, "compression_ratio": 1.6544502617801047, "no_speech_prob": 9.223156666848809e-06}, {"id": 717, "seek": 400404, "start": 4014.72, "end": 4023.2, "text": " So the EPM is a function that goes from R2 to R which gives...", "tokens": [50364, 264, 12437, 2281, 307, 516, 281, 589, 13, 1033, 13, 407, 321, 643, 281, 3909, 264, 2281, 2445, 370, 50582, 50582, 300, 309, 2709, 2295, 2281, 281, 264, 665, 398, 311, 337, 257, 2212, 1783, 293, 1090, 2281, 281, 1578, 398, 311, 337, 257, 50848, 50848, 2212, 1783, 13, 50898, 50898, 407, 264, 462, 18819, 307, 257, 2445, 300, 1709, 490, 497, 17, 281, 497, 597, 2709, 485, 51322, 51322, 467, 1709, 490, 497, 11, 286, 914, 309, 1709, 490, 604, 9274, 291, 528, 281, 39684, 13, 1079, 13, 51522, 51522], "temperature": 0.0, "avg_logprob": -0.1991582480810022, "compression_ratio": 1.6544502617801047, "no_speech_prob": 9.223156666848809e-06}, {"id": 718, "seek": 400404, "start": 4023.2, "end": 4027.2, "text": " It goes from R, I mean it goes from any domain you want to scalar. Yes.", "tokens": [50364, 264, 12437, 2281, 307, 516, 281, 589, 13, 1033, 13, 407, 321, 643, 281, 3909, 264, 2281, 2445, 370, 50582, 50582, 300, 309, 2709, 2295, 2281, 281, 264, 665, 398, 311, 337, 257, 2212, 1783, 293, 1090, 2281, 281, 1578, 398, 311, 337, 257, 50848, 50848, 2212, 1783, 13, 50898, 50898, 407, 264, 462, 18819, 307, 257, 2445, 300, 1709, 490, 497, 17, 281, 497, 597, 2709, 485, 51322, 51322, 467, 1709, 490, 497, 11, 286, 914, 309, 1709, 490, 604, 9274, 291, 528, 281, 39684, 13, 1079, 13, 51522, 51522], "temperature": 0.0, "avg_logprob": -0.1991582480810022, "compression_ratio": 1.6544502617801047, "no_speech_prob": 9.223156666848809e-06}, {"id": 719, "seek": 402720, "start": 4027.2, "end": 4034.96, "text": " Okay. And the idea is then that the latent variable sort of shapes the level... Like", "tokens": [50364, 1033, 13, 400, 264, 1558, 307, 550, 300, 264, 48994, 7006, 1333, 295, 10854, 264, 1496, 485, 1743, 50752, 50752, 286, 478, 1237, 337, 257, 1496, 7605, 300, 4464, 5660, 570, 264, 3827, 307, 572, 2854, 3845, 11, 51002, 51002, 558, 30, 1119, 383, 550, 1333, 295, 25945, 264, 1901, 926, 341, 1496, 7605, 281, 652, 309, 544, 2473, 30876, 30, 51388, 51388, 1726, 4725, 13, 407, 341, 2316, 767, 307, 257, 48994, 7006, 2316, 13, 682, 1186, 11, 881, 295, 51734, 51734], "temperature": 0.0, "avg_logprob": -0.18609706654268152, "compression_ratio": 1.6192660550458715, "no_speech_prob": 9.222216249327175e-06}, {"id": 720, "seek": 402720, "start": 4034.96, "end": 4039.96, "text": " I'm looking for a level curve that minimizes because the solution is no longer unique,", "tokens": [50364, 1033, 13, 400, 264, 1558, 307, 550, 300, 264, 48994, 7006, 1333, 295, 10854, 264, 1496, 485, 1743, 50752, 50752, 286, 478, 1237, 337, 257, 1496, 7605, 300, 4464, 5660, 570, 264, 3827, 307, 572, 2854, 3845, 11, 51002, 51002, 558, 30, 1119, 383, 550, 1333, 295, 25945, 264, 1901, 926, 341, 1496, 7605, 281, 652, 309, 544, 2473, 30876, 30, 51388, 51388, 1726, 4725, 13, 407, 341, 2316, 767, 307, 257, 48994, 7006, 2316, 13, 682, 1186, 11, 881, 295, 51734, 51734], "temperature": 0.0, "avg_logprob": -0.18609706654268152, "compression_ratio": 1.6192660550458715, "no_speech_prob": 9.222216249327175e-06}, {"id": 721, "seek": 402720, "start": 4039.96, "end": 4047.68, "text": " right? Is C then sort of shaping the space around this level curve to make it more identifiable?", "tokens": [50364, 1033, 13, 400, 264, 1558, 307, 550, 300, 264, 48994, 7006, 1333, 295, 10854, 264, 1496, 485, 1743, 50752, 50752, 286, 478, 1237, 337, 257, 1496, 7605, 300, 4464, 5660, 570, 264, 3827, 307, 572, 2854, 3845, 11, 51002, 51002, 558, 30, 1119, 383, 550, 1333, 295, 25945, 264, 1901, 926, 341, 1496, 7605, 281, 652, 309, 544, 2473, 30876, 30, 51388, 51388, 1726, 4725, 13, 407, 341, 2316, 767, 307, 257, 48994, 7006, 2316, 13, 682, 1186, 11, 881, 295, 51734, 51734], "temperature": 0.0, "avg_logprob": -0.18609706654268152, "compression_ratio": 1.6192660550458715, "no_speech_prob": 9.222216249327175e-06}, {"id": 722, "seek": 402720, "start": 4047.68, "end": 4054.6, "text": " Not necessarily. So this model actually is a latent variable model. In fact, most of", "tokens": [50364, 1033, 13, 400, 264, 1558, 307, 550, 300, 264, 48994, 7006, 1333, 295, 10854, 264, 1496, 485, 1743, 50752, 50752, 286, 478, 1237, 337, 257, 1496, 7605, 300, 4464, 5660, 570, 264, 3827, 307, 572, 2854, 3845, 11, 51002, 51002, 558, 30, 1119, 383, 550, 1333, 295, 25945, 264, 1901, 926, 341, 1496, 7605, 281, 652, 309, 544, 2473, 30876, 30, 51388, 51388, 1726, 4725, 13, 407, 341, 2316, 767, 307, 257, 48994, 7006, 2316, 13, 682, 1186, 11, 881, 295, 51734, 51734], "temperature": 0.0, "avg_logprob": -0.18609706654268152, "compression_ratio": 1.6192660550458715, "no_speech_prob": 9.222216249327175e-06}, {"id": 723, "seek": 405460, "start": 4054.6, "end": 4063.52, "text": " you are probably very familiar with the energy... With the model is used here is k-means. So", "tokens": [50364, 291, 366, 1391, 588, 4963, 365, 264, 2281, 485, 2022, 264, 2316, 307, 1143, 510, 307, 350, 12, 1398, 599, 13, 407, 50810, 50810, 577, 307, 341, 7126, 30, 1033, 13, 961, 385, 8577, 341, 337, 257, 857, 13, 1033, 13, 583, 341, 307, 264, 2281, 3753, 51358, 51358], "temperature": 0.0, "avg_logprob": -0.2091967638801126, "compression_ratio": 1.3576642335766422, "no_speech_prob": 1.2218602932989597e-05}, {"id": 724, "seek": 405460, "start": 4063.52, "end": 4074.48, "text": " how is this produced? Okay. Let me delay this for a bit. Okay. But this is the energy surface", "tokens": [50364, 291, 366, 1391, 588, 4963, 365, 264, 2281, 485, 2022, 264, 2316, 307, 1143, 510, 307, 350, 12, 1398, 599, 13, 407, 50810, 50810, 577, 307, 341, 7126, 30, 1033, 13, 961, 385, 8577, 341, 337, 257, 857, 13, 1033, 13, 583, 341, 307, 264, 2281, 3753, 51358, 51358], "temperature": 0.0, "avg_logprob": -0.2091967638801126, "compression_ratio": 1.3576642335766422, "no_speech_prob": 1.2218602932989597e-05}, {"id": 725, "seek": 407448, "start": 4074.48, "end": 4084.84, "text": " of k-means which is a latent variable model. Let's keep the latent variable thing kind", "tokens": [50364, 295, 350, 12, 1398, 599, 597, 307, 257, 48994, 7006, 2316, 13, 961, 311, 1066, 264, 48994, 7006, 551, 733, 50882, 50882, 295, 7359, 337, 257, 3456, 13, 1449, 519, 295, 341, 382, 291, 362, 364, 2281, 479, 295, 48826, 293, 264, 1186, 51162, 51162, 300, 456, 815, 312, 14217, 48994, 7006, 337, 586, 307, 28682, 13, 1033, 13, 821, 311, 732, 5359, 51584, 51584], "temperature": 0.0, "avg_logprob": -0.10987265430279632, "compression_ratio": 1.497175141242938, "no_speech_prob": 8.397627425438259e-06}, {"id": 726, "seek": 407448, "start": 4084.84, "end": 4090.44, "text": " of aside for a minute. Just think of this as you have an energy F of XY and the fact", "tokens": [50364, 295, 350, 12, 1398, 599, 597, 307, 257, 48994, 7006, 2316, 13, 961, 311, 1066, 264, 48994, 7006, 551, 733, 50882, 50882, 295, 7359, 337, 257, 3456, 13, 1449, 519, 295, 341, 382, 291, 362, 364, 2281, 479, 295, 48826, 293, 264, 1186, 51162, 51162, 300, 456, 815, 312, 14217, 48994, 7006, 337, 586, 307, 28682, 13, 1033, 13, 821, 311, 732, 5359, 51584, 51584], "temperature": 0.0, "avg_logprob": -0.10987265430279632, "compression_ratio": 1.497175141242938, "no_speech_prob": 8.397627425438259e-06}, {"id": 727, "seek": 407448, "start": 4090.44, "end": 4098.88, "text": " that there may be underlying latent variable for now is irrelevant. Okay. There's two classes", "tokens": [50364, 295, 350, 12, 1398, 599, 597, 307, 257, 48994, 7006, 2316, 13, 961, 311, 1066, 264, 48994, 7006, 551, 733, 50882, 50882, 295, 7359, 337, 257, 3456, 13, 1449, 519, 295, 341, 382, 291, 362, 364, 2281, 479, 295, 48826, 293, 264, 1186, 51162, 51162, 300, 456, 815, 312, 14217, 48994, 7006, 337, 586, 307, 28682, 13, 1033, 13, 821, 311, 732, 5359, 51584, 51584], "temperature": 0.0, "avg_logprob": -0.10987265430279632, "compression_ratio": 1.497175141242938, "no_speech_prob": 8.397627425438259e-06}, {"id": 728, "seek": 409888, "start": 4098.88, "end": 4104.8, "text": " of methods to train energy-based models. And again, probabilistic methods are all kind of, you know,", "tokens": [50364, 295, 7150, 281, 3847, 2281, 12, 6032, 5245, 13, 400, 797, 11, 31959, 3142, 7150, 366, 439, 733, 295, 11, 291, 458, 11, 50660, 50660, 2121, 3331, 1951, 729, 13, 1485, 1508, 307, 1219, 8712, 488, 7150, 13, 400, 341, 1558, 307, 588, 3303, 13, 50980, 50980, 3664, 257, 3097, 6889, 11, 1783, 295, 1783, 40, 56, 40, 11, 293, 1319, 264, 9834, 295, 264, 2281, 2445, 370, 300, 51408, 51408], "temperature": 0.0, "avg_logprob": -0.1987568058379709, "compression_ratio": 1.4747474747474747, "no_speech_prob": 1.5687866834923625e-05}, {"id": 729, "seek": 409888, "start": 4104.8, "end": 4111.2, "text": " special cases within those. One class is called contrastive methods. And this idea is very natural.", "tokens": [50364, 295, 7150, 281, 3847, 2281, 12, 6032, 5245, 13, 400, 797, 11, 31959, 3142, 7150, 366, 439, 733, 295, 11, 291, 458, 11, 50660, 50660, 2121, 3331, 1951, 729, 13, 1485, 1508, 307, 1219, 8712, 488, 7150, 13, 400, 341, 1558, 307, 588, 3303, 13, 50980, 50980, 3664, 257, 3097, 6889, 11, 1783, 295, 1783, 40, 56, 40, 11, 293, 1319, 264, 9834, 295, 264, 2281, 2445, 370, 300, 51408, 51408], "temperature": 0.0, "avg_logprob": -0.1987568058379709, "compression_ratio": 1.4747474747474747, "no_speech_prob": 1.5687866834923625e-05}, {"id": 730, "seek": 409888, "start": 4111.2, "end": 4119.76, "text": " Take a training sample, X of XIYI, and change the parameters of the energy function so that", "tokens": [50364, 295, 7150, 281, 3847, 2281, 12, 6032, 5245, 13, 400, 797, 11, 31959, 3142, 7150, 366, 439, 733, 295, 11, 291, 458, 11, 50660, 50660, 2121, 3331, 1951, 729, 13, 1485, 1508, 307, 1219, 8712, 488, 7150, 13, 400, 341, 1558, 307, 588, 3303, 13, 50980, 50980, 3664, 257, 3097, 6889, 11, 1783, 295, 1783, 40, 56, 40, 11, 293, 1319, 264, 9834, 295, 264, 2281, 2445, 370, 300, 51408, 51408], "temperature": 0.0, "avg_logprob": -0.1987568058379709, "compression_ratio": 1.4747474747474747, "no_speech_prob": 1.5687866834923625e-05}, {"id": 731, "seek": 411976, "start": 4119.76, "end": 4129.72, "text": " its energy goes down. Okay. Easy enough. Conversely, take other points outside of the manifold", "tokens": [50364, 1080, 2281, 1709, 760, 13, 1033, 13, 16002, 1547, 13, 33247, 736, 11, 747, 661, 2793, 2380, 295, 264, 47138, 50862, 50862, 295, 1412, 13, 407, 362, 512, 1399, 538, 597, 291, 1888, 337, 257, 2212, 1783, 11, 291, 1888, 257, 1578, 398, 293, 550, 51248, 51248, 2944, 300, 2146, 493, 13, 1033, 13, 759, 291, 1066, 884, 341, 365, 264, 1036, 2445, 300, 2516, 666, 2696, 51640, 51640], "temperature": 0.0, "avg_logprob": -0.1789492620548732, "compression_ratio": 1.4352331606217616, "no_speech_prob": 1.520559726486681e-05}, {"id": 732, "seek": 411976, "start": 4129.72, "end": 4137.4400000000005, "text": " of data. So have some process by which you pick for a given X, you pick a bad Y and then", "tokens": [50364, 1080, 2281, 1709, 760, 13, 1033, 13, 16002, 1547, 13, 33247, 736, 11, 747, 661, 2793, 2380, 295, 264, 47138, 50862, 50862, 295, 1412, 13, 407, 362, 512, 1399, 538, 597, 291, 1888, 337, 257, 2212, 1783, 11, 291, 1888, 257, 1578, 398, 293, 550, 51248, 51248, 2944, 300, 2146, 493, 13, 1033, 13, 759, 291, 1066, 884, 341, 365, 264, 1036, 2445, 300, 2516, 666, 2696, 51640, 51640], "temperature": 0.0, "avg_logprob": -0.1789492620548732, "compression_ratio": 1.4352331606217616, "no_speech_prob": 1.520559726486681e-05}, {"id": 733, "seek": 411976, "start": 4137.4400000000005, "end": 4145.280000000001, "text": " push that guy up. Okay. If you keep doing this with the last function that takes into account", "tokens": [50364, 1080, 2281, 1709, 760, 13, 1033, 13, 16002, 1547, 13, 33247, 736, 11, 747, 661, 2793, 2380, 295, 264, 47138, 50862, 50862, 295, 1412, 13, 407, 362, 512, 1399, 538, 597, 291, 1888, 337, 257, 2212, 1783, 11, 291, 1888, 257, 1578, 398, 293, 550, 51248, 51248, 2944, 300, 2146, 493, 13, 1033, 13, 759, 291, 1066, 884, 341, 365, 264, 1036, 2445, 300, 2516, 666, 2696, 51640, 51640], "temperature": 0.0, "avg_logprob": -0.1789492620548732, "compression_ratio": 1.4352331606217616, "no_speech_prob": 1.520559726486681e-05}, {"id": 734, "seek": 414528, "start": 4145.28, "end": 4151.2, "text": " those different energies, then the energy function is going to take a shape such that", "tokens": [50364, 729, 819, 25737, 11, 550, 264, 2281, 2445, 307, 516, 281, 747, 257, 3909, 1270, 300, 50660, 50660, 264, 3006, 398, 486, 362, 3126, 2281, 813, 264, 1578, 398, 82, 13, 1033, 13, 5527, 7380, 760, 322, 264, 50950, 50950, 665, 4190, 295, 398, 11, 1066, 7380, 493, 322, 264, 1578, 4190, 295, 398, 13, 407, 729, 366, 1219, 8712, 488, 51290, 51290, 7150, 13, 400, 436, 439, 743, 538, 577, 291, 1888, 264, 398, 82, 300, 291, 2944, 493, 13, 400, 436, 439, 743, 51688, 51688], "temperature": 0.0, "avg_logprob": -0.10311657123351364, "compression_ratio": 1.6826923076923077, "no_speech_prob": 3.966747044614749e-06}, {"id": 735, "seek": 414528, "start": 4151.2, "end": 4157.0, "text": " the correct Y will have lower energy than the bad Ys. Okay. Keep pushing down on the", "tokens": [50364, 729, 819, 25737, 11, 550, 264, 2281, 2445, 307, 516, 281, 747, 257, 3909, 1270, 300, 50660, 50660, 264, 3006, 398, 486, 362, 3126, 2281, 813, 264, 1578, 398, 82, 13, 1033, 13, 5527, 7380, 760, 322, 264, 50950, 50950, 665, 4190, 295, 398, 11, 1066, 7380, 493, 322, 264, 1578, 4190, 295, 398, 13, 407, 729, 366, 1219, 8712, 488, 51290, 51290, 7150, 13, 400, 436, 439, 743, 538, 577, 291, 1888, 264, 398, 82, 300, 291, 2944, 493, 13, 400, 436, 439, 743, 51688, 51688], "temperature": 0.0, "avg_logprob": -0.10311657123351364, "compression_ratio": 1.6826923076923077, "no_speech_prob": 3.966747044614749e-06}, {"id": 736, "seek": 414528, "start": 4157.0, "end": 4163.8, "text": " good values of Y, keep pushing up on the bad values of Y. So those are called contrastive", "tokens": [50364, 729, 819, 25737, 11, 550, 264, 2281, 2445, 307, 516, 281, 747, 257, 3909, 1270, 300, 50660, 50660, 264, 3006, 398, 486, 362, 3126, 2281, 813, 264, 1578, 398, 82, 13, 1033, 13, 5527, 7380, 760, 322, 264, 50950, 50950, 665, 4190, 295, 398, 11, 1066, 7380, 493, 322, 264, 1578, 4190, 295, 398, 13, 407, 729, 366, 1219, 8712, 488, 51290, 51290, 7150, 13, 400, 436, 439, 743, 538, 577, 291, 1888, 264, 398, 82, 300, 291, 2944, 493, 13, 400, 436, 439, 743, 51688, 51688], "temperature": 0.0, "avg_logprob": -0.10311657123351364, "compression_ratio": 1.6826923076923077, "no_speech_prob": 3.966747044614749e-06}, {"id": 737, "seek": 414528, "start": 4163.8, "end": 4171.759999999999, "text": " methods. And they all differ by how you pick the Ys that you push up. And they all differ", "tokens": [50364, 729, 819, 25737, 11, 550, 264, 2281, 2445, 307, 516, 281, 747, 257, 3909, 1270, 300, 50660, 50660, 264, 3006, 398, 486, 362, 3126, 2281, 813, 264, 1578, 398, 82, 13, 1033, 13, 5527, 7380, 760, 322, 264, 50950, 50950, 665, 4190, 295, 398, 11, 1066, 7380, 493, 322, 264, 1578, 4190, 295, 398, 13, 407, 729, 366, 1219, 8712, 488, 51290, 51290, 7150, 13, 400, 436, 439, 743, 538, 577, 291, 1888, 264, 398, 82, 300, 291, 2944, 493, 13, 400, 436, 439, 743, 51688, 51688], "temperature": 0.0, "avg_logprob": -0.10311657123351364, "compression_ratio": 1.6826923076923077, "no_speech_prob": 3.966747044614749e-06}, {"id": 738, "seek": 417176, "start": 4171.76, "end": 4180.2, "text": " by the last function you use to do this pushing up and pushing down. There's a second category", "tokens": [50364, 538, 264, 1036, 2445, 291, 764, 281, 360, 341, 7380, 493, 293, 7380, 760, 13, 821, 311, 257, 1150, 7719, 50786, 50786, 295, 7150, 13, 400, 286, 818, 552, 26621, 7150, 13, 682, 300, 1389, 11, 291, 1322, 264, 2281, 51176, 51176, 2445, 11, 479, 295, 48826, 11, 370, 300, 264, 5523, 295, 2295, 2281, 10682, 307, 5567, 420, 307, 4464, 1602, 51506, 51506, 807, 3890, 2144, 13, 407, 291, 1322, 257, 2316, 294, 1270, 257, 636, 300, 2035, 291, 2944, 760, 51806, 51806], "temperature": 0.0, "avg_logprob": -0.12730672747589822, "compression_ratio": 1.6018099547511313, "no_speech_prob": 5.9547687669692095e-06}, {"id": 739, "seek": 417176, "start": 4180.2, "end": 4188.0, "text": " of methods. And I call them architectural methods. In that case, you build the energy", "tokens": [50364, 538, 264, 1036, 2445, 291, 764, 281, 360, 341, 7380, 493, 293, 7380, 760, 13, 821, 311, 257, 1150, 7719, 50786, 50786, 295, 7150, 13, 400, 286, 818, 552, 26621, 7150, 13, 682, 300, 1389, 11, 291, 1322, 264, 2281, 51176, 51176, 2445, 11, 479, 295, 48826, 11, 370, 300, 264, 5523, 295, 2295, 2281, 10682, 307, 5567, 420, 307, 4464, 1602, 51506, 51506, 807, 3890, 2144, 13, 407, 291, 1322, 257, 2316, 294, 1270, 257, 636, 300, 2035, 291, 2944, 760, 51806, 51806], "temperature": 0.0, "avg_logprob": -0.12730672747589822, "compression_ratio": 1.6018099547511313, "no_speech_prob": 5.9547687669692095e-06}, {"id": 740, "seek": 417176, "start": 4188.0, "end": 4194.6, "text": " function, F of XY, so that the volume of low energy regions is limited or is minimized", "tokens": [50364, 538, 264, 1036, 2445, 291, 764, 281, 360, 341, 7380, 493, 293, 7380, 760, 13, 821, 311, 257, 1150, 7719, 50786, 50786, 295, 7150, 13, 400, 286, 818, 552, 26621, 7150, 13, 682, 300, 1389, 11, 291, 1322, 264, 2281, 51176, 51176, 2445, 11, 479, 295, 48826, 11, 370, 300, 264, 5523, 295, 2295, 2281, 10682, 307, 5567, 420, 307, 4464, 1602, 51506, 51506, 807, 3890, 2144, 13, 407, 291, 1322, 257, 2316, 294, 1270, 257, 636, 300, 2035, 291, 2944, 760, 51806, 51806], "temperature": 0.0, "avg_logprob": -0.12730672747589822, "compression_ratio": 1.6018099547511313, "no_speech_prob": 5.9547687669692095e-06}, {"id": 741, "seek": 417176, "start": 4194.6, "end": 4200.6, "text": " through regularization. So you build a model in such a way that whatever you push down", "tokens": [50364, 538, 264, 1036, 2445, 291, 764, 281, 360, 341, 7380, 493, 293, 7380, 760, 13, 821, 311, 257, 1150, 7719, 50786, 50786, 295, 7150, 13, 400, 286, 818, 552, 26621, 7150, 13, 682, 300, 1389, 11, 291, 1322, 264, 2281, 51176, 51176, 2445, 11, 479, 295, 48826, 11, 370, 300, 264, 5523, 295, 2295, 2281, 10682, 307, 5567, 420, 307, 4464, 1602, 51506, 51506, 807, 3890, 2144, 13, 407, 291, 1322, 257, 2316, 294, 1270, 257, 636, 300, 2035, 291, 2944, 760, 51806, 51806], "temperature": 0.0, "avg_logprob": -0.12730672747589822, "compression_ratio": 1.6018099547511313, "no_speech_prob": 5.9547687669692095e-06}, {"id": 742, "seek": 420060, "start": 4200.6, "end": 4207.72, "text": " on the energy of data points, the rest goes up more or less automatically because the", "tokens": [50364, 322, 264, 2281, 295, 1412, 2793, 11, 264, 1472, 1709, 493, 544, 420, 1570, 6772, 570, 264, 50720, 50720, 5523, 295, 1507, 300, 393, 747, 2295, 2281, 307, 5567, 420, 4464, 1602, 807, 512, 3890, 2144, 13, 51012, 51012, 1033, 13, 3950, 366, 588, 4152, 10392, 13, 1033, 13, 1079, 13, 51334, 51334], "temperature": 0.0, "avg_logprob": -0.20116058696400035, "compression_ratio": 1.4276729559748427, "no_speech_prob": 3.0225930458982475e-05}, {"id": 743, "seek": 420060, "start": 4207.72, "end": 4213.56, "text": " volume of stuff that can take low energy is limited or minimized through some regularization.", "tokens": [50364, 322, 264, 2281, 295, 1412, 2793, 11, 264, 1472, 1709, 493, 544, 420, 1570, 6772, 570, 264, 50720, 50720, 5523, 295, 1507, 300, 393, 747, 2295, 2281, 307, 5567, 420, 4464, 1602, 807, 512, 3890, 2144, 13, 51012, 51012, 1033, 13, 3950, 366, 588, 4152, 10392, 13, 1033, 13, 1079, 13, 51334, 51334], "temperature": 0.0, "avg_logprob": -0.20116058696400035, "compression_ratio": 1.4276729559748427, "no_speech_prob": 3.0225930458982475e-05}, {"id": 744, "seek": 420060, "start": 4213.56, "end": 4220.0, "text": " Okay. Those are very broad concepts. Okay. Yes.", "tokens": [50364, 322, 264, 2281, 295, 1412, 2793, 11, 264, 1472, 1709, 493, 544, 420, 1570, 6772, 570, 264, 50720, 50720, 5523, 295, 1507, 300, 393, 747, 2295, 2281, 307, 5567, 420, 4464, 1602, 807, 512, 3890, 2144, 13, 51012, 51012, 1033, 13, 3950, 366, 588, 4152, 10392, 13, 1033, 13, 1079, 13, 51334, 51334], "temperature": 0.0, "avg_logprob": -0.20116058696400035, "compression_ratio": 1.4276729559748427, "no_speech_prob": 3.0225930458982475e-05}, {"id": 745, "seek": 422000, "start": 4220.0, "end": 4238.68, "text": " That's one set of techniques, but there's many.", "tokens": [50364, 663, 311, 472, 992, 295, 7512, 11, 457, 456, 311, 867, 13, 51298, 51298, 407, 456, 307, 257, 992, 295, 7150, 411, 6175, 14324, 11, 337, 1365, 11, 300, 1619, 264, 16235, 295, 264, 51560, 51560, 2281, 926, 264, 6889, 820, 312, 4018, 293, 264, 1150, 13760, 820, 312, 382, 2416, 382, 51810, 51810], "temperature": 0.0, "avg_logprob": -0.19297550405774797, "compression_ratio": 1.52, "no_speech_prob": 3.7602876545861363e-05}, {"id": 746, "seek": 422000, "start": 4238.68, "end": 4243.92, "text": " So there is a set of methods like score matching, for example, that says the gradient of the", "tokens": [50364, 663, 311, 472, 992, 295, 7512, 11, 457, 456, 311, 867, 13, 51298, 51298, 407, 456, 307, 257, 992, 295, 7150, 411, 6175, 14324, 11, 337, 1365, 11, 300, 1619, 264, 16235, 295, 264, 51560, 51560, 2281, 926, 264, 6889, 820, 312, 4018, 293, 264, 1150, 13760, 820, 312, 382, 2416, 382, 51810, 51810], "temperature": 0.0, "avg_logprob": -0.19297550405774797, "compression_ratio": 1.52, "no_speech_prob": 3.7602876545861363e-05}, {"id": 747, "seek": 422000, "start": 4243.92, "end": 4248.92, "text": " energy around the sample should be zero and the second derivative should be as large as", "tokens": [50364, 663, 311, 472, 992, 295, 7512, 11, 457, 456, 311, 867, 13, 51298, 51298, 407, 456, 307, 257, 992, 295, 7150, 411, 6175, 14324, 11, 337, 1365, 11, 300, 1619, 264, 16235, 295, 264, 51560, 51560, 2281, 926, 264, 6889, 820, 312, 4018, 293, 264, 1150, 13760, 820, 312, 382, 2416, 382, 51810, 51810], "temperature": 0.0, "avg_logprob": -0.19297550405774797, "compression_ratio": 1.52, "no_speech_prob": 3.7602876545861363e-05}, {"id": 748, "seek": 424892, "start": 4248.92, "end": 4252.56, "text": " possible. The trace of the Hessian should be large. And so basically you're telling", "tokens": [50364, 1944, 13, 440, 13508, 295, 264, 35960, 952, 820, 312, 2416, 13, 400, 370, 1936, 291, 434, 3585, 50546, 50546, 309, 652, 633, 1412, 935, 257, 7285, 295, 264, 2281, 538, 1455, 988, 264, 2281, 36950, 493, 50948, 50948, 926, 633, 3097, 6889, 13, 467, 311, 588, 11, 588, 1152, 281, 3079, 294, 3124, 570, 291, 362, 51172, 51172, 281, 14722, 264, 16235, 365, 3104, 281, 264, 17443, 295, 264, 13508, 295, 264, 35960, 952, 295, 264, 51378, 51378, 2281, 2445, 365, 3104, 281, 264, 15743, 13, 286, 914, 11, 309, 311, 3566, 4921, 11, 457, 1338, 13, 51748, 51748], "temperature": 0.0, "avg_logprob": -0.13443846796073167, "compression_ratio": 1.7489711934156378, "no_speech_prob": 1.7500049580121413e-05}, {"id": 749, "seek": 424892, "start": 4252.56, "end": 4260.6, "text": " it make every data point a minimum of the energy by making sure the energy curls up", "tokens": [50364, 1944, 13, 440, 13508, 295, 264, 35960, 952, 820, 312, 2416, 13, 400, 370, 1936, 291, 434, 3585, 50546, 50546, 309, 652, 633, 1412, 935, 257, 7285, 295, 264, 2281, 538, 1455, 988, 264, 2281, 36950, 493, 50948, 50948, 926, 633, 3097, 6889, 13, 467, 311, 588, 11, 588, 1152, 281, 3079, 294, 3124, 570, 291, 362, 51172, 51172, 281, 14722, 264, 16235, 365, 3104, 281, 264, 17443, 295, 264, 13508, 295, 264, 35960, 952, 295, 264, 51378, 51378, 2281, 2445, 365, 3104, 281, 264, 15743, 13, 286, 914, 11, 309, 311, 3566, 4921, 11, 457, 1338, 13, 51748, 51748], "temperature": 0.0, "avg_logprob": -0.13443846796073167, "compression_ratio": 1.7489711934156378, "no_speech_prob": 1.7500049580121413e-05}, {"id": 750, "seek": 424892, "start": 4260.6, "end": 4265.08, "text": " around every training sample. It's very, very hard to apply in practice because you have", "tokens": [50364, 1944, 13, 440, 13508, 295, 264, 35960, 952, 820, 312, 2416, 13, 400, 370, 1936, 291, 434, 3585, 50546, 50546, 309, 652, 633, 1412, 935, 257, 7285, 295, 264, 2281, 538, 1455, 988, 264, 2281, 36950, 493, 50948, 50948, 926, 633, 3097, 6889, 13, 467, 311, 588, 11, 588, 1152, 281, 3079, 294, 3124, 570, 291, 362, 51172, 51172, 281, 14722, 264, 16235, 365, 3104, 281, 264, 17443, 295, 264, 13508, 295, 264, 35960, 952, 295, 264, 51378, 51378, 2281, 2445, 365, 3104, 281, 264, 15743, 13, 286, 914, 11, 309, 311, 3566, 4921, 11, 457, 1338, 13, 51748, 51748], "temperature": 0.0, "avg_logprob": -0.13443846796073167, "compression_ratio": 1.7489711934156378, "no_speech_prob": 1.7500049580121413e-05}, {"id": 751, "seek": 424892, "start": 4265.08, "end": 4269.2, "text": " to compute the gradient with respect to the weights of the trace of the Hessian of the", "tokens": [50364, 1944, 13, 440, 13508, 295, 264, 35960, 952, 820, 312, 2416, 13, 400, 370, 1936, 291, 434, 3585, 50546, 50546, 309, 652, 633, 1412, 935, 257, 7285, 295, 264, 2281, 538, 1455, 988, 264, 2281, 36950, 493, 50948, 50948, 926, 633, 3097, 6889, 13, 467, 311, 588, 11, 588, 1152, 281, 3079, 294, 3124, 570, 291, 362, 51172, 51172, 281, 14722, 264, 16235, 365, 3104, 281, 264, 17443, 295, 264, 13508, 295, 264, 35960, 952, 295, 264, 51378, 51378, 2281, 2445, 365, 3104, 281, 264, 15743, 13, 286, 914, 11, 309, 311, 3566, 4921, 11, 457, 1338, 13, 51748, 51748], "temperature": 0.0, "avg_logprob": -0.13443846796073167, "compression_ratio": 1.7489711934156378, "no_speech_prob": 1.7500049580121413e-05}, {"id": 752, "seek": 424892, "start": 4269.2, "end": 4276.6, "text": " energy function with respect to the inputs. I mean, it's complete hell, but yeah.", "tokens": [50364, 1944, 13, 440, 13508, 295, 264, 35960, 952, 820, 312, 2416, 13, 400, 370, 1936, 291, 434, 3585, 50546, 50546, 309, 652, 633, 1412, 935, 257, 7285, 295, 264, 2281, 538, 1455, 988, 264, 2281, 36950, 493, 50948, 50948, 926, 633, 3097, 6889, 13, 467, 311, 588, 11, 588, 1152, 281, 3079, 294, 3124, 570, 291, 362, 51172, 51172, 281, 14722, 264, 16235, 365, 3104, 281, 264, 17443, 295, 264, 13508, 295, 264, 35960, 952, 295, 264, 51378, 51378, 2281, 2445, 365, 3104, 281, 264, 15743, 13, 286, 914, 11, 309, 311, 3566, 4921, 11, 457, 1338, 13, 51748, 51748], "temperature": 0.0, "avg_logprob": -0.13443846796073167, "compression_ratio": 1.7489711934156378, "no_speech_prob": 1.7500049580121413e-05}, {"id": 753, "seek": 427660, "start": 4276.6, "end": 4283.360000000001, "text": " For simple models, PyTorch can do it. Yeah. Simple models. Like for linear models. But", "tokens": [50364, 1171, 2199, 5245, 11, 9953, 51, 284, 339, 393, 360, 309, 13, 865, 13, 21532, 5245, 13, 1743, 337, 8213, 5245, 13, 583, 50702, 50702, 309, 311, 4921, 13, 286, 1116, 1754, 1314, 490, 309, 13, 1033, 13, 51084, 51084, 407, 456, 311, 257, 1230, 295, 819, 9029, 13, 1692, 309, 1619, 3407, 9029, 11, 457, 286, 733, 51374, 51374, 295, 41203, 1125, 341, 666, 729, 732, 10479, 295, 8712, 488, 7150, 293, 26621, 7150, 13, 51638, 51638], "temperature": 0.0, "avg_logprob": -0.1675587296485901, "compression_ratio": 1.4807692307692308, "no_speech_prob": 8.939055078371894e-06}, {"id": 754, "seek": 427660, "start": 4283.360000000001, "end": 4291.0, "text": " it's hell. I'd stay away from it. Okay.", "tokens": [50364, 1171, 2199, 5245, 11, 9953, 51, 284, 339, 393, 360, 309, 13, 865, 13, 21532, 5245, 13, 1743, 337, 8213, 5245, 13, 583, 50702, 50702, 309, 311, 4921, 13, 286, 1116, 1754, 1314, 490, 309, 13, 1033, 13, 51084, 51084, 407, 456, 311, 257, 1230, 295, 819, 9029, 13, 1692, 309, 1619, 3407, 9029, 11, 457, 286, 733, 51374, 51374, 295, 41203, 1125, 341, 666, 729, 732, 10479, 295, 8712, 488, 7150, 293, 26621, 7150, 13, 51638, 51638], "temperature": 0.0, "avg_logprob": -0.1675587296485901, "compression_ratio": 1.4807692307692308, "no_speech_prob": 8.939055078371894e-06}, {"id": 755, "seek": 427660, "start": 4291.0, "end": 4296.8, "text": " So there's a number of different strategies. Here it says seven strategies, but I kind", "tokens": [50364, 1171, 2199, 5245, 11, 9953, 51, 284, 339, 393, 360, 309, 13, 865, 13, 21532, 5245, 13, 1743, 337, 8213, 5245, 13, 583, 50702, 50702, 309, 311, 4921, 13, 286, 1116, 1754, 1314, 490, 309, 13, 1033, 13, 51084, 51084, 407, 456, 311, 257, 1230, 295, 819, 9029, 13, 1692, 309, 1619, 3407, 9029, 11, 457, 286, 733, 51374, 51374, 295, 41203, 1125, 341, 666, 729, 732, 10479, 295, 8712, 488, 7150, 293, 26621, 7150, 13, 51638, 51638], "temperature": 0.0, "avg_logprob": -0.1675587296485901, "compression_ratio": 1.4807692307692308, "no_speech_prob": 8.939055078371894e-06}, {"id": 756, "seek": 427660, "start": 4296.8, "end": 4302.08, "text": " of reorganize this into those two categories of contrastive methods and architectural methods.", "tokens": [50364, 1171, 2199, 5245, 11, 9953, 51, 284, 339, 393, 360, 309, 13, 865, 13, 21532, 5245, 13, 1743, 337, 8213, 5245, 13, 583, 50702, 50702, 309, 311, 4921, 13, 286, 1116, 1754, 1314, 490, 309, 13, 1033, 13, 51084, 51084, 407, 456, 311, 257, 1230, 295, 819, 9029, 13, 1692, 309, 1619, 3407, 9029, 11, 457, 286, 733, 51374, 51374, 295, 41203, 1125, 341, 666, 729, 732, 10479, 295, 8712, 488, 7150, 293, 26621, 7150, 13, 51638, 51638], "temperature": 0.0, "avg_logprob": -0.1675587296485901, "compression_ratio": 1.4807692307692308, "no_speech_prob": 8.939055078371894e-06}, {"id": 757, "seek": 430208, "start": 4302.08, "end": 4306.4, "text": " And there are kind of three subcategories, you know, in contrast even four subcategories", "tokens": [50364, 400, 456, 366, 733, 295, 1045, 1422, 66, 2968, 2083, 11, 291, 458, 11, 294, 8712, 754, 1451, 1422, 66, 2968, 2083, 50580, 50580, 294, 26621, 13, 400, 456, 311, 512, 5288, 295, 3683, 14642, 510, 300, 291, 1062, 5521, 11, 50830, 50830, 512, 661, 300, 291, 815, 406, 5521, 11, 597, 307, 1392, 13, 400, 286, 478, 516, 281, 853, 281, 352, 807, 51080, 51080, 512, 295, 552, 13, 51352, 51352], "temperature": 0.0, "avg_logprob": -0.17271052180109797, "compression_ratio": 1.6285714285714286, "no_speech_prob": 1.028845326800365e-05}, {"id": 758, "seek": 430208, "start": 4306.4, "end": 4311.4, "text": " in architectural. And there's some names of various algorithms here that you might recognize,", "tokens": [50364, 400, 456, 366, 733, 295, 1045, 1422, 66, 2968, 2083, 11, 291, 458, 11, 294, 8712, 754, 1451, 1422, 66, 2968, 2083, 50580, 50580, 294, 26621, 13, 400, 456, 311, 512, 5288, 295, 3683, 14642, 510, 300, 291, 1062, 5521, 11, 50830, 50830, 512, 661, 300, 291, 815, 406, 5521, 11, 597, 307, 1392, 13, 400, 286, 478, 516, 281, 853, 281, 352, 807, 51080, 51080, 512, 295, 552, 13, 51352, 51352], "temperature": 0.0, "avg_logprob": -0.17271052180109797, "compression_ratio": 1.6285714285714286, "no_speech_prob": 1.028845326800365e-05}, {"id": 759, "seek": 430208, "start": 4311.4, "end": 4316.4, "text": " some other that you may not recognize, which is okay. And I'm going to try to go through", "tokens": [50364, 400, 456, 366, 733, 295, 1045, 1422, 66, 2968, 2083, 11, 291, 458, 11, 294, 8712, 754, 1451, 1422, 66, 2968, 2083, 50580, 50580, 294, 26621, 13, 400, 456, 311, 512, 5288, 295, 3683, 14642, 510, 300, 291, 1062, 5521, 11, 50830, 50830, 512, 661, 300, 291, 815, 406, 5521, 11, 597, 307, 1392, 13, 400, 286, 478, 516, 281, 853, 281, 352, 807, 51080, 51080, 512, 295, 552, 13, 51352, 51352], "temperature": 0.0, "avg_logprob": -0.17271052180109797, "compression_ratio": 1.6285714285714286, "no_speech_prob": 1.028845326800365e-05}, {"id": 760, "seek": 430208, "start": 4316.4, "end": 4321.84, "text": " some of them.", "tokens": [50364, 400, 456, 366, 733, 295, 1045, 1422, 66, 2968, 2083, 11, 291, 458, 11, 294, 8712, 754, 1451, 1422, 66, 2968, 2083, 50580, 50580, 294, 26621, 13, 400, 456, 311, 512, 5288, 295, 3683, 14642, 510, 300, 291, 1062, 5521, 11, 50830, 50830, 512, 661, 300, 291, 815, 406, 5521, 11, 597, 307, 1392, 13, 400, 286, 478, 516, 281, 853, 281, 352, 807, 51080, 51080, 512, 295, 552, 13, 51352, 51352], "temperature": 0.0, "avg_logprob": -0.17271052180109797, "compression_ratio": 1.6285714285714286, "no_speech_prob": 1.028845326800365e-05}, {"id": 761, "seek": 432184, "start": 4321.84, "end": 4344.4800000000005, "text": " Now what I need to do is called score matching. Okay. Bear with me for just one second.", "tokens": [50364, 823, 437, 286, 643, 281, 360, 307, 1219, 6175, 14324, 13, 1033, 13, 19836, 365, 385, 337, 445, 472, 1150, 13, 51496, 51496], "temperature": 0.0, "avg_logprob": -0.33256126403808595, "compression_ratio": 1.0481927710843373, "no_speech_prob": 4.2585535993566737e-05}, {"id": 762, "seek": 434448, "start": 4344.48, "end": 4351.98, "text": " There we go.", "tokens": [50364, 821, 321, 352, 13, 50739, 50739, 21726, 13, 50918, 50918], "temperature": 1.0, "avg_logprob": -1.7010300954182942, "compression_ratio": 0.6923076923076923, "no_speech_prob": 0.0015970197273418307}, {"id": 763, "seek": 434448, "start": 4351.98, "end": 4355.5599999999995, "text": " Oops.", "tokens": [50364, 821, 321, 352, 13, 50739, 50739, 21726, 13, 50918, 50918], "temperature": 1.0, "avg_logprob": -1.7010300954182942, "compression_ratio": 0.6923076923076923, "no_speech_prob": 0.0015970197273418307}, {"id": 764, "seek": 435556, "start": 4355.56, "end": 4361.56, "text": " Oops.", "tokens": [50364, 21726, 13, 50664, 50664, 1033, 13, 50964, 50964, 407, 383, 16, 8712, 488, 1422, 66, 48701, 502, 11, 51264, 51264, 2944, 760, 264, 2281, 295, 264, 12018, 13, 51564, 51564], "temperature": 0.0, "avg_logprob": -0.6943613290786743, "compression_ratio": 0.9629629629629629, "no_speech_prob": 0.14739932119846344}, {"id": 765, "seek": 435556, "start": 4361.56, "end": 4367.56, "text": " Okay.", "tokens": [50364, 21726, 13, 50664, 50664, 1033, 13, 50964, 50964, 407, 383, 16, 8712, 488, 1422, 66, 48701, 502, 11, 51264, 51264, 2944, 760, 264, 2281, 295, 264, 12018, 13, 51564, 51564], "temperature": 0.0, "avg_logprob": -0.6943613290786743, "compression_ratio": 0.9629629629629629, "no_speech_prob": 0.14739932119846344}, {"id": 766, "seek": 435556, "start": 4367.56, "end": 4373.56, "text": " So C1 contrastive subcategory 1,", "tokens": [50364, 21726, 13, 50664, 50664, 1033, 13, 50964, 50964, 407, 383, 16, 8712, 488, 1422, 66, 48701, 502, 11, 51264, 51264, 2944, 760, 264, 2281, 295, 264, 12018, 13, 51564, 51564], "temperature": 0.0, "avg_logprob": -0.6943613290786743, "compression_ratio": 0.9629629629629629, "no_speech_prob": 0.14739932119846344}, {"id": 767, "seek": 435556, "start": 4373.56, "end": 4379.56, "text": " push down the energy of the atom.", "tokens": [50364, 21726, 13, 50664, 50664, 1033, 13, 50964, 50964, 407, 383, 16, 8712, 488, 1422, 66, 48701, 502, 11, 51264, 51264, 2944, 760, 264, 2281, 295, 264, 12018, 13, 51564, 51564], "temperature": 0.0, "avg_logprob": -0.6943613290786743, "compression_ratio": 0.9629629629629629, "no_speech_prob": 0.14739932119846344}, {"id": 768, "seek": 437956, "start": 4379.56, "end": 4385.56, "text": " Okay.", "tokens": [50364, 1033, 13, 50664, 50664, 407, 383, 16, 8712, 488, 1422, 66, 48701, 502, 11, 2944, 760, 264, 2281, 295, 1412, 935, 11, 2944, 493, 5315, 1646, 13, 50864, 50864, 400, 341, 307, 437, 6674, 22119, 775, 13, 51064, 51064, 400, 6674, 22119, 21020, 760, 264, 2281, 295, 1412, 2793, 281, 3175, 13202, 51264, 51264, 293, 21020, 493, 264, 2281, 295, 661, 2793, 281, 1804, 13202, 11, 51414, 51414, 597, 307, 264, 1154, 300, 321, 645, 445, 1417, 466, 3071, 13, 51614, 51614, 400, 370, 510, 307, 437, 2314, 13, 51814, 51814], "temperature": 0.0, "avg_logprob": -0.13178873574861916, "compression_ratio": 1.7535545023696681, "no_speech_prob": 4.2615632992237806e-05}, {"id": 769, "seek": 437956, "start": 4385.56, "end": 4389.56, "text": " So C1 contrastive subcategory 1, push down the energy of data point, push up everywhere else.", "tokens": [50364, 1033, 13, 50664, 50664, 407, 383, 16, 8712, 488, 1422, 66, 48701, 502, 11, 2944, 760, 264, 2281, 295, 1412, 935, 11, 2944, 493, 5315, 1646, 13, 50864, 50864, 400, 341, 307, 437, 6674, 22119, 775, 13, 51064, 51064, 400, 6674, 22119, 21020, 760, 264, 2281, 295, 1412, 2793, 281, 3175, 13202, 51264, 51264, 293, 21020, 493, 264, 2281, 295, 661, 2793, 281, 1804, 13202, 11, 51414, 51414, 597, 307, 264, 1154, 300, 321, 645, 445, 1417, 466, 3071, 13, 51614, 51614, 400, 370, 510, 307, 437, 2314, 13, 51814, 51814], "temperature": 0.0, "avg_logprob": -0.13178873574861916, "compression_ratio": 1.7535545023696681, "no_speech_prob": 4.2615632992237806e-05}, {"id": 770, "seek": 437956, "start": 4389.56, "end": 4393.56, "text": " And this is what maximum likelihood does.", "tokens": [50364, 1033, 13, 50664, 50664, 407, 383, 16, 8712, 488, 1422, 66, 48701, 502, 11, 2944, 760, 264, 2281, 295, 1412, 935, 11, 2944, 493, 5315, 1646, 13, 50864, 50864, 400, 341, 307, 437, 6674, 22119, 775, 13, 51064, 51064, 400, 6674, 22119, 21020, 760, 264, 2281, 295, 1412, 2793, 281, 3175, 13202, 51264, 51264, 293, 21020, 493, 264, 2281, 295, 661, 2793, 281, 1804, 13202, 11, 51414, 51414, 597, 307, 264, 1154, 300, 321, 645, 445, 1417, 466, 3071, 13, 51614, 51614, 400, 370, 510, 307, 437, 2314, 13, 51814, 51814], "temperature": 0.0, "avg_logprob": -0.13178873574861916, "compression_ratio": 1.7535545023696681, "no_speech_prob": 4.2615632992237806e-05}, {"id": 771, "seek": 437956, "start": 4393.56, "end": 4397.56, "text": " And maximum likelihood pushes down the energy of data points to minus infinity", "tokens": [50364, 1033, 13, 50664, 50664, 407, 383, 16, 8712, 488, 1422, 66, 48701, 502, 11, 2944, 760, 264, 2281, 295, 1412, 935, 11, 2944, 493, 5315, 1646, 13, 50864, 50864, 400, 341, 307, 437, 6674, 22119, 775, 13, 51064, 51064, 400, 6674, 22119, 21020, 760, 264, 2281, 295, 1412, 2793, 281, 3175, 13202, 51264, 51264, 293, 21020, 493, 264, 2281, 295, 661, 2793, 281, 1804, 13202, 11, 51414, 51414, 597, 307, 264, 1154, 300, 321, 645, 445, 1417, 466, 3071, 13, 51614, 51614, 400, 370, 510, 307, 437, 2314, 13, 51814, 51814], "temperature": 0.0, "avg_logprob": -0.13178873574861916, "compression_ratio": 1.7535545023696681, "no_speech_prob": 4.2615632992237806e-05}, {"id": 772, "seek": 437956, "start": 4397.56, "end": 4400.56, "text": " and pushes up the energy of other points to plus infinity,", "tokens": [50364, 1033, 13, 50664, 50664, 407, 383, 16, 8712, 488, 1422, 66, 48701, 502, 11, 2944, 760, 264, 2281, 295, 1412, 935, 11, 2944, 493, 5315, 1646, 13, 50864, 50864, 400, 341, 307, 437, 6674, 22119, 775, 13, 51064, 51064, 400, 6674, 22119, 21020, 760, 264, 2281, 295, 1412, 2793, 281, 3175, 13202, 51264, 51264, 293, 21020, 493, 264, 2281, 295, 661, 2793, 281, 1804, 13202, 11, 51414, 51414, 597, 307, 264, 1154, 300, 321, 645, 445, 1417, 466, 3071, 13, 51614, 51614, 400, 370, 510, 307, 437, 2314, 13, 51814, 51814], "temperature": 0.0, "avg_logprob": -0.13178873574861916, "compression_ratio": 1.7535545023696681, "no_speech_prob": 4.2615632992237806e-05}, {"id": 773, "seek": 437956, "start": 4400.56, "end": 4404.56, "text": " which is the problem that we were just talking about earlier.", "tokens": [50364, 1033, 13, 50664, 50664, 407, 383, 16, 8712, 488, 1422, 66, 48701, 502, 11, 2944, 760, 264, 2281, 295, 1412, 935, 11, 2944, 493, 5315, 1646, 13, 50864, 50864, 400, 341, 307, 437, 6674, 22119, 775, 13, 51064, 51064, 400, 6674, 22119, 21020, 760, 264, 2281, 295, 1412, 2793, 281, 3175, 13202, 51264, 51264, 293, 21020, 493, 264, 2281, 295, 661, 2793, 281, 1804, 13202, 11, 51414, 51414, 597, 307, 264, 1154, 300, 321, 645, 445, 1417, 466, 3071, 13, 51614, 51614, 400, 370, 510, 307, 437, 2314, 13, 51814, 51814], "temperature": 0.0, "avg_logprob": -0.13178873574861916, "compression_ratio": 1.7535545023696681, "no_speech_prob": 4.2615632992237806e-05}, {"id": 774, "seek": 437956, "start": 4404.56, "end": 4408.56, "text": " And so here is what happens.", "tokens": [50364, 1033, 13, 50664, 50664, 407, 383, 16, 8712, 488, 1422, 66, 48701, 502, 11, 2944, 760, 264, 2281, 295, 1412, 935, 11, 2944, 493, 5315, 1646, 13, 50864, 50864, 400, 341, 307, 437, 6674, 22119, 775, 13, 51064, 51064, 400, 6674, 22119, 21020, 760, 264, 2281, 295, 1412, 2793, 281, 3175, 13202, 51264, 51264, 293, 21020, 493, 264, 2281, 295, 661, 2793, 281, 1804, 13202, 11, 51414, 51414, 597, 307, 264, 1154, 300, 321, 645, 445, 1417, 466, 3071, 13, 51614, 51614, 400, 370, 510, 307, 437, 2314, 13, 51814, 51814], "temperature": 0.0, "avg_logprob": -0.13178873574861916, "compression_ratio": 1.7535545023696681, "no_speech_prob": 4.2615632992237806e-05}, {"id": 775, "seek": 440856, "start": 4408.56, "end": 4414.56, "text": " This gives, both line distribution, that gives the likelihood of y given x,", "tokens": [50364, 639, 2709, 11, 1293, 1622, 7316, 11, 300, 2709, 264, 22119, 295, 288, 2212, 2031, 11, 50664, 50664, 597, 307, 337, 257, 1729, 1412, 935, 11, 288, 72, 11, 36800, 13, 50864, 50864, 467, 2709, 291, 264, 8482, 300, 428, 2316, 2709, 281, 341, 1729, 2158, 295, 288, 72, 337, 257, 2212, 36800, 13, 51114, 51114, 400, 309, 311, 11, 291, 458, 11, 21510, 3175, 9861, 264, 2281, 51264, 51264, 6666, 538, 21510, 3175, 9861, 264, 2281, 10919, 670, 439, 288, 311, 13, 51464, 51464, 1033, 13, 407, 498, 291, 528, 281, 19874, 11, 370, 718, 311, 584, 291, 362, 257, 3840, 295, 1412, 2793, 11, 51714, 51714], "temperature": 0.0, "avg_logprob": -0.16787849773060193, "compression_ratio": 1.7125506072874495, "no_speech_prob": 0.00010218303941655904}, {"id": 776, "seek": 440856, "start": 4414.56, "end": 4418.56, "text": " which is for a particular data point, yi, xi.", "tokens": [50364, 639, 2709, 11, 1293, 1622, 7316, 11, 300, 2709, 264, 22119, 295, 288, 2212, 2031, 11, 50664, 50664, 597, 307, 337, 257, 1729, 1412, 935, 11, 288, 72, 11, 36800, 13, 50864, 50864, 467, 2709, 291, 264, 8482, 300, 428, 2316, 2709, 281, 341, 1729, 2158, 295, 288, 72, 337, 257, 2212, 36800, 13, 51114, 51114, 400, 309, 311, 11, 291, 458, 11, 21510, 3175, 9861, 264, 2281, 51264, 51264, 6666, 538, 21510, 3175, 9861, 264, 2281, 10919, 670, 439, 288, 311, 13, 51464, 51464, 1033, 13, 407, 498, 291, 528, 281, 19874, 11, 370, 718, 311, 584, 291, 362, 257, 3840, 295, 1412, 2793, 11, 51714, 51714], "temperature": 0.0, "avg_logprob": -0.16787849773060193, "compression_ratio": 1.7125506072874495, "no_speech_prob": 0.00010218303941655904}, {"id": 777, "seek": 440856, "start": 4418.56, "end": 4423.56, "text": " It gives you the probability that your model gives to this particular value of yi for a given xi.", "tokens": [50364, 639, 2709, 11, 1293, 1622, 7316, 11, 300, 2709, 264, 22119, 295, 288, 2212, 2031, 11, 50664, 50664, 597, 307, 337, 257, 1729, 1412, 935, 11, 288, 72, 11, 36800, 13, 50864, 50864, 467, 2709, 291, 264, 8482, 300, 428, 2316, 2709, 281, 341, 1729, 2158, 295, 288, 72, 337, 257, 2212, 36800, 13, 51114, 51114, 400, 309, 311, 11, 291, 458, 11, 21510, 3175, 9861, 264, 2281, 51264, 51264, 6666, 538, 21510, 3175, 9861, 264, 2281, 10919, 670, 439, 288, 311, 13, 51464, 51464, 1033, 13, 407, 498, 291, 528, 281, 19874, 11, 370, 718, 311, 584, 291, 362, 257, 3840, 295, 1412, 2793, 11, 51714, 51714], "temperature": 0.0, "avg_logprob": -0.16787849773060193, "compression_ratio": 1.7125506072874495, "no_speech_prob": 0.00010218303941655904}, {"id": 778, "seek": 440856, "start": 4423.56, "end": 4426.56, "text": " And it's, you know, exponential minus beta the energy", "tokens": [50364, 639, 2709, 11, 1293, 1622, 7316, 11, 300, 2709, 264, 22119, 295, 288, 2212, 2031, 11, 50664, 50664, 597, 307, 337, 257, 1729, 1412, 935, 11, 288, 72, 11, 36800, 13, 50864, 50864, 467, 2709, 291, 264, 8482, 300, 428, 2316, 2709, 281, 341, 1729, 2158, 295, 288, 72, 337, 257, 2212, 36800, 13, 51114, 51114, 400, 309, 311, 11, 291, 458, 11, 21510, 3175, 9861, 264, 2281, 51264, 51264, 6666, 538, 21510, 3175, 9861, 264, 2281, 10919, 670, 439, 288, 311, 13, 51464, 51464, 1033, 13, 407, 498, 291, 528, 281, 19874, 11, 370, 718, 311, 584, 291, 362, 257, 3840, 295, 1412, 2793, 11, 51714, 51714], "temperature": 0.0, "avg_logprob": -0.16787849773060193, "compression_ratio": 1.7125506072874495, "no_speech_prob": 0.00010218303941655904}, {"id": 779, "seek": 440856, "start": 4426.56, "end": 4430.56, "text": " divided by exponential minus beta the energy integrated over all y's.", "tokens": [50364, 639, 2709, 11, 1293, 1622, 7316, 11, 300, 2709, 264, 22119, 295, 288, 2212, 2031, 11, 50664, 50664, 597, 307, 337, 257, 1729, 1412, 935, 11, 288, 72, 11, 36800, 13, 50864, 50864, 467, 2709, 291, 264, 8482, 300, 428, 2316, 2709, 281, 341, 1729, 2158, 295, 288, 72, 337, 257, 2212, 36800, 13, 51114, 51114, 400, 309, 311, 11, 291, 458, 11, 21510, 3175, 9861, 264, 2281, 51264, 51264, 6666, 538, 21510, 3175, 9861, 264, 2281, 10919, 670, 439, 288, 311, 13, 51464, 51464, 1033, 13, 407, 498, 291, 528, 281, 19874, 11, 370, 718, 311, 584, 291, 362, 257, 3840, 295, 1412, 2793, 11, 51714, 51714], "temperature": 0.0, "avg_logprob": -0.16787849773060193, "compression_ratio": 1.7125506072874495, "no_speech_prob": 0.00010218303941655904}, {"id": 780, "seek": 440856, "start": 4430.56, "end": 4435.56, "text": " Okay. So if you want to maximize, so let's say you have a bunch of data points,", "tokens": [50364, 639, 2709, 11, 1293, 1622, 7316, 11, 300, 2709, 264, 22119, 295, 288, 2212, 2031, 11, 50664, 50664, 597, 307, 337, 257, 1729, 1412, 935, 11, 288, 72, 11, 36800, 13, 50864, 50864, 467, 2709, 291, 264, 8482, 300, 428, 2316, 2709, 281, 341, 1729, 2158, 295, 288, 72, 337, 257, 2212, 36800, 13, 51114, 51114, 400, 309, 311, 11, 291, 458, 11, 21510, 3175, 9861, 264, 2281, 51264, 51264, 6666, 538, 21510, 3175, 9861, 264, 2281, 10919, 670, 439, 288, 311, 13, 51464, 51464, 1033, 13, 407, 498, 291, 528, 281, 19874, 11, 370, 718, 311, 584, 291, 362, 257, 3840, 295, 1412, 2793, 11, 51714, 51714], "temperature": 0.0, "avg_logprob": -0.16787849773060193, "compression_ratio": 1.7125506072874495, "no_speech_prob": 0.00010218303941655904}, {"id": 781, "seek": 443556, "start": 4435.56, "end": 4442.56, "text": " and you want to maximize, so here I'm not writing x because it doesn't matter,", "tokens": [50364, 293, 291, 528, 281, 19874, 11, 370, 510, 286, 478, 406, 3579, 2031, 570, 309, 1177, 380, 1871, 11, 50714, 50714, 293, 291, 528, 281, 19874, 264, 8482, 300, 428, 2316, 2709, 281, 341, 1729, 2158, 295, 288, 13, 51014, 51014, 509, 528, 281, 652, 264, 2281, 295, 341, 288, 1359, 11, 51314, 51314, 597, 1355, 291, 528, 281, 652, 264, 308, 281, 264, 3175, 9861, 264, 2281, 295, 341, 955, 13, 51614, 51614], "temperature": 0.0, "avg_logprob": -0.07045334891269081, "compression_ratio": 1.7294117647058824, "no_speech_prob": 9.818191756494343e-06}, {"id": 782, "seek": 443556, "start": 4442.56, "end": 4448.56, "text": " and you want to maximize the probability that your model gives to this particular value of y.", "tokens": [50364, 293, 291, 528, 281, 19874, 11, 370, 510, 286, 478, 406, 3579, 2031, 570, 309, 1177, 380, 1871, 11, 50714, 50714, 293, 291, 528, 281, 19874, 264, 8482, 300, 428, 2316, 2709, 281, 341, 1729, 2158, 295, 288, 13, 51014, 51014, 509, 528, 281, 652, 264, 2281, 295, 341, 288, 1359, 11, 51314, 51314, 597, 1355, 291, 528, 281, 652, 264, 308, 281, 264, 3175, 9861, 264, 2281, 295, 341, 955, 13, 51614, 51614], "temperature": 0.0, "avg_logprob": -0.07045334891269081, "compression_ratio": 1.7294117647058824, "no_speech_prob": 9.818191756494343e-06}, {"id": 783, "seek": 443556, "start": 4448.56, "end": 4454.56, "text": " You want to make the energy of this y small,", "tokens": [50364, 293, 291, 528, 281, 19874, 11, 370, 510, 286, 478, 406, 3579, 2031, 570, 309, 1177, 380, 1871, 11, 50714, 50714, 293, 291, 528, 281, 19874, 264, 8482, 300, 428, 2316, 2709, 281, 341, 1729, 2158, 295, 288, 13, 51014, 51014, 509, 528, 281, 652, 264, 2281, 295, 341, 288, 1359, 11, 51314, 51314, 597, 1355, 291, 528, 281, 652, 264, 308, 281, 264, 3175, 9861, 264, 2281, 295, 341, 955, 13, 51614, 51614], "temperature": 0.0, "avg_logprob": -0.07045334891269081, "compression_ratio": 1.7294117647058824, "no_speech_prob": 9.818191756494343e-06}, {"id": 784, "seek": 443556, "start": 4454.56, "end": 4460.56, "text": " which means you want to make the e to the minus beta the energy of this big.", "tokens": [50364, 293, 291, 528, 281, 19874, 11, 370, 510, 286, 478, 406, 3579, 2031, 570, 309, 1177, 380, 1871, 11, 50714, 50714, 293, 291, 528, 281, 19874, 264, 8482, 300, 428, 2316, 2709, 281, 341, 1729, 2158, 295, 288, 13, 51014, 51014, 509, 528, 281, 652, 264, 2281, 295, 341, 288, 1359, 11, 51314, 51314, 597, 1355, 291, 528, 281, 652, 264, 308, 281, 264, 3175, 9861, 264, 2281, 295, 341, 955, 13, 51614, 51614], "temperature": 0.0, "avg_logprob": -0.07045334891269081, "compression_ratio": 1.7294117647058824, "no_speech_prob": 9.818191756494343e-06}, {"id": 785, "seek": 446056, "start": 4460.56, "end": 4466.56, "text": " And you want to make the stuff at the bottom as small as possible.", "tokens": [50364, 400, 291, 528, 281, 652, 264, 1507, 412, 264, 2767, 382, 1359, 382, 1944, 13, 50664, 50664, 407, 2602, 295, 5138, 3319, 280, 295, 288, 11, 321, 434, 516, 281, 17522, 3175, 3565, 280, 295, 288, 13, 50914, 50914, 407, 3175, 3565, 280, 295, 288, 11, 370, 498, 286, 747, 264, 3565, 295, 341, 8509, 11, 51114, 51114, 286, 478, 516, 281, 483, 264, 2649, 295, 729, 732, 2115, 13, 51314, 51314, 440, 3565, 295, 264, 2649, 11, 291, 458, 11, 264, 2649, 295, 264, 20820, 295, 729, 732, 2115, 13, 51564, 51564, 440, 3565, 295, 264, 8509, 307, 264, 2649, 295, 264, 20820, 11, 558, 30, 51664, 51664], "temperature": 0.0, "avg_logprob": -0.06849710790960638, "compression_ratio": 2.046875, "no_speech_prob": 1.045084536599461e-05}, {"id": 786, "seek": 446056, "start": 4466.56, "end": 4471.56, "text": " So instead of maximizing p of y, we're going to minimize minus log p of y.", "tokens": [50364, 400, 291, 528, 281, 652, 264, 1507, 412, 264, 2767, 382, 1359, 382, 1944, 13, 50664, 50664, 407, 2602, 295, 5138, 3319, 280, 295, 288, 11, 321, 434, 516, 281, 17522, 3175, 3565, 280, 295, 288, 13, 50914, 50914, 407, 3175, 3565, 280, 295, 288, 11, 370, 498, 286, 747, 264, 3565, 295, 341, 8509, 11, 51114, 51114, 286, 478, 516, 281, 483, 264, 2649, 295, 729, 732, 2115, 13, 51314, 51314, 440, 3565, 295, 264, 2649, 11, 291, 458, 11, 264, 2649, 295, 264, 20820, 295, 729, 732, 2115, 13, 51564, 51564, 440, 3565, 295, 264, 8509, 307, 264, 2649, 295, 264, 20820, 11, 558, 30, 51664, 51664], "temperature": 0.0, "avg_logprob": -0.06849710790960638, "compression_ratio": 2.046875, "no_speech_prob": 1.045084536599461e-05}, {"id": 787, "seek": 446056, "start": 4471.56, "end": 4475.56, "text": " So minus log p of y, so if I take the log of this ratio,", "tokens": [50364, 400, 291, 528, 281, 652, 264, 1507, 412, 264, 2767, 382, 1359, 382, 1944, 13, 50664, 50664, 407, 2602, 295, 5138, 3319, 280, 295, 288, 11, 321, 434, 516, 281, 17522, 3175, 3565, 280, 295, 288, 13, 50914, 50914, 407, 3175, 3565, 280, 295, 288, 11, 370, 498, 286, 747, 264, 3565, 295, 341, 8509, 11, 51114, 51114, 286, 478, 516, 281, 483, 264, 2649, 295, 729, 732, 2115, 13, 51314, 51314, 440, 3565, 295, 264, 2649, 11, 291, 458, 11, 264, 2649, 295, 264, 20820, 295, 729, 732, 2115, 13, 51564, 51564, 440, 3565, 295, 264, 8509, 307, 264, 2649, 295, 264, 20820, 11, 558, 30, 51664, 51664], "temperature": 0.0, "avg_logprob": -0.06849710790960638, "compression_ratio": 2.046875, "no_speech_prob": 1.045084536599461e-05}, {"id": 788, "seek": 446056, "start": 4475.56, "end": 4479.56, "text": " I'm going to get the difference of those two terms.", "tokens": [50364, 400, 291, 528, 281, 652, 264, 1507, 412, 264, 2767, 382, 1359, 382, 1944, 13, 50664, 50664, 407, 2602, 295, 5138, 3319, 280, 295, 288, 11, 321, 434, 516, 281, 17522, 3175, 3565, 280, 295, 288, 13, 50914, 50914, 407, 3175, 3565, 280, 295, 288, 11, 370, 498, 286, 747, 264, 3565, 295, 341, 8509, 11, 51114, 51114, 286, 478, 516, 281, 483, 264, 2649, 295, 729, 732, 2115, 13, 51314, 51314, 440, 3565, 295, 264, 2649, 11, 291, 458, 11, 264, 2649, 295, 264, 20820, 295, 729, 732, 2115, 13, 51564, 51564, 440, 3565, 295, 264, 8509, 307, 264, 2649, 295, 264, 20820, 11, 558, 30, 51664, 51664], "temperature": 0.0, "avg_logprob": -0.06849710790960638, "compression_ratio": 2.046875, "no_speech_prob": 1.045084536599461e-05}, {"id": 789, "seek": 446056, "start": 4479.56, "end": 4484.56, "text": " The log of the difference, you know, the difference of the logs of those two terms.", "tokens": [50364, 400, 291, 528, 281, 652, 264, 1507, 412, 264, 2767, 382, 1359, 382, 1944, 13, 50664, 50664, 407, 2602, 295, 5138, 3319, 280, 295, 288, 11, 321, 434, 516, 281, 17522, 3175, 3565, 280, 295, 288, 13, 50914, 50914, 407, 3175, 3565, 280, 295, 288, 11, 370, 498, 286, 747, 264, 3565, 295, 341, 8509, 11, 51114, 51114, 286, 478, 516, 281, 483, 264, 2649, 295, 729, 732, 2115, 13, 51314, 51314, 440, 3565, 295, 264, 2649, 11, 291, 458, 11, 264, 2649, 295, 264, 20820, 295, 729, 732, 2115, 13, 51564, 51564, 440, 3565, 295, 264, 8509, 307, 264, 2649, 295, 264, 20820, 11, 558, 30, 51664, 51664], "temperature": 0.0, "avg_logprob": -0.06849710790960638, "compression_ratio": 2.046875, "no_speech_prob": 1.045084536599461e-05}, {"id": 790, "seek": 446056, "start": 4484.56, "end": 4486.56, "text": " The log of the ratio is the difference of the logs, right?", "tokens": [50364, 400, 291, 528, 281, 652, 264, 1507, 412, 264, 2767, 382, 1359, 382, 1944, 13, 50664, 50664, 407, 2602, 295, 5138, 3319, 280, 295, 288, 11, 321, 434, 516, 281, 17522, 3175, 3565, 280, 295, 288, 13, 50914, 50914, 407, 3175, 3565, 280, 295, 288, 11, 370, 498, 286, 747, 264, 3565, 295, 341, 8509, 11, 51114, 51114, 286, 478, 516, 281, 483, 264, 2649, 295, 729, 732, 2115, 13, 51314, 51314, 440, 3565, 295, 264, 2649, 11, 291, 458, 11, 264, 2649, 295, 264, 20820, 295, 729, 732, 2115, 13, 51564, 51564, 440, 3565, 295, 264, 8509, 307, 264, 2649, 295, 264, 20820, 11, 558, 30, 51664, 51664], "temperature": 0.0, "avg_logprob": -0.06849710790960638, "compression_ratio": 2.046875, "no_speech_prob": 1.045084536599461e-05}, {"id": 791, "seek": 448656, "start": 4486.56, "end": 4490.56, "text": " So I get log of e to the minus beta e of y,", "tokens": [50364, 407, 286, 483, 3565, 295, 308, 281, 264, 3175, 9861, 308, 295, 288, 11, 50564, 50564, 293, 550, 286, 2041, 286, 483, 3175, 3565, 11573, 670, 288, 295, 308, 281, 264, 3175, 9861, 308, 295, 288, 13, 51214, 51214, 286, 747, 264, 3671, 295, 341, 570, 286, 528, 281, 17522, 11, 1392, 11, 51464, 51464, 370, 3671, 3565, 8482, 307, 437, 286, 528, 281, 17522, 11, 51664, 51664, 293, 286, 483, 264, 1036, 2445, 510, 412, 264, 2767, 13, 51764, 51764], "temperature": 0.0, "avg_logprob": -0.08758862621812935, "compression_ratio": 1.795031055900621, "no_speech_prob": 1.1478362466732506e-05}, {"id": 792, "seek": 448656, "start": 4490.56, "end": 4503.56, "text": " and then I guess I get minus log integral over y of e to the minus beta e of y.", "tokens": [50364, 407, 286, 483, 3565, 295, 308, 281, 264, 3175, 9861, 308, 295, 288, 11, 50564, 50564, 293, 550, 286, 2041, 286, 483, 3175, 3565, 11573, 670, 288, 295, 308, 281, 264, 3175, 9861, 308, 295, 288, 13, 51214, 51214, 286, 747, 264, 3671, 295, 341, 570, 286, 528, 281, 17522, 11, 1392, 11, 51464, 51464, 370, 3671, 3565, 8482, 307, 437, 286, 528, 281, 17522, 11, 51664, 51664, 293, 286, 483, 264, 1036, 2445, 510, 412, 264, 2767, 13, 51764, 51764], "temperature": 0.0, "avg_logprob": -0.08758862621812935, "compression_ratio": 1.795031055900621, "no_speech_prob": 1.1478362466732506e-05}, {"id": 793, "seek": 448656, "start": 4503.56, "end": 4508.56, "text": " I take the negative of this because I want to minimize, okay,", "tokens": [50364, 407, 286, 483, 3565, 295, 308, 281, 264, 3175, 9861, 308, 295, 288, 11, 50564, 50564, 293, 550, 286, 2041, 286, 483, 3175, 3565, 11573, 670, 288, 295, 308, 281, 264, 3175, 9861, 308, 295, 288, 13, 51214, 51214, 286, 747, 264, 3671, 295, 341, 570, 286, 528, 281, 17522, 11, 1392, 11, 51464, 51464, 370, 3671, 3565, 8482, 307, 437, 286, 528, 281, 17522, 11, 51664, 51664, 293, 286, 483, 264, 1036, 2445, 510, 412, 264, 2767, 13, 51764, 51764], "temperature": 0.0, "avg_logprob": -0.08758862621812935, "compression_ratio": 1.795031055900621, "no_speech_prob": 1.1478362466732506e-05}, {"id": 794, "seek": 448656, "start": 4508.56, "end": 4512.56, "text": " so negative log probability is what I want to minimize,", "tokens": [50364, 407, 286, 483, 3565, 295, 308, 281, 264, 3175, 9861, 308, 295, 288, 11, 50564, 50564, 293, 550, 286, 2041, 286, 483, 3175, 3565, 11573, 670, 288, 295, 308, 281, 264, 3175, 9861, 308, 295, 288, 13, 51214, 51214, 286, 747, 264, 3671, 295, 341, 570, 286, 528, 281, 17522, 11, 1392, 11, 51464, 51464, 370, 3671, 3565, 8482, 307, 437, 286, 528, 281, 17522, 11, 51664, 51664, 293, 286, 483, 264, 1036, 2445, 510, 412, 264, 2767, 13, 51764, 51764], "temperature": 0.0, "avg_logprob": -0.08758862621812935, "compression_ratio": 1.795031055900621, "no_speech_prob": 1.1478362466732506e-05}, {"id": 795, "seek": 448656, "start": 4512.56, "end": 4514.56, "text": " and I get the last function here at the bottom.", "tokens": [50364, 407, 286, 483, 3565, 295, 308, 281, 264, 3175, 9861, 308, 295, 288, 11, 50564, 50564, 293, 550, 286, 2041, 286, 483, 3175, 3565, 11573, 670, 288, 295, 308, 281, 264, 3175, 9861, 308, 295, 288, 13, 51214, 51214, 286, 747, 264, 3671, 295, 341, 570, 286, 528, 281, 17522, 11, 1392, 11, 51464, 51464, 370, 3671, 3565, 8482, 307, 437, 286, 528, 281, 17522, 11, 51664, 51664, 293, 286, 483, 264, 1036, 2445, 510, 412, 264, 2767, 13, 51764, 51764], "temperature": 0.0, "avg_logprob": -0.08758862621812935, "compression_ratio": 1.795031055900621, "no_speech_prob": 1.1478362466732506e-05}, {"id": 796, "seek": 451456, "start": 4514.56, "end": 4519.56, "text": " I divided everything by beta, which makes no difference as far as the minimum is concerned.", "tokens": [50364, 286, 6666, 1203, 538, 9861, 11, 597, 1669, 572, 2649, 382, 1400, 382, 264, 7285, 307, 5922, 13, 50614, 50614, 1033, 11, 370, 281, 352, 490, 264, 1192, 8513, 281, 264, 2767, 8513, 11, 50814, 50814, 291, 747, 3175, 3565, 295, 264, 1192, 8513, 293, 291, 9845, 538, 9861, 13, 51064, 51064, 407, 586, 321, 362, 257, 11, 300, 2709, 505, 257, 1036, 2445, 11, 51214, 51214, 293, 341, 1036, 2445, 562, 321, 17522, 309, 1619, 652, 264, 2281, 295, 264, 1412, 935, 288, 382, 2295, 382, 1944, 13, 51514, 51514, 462, 295, 288, 820, 312, 1359, 13, 51714, 51714], "temperature": 0.0, "avg_logprob": -0.11650573506074793, "compression_ratio": 1.6553191489361703, "no_speech_prob": 1.834178328863345e-05}, {"id": 797, "seek": 451456, "start": 4519.56, "end": 4523.56, "text": " Okay, so to go from the top formula to the bottom formula,", "tokens": [50364, 286, 6666, 1203, 538, 9861, 11, 597, 1669, 572, 2649, 382, 1400, 382, 264, 7285, 307, 5922, 13, 50614, 50614, 1033, 11, 370, 281, 352, 490, 264, 1192, 8513, 281, 264, 2767, 8513, 11, 50814, 50814, 291, 747, 3175, 3565, 295, 264, 1192, 8513, 293, 291, 9845, 538, 9861, 13, 51064, 51064, 407, 586, 321, 362, 257, 11, 300, 2709, 505, 257, 1036, 2445, 11, 51214, 51214, 293, 341, 1036, 2445, 562, 321, 17522, 309, 1619, 652, 264, 2281, 295, 264, 1412, 935, 288, 382, 2295, 382, 1944, 13, 51514, 51514, 462, 295, 288, 820, 312, 1359, 13, 51714, 51714], "temperature": 0.0, "avg_logprob": -0.11650573506074793, "compression_ratio": 1.6553191489361703, "no_speech_prob": 1.834178328863345e-05}, {"id": 798, "seek": 451456, "start": 4523.56, "end": 4528.56, "text": " you take minus log of the top formula and you divide by beta.", "tokens": [50364, 286, 6666, 1203, 538, 9861, 11, 597, 1669, 572, 2649, 382, 1400, 382, 264, 7285, 307, 5922, 13, 50614, 50614, 1033, 11, 370, 281, 352, 490, 264, 1192, 8513, 281, 264, 2767, 8513, 11, 50814, 50814, 291, 747, 3175, 3565, 295, 264, 1192, 8513, 293, 291, 9845, 538, 9861, 13, 51064, 51064, 407, 586, 321, 362, 257, 11, 300, 2709, 505, 257, 1036, 2445, 11, 51214, 51214, 293, 341, 1036, 2445, 562, 321, 17522, 309, 1619, 652, 264, 2281, 295, 264, 1412, 935, 288, 382, 2295, 382, 1944, 13, 51514, 51514, 462, 295, 288, 820, 312, 1359, 13, 51714, 51714], "temperature": 0.0, "avg_logprob": -0.11650573506074793, "compression_ratio": 1.6553191489361703, "no_speech_prob": 1.834178328863345e-05}, {"id": 799, "seek": 451456, "start": 4528.56, "end": 4531.56, "text": " So now we have a, that gives us a last function,", "tokens": [50364, 286, 6666, 1203, 538, 9861, 11, 597, 1669, 572, 2649, 382, 1400, 382, 264, 7285, 307, 5922, 13, 50614, 50614, 1033, 11, 370, 281, 352, 490, 264, 1192, 8513, 281, 264, 2767, 8513, 11, 50814, 50814, 291, 747, 3175, 3565, 295, 264, 1192, 8513, 293, 291, 9845, 538, 9861, 13, 51064, 51064, 407, 586, 321, 362, 257, 11, 300, 2709, 505, 257, 1036, 2445, 11, 51214, 51214, 293, 341, 1036, 2445, 562, 321, 17522, 309, 1619, 652, 264, 2281, 295, 264, 1412, 935, 288, 382, 2295, 382, 1944, 13, 51514, 51514, 462, 295, 288, 820, 312, 1359, 13, 51714, 51714], "temperature": 0.0, "avg_logprob": -0.11650573506074793, "compression_ratio": 1.6553191489361703, "no_speech_prob": 1.834178328863345e-05}, {"id": 800, "seek": 451456, "start": 4531.56, "end": 4537.56, "text": " and this last function when we minimize it says make the energy of the data point y as low as possible.", "tokens": [50364, 286, 6666, 1203, 538, 9861, 11, 597, 1669, 572, 2649, 382, 1400, 382, 264, 7285, 307, 5922, 13, 50614, 50614, 1033, 11, 370, 281, 352, 490, 264, 1192, 8513, 281, 264, 2767, 8513, 11, 50814, 50814, 291, 747, 3175, 3565, 295, 264, 1192, 8513, 293, 291, 9845, 538, 9861, 13, 51064, 51064, 407, 586, 321, 362, 257, 11, 300, 2709, 505, 257, 1036, 2445, 11, 51214, 51214, 293, 341, 1036, 2445, 562, 321, 17522, 309, 1619, 652, 264, 2281, 295, 264, 1412, 935, 288, 382, 2295, 382, 1944, 13, 51514, 51514, 462, 295, 288, 820, 312, 1359, 13, 51714, 51714], "temperature": 0.0, "avg_logprob": -0.11650573506074793, "compression_ratio": 1.6553191489361703, "no_speech_prob": 1.834178328863345e-05}, {"id": 801, "seek": 451456, "start": 4537.56, "end": 4541.56, "text": " E of y should be small.", "tokens": [50364, 286, 6666, 1203, 538, 9861, 11, 597, 1669, 572, 2649, 382, 1400, 382, 264, 7285, 307, 5922, 13, 50614, 50614, 1033, 11, 370, 281, 352, 490, 264, 1192, 8513, 281, 264, 2767, 8513, 11, 50814, 50814, 291, 747, 3175, 3565, 295, 264, 1192, 8513, 293, 291, 9845, 538, 9861, 13, 51064, 51064, 407, 586, 321, 362, 257, 11, 300, 2709, 505, 257, 1036, 2445, 11, 51214, 51214, 293, 341, 1036, 2445, 562, 321, 17522, 309, 1619, 652, 264, 2281, 295, 264, 1412, 935, 288, 382, 2295, 382, 1944, 13, 51514, 51514, 462, 295, 288, 820, 312, 1359, 13, 51714, 51714], "temperature": 0.0, "avg_logprob": -0.11650573506074793, "compression_ratio": 1.6553191489361703, "no_speech_prob": 1.834178328863345e-05}, {"id": 802, "seek": 454156, "start": 4541.56, "end": 4544.56, "text": " So I make the second term as small as possible,", "tokens": [50364, 407, 286, 652, 264, 1150, 1433, 382, 1359, 382, 1944, 11, 50514, 50514, 597, 1355, 652, 264, 25737, 300, 366, 1854, 295, 341, 21510, 3175, 382, 2416, 382, 1944, 13, 51014, 51014, 407, 264, 1150, 1433, 307, 516, 281, 2944, 493, 322, 264, 2281, 295, 633, 935, 11, 3009, 264, 1412, 935, 13, 51464, 51464, 823, 498, 286, 14722, 264, 16235, 295, 341, 10024, 2445, 11, 51564, 51564, 370, 341, 307, 264, 31959, 3142, 3109, 11, 1392, 11, 6674, 22119, 13, 51764, 51764], "temperature": 0.0, "avg_logprob": -0.07975430769078871, "compression_ratio": 1.646788990825688, "no_speech_prob": 1.012968823488336e-05}, {"id": 803, "seek": 454156, "start": 4544.56, "end": 4554.56, "text": " which means make the energies that are inside of this exponential minus as large as possible.", "tokens": [50364, 407, 286, 652, 264, 1150, 1433, 382, 1359, 382, 1944, 11, 50514, 50514, 597, 1355, 652, 264, 25737, 300, 366, 1854, 295, 341, 21510, 3175, 382, 2416, 382, 1944, 13, 51014, 51014, 407, 264, 1150, 1433, 307, 516, 281, 2944, 493, 322, 264, 2281, 295, 633, 935, 11, 3009, 264, 1412, 935, 13, 51464, 51464, 823, 498, 286, 14722, 264, 16235, 295, 341, 10024, 2445, 11, 51564, 51564, 370, 341, 307, 264, 31959, 3142, 3109, 11, 1392, 11, 6674, 22119, 13, 51764, 51764], "temperature": 0.0, "avg_logprob": -0.07975430769078871, "compression_ratio": 1.646788990825688, "no_speech_prob": 1.012968823488336e-05}, {"id": 804, "seek": 454156, "start": 4554.56, "end": 4563.56, "text": " So the second term is going to push up on the energy of every point, including the data point.", "tokens": [50364, 407, 286, 652, 264, 1150, 1433, 382, 1359, 382, 1944, 11, 50514, 50514, 597, 1355, 652, 264, 25737, 300, 366, 1854, 295, 341, 21510, 3175, 382, 2416, 382, 1944, 13, 51014, 51014, 407, 264, 1150, 1433, 307, 516, 281, 2944, 493, 322, 264, 2281, 295, 633, 935, 11, 3009, 264, 1412, 935, 13, 51464, 51464, 823, 498, 286, 14722, 264, 16235, 295, 341, 10024, 2445, 11, 51564, 51564, 370, 341, 307, 264, 31959, 3142, 3109, 11, 1392, 11, 6674, 22119, 13, 51764, 51764], "temperature": 0.0, "avg_logprob": -0.07975430769078871, "compression_ratio": 1.646788990825688, "no_speech_prob": 1.012968823488336e-05}, {"id": 805, "seek": 454156, "start": 4563.56, "end": 4565.56, "text": " Now if I compute the gradient of this objective function,", "tokens": [50364, 407, 286, 652, 264, 1150, 1433, 382, 1359, 382, 1944, 11, 50514, 50514, 597, 1355, 652, 264, 25737, 300, 366, 1854, 295, 341, 21510, 3175, 382, 2416, 382, 1944, 13, 51014, 51014, 407, 264, 1150, 1433, 307, 516, 281, 2944, 493, 322, 264, 2281, 295, 633, 935, 11, 3009, 264, 1412, 935, 13, 51464, 51464, 823, 498, 286, 14722, 264, 16235, 295, 341, 10024, 2445, 11, 51564, 51564, 370, 341, 307, 264, 31959, 3142, 3109, 11, 1392, 11, 6674, 22119, 13, 51764, 51764], "temperature": 0.0, "avg_logprob": -0.07975430769078871, "compression_ratio": 1.646788990825688, "no_speech_prob": 1.012968823488336e-05}, {"id": 806, "seek": 454156, "start": 4565.56, "end": 4569.56, "text": " so this is the probabilistic approach, okay, maximum likelihood.", "tokens": [50364, 407, 286, 652, 264, 1150, 1433, 382, 1359, 382, 1944, 11, 50514, 50514, 597, 1355, 652, 264, 25737, 300, 366, 1854, 295, 341, 21510, 3175, 382, 2416, 382, 1944, 13, 51014, 51014, 407, 264, 1150, 1433, 307, 516, 281, 2944, 493, 322, 264, 2281, 295, 633, 935, 11, 3009, 264, 1412, 935, 13, 51464, 51464, 823, 498, 286, 14722, 264, 16235, 295, 341, 10024, 2445, 11, 51564, 51564, 370, 341, 307, 264, 31959, 3142, 3109, 11, 1392, 11, 6674, 22119, 13, 51764, 51764], "temperature": 0.0, "avg_logprob": -0.07975430769078871, "compression_ratio": 1.646788990825688, "no_speech_prob": 1.012968823488336e-05}, {"id": 807, "seek": 456956, "start": 4569.56, "end": 4571.56, "text": " If I compute the gradient of this objective function,", "tokens": [50364, 759, 286, 14722, 264, 16235, 295, 341, 10024, 2445, 11, 50464, 50464, 286, 483, 264, 16235, 295, 264, 2281, 412, 264, 1412, 935, 288, 11, 1392, 11, 50714, 50714, 3175, 341, 8513, 510, 11, 597, 307, 264, 5176, 2158, 670, 288, 51114, 51114, 295, 264, 8482, 300, 452, 2316, 2709, 281, 288, 300, 307, 2212, 538, 264, 30199, 12, 54, 401, 602, 12, 50, 1424, 409, 268, 7316, 11, 51464, 51464, 293, 300, 307, 1143, 382, 257, 17619, 281, 13843, 264, 16235, 295, 264, 2281, 2445, 412, 300, 4914, 11, 1392, 13, 51764, 51764], "temperature": 0.0, "avg_logprob": -0.1568796435991923, "compression_ratio": 1.7361111111111112, "no_speech_prob": 3.023945464519784e-05}, {"id": 808, "seek": 456956, "start": 4571.56, "end": 4576.56, "text": " I get the gradient of the energy at the data point y, okay,", "tokens": [50364, 759, 286, 14722, 264, 16235, 295, 341, 10024, 2445, 11, 50464, 50464, 286, 483, 264, 16235, 295, 264, 2281, 412, 264, 1412, 935, 288, 11, 1392, 11, 50714, 50714, 3175, 341, 8513, 510, 11, 597, 307, 264, 5176, 2158, 670, 288, 51114, 51114, 295, 264, 8482, 300, 452, 2316, 2709, 281, 288, 300, 307, 2212, 538, 264, 30199, 12, 54, 401, 602, 12, 50, 1424, 409, 268, 7316, 11, 51464, 51464, 293, 300, 307, 1143, 382, 257, 17619, 281, 13843, 264, 16235, 295, 264, 2281, 2445, 412, 300, 4914, 11, 1392, 13, 51764, 51764], "temperature": 0.0, "avg_logprob": -0.1568796435991923, "compression_ratio": 1.7361111111111112, "no_speech_prob": 3.023945464519784e-05}, {"id": 809, "seek": 456956, "start": 4576.56, "end": 4584.56, "text": " minus this formula here, which is the expected value over y", "tokens": [50364, 759, 286, 14722, 264, 16235, 295, 341, 10024, 2445, 11, 50464, 50464, 286, 483, 264, 16235, 295, 264, 2281, 412, 264, 1412, 935, 288, 11, 1392, 11, 50714, 50714, 3175, 341, 8513, 510, 11, 597, 307, 264, 5176, 2158, 670, 288, 51114, 51114, 295, 264, 8482, 300, 452, 2316, 2709, 281, 288, 300, 307, 2212, 538, 264, 30199, 12, 54, 401, 602, 12, 50, 1424, 409, 268, 7316, 11, 51464, 51464, 293, 300, 307, 1143, 382, 257, 17619, 281, 13843, 264, 16235, 295, 264, 2281, 2445, 412, 300, 4914, 11, 1392, 13, 51764, 51764], "temperature": 0.0, "avg_logprob": -0.1568796435991923, "compression_ratio": 1.7361111111111112, "no_speech_prob": 3.023945464519784e-05}, {"id": 810, "seek": 456956, "start": 4584.56, "end": 4591.56, "text": " of the probability that my model gives to y that is given by the Gibbs-Wolff-Sprunen distribution,", "tokens": [50364, 759, 286, 14722, 264, 16235, 295, 341, 10024, 2445, 11, 50464, 50464, 286, 483, 264, 16235, 295, 264, 2281, 412, 264, 1412, 935, 288, 11, 1392, 11, 50714, 50714, 3175, 341, 8513, 510, 11, 597, 307, 264, 5176, 2158, 670, 288, 51114, 51114, 295, 264, 8482, 300, 452, 2316, 2709, 281, 288, 300, 307, 2212, 538, 264, 30199, 12, 54, 401, 602, 12, 50, 1424, 409, 268, 7316, 11, 51464, 51464, 293, 300, 307, 1143, 382, 257, 17619, 281, 13843, 264, 16235, 295, 264, 2281, 2445, 412, 300, 4914, 11, 1392, 13, 51764, 51764], "temperature": 0.0, "avg_logprob": -0.1568796435991923, "compression_ratio": 1.7361111111111112, "no_speech_prob": 3.023945464519784e-05}, {"id": 811, "seek": 456956, "start": 4591.56, "end": 4597.56, "text": " and that is used as a coefficient to weigh the gradient of the energy function at that location, okay.", "tokens": [50364, 759, 286, 14722, 264, 16235, 295, 341, 10024, 2445, 11, 50464, 50464, 286, 483, 264, 16235, 295, 264, 2281, 412, 264, 1412, 935, 288, 11, 1392, 11, 50714, 50714, 3175, 341, 8513, 510, 11, 597, 307, 264, 5176, 2158, 670, 288, 51114, 51114, 295, 264, 8482, 300, 452, 2316, 2709, 281, 288, 300, 307, 2212, 538, 264, 30199, 12, 54, 401, 602, 12, 50, 1424, 409, 268, 7316, 11, 51464, 51464, 293, 300, 307, 1143, 382, 257, 17619, 281, 13843, 264, 16235, 295, 264, 2281, 2445, 412, 300, 4914, 11, 1392, 13, 51764, 51764], "temperature": 0.0, "avg_logprob": -0.1568796435991923, "compression_ratio": 1.7361111111111112, "no_speech_prob": 3.023945464519784e-05}, {"id": 812, "seek": 459756, "start": 4597.56, "end": 4603.56, "text": " So this integral here, the second term, is basically an expected value of the gradient.", "tokens": [50364, 407, 341, 11573, 510, 11, 264, 1150, 1433, 11, 307, 1936, 364, 5176, 2158, 295, 264, 16235, 13, 50664, 50664, 286, 14722, 264, 16235, 295, 264, 2281, 2445, 412, 633, 935, 13, 50814, 50814, 286, 13843, 633, 935, 538, 264, 8482, 300, 264, 2316, 2709, 281, 300, 1729, 288, 11, 51064, 51064, 293, 286, 14722, 300, 32807, 2408, 4476, 13, 51214, 51214, 759, 288, 307, 27706, 11, 341, 307, 257, 27706, 2408, 13, 51314, 51314, 759, 288, 307, 10957, 11, 309, 311, 364, 11573, 13, 51714, 51714], "temperature": 0.0, "avg_logprob": -0.07948237322689441, "compression_ratio": 1.7281553398058251, "no_speech_prob": 1.1478216947580222e-05}, {"id": 813, "seek": 459756, "start": 4603.56, "end": 4606.56, "text": " I compute the gradient of the energy function at every point.", "tokens": [50364, 407, 341, 11573, 510, 11, 264, 1150, 1433, 11, 307, 1936, 364, 5176, 2158, 295, 264, 16235, 13, 50664, 50664, 286, 14722, 264, 16235, 295, 264, 2281, 2445, 412, 633, 935, 13, 50814, 50814, 286, 13843, 633, 935, 538, 264, 8482, 300, 264, 2316, 2709, 281, 300, 1729, 288, 11, 51064, 51064, 293, 286, 14722, 300, 32807, 2408, 4476, 13, 51214, 51214, 759, 288, 307, 27706, 11, 341, 307, 257, 27706, 2408, 13, 51314, 51314, 759, 288, 307, 10957, 11, 309, 311, 364, 11573, 13, 51714, 51714], "temperature": 0.0, "avg_logprob": -0.07948237322689441, "compression_ratio": 1.7281553398058251, "no_speech_prob": 1.1478216947580222e-05}, {"id": 814, "seek": 459756, "start": 4606.56, "end": 4611.56, "text": " I weigh every point by the probability that the model gives to that particular y,", "tokens": [50364, 407, 341, 11573, 510, 11, 264, 1150, 1433, 11, 307, 1936, 364, 5176, 2158, 295, 264, 16235, 13, 50664, 50664, 286, 14722, 264, 16235, 295, 264, 2281, 2445, 412, 633, 935, 13, 50814, 50814, 286, 13843, 633, 935, 538, 264, 8482, 300, 264, 2316, 2709, 281, 300, 1729, 288, 11, 51064, 51064, 293, 286, 14722, 300, 32807, 2408, 4476, 13, 51214, 51214, 759, 288, 307, 27706, 11, 341, 307, 257, 27706, 2408, 13, 51314, 51314, 759, 288, 307, 10957, 11, 309, 311, 364, 11573, 13, 51714, 51714], "temperature": 0.0, "avg_logprob": -0.07948237322689441, "compression_ratio": 1.7281553398058251, "no_speech_prob": 1.1478216947580222e-05}, {"id": 815, "seek": 459756, "start": 4611.56, "end": 4614.56, "text": " and I compute that weighted sum essentially.", "tokens": [50364, 407, 341, 11573, 510, 11, 264, 1150, 1433, 11, 307, 1936, 364, 5176, 2158, 295, 264, 16235, 13, 50664, 50664, 286, 14722, 264, 16235, 295, 264, 2281, 2445, 412, 633, 935, 13, 50814, 50814, 286, 13843, 633, 935, 538, 264, 8482, 300, 264, 2316, 2709, 281, 300, 1729, 288, 11, 51064, 51064, 293, 286, 14722, 300, 32807, 2408, 4476, 13, 51214, 51214, 759, 288, 307, 27706, 11, 341, 307, 257, 27706, 2408, 13, 51314, 51314, 759, 288, 307, 10957, 11, 309, 311, 364, 11573, 13, 51714, 51714], "temperature": 0.0, "avg_logprob": -0.07948237322689441, "compression_ratio": 1.7281553398058251, "no_speech_prob": 1.1478216947580222e-05}, {"id": 816, "seek": 459756, "start": 4614.56, "end": 4616.56, "text": " If y is discrete, this is a discrete sum.", "tokens": [50364, 407, 341, 11573, 510, 11, 264, 1150, 1433, 11, 307, 1936, 364, 5176, 2158, 295, 264, 16235, 13, 50664, 50664, 286, 14722, 264, 16235, 295, 264, 2281, 2445, 412, 633, 935, 13, 50814, 50814, 286, 13843, 633, 935, 538, 264, 8482, 300, 264, 2316, 2709, 281, 300, 1729, 288, 11, 51064, 51064, 293, 286, 14722, 300, 32807, 2408, 4476, 13, 51214, 51214, 759, 288, 307, 27706, 11, 341, 307, 257, 27706, 2408, 13, 51314, 51314, 759, 288, 307, 10957, 11, 309, 311, 364, 11573, 13, 51714, 51714], "temperature": 0.0, "avg_logprob": -0.07948237322689441, "compression_ratio": 1.7281553398058251, "no_speech_prob": 1.1478216947580222e-05}, {"id": 817, "seek": 459756, "start": 4616.56, "end": 4624.56, "text": " If y is continuous, it's an integral.", "tokens": [50364, 407, 341, 11573, 510, 11, 264, 1150, 1433, 11, 307, 1936, 364, 5176, 2158, 295, 264, 16235, 13, 50664, 50664, 286, 14722, 264, 16235, 295, 264, 2281, 2445, 412, 633, 935, 13, 50814, 50814, 286, 13843, 633, 935, 538, 264, 8482, 300, 264, 2316, 2709, 281, 300, 1729, 288, 11, 51064, 51064, 293, 286, 14722, 300, 32807, 2408, 4476, 13, 51214, 51214, 759, 288, 307, 27706, 11, 341, 307, 257, 27706, 2408, 13, 51314, 51314, 759, 288, 307, 10957, 11, 309, 311, 364, 11573, 13, 51714, 51714], "temperature": 0.0, "avg_logprob": -0.07948237322689441, "compression_ratio": 1.7281553398058251, "no_speech_prob": 1.1478216947580222e-05}, {"id": 818, "seek": 462456, "start": 4624.56, "end": 4630.56, "text": " So the first term, so now if I use this in a gradient, you know, a stochastic gradient algorithm,", "tokens": [50364, 407, 264, 700, 1433, 11, 370, 586, 498, 286, 764, 341, 294, 257, 16235, 11, 291, 458, 11, 257, 342, 8997, 2750, 16235, 9284, 11, 50664, 50664, 264, 700, 1433, 307, 516, 281, 853, 281, 652, 264, 2281, 295, 452, 1412, 935, 382, 1359, 382, 1944, 11, 50914, 50914, 293, 264, 1150, 1433, 307, 516, 281, 2944, 484, 264, 2281, 295, 633, 2167, 935, 11, 633, 288, 11, 1392, 13, 51214, 51214, 400, 264, 1154, 307, 11, 393, 286, 14722, 341, 412, 439, 30, 51364, 51364, 1664, 286, 14722, 341, 11573, 30, 51464, 51464, 407, 364, 11322, 16635, 295, 25618, 294, 31959, 3142, 15983, 362, 281, 360, 365, 11, 51764, 51764], "temperature": 0.0, "avg_logprob": -0.07408375866645206, "compression_ratio": 1.763265306122449, "no_speech_prob": 2.2124066163087264e-05}, {"id": 819, "seek": 462456, "start": 4630.56, "end": 4635.56, "text": " the first term is going to try to make the energy of my data point as small as possible,", "tokens": [50364, 407, 264, 700, 1433, 11, 370, 586, 498, 286, 764, 341, 294, 257, 16235, 11, 291, 458, 11, 257, 342, 8997, 2750, 16235, 9284, 11, 50664, 50664, 264, 700, 1433, 307, 516, 281, 853, 281, 652, 264, 2281, 295, 452, 1412, 935, 382, 1359, 382, 1944, 11, 50914, 50914, 293, 264, 1150, 1433, 307, 516, 281, 2944, 484, 264, 2281, 295, 633, 2167, 935, 11, 633, 288, 11, 1392, 13, 51214, 51214, 400, 264, 1154, 307, 11, 393, 286, 14722, 341, 412, 439, 30, 51364, 51364, 1664, 286, 14722, 341, 11573, 30, 51464, 51464, 407, 364, 11322, 16635, 295, 25618, 294, 31959, 3142, 15983, 362, 281, 360, 365, 11, 51764, 51764], "temperature": 0.0, "avg_logprob": -0.07408375866645206, "compression_ratio": 1.763265306122449, "no_speech_prob": 2.2124066163087264e-05}, {"id": 820, "seek": 462456, "start": 4635.56, "end": 4641.56, "text": " and the second term is going to push out the energy of every single point, every y, okay.", "tokens": [50364, 407, 264, 700, 1433, 11, 370, 586, 498, 286, 764, 341, 294, 257, 16235, 11, 291, 458, 11, 257, 342, 8997, 2750, 16235, 9284, 11, 50664, 50664, 264, 700, 1433, 307, 516, 281, 853, 281, 652, 264, 2281, 295, 452, 1412, 935, 382, 1359, 382, 1944, 11, 50914, 50914, 293, 264, 1150, 1433, 307, 516, 281, 2944, 484, 264, 2281, 295, 633, 2167, 935, 11, 633, 288, 11, 1392, 13, 51214, 51214, 400, 264, 1154, 307, 11, 393, 286, 14722, 341, 412, 439, 30, 51364, 51364, 1664, 286, 14722, 341, 11573, 30, 51464, 51464, 407, 364, 11322, 16635, 295, 25618, 294, 31959, 3142, 15983, 362, 281, 360, 365, 11, 51764, 51764], "temperature": 0.0, "avg_logprob": -0.07408375866645206, "compression_ratio": 1.763265306122449, "no_speech_prob": 2.2124066163087264e-05}, {"id": 821, "seek": 462456, "start": 4641.56, "end": 4644.56, "text": " And the problem is, can I compute this at all?", "tokens": [50364, 407, 264, 700, 1433, 11, 370, 586, 498, 286, 764, 341, 294, 257, 16235, 11, 291, 458, 11, 257, 342, 8997, 2750, 16235, 9284, 11, 50664, 50664, 264, 700, 1433, 307, 516, 281, 853, 281, 652, 264, 2281, 295, 452, 1412, 935, 382, 1359, 382, 1944, 11, 50914, 50914, 293, 264, 1150, 1433, 307, 516, 281, 2944, 484, 264, 2281, 295, 633, 2167, 935, 11, 633, 288, 11, 1392, 13, 51214, 51214, 400, 264, 1154, 307, 11, 393, 286, 14722, 341, 412, 439, 30, 51364, 51364, 1664, 286, 14722, 341, 11573, 30, 51464, 51464, 407, 364, 11322, 16635, 295, 25618, 294, 31959, 3142, 15983, 362, 281, 360, 365, 11, 51764, 51764], "temperature": 0.0, "avg_logprob": -0.07408375866645206, "compression_ratio": 1.763265306122449, "no_speech_prob": 2.2124066163087264e-05}, {"id": 822, "seek": 462456, "start": 4644.56, "end": 4646.56, "text": " Can I compute this integral?", "tokens": [50364, 407, 264, 700, 1433, 11, 370, 586, 498, 286, 764, 341, 294, 257, 16235, 11, 291, 458, 11, 257, 342, 8997, 2750, 16235, 9284, 11, 50664, 50664, 264, 700, 1433, 307, 516, 281, 853, 281, 652, 264, 2281, 295, 452, 1412, 935, 382, 1359, 382, 1944, 11, 50914, 50914, 293, 264, 1150, 1433, 307, 516, 281, 2944, 484, 264, 2281, 295, 633, 2167, 935, 11, 633, 288, 11, 1392, 13, 51214, 51214, 400, 264, 1154, 307, 11, 393, 286, 14722, 341, 412, 439, 30, 51364, 51364, 1664, 286, 14722, 341, 11573, 30, 51464, 51464, 407, 364, 11322, 16635, 295, 25618, 294, 31959, 3142, 15983, 362, 281, 360, 365, 11, 51764, 51764], "temperature": 0.0, "avg_logprob": -0.07408375866645206, "compression_ratio": 1.763265306122449, "no_speech_prob": 2.2124066163087264e-05}, {"id": 823, "seek": 462456, "start": 4646.56, "end": 4652.56, "text": " So an enormous chunk of publications in probabilistic modeling have to do with,", "tokens": [50364, 407, 264, 700, 1433, 11, 370, 586, 498, 286, 764, 341, 294, 257, 16235, 11, 291, 458, 11, 257, 342, 8997, 2750, 16235, 9284, 11, 50664, 50664, 264, 700, 1433, 307, 516, 281, 853, 281, 652, 264, 2281, 295, 452, 1412, 935, 382, 1359, 382, 1944, 11, 50914, 50914, 293, 264, 1150, 1433, 307, 516, 281, 2944, 484, 264, 2281, 295, 633, 2167, 935, 11, 633, 288, 11, 1392, 13, 51214, 51214, 400, 264, 1154, 307, 11, 393, 286, 14722, 341, 412, 439, 30, 51364, 51364, 1664, 286, 14722, 341, 11573, 30, 51464, 51464, 407, 364, 11322, 16635, 295, 25618, 294, 31959, 3142, 15983, 362, 281, 360, 365, 11, 51764, 51764], "temperature": 0.0, "avg_logprob": -0.07408375866645206, "compression_ratio": 1.763265306122449, "no_speech_prob": 2.2124066163087264e-05}, {"id": 824, "seek": 465256, "start": 4652.56, "end": 4657.56, "text": " how do you either compute this, estimate this, or approximate this?", "tokens": [50364, 577, 360, 291, 2139, 14722, 341, 11, 12539, 341, 11, 420, 30874, 341, 30, 50614, 50614, 1436, 300, 11573, 307, 11, 294, 1880, 3331, 11, 307, 560, 1897, 712, 13, 50964, 50964, 1033, 11, 498, 288, 307, 264, 1901, 295, 5267, 11, 286, 2644, 14722, 364, 11573, 295, 439, 1944, 5267, 13, 51264, 51264, 821, 311, 572, 636, 13, 51364, 51364, 16192, 498, 264, 2281, 2445, 420, 264, 16235, 295, 264, 2281, 2445, 307, 588, 11, 588, 2199, 11, 1392, 13, 51614, 51614, 4534, 295, 264, 565, 309, 311, 406, 300, 2199, 13, 51714, 51714], "temperature": 0.0, "avg_logprob": -0.10430918034818984, "compression_ratio": 1.7096774193548387, "no_speech_prob": 6.603692600037903e-05}, {"id": 825, "seek": 465256, "start": 4657.56, "end": 4664.56, "text": " Because that integral is, in interesting cases, is intractable.", "tokens": [50364, 577, 360, 291, 2139, 14722, 341, 11, 12539, 341, 11, 420, 30874, 341, 30, 50614, 50614, 1436, 300, 11573, 307, 11, 294, 1880, 3331, 11, 307, 560, 1897, 712, 13, 50964, 50964, 1033, 11, 498, 288, 307, 264, 1901, 295, 5267, 11, 286, 2644, 14722, 364, 11573, 295, 439, 1944, 5267, 13, 51264, 51264, 821, 311, 572, 636, 13, 51364, 51364, 16192, 498, 264, 2281, 2445, 420, 264, 16235, 295, 264, 2281, 2445, 307, 588, 11, 588, 2199, 11, 1392, 13, 51614, 51614, 4534, 295, 264, 565, 309, 311, 406, 300, 2199, 13, 51714, 51714], "temperature": 0.0, "avg_logprob": -0.10430918034818984, "compression_ratio": 1.7096774193548387, "no_speech_prob": 6.603692600037903e-05}, {"id": 826, "seek": 465256, "start": 4664.56, "end": 4670.56, "text": " Okay, if y is the space of images, I cannot compute an integral of all possible images.", "tokens": [50364, 577, 360, 291, 2139, 14722, 341, 11, 12539, 341, 11, 420, 30874, 341, 30, 50614, 50614, 1436, 300, 11573, 307, 11, 294, 1880, 3331, 11, 307, 560, 1897, 712, 13, 50964, 50964, 1033, 11, 498, 288, 307, 264, 1901, 295, 5267, 11, 286, 2644, 14722, 364, 11573, 295, 439, 1944, 5267, 13, 51264, 51264, 821, 311, 572, 636, 13, 51364, 51364, 16192, 498, 264, 2281, 2445, 420, 264, 16235, 295, 264, 2281, 2445, 307, 588, 11, 588, 2199, 11, 1392, 13, 51614, 51614, 4534, 295, 264, 565, 309, 311, 406, 300, 2199, 13, 51714, 51714], "temperature": 0.0, "avg_logprob": -0.10430918034818984, "compression_ratio": 1.7096774193548387, "no_speech_prob": 6.603692600037903e-05}, {"id": 827, "seek": 465256, "start": 4670.56, "end": 4672.56, "text": " There's no way.", "tokens": [50364, 577, 360, 291, 2139, 14722, 341, 11, 12539, 341, 11, 420, 30874, 341, 30, 50614, 50614, 1436, 300, 11573, 307, 11, 294, 1880, 3331, 11, 307, 560, 1897, 712, 13, 50964, 50964, 1033, 11, 498, 288, 307, 264, 1901, 295, 5267, 11, 286, 2644, 14722, 364, 11573, 295, 439, 1944, 5267, 13, 51264, 51264, 821, 311, 572, 636, 13, 51364, 51364, 16192, 498, 264, 2281, 2445, 420, 264, 16235, 295, 264, 2281, 2445, 307, 588, 11, 588, 2199, 11, 1392, 13, 51614, 51614, 4534, 295, 264, 565, 309, 311, 406, 300, 2199, 13, 51714, 51714], "temperature": 0.0, "avg_logprob": -0.10430918034818984, "compression_ratio": 1.7096774193548387, "no_speech_prob": 6.603692600037903e-05}, {"id": 828, "seek": 465256, "start": 4672.56, "end": 4677.56, "text": " Except if the energy function or the gradient of the energy function is very, very simple, okay.", "tokens": [50364, 577, 360, 291, 2139, 14722, 341, 11, 12539, 341, 11, 420, 30874, 341, 30, 50614, 50614, 1436, 300, 11573, 307, 11, 294, 1880, 3331, 11, 307, 560, 1897, 712, 13, 50964, 50964, 1033, 11, 498, 288, 307, 264, 1901, 295, 5267, 11, 286, 2644, 14722, 364, 11573, 295, 439, 1944, 5267, 13, 51264, 51264, 821, 311, 572, 636, 13, 51364, 51364, 16192, 498, 264, 2281, 2445, 420, 264, 16235, 295, 264, 2281, 2445, 307, 588, 11, 588, 2199, 11, 1392, 13, 51614, 51614, 4534, 295, 264, 565, 309, 311, 406, 300, 2199, 13, 51714, 51714], "temperature": 0.0, "avg_logprob": -0.10430918034818984, "compression_ratio": 1.7096774193548387, "no_speech_prob": 6.603692600037903e-05}, {"id": 829, "seek": 465256, "start": 4677.56, "end": 4679.56, "text": " Most of the time it's not that simple.", "tokens": [50364, 577, 360, 291, 2139, 14722, 341, 11, 12539, 341, 11, 420, 30874, 341, 30, 50614, 50614, 1436, 300, 11573, 307, 11, 294, 1880, 3331, 11, 307, 560, 1897, 712, 13, 50964, 50964, 1033, 11, 498, 288, 307, 264, 1901, 295, 5267, 11, 286, 2644, 14722, 364, 11573, 295, 439, 1944, 5267, 13, 51264, 51264, 821, 311, 572, 636, 13, 51364, 51364, 16192, 498, 264, 2281, 2445, 420, 264, 16235, 295, 264, 2281, 2445, 307, 588, 11, 588, 2199, 11, 1392, 13, 51614, 51614, 4534, 295, 264, 565, 309, 311, 406, 300, 2199, 13, 51714, 51714], "temperature": 0.0, "avg_logprob": -0.10430918034818984, "compression_ratio": 1.7096774193548387, "no_speech_prob": 6.603692600037903e-05}, {"id": 830, "seek": 467956, "start": 4679.56, "end": 4683.56, "text": " So if I use this model to capture the dependency of the world, it's not going to be that simple.", "tokens": [50364, 407, 498, 286, 764, 341, 2316, 281, 7983, 264, 33621, 295, 264, 1002, 11, 309, 311, 406, 516, 281, 312, 300, 2199, 13, 50564, 50564, 467, 311, 516, 281, 312, 512, 955, 18161, 2533, 13, 50664, 50664, 407, 341, 11573, 307, 516, 281, 312, 2584, 560, 1897, 712, 13, 50864, 50864, 823, 11, 456, 307, 257, 707, 857, 295, 17456, 294, 264, 1186, 300, 341, 307, 364, 5176, 2158, 11, 51164, 51164, 293, 370, 281, 14722, 364, 28023, 295, 364, 5176, 2158, 11, 51314, 51314, 291, 393, 14722, 364, 4274, 295, 257, 19362, 1230, 295, 10938, 13, 51464, 51464, 407, 498, 286, 6889, 288, 311, 490, 341, 7316, 11, 597, 307, 264, 7316, 300, 452, 2316, 2709, 281, 288, 11, 51814, 51814], "temperature": 0.0, "avg_logprob": -0.1164943479722546, "compression_ratio": 1.8403041825095057, "no_speech_prob": 1.834176146076061e-05}, {"id": 831, "seek": 467956, "start": 4683.56, "end": 4685.56, "text": " It's going to be some big neural net.", "tokens": [50364, 407, 498, 286, 764, 341, 2316, 281, 7983, 264, 33621, 295, 264, 1002, 11, 309, 311, 406, 516, 281, 312, 300, 2199, 13, 50564, 50564, 467, 311, 516, 281, 312, 512, 955, 18161, 2533, 13, 50664, 50664, 407, 341, 11573, 307, 516, 281, 312, 2584, 560, 1897, 712, 13, 50864, 50864, 823, 11, 456, 307, 257, 707, 857, 295, 17456, 294, 264, 1186, 300, 341, 307, 364, 5176, 2158, 11, 51164, 51164, 293, 370, 281, 14722, 364, 28023, 295, 364, 5176, 2158, 11, 51314, 51314, 291, 393, 14722, 364, 4274, 295, 257, 19362, 1230, 295, 10938, 13, 51464, 51464, 407, 498, 286, 6889, 288, 311, 490, 341, 7316, 11, 597, 307, 264, 7316, 300, 452, 2316, 2709, 281, 288, 11, 51814, 51814], "temperature": 0.0, "avg_logprob": -0.1164943479722546, "compression_ratio": 1.8403041825095057, "no_speech_prob": 1.834176146076061e-05}, {"id": 832, "seek": 467956, "start": 4685.56, "end": 4689.56, "text": " So this integral is going to be completely intractable.", "tokens": [50364, 407, 498, 286, 764, 341, 2316, 281, 7983, 264, 33621, 295, 264, 1002, 11, 309, 311, 406, 516, 281, 312, 300, 2199, 13, 50564, 50564, 467, 311, 516, 281, 312, 512, 955, 18161, 2533, 13, 50664, 50664, 407, 341, 11573, 307, 516, 281, 312, 2584, 560, 1897, 712, 13, 50864, 50864, 823, 11, 456, 307, 257, 707, 857, 295, 17456, 294, 264, 1186, 300, 341, 307, 364, 5176, 2158, 11, 51164, 51164, 293, 370, 281, 14722, 364, 28023, 295, 364, 5176, 2158, 11, 51314, 51314, 291, 393, 14722, 364, 4274, 295, 257, 19362, 1230, 295, 10938, 13, 51464, 51464, 407, 498, 286, 6889, 288, 311, 490, 341, 7316, 11, 597, 307, 264, 7316, 300, 452, 2316, 2709, 281, 288, 11, 51814, 51814], "temperature": 0.0, "avg_logprob": -0.1164943479722546, "compression_ratio": 1.8403041825095057, "no_speech_prob": 1.834176146076061e-05}, {"id": 833, "seek": 467956, "start": 4689.56, "end": 4695.56, "text": " Now, there is a little bit of salvation in the fact that this is an expected value,", "tokens": [50364, 407, 498, 286, 764, 341, 2316, 281, 7983, 264, 33621, 295, 264, 1002, 11, 309, 311, 406, 516, 281, 312, 300, 2199, 13, 50564, 50564, 467, 311, 516, 281, 312, 512, 955, 18161, 2533, 13, 50664, 50664, 407, 341, 11573, 307, 516, 281, 312, 2584, 560, 1897, 712, 13, 50864, 50864, 823, 11, 456, 307, 257, 707, 857, 295, 17456, 294, 264, 1186, 300, 341, 307, 364, 5176, 2158, 11, 51164, 51164, 293, 370, 281, 14722, 364, 28023, 295, 364, 5176, 2158, 11, 51314, 51314, 291, 393, 14722, 364, 4274, 295, 257, 19362, 1230, 295, 10938, 13, 51464, 51464, 407, 498, 286, 6889, 288, 311, 490, 341, 7316, 11, 597, 307, 264, 7316, 300, 452, 2316, 2709, 281, 288, 11, 51814, 51814], "temperature": 0.0, "avg_logprob": -0.1164943479722546, "compression_ratio": 1.8403041825095057, "no_speech_prob": 1.834176146076061e-05}, {"id": 834, "seek": 467956, "start": 4695.56, "end": 4698.56, "text": " and so to compute an approximation of an expected value,", "tokens": [50364, 407, 498, 286, 764, 341, 2316, 281, 7983, 264, 33621, 295, 264, 1002, 11, 309, 311, 406, 516, 281, 312, 300, 2199, 13, 50564, 50564, 467, 311, 516, 281, 312, 512, 955, 18161, 2533, 13, 50664, 50664, 407, 341, 11573, 307, 516, 281, 312, 2584, 560, 1897, 712, 13, 50864, 50864, 823, 11, 456, 307, 257, 707, 857, 295, 17456, 294, 264, 1186, 300, 341, 307, 364, 5176, 2158, 11, 51164, 51164, 293, 370, 281, 14722, 364, 28023, 295, 364, 5176, 2158, 11, 51314, 51314, 291, 393, 14722, 364, 4274, 295, 257, 19362, 1230, 295, 10938, 13, 51464, 51464, 407, 498, 286, 6889, 288, 311, 490, 341, 7316, 11, 597, 307, 264, 7316, 300, 452, 2316, 2709, 281, 288, 11, 51814, 51814], "temperature": 0.0, "avg_logprob": -0.1164943479722546, "compression_ratio": 1.8403041825095057, "no_speech_prob": 1.834176146076061e-05}, {"id": 835, "seek": 467956, "start": 4698.56, "end": 4701.56, "text": " you can compute an average of a finite number of samples.", "tokens": [50364, 407, 498, 286, 764, 341, 2316, 281, 7983, 264, 33621, 295, 264, 1002, 11, 309, 311, 406, 516, 281, 312, 300, 2199, 13, 50564, 50564, 467, 311, 516, 281, 312, 512, 955, 18161, 2533, 13, 50664, 50664, 407, 341, 11573, 307, 516, 281, 312, 2584, 560, 1897, 712, 13, 50864, 50864, 823, 11, 456, 307, 257, 707, 857, 295, 17456, 294, 264, 1186, 300, 341, 307, 364, 5176, 2158, 11, 51164, 51164, 293, 370, 281, 14722, 364, 28023, 295, 364, 5176, 2158, 11, 51314, 51314, 291, 393, 14722, 364, 4274, 295, 257, 19362, 1230, 295, 10938, 13, 51464, 51464, 407, 498, 286, 6889, 288, 311, 490, 341, 7316, 11, 597, 307, 264, 7316, 300, 452, 2316, 2709, 281, 288, 11, 51814, 51814], "temperature": 0.0, "avg_logprob": -0.1164943479722546, "compression_ratio": 1.8403041825095057, "no_speech_prob": 1.834176146076061e-05}, {"id": 836, "seek": 467956, "start": 4701.56, "end": 4708.56, "text": " So if I sample y's from this distribution, which is the distribution that my model gives to y,", "tokens": [50364, 407, 498, 286, 764, 341, 2316, 281, 7983, 264, 33621, 295, 264, 1002, 11, 309, 311, 406, 516, 281, 312, 300, 2199, 13, 50564, 50564, 467, 311, 516, 281, 312, 512, 955, 18161, 2533, 13, 50664, 50664, 407, 341, 11573, 307, 516, 281, 312, 2584, 560, 1897, 712, 13, 50864, 50864, 823, 11, 456, 307, 257, 707, 857, 295, 17456, 294, 264, 1186, 300, 341, 307, 364, 5176, 2158, 11, 51164, 51164, 293, 370, 281, 14722, 364, 28023, 295, 364, 5176, 2158, 11, 51314, 51314, 291, 393, 14722, 364, 4274, 295, 257, 19362, 1230, 295, 10938, 13, 51464, 51464, 407, 498, 286, 6889, 288, 311, 490, 341, 7316, 11, 597, 307, 264, 7316, 300, 452, 2316, 2709, 281, 288, 11, 51814, 51814], "temperature": 0.0, "avg_logprob": -0.1164943479722546, "compression_ratio": 1.8403041825095057, "no_speech_prob": 1.834176146076061e-05}, {"id": 837, "seek": 470856, "start": 4708.56, "end": 4712.56, "text": " and I get the average of the gradient over those samples,", "tokens": [50364, 293, 286, 483, 264, 4274, 295, 264, 16235, 670, 729, 10938, 11, 50564, 50564, 286, 483, 257, 19362, 28023, 295, 341, 13, 50664, 50664, 467, 311, 1219, 38105, 45112, 7150, 13, 50814, 50814, 1033, 11, 309, 311, 1219, 38105, 45112, 28023, 11, 50964, 50964, 14479, 538, 48716, 562, 436, 645, 1382, 281, 1322, 364, 12018, 7851, 294, 264, 3356, 82, 13, 51364, 51364, 821, 366, 661, 7150, 300, 366, 2361, 322, 3034, 1478, 7150, 13, 51514, 51514, 407, 286, 500, 380, 534, 458, 577, 281, 14722, 280, 13, 286, 393, 380, 14722, 341, 11573, 11, 51714, 51714], "temperature": 0.0, "avg_logprob": -0.15265563040068655, "compression_ratio": 1.6329113924050633, "no_speech_prob": 4.1314473492093384e-05}, {"id": 838, "seek": 470856, "start": 4712.56, "end": 4714.56, "text": " I get a finite approximation of this.", "tokens": [50364, 293, 286, 483, 264, 4274, 295, 264, 16235, 670, 729, 10938, 11, 50564, 50564, 286, 483, 257, 19362, 28023, 295, 341, 13, 50664, 50664, 467, 311, 1219, 38105, 45112, 7150, 13, 50814, 50814, 1033, 11, 309, 311, 1219, 38105, 45112, 28023, 11, 50964, 50964, 14479, 538, 48716, 562, 436, 645, 1382, 281, 1322, 364, 12018, 7851, 294, 264, 3356, 82, 13, 51364, 51364, 821, 366, 661, 7150, 300, 366, 2361, 322, 3034, 1478, 7150, 13, 51514, 51514, 407, 286, 500, 380, 534, 458, 577, 281, 14722, 280, 13, 286, 393, 380, 14722, 341, 11573, 11, 51714, 51714], "temperature": 0.0, "avg_logprob": -0.15265563040068655, "compression_ratio": 1.6329113924050633, "no_speech_prob": 4.1314473492093384e-05}, {"id": 839, "seek": 470856, "start": 4714.56, "end": 4717.56, "text": " It's called Monte Carlo methods.", "tokens": [50364, 293, 286, 483, 264, 4274, 295, 264, 16235, 670, 729, 10938, 11, 50564, 50564, 286, 483, 257, 19362, 28023, 295, 341, 13, 50664, 50664, 467, 311, 1219, 38105, 45112, 7150, 13, 50814, 50814, 1033, 11, 309, 311, 1219, 38105, 45112, 28023, 11, 50964, 50964, 14479, 538, 48716, 562, 436, 645, 1382, 281, 1322, 364, 12018, 7851, 294, 264, 3356, 82, 13, 51364, 51364, 821, 366, 661, 7150, 300, 366, 2361, 322, 3034, 1478, 7150, 13, 51514, 51514, 407, 286, 500, 380, 534, 458, 577, 281, 14722, 280, 13, 286, 393, 380, 14722, 341, 11573, 11, 51714, 51714], "temperature": 0.0, "avg_logprob": -0.15265563040068655, "compression_ratio": 1.6329113924050633, "no_speech_prob": 4.1314473492093384e-05}, {"id": 840, "seek": 470856, "start": 4717.56, "end": 4720.56, "text": " Okay, it's called Monte Carlo approximation,", "tokens": [50364, 293, 286, 483, 264, 4274, 295, 264, 16235, 670, 729, 10938, 11, 50564, 50564, 286, 483, 257, 19362, 28023, 295, 341, 13, 50664, 50664, 467, 311, 1219, 38105, 45112, 7150, 13, 50814, 50814, 1033, 11, 309, 311, 1219, 38105, 45112, 28023, 11, 50964, 50964, 14479, 538, 48716, 562, 436, 645, 1382, 281, 1322, 364, 12018, 7851, 294, 264, 3356, 82, 13, 51364, 51364, 821, 366, 661, 7150, 300, 366, 2361, 322, 3034, 1478, 7150, 13, 51514, 51514, 407, 286, 500, 380, 534, 458, 577, 281, 14722, 280, 13, 286, 393, 380, 14722, 341, 11573, 11, 51714, 51714], "temperature": 0.0, "avg_logprob": -0.15265563040068655, "compression_ratio": 1.6329113924050633, "no_speech_prob": 4.1314473492093384e-05}, {"id": 841, "seek": 470856, "start": 4720.56, "end": 4728.56, "text": " invented by physicists when they were trying to build an atom bomb in the 40s.", "tokens": [50364, 293, 286, 483, 264, 4274, 295, 264, 16235, 670, 729, 10938, 11, 50564, 50564, 286, 483, 257, 19362, 28023, 295, 341, 13, 50664, 50664, 467, 311, 1219, 38105, 45112, 7150, 13, 50814, 50814, 1033, 11, 309, 311, 1219, 38105, 45112, 28023, 11, 50964, 50964, 14479, 538, 48716, 562, 436, 645, 1382, 281, 1322, 364, 12018, 7851, 294, 264, 3356, 82, 13, 51364, 51364, 821, 366, 661, 7150, 300, 366, 2361, 322, 3034, 1478, 7150, 13, 51514, 51514, 407, 286, 500, 380, 534, 458, 577, 281, 14722, 280, 13, 286, 393, 380, 14722, 341, 11573, 11, 51714, 51714], "temperature": 0.0, "avg_logprob": -0.15265563040068655, "compression_ratio": 1.6329113924050633, "no_speech_prob": 4.1314473492093384e-05}, {"id": 842, "seek": 470856, "start": 4728.56, "end": 4731.56, "text": " There are other methods that are based on variational methods.", "tokens": [50364, 293, 286, 483, 264, 4274, 295, 264, 16235, 670, 729, 10938, 11, 50564, 50564, 286, 483, 257, 19362, 28023, 295, 341, 13, 50664, 50664, 467, 311, 1219, 38105, 45112, 7150, 13, 50814, 50814, 1033, 11, 309, 311, 1219, 38105, 45112, 28023, 11, 50964, 50964, 14479, 538, 48716, 562, 436, 645, 1382, 281, 1322, 364, 12018, 7851, 294, 264, 3356, 82, 13, 51364, 51364, 821, 366, 661, 7150, 300, 366, 2361, 322, 3034, 1478, 7150, 13, 51514, 51514, 407, 286, 500, 380, 534, 458, 577, 281, 14722, 280, 13, 286, 393, 380, 14722, 341, 11573, 11, 51714, 51714], "temperature": 0.0, "avg_logprob": -0.15265563040068655, "compression_ratio": 1.6329113924050633, "no_speech_prob": 4.1314473492093384e-05}, {"id": 843, "seek": 470856, "start": 4731.56, "end": 4735.56, "text": " So I don't really know how to compute p. I can't compute this integral,", "tokens": [50364, 293, 286, 483, 264, 4274, 295, 264, 16235, 670, 729, 10938, 11, 50564, 50564, 286, 483, 257, 19362, 28023, 295, 341, 13, 50664, 50664, 467, 311, 1219, 38105, 45112, 7150, 13, 50814, 50814, 1033, 11, 309, 311, 1219, 38105, 45112, 28023, 11, 50964, 50964, 14479, 538, 48716, 562, 436, 645, 1382, 281, 1322, 364, 12018, 7851, 294, 264, 3356, 82, 13, 51364, 51364, 821, 366, 661, 7150, 300, 366, 2361, 322, 3034, 1478, 7150, 13, 51514, 51514, 407, 286, 500, 380, 534, 458, 577, 281, 14722, 280, 13, 286, 393, 380, 14722, 341, 11573, 11, 51714, 51714], "temperature": 0.0, "avg_logprob": -0.15265563040068655, "compression_ratio": 1.6329113924050633, "no_speech_prob": 4.1314473492093384e-05}, {"id": 844, "seek": 473556, "start": 4735.56, "end": 4742.56, "text": " p by another distribution q, for which I can't compute this average, let's say Gaussian or something.", "tokens": [50364, 280, 538, 1071, 7316, 9505, 11, 337, 597, 286, 393, 380, 14722, 341, 4274, 11, 718, 311, 584, 39148, 420, 746, 13, 50714, 50714, 400, 550, 286, 853, 281, 652, 9505, 382, 1998, 281, 280, 382, 1944, 13, 50814, 50814, 663, 311, 1219, 3034, 1478, 7150, 13, 50914, 50914, 1033, 11, 291, 600, 1391, 2198, 300, 1433, 867, 1413, 13, 51114, 51114, 663, 311, 257, 3875, 1558, 295, 3034, 1478, 7150, 13, 51164, 51164, 509, 30874, 364, 14334, 670, 257, 7316, 51414, 51414, 538, 19139, 264, 7316, 538, 746, 291, 393, 767, 14722, 11, 51564, 51564, 293, 291, 853, 281, 652, 341, 2807, 712, 7316, 382, 1998, 382, 1944, 281, 264, 957, 7316, 51814, 51814], "temperature": 0.0, "avg_logprob": -0.07093279585879073, "compression_ratio": 1.8475836431226766, "no_speech_prob": 4.006121525890194e-05}, {"id": 845, "seek": 473556, "start": 4742.56, "end": 4744.56, "text": " And then I try to make q as close to p as possible.", "tokens": [50364, 280, 538, 1071, 7316, 9505, 11, 337, 597, 286, 393, 380, 14722, 341, 4274, 11, 718, 311, 584, 39148, 420, 746, 13, 50714, 50714, 400, 550, 286, 853, 281, 652, 9505, 382, 1998, 281, 280, 382, 1944, 13, 50814, 50814, 663, 311, 1219, 3034, 1478, 7150, 13, 50914, 50914, 1033, 11, 291, 600, 1391, 2198, 300, 1433, 867, 1413, 13, 51114, 51114, 663, 311, 257, 3875, 1558, 295, 3034, 1478, 7150, 13, 51164, 51164, 509, 30874, 364, 14334, 670, 257, 7316, 51414, 51414, 538, 19139, 264, 7316, 538, 746, 291, 393, 767, 14722, 11, 51564, 51564, 293, 291, 853, 281, 652, 341, 2807, 712, 7316, 382, 1998, 382, 1944, 281, 264, 957, 7316, 51814, 51814], "temperature": 0.0, "avg_logprob": -0.07093279585879073, "compression_ratio": 1.8475836431226766, "no_speech_prob": 4.006121525890194e-05}, {"id": 846, "seek": 473556, "start": 4744.56, "end": 4746.56, "text": " That's called variational methods.", "tokens": [50364, 280, 538, 1071, 7316, 9505, 11, 337, 597, 286, 393, 380, 14722, 341, 4274, 11, 718, 311, 584, 39148, 420, 746, 13, 50714, 50714, 400, 550, 286, 853, 281, 652, 9505, 382, 1998, 281, 280, 382, 1944, 13, 50814, 50814, 663, 311, 1219, 3034, 1478, 7150, 13, 50914, 50914, 1033, 11, 291, 600, 1391, 2198, 300, 1433, 867, 1413, 13, 51114, 51114, 663, 311, 257, 3875, 1558, 295, 3034, 1478, 7150, 13, 51164, 51164, 509, 30874, 364, 14334, 670, 257, 7316, 51414, 51414, 538, 19139, 264, 7316, 538, 746, 291, 393, 767, 14722, 11, 51564, 51564, 293, 291, 853, 281, 652, 341, 2807, 712, 7316, 382, 1998, 382, 1944, 281, 264, 957, 7316, 51814, 51814], "temperature": 0.0, "avg_logprob": -0.07093279585879073, "compression_ratio": 1.8475836431226766, "no_speech_prob": 4.006121525890194e-05}, {"id": 847, "seek": 473556, "start": 4746.56, "end": 4750.56, "text": " Okay, you've probably heard that term many times.", "tokens": [50364, 280, 538, 1071, 7316, 9505, 11, 337, 597, 286, 393, 380, 14722, 341, 4274, 11, 718, 311, 584, 39148, 420, 746, 13, 50714, 50714, 400, 550, 286, 853, 281, 652, 9505, 382, 1998, 281, 280, 382, 1944, 13, 50814, 50814, 663, 311, 1219, 3034, 1478, 7150, 13, 50914, 50914, 1033, 11, 291, 600, 1391, 2198, 300, 1433, 867, 1413, 13, 51114, 51114, 663, 311, 257, 3875, 1558, 295, 3034, 1478, 7150, 13, 51164, 51164, 509, 30874, 364, 14334, 670, 257, 7316, 51414, 51414, 538, 19139, 264, 7316, 538, 746, 291, 393, 767, 14722, 11, 51564, 51564, 293, 291, 853, 281, 652, 341, 2807, 712, 7316, 382, 1998, 382, 1944, 281, 264, 957, 7316, 51814, 51814], "temperature": 0.0, "avg_logprob": -0.07093279585879073, "compression_ratio": 1.8475836431226766, "no_speech_prob": 4.006121525890194e-05}, {"id": 848, "seek": 473556, "start": 4750.56, "end": 4751.56, "text": " That's a basic idea of variational methods.", "tokens": [50364, 280, 538, 1071, 7316, 9505, 11, 337, 597, 286, 393, 380, 14722, 341, 4274, 11, 718, 311, 584, 39148, 420, 746, 13, 50714, 50714, 400, 550, 286, 853, 281, 652, 9505, 382, 1998, 281, 280, 382, 1944, 13, 50814, 50814, 663, 311, 1219, 3034, 1478, 7150, 13, 50914, 50914, 1033, 11, 291, 600, 1391, 2198, 300, 1433, 867, 1413, 13, 51114, 51114, 663, 311, 257, 3875, 1558, 295, 3034, 1478, 7150, 13, 51164, 51164, 509, 30874, 364, 14334, 670, 257, 7316, 51414, 51414, 538, 19139, 264, 7316, 538, 746, 291, 393, 767, 14722, 11, 51564, 51564, 293, 291, 853, 281, 652, 341, 2807, 712, 7316, 382, 1998, 382, 1944, 281, 264, 957, 7316, 51814, 51814], "temperature": 0.0, "avg_logprob": -0.07093279585879073, "compression_ratio": 1.8475836431226766, "no_speech_prob": 4.006121525890194e-05}, {"id": 849, "seek": 473556, "start": 4751.56, "end": 4756.56, "text": " You approximate an expectation over a distribution", "tokens": [50364, 280, 538, 1071, 7316, 9505, 11, 337, 597, 286, 393, 380, 14722, 341, 4274, 11, 718, 311, 584, 39148, 420, 746, 13, 50714, 50714, 400, 550, 286, 853, 281, 652, 9505, 382, 1998, 281, 280, 382, 1944, 13, 50814, 50814, 663, 311, 1219, 3034, 1478, 7150, 13, 50914, 50914, 1033, 11, 291, 600, 1391, 2198, 300, 1433, 867, 1413, 13, 51114, 51114, 663, 311, 257, 3875, 1558, 295, 3034, 1478, 7150, 13, 51164, 51164, 509, 30874, 364, 14334, 670, 257, 7316, 51414, 51414, 538, 19139, 264, 7316, 538, 746, 291, 393, 767, 14722, 11, 51564, 51564, 293, 291, 853, 281, 652, 341, 2807, 712, 7316, 382, 1998, 382, 1944, 281, 264, 957, 7316, 51814, 51814], "temperature": 0.0, "avg_logprob": -0.07093279585879073, "compression_ratio": 1.8475836431226766, "no_speech_prob": 4.006121525890194e-05}, {"id": 850, "seek": 473556, "start": 4756.56, "end": 4759.56, "text": " by replacing the distribution by something you can actually compute,", "tokens": [50364, 280, 538, 1071, 7316, 9505, 11, 337, 597, 286, 393, 380, 14722, 341, 4274, 11, 718, 311, 584, 39148, 420, 746, 13, 50714, 50714, 400, 550, 286, 853, 281, 652, 9505, 382, 1998, 281, 280, 382, 1944, 13, 50814, 50814, 663, 311, 1219, 3034, 1478, 7150, 13, 50914, 50914, 1033, 11, 291, 600, 1391, 2198, 300, 1433, 867, 1413, 13, 51114, 51114, 663, 311, 257, 3875, 1558, 295, 3034, 1478, 7150, 13, 51164, 51164, 509, 30874, 364, 14334, 670, 257, 7316, 51414, 51414, 538, 19139, 264, 7316, 538, 746, 291, 393, 767, 14722, 11, 51564, 51564, 293, 291, 853, 281, 652, 341, 2807, 712, 7316, 382, 1998, 382, 1944, 281, 264, 957, 7316, 51814, 51814], "temperature": 0.0, "avg_logprob": -0.07093279585879073, "compression_ratio": 1.8475836431226766, "no_speech_prob": 4.006121525890194e-05}, {"id": 851, "seek": 473556, "start": 4759.56, "end": 4764.56, "text": " and you try to make this computable distribution as close as possible to the real distribution", "tokens": [50364, 280, 538, 1071, 7316, 9505, 11, 337, 597, 286, 393, 380, 14722, 341, 4274, 11, 718, 311, 584, 39148, 420, 746, 13, 50714, 50714, 400, 550, 286, 853, 281, 652, 9505, 382, 1998, 281, 280, 382, 1944, 13, 50814, 50814, 663, 311, 1219, 3034, 1478, 7150, 13, 50914, 50914, 1033, 11, 291, 600, 1391, 2198, 300, 1433, 867, 1413, 13, 51114, 51114, 663, 311, 257, 3875, 1558, 295, 3034, 1478, 7150, 13, 51164, 51164, 509, 30874, 364, 14334, 670, 257, 7316, 51414, 51414, 538, 19139, 264, 7316, 538, 746, 291, 393, 767, 14722, 11, 51564, 51564, 293, 291, 853, 281, 652, 341, 2807, 712, 7316, 382, 1998, 382, 1944, 281, 264, 957, 7316, 51814, 51814], "temperature": 0.0, "avg_logprob": -0.07093279585879073, "compression_ratio": 1.8475836431226766, "no_speech_prob": 4.006121525890194e-05}, {"id": 852, "seek": 476456, "start": 4764.56, "end": 4770.56, "text": " using some measure, KL divergence.", "tokens": [50364, 1228, 512, 3481, 11, 47991, 47387, 13, 50664, 50664, 1779, 11, 370, 510, 307, 591, 12, 1398, 599, 13, 50764, 50764, 407, 591, 12, 1398, 599, 307, 257, 11, 291, 393, 519, 295, 591, 12, 1398, 599, 382, 364, 2281, 12, 6032, 2316, 13, 50964, 50964, 509, 393, 7302, 591, 12, 1398, 599, 294, 2115, 295, 2281, 12, 6032, 2316, 13, 51314, 51314, 1119, 2878, 1392, 365, 437, 591, 12, 1398, 599, 307, 30, 51514, 51514, 3560, 291, 11832, 437, 591, 12, 1398, 599, 307, 30, 51564, 51564], "temperature": 0.0, "avg_logprob": -0.13139581680297852, "compression_ratio": 1.625, "no_speech_prob": 2.111002686433494e-05}, {"id": 853, "seek": 476456, "start": 4770.56, "end": 4772.56, "text": " Right, so here is K-means.", "tokens": [50364, 1228, 512, 3481, 11, 47991, 47387, 13, 50664, 50664, 1779, 11, 370, 510, 307, 591, 12, 1398, 599, 13, 50764, 50764, 407, 591, 12, 1398, 599, 307, 257, 11, 291, 393, 519, 295, 591, 12, 1398, 599, 382, 364, 2281, 12, 6032, 2316, 13, 50964, 50964, 509, 393, 7302, 591, 12, 1398, 599, 294, 2115, 295, 2281, 12, 6032, 2316, 13, 51314, 51314, 1119, 2878, 1392, 365, 437, 591, 12, 1398, 599, 307, 30, 51514, 51514, 3560, 291, 11832, 437, 591, 12, 1398, 599, 307, 30, 51564, 51564], "temperature": 0.0, "avg_logprob": -0.13139581680297852, "compression_ratio": 1.625, "no_speech_prob": 2.111002686433494e-05}, {"id": 854, "seek": 476456, "start": 4772.56, "end": 4776.56, "text": " So K-means is a, you can think of K-means as an energy-based model.", "tokens": [50364, 1228, 512, 3481, 11, 47991, 47387, 13, 50664, 50664, 1779, 11, 370, 510, 307, 591, 12, 1398, 599, 13, 50764, 50764, 407, 591, 12, 1398, 599, 307, 257, 11, 291, 393, 519, 295, 591, 12, 1398, 599, 382, 364, 2281, 12, 6032, 2316, 13, 50964, 50964, 509, 393, 7302, 591, 12, 1398, 599, 294, 2115, 295, 2281, 12, 6032, 2316, 13, 51314, 51314, 1119, 2878, 1392, 365, 437, 591, 12, 1398, 599, 307, 30, 51514, 51514, 3560, 291, 11832, 437, 591, 12, 1398, 599, 307, 30, 51564, 51564], "temperature": 0.0, "avg_logprob": -0.13139581680297852, "compression_ratio": 1.625, "no_speech_prob": 2.111002686433494e-05}, {"id": 855, "seek": 476456, "start": 4776.56, "end": 4783.56, "text": " You can interpret K-means in terms of energy-based model.", "tokens": [50364, 1228, 512, 3481, 11, 47991, 47387, 13, 50664, 50664, 1779, 11, 370, 510, 307, 591, 12, 1398, 599, 13, 50764, 50764, 407, 591, 12, 1398, 599, 307, 257, 11, 291, 393, 519, 295, 591, 12, 1398, 599, 382, 364, 2281, 12, 6032, 2316, 13, 50964, 50964, 509, 393, 7302, 591, 12, 1398, 599, 294, 2115, 295, 2281, 12, 6032, 2316, 13, 51314, 51314, 1119, 2878, 1392, 365, 437, 591, 12, 1398, 599, 307, 30, 51514, 51514, 3560, 291, 11832, 437, 591, 12, 1398, 599, 307, 30, 51564, 51564], "temperature": 0.0, "avg_logprob": -0.13139581680297852, "compression_ratio": 1.625, "no_speech_prob": 2.111002686433494e-05}, {"id": 856, "seek": 476456, "start": 4783.56, "end": 4787.56, "text": " Is anyone okay with what K-means is?", "tokens": [50364, 1228, 512, 3481, 11, 47991, 47387, 13, 50664, 50664, 1779, 11, 370, 510, 307, 591, 12, 1398, 599, 13, 50764, 50764, 407, 591, 12, 1398, 599, 307, 257, 11, 291, 393, 519, 295, 591, 12, 1398, 599, 382, 364, 2281, 12, 6032, 2316, 13, 50964, 50964, 509, 393, 7302, 591, 12, 1398, 599, 294, 2115, 295, 2281, 12, 6032, 2316, 13, 51314, 51314, 1119, 2878, 1392, 365, 437, 591, 12, 1398, 599, 307, 30, 51514, 51514, 3560, 291, 11832, 437, 591, 12, 1398, 599, 307, 30, 51564, 51564], "temperature": 0.0, "avg_logprob": -0.13139581680297852, "compression_ratio": 1.625, "no_speech_prob": 2.111002686433494e-05}, {"id": 857, "seek": 476456, "start": 4787.56, "end": 4788.56, "text": " Have you forgotten what K-means is?", "tokens": [50364, 1228, 512, 3481, 11, 47991, 47387, 13, 50664, 50664, 1779, 11, 370, 510, 307, 591, 12, 1398, 599, 13, 50764, 50764, 407, 591, 12, 1398, 599, 307, 257, 11, 291, 393, 519, 295, 591, 12, 1398, 599, 382, 364, 2281, 12, 6032, 2316, 13, 50964, 50964, 509, 393, 7302, 591, 12, 1398, 599, 294, 2115, 295, 2281, 12, 6032, 2316, 13, 51314, 51314, 1119, 2878, 1392, 365, 437, 591, 12, 1398, 599, 307, 30, 51514, 51514, 3560, 291, 11832, 437, 591, 12, 1398, 599, 307, 30, 51564, 51564], "temperature": 0.0, "avg_logprob": -0.13139581680297852, "compression_ratio": 1.625, "no_speech_prob": 2.111002686433494e-05}, {"id": 858, "seek": 478856, "start": 4788.56, "end": 4795.56, "text": " Okay, so K-means is this very simple clustering algorithm where the energy function,", "tokens": [50364, 1033, 11, 370, 591, 12, 1398, 599, 307, 341, 588, 2199, 596, 48673, 9284, 689, 264, 2281, 2445, 11, 50714, 50714, 498, 291, 600, 1128, 2198, 295, 309, 11, 341, 307, 257, 636, 281, 2903, 591, 12, 1398, 599, 13, 50864, 50864, 440, 2281, 2445, 307, 3720, 412, 264, 1192, 510, 13, 51014, 51014, 462, 295, 288, 89, 307, 288, 3175, 261, 89, 11, 689, 261, 307, 257, 8141, 11, 293, 710, 307, 257, 992, 295, 472, 12, 12194, 18875, 13, 51364, 51364, 1033, 11, 370, 710, 307, 341, 27706, 7006, 365, 591, 1944, 4190, 11, 51564, 51564, 293, 309, 311, 257, 591, 12, 18759, 8062, 365, 472, 6542, 2681, 281, 472, 293, 439, 264, 661, 2306, 2681, 281, 4018, 13, 51814, 51814], "temperature": 0.0, "avg_logprob": -0.09307489013671875, "compression_ratio": 1.6807692307692308, "no_speech_prob": 1.6186118955374695e-05}, {"id": 859, "seek": 478856, "start": 4795.56, "end": 4798.56, "text": " if you've never heard of it, this is a way to explain K-means.", "tokens": [50364, 1033, 11, 370, 591, 12, 1398, 599, 307, 341, 588, 2199, 596, 48673, 9284, 689, 264, 2281, 2445, 11, 50714, 50714, 498, 291, 600, 1128, 2198, 295, 309, 11, 341, 307, 257, 636, 281, 2903, 591, 12, 1398, 599, 13, 50864, 50864, 440, 2281, 2445, 307, 3720, 412, 264, 1192, 510, 13, 51014, 51014, 462, 295, 288, 89, 307, 288, 3175, 261, 89, 11, 689, 261, 307, 257, 8141, 11, 293, 710, 307, 257, 992, 295, 472, 12, 12194, 18875, 13, 51364, 51364, 1033, 11, 370, 710, 307, 341, 27706, 7006, 365, 591, 1944, 4190, 11, 51564, 51564, 293, 309, 311, 257, 591, 12, 18759, 8062, 365, 472, 6542, 2681, 281, 472, 293, 439, 264, 661, 2306, 2681, 281, 4018, 13, 51814, 51814], "temperature": 0.0, "avg_logprob": -0.09307489013671875, "compression_ratio": 1.6807692307692308, "no_speech_prob": 1.6186118955374695e-05}, {"id": 860, "seek": 478856, "start": 4798.56, "end": 4801.56, "text": " The energy function is written at the top here.", "tokens": [50364, 1033, 11, 370, 591, 12, 1398, 599, 307, 341, 588, 2199, 596, 48673, 9284, 689, 264, 2281, 2445, 11, 50714, 50714, 498, 291, 600, 1128, 2198, 295, 309, 11, 341, 307, 257, 636, 281, 2903, 591, 12, 1398, 599, 13, 50864, 50864, 440, 2281, 2445, 307, 3720, 412, 264, 1192, 510, 13, 51014, 51014, 462, 295, 288, 89, 307, 288, 3175, 261, 89, 11, 689, 261, 307, 257, 8141, 11, 293, 710, 307, 257, 992, 295, 472, 12, 12194, 18875, 13, 51364, 51364, 1033, 11, 370, 710, 307, 341, 27706, 7006, 365, 591, 1944, 4190, 11, 51564, 51564, 293, 309, 311, 257, 591, 12, 18759, 8062, 365, 472, 6542, 2681, 281, 472, 293, 439, 264, 661, 2306, 2681, 281, 4018, 13, 51814, 51814], "temperature": 0.0, "avg_logprob": -0.09307489013671875, "compression_ratio": 1.6807692307692308, "no_speech_prob": 1.6186118955374695e-05}, {"id": 861, "seek": 478856, "start": 4801.56, "end": 4808.56, "text": " E of yz is y minus wz, where w is a matrix, and z is a set of one-hot vectors.", "tokens": [50364, 1033, 11, 370, 591, 12, 1398, 599, 307, 341, 588, 2199, 596, 48673, 9284, 689, 264, 2281, 2445, 11, 50714, 50714, 498, 291, 600, 1128, 2198, 295, 309, 11, 341, 307, 257, 636, 281, 2903, 591, 12, 1398, 599, 13, 50864, 50864, 440, 2281, 2445, 307, 3720, 412, 264, 1192, 510, 13, 51014, 51014, 462, 295, 288, 89, 307, 288, 3175, 261, 89, 11, 689, 261, 307, 257, 8141, 11, 293, 710, 307, 257, 992, 295, 472, 12, 12194, 18875, 13, 51364, 51364, 1033, 11, 370, 710, 307, 341, 27706, 7006, 365, 591, 1944, 4190, 11, 51564, 51564, 293, 309, 311, 257, 591, 12, 18759, 8062, 365, 472, 6542, 2681, 281, 472, 293, 439, 264, 661, 2306, 2681, 281, 4018, 13, 51814, 51814], "temperature": 0.0, "avg_logprob": -0.09307489013671875, "compression_ratio": 1.6807692307692308, "no_speech_prob": 1.6186118955374695e-05}, {"id": 862, "seek": 478856, "start": 4808.56, "end": 4812.56, "text": " Okay, so z is this discrete variable with K possible values,", "tokens": [50364, 1033, 11, 370, 591, 12, 1398, 599, 307, 341, 588, 2199, 596, 48673, 9284, 689, 264, 2281, 2445, 11, 50714, 50714, 498, 291, 600, 1128, 2198, 295, 309, 11, 341, 307, 257, 636, 281, 2903, 591, 12, 1398, 599, 13, 50864, 50864, 440, 2281, 2445, 307, 3720, 412, 264, 1192, 510, 13, 51014, 51014, 462, 295, 288, 89, 307, 288, 3175, 261, 89, 11, 689, 261, 307, 257, 8141, 11, 293, 710, 307, 257, 992, 295, 472, 12, 12194, 18875, 13, 51364, 51364, 1033, 11, 370, 710, 307, 341, 27706, 7006, 365, 591, 1944, 4190, 11, 51564, 51564, 293, 309, 311, 257, 591, 12, 18759, 8062, 365, 472, 6542, 2681, 281, 472, 293, 439, 264, 661, 2306, 2681, 281, 4018, 13, 51814, 51814], "temperature": 0.0, "avg_logprob": -0.09307489013671875, "compression_ratio": 1.6807692307692308, "no_speech_prob": 1.6186118955374695e-05}, {"id": 863, "seek": 478856, "start": 4812.56, "end": 4817.56, "text": " and it's a K-dimensional vector with one component equal to one and all the other ones equal to zero.", "tokens": [50364, 1033, 11, 370, 591, 12, 1398, 599, 307, 341, 588, 2199, 596, 48673, 9284, 689, 264, 2281, 2445, 11, 50714, 50714, 498, 291, 600, 1128, 2198, 295, 309, 11, 341, 307, 257, 636, 281, 2903, 591, 12, 1398, 599, 13, 50864, 50864, 440, 2281, 2445, 307, 3720, 412, 264, 1192, 510, 13, 51014, 51014, 462, 295, 288, 89, 307, 288, 3175, 261, 89, 11, 689, 261, 307, 257, 8141, 11, 293, 710, 307, 257, 992, 295, 472, 12, 12194, 18875, 13, 51364, 51364, 1033, 11, 370, 710, 307, 341, 27706, 7006, 365, 591, 1944, 4190, 11, 51564, 51564, 293, 309, 311, 257, 591, 12, 18759, 8062, 365, 472, 6542, 2681, 281, 472, 293, 439, 264, 661, 2306, 2681, 281, 4018, 13, 51814, 51814], "temperature": 0.0, "avg_logprob": -0.09307489013671875, "compression_ratio": 1.6807692307692308, "no_speech_prob": 1.6186118955374695e-05}, {"id": 864, "seek": 481756, "start": 4817.56, "end": 4830.56, "text": " Okay, so you multiply z by the matrix w, the effect is that what you get as this product is one of the columns of w.", "tokens": [50364, 1033, 11, 370, 291, 12972, 710, 538, 264, 8141, 261, 11, 264, 1802, 307, 300, 437, 291, 483, 382, 341, 1674, 307, 472, 295, 264, 13766, 295, 261, 13, 51014, 51014, 1033, 11, 264, 7738, 295, 261, 300, 2170, 17207, 538, 264, 6542, 295, 710, 300, 311, 2681, 281, 472, 2170, 11408, 1232, 11, 51264, 51264, 293, 1203, 1646, 307, 2780, 13, 51414, 51414, 1033, 11, 370, 300, 1674, 3048, 82, 472, 7738, 490, 261, 13, 51614, 51614, 440, 13766, 295, 261, 366, 1219, 42197, 13, 51764, 51764], "temperature": 0.0, "avg_logprob": -0.0964080810546875, "compression_ratio": 1.75, "no_speech_prob": 1.3005911569052842e-05}, {"id": 865, "seek": 481756, "start": 4830.56, "end": 4835.56, "text": " Okay, the column of w that gets multiplied by the component of z that's equal to one gets reproduced,", "tokens": [50364, 1033, 11, 370, 291, 12972, 710, 538, 264, 8141, 261, 11, 264, 1802, 307, 300, 437, 291, 483, 382, 341, 1674, 307, 472, 295, 264, 13766, 295, 261, 13, 51014, 51014, 1033, 11, 264, 7738, 295, 261, 300, 2170, 17207, 538, 264, 6542, 295, 710, 300, 311, 2681, 281, 472, 2170, 11408, 1232, 11, 51264, 51264, 293, 1203, 1646, 307, 2780, 13, 51414, 51414, 1033, 11, 370, 300, 1674, 3048, 82, 472, 7738, 490, 261, 13, 51614, 51614, 440, 13766, 295, 261, 366, 1219, 42197, 13, 51764, 51764], "temperature": 0.0, "avg_logprob": -0.0964080810546875, "compression_ratio": 1.75, "no_speech_prob": 1.3005911569052842e-05}, {"id": 866, "seek": 481756, "start": 4835.56, "end": 4838.56, "text": " and everything else is gone.", "tokens": [50364, 1033, 11, 370, 291, 12972, 710, 538, 264, 8141, 261, 11, 264, 1802, 307, 300, 437, 291, 483, 382, 341, 1674, 307, 472, 295, 264, 13766, 295, 261, 13, 51014, 51014, 1033, 11, 264, 7738, 295, 261, 300, 2170, 17207, 538, 264, 6542, 295, 710, 300, 311, 2681, 281, 472, 2170, 11408, 1232, 11, 51264, 51264, 293, 1203, 1646, 307, 2780, 13, 51414, 51414, 1033, 11, 370, 300, 1674, 3048, 82, 472, 7738, 490, 261, 13, 51614, 51614, 440, 13766, 295, 261, 366, 1219, 42197, 13, 51764, 51764], "temperature": 0.0, "avg_logprob": -0.0964080810546875, "compression_ratio": 1.75, "no_speech_prob": 1.3005911569052842e-05}, {"id": 867, "seek": 481756, "start": 4838.56, "end": 4842.56, "text": " Okay, so that product selects one column from w.", "tokens": [50364, 1033, 11, 370, 291, 12972, 710, 538, 264, 8141, 261, 11, 264, 1802, 307, 300, 437, 291, 483, 382, 341, 1674, 307, 472, 295, 264, 13766, 295, 261, 13, 51014, 51014, 1033, 11, 264, 7738, 295, 261, 300, 2170, 17207, 538, 264, 6542, 295, 710, 300, 311, 2681, 281, 472, 2170, 11408, 1232, 11, 51264, 51264, 293, 1203, 1646, 307, 2780, 13, 51414, 51414, 1033, 11, 370, 300, 1674, 3048, 82, 472, 7738, 490, 261, 13, 51614, 51614, 440, 13766, 295, 261, 366, 1219, 42197, 13, 51764, 51764], "temperature": 0.0, "avg_logprob": -0.0964080810546875, "compression_ratio": 1.75, "no_speech_prob": 1.3005911569052842e-05}, {"id": 868, "seek": 481756, "start": 4842.56, "end": 4845.56, "text": " The columns of w are called prototypes.", "tokens": [50364, 1033, 11, 370, 291, 12972, 710, 538, 264, 8141, 261, 11, 264, 1802, 307, 300, 437, 291, 483, 382, 341, 1674, 307, 472, 295, 264, 13766, 295, 261, 13, 51014, 51014, 1033, 11, 264, 7738, 295, 261, 300, 2170, 17207, 538, 264, 6542, 295, 710, 300, 311, 2681, 281, 472, 2170, 11408, 1232, 11, 51264, 51264, 293, 1203, 1646, 307, 2780, 13, 51414, 51414, 1033, 11, 370, 300, 1674, 3048, 82, 472, 7738, 490, 261, 13, 51614, 51614, 440, 13766, 295, 261, 366, 1219, 42197, 13, 51764, 51764], "temperature": 0.0, "avg_logprob": -0.0964080810546875, "compression_ratio": 1.75, "no_speech_prob": 1.3005911569052842e-05}, {"id": 869, "seek": 484556, "start": 4845.56, "end": 4851.56, "text": " Okay, and if I give you a y, the way you do inference is that you figure out which z,", "tokens": [50364, 1033, 11, 293, 498, 286, 976, 291, 257, 288, 11, 264, 636, 291, 360, 38253, 307, 300, 291, 2573, 484, 597, 710, 11, 50664, 50664, 597, 295, 264, 591, 1944, 18875, 295, 710, 11, 4464, 5660, 264, 31565, 6713, 11, 50864, 50864, 4464, 5660, 264, 3732, 4560, 1296, 264, 11760, 7738, 295, 261, 293, 264, 1412, 935, 300, 286, 478, 1237, 412, 13, 51314, 51314, 400, 264, 2281, 307, 445, 257, 3732, 4560, 1296, 264, 732, 13, 51514, 51514], "temperature": 0.0, "avg_logprob": -0.08135949240790473, "compression_ratio": 1.6581632653061225, "no_speech_prob": 1.1842779713333584e-05}, {"id": 870, "seek": 484556, "start": 4851.56, "end": 4855.56, "text": " which of the K possible vectors of z, minimizes the reconstruction error,", "tokens": [50364, 1033, 11, 293, 498, 286, 976, 291, 257, 288, 11, 264, 636, 291, 360, 38253, 307, 300, 291, 2573, 484, 597, 710, 11, 50664, 50664, 597, 295, 264, 591, 1944, 18875, 295, 710, 11, 4464, 5660, 264, 31565, 6713, 11, 50864, 50864, 4464, 5660, 264, 3732, 4560, 1296, 264, 11760, 7738, 295, 261, 293, 264, 1412, 935, 300, 286, 478, 1237, 412, 13, 51314, 51314, 400, 264, 2281, 307, 445, 257, 3732, 4560, 1296, 264, 732, 13, 51514, 51514], "temperature": 0.0, "avg_logprob": -0.08135949240790473, "compression_ratio": 1.6581632653061225, "no_speech_prob": 1.1842779713333584e-05}, {"id": 871, "seek": 484556, "start": 4855.56, "end": 4864.56, "text": " minimizes the square distance between the corresponding column of w and the data point that I'm looking at.", "tokens": [50364, 1033, 11, 293, 498, 286, 976, 291, 257, 288, 11, 264, 636, 291, 360, 38253, 307, 300, 291, 2573, 484, 597, 710, 11, 50664, 50664, 597, 295, 264, 591, 1944, 18875, 295, 710, 11, 4464, 5660, 264, 31565, 6713, 11, 50864, 50864, 4464, 5660, 264, 3732, 4560, 1296, 264, 11760, 7738, 295, 261, 293, 264, 1412, 935, 300, 286, 478, 1237, 412, 13, 51314, 51314, 400, 264, 2281, 307, 445, 257, 3732, 4560, 1296, 264, 732, 13, 51514, 51514], "temperature": 0.0, "avg_logprob": -0.08135949240790473, "compression_ratio": 1.6581632653061225, "no_speech_prob": 1.1842779713333584e-05}, {"id": 872, "seek": 484556, "start": 4864.56, "end": 4868.56, "text": " And the energy is just a square distance between the two.", "tokens": [50364, 1033, 11, 293, 498, 286, 976, 291, 257, 288, 11, 264, 636, 291, 360, 38253, 307, 300, 291, 2573, 484, 597, 710, 11, 50664, 50664, 597, 295, 264, 591, 1944, 18875, 295, 710, 11, 4464, 5660, 264, 31565, 6713, 11, 50864, 50864, 4464, 5660, 264, 3732, 4560, 1296, 264, 11760, 7738, 295, 261, 293, 264, 1412, 935, 300, 286, 478, 1237, 412, 13, 51314, 51314, 400, 264, 2281, 307, 445, 257, 3732, 4560, 1296, 264, 732, 13, 51514, 51514], "temperature": 0.0, "avg_logprob": -0.08135949240790473, "compression_ratio": 1.6581632653061225, "no_speech_prob": 1.1842779713333584e-05}, {"id": 873, "seek": 486856, "start": 4868.56, "end": 4877.56, "text": " Okay, now the energy function you see here represented in this chart,", "tokens": [50364, 1033, 11, 586, 264, 2281, 2445, 291, 536, 510, 10379, 294, 341, 6927, 11, 50814, 50814, 34166, 11, 558, 510, 11, 437, 291, 536, 510, 366, 733, 295, 2211, 1749, 929, 11, 51214, 51214, 293, 729, 6805, 281, 37262, 30984, 926, 1184, 295, 264, 42197, 295, 261, 13, 51614, 51614], "temperature": 0.0, "avg_logprob": -0.08800425896277794, "compression_ratio": 1.4405594405594406, "no_speech_prob": 8.664372217026539e-06}, {"id": 874, "seek": 486856, "start": 4877.56, "end": 4885.56, "text": " oops, right here, what you see here are kind of black blobs,", "tokens": [50364, 1033, 11, 586, 264, 2281, 2445, 291, 536, 510, 10379, 294, 341, 6927, 11, 50814, 50814, 34166, 11, 558, 510, 11, 437, 291, 536, 510, 366, 733, 295, 2211, 1749, 929, 11, 51214, 51214, 293, 729, 6805, 281, 37262, 30984, 926, 1184, 295, 264, 42197, 295, 261, 13, 51614, 51614], "temperature": 0.0, "avg_logprob": -0.08800425896277794, "compression_ratio": 1.4405594405594406, "no_speech_prob": 8.664372217026539e-06}, {"id": 875, "seek": 486856, "start": 4885.56, "end": 4893.56, "text": " and those correspond to quadratic wells around each of the prototypes of w.", "tokens": [50364, 1033, 11, 586, 264, 2281, 2445, 291, 536, 510, 10379, 294, 341, 6927, 11, 50814, 50814, 34166, 11, 558, 510, 11, 437, 291, 536, 510, 366, 733, 295, 2211, 1749, 929, 11, 51214, 51214, 293, 729, 6805, 281, 37262, 30984, 926, 1184, 295, 264, 42197, 295, 261, 13, 51614, 51614], "temperature": 0.0, "avg_logprob": -0.08800425896277794, "compression_ratio": 1.4405594405594406, "no_speech_prob": 8.664372217026539e-06}, {"id": 876, "seek": 489356, "start": 4893.56, "end": 4899.56, "text": " So the system here has been trained, and it placed the columns of w along the manifold of training samples,", "tokens": [50364, 407, 264, 1185, 510, 575, 668, 8895, 11, 293, 309, 7074, 264, 13766, 295, 261, 2051, 264, 47138, 295, 3097, 10938, 11, 50664, 50664, 597, 307, 341, 25165, 11, 300, 311, 689, 439, 264, 3097, 10938, 366, 8209, 13, 50914, 50914, 400, 264, 636, 341, 307, 8895, 307, 588, 2199, 13, 51064, 51064, 509, 445, 17522, 264, 5176, 11, 264, 4274, 2281, 670, 257, 3097, 992, 13, 51414, 51414, 1033, 11, 370, 1936, 286, 976, 291, 257, 288, 11, 288, 307, 257, 3097, 6889, 13, 51714, 51714], "temperature": 0.0, "avg_logprob": -0.10043686427427141, "compression_ratio": 1.6872037914691944, "no_speech_prob": 1.1841877494589426e-05}, {"id": 877, "seek": 489356, "start": 4899.56, "end": 4904.56, "text": " which is this spiral, that's where all the training samples are selected.", "tokens": [50364, 407, 264, 1185, 510, 575, 668, 8895, 11, 293, 309, 7074, 264, 13766, 295, 261, 2051, 264, 47138, 295, 3097, 10938, 11, 50664, 50664, 597, 307, 341, 25165, 11, 300, 311, 689, 439, 264, 3097, 10938, 366, 8209, 13, 50914, 50914, 400, 264, 636, 341, 307, 8895, 307, 588, 2199, 13, 51064, 51064, 509, 445, 17522, 264, 5176, 11, 264, 4274, 2281, 670, 257, 3097, 992, 13, 51414, 51414, 1033, 11, 370, 1936, 286, 976, 291, 257, 288, 11, 288, 307, 257, 3097, 6889, 13, 51714, 51714], "temperature": 0.0, "avg_logprob": -0.10043686427427141, "compression_ratio": 1.6872037914691944, "no_speech_prob": 1.1841877494589426e-05}, {"id": 878, "seek": 489356, "start": 4904.56, "end": 4907.56, "text": " And the way this is trained is very simple.", "tokens": [50364, 407, 264, 1185, 510, 575, 668, 8895, 11, 293, 309, 7074, 264, 13766, 295, 261, 2051, 264, 47138, 295, 3097, 10938, 11, 50664, 50664, 597, 307, 341, 25165, 11, 300, 311, 689, 439, 264, 3097, 10938, 366, 8209, 13, 50914, 50914, 400, 264, 636, 341, 307, 8895, 307, 588, 2199, 13, 51064, 51064, 509, 445, 17522, 264, 5176, 11, 264, 4274, 2281, 670, 257, 3097, 992, 13, 51414, 51414, 1033, 11, 370, 1936, 286, 976, 291, 257, 288, 11, 288, 307, 257, 3097, 6889, 13, 51714, 51714], "temperature": 0.0, "avg_logprob": -0.10043686427427141, "compression_ratio": 1.6872037914691944, "no_speech_prob": 1.1841877494589426e-05}, {"id": 879, "seek": 489356, "start": 4907.56, "end": 4914.56, "text": " You just minimize the expected, the average energy over a training set.", "tokens": [50364, 407, 264, 1185, 510, 575, 668, 8895, 11, 293, 309, 7074, 264, 13766, 295, 261, 2051, 264, 47138, 295, 3097, 10938, 11, 50664, 50664, 597, 307, 341, 25165, 11, 300, 311, 689, 439, 264, 3097, 10938, 366, 8209, 13, 50914, 50914, 400, 264, 636, 341, 307, 8895, 307, 588, 2199, 13, 51064, 51064, 509, 445, 17522, 264, 5176, 11, 264, 4274, 2281, 670, 257, 3097, 992, 13, 51414, 51414, 1033, 11, 370, 1936, 286, 976, 291, 257, 288, 11, 288, 307, 257, 3097, 6889, 13, 51714, 51714], "temperature": 0.0, "avg_logprob": -0.10043686427427141, "compression_ratio": 1.6872037914691944, "no_speech_prob": 1.1841877494589426e-05}, {"id": 880, "seek": 489356, "start": 4914.56, "end": 4920.56, "text": " Okay, so basically I give you a y, y is a training sample.", "tokens": [50364, 407, 264, 1185, 510, 575, 668, 8895, 11, 293, 309, 7074, 264, 13766, 295, 261, 2051, 264, 47138, 295, 3097, 10938, 11, 50664, 50664, 597, 307, 341, 25165, 11, 300, 311, 689, 439, 264, 3097, 10938, 366, 8209, 13, 50914, 50914, 400, 264, 636, 341, 307, 8895, 307, 588, 2199, 13, 51064, 51064, 509, 445, 17522, 264, 5176, 11, 264, 4274, 2281, 670, 257, 3097, 992, 13, 51414, 51414, 1033, 11, 370, 1936, 286, 976, 291, 257, 288, 11, 288, 307, 257, 3097, 6889, 13, 51714, 51714], "temperature": 0.0, "avg_logprob": -0.10043686427427141, "compression_ratio": 1.6872037914691944, "no_speech_prob": 1.1841877494589426e-05}, {"id": 881, "seek": 492056, "start": 4920.56, "end": 4925.56, "text": " You find the z that minimizes the energy, so you find the prototype that is closest to y,", "tokens": [50364, 509, 915, 264, 710, 300, 4464, 5660, 264, 2281, 11, 370, 291, 915, 264, 19475, 300, 307, 13699, 281, 288, 11, 50614, 50614, 264, 7738, 295, 261, 300, 311, 13699, 281, 288, 11, 293, 550, 291, 360, 472, 1823, 295, 16235, 23475, 11, 50864, 50864, 370, 291, 1286, 300, 8062, 4966, 281, 288, 13, 51114, 51114, 1396, 291, 747, 1071, 288, 11, 3048, 597, 13766, 295, 261, 307, 13699, 281, 309, 11, 51414, 51414, 293, 1286, 300, 7738, 257, 707, 857, 4966, 281, 288, 11, 293, 550, 291, 1066, 884, 341, 13, 51614, 51614, 663, 311, 406, 2293, 264, 591, 12, 1398, 599, 9284, 13, 51714, 51714], "temperature": 0.0, "avg_logprob": -0.10195722492462998, "compression_ratio": 1.8815165876777251, "no_speech_prob": 3.426547482376918e-05}, {"id": 882, "seek": 492056, "start": 4925.56, "end": 4930.56, "text": " the column of w that's closest to y, and then you do one step of gradient descent,", "tokens": [50364, 509, 915, 264, 710, 300, 4464, 5660, 264, 2281, 11, 370, 291, 915, 264, 19475, 300, 307, 13699, 281, 288, 11, 50614, 50614, 264, 7738, 295, 261, 300, 311, 13699, 281, 288, 11, 293, 550, 291, 360, 472, 1823, 295, 16235, 23475, 11, 50864, 50864, 370, 291, 1286, 300, 8062, 4966, 281, 288, 13, 51114, 51114, 1396, 291, 747, 1071, 288, 11, 3048, 597, 13766, 295, 261, 307, 13699, 281, 309, 11, 51414, 51414, 293, 1286, 300, 7738, 257, 707, 857, 4966, 281, 288, 11, 293, 550, 291, 1066, 884, 341, 13, 51614, 51614, 663, 311, 406, 2293, 264, 591, 12, 1398, 599, 9284, 13, 51714, 51714], "temperature": 0.0, "avg_logprob": -0.10195722492462998, "compression_ratio": 1.8815165876777251, "no_speech_prob": 3.426547482376918e-05}, {"id": 883, "seek": 492056, "start": 4930.56, "end": 4935.56, "text": " so you move that vector closer to y.", "tokens": [50364, 509, 915, 264, 710, 300, 4464, 5660, 264, 2281, 11, 370, 291, 915, 264, 19475, 300, 307, 13699, 281, 288, 11, 50614, 50614, 264, 7738, 295, 261, 300, 311, 13699, 281, 288, 11, 293, 550, 291, 360, 472, 1823, 295, 16235, 23475, 11, 50864, 50864, 370, 291, 1286, 300, 8062, 4966, 281, 288, 13, 51114, 51114, 1396, 291, 747, 1071, 288, 11, 3048, 597, 13766, 295, 261, 307, 13699, 281, 309, 11, 51414, 51414, 293, 1286, 300, 7738, 257, 707, 857, 4966, 281, 288, 11, 293, 550, 291, 1066, 884, 341, 13, 51614, 51614, 663, 311, 406, 2293, 264, 591, 12, 1398, 599, 9284, 13, 51714, 51714], "temperature": 0.0, "avg_logprob": -0.10195722492462998, "compression_ratio": 1.8815165876777251, "no_speech_prob": 3.426547482376918e-05}, {"id": 884, "seek": 492056, "start": 4935.56, "end": 4941.56, "text": " Then you take another y, select which columns of w is closest to it,", "tokens": [50364, 509, 915, 264, 710, 300, 4464, 5660, 264, 2281, 11, 370, 291, 915, 264, 19475, 300, 307, 13699, 281, 288, 11, 50614, 50614, 264, 7738, 295, 261, 300, 311, 13699, 281, 288, 11, 293, 550, 291, 360, 472, 1823, 295, 16235, 23475, 11, 50864, 50864, 370, 291, 1286, 300, 8062, 4966, 281, 288, 13, 51114, 51114, 1396, 291, 747, 1071, 288, 11, 3048, 597, 13766, 295, 261, 307, 13699, 281, 309, 11, 51414, 51414, 293, 1286, 300, 7738, 257, 707, 857, 4966, 281, 288, 11, 293, 550, 291, 1066, 884, 341, 13, 51614, 51614, 663, 311, 406, 2293, 264, 591, 12, 1398, 599, 9284, 13, 51714, 51714], "temperature": 0.0, "avg_logprob": -0.10195722492462998, "compression_ratio": 1.8815165876777251, "no_speech_prob": 3.426547482376918e-05}, {"id": 885, "seek": 492056, "start": 4941.56, "end": 4945.56, "text": " and move that column a little bit closer to y, and then you keep doing this.", "tokens": [50364, 509, 915, 264, 710, 300, 4464, 5660, 264, 2281, 11, 370, 291, 915, 264, 19475, 300, 307, 13699, 281, 288, 11, 50614, 50614, 264, 7738, 295, 261, 300, 311, 13699, 281, 288, 11, 293, 550, 291, 360, 472, 1823, 295, 16235, 23475, 11, 50864, 50864, 370, 291, 1286, 300, 8062, 4966, 281, 288, 13, 51114, 51114, 1396, 291, 747, 1071, 288, 11, 3048, 597, 13766, 295, 261, 307, 13699, 281, 309, 11, 51414, 51414, 293, 1286, 300, 7738, 257, 707, 857, 4966, 281, 288, 11, 293, 550, 291, 1066, 884, 341, 13, 51614, 51614, 663, 311, 406, 2293, 264, 591, 12, 1398, 599, 9284, 13, 51714, 51714], "temperature": 0.0, "avg_logprob": -0.10195722492462998, "compression_ratio": 1.8815165876777251, "no_speech_prob": 3.426547482376918e-05}, {"id": 886, "seek": 492056, "start": 4945.56, "end": 4947.56, "text": " That's not exactly the K-means algorithm.", "tokens": [50364, 509, 915, 264, 710, 300, 4464, 5660, 264, 2281, 11, 370, 291, 915, 264, 19475, 300, 307, 13699, 281, 288, 11, 50614, 50614, 264, 7738, 295, 261, 300, 311, 13699, 281, 288, 11, 293, 550, 291, 360, 472, 1823, 295, 16235, 23475, 11, 50864, 50864, 370, 291, 1286, 300, 8062, 4966, 281, 288, 13, 51114, 51114, 1396, 291, 747, 1071, 288, 11, 3048, 597, 13766, 295, 261, 307, 13699, 281, 309, 11, 51414, 51414, 293, 1286, 300, 7738, 257, 707, 857, 4966, 281, 288, 11, 293, 550, 291, 1066, 884, 341, 13, 51614, 51614, 663, 311, 406, 2293, 264, 591, 12, 1398, 599, 9284, 13, 51714, 51714], "temperature": 0.0, "avg_logprob": -0.10195722492462998, "compression_ratio": 1.8815165876777251, "no_speech_prob": 3.426547482376918e-05}, {"id": 887, "seek": 494756, "start": 4947.56, "end": 4951.56, "text": " This is the kind of stochastic gradient form of the K-means algorithm.", "tokens": [50364, 639, 307, 264, 733, 295, 342, 8997, 2750, 16235, 1254, 295, 264, 591, 12, 1398, 599, 9284, 13, 50564, 50564, 440, 957, 591, 12, 1398, 599, 9284, 767, 733, 295, 775, 1333, 295, 15670, 23475, 11, 498, 291, 528, 11, 50914, 50914, 370, 309, 700, 1709, 807, 264, 2302, 3097, 992, 293, 9624, 484, 337, 1184, 1412, 935, 51114, 51114, 597, 7738, 295, 261, 307, 13699, 281, 309, 11, 293, 550, 934, 291, 600, 1096, 341, 11, 51414, 51414, 291, 14722, 633, 1412, 935, 11, 633, 7738, 295, 261, 382, 264, 4274, 295, 439, 264, 1412, 2793, 281, 597, 309, 311, 6615, 13, 51814, 51814], "temperature": 0.0, "avg_logprob": -0.06264379982636353, "compression_ratio": 1.7459016393442623, "no_speech_prob": 1.9523820810718462e-05}, {"id": 888, "seek": 494756, "start": 4951.56, "end": 4958.56, "text": " The real K-means algorithm actually kind of does sort of coordinate descent, if you want,", "tokens": [50364, 639, 307, 264, 733, 295, 342, 8997, 2750, 16235, 1254, 295, 264, 591, 12, 1398, 599, 9284, 13, 50564, 50564, 440, 957, 591, 12, 1398, 599, 9284, 767, 733, 295, 775, 1333, 295, 15670, 23475, 11, 498, 291, 528, 11, 50914, 50914, 370, 309, 700, 1709, 807, 264, 2302, 3097, 992, 293, 9624, 484, 337, 1184, 1412, 935, 51114, 51114, 597, 7738, 295, 261, 307, 13699, 281, 309, 11, 293, 550, 934, 291, 600, 1096, 341, 11, 51414, 51414, 291, 14722, 633, 1412, 935, 11, 633, 7738, 295, 261, 382, 264, 4274, 295, 439, 264, 1412, 2793, 281, 597, 309, 311, 6615, 13, 51814, 51814], "temperature": 0.0, "avg_logprob": -0.06264379982636353, "compression_ratio": 1.7459016393442623, "no_speech_prob": 1.9523820810718462e-05}, {"id": 889, "seek": 494756, "start": 4958.56, "end": 4962.56, "text": " so it first goes through the entire training set and figures out for each data point", "tokens": [50364, 639, 307, 264, 733, 295, 342, 8997, 2750, 16235, 1254, 295, 264, 591, 12, 1398, 599, 9284, 13, 50564, 50564, 440, 957, 591, 12, 1398, 599, 9284, 767, 733, 295, 775, 1333, 295, 15670, 23475, 11, 498, 291, 528, 11, 50914, 50914, 370, 309, 700, 1709, 807, 264, 2302, 3097, 992, 293, 9624, 484, 337, 1184, 1412, 935, 51114, 51114, 597, 7738, 295, 261, 307, 13699, 281, 309, 11, 293, 550, 934, 291, 600, 1096, 341, 11, 51414, 51414, 291, 14722, 633, 1412, 935, 11, 633, 7738, 295, 261, 382, 264, 4274, 295, 439, 264, 1412, 2793, 281, 597, 309, 311, 6615, 13, 51814, 51814], "temperature": 0.0, "avg_logprob": -0.06264379982636353, "compression_ratio": 1.7459016393442623, "no_speech_prob": 1.9523820810718462e-05}, {"id": 890, "seek": 494756, "start": 4962.56, "end": 4968.56, "text": " which column of w is closest to it, and then after you've done this,", "tokens": [50364, 639, 307, 264, 733, 295, 342, 8997, 2750, 16235, 1254, 295, 264, 591, 12, 1398, 599, 9284, 13, 50564, 50564, 440, 957, 591, 12, 1398, 599, 9284, 767, 733, 295, 775, 1333, 295, 15670, 23475, 11, 498, 291, 528, 11, 50914, 50914, 370, 309, 700, 1709, 807, 264, 2302, 3097, 992, 293, 9624, 484, 337, 1184, 1412, 935, 51114, 51114, 597, 7738, 295, 261, 307, 13699, 281, 309, 11, 293, 550, 934, 291, 600, 1096, 341, 11, 51414, 51414, 291, 14722, 633, 1412, 935, 11, 633, 7738, 295, 261, 382, 264, 4274, 295, 439, 264, 1412, 2793, 281, 597, 309, 311, 6615, 13, 51814, 51814], "temperature": 0.0, "avg_logprob": -0.06264379982636353, "compression_ratio": 1.7459016393442623, "no_speech_prob": 1.9523820810718462e-05}, {"id": 891, "seek": 494756, "start": 4968.56, "end": 4976.56, "text": " you compute every data point, every column of w as the average of all the data points to which it's associated.", "tokens": [50364, 639, 307, 264, 733, 295, 342, 8997, 2750, 16235, 1254, 295, 264, 591, 12, 1398, 599, 9284, 13, 50564, 50564, 440, 957, 591, 12, 1398, 599, 9284, 767, 733, 295, 775, 1333, 295, 15670, 23475, 11, 498, 291, 528, 11, 50914, 50914, 370, 309, 700, 1709, 807, 264, 2302, 3097, 992, 293, 9624, 484, 337, 1184, 1412, 935, 51114, 51114, 597, 7738, 295, 261, 307, 13699, 281, 309, 11, 293, 550, 934, 291, 600, 1096, 341, 11, 51414, 51414, 291, 14722, 633, 1412, 935, 11, 633, 7738, 295, 261, 382, 264, 4274, 295, 439, 264, 1412, 2793, 281, 597, 309, 311, 6615, 13, 51814, 51814], "temperature": 0.0, "avg_logprob": -0.06264379982636353, "compression_ratio": 1.7459016393442623, "no_speech_prob": 1.9523820810718462e-05}, {"id": 892, "seek": 497656, "start": 4976.56, "end": 4983.56, "text": " And it goes a bit faster if you do it this way, as opposed to stochastic gradient.", "tokens": [50364, 400, 309, 1709, 257, 857, 4663, 498, 291, 360, 309, 341, 636, 11, 382, 8851, 281, 342, 8997, 2750, 16235, 13, 50714, 50714, 583, 264, 1874, 307, 264, 912, 13, 682, 264, 917, 11, 291, 17522, 264, 4274, 295, 264, 2281, 670, 264, 3097, 992, 13, 51114, 51114, 1033, 11, 370, 300, 311, 364, 1365, 13, 821, 390, 257, 1168, 466, 48994, 7006, 3071, 13, 51264, 51264, 663, 311, 364, 1365, 295, 257, 48994, 7006, 2316, 11, 588, 2199, 472, 11, 689, 264, 979, 19866, 307, 8213, 13, 51464, 51464, 821, 311, 572, 33621, 322, 2031, 11, 293, 437, 291, 434, 445, 1382, 281, 360, 307, 2316, 264, 7316, 670, 288, 13, 51714, 51714], "temperature": 0.0, "avg_logprob": -0.11626537092800798, "compression_ratio": 1.692883895131086, "no_speech_prob": 1.4285249562817626e-05}, {"id": 893, "seek": 497656, "start": 4983.56, "end": 4991.56, "text": " But the result is the same. In the end, you minimize the average of the energy over the training set.", "tokens": [50364, 400, 309, 1709, 257, 857, 4663, 498, 291, 360, 309, 341, 636, 11, 382, 8851, 281, 342, 8997, 2750, 16235, 13, 50714, 50714, 583, 264, 1874, 307, 264, 912, 13, 682, 264, 917, 11, 291, 17522, 264, 4274, 295, 264, 2281, 670, 264, 3097, 992, 13, 51114, 51114, 1033, 11, 370, 300, 311, 364, 1365, 13, 821, 390, 257, 1168, 466, 48994, 7006, 3071, 13, 51264, 51264, 663, 311, 364, 1365, 295, 257, 48994, 7006, 2316, 11, 588, 2199, 472, 11, 689, 264, 979, 19866, 307, 8213, 13, 51464, 51464, 821, 311, 572, 33621, 322, 2031, 11, 293, 437, 291, 434, 445, 1382, 281, 360, 307, 2316, 264, 7316, 670, 288, 13, 51714, 51714], "temperature": 0.0, "avg_logprob": -0.11626537092800798, "compression_ratio": 1.692883895131086, "no_speech_prob": 1.4285249562817626e-05}, {"id": 894, "seek": 497656, "start": 4991.56, "end": 4994.56, "text": " Okay, so that's an example. There was a question about latent variable earlier.", "tokens": [50364, 400, 309, 1709, 257, 857, 4663, 498, 291, 360, 309, 341, 636, 11, 382, 8851, 281, 342, 8997, 2750, 16235, 13, 50714, 50714, 583, 264, 1874, 307, 264, 912, 13, 682, 264, 917, 11, 291, 17522, 264, 4274, 295, 264, 2281, 670, 264, 3097, 992, 13, 51114, 51114, 1033, 11, 370, 300, 311, 364, 1365, 13, 821, 390, 257, 1168, 466, 48994, 7006, 3071, 13, 51264, 51264, 663, 311, 364, 1365, 295, 257, 48994, 7006, 2316, 11, 588, 2199, 472, 11, 689, 264, 979, 19866, 307, 8213, 13, 51464, 51464, 821, 311, 572, 33621, 322, 2031, 11, 293, 437, 291, 434, 445, 1382, 281, 360, 307, 2316, 264, 7316, 670, 288, 13, 51714, 51714], "temperature": 0.0, "avg_logprob": -0.11626537092800798, "compression_ratio": 1.692883895131086, "no_speech_prob": 1.4285249562817626e-05}, {"id": 895, "seek": 497656, "start": 4994.56, "end": 4998.56, "text": " That's an example of a latent variable model, very simple one, where the decoder is linear.", "tokens": [50364, 400, 309, 1709, 257, 857, 4663, 498, 291, 360, 309, 341, 636, 11, 382, 8851, 281, 342, 8997, 2750, 16235, 13, 50714, 50714, 583, 264, 1874, 307, 264, 912, 13, 682, 264, 917, 11, 291, 17522, 264, 4274, 295, 264, 2281, 670, 264, 3097, 992, 13, 51114, 51114, 1033, 11, 370, 300, 311, 364, 1365, 13, 821, 390, 257, 1168, 466, 48994, 7006, 3071, 13, 51264, 51264, 663, 311, 364, 1365, 295, 257, 48994, 7006, 2316, 11, 588, 2199, 472, 11, 689, 264, 979, 19866, 307, 8213, 13, 51464, 51464, 821, 311, 572, 33621, 322, 2031, 11, 293, 437, 291, 434, 445, 1382, 281, 360, 307, 2316, 264, 7316, 670, 288, 13, 51714, 51714], "temperature": 0.0, "avg_logprob": -0.11626537092800798, "compression_ratio": 1.692883895131086, "no_speech_prob": 1.4285249562817626e-05}, {"id": 896, "seek": 497656, "start": 4998.56, "end": 5003.56, "text": " There's no dependency on x, and what you're just trying to do is model the distribution over y.", "tokens": [50364, 400, 309, 1709, 257, 857, 4663, 498, 291, 360, 309, 341, 636, 11, 382, 8851, 281, 342, 8997, 2750, 16235, 13, 50714, 50714, 583, 264, 1874, 307, 264, 912, 13, 682, 264, 917, 11, 291, 17522, 264, 4274, 295, 264, 2281, 670, 264, 3097, 992, 13, 51114, 51114, 1033, 11, 370, 300, 311, 364, 1365, 13, 821, 390, 257, 1168, 466, 48994, 7006, 3071, 13, 51264, 51264, 663, 311, 364, 1365, 295, 257, 48994, 7006, 2316, 11, 588, 2199, 472, 11, 689, 264, 979, 19866, 307, 8213, 13, 51464, 51464, 821, 311, 572, 33621, 322, 2031, 11, 293, 437, 291, 434, 445, 1382, 281, 360, 307, 2316, 264, 7316, 670, 288, 13, 51714, 51714], "temperature": 0.0, "avg_logprob": -0.11626537092800798, "compression_ratio": 1.692883895131086, "no_speech_prob": 1.4285249562817626e-05}, {"id": 897, "seek": 500356, "start": 5003.56, "end": 5007.56, "text": " Here y is two-dimensional, and you're just trying to say, you know,", "tokens": [50364, 1692, 288, 307, 732, 12, 18759, 11, 293, 291, 434, 445, 1382, 281, 584, 11, 291, 458, 11, 50564, 50564, 498, 286, 458, 472, 2158, 295, 288, 11, 393, 291, 980, 385, 11, 498, 286, 458, 288, 16, 11, 393, 291, 980, 385, 1340, 466, 264, 2158, 295, 288, 17, 30, 50864, 50864, 400, 1564, 291, 362, 341, 2281, 2445, 11, 291, 393, 13, 51014, 51014, 286, 976, 291, 288, 16, 11, 291, 393, 6069, 437, 264, 2158, 295, 288, 17, 820, 312, 13, 51214, 51214, 286, 976, 291, 257, 4974, 935, 11, 291, 393, 980, 385, 437, 311, 264, 13699, 935, 322, 264, 1412, 47138, 51414, 51414, 538, 445, 10808, 337, 264, 13699, 19475, 11, 1936, 13, 51764, 51764], "temperature": 0.0, "avg_logprob": -0.07311067424836706, "compression_ratio": 1.8177966101694916, "no_speech_prob": 2.2826334316050634e-05}, {"id": 898, "seek": 500356, "start": 5007.56, "end": 5013.56, "text": " if I know one value of y, can you tell me, if I know y1, can you tell me anything about the value of y2?", "tokens": [50364, 1692, 288, 307, 732, 12, 18759, 11, 293, 291, 434, 445, 1382, 281, 584, 11, 291, 458, 11, 50564, 50564, 498, 286, 458, 472, 2158, 295, 288, 11, 393, 291, 980, 385, 11, 498, 286, 458, 288, 16, 11, 393, 291, 980, 385, 1340, 466, 264, 2158, 295, 288, 17, 30, 50864, 50864, 400, 1564, 291, 362, 341, 2281, 2445, 11, 291, 393, 13, 51014, 51014, 286, 976, 291, 288, 16, 11, 291, 393, 6069, 437, 264, 2158, 295, 288, 17, 820, 312, 13, 51214, 51214, 286, 976, 291, 257, 4974, 935, 11, 291, 393, 980, 385, 437, 311, 264, 13699, 935, 322, 264, 1412, 47138, 51414, 51414, 538, 445, 10808, 337, 264, 13699, 19475, 11, 1936, 13, 51764, 51764], "temperature": 0.0, "avg_logprob": -0.07311067424836706, "compression_ratio": 1.8177966101694916, "no_speech_prob": 2.2826334316050634e-05}, {"id": 899, "seek": 500356, "start": 5013.56, "end": 5016.56, "text": " And once you have this energy function, you can.", "tokens": [50364, 1692, 288, 307, 732, 12, 18759, 11, 293, 291, 434, 445, 1382, 281, 584, 11, 291, 458, 11, 50564, 50564, 498, 286, 458, 472, 2158, 295, 288, 11, 393, 291, 980, 385, 11, 498, 286, 458, 288, 16, 11, 393, 291, 980, 385, 1340, 466, 264, 2158, 295, 288, 17, 30, 50864, 50864, 400, 1564, 291, 362, 341, 2281, 2445, 11, 291, 393, 13, 51014, 51014, 286, 976, 291, 288, 16, 11, 291, 393, 6069, 437, 264, 2158, 295, 288, 17, 820, 312, 13, 51214, 51214, 286, 976, 291, 257, 4974, 935, 11, 291, 393, 980, 385, 437, 311, 264, 13699, 935, 322, 264, 1412, 47138, 51414, 51414, 538, 445, 10808, 337, 264, 13699, 19475, 11, 1936, 13, 51764, 51764], "temperature": 0.0, "avg_logprob": -0.07311067424836706, "compression_ratio": 1.8177966101694916, "no_speech_prob": 2.2826334316050634e-05}, {"id": 900, "seek": 500356, "start": 5016.56, "end": 5020.56, "text": " I give you y1, you can predict what the value of y2 should be.", "tokens": [50364, 1692, 288, 307, 732, 12, 18759, 11, 293, 291, 434, 445, 1382, 281, 584, 11, 291, 458, 11, 50564, 50564, 498, 286, 458, 472, 2158, 295, 288, 11, 393, 291, 980, 385, 11, 498, 286, 458, 288, 16, 11, 393, 291, 980, 385, 1340, 466, 264, 2158, 295, 288, 17, 30, 50864, 50864, 400, 1564, 291, 362, 341, 2281, 2445, 11, 291, 393, 13, 51014, 51014, 286, 976, 291, 288, 16, 11, 291, 393, 6069, 437, 264, 2158, 295, 288, 17, 820, 312, 13, 51214, 51214, 286, 976, 291, 257, 4974, 935, 11, 291, 393, 980, 385, 437, 311, 264, 13699, 935, 322, 264, 1412, 47138, 51414, 51414, 538, 445, 10808, 337, 264, 13699, 19475, 11, 1936, 13, 51764, 51764], "temperature": 0.0, "avg_logprob": -0.07311067424836706, "compression_ratio": 1.8177966101694916, "no_speech_prob": 2.2826334316050634e-05}, {"id": 901, "seek": 500356, "start": 5020.56, "end": 5024.56, "text": " I give you a random point, you can tell me what's the closest point on the data manifold", "tokens": [50364, 1692, 288, 307, 732, 12, 18759, 11, 293, 291, 434, 445, 1382, 281, 584, 11, 291, 458, 11, 50564, 50564, 498, 286, 458, 472, 2158, 295, 288, 11, 393, 291, 980, 385, 11, 498, 286, 458, 288, 16, 11, 393, 291, 980, 385, 1340, 466, 264, 2158, 295, 288, 17, 30, 50864, 50864, 400, 1564, 291, 362, 341, 2281, 2445, 11, 291, 393, 13, 51014, 51014, 286, 976, 291, 288, 16, 11, 291, 393, 6069, 437, 264, 2158, 295, 288, 17, 820, 312, 13, 51214, 51214, 286, 976, 291, 257, 4974, 935, 11, 291, 393, 980, 385, 437, 311, 264, 13699, 935, 322, 264, 1412, 47138, 51414, 51414, 538, 445, 10808, 337, 264, 13699, 19475, 11, 1936, 13, 51764, 51764], "temperature": 0.0, "avg_logprob": -0.07311067424836706, "compression_ratio": 1.8177966101694916, "no_speech_prob": 2.2826334316050634e-05}, {"id": 902, "seek": 500356, "start": 5024.56, "end": 5031.56, "text": " by just searching for the closest prototype, basically.", "tokens": [50364, 1692, 288, 307, 732, 12, 18759, 11, 293, 291, 434, 445, 1382, 281, 584, 11, 291, 458, 11, 50564, 50564, 498, 286, 458, 472, 2158, 295, 288, 11, 393, 291, 980, 385, 11, 498, 286, 458, 288, 16, 11, 393, 291, 980, 385, 1340, 466, 264, 2158, 295, 288, 17, 30, 50864, 50864, 400, 1564, 291, 362, 341, 2281, 2445, 11, 291, 393, 13, 51014, 51014, 286, 976, 291, 288, 16, 11, 291, 393, 6069, 437, 264, 2158, 295, 288, 17, 820, 312, 13, 51214, 51214, 286, 976, 291, 257, 4974, 935, 11, 291, 393, 980, 385, 437, 311, 264, 13699, 935, 322, 264, 1412, 47138, 51414, 51414, 538, 445, 10808, 337, 264, 13699, 19475, 11, 1936, 13, 51764, 51764], "temperature": 0.0, "avg_logprob": -0.07311067424836706, "compression_ratio": 1.8177966101694916, "no_speech_prob": 2.2826334316050634e-05}, {"id": 903, "seek": 503156, "start": 5031.56, "end": 5037.56, "text": " So k-means, that I just explained here, belongs to the architectural methods.", "tokens": [50364, 407, 350, 12, 1398, 599, 11, 300, 286, 445, 8825, 510, 11, 12953, 281, 264, 26621, 7150, 13, 50664, 50664, 467, 311, 406, 257, 8712, 488, 3170, 11, 382, 291, 393, 11441, 13, 50914, 50914, 286, 630, 406, 2944, 493, 322, 264, 2281, 295, 1340, 11, 286, 445, 9152, 760, 322, 264, 2281, 295, 1507, 13, 51164, 51164, 440, 350, 12, 1398, 599, 307, 3094, 294, 1270, 257, 636, 300, 456, 307, 787, 350, 2793, 294, 264, 1901, 300, 393, 362, 4018, 2281, 11, 51414, 51414, 293, 1203, 1646, 486, 362, 2946, 2281, 13, 51614, 51614, 1033, 11, 309, 311, 445, 4761, 341, 636, 11, 558, 30, 51714, 51714], "temperature": 0.0, "avg_logprob": -0.09523166622127499, "compression_ratio": 1.6571428571428573, "no_speech_prob": 4.13263842347078e-05}, {"id": 904, "seek": 503156, "start": 5037.56, "end": 5042.56, "text": " It's not a contrastive method, as you can observe.", "tokens": [50364, 407, 350, 12, 1398, 599, 11, 300, 286, 445, 8825, 510, 11, 12953, 281, 264, 26621, 7150, 13, 50664, 50664, 467, 311, 406, 257, 8712, 488, 3170, 11, 382, 291, 393, 11441, 13, 50914, 50914, 286, 630, 406, 2944, 493, 322, 264, 2281, 295, 1340, 11, 286, 445, 9152, 760, 322, 264, 2281, 295, 1507, 13, 51164, 51164, 440, 350, 12, 1398, 599, 307, 3094, 294, 1270, 257, 636, 300, 456, 307, 787, 350, 2793, 294, 264, 1901, 300, 393, 362, 4018, 2281, 11, 51414, 51414, 293, 1203, 1646, 486, 362, 2946, 2281, 13, 51614, 51614, 1033, 11, 309, 311, 445, 4761, 341, 636, 11, 558, 30, 51714, 51714], "temperature": 0.0, "avg_logprob": -0.09523166622127499, "compression_ratio": 1.6571428571428573, "no_speech_prob": 4.13263842347078e-05}, {"id": 905, "seek": 503156, "start": 5042.56, "end": 5047.56, "text": " I did not push up on the energy of anything, I just pushed down on the energy of stuff.", "tokens": [50364, 407, 350, 12, 1398, 599, 11, 300, 286, 445, 8825, 510, 11, 12953, 281, 264, 26621, 7150, 13, 50664, 50664, 467, 311, 406, 257, 8712, 488, 3170, 11, 382, 291, 393, 11441, 13, 50914, 50914, 286, 630, 406, 2944, 493, 322, 264, 2281, 295, 1340, 11, 286, 445, 9152, 760, 322, 264, 2281, 295, 1507, 13, 51164, 51164, 440, 350, 12, 1398, 599, 307, 3094, 294, 1270, 257, 636, 300, 456, 307, 787, 350, 2793, 294, 264, 1901, 300, 393, 362, 4018, 2281, 11, 51414, 51414, 293, 1203, 1646, 486, 362, 2946, 2281, 13, 51614, 51614, 1033, 11, 309, 311, 445, 4761, 341, 636, 11, 558, 30, 51714, 51714], "temperature": 0.0, "avg_logprob": -0.09523166622127499, "compression_ratio": 1.6571428571428573, "no_speech_prob": 4.13263842347078e-05}, {"id": 906, "seek": 503156, "start": 5047.56, "end": 5052.56, "text": " The k-means is built in such a way that there is only k points in the space that can have zero energy,", "tokens": [50364, 407, 350, 12, 1398, 599, 11, 300, 286, 445, 8825, 510, 11, 12953, 281, 264, 26621, 7150, 13, 50664, 50664, 467, 311, 406, 257, 8712, 488, 3170, 11, 382, 291, 393, 11441, 13, 50914, 50914, 286, 630, 406, 2944, 493, 322, 264, 2281, 295, 1340, 11, 286, 445, 9152, 760, 322, 264, 2281, 295, 1507, 13, 51164, 51164, 440, 350, 12, 1398, 599, 307, 3094, 294, 1270, 257, 636, 300, 456, 307, 787, 350, 2793, 294, 264, 1901, 300, 393, 362, 4018, 2281, 11, 51414, 51414, 293, 1203, 1646, 486, 362, 2946, 2281, 13, 51614, 51614, 1033, 11, 309, 311, 445, 4761, 341, 636, 11, 558, 30, 51714, 51714], "temperature": 0.0, "avg_logprob": -0.09523166622127499, "compression_ratio": 1.6571428571428573, "no_speech_prob": 4.13263842347078e-05}, {"id": 907, "seek": 503156, "start": 5052.56, "end": 5056.56, "text": " and everything else will have higher energy.", "tokens": [50364, 407, 350, 12, 1398, 599, 11, 300, 286, 445, 8825, 510, 11, 12953, 281, 264, 26621, 7150, 13, 50664, 50664, 467, 311, 406, 257, 8712, 488, 3170, 11, 382, 291, 393, 11441, 13, 50914, 50914, 286, 630, 406, 2944, 493, 322, 264, 2281, 295, 1340, 11, 286, 445, 9152, 760, 322, 264, 2281, 295, 1507, 13, 51164, 51164, 440, 350, 12, 1398, 599, 307, 3094, 294, 1270, 257, 636, 300, 456, 307, 787, 350, 2793, 294, 264, 1901, 300, 393, 362, 4018, 2281, 11, 51414, 51414, 293, 1203, 1646, 486, 362, 2946, 2281, 13, 51614, 51614, 1033, 11, 309, 311, 445, 4761, 341, 636, 11, 558, 30, 51714, 51714], "temperature": 0.0, "avg_logprob": -0.09523166622127499, "compression_ratio": 1.6571428571428573, "no_speech_prob": 4.13263842347078e-05}, {"id": 908, "seek": 503156, "start": 5056.56, "end": 5058.56, "text": " Okay, it's just designed this way, right?", "tokens": [50364, 407, 350, 12, 1398, 599, 11, 300, 286, 445, 8825, 510, 11, 12953, 281, 264, 26621, 7150, 13, 50664, 50664, 467, 311, 406, 257, 8712, 488, 3170, 11, 382, 291, 393, 11441, 13, 50914, 50914, 286, 630, 406, 2944, 493, 322, 264, 2281, 295, 1340, 11, 286, 445, 9152, 760, 322, 264, 2281, 295, 1507, 13, 51164, 51164, 440, 350, 12, 1398, 599, 307, 3094, 294, 1270, 257, 636, 300, 456, 307, 787, 350, 2793, 294, 264, 1901, 300, 393, 362, 4018, 2281, 11, 51414, 51414, 293, 1203, 1646, 486, 362, 2946, 2281, 13, 51614, 51614, 1033, 11, 309, 311, 445, 4761, 341, 636, 11, 558, 30, 51714, 51714], "temperature": 0.0, "avg_logprob": -0.09523166622127499, "compression_ratio": 1.6571428571428573, "no_speech_prob": 4.13263842347078e-05}, {"id": 909, "seek": 505856, "start": 5058.56, "end": 5061.56, "text": " So it's architectural in that sense.", "tokens": [50364, 407, 309, 311, 26621, 294, 300, 2020, 13, 50514, 50514, 3443, 286, 600, 3047, 322, 350, 11, 286, 600, 5567, 264, 5523, 295, 1901, 294, 288, 300, 393, 747, 2295, 2281, 11, 50814, 50814, 570, 456, 311, 787, 350, 2793, 300, 393, 362, 4018, 2281, 13, 51114, 51114, 5471, 1646, 13156, 10787, 4481, 984, 382, 286, 1286, 1314, 490, 552, 13, 51364, 51364, 823, 718, 311, 751, 466, 11, 456, 311, 257, 3840, 295, 661, 7150, 13, 51514, 51514, 1981, 366, 452, 2954, 7150, 13, 51614, 51614, 286, 519, 6284, 2201, 486, 312, 1228, 26621, 7150, 13, 51814, 51814], "temperature": 0.0, "avg_logprob": -0.08473443512869354, "compression_ratio": 1.616326530612245, "no_speech_prob": 1.952254751813598e-05}, {"id": 910, "seek": 505856, "start": 5061.56, "end": 5067.56, "text": " Once I've decided on k, I've limited the volume of space in y that can take low energy,", "tokens": [50364, 407, 309, 311, 26621, 294, 300, 2020, 13, 50514, 50514, 3443, 286, 600, 3047, 322, 350, 11, 286, 600, 5567, 264, 5523, 295, 1901, 294, 288, 300, 393, 747, 2295, 2281, 11, 50814, 50814, 570, 456, 311, 787, 350, 2793, 300, 393, 362, 4018, 2281, 13, 51114, 51114, 5471, 1646, 13156, 10787, 4481, 984, 382, 286, 1286, 1314, 490, 552, 13, 51364, 51364, 823, 718, 311, 751, 466, 11, 456, 311, 257, 3840, 295, 661, 7150, 13, 51514, 51514, 1981, 366, 452, 2954, 7150, 13, 51614, 51614, 286, 519, 6284, 2201, 486, 312, 1228, 26621, 7150, 13, 51814, 51814], "temperature": 0.0, "avg_logprob": -0.08473443512869354, "compression_ratio": 1.616326530612245, "no_speech_prob": 1.952254751813598e-05}, {"id": 911, "seek": 505856, "start": 5067.56, "end": 5073.56, "text": " because there's only k points that can have zero energy.", "tokens": [50364, 407, 309, 311, 26621, 294, 300, 2020, 13, 50514, 50514, 3443, 286, 600, 3047, 322, 350, 11, 286, 600, 5567, 264, 5523, 295, 1901, 294, 288, 300, 393, 747, 2295, 2281, 11, 50814, 50814, 570, 456, 311, 787, 350, 2793, 300, 393, 362, 4018, 2281, 13, 51114, 51114, 5471, 1646, 13156, 10787, 4481, 984, 382, 286, 1286, 1314, 490, 552, 13, 51364, 51364, 823, 718, 311, 751, 466, 11, 456, 311, 257, 3840, 295, 661, 7150, 13, 51514, 51514, 1981, 366, 452, 2954, 7150, 13, 51614, 51614, 286, 519, 6284, 2201, 486, 312, 1228, 26621, 7150, 13, 51814, 51814], "temperature": 0.0, "avg_logprob": -0.08473443512869354, "compression_ratio": 1.616326530612245, "no_speech_prob": 1.952254751813598e-05}, {"id": 912, "seek": 505856, "start": 5073.56, "end": 5078.56, "text": " Everything else grows quadratically as I move away from them.", "tokens": [50364, 407, 309, 311, 26621, 294, 300, 2020, 13, 50514, 50514, 3443, 286, 600, 3047, 322, 350, 11, 286, 600, 5567, 264, 5523, 295, 1901, 294, 288, 300, 393, 747, 2295, 2281, 11, 50814, 50814, 570, 456, 311, 787, 350, 2793, 300, 393, 362, 4018, 2281, 13, 51114, 51114, 5471, 1646, 13156, 10787, 4481, 984, 382, 286, 1286, 1314, 490, 552, 13, 51364, 51364, 823, 718, 311, 751, 466, 11, 456, 311, 257, 3840, 295, 661, 7150, 13, 51514, 51514, 1981, 366, 452, 2954, 7150, 13, 51614, 51614, 286, 519, 6284, 2201, 486, 312, 1228, 26621, 7150, 13, 51814, 51814], "temperature": 0.0, "avg_logprob": -0.08473443512869354, "compression_ratio": 1.616326530612245, "no_speech_prob": 1.952254751813598e-05}, {"id": 913, "seek": 505856, "start": 5078.56, "end": 5081.56, "text": " Now let's talk about, there's a bunch of other methods.", "tokens": [50364, 407, 309, 311, 26621, 294, 300, 2020, 13, 50514, 50514, 3443, 286, 600, 3047, 322, 350, 11, 286, 600, 5567, 264, 5523, 295, 1901, 294, 288, 300, 393, 747, 2295, 2281, 11, 50814, 50814, 570, 456, 311, 787, 350, 2793, 300, 393, 362, 4018, 2281, 13, 51114, 51114, 5471, 1646, 13156, 10787, 4481, 984, 382, 286, 1286, 1314, 490, 552, 13, 51364, 51364, 823, 718, 311, 751, 466, 11, 456, 311, 257, 3840, 295, 661, 7150, 13, 51514, 51514, 1981, 366, 452, 2954, 7150, 13, 51614, 51614, 286, 519, 6284, 2201, 486, 312, 1228, 26621, 7150, 13, 51814, 51814], "temperature": 0.0, "avg_logprob": -0.08473443512869354, "compression_ratio": 1.616326530612245, "no_speech_prob": 1.952254751813598e-05}, {"id": 914, "seek": 505856, "start": 5081.56, "end": 5083.56, "text": " These are my favorite methods.", "tokens": [50364, 407, 309, 311, 26621, 294, 300, 2020, 13, 50514, 50514, 3443, 286, 600, 3047, 322, 350, 11, 286, 600, 5567, 264, 5523, 295, 1901, 294, 288, 300, 393, 747, 2295, 2281, 11, 50814, 50814, 570, 456, 311, 787, 350, 2793, 300, 393, 362, 4018, 2281, 13, 51114, 51114, 5471, 1646, 13156, 10787, 4481, 984, 382, 286, 1286, 1314, 490, 552, 13, 51364, 51364, 823, 718, 311, 751, 466, 11, 456, 311, 257, 3840, 295, 661, 7150, 13, 51514, 51514, 1981, 366, 452, 2954, 7150, 13, 51614, 51614, 286, 519, 6284, 2201, 486, 312, 1228, 26621, 7150, 13, 51814, 51814], "temperature": 0.0, "avg_logprob": -0.08473443512869354, "compression_ratio": 1.616326530612245, "no_speech_prob": 1.952254751813598e-05}, {"id": 915, "seek": 505856, "start": 5083.56, "end": 5087.56, "text": " I think ultimately everybody will be using architectural methods.", "tokens": [50364, 407, 309, 311, 26621, 294, 300, 2020, 13, 50514, 50514, 3443, 286, 600, 3047, 322, 350, 11, 286, 600, 5567, 264, 5523, 295, 1901, 294, 288, 300, 393, 747, 2295, 2281, 11, 50814, 50814, 570, 456, 311, 787, 350, 2793, 300, 393, 362, 4018, 2281, 13, 51114, 51114, 5471, 1646, 13156, 10787, 4481, 984, 382, 286, 1286, 1314, 490, 552, 13, 51364, 51364, 823, 718, 311, 751, 466, 11, 456, 311, 257, 3840, 295, 661, 7150, 13, 51514, 51514, 1981, 366, 452, 2954, 7150, 13, 51614, 51614, 286, 519, 6284, 2201, 486, 312, 1228, 26621, 7150, 13, 51814, 51814], "temperature": 0.0, "avg_logprob": -0.08473443512869354, "compression_ratio": 1.616326530612245, "no_speech_prob": 1.952254751813598e-05}, {"id": 916, "seek": 508756, "start": 5087.56, "end": 5095.56, "text": " But right now the stuff that works in images is contrastive.", "tokens": [50364, 583, 558, 586, 264, 1507, 300, 1985, 294, 5267, 307, 8712, 488, 13, 50764, 50764, 1033, 11, 370, 8712, 488, 7150, 13, 51114, 51114, 286, 362, 1412, 2793, 13, 51514, 51514], "temperature": 0.0, "avg_logprob": -0.14655588612411963, "compression_ratio": 1.1956521739130435, "no_speech_prob": 2.429656706226524e-05}, {"id": 917, "seek": 508756, "start": 5095.56, "end": 5102.56, "text": " Okay, so contrastive methods.", "tokens": [50364, 583, 558, 586, 264, 1507, 300, 1985, 294, 5267, 307, 8712, 488, 13, 50764, 50764, 1033, 11, 370, 8712, 488, 7150, 13, 51114, 51114, 286, 362, 1412, 2793, 13, 51514, 51514], "temperature": 0.0, "avg_logprob": -0.14655588612411963, "compression_ratio": 1.1956521739130435, "no_speech_prob": 2.429656706226524e-05}, {"id": 918, "seek": 508756, "start": 5102.56, "end": 5110.56, "text": " I have data points.", "tokens": [50364, 583, 558, 586, 264, 1507, 300, 1985, 294, 5267, 307, 8712, 488, 13, 50764, 50764, 1033, 11, 370, 8712, 488, 7150, 13, 51114, 51114, 286, 362, 1412, 2793, 13, 51514, 51514], "temperature": 0.0, "avg_logprob": -0.14655588612411963, "compression_ratio": 1.1956521739130435, "no_speech_prob": 2.429656706226524e-05}, {"id": 919, "seek": 511056, "start": 5110.56, "end": 5119.56, "text": " And currently my model computes an energy function, let's say that looks like this.", "tokens": [50364, 400, 4362, 452, 2316, 715, 1819, 364, 2281, 2445, 11, 718, 311, 584, 300, 1542, 411, 341, 13, 50814, 50814, 407, 286, 478, 6316, 264, 660, 5067, 295, 2681, 2063, 13, 51114, 51114, 1033, 11, 309, 311, 411, 257, 1192, 12295, 4471, 13, 51364, 51364, 407, 2745, 300, 2316, 307, 1578, 11, 558, 11, 570, 309, 2709, 2295, 2281, 281, 729, 2793, 510, 13, 51564, 51564, 3950, 2793, 362, 2295, 2281, 293, 436, 820, 406, 13, 51814, 51814], "temperature": 0.0, "avg_logprob": -0.09960679411888122, "compression_ratio": 1.492537313432836, "no_speech_prob": 1.3628068700199947e-05}, {"id": 920, "seek": 511056, "start": 5119.56, "end": 5125.56, "text": " So I'm drawing the contours of equal cost.", "tokens": [50364, 400, 4362, 452, 2316, 715, 1819, 364, 2281, 2445, 11, 718, 311, 584, 300, 1542, 411, 341, 13, 50814, 50814, 407, 286, 478, 6316, 264, 660, 5067, 295, 2681, 2063, 13, 51114, 51114, 1033, 11, 309, 311, 411, 257, 1192, 12295, 4471, 13, 51364, 51364, 407, 2745, 300, 2316, 307, 1578, 11, 558, 11, 570, 309, 2709, 2295, 2281, 281, 729, 2793, 510, 13, 51564, 51564, 3950, 2793, 362, 2295, 2281, 293, 436, 820, 406, 13, 51814, 51814], "temperature": 0.0, "avg_logprob": -0.09960679411888122, "compression_ratio": 1.492537313432836, "no_speech_prob": 1.3628068700199947e-05}, {"id": 921, "seek": 511056, "start": 5125.56, "end": 5130.56, "text": " Okay, it's like a topographic map.", "tokens": [50364, 400, 4362, 452, 2316, 715, 1819, 364, 2281, 2445, 11, 718, 311, 584, 300, 1542, 411, 341, 13, 50814, 50814, 407, 286, 478, 6316, 264, 660, 5067, 295, 2681, 2063, 13, 51114, 51114, 1033, 11, 309, 311, 411, 257, 1192, 12295, 4471, 13, 51364, 51364, 407, 2745, 300, 2316, 307, 1578, 11, 558, 11, 570, 309, 2709, 2295, 2281, 281, 729, 2793, 510, 13, 51564, 51564, 3950, 2793, 362, 2295, 2281, 293, 436, 820, 406, 13, 51814, 51814], "temperature": 0.0, "avg_logprob": -0.09960679411888122, "compression_ratio": 1.492537313432836, "no_speech_prob": 1.3628068700199947e-05}, {"id": 922, "seek": 511056, "start": 5130.56, "end": 5134.56, "text": " So obviously that model is bad, right, because it gives low energy to those points here.", "tokens": [50364, 400, 4362, 452, 2316, 715, 1819, 364, 2281, 2445, 11, 718, 311, 584, 300, 1542, 411, 341, 13, 50814, 50814, 407, 286, 478, 6316, 264, 660, 5067, 295, 2681, 2063, 13, 51114, 51114, 1033, 11, 309, 311, 411, 257, 1192, 12295, 4471, 13, 51364, 51364, 407, 2745, 300, 2316, 307, 1578, 11, 558, 11, 570, 309, 2709, 2295, 2281, 281, 729, 2793, 510, 13, 51564, 51564, 3950, 2793, 362, 2295, 2281, 293, 436, 820, 406, 13, 51814, 51814], "temperature": 0.0, "avg_logprob": -0.09960679411888122, "compression_ratio": 1.492537313432836, "no_speech_prob": 1.3628068700199947e-05}, {"id": 923, "seek": 511056, "start": 5134.56, "end": 5139.56, "text": " Those points have low energy and they should not.", "tokens": [50364, 400, 4362, 452, 2316, 715, 1819, 364, 2281, 2445, 11, 718, 311, 584, 300, 1542, 411, 341, 13, 50814, 50814, 407, 286, 478, 6316, 264, 660, 5067, 295, 2681, 2063, 13, 51114, 51114, 1033, 11, 309, 311, 411, 257, 1192, 12295, 4471, 13, 51364, 51364, 407, 2745, 300, 2316, 307, 1578, 11, 558, 11, 570, 309, 2709, 2295, 2281, 281, 729, 2793, 510, 13, 51564, 51564, 3950, 2793, 362, 2295, 2281, 293, 436, 820, 406, 13, 51814, 51814], "temperature": 0.0, "avg_logprob": -0.09960679411888122, "compression_ratio": 1.492537313432836, "no_speech_prob": 1.3628068700199947e-05}, {"id": 924, "seek": 513956, "start": 5139.56, "end": 5144.56, "text": " And then those points have high energy and they should not.", "tokens": [50364, 400, 550, 729, 2793, 362, 1090, 2281, 293, 436, 820, 406, 13, 50614, 50614, 407, 437, 820, 286, 360, 30, 50764, 50764, 407, 2745, 498, 286, 747, 257, 3097, 6889, 510, 11, 51164, 51164, 293, 286, 1319, 264, 9834, 295, 283, 295, 364, 2031, 11, 288, 370, 300, 264, 2281, 1709, 760, 11, 51414, 51414, 309, 311, 1391, 516, 281, 1286, 264, 2445, 281, 362, 733, 295, 3126, 4190, 294, 300, 4458, 13, 51814, 51814], "temperature": 0.0, "avg_logprob": -0.0829168109150676, "compression_ratio": 1.5105263157894737, "no_speech_prob": 3.5347373341210186e-05}, {"id": 925, "seek": 513956, "start": 5144.56, "end": 5147.56, "text": " So what should I do?", "tokens": [50364, 400, 550, 729, 2793, 362, 1090, 2281, 293, 436, 820, 406, 13, 50614, 50614, 407, 437, 820, 286, 360, 30, 50764, 50764, 407, 2745, 498, 286, 747, 257, 3097, 6889, 510, 11, 51164, 51164, 293, 286, 1319, 264, 9834, 295, 283, 295, 364, 2031, 11, 288, 370, 300, 264, 2281, 1709, 760, 11, 51414, 51414, 309, 311, 1391, 516, 281, 1286, 264, 2445, 281, 362, 733, 295, 3126, 4190, 294, 300, 4458, 13, 51814, 51814], "temperature": 0.0, "avg_logprob": -0.0829168109150676, "compression_ratio": 1.5105263157894737, "no_speech_prob": 3.5347373341210186e-05}, {"id": 926, "seek": 513956, "start": 5147.56, "end": 5155.56, "text": " So obviously if I take a training sample here,", "tokens": [50364, 400, 550, 729, 2793, 362, 1090, 2281, 293, 436, 820, 406, 13, 50614, 50614, 407, 437, 820, 286, 360, 30, 50764, 50764, 407, 2745, 498, 286, 747, 257, 3097, 6889, 510, 11, 51164, 51164, 293, 286, 1319, 264, 9834, 295, 283, 295, 364, 2031, 11, 288, 370, 300, 264, 2281, 1709, 760, 11, 51414, 51414, 309, 311, 1391, 516, 281, 1286, 264, 2445, 281, 362, 733, 295, 3126, 4190, 294, 300, 4458, 13, 51814, 51814], "temperature": 0.0, "avg_logprob": -0.0829168109150676, "compression_ratio": 1.5105263157894737, "no_speech_prob": 3.5347373341210186e-05}, {"id": 927, "seek": 513956, "start": 5155.56, "end": 5160.56, "text": " and I change the parameters of f of an x, y so that the energy goes down,", "tokens": [50364, 400, 550, 729, 2793, 362, 1090, 2281, 293, 436, 820, 406, 13, 50614, 50614, 407, 437, 820, 286, 360, 30, 50764, 50764, 407, 2745, 498, 286, 747, 257, 3097, 6889, 510, 11, 51164, 51164, 293, 286, 1319, 264, 9834, 295, 283, 295, 364, 2031, 11, 288, 370, 300, 264, 2281, 1709, 760, 11, 51414, 51414, 309, 311, 1391, 516, 281, 1286, 264, 2445, 281, 362, 733, 295, 3126, 4190, 294, 300, 4458, 13, 51814, 51814], "temperature": 0.0, "avg_logprob": -0.0829168109150676, "compression_ratio": 1.5105263157894737, "no_speech_prob": 3.5347373341210186e-05}, {"id": 928, "seek": 513956, "start": 5160.56, "end": 5168.56, "text": " it's probably going to move the function to have kind of lower values in that region.", "tokens": [50364, 400, 550, 729, 2793, 362, 1090, 2281, 293, 436, 820, 406, 13, 50614, 50614, 407, 437, 820, 286, 360, 30, 50764, 50764, 407, 2745, 498, 286, 747, 257, 3097, 6889, 510, 11, 51164, 51164, 293, 286, 1319, 264, 9834, 295, 283, 295, 364, 2031, 11, 288, 370, 300, 264, 2281, 1709, 760, 11, 51414, 51414, 309, 311, 1391, 516, 281, 1286, 264, 2445, 281, 362, 733, 295, 3126, 4190, 294, 300, 4458, 13, 51814, 51814], "temperature": 0.0, "avg_logprob": -0.0829168109150676, "compression_ratio": 1.5105263157894737, "no_speech_prob": 3.5347373341210186e-05}, {"id": 929, "seek": 516856, "start": 5168.56, "end": 5172.56, "text": " But that may not be sufficient because it could be that my energy function is parameterized", "tokens": [50364, 583, 300, 815, 406, 312, 11563, 570, 309, 727, 312, 300, 452, 2281, 2445, 307, 13075, 1602, 50564, 50564, 294, 1270, 257, 636, 300, 309, 727, 312, 4962, 11, 727, 312, 4018, 11, 5315, 13, 50764, 50764, 407, 286, 643, 281, 20803, 2944, 493, 322, 661, 3190, 13, 51014, 51014, 400, 370, 257, 665, 4914, 281, 2944, 493, 576, 312, 729, 2182, 9253, 510, 13, 51264, 51264, 1981, 366, 9253, 300, 452, 2316, 2709, 2295, 2281, 281, 11, 457, 820, 406, 362, 2295, 2281, 13, 51714, 51714], "temperature": 0.0, "avg_logprob": -0.08981973133730085, "compression_ratio": 1.7391304347826086, "no_speech_prob": 2.505765405658167e-05}, {"id": 930, "seek": 516856, "start": 5172.56, "end": 5176.56, "text": " in such a way that it could be flat, could be zero, everywhere.", "tokens": [50364, 583, 300, 815, 406, 312, 11563, 570, 309, 727, 312, 300, 452, 2281, 2445, 307, 13075, 1602, 50564, 50564, 294, 1270, 257, 636, 300, 309, 727, 312, 4962, 11, 727, 312, 4018, 11, 5315, 13, 50764, 50764, 407, 286, 643, 281, 20803, 2944, 493, 322, 661, 3190, 13, 51014, 51014, 400, 370, 257, 665, 4914, 281, 2944, 493, 576, 312, 729, 2182, 9253, 510, 13, 51264, 51264, 1981, 366, 9253, 300, 452, 2316, 2709, 2295, 2281, 281, 11, 457, 820, 406, 362, 2295, 2281, 13, 51714, 51714], "temperature": 0.0, "avg_logprob": -0.08981973133730085, "compression_ratio": 1.7391304347826086, "no_speech_prob": 2.505765405658167e-05}, {"id": 931, "seek": 516856, "start": 5176.56, "end": 5181.56, "text": " So I need to explicitly push up on other places.", "tokens": [50364, 583, 300, 815, 406, 312, 11563, 570, 309, 727, 312, 300, 452, 2281, 2445, 307, 13075, 1602, 50564, 50564, 294, 1270, 257, 636, 300, 309, 727, 312, 4962, 11, 727, 312, 4018, 11, 5315, 13, 50764, 50764, 407, 286, 643, 281, 20803, 2944, 493, 322, 661, 3190, 13, 51014, 51014, 400, 370, 257, 665, 4914, 281, 2944, 493, 576, 312, 729, 2182, 9253, 510, 13, 51264, 51264, 1981, 366, 9253, 300, 452, 2316, 2709, 2295, 2281, 281, 11, 457, 820, 406, 362, 2295, 2281, 13, 51714, 51714], "temperature": 0.0, "avg_logprob": -0.08981973133730085, "compression_ratio": 1.7391304347826086, "no_speech_prob": 2.505765405658167e-05}, {"id": 932, "seek": 516856, "start": 5181.56, "end": 5186.56, "text": " And so a good location to push up would be those red locations here.", "tokens": [50364, 583, 300, 815, 406, 312, 11563, 570, 309, 727, 312, 300, 452, 2281, 2445, 307, 13075, 1602, 50564, 50564, 294, 1270, 257, 636, 300, 309, 727, 312, 4962, 11, 727, 312, 4018, 11, 5315, 13, 50764, 50764, 407, 286, 643, 281, 20803, 2944, 493, 322, 661, 3190, 13, 51014, 51014, 400, 370, 257, 665, 4914, 281, 2944, 493, 576, 312, 729, 2182, 9253, 510, 13, 51264, 51264, 1981, 366, 9253, 300, 452, 2316, 2709, 2295, 2281, 281, 11, 457, 820, 406, 362, 2295, 2281, 13, 51714, 51714], "temperature": 0.0, "avg_logprob": -0.08981973133730085, "compression_ratio": 1.7391304347826086, "no_speech_prob": 2.505765405658167e-05}, {"id": 933, "seek": 516856, "start": 5186.56, "end": 5195.56, "text": " These are locations that my model gives low energy to, but should not have low energy.", "tokens": [50364, 583, 300, 815, 406, 312, 11563, 570, 309, 727, 312, 300, 452, 2281, 2445, 307, 13075, 1602, 50564, 50564, 294, 1270, 257, 636, 300, 309, 727, 312, 4962, 11, 727, 312, 4018, 11, 5315, 13, 50764, 50764, 407, 286, 643, 281, 20803, 2944, 493, 322, 661, 3190, 13, 51014, 51014, 400, 370, 257, 665, 4914, 281, 2944, 493, 576, 312, 729, 2182, 9253, 510, 13, 51264, 51264, 1981, 366, 9253, 300, 452, 2316, 2709, 2295, 2281, 281, 11, 457, 820, 406, 362, 2295, 2281, 13, 51714, 51714], "temperature": 0.0, "avg_logprob": -0.08981973133730085, "compression_ratio": 1.7391304347826086, "no_speech_prob": 2.505765405658167e-05}, {"id": 934, "seek": 519556, "start": 5195.56, "end": 5203.56, "text": " So let's say this is my training sample right now.", "tokens": [50364, 407, 718, 311, 584, 341, 307, 452, 3097, 6889, 558, 586, 13, 50764, 50764, 1033, 11, 264, 955, 2211, 5893, 510, 11, 300, 311, 452, 3097, 6889, 13, 50964, 50964, 1485, 636, 286, 393, 3847, 257, 8712, 488, 1185, 307, 538, 1566, 286, 478, 516, 281, 2944, 760, 322, 264, 2281, 295, 300, 935, 11, 51314, 51314, 293, 286, 478, 516, 281, 40468, 300, 935, 257, 707, 857, 538, 17366, 278, 309, 512, 636, 11, 5127, 5658, 281, 309, 11, 51714, 51714], "temperature": 0.0, "avg_logprob": -0.07814649173191615, "compression_ratio": 1.6436170212765957, "no_speech_prob": 1.892024556582328e-05}, {"id": 935, "seek": 519556, "start": 5203.56, "end": 5207.56, "text": " Okay, the big black dot here, that's my training sample.", "tokens": [50364, 407, 718, 311, 584, 341, 307, 452, 3097, 6889, 558, 586, 13, 50764, 50764, 1033, 11, 264, 955, 2211, 5893, 510, 11, 300, 311, 452, 3097, 6889, 13, 50964, 50964, 1485, 636, 286, 393, 3847, 257, 8712, 488, 1185, 307, 538, 1566, 286, 478, 516, 281, 2944, 760, 322, 264, 2281, 295, 300, 935, 11, 51314, 51314, 293, 286, 478, 516, 281, 40468, 300, 935, 257, 707, 857, 538, 17366, 278, 309, 512, 636, 11, 5127, 5658, 281, 309, 11, 51714, 51714], "temperature": 0.0, "avg_logprob": -0.07814649173191615, "compression_ratio": 1.6436170212765957, "no_speech_prob": 1.892024556582328e-05}, {"id": 936, "seek": 519556, "start": 5207.56, "end": 5214.56, "text": " One way I can train a contrastive system is by saying I'm going to push down on the energy of that point,", "tokens": [50364, 407, 718, 311, 584, 341, 307, 452, 3097, 6889, 558, 586, 13, 50764, 50764, 1033, 11, 264, 955, 2211, 5893, 510, 11, 300, 311, 452, 3097, 6889, 13, 50964, 50964, 1485, 636, 286, 393, 3847, 257, 8712, 488, 1185, 307, 538, 1566, 286, 478, 516, 281, 2944, 760, 322, 264, 2281, 295, 300, 935, 11, 51314, 51314, 293, 286, 478, 516, 281, 40468, 300, 935, 257, 707, 857, 538, 17366, 278, 309, 512, 636, 11, 5127, 5658, 281, 309, 11, 51714, 51714], "temperature": 0.0, "avg_logprob": -0.07814649173191615, "compression_ratio": 1.6436170212765957, "no_speech_prob": 1.892024556582328e-05}, {"id": 937, "seek": 519556, "start": 5214.56, "end": 5222.56, "text": " and I'm going to perturb that point a little bit by corrupting it some way, adding noise to it,", "tokens": [50364, 407, 718, 311, 584, 341, 307, 452, 3097, 6889, 558, 586, 13, 50764, 50764, 1033, 11, 264, 955, 2211, 5893, 510, 11, 300, 311, 452, 3097, 6889, 13, 50964, 50964, 1485, 636, 286, 393, 3847, 257, 8712, 488, 1185, 307, 538, 1566, 286, 478, 516, 281, 2944, 760, 322, 264, 2281, 295, 300, 935, 11, 51314, 51314, 293, 286, 478, 516, 281, 40468, 300, 935, 257, 707, 857, 538, 17366, 278, 309, 512, 636, 11, 5127, 5658, 281, 309, 11, 51714, 51714], "temperature": 0.0, "avg_logprob": -0.07814649173191615, "compression_ratio": 1.6436170212765957, "no_speech_prob": 1.892024556582328e-05}, {"id": 938, "seek": 522256, "start": 5222.56, "end": 5227.56, "text": " and I'll push up on the energy of a point that's nearby.", "tokens": [50364, 293, 286, 603, 2944, 493, 322, 264, 2281, 295, 257, 935, 300, 311, 11184, 13, 50614, 50614, 1033, 11, 293, 286, 478, 516, 281, 360, 341, 3866, 1413, 13, 50914, 50914, 407, 498, 286, 360, 341, 31868, 867, 1413, 11, 4728, 264, 2281, 2445, 307, 516, 281, 22591, 493, 926, 633, 6889, 51314, 51314, 570, 286, 16927, 257, 6889, 293, 286, 2944, 493, 11, 291, 458, 11, 286, 17366, 309, 257, 707, 857, 11, 51514, 51514, 293, 286, 2944, 493, 322, 264, 2281, 295, 300, 39480, 6889, 11, 264, 8712, 488, 6889, 13, 51814, 51814], "temperature": 0.0, "avg_logprob": -0.08840054580845784, "compression_ratio": 1.733644859813084, "no_speech_prob": 3.320641189930029e-05}, {"id": 939, "seek": 522256, "start": 5227.56, "end": 5233.56, "text": " Okay, and I'm going to do this multiple times.", "tokens": [50364, 293, 286, 603, 2944, 493, 322, 264, 2281, 295, 257, 935, 300, 311, 11184, 13, 50614, 50614, 1033, 11, 293, 286, 478, 516, 281, 360, 341, 3866, 1413, 13, 50914, 50914, 407, 498, 286, 360, 341, 31868, 867, 1413, 11, 4728, 264, 2281, 2445, 307, 516, 281, 22591, 493, 926, 633, 6889, 51314, 51314, 570, 286, 16927, 257, 6889, 293, 286, 2944, 493, 11, 291, 458, 11, 286, 17366, 309, 257, 707, 857, 11, 51514, 51514, 293, 286, 2944, 493, 322, 264, 2281, 295, 300, 39480, 6889, 11, 264, 8712, 488, 6889, 13, 51814, 51814], "temperature": 0.0, "avg_logprob": -0.08840054580845784, "compression_ratio": 1.733644859813084, "no_speech_prob": 3.320641189930029e-05}, {"id": 940, "seek": 522256, "start": 5233.56, "end": 5241.56, "text": " So if I do this sufficiently many times, eventually the energy function is going to curl up around every sample", "tokens": [50364, 293, 286, 603, 2944, 493, 322, 264, 2281, 295, 257, 935, 300, 311, 11184, 13, 50614, 50614, 1033, 11, 293, 286, 478, 516, 281, 360, 341, 3866, 1413, 13, 50914, 50914, 407, 498, 286, 360, 341, 31868, 867, 1413, 11, 4728, 264, 2281, 2445, 307, 516, 281, 22591, 493, 926, 633, 6889, 51314, 51314, 570, 286, 16927, 257, 6889, 293, 286, 2944, 493, 11, 291, 458, 11, 286, 17366, 309, 257, 707, 857, 11, 51514, 51514, 293, 286, 2944, 493, 322, 264, 2281, 295, 300, 39480, 6889, 11, 264, 8712, 488, 6889, 13, 51814, 51814], "temperature": 0.0, "avg_logprob": -0.08840054580845784, "compression_ratio": 1.733644859813084, "no_speech_prob": 3.320641189930029e-05}, {"id": 941, "seek": 522256, "start": 5241.56, "end": 5245.56, "text": " because I modify a sample and I push up, you know, I corrupt it a little bit,", "tokens": [50364, 293, 286, 603, 2944, 493, 322, 264, 2281, 295, 257, 935, 300, 311, 11184, 13, 50614, 50614, 1033, 11, 293, 286, 478, 516, 281, 360, 341, 3866, 1413, 13, 50914, 50914, 407, 498, 286, 360, 341, 31868, 867, 1413, 11, 4728, 264, 2281, 2445, 307, 516, 281, 22591, 493, 926, 633, 6889, 51314, 51314, 570, 286, 16927, 257, 6889, 293, 286, 2944, 493, 11, 291, 458, 11, 286, 17366, 309, 257, 707, 857, 11, 51514, 51514, 293, 286, 2944, 493, 322, 264, 2281, 295, 300, 39480, 6889, 11, 264, 8712, 488, 6889, 13, 51814, 51814], "temperature": 0.0, "avg_logprob": -0.08840054580845784, "compression_ratio": 1.733644859813084, "no_speech_prob": 3.320641189930029e-05}, {"id": 942, "seek": 522256, "start": 5245.56, "end": 5251.56, "text": " and I push up on the energy of that corrupted sample, the contrastive sample.", "tokens": [50364, 293, 286, 603, 2944, 493, 322, 264, 2281, 295, 257, 935, 300, 311, 11184, 13, 50614, 50614, 1033, 11, 293, 286, 478, 516, 281, 360, 341, 3866, 1413, 13, 50914, 50914, 407, 498, 286, 360, 341, 31868, 867, 1413, 11, 4728, 264, 2281, 2445, 307, 516, 281, 22591, 493, 926, 633, 6889, 51314, 51314, 570, 286, 16927, 257, 6889, 293, 286, 2944, 493, 11, 291, 458, 11, 286, 17366, 309, 257, 707, 857, 11, 51514, 51514, 293, 286, 2944, 493, 322, 264, 2281, 295, 300, 39480, 6889, 11, 264, 8712, 488, 6889, 13, 51814, 51814], "temperature": 0.0, "avg_logprob": -0.08840054580845784, "compression_ratio": 1.733644859813084, "no_speech_prob": 3.320641189930029e-05}, {"id": 943, "seek": 525156, "start": 5251.56, "end": 5254.56, "text": " So eventually the energy is going to take the right place.", "tokens": [50364, 407, 4728, 264, 2281, 307, 516, 281, 747, 264, 558, 1081, 13, 50514, 50514, 6595, 257, 707, 20294, 11, 2602, 295, 1333, 295, 16979, 13269, 374, 4324, 264, 3097, 6889, 538, 11, 291, 458, 11, 512, 40468, 399, 926, 309, 11, 51064, 51064, 286, 478, 516, 281, 764, 16235, 23475, 281, 733, 295, 352, 760, 294, 264, 2281, 3753, 11, 51564, 51564, 293, 550, 286, 478, 516, 281, 483, 341, 935, 293, 2944, 309, 493, 13, 51814, 51814], "temperature": 0.0, "avg_logprob": -0.06278103590011597, "compression_ratio": 1.592964824120603, "no_speech_prob": 1.9524837625795044e-05}, {"id": 944, "seek": 525156, "start": 5254.56, "end": 5265.56, "text": " Something a little smarter, instead of sort of randomly perturbing the training sample by, you know, some perturbation around it,", "tokens": [50364, 407, 4728, 264, 2281, 307, 516, 281, 747, 264, 558, 1081, 13, 50514, 50514, 6595, 257, 707, 20294, 11, 2602, 295, 1333, 295, 16979, 13269, 374, 4324, 264, 3097, 6889, 538, 11, 291, 458, 11, 512, 40468, 399, 926, 309, 11, 51064, 51064, 286, 478, 516, 281, 764, 16235, 23475, 281, 733, 295, 352, 760, 294, 264, 2281, 3753, 11, 51564, 51564, 293, 550, 286, 478, 516, 281, 483, 341, 935, 293, 2944, 309, 493, 13, 51814, 51814], "temperature": 0.0, "avg_logprob": -0.06278103590011597, "compression_ratio": 1.592964824120603, "no_speech_prob": 1.9524837625795044e-05}, {"id": 945, "seek": 525156, "start": 5265.56, "end": 5275.56, "text": " I'm going to use gradient descent to kind of go down in the energy surface,", "tokens": [50364, 407, 4728, 264, 2281, 307, 516, 281, 747, 264, 558, 1081, 13, 50514, 50514, 6595, 257, 707, 20294, 11, 2602, 295, 1333, 295, 16979, 13269, 374, 4324, 264, 3097, 6889, 538, 11, 291, 458, 11, 512, 40468, 399, 926, 309, 11, 51064, 51064, 286, 478, 516, 281, 764, 16235, 23475, 281, 733, 295, 352, 760, 294, 264, 2281, 3753, 11, 51564, 51564, 293, 550, 286, 478, 516, 281, 483, 341, 935, 293, 2944, 309, 493, 13, 51814, 51814], "temperature": 0.0, "avg_logprob": -0.06278103590011597, "compression_ratio": 1.592964824120603, "no_speech_prob": 1.9524837625795044e-05}, {"id": 946, "seek": 525156, "start": 5275.56, "end": 5280.56, "text": " and then I'm going to get this point and push it up.", "tokens": [50364, 407, 4728, 264, 2281, 307, 516, 281, 747, 264, 558, 1081, 13, 50514, 50514, 6595, 257, 707, 20294, 11, 2602, 295, 1333, 295, 16979, 13269, 374, 4324, 264, 3097, 6889, 538, 11, 291, 458, 11, 512, 40468, 399, 926, 309, 11, 51064, 51064, 286, 478, 516, 281, 764, 16235, 23475, 281, 733, 295, 352, 760, 294, 264, 2281, 3753, 11, 51564, 51564, 293, 550, 286, 478, 516, 281, 483, 341, 935, 293, 2944, 309, 493, 13, 51814, 51814], "temperature": 0.0, "avg_logprob": -0.06278103590011597, "compression_ratio": 1.592964824120603, "no_speech_prob": 1.9524837625795044e-05}, {"id": 947, "seek": 528056, "start": 5280.56, "end": 5285.56, "text": " Okay, that makes more sense, right, because I'm going for the jiggler here.", "tokens": [50364, 1033, 11, 300, 1669, 544, 2020, 11, 558, 11, 570, 286, 478, 516, 337, 264, 361, 6249, 1918, 510, 13, 50614, 50614, 509, 458, 11, 264, 1185, 733, 295, 10704, 257, 935, 300, 264, 1185, 2709, 11, 300, 309, 2709, 2295, 2281, 281, 4362, 11, 293, 309, 21020, 493, 13, 51164, 51164, 1779, 11, 370, 264, 10747, 307, 510, 307, 257, 3097, 6889, 11, 51514, 51514], "temperature": 0.0, "avg_logprob": -0.14635851803947897, "compression_ratio": 1.4736842105263157, "no_speech_prob": 1.5688610801589675e-05}, {"id": 948, "seek": 528056, "start": 5285.56, "end": 5296.56, "text": " You know, the system kind of finds a point that the system gives, that it gives low energy to currently, and it pushes up.", "tokens": [50364, 1033, 11, 300, 1669, 544, 2020, 11, 558, 11, 570, 286, 478, 516, 337, 264, 361, 6249, 1918, 510, 13, 50614, 50614, 509, 458, 11, 264, 1185, 733, 295, 10704, 257, 935, 300, 264, 1185, 2709, 11, 300, 309, 2709, 2295, 2281, 281, 4362, 11, 293, 309, 21020, 493, 13, 51164, 51164, 1779, 11, 370, 264, 10747, 307, 510, 307, 257, 3097, 6889, 11, 51514, 51514], "temperature": 0.0, "avg_logprob": -0.14635851803947897, "compression_ratio": 1.4736842105263157, "no_speech_prob": 1.5688610801589675e-05}, {"id": 949, "seek": 528056, "start": 5296.56, "end": 5303.56, "text": " Right, so the procedure is here is a training sample,", "tokens": [50364, 1033, 11, 300, 1669, 544, 2020, 11, 558, 11, 570, 286, 478, 516, 337, 264, 361, 6249, 1918, 510, 13, 50614, 50614, 509, 458, 11, 264, 1185, 733, 295, 10704, 257, 935, 300, 264, 1185, 2709, 11, 300, 309, 2709, 2295, 2281, 281, 4362, 11, 293, 309, 21020, 493, 13, 51164, 51164, 1779, 11, 370, 264, 10747, 307, 510, 307, 257, 3097, 6889, 11, 51514, 51514], "temperature": 0.0, "avg_logprob": -0.14635851803947897, "compression_ratio": 1.4736842105263157, "no_speech_prob": 1.5688610801589675e-05}, {"id": 950, "seek": 530356, "start": 5303.56, "end": 5313.56, "text": " move down in the energy surface, so find a value of y that has lower energy than the one you started from,", "tokens": [50364, 1286, 760, 294, 264, 2281, 3753, 11, 370, 915, 257, 2158, 295, 288, 300, 575, 3126, 2281, 813, 264, 472, 291, 1409, 490, 11, 50864, 50864, 293, 550, 300, 311, 257, 8712, 488, 6889, 11, 2944, 309, 493, 13, 51014, 51014, 18229, 760, 322, 264, 3380, 6889, 11, 2944, 493, 322, 341, 777, 6889, 291, 445, 658, 13, 51164, 51164, 823, 341, 1062, 312, 5124, 11, 293, 428, 2281, 2445, 1062, 312, 6179, 11, 309, 815, 362, 2654, 4464, 64, 11, 51414, 51414, 370, 510, 311, 1071, 6532, 13, 440, 661, 6532, 307, 722, 490, 264, 912, 3097, 6889, 11, 51764, 51764], "temperature": 0.0, "avg_logprob": -0.11124756703009972, "compression_ratio": 1.7510373443983402, "no_speech_prob": 8.939365216065198e-06}, {"id": 951, "seek": 530356, "start": 5313.56, "end": 5316.56, "text": " and then that's a contrastive sample, push it up.", "tokens": [50364, 1286, 760, 294, 264, 2281, 3753, 11, 370, 915, 257, 2158, 295, 288, 300, 575, 3126, 2281, 813, 264, 472, 291, 1409, 490, 11, 50864, 50864, 293, 550, 300, 311, 257, 8712, 488, 6889, 11, 2944, 309, 493, 13, 51014, 51014, 18229, 760, 322, 264, 3380, 6889, 11, 2944, 493, 322, 341, 777, 6889, 291, 445, 658, 13, 51164, 51164, 823, 341, 1062, 312, 5124, 11, 293, 428, 2281, 2445, 1062, 312, 6179, 11, 309, 815, 362, 2654, 4464, 64, 11, 51414, 51414, 370, 510, 311, 1071, 6532, 13, 440, 661, 6532, 307, 722, 490, 264, 912, 3097, 6889, 11, 51764, 51764], "temperature": 0.0, "avg_logprob": -0.11124756703009972, "compression_ratio": 1.7510373443983402, "no_speech_prob": 8.939365216065198e-06}, {"id": 952, "seek": 530356, "start": 5316.56, "end": 5319.56, "text": " Push down on the original sample, push up on this new sample you just got.", "tokens": [50364, 1286, 760, 294, 264, 2281, 3753, 11, 370, 915, 257, 2158, 295, 288, 300, 575, 3126, 2281, 813, 264, 472, 291, 1409, 490, 11, 50864, 50864, 293, 550, 300, 311, 257, 8712, 488, 6889, 11, 2944, 309, 493, 13, 51014, 51014, 18229, 760, 322, 264, 3380, 6889, 11, 2944, 493, 322, 341, 777, 6889, 291, 445, 658, 13, 51164, 51164, 823, 341, 1062, 312, 5124, 11, 293, 428, 2281, 2445, 1062, 312, 6179, 11, 309, 815, 362, 2654, 4464, 64, 11, 51414, 51414, 370, 510, 311, 1071, 6532, 13, 440, 661, 6532, 307, 722, 490, 264, 912, 3097, 6889, 11, 51764, 51764], "temperature": 0.0, "avg_logprob": -0.11124756703009972, "compression_ratio": 1.7510373443983402, "no_speech_prob": 8.939365216065198e-06}, {"id": 953, "seek": 530356, "start": 5319.56, "end": 5324.56, "text": " Now this might be expensive, and your energy function might be complicated, it may have local minima,", "tokens": [50364, 1286, 760, 294, 264, 2281, 3753, 11, 370, 915, 257, 2158, 295, 288, 300, 575, 3126, 2281, 813, 264, 472, 291, 1409, 490, 11, 50864, 50864, 293, 550, 300, 311, 257, 8712, 488, 6889, 11, 2944, 309, 493, 13, 51014, 51014, 18229, 760, 322, 264, 3380, 6889, 11, 2944, 493, 322, 341, 777, 6889, 291, 445, 658, 13, 51164, 51164, 823, 341, 1062, 312, 5124, 11, 293, 428, 2281, 2445, 1062, 312, 6179, 11, 309, 815, 362, 2654, 4464, 64, 11, 51414, 51414, 370, 510, 311, 1071, 6532, 13, 440, 661, 6532, 307, 722, 490, 264, 912, 3097, 6889, 11, 51764, 51764], "temperature": 0.0, "avg_logprob": -0.11124756703009972, "compression_ratio": 1.7510373443983402, "no_speech_prob": 8.939365216065198e-06}, {"id": 954, "seek": 530356, "start": 5324.56, "end": 5331.56, "text": " so here's another technique. The other technique is start from the same training sample,", "tokens": [50364, 1286, 760, 294, 264, 2281, 3753, 11, 370, 915, 257, 2158, 295, 288, 300, 575, 3126, 2281, 813, 264, 472, 291, 1409, 490, 11, 50864, 50864, 293, 550, 300, 311, 257, 8712, 488, 6889, 11, 2944, 309, 493, 13, 51014, 51014, 18229, 760, 322, 264, 3380, 6889, 11, 2944, 493, 322, 341, 777, 6889, 291, 445, 658, 13, 51164, 51164, 823, 341, 1062, 312, 5124, 11, 293, 428, 2281, 2445, 1062, 312, 6179, 11, 309, 815, 362, 2654, 4464, 64, 11, 51414, 51414, 370, 510, 311, 1071, 6532, 13, 440, 661, 6532, 307, 722, 490, 264, 912, 3097, 6889, 11, 51764, 51764], "temperature": 0.0, "avg_logprob": -0.11124756703009972, "compression_ratio": 1.7510373443983402, "no_speech_prob": 8.939365216065198e-06}, {"id": 955, "seek": 533156, "start": 5331.56, "end": 5343.56, "text": " and imagine that this surface is like a, you know, like a smooth mountain range,", "tokens": [50364, 293, 3811, 300, 341, 3753, 307, 411, 257, 11, 291, 458, 11, 411, 257, 5508, 6937, 3613, 11, 50964, 50964, 293, 550, 976, 257, 4974, 4437, 281, 341, 26844, 11, 519, 295, 309, 382, 257, 26844, 11, 51264, 51264, 291, 434, 516, 281, 976, 309, 257, 4974, 4437, 294, 257, 4974, 3513, 11, 51414, 51414, 293, 291, 434, 516, 281, 27817, 341, 382, 257, 26844, 9439, 760, 341, 2281, 3753, 13, 51614, 51614, 407, 718, 311, 584, 286, 478, 516, 281, 4437, 309, 294, 341, 3513, 11, 309, 311, 516, 281, 352, 294, 341, 3513, 337, 257, 1339, 11, 51814, 51814], "temperature": 0.0, "avg_logprob": -0.06745394919682475, "compression_ratio": 1.9166666666666667, "no_speech_prob": 4.6833949454594404e-05}, {"id": 956, "seek": 533156, "start": 5343.56, "end": 5349.56, "text": " and then give a random kick to this marble, think of it as a marble,", "tokens": [50364, 293, 3811, 300, 341, 3753, 307, 411, 257, 11, 291, 458, 11, 411, 257, 5508, 6937, 3613, 11, 50964, 50964, 293, 550, 976, 257, 4974, 4437, 281, 341, 26844, 11, 519, 295, 309, 382, 257, 26844, 11, 51264, 51264, 291, 434, 516, 281, 976, 309, 257, 4974, 4437, 294, 257, 4974, 3513, 11, 51414, 51414, 293, 291, 434, 516, 281, 27817, 341, 382, 257, 26844, 9439, 760, 341, 2281, 3753, 13, 51614, 51614, 407, 718, 311, 584, 286, 478, 516, 281, 4437, 309, 294, 341, 3513, 11, 309, 311, 516, 281, 352, 294, 341, 3513, 337, 257, 1339, 11, 51814, 51814], "temperature": 0.0, "avg_logprob": -0.06745394919682475, "compression_ratio": 1.9166666666666667, "no_speech_prob": 4.6833949454594404e-05}, {"id": 957, "seek": 533156, "start": 5349.56, "end": 5352.56, "text": " you're going to give it a random kick in a random direction,", "tokens": [50364, 293, 3811, 300, 341, 3753, 307, 411, 257, 11, 291, 458, 11, 411, 257, 5508, 6937, 3613, 11, 50964, 50964, 293, 550, 976, 257, 4974, 4437, 281, 341, 26844, 11, 519, 295, 309, 382, 257, 26844, 11, 51264, 51264, 291, 434, 516, 281, 976, 309, 257, 4974, 4437, 294, 257, 4974, 3513, 11, 51414, 51414, 293, 291, 434, 516, 281, 27817, 341, 382, 257, 26844, 9439, 760, 341, 2281, 3753, 13, 51614, 51614, 407, 718, 311, 584, 286, 478, 516, 281, 4437, 309, 294, 341, 3513, 11, 309, 311, 516, 281, 352, 294, 341, 3513, 337, 257, 1339, 11, 51814, 51814], "temperature": 0.0, "avg_logprob": -0.06745394919682475, "compression_ratio": 1.9166666666666667, "no_speech_prob": 4.6833949454594404e-05}, {"id": 958, "seek": 533156, "start": 5352.56, "end": 5356.56, "text": " and you're going to simulate this as a marble rolling down this energy surface.", "tokens": [50364, 293, 3811, 300, 341, 3753, 307, 411, 257, 11, 291, 458, 11, 411, 257, 5508, 6937, 3613, 11, 50964, 50964, 293, 550, 976, 257, 4974, 4437, 281, 341, 26844, 11, 519, 295, 309, 382, 257, 26844, 11, 51264, 51264, 291, 434, 516, 281, 976, 309, 257, 4974, 4437, 294, 257, 4974, 3513, 11, 51414, 51414, 293, 291, 434, 516, 281, 27817, 341, 382, 257, 26844, 9439, 760, 341, 2281, 3753, 13, 51614, 51614, 407, 718, 311, 584, 286, 478, 516, 281, 4437, 309, 294, 341, 3513, 11, 309, 311, 516, 281, 352, 294, 341, 3513, 337, 257, 1339, 11, 51814, 51814], "temperature": 0.0, "avg_logprob": -0.06745394919682475, "compression_ratio": 1.9166666666666667, "no_speech_prob": 4.6833949454594404e-05}, {"id": 959, "seek": 533156, "start": 5356.56, "end": 5360.56, "text": " So let's say I'm going to kick it in this direction, it's going to go in this direction for a while,", "tokens": [50364, 293, 3811, 300, 341, 3753, 307, 411, 257, 11, 291, 458, 11, 411, 257, 5508, 6937, 3613, 11, 50964, 50964, 293, 550, 976, 257, 4974, 4437, 281, 341, 26844, 11, 519, 295, 309, 382, 257, 26844, 11, 51264, 51264, 291, 434, 516, 281, 976, 309, 257, 4974, 4437, 294, 257, 4974, 3513, 11, 51414, 51414, 293, 291, 434, 516, 281, 27817, 341, 382, 257, 26844, 9439, 760, 341, 2281, 3753, 13, 51614, 51614, 407, 718, 311, 584, 286, 478, 516, 281, 4437, 309, 294, 341, 3513, 11, 309, 311, 516, 281, 352, 294, 341, 3513, 337, 257, 1339, 11, 51814, 51814], "temperature": 0.0, "avg_logprob": -0.06745394919682475, "compression_ratio": 1.9166666666666667, "no_speech_prob": 4.6833949454594404e-05}, {"id": 960, "seek": 536056, "start": 5360.56, "end": 5363.56, "text": " and then it's going to go down in the energy.", "tokens": [50364, 293, 550, 309, 311, 516, 281, 352, 760, 294, 264, 2281, 13, 50514, 50514, 2381, 257, 1339, 11, 1723, 309, 766, 11, 291, 483, 257, 935, 412, 264, 917, 295, 341, 21512, 11, 2944, 309, 493, 13, 50864, 50864, 1033, 11, 370, 286, 478, 884, 341, 588, 1356, 379, 11, 457, 294, 1186, 456, 366, 13, 51014, 51014, 407, 5413, 322, 577, 291, 360, 341, 11, 510, 286, 478, 13468, 264, 9156, 295, 577, 729, 7150, 589, 11, 51264, 51264, 457, 294, 1186, 11, 498, 291, 366, 3102, 294, 31959, 3142, 15983, 11, 51514, 51514, 293, 437, 291, 434, 3102, 294, 307, 884, 6674, 22119, 11, 51664, 51664], "temperature": 0.0, "avg_logprob": -0.08018667047674005, "compression_ratio": 1.6506024096385543, "no_speech_prob": 5.826195047120564e-05}, {"id": 961, "seek": 536056, "start": 5363.56, "end": 5370.56, "text": " After a while, cut it off, you get a point at the end of this trajectory, push it up.", "tokens": [50364, 293, 550, 309, 311, 516, 281, 352, 760, 294, 264, 2281, 13, 50514, 50514, 2381, 257, 1339, 11, 1723, 309, 766, 11, 291, 483, 257, 935, 412, 264, 917, 295, 341, 21512, 11, 2944, 309, 493, 13, 50864, 50864, 1033, 11, 370, 286, 478, 884, 341, 588, 1356, 379, 11, 457, 294, 1186, 456, 366, 13, 51014, 51014, 407, 5413, 322, 577, 291, 360, 341, 11, 510, 286, 478, 13468, 264, 9156, 295, 577, 729, 7150, 589, 11, 51264, 51264, 457, 294, 1186, 11, 498, 291, 366, 3102, 294, 31959, 3142, 15983, 11, 51514, 51514, 293, 437, 291, 434, 3102, 294, 307, 884, 6674, 22119, 11, 51664, 51664], "temperature": 0.0, "avg_logprob": -0.08018667047674005, "compression_ratio": 1.6506024096385543, "no_speech_prob": 5.826195047120564e-05}, {"id": 962, "seek": 536056, "start": 5370.56, "end": 5373.56, "text": " Okay, so I'm doing this very informally, but in fact there are.", "tokens": [50364, 293, 550, 309, 311, 516, 281, 352, 760, 294, 264, 2281, 13, 50514, 50514, 2381, 257, 1339, 11, 1723, 309, 766, 11, 291, 483, 257, 935, 412, 264, 917, 295, 341, 21512, 11, 2944, 309, 493, 13, 50864, 50864, 1033, 11, 370, 286, 478, 884, 341, 588, 1356, 379, 11, 457, 294, 1186, 456, 366, 13, 51014, 51014, 407, 5413, 322, 577, 291, 360, 341, 11, 510, 286, 478, 13468, 264, 9156, 295, 577, 729, 7150, 589, 11, 51264, 51264, 457, 294, 1186, 11, 498, 291, 366, 3102, 294, 31959, 3142, 15983, 11, 51514, 51514, 293, 437, 291, 434, 3102, 294, 307, 884, 6674, 22119, 11, 51664, 51664], "temperature": 0.0, "avg_logprob": -0.08018667047674005, "compression_ratio": 1.6506024096385543, "no_speech_prob": 5.826195047120564e-05}, {"id": 963, "seek": 536056, "start": 5373.56, "end": 5378.56, "text": " So depending on how you do this, here I'm explaining the principles of how those methods work,", "tokens": [50364, 293, 550, 309, 311, 516, 281, 352, 760, 294, 264, 2281, 13, 50514, 50514, 2381, 257, 1339, 11, 1723, 309, 766, 11, 291, 483, 257, 935, 412, 264, 917, 295, 341, 21512, 11, 2944, 309, 493, 13, 50864, 50864, 1033, 11, 370, 286, 478, 884, 341, 588, 1356, 379, 11, 457, 294, 1186, 456, 366, 13, 51014, 51014, 407, 5413, 322, 577, 291, 360, 341, 11, 510, 286, 478, 13468, 264, 9156, 295, 577, 729, 7150, 589, 11, 51264, 51264, 457, 294, 1186, 11, 498, 291, 366, 3102, 294, 31959, 3142, 15983, 11, 51514, 51514, 293, 437, 291, 434, 3102, 294, 307, 884, 6674, 22119, 11, 51664, 51664], "temperature": 0.0, "avg_logprob": -0.08018667047674005, "compression_ratio": 1.6506024096385543, "no_speech_prob": 5.826195047120564e-05}, {"id": 964, "seek": 536056, "start": 5378.56, "end": 5383.56, "text": " but in fact, if you are interested in probabilistic modeling,", "tokens": [50364, 293, 550, 309, 311, 516, 281, 352, 760, 294, 264, 2281, 13, 50514, 50514, 2381, 257, 1339, 11, 1723, 309, 766, 11, 291, 483, 257, 935, 412, 264, 917, 295, 341, 21512, 11, 2944, 309, 493, 13, 50864, 50864, 1033, 11, 370, 286, 478, 884, 341, 588, 1356, 379, 11, 457, 294, 1186, 456, 366, 13, 51014, 51014, 407, 5413, 322, 577, 291, 360, 341, 11, 510, 286, 478, 13468, 264, 9156, 295, 577, 729, 7150, 589, 11, 51264, 51264, 457, 294, 1186, 11, 498, 291, 366, 3102, 294, 31959, 3142, 15983, 11, 51514, 51514, 293, 437, 291, 434, 3102, 294, 307, 884, 6674, 22119, 11, 51664, 51664], "temperature": 0.0, "avg_logprob": -0.08018667047674005, "compression_ratio": 1.6506024096385543, "no_speech_prob": 5.826195047120564e-05}, {"id": 965, "seek": 536056, "start": 5383.56, "end": 5386.56, "text": " and what you're interested in is doing maximum likelihood,", "tokens": [50364, 293, 550, 309, 311, 516, 281, 352, 760, 294, 264, 2281, 13, 50514, 50514, 2381, 257, 1339, 11, 1723, 309, 766, 11, 291, 483, 257, 935, 412, 264, 917, 295, 341, 21512, 11, 2944, 309, 493, 13, 50864, 50864, 1033, 11, 370, 286, 478, 884, 341, 588, 1356, 379, 11, 457, 294, 1186, 456, 366, 13, 51014, 51014, 407, 5413, 322, 577, 291, 360, 341, 11, 510, 286, 478, 13468, 264, 9156, 295, 577, 729, 7150, 589, 11, 51264, 51264, 457, 294, 1186, 11, 498, 291, 366, 3102, 294, 31959, 3142, 15983, 11, 51514, 51514, 293, 437, 291, 434, 3102, 294, 307, 884, 6674, 22119, 11, 51664, 51664], "temperature": 0.0, "avg_logprob": -0.08018667047674005, "compression_ratio": 1.6506024096385543, "no_speech_prob": 5.826195047120564e-05}, {"id": 966, "seek": 538656, "start": 5386.56, "end": 5393.56, "text": " what you need to do is produce samples according to the probability your model gives to the samples,", "tokens": [50364, 437, 291, 643, 281, 360, 307, 5258, 10938, 4650, 281, 264, 8482, 428, 2316, 2709, 281, 264, 10938, 11, 50714, 50714, 293, 456, 311, 2098, 281, 1190, 729, 14642, 294, 1270, 257, 636, 300, 264, 8509, 295, 264, 8482, 50964, 50964, 365, 597, 291, 486, 1888, 732, 10938, 23249, 281, 264, 8509, 295, 641, 33783, 2212, 538, 264, 2316, 11, 51314, 51314, 597, 307, 439, 291, 643, 13, 51414, 51414, 400, 300, 311, 4476, 1096, 538, 11, 291, 458, 11, 264, 4365, 295, 577, 291, 4445, 729, 733, 295, 18257, 2083, 11, 51814, 51814], "temperature": 0.0, "avg_logprob": -0.06718718508879344, "compression_ratio": 1.834061135371179, "no_speech_prob": 0.0001739475119393319}, {"id": 967, "seek": 538656, "start": 5393.56, "end": 5398.56, "text": " and there's ways to run those algorithms in such a way that the ratio of the probability", "tokens": [50364, 437, 291, 643, 281, 360, 307, 5258, 10938, 4650, 281, 264, 8482, 428, 2316, 2709, 281, 264, 10938, 11, 50714, 50714, 293, 456, 311, 2098, 281, 1190, 729, 14642, 294, 1270, 257, 636, 300, 264, 8509, 295, 264, 8482, 50964, 50964, 365, 597, 291, 486, 1888, 732, 10938, 23249, 281, 264, 8509, 295, 641, 33783, 2212, 538, 264, 2316, 11, 51314, 51314, 597, 307, 439, 291, 643, 13, 51414, 51414, 400, 300, 311, 4476, 1096, 538, 11, 291, 458, 11, 264, 4365, 295, 577, 291, 4445, 729, 733, 295, 18257, 2083, 11, 51814, 51814], "temperature": 0.0, "avg_logprob": -0.06718718508879344, "compression_ratio": 1.834061135371179, "no_speech_prob": 0.0001739475119393319}, {"id": 968, "seek": 538656, "start": 5398.56, "end": 5405.56, "text": " with which you will pick two samples corresponds to the ratio of their probabilities given by the model,", "tokens": [50364, 437, 291, 643, 281, 360, 307, 5258, 10938, 4650, 281, 264, 8482, 428, 2316, 2709, 281, 264, 10938, 11, 50714, 50714, 293, 456, 311, 2098, 281, 1190, 729, 14642, 294, 1270, 257, 636, 300, 264, 8509, 295, 264, 8482, 50964, 50964, 365, 597, 291, 486, 1888, 732, 10938, 23249, 281, 264, 8509, 295, 641, 33783, 2212, 538, 264, 2316, 11, 51314, 51314, 597, 307, 439, 291, 643, 13, 51414, 51414, 400, 300, 311, 4476, 1096, 538, 11, 291, 458, 11, 264, 4365, 295, 577, 291, 4445, 729, 733, 295, 18257, 2083, 11, 51814, 51814], "temperature": 0.0, "avg_logprob": -0.06718718508879344, "compression_ratio": 1.834061135371179, "no_speech_prob": 0.0001739475119393319}, {"id": 969, "seek": 538656, "start": 5405.56, "end": 5407.56, "text": " which is all you need.", "tokens": [50364, 437, 291, 643, 281, 360, 307, 5258, 10938, 4650, 281, 264, 8482, 428, 2316, 2709, 281, 264, 10938, 11, 50714, 50714, 293, 456, 311, 2098, 281, 1190, 729, 14642, 294, 1270, 257, 636, 300, 264, 8509, 295, 264, 8482, 50964, 50964, 365, 597, 291, 486, 1888, 732, 10938, 23249, 281, 264, 8509, 295, 641, 33783, 2212, 538, 264, 2316, 11, 51314, 51314, 597, 307, 439, 291, 643, 13, 51414, 51414, 400, 300, 311, 4476, 1096, 538, 11, 291, 458, 11, 264, 4365, 295, 577, 291, 4445, 729, 733, 295, 18257, 2083, 11, 51814, 51814], "temperature": 0.0, "avg_logprob": -0.06718718508879344, "compression_ratio": 1.834061135371179, "no_speech_prob": 0.0001739475119393319}, {"id": 970, "seek": 538656, "start": 5407.56, "end": 5415.56, "text": " And that's essentially done by, you know, the details of how you implement those kind of trajectories,", "tokens": [50364, 437, 291, 643, 281, 360, 307, 5258, 10938, 4650, 281, 264, 8482, 428, 2316, 2709, 281, 264, 10938, 11, 50714, 50714, 293, 456, 311, 2098, 281, 1190, 729, 14642, 294, 1270, 257, 636, 300, 264, 8509, 295, 264, 8482, 50964, 50964, 365, 597, 291, 486, 1888, 732, 10938, 23249, 281, 264, 8509, 295, 641, 33783, 2212, 538, 264, 2316, 11, 51314, 51314, 597, 307, 439, 291, 643, 13, 51414, 51414, 400, 300, 311, 4476, 1096, 538, 11, 291, 458, 11, 264, 4365, 295, 577, 291, 4445, 729, 733, 295, 18257, 2083, 11, 51814, 51814], "temperature": 0.0, "avg_logprob": -0.06718718508879344, "compression_ratio": 1.834061135371179, "no_speech_prob": 0.0001739475119393319}, {"id": 971, "seek": 541556, "start": 5415.56, "end": 5418.56, "text": " basically, and like the noise that you use to...", "tokens": [50364, 1936, 11, 293, 411, 264, 5658, 300, 291, 764, 281, 485, 50514, 50514, 407, 11, 1392, 11, 370, 718, 385, 976, 291, 5288, 337, 341, 13, 50664, 50664, 1033, 11, 264, 4974, 572, 3436, 23249, 281, 364, 9284, 1219, 1441, 78, 3436, 8399, 22660, 19866, 13, 51264, 51264, 400, 28327, 78, 307, 516, 281, 980, 291, 544, 466, 341, 13, 51464, 51464], "temperature": 0.0, "avg_logprob": -0.16949348151683807, "compression_ratio": 1.4580645161290322, "no_speech_prob": 4.681529026129283e-05}, {"id": 972, "seek": 541556, "start": 5418.56, "end": 5421.56, "text": " So, okay, so let me give you names for this.", "tokens": [50364, 1936, 11, 293, 411, 264, 5658, 300, 291, 764, 281, 485, 50514, 50514, 407, 11, 1392, 11, 370, 718, 385, 976, 291, 5288, 337, 341, 13, 50664, 50664, 1033, 11, 264, 4974, 572, 3436, 23249, 281, 364, 9284, 1219, 1441, 78, 3436, 8399, 22660, 19866, 13, 51264, 51264, 400, 28327, 78, 307, 516, 281, 980, 291, 544, 466, 341, 13, 51464, 51464], "temperature": 0.0, "avg_logprob": -0.16949348151683807, "compression_ratio": 1.4580645161290322, "no_speech_prob": 4.681529026129283e-05}, {"id": 973, "seek": 541556, "start": 5421.56, "end": 5433.56, "text": " Okay, the random noising corresponds to an algorithm called denoising autoencoder.", "tokens": [50364, 1936, 11, 293, 411, 264, 5658, 300, 291, 764, 281, 485, 50514, 50514, 407, 11, 1392, 11, 370, 718, 385, 976, 291, 5288, 337, 341, 13, 50664, 50664, 1033, 11, 264, 4974, 572, 3436, 23249, 281, 364, 9284, 1219, 1441, 78, 3436, 8399, 22660, 19866, 13, 51264, 51264, 400, 28327, 78, 307, 516, 281, 980, 291, 544, 466, 341, 13, 51464, 51464], "temperature": 0.0, "avg_logprob": -0.16949348151683807, "compression_ratio": 1.4580645161290322, "no_speech_prob": 4.681529026129283e-05}, {"id": 974, "seek": 541556, "start": 5433.56, "end": 5437.56, "text": " And Alfredo is going to tell you more about this.", "tokens": [50364, 1936, 11, 293, 411, 264, 5658, 300, 291, 764, 281, 485, 50514, 50514, 407, 11, 1392, 11, 370, 718, 385, 976, 291, 5288, 337, 341, 13, 50664, 50664, 1033, 11, 264, 4974, 572, 3436, 23249, 281, 364, 9284, 1219, 1441, 78, 3436, 8399, 22660, 19866, 13, 51264, 51264, 400, 28327, 78, 307, 516, 281, 980, 291, 544, 466, 341, 13, 51464, 51464], "temperature": 0.0, "avg_logprob": -0.16949348151683807, "compression_ratio": 1.4580645161290322, "no_speech_prob": 4.681529026129283e-05}, {"id": 975, "seek": 543756, "start": 5437.56, "end": 5448.56, "text": " The gradient descent and random kick versions, the random kick,", "tokens": [50364, 440, 16235, 23475, 293, 4974, 4437, 9606, 11, 264, 4974, 4437, 11, 50914, 50914, 300, 311, 1219, 8712, 488, 47387, 11, 293, 456, 366, 257, 1254, 295, 341, 337, 485, 51414, 51414, 400, 498, 291, 360, 257, 3164, 807, 264, 1901, 538, 733, 295, 4974, 40468, 763, 11, 51664, 51664], "temperature": 0.0, "avg_logprob": -0.11893507150503305, "compression_ratio": 1.4452054794520548, "no_speech_prob": 2.586195114417933e-05}, {"id": 976, "seek": 543756, "start": 5448.56, "end": 5458.56, "text": " that's called contrastive divergence, and there are a form of this for...", "tokens": [50364, 440, 16235, 23475, 293, 4974, 4437, 9606, 11, 264, 4974, 4437, 11, 50914, 50914, 300, 311, 1219, 8712, 488, 47387, 11, 293, 456, 366, 257, 1254, 295, 341, 337, 485, 51414, 51414, 400, 498, 291, 360, 257, 3164, 807, 264, 1901, 538, 733, 295, 4974, 40468, 763, 11, 51664, 51664], "temperature": 0.0, "avg_logprob": -0.11893507150503305, "compression_ratio": 1.4452054794520548, "no_speech_prob": 2.586195114417933e-05}, {"id": 977, "seek": 543756, "start": 5458.56, "end": 5463.56, "text": " And if you do a search through the space by kind of random perturbations,", "tokens": [50364, 440, 16235, 23475, 293, 4974, 4437, 9606, 11, 264, 4974, 4437, 11, 50914, 50914, 300, 311, 1219, 8712, 488, 47387, 11, 293, 456, 366, 257, 1254, 295, 341, 337, 485, 51414, 51414, 400, 498, 291, 360, 257, 3164, 807, 264, 1901, 538, 733, 295, 4974, 40468, 763, 11, 51664, 51664], "temperature": 0.0, "avg_logprob": -0.11893507150503305, "compression_ratio": 1.4452054794520548, "no_speech_prob": 2.586195114417933e-05}, {"id": 978, "seek": 546356, "start": 5463.56, "end": 5475.56, "text": " sort of trying to find low energy space with noise, it's a special case of Monte Carlo methods.", "tokens": [50364, 1333, 295, 1382, 281, 915, 2295, 2281, 1901, 365, 5658, 11, 309, 311, 257, 2121, 1389, 295, 38105, 45112, 7150, 13, 50964, 50964, 400, 498, 309, 311, 257, 10957, 21512, 11, 406, 257, 10957, 11, 457, 498, 309, 311, 257, 21512, 11, 51214, 51214, 309, 727, 312, 27706, 11, 309, 311, 1219, 3934, 5179, 5021, 38105, 45112, 7150, 11, 420, 8797, 39261, 13, 51764, 51764], "temperature": 0.0, "avg_logprob": -0.1075761567300825, "compression_ratio": 1.6217948717948718, "no_speech_prob": 4.975789852323942e-05}, {"id": 979, "seek": 546356, "start": 5475.56, "end": 5480.56, "text": " And if it's a continuous trajectory, not a continuous, but if it's a trajectory,", "tokens": [50364, 1333, 295, 1382, 281, 915, 2295, 2281, 1901, 365, 5658, 11, 309, 311, 257, 2121, 1389, 295, 38105, 45112, 7150, 13, 50964, 50964, 400, 498, 309, 311, 257, 10957, 21512, 11, 406, 257, 10957, 11, 457, 498, 309, 311, 257, 21512, 11, 51214, 51214, 309, 727, 312, 27706, 11, 309, 311, 1219, 3934, 5179, 5021, 38105, 45112, 7150, 11, 420, 8797, 39261, 13, 51764, 51764], "temperature": 0.0, "avg_logprob": -0.1075761567300825, "compression_ratio": 1.6217948717948718, "no_speech_prob": 4.975789852323942e-05}, {"id": 980, "seek": 546356, "start": 5480.56, "end": 5491.56, "text": " it could be discrete, it's called Markov chain Monte Carlo methods, or MCMC.", "tokens": [50364, 1333, 295, 1382, 281, 915, 2295, 2281, 1901, 365, 5658, 11, 309, 311, 257, 2121, 1389, 295, 38105, 45112, 7150, 13, 50964, 50964, 400, 498, 309, 311, 257, 10957, 21512, 11, 406, 257, 10957, 11, 457, 498, 309, 311, 257, 21512, 11, 51214, 51214, 309, 727, 312, 27706, 11, 309, 311, 1219, 3934, 5179, 5021, 38105, 45112, 7150, 11, 420, 8797, 39261, 13, 51764, 51764], "temperature": 0.0, "avg_logprob": -0.1075761567300825, "compression_ratio": 1.6217948717948718, "no_speech_prob": 4.975789852323942e-05}, {"id": 981, "seek": 549156, "start": 5491.56, "end": 5500.56, "text": " And if it's in a continuous space where you use kind of this rolling ball with a random kick method,", "tokens": [50364, 400, 498, 309, 311, 294, 257, 10957, 1901, 689, 291, 764, 733, 295, 341, 9439, 2594, 365, 257, 4974, 4437, 3170, 11, 50814, 50814, 300, 311, 1219, 18484, 952, 38105, 45112, 13, 51164, 51164, 389, 45, 34, 11, 456, 311, 257, 1168, 13, 883, 30, 1033, 13, 51664, 51664], "temperature": 0.0, "avg_logprob": -0.12460920857448204, "compression_ratio": 1.2608695652173914, "no_speech_prob": 1.6696591046638787e-05}, {"id": 982, "seek": 549156, "start": 5500.56, "end": 5507.56, "text": " that's called Hamiltonian Monte Carlo.", "tokens": [50364, 400, 498, 309, 311, 294, 257, 10957, 1901, 689, 291, 764, 733, 295, 341, 9439, 2594, 365, 257, 4974, 4437, 3170, 11, 50814, 50814, 300, 311, 1219, 18484, 952, 38105, 45112, 13, 51164, 51164, 389, 45, 34, 11, 456, 311, 257, 1168, 13, 883, 30, 1033, 13, 51664, 51664], "temperature": 0.0, "avg_logprob": -0.12460920857448204, "compression_ratio": 1.2608695652173914, "no_speech_prob": 1.6696591046638787e-05}, {"id": 983, "seek": 549156, "start": 5507.56, "end": 5517.56, "text": " HNC, there's a question. No? Okay.", "tokens": [50364, 400, 498, 309, 311, 294, 257, 10957, 1901, 689, 291, 764, 733, 295, 341, 9439, 2594, 365, 257, 4974, 4437, 3170, 11, 50814, 50814, 300, 311, 1219, 18484, 952, 38105, 45112, 13, 51164, 51164, 389, 45, 34, 11, 456, 311, 257, 1168, 13, 883, 30, 1033, 13, 51664, 51664], "temperature": 0.0, "avg_logprob": -0.12460920857448204, "compression_ratio": 1.2608695652173914, "no_speech_prob": 1.6696591046638787e-05}, {"id": 984, "seek": 551756, "start": 5517.56, "end": 5524.56, "text": " Well, the time is late, let me just talk about denoising autoencoder.", "tokens": [50364, 1042, 11, 264, 565, 307, 3469, 11, 718, 385, 445, 751, 466, 1441, 78, 3436, 8399, 22660, 19866, 13, 50714, 50714, 407, 437, 311, 257, 1441, 78, 3436, 8399, 22660, 19866, 30, 50814, 50814, 467, 311, 257, 1729, 2010, 295, 2281, 12, 6032, 2316, 689, 291, 722, 365, 257, 398, 11, 370, 291, 787, 362, 398, 82, 13, 51514, 51514], "temperature": 0.0, "avg_logprob": -0.17684255107756583, "compression_ratio": 1.410071942446043, "no_speech_prob": 1.668476761551574e-05}, {"id": 985, "seek": 551756, "start": 5524.56, "end": 5526.56, "text": " So what's a denoising autoencoder?", "tokens": [50364, 1042, 11, 264, 565, 307, 3469, 11, 718, 385, 445, 751, 466, 1441, 78, 3436, 8399, 22660, 19866, 13, 50714, 50714, 407, 437, 311, 257, 1441, 78, 3436, 8399, 22660, 19866, 30, 50814, 50814, 467, 311, 257, 1729, 2010, 295, 2281, 12, 6032, 2316, 689, 291, 722, 365, 257, 398, 11, 370, 291, 787, 362, 398, 82, 13, 51514, 51514], "temperature": 0.0, "avg_logprob": -0.17684255107756583, "compression_ratio": 1.410071942446043, "no_speech_prob": 1.668476761551574e-05}, {"id": 986, "seek": 551756, "start": 5526.56, "end": 5540.56, "text": " It's a particular type of energy-based model where you start with a Y, so you only have Ys.", "tokens": [50364, 1042, 11, 264, 565, 307, 3469, 11, 718, 385, 445, 751, 466, 1441, 78, 3436, 8399, 22660, 19866, 13, 50714, 50714, 407, 437, 311, 257, 1441, 78, 3436, 8399, 22660, 19866, 30, 50814, 50814, 467, 311, 257, 1729, 2010, 295, 2281, 12, 6032, 2316, 689, 291, 722, 365, 257, 398, 11, 370, 291, 787, 362, 398, 82, 13, 51514, 51514], "temperature": 0.0, "avg_logprob": -0.17684255107756583, "compression_ratio": 1.410071942446043, "no_speech_prob": 1.668476761551574e-05}, {"id": 987, "seek": 554056, "start": 5540.56, "end": 5556.56, "text": " So you start with Y, you correct it, so this is the little diagram that I showed earlier, you correct the sample, okay?", "tokens": [50364, 407, 291, 722, 365, 398, 11, 291, 3006, 309, 11, 370, 341, 307, 264, 707, 10686, 300, 286, 4712, 3071, 11, 291, 3006, 264, 6889, 11, 1392, 30, 51164, 51164, 509, 483, 1071, 6889, 300, 286, 478, 406, 516, 281, 818, 11, 293, 291, 1320, 341, 807, 364, 2058, 19866, 11, 51564, 51564], "temperature": 0.0, "avg_logprob": -0.1460908369584517, "compression_ratio": 1.475177304964539, "no_speech_prob": 3.500520051602507e-06}, {"id": 988, "seek": 554056, "start": 5556.56, "end": 5564.56, "text": " You get another sample that I'm not going to call, and you pass this through an encoder,", "tokens": [50364, 407, 291, 722, 365, 398, 11, 291, 3006, 309, 11, 370, 341, 307, 264, 707, 10686, 300, 286, 4712, 3071, 11, 291, 3006, 264, 6889, 11, 1392, 30, 51164, 51164, 509, 483, 1071, 6889, 300, 286, 478, 406, 516, 281, 818, 11, 293, 291, 1320, 341, 807, 364, 2058, 19866, 11, 51564, 51564], "temperature": 0.0, "avg_logprob": -0.1460908369584517, "compression_ratio": 1.475177304964539, "no_speech_prob": 3.500520051602507e-06}, {"id": 989, "seek": 556456, "start": 5564.56, "end": 5573.56, "text": " which is a neural net, and a decoder, which is another neural net, and then you compare the output,", "tokens": [50364, 597, 307, 257, 18161, 2533, 11, 293, 257, 979, 19866, 11, 597, 307, 1071, 18161, 2533, 11, 293, 550, 291, 6794, 264, 5598, 11, 50814, 50814, 597, 307, 257, 31565, 337, 398, 11, 365, 398, 13, 51264, 51264, 639, 307, 445, 294, 264, 13735, 1254, 11, 341, 307, 264, 4560, 1296, 398, 293, 398, 2159, 8889, 13, 51664, 51664], "temperature": 0.0, "avg_logprob": -0.10420871171794954, "compression_ratio": 1.5586206896551724, "no_speech_prob": 6.959300662856549e-06}, {"id": 990, "seek": 556456, "start": 5573.56, "end": 5582.56, "text": " which is a reconstruction for Y, with Y.", "tokens": [50364, 597, 307, 257, 18161, 2533, 11, 293, 257, 979, 19866, 11, 597, 307, 1071, 18161, 2533, 11, 293, 550, 291, 6794, 264, 5598, 11, 50814, 50814, 597, 307, 257, 31565, 337, 398, 11, 365, 398, 13, 51264, 51264, 639, 307, 445, 294, 264, 13735, 1254, 11, 341, 307, 264, 4560, 1296, 398, 293, 398, 2159, 8889, 13, 51664, 51664], "temperature": 0.0, "avg_logprob": -0.10420871171794954, "compression_ratio": 1.5586206896551724, "no_speech_prob": 6.959300662856549e-06}, {"id": 991, "seek": 556456, "start": 5582.56, "end": 5590.56, "text": " This is just in the classical form, this is the distance between Y and Y bar squared.", "tokens": [50364, 597, 307, 257, 18161, 2533, 11, 293, 257, 979, 19866, 11, 597, 307, 1071, 18161, 2533, 11, 293, 550, 291, 6794, 264, 5598, 11, 50814, 50814, 597, 307, 257, 31565, 337, 398, 11, 365, 398, 13, 51264, 51264, 639, 307, 445, 294, 264, 13735, 1254, 11, 341, 307, 264, 4560, 1296, 398, 293, 398, 2159, 8889, 13, 51664, 51664], "temperature": 0.0, "avg_logprob": -0.10420871171794954, "compression_ratio": 1.5586206896551724, "no_speech_prob": 6.959300662856549e-06}, {"id": 992, "seek": 559056, "start": 5590.56, "end": 5596.56, "text": " And you see here, the network on the left is just some neural net that you train.", "tokens": [50364, 400, 291, 536, 510, 11, 264, 3209, 322, 264, 1411, 307, 445, 512, 18161, 2533, 300, 291, 3847, 13, 50664, 50664, 440, 17959, 307, 3094, 538, 1011, 11, 309, 311, 406, 8895, 13, 50964, 50964, 407, 437, 775, 300, 360, 337, 291, 30, 51214, 51214, 639, 767, 21020, 484, 264, 2281, 295, 39480, 2793, 13, 51514, 51514], "temperature": 0.0, "avg_logprob": -0.11239541587183031, "compression_ratio": 1.4407894736842106, "no_speech_prob": 1.5205588169919793e-05}, {"id": 993, "seek": 559056, "start": 5596.56, "end": 5602.56, "text": " The corruption is built by hand, it's not trained.", "tokens": [50364, 400, 291, 536, 510, 11, 264, 3209, 322, 264, 1411, 307, 445, 512, 18161, 2533, 300, 291, 3847, 13, 50664, 50664, 440, 17959, 307, 3094, 538, 1011, 11, 309, 311, 406, 8895, 13, 50964, 50964, 407, 437, 775, 300, 360, 337, 291, 30, 51214, 51214, 639, 767, 21020, 484, 264, 2281, 295, 39480, 2793, 13, 51514, 51514], "temperature": 0.0, "avg_logprob": -0.11239541587183031, "compression_ratio": 1.4407894736842106, "no_speech_prob": 1.5205588169919793e-05}, {"id": 994, "seek": 559056, "start": 5602.56, "end": 5607.56, "text": " So what does that do for you?", "tokens": [50364, 400, 291, 536, 510, 11, 264, 3209, 322, 264, 1411, 307, 445, 512, 18161, 2533, 300, 291, 3847, 13, 50664, 50664, 440, 17959, 307, 3094, 538, 1011, 11, 309, 311, 406, 8895, 13, 50964, 50964, 407, 437, 775, 300, 360, 337, 291, 30, 51214, 51214, 639, 767, 21020, 484, 264, 2281, 295, 39480, 2793, 13, 51514, 51514], "temperature": 0.0, "avg_logprob": -0.11239541587183031, "compression_ratio": 1.4407894736842106, "no_speech_prob": 1.5205588169919793e-05}, {"id": 995, "seek": 559056, "start": 5607.56, "end": 5613.56, "text": " This actually pushes out the energy of corrupted points.", "tokens": [50364, 400, 291, 536, 510, 11, 264, 3209, 322, 264, 1411, 307, 445, 512, 18161, 2533, 300, 291, 3847, 13, 50664, 50664, 440, 17959, 307, 3094, 538, 1011, 11, 309, 311, 406, 8895, 13, 50964, 50964, 407, 437, 775, 300, 360, 337, 291, 30, 51214, 51214, 639, 767, 21020, 484, 264, 2281, 295, 39480, 2793, 13, 51514, 51514], "temperature": 0.0, "avg_logprob": -0.11239541587183031, "compression_ratio": 1.4407894736842106, "no_speech_prob": 1.5205588169919793e-05}, {"id": 996, "seek": 561356, "start": 5613.56, "end": 5623.56, "text": " So here the energy is, so this is how you train the system, but the actual system doesn't have the corruption.", "tokens": [50364, 407, 510, 264, 2281, 307, 11, 370, 341, 307, 577, 291, 3847, 264, 1185, 11, 457, 264, 3539, 1185, 1177, 380, 362, 264, 17959, 13, 50864, 50864, 509, 976, 309, 257, 398, 11, 291, 1190, 309, 807, 264, 2058, 19866, 293, 264, 979, 19866, 11, 293, 3481, 264, 31565, 6713, 13, 51464, 51464], "temperature": 0.0, "avg_logprob": -0.0953266750682484, "compression_ratio": 1.5214285714285714, "no_speech_prob": 1.2605277333932463e-05}, {"id": 997, "seek": 561356, "start": 5623.56, "end": 5635.56, "text": " You give it a Y, you run it through the encoder and the decoder, and measure the reconstruction error.", "tokens": [50364, 407, 510, 264, 2281, 307, 11, 370, 341, 307, 577, 291, 3847, 264, 1185, 11, 457, 264, 3539, 1185, 1177, 380, 362, 264, 17959, 13, 50864, 50864, 509, 976, 309, 257, 398, 11, 291, 1190, 309, 807, 264, 2058, 19866, 293, 264, 979, 19866, 11, 293, 3481, 264, 31565, 6713, 13, 51464, 51464], "temperature": 0.0, "avg_logprob": -0.0953266750682484, "compression_ratio": 1.5214285714285714, "no_speech_prob": 1.2605277333932463e-05}, {"id": 998, "seek": 563556, "start": 5635.56, "end": 5647.56, "text": " Okay, so it's exactly the same diagram, except no corruption. So the corruption is for training.", "tokens": [50364, 1033, 11, 370, 309, 311, 2293, 264, 912, 10686, 11, 3993, 572, 17959, 13, 407, 264, 17959, 307, 337, 3097, 13, 50964, 50964, 400, 341, 307, 577, 291, 764, 309, 13, 51164, 51164, 1033, 11, 437, 775, 300, 360, 337, 291, 30, 509, 362, 1901, 295, 398, 11, 291, 362, 1412, 2793, 13, 51664, 51664], "temperature": 0.0, "avg_logprob": -0.10226833611203913, "compression_ratio": 1.3793103448275863, "no_speech_prob": 2.3547143428004347e-05}, {"id": 999, "seek": 563556, "start": 5647.56, "end": 5651.56, "text": " And this is how you use it.", "tokens": [50364, 1033, 11, 370, 309, 311, 2293, 264, 912, 10686, 11, 3993, 572, 17959, 13, 407, 264, 17959, 307, 337, 3097, 13, 50964, 50964, 400, 341, 307, 577, 291, 764, 309, 13, 51164, 51164, 1033, 11, 437, 775, 300, 360, 337, 291, 30, 509, 362, 1901, 295, 398, 11, 291, 362, 1412, 2793, 13, 51664, 51664], "temperature": 0.0, "avg_logprob": -0.10226833611203913, "compression_ratio": 1.3793103448275863, "no_speech_prob": 2.3547143428004347e-05}, {"id": 1000, "seek": 563556, "start": 5651.56, "end": 5661.56, "text": " Okay, what does that do for you? You have space of Y, you have data points.", "tokens": [50364, 1033, 11, 370, 309, 311, 2293, 264, 912, 10686, 11, 3993, 572, 17959, 13, 407, 264, 17959, 307, 337, 3097, 13, 50964, 50964, 400, 341, 307, 577, 291, 764, 309, 13, 51164, 51164, 1033, 11, 437, 775, 300, 360, 337, 291, 30, 509, 362, 1901, 295, 398, 11, 291, 362, 1412, 2793, 13, 51664, 51664], "temperature": 0.0, "avg_logprob": -0.10226833611203913, "compression_ratio": 1.3793103448275863, "no_speech_prob": 2.3547143428004347e-05}, {"id": 1001, "seek": 566156, "start": 5661.56, "end": 5669.56, "text": " Take a point Y and corrupt it.", "tokens": [50364, 3664, 257, 935, 398, 293, 17366, 309, 13, 50764, 50764, 400, 586, 291, 3847, 341, 18161, 2533, 11, 341, 2058, 19866, 12, 42821, 19866, 11, 281, 1936, 31499, 341, 39480, 935, 51264, 51264, 490, 264, 39480, 935, 281, 5258, 264, 3380, 935, 11, 264, 3380, 3097, 935, 13, 51564, 51564], "temperature": 0.0, "avg_logprob": -0.10359626549940842, "compression_ratio": 1.626865671641791, "no_speech_prob": 1.4283833479566965e-05}, {"id": 1002, "seek": 566156, "start": 5669.56, "end": 5679.56, "text": " And now you train this neural net, this encoder-decoder, to basically reconstruct this corrupted point", "tokens": [50364, 3664, 257, 935, 398, 293, 17366, 309, 13, 50764, 50764, 400, 586, 291, 3847, 341, 18161, 2533, 11, 341, 2058, 19866, 12, 42821, 19866, 11, 281, 1936, 31499, 341, 39480, 935, 51264, 51264, 490, 264, 39480, 935, 281, 5258, 264, 3380, 935, 11, 264, 3380, 3097, 935, 13, 51564, 51564], "temperature": 0.0, "avg_logprob": -0.10359626549940842, "compression_ratio": 1.626865671641791, "no_speech_prob": 1.4283833479566965e-05}, {"id": 1003, "seek": 566156, "start": 5679.56, "end": 5685.56, "text": " from the corrupted point to produce the original point, the original training point.", "tokens": [50364, 3664, 257, 935, 398, 293, 17366, 309, 13, 50764, 50764, 400, 586, 291, 3847, 341, 18161, 2533, 11, 341, 2058, 19866, 12, 42821, 19866, 11, 281, 1936, 31499, 341, 39480, 935, 51264, 51264, 490, 264, 39480, 935, 281, 5258, 264, 3380, 935, 11, 264, 3380, 3097, 935, 13, 51564, 51564], "temperature": 0.0, "avg_logprob": -0.10359626549940842, "compression_ratio": 1.626865671641791, "no_speech_prob": 1.4283833479566965e-05}, {"id": 1004, "seek": 568556, "start": 5685.56, "end": 5695.56, "text": " So the neural net function is going to map this point to that point.", "tokens": [50364, 407, 264, 18161, 2533, 2445, 307, 516, 281, 4471, 341, 935, 281, 300, 935, 13, 50864, 50864, 1033, 30, 51014, 51014, 708, 775, 300, 914, 30, 663, 1355, 562, 291, 5452, 257, 8062, 510, 398, 11, 293, 291, 360, 341, 337, 633, 3097, 6889, 293, 257, 2416, 1230, 295, 17366, 626, 13, 51514, 51514], "temperature": 0.0, "avg_logprob": -0.12110227346420288, "compression_ratio": 1.4172185430463575, "no_speech_prob": 9.515221790934447e-06}, {"id": 1005, "seek": 568556, "start": 5695.56, "end": 5698.56, "text": " Okay?", "tokens": [50364, 407, 264, 18161, 2533, 2445, 307, 516, 281, 4471, 341, 935, 281, 300, 935, 13, 50864, 50864, 1033, 30, 51014, 51014, 708, 775, 300, 914, 30, 663, 1355, 562, 291, 5452, 257, 8062, 510, 398, 11, 293, 291, 360, 341, 337, 633, 3097, 6889, 293, 257, 2416, 1230, 295, 17366, 626, 13, 51514, 51514], "temperature": 0.0, "avg_logprob": -0.12110227346420288, "compression_ratio": 1.4172185430463575, "no_speech_prob": 9.515221790934447e-06}, {"id": 1006, "seek": 568556, "start": 5698.56, "end": 5708.56, "text": " What does that mean? That means when you plug a vector here Y, and you do this for every training sample and a large number of corruptions.", "tokens": [50364, 407, 264, 18161, 2533, 2445, 307, 516, 281, 4471, 341, 935, 281, 300, 935, 13, 50864, 50864, 1033, 30, 51014, 51014, 708, 775, 300, 914, 30, 663, 1355, 562, 291, 5452, 257, 8062, 510, 398, 11, 293, 291, 360, 341, 337, 633, 3097, 6889, 293, 257, 2416, 1230, 295, 17366, 626, 13, 51514, 51514], "temperature": 0.0, "avg_logprob": -0.12110227346420288, "compression_ratio": 1.4172185430463575, "no_speech_prob": 9.515221790934447e-06}, {"id": 1007, "seek": 570856, "start": 5708.56, "end": 5717.56, "text": " Okay? What it means is that when you plug a point Y here on the input, and you measure its energy, which is a reconstruction error,", "tokens": [50364, 1033, 30, 708, 309, 1355, 307, 300, 562, 291, 5452, 257, 935, 398, 510, 322, 264, 4846, 11, 293, 291, 3481, 1080, 2281, 11, 597, 307, 257, 31565, 6713, 11, 50814, 50814, 341, 935, 11, 498, 309, 311, 322, 264, 47138, 11, 498, 309, 311, 322, 264, 47138, 295, 1412, 11, 307, 516, 281, 312, 31499, 292, 382, 2564, 13, 51164, 51164, 7504, 11, 1080, 2281, 510, 11, 597, 307, 257, 31565, 6713, 11, 486, 312, 4018, 13, 51414, 51414, 1033, 30, 759, 309, 311, 8895, 6108, 13, 51564, 51564], "temperature": 0.0, "avg_logprob": -0.1122280100117559, "compression_ratio": 1.766497461928934, "no_speech_prob": 2.014370147662703e-05}, {"id": 1008, "seek": 570856, "start": 5717.56, "end": 5724.56, "text": " this point, if it's on the manifold, if it's on the manifold of data, is going to be reconstructed as itself.", "tokens": [50364, 1033, 30, 708, 309, 1355, 307, 300, 562, 291, 5452, 257, 935, 398, 510, 322, 264, 4846, 11, 293, 291, 3481, 1080, 2281, 11, 597, 307, 257, 31565, 6713, 11, 50814, 50814, 341, 935, 11, 498, 309, 311, 322, 264, 47138, 11, 498, 309, 311, 322, 264, 47138, 295, 1412, 11, 307, 516, 281, 312, 31499, 292, 382, 2564, 13, 51164, 51164, 7504, 11, 1080, 2281, 510, 11, 597, 307, 257, 31565, 6713, 11, 486, 312, 4018, 13, 51414, 51414, 1033, 30, 759, 309, 311, 8895, 6108, 13, 51564, 51564], "temperature": 0.0, "avg_logprob": -0.1122280100117559, "compression_ratio": 1.766497461928934, "no_speech_prob": 2.014370147662703e-05}, {"id": 1009, "seek": 570856, "start": 5724.56, "end": 5729.56, "text": " Therefore, its energy here, which is a reconstruction error, will be zero.", "tokens": [50364, 1033, 30, 708, 309, 1355, 307, 300, 562, 291, 5452, 257, 935, 398, 510, 322, 264, 4846, 11, 293, 291, 3481, 1080, 2281, 11, 597, 307, 257, 31565, 6713, 11, 50814, 50814, 341, 935, 11, 498, 309, 311, 322, 264, 47138, 11, 498, 309, 311, 322, 264, 47138, 295, 1412, 11, 307, 516, 281, 312, 31499, 292, 382, 2564, 13, 51164, 51164, 7504, 11, 1080, 2281, 510, 11, 597, 307, 257, 31565, 6713, 11, 486, 312, 4018, 13, 51414, 51414, 1033, 30, 759, 309, 311, 8895, 6108, 13, 51564, 51564], "temperature": 0.0, "avg_logprob": -0.1122280100117559, "compression_ratio": 1.766497461928934, "no_speech_prob": 2.014370147662703e-05}, {"id": 1010, "seek": 570856, "start": 5729.56, "end": 5732.56, "text": " Okay? If it's trained properly.", "tokens": [50364, 1033, 30, 708, 309, 1355, 307, 300, 562, 291, 5452, 257, 935, 398, 510, 322, 264, 4846, 11, 293, 291, 3481, 1080, 2281, 11, 597, 307, 257, 31565, 6713, 11, 50814, 50814, 341, 935, 11, 498, 309, 311, 322, 264, 47138, 11, 498, 309, 311, 322, 264, 47138, 295, 1412, 11, 307, 516, 281, 312, 31499, 292, 382, 2564, 13, 51164, 51164, 7504, 11, 1080, 2281, 510, 11, 597, 307, 257, 31565, 6713, 11, 486, 312, 4018, 13, 51414, 51414, 1033, 30, 759, 309, 311, 8895, 6108, 13, 51564, 51564], "temperature": 0.0, "avg_logprob": -0.1122280100117559, "compression_ratio": 1.766497461928934, "no_speech_prob": 2.014370147662703e-05}, {"id": 1011, "seek": 573256, "start": 5732.56, "end": 5744.56, "text": " Because if you put on the input a point that is outside the manifold, it's going to get reconstructed as the closest point on the manifold,", "tokens": [50364, 1436, 498, 291, 829, 322, 264, 4846, 257, 935, 300, 307, 2380, 264, 47138, 11, 309, 311, 516, 281, 483, 31499, 292, 382, 264, 13699, 935, 322, 264, 47138, 11, 50964, 50964, 570, 309, 311, 668, 8895, 281, 360, 300, 13, 51114, 51114, 7504, 11, 264, 31565, 6713, 510, 486, 312, 341, 4560, 13, 51414, 51414], "temperature": 0.0, "avg_logprob": -0.0805888504817568, "compression_ratio": 1.5751633986928104, "no_speech_prob": 1.4283567907114048e-05}, {"id": 1012, "seek": 573256, "start": 5744.56, "end": 5747.56, "text": " because it's been trained to do that.", "tokens": [50364, 1436, 498, 291, 829, 322, 264, 4846, 257, 935, 300, 307, 2380, 264, 47138, 11, 309, 311, 516, 281, 483, 31499, 292, 382, 264, 13699, 935, 322, 264, 47138, 11, 50964, 50964, 570, 309, 311, 668, 8895, 281, 360, 300, 13, 51114, 51114, 7504, 11, 264, 31565, 6713, 510, 486, 312, 341, 4560, 13, 51414, 51414], "temperature": 0.0, "avg_logprob": -0.0805888504817568, "compression_ratio": 1.5751633986928104, "no_speech_prob": 1.4283567907114048e-05}, {"id": 1013, "seek": 573256, "start": 5747.56, "end": 5753.56, "text": " Therefore, the reconstruction error here will be this distance.", "tokens": [50364, 1436, 498, 291, 829, 322, 264, 4846, 257, 935, 300, 307, 2380, 264, 47138, 11, 309, 311, 516, 281, 483, 31499, 292, 382, 264, 13699, 935, 322, 264, 47138, 11, 50964, 50964, 570, 309, 311, 668, 8895, 281, 360, 300, 13, 51114, 51114, 7504, 11, 264, 31565, 6713, 510, 486, 312, 341, 4560, 13, 51414, 51414], "temperature": 0.0, "avg_logprob": -0.0805888504817568, "compression_ratio": 1.5751633986928104, "no_speech_prob": 1.4283567907114048e-05}, {"id": 1014, "seek": 575356, "start": 5753.56, "end": 5769.56, "text": " Okay? What that means is now that the energy computed by this denousi-autoencoder is such that it grows quadratically as you move away from the manifold of data,", "tokens": [50364, 1033, 30, 708, 300, 1355, 307, 586, 300, 264, 2281, 40610, 538, 341, 1441, 563, 72, 12, 41988, 22660, 19866, 307, 1270, 300, 309, 13156, 10787, 4481, 984, 382, 291, 1286, 1314, 490, 264, 47138, 295, 1412, 11, 51164, 51164, 498, 264, 551, 307, 6108, 8895, 13, 51314, 51314, 1033, 30, 51414, 51414], "temperature": 0.0, "avg_logprob": -0.1515236247669567, "compression_ratio": 1.3767123287671232, "no_speech_prob": 4.936546247336082e-06}, {"id": 1015, "seek": 575356, "start": 5769.56, "end": 5772.56, "text": " if the thing is properly trained.", "tokens": [50364, 1033, 30, 708, 300, 1355, 307, 586, 300, 264, 2281, 40610, 538, 341, 1441, 563, 72, 12, 41988, 22660, 19866, 307, 1270, 300, 309, 13156, 10787, 4481, 984, 382, 291, 1286, 1314, 490, 264, 47138, 295, 1412, 11, 51164, 51164, 498, 264, 551, 307, 6108, 8895, 13, 51314, 51314, 1033, 30, 51414, 51414], "temperature": 0.0, "avg_logprob": -0.1515236247669567, "compression_ratio": 1.3767123287671232, "no_speech_prob": 4.936546247336082e-06}, {"id": 1016, "seek": 575356, "start": 5772.56, "end": 5774.56, "text": " Okay?", "tokens": [50364, 1033, 30, 708, 300, 1355, 307, 586, 300, 264, 2281, 40610, 538, 341, 1441, 563, 72, 12, 41988, 22660, 19866, 307, 1270, 300, 309, 13156, 10787, 4481, 984, 382, 291, 1286, 1314, 490, 264, 47138, 295, 1412, 11, 51164, 51164, 498, 264, 551, 307, 6108, 8895, 13, 51314, 51314, 1033, 30, 51414, 51414], "temperature": 0.0, "avg_logprob": -0.1515236247669567, "compression_ratio": 1.3767123287671232, "no_speech_prob": 4.936546247336082e-06}, {"id": 1017, "seek": 577456, "start": 5774.56, "end": 5786.56, "text": " So that's an example of contrastive methods, because you say on the manifold things should be zero, the reconstruction energy should be zero.", "tokens": [50364, 407, 300, 311, 364, 1365, 295, 8712, 488, 7150, 11, 570, 291, 584, 322, 264, 47138, 721, 820, 312, 4018, 11, 264, 31565, 2281, 820, 312, 4018, 13, 50964, 50964, 28218, 264, 47138, 11, 264, 31565, 2281, 820, 312, 264, 4560, 281, 264, 47138, 13, 51214, 51214, 1033, 30, 51314, 51314, 639, 307, 363, 31479, 13, 407, 363, 31479, 307, 8895, 341, 636, 11, 3993, 264, 1901, 307, 27706, 11, 1673, 2512, 31927, 831, 11, 570, 309, 311, 2487, 13, 51764, 51764], "temperature": 0.0, "avg_logprob": -0.09263514337085542, "compression_ratio": 1.7107843137254901, "no_speech_prob": 8.39663243823452e-06}, {"id": 1018, "seek": 577456, "start": 5786.56, "end": 5791.56, "text": " Outside the manifold, the reconstruction energy should be the distance to the manifold.", "tokens": [50364, 407, 300, 311, 364, 1365, 295, 8712, 488, 7150, 11, 570, 291, 584, 322, 264, 47138, 721, 820, 312, 4018, 11, 264, 31565, 2281, 820, 312, 4018, 13, 50964, 50964, 28218, 264, 47138, 11, 264, 31565, 2281, 820, 312, 264, 4560, 281, 264, 47138, 13, 51214, 51214, 1033, 30, 51314, 51314, 639, 307, 363, 31479, 13, 407, 363, 31479, 307, 8895, 341, 636, 11, 3993, 264, 1901, 307, 27706, 11, 1673, 2512, 31927, 831, 11, 570, 309, 311, 2487, 13, 51764, 51764], "temperature": 0.0, "avg_logprob": -0.09263514337085542, "compression_ratio": 1.7107843137254901, "no_speech_prob": 8.39663243823452e-06}, {"id": 1019, "seek": 577456, "start": 5791.56, "end": 5793.56, "text": " Okay?", "tokens": [50364, 407, 300, 311, 364, 1365, 295, 8712, 488, 7150, 11, 570, 291, 584, 322, 264, 47138, 721, 820, 312, 4018, 11, 264, 31565, 2281, 820, 312, 4018, 13, 50964, 50964, 28218, 264, 47138, 11, 264, 31565, 2281, 820, 312, 264, 4560, 281, 264, 47138, 13, 51214, 51214, 1033, 30, 51314, 51314, 639, 307, 363, 31479, 13, 407, 363, 31479, 307, 8895, 341, 636, 11, 3993, 264, 1901, 307, 27706, 11, 1673, 2512, 31927, 831, 11, 570, 309, 311, 2487, 13, 51764, 51764], "temperature": 0.0, "avg_logprob": -0.09263514337085542, "compression_ratio": 1.7107843137254901, "no_speech_prob": 8.39663243823452e-06}, {"id": 1020, "seek": 577456, "start": 5793.56, "end": 5802.56, "text": " This is BERT. So BERT is trained this way, except the space is discrete, though combinatorial, because it's text.", "tokens": [50364, 407, 300, 311, 364, 1365, 295, 8712, 488, 7150, 11, 570, 291, 584, 322, 264, 47138, 721, 820, 312, 4018, 11, 264, 31565, 2281, 820, 312, 4018, 13, 50964, 50964, 28218, 264, 47138, 11, 264, 31565, 2281, 820, 312, 264, 4560, 281, 264, 47138, 13, 51214, 51214, 1033, 30, 51314, 51314, 639, 307, 363, 31479, 13, 407, 363, 31479, 307, 8895, 341, 636, 11, 3993, 264, 1901, 307, 27706, 11, 1673, 2512, 31927, 831, 11, 570, 309, 311, 2487, 13, 51764, 51764], "temperature": 0.0, "avg_logprob": -0.09263514337085542, "compression_ratio": 1.7107843137254901, "no_speech_prob": 8.39663243823452e-06}, {"id": 1021, "seek": 580256, "start": 5802.56, "end": 5809.56, "text": " And the corruption technique consists in masking some of the words.", "tokens": [50364, 400, 264, 17959, 6532, 14689, 294, 31226, 512, 295, 264, 2283, 13, 50714, 50714, 400, 550, 264, 31565, 14689, 294, 32884, 264, 2283, 300, 366, 5361, 13, 50864, 50864, 509, 393, 1009, 5055, 264, 2283, 300, 366, 406, 5361, 11, 370, 291, 500, 380, 643, 281, 360, 309, 13, 51064, 51064, 1033, 30, 51114, 51114, 407, 309, 311, 257, 2121, 1389, 295, 1441, 563, 72, 12, 41988, 22660, 19866, 13, 51264, 51264, 467, 311, 767, 1219, 257, 45249, 8399, 22660, 19866, 11, 570, 264, 2010, 295, 17959, 291, 360, 307, 31226, 3755, 295, 264, 4846, 13, 51814, 51814], "temperature": 0.0, "avg_logprob": -0.05593109607696533, "compression_ratio": 1.75, "no_speech_prob": 3.7622237869072706e-05}, {"id": 1022, "seek": 580256, "start": 5809.56, "end": 5812.56, "text": " And then the reconstruction consists in predicting the words that are missing.", "tokens": [50364, 400, 264, 17959, 6532, 14689, 294, 31226, 512, 295, 264, 2283, 13, 50714, 50714, 400, 550, 264, 31565, 14689, 294, 32884, 264, 2283, 300, 366, 5361, 13, 50864, 50864, 509, 393, 1009, 5055, 264, 2283, 300, 366, 406, 5361, 11, 370, 291, 500, 380, 643, 281, 360, 309, 13, 51064, 51064, 1033, 30, 51114, 51114, 407, 309, 311, 257, 2121, 1389, 295, 1441, 563, 72, 12, 41988, 22660, 19866, 13, 51264, 51264, 467, 311, 767, 1219, 257, 45249, 8399, 22660, 19866, 11, 570, 264, 2010, 295, 17959, 291, 360, 307, 31226, 3755, 295, 264, 4846, 13, 51814, 51814], "temperature": 0.0, "avg_logprob": -0.05593109607696533, "compression_ratio": 1.75, "no_speech_prob": 3.7622237869072706e-05}, {"id": 1023, "seek": 580256, "start": 5812.56, "end": 5816.56, "text": " You can always copy the words that are not missing, so you don't need to do it.", "tokens": [50364, 400, 264, 17959, 6532, 14689, 294, 31226, 512, 295, 264, 2283, 13, 50714, 50714, 400, 550, 264, 31565, 14689, 294, 32884, 264, 2283, 300, 366, 5361, 13, 50864, 50864, 509, 393, 1009, 5055, 264, 2283, 300, 366, 406, 5361, 11, 370, 291, 500, 380, 643, 281, 360, 309, 13, 51064, 51064, 1033, 30, 51114, 51114, 407, 309, 311, 257, 2121, 1389, 295, 1441, 563, 72, 12, 41988, 22660, 19866, 13, 51264, 51264, 467, 311, 767, 1219, 257, 45249, 8399, 22660, 19866, 11, 570, 264, 2010, 295, 17959, 291, 360, 307, 31226, 3755, 295, 264, 4846, 13, 51814, 51814], "temperature": 0.0, "avg_logprob": -0.05593109607696533, "compression_ratio": 1.75, "no_speech_prob": 3.7622237869072706e-05}, {"id": 1024, "seek": 580256, "start": 5816.56, "end": 5817.56, "text": " Okay?", "tokens": [50364, 400, 264, 17959, 6532, 14689, 294, 31226, 512, 295, 264, 2283, 13, 50714, 50714, 400, 550, 264, 31565, 14689, 294, 32884, 264, 2283, 300, 366, 5361, 13, 50864, 50864, 509, 393, 1009, 5055, 264, 2283, 300, 366, 406, 5361, 11, 370, 291, 500, 380, 643, 281, 360, 309, 13, 51064, 51064, 1033, 30, 51114, 51114, 407, 309, 311, 257, 2121, 1389, 295, 1441, 563, 72, 12, 41988, 22660, 19866, 13, 51264, 51264, 467, 311, 767, 1219, 257, 45249, 8399, 22660, 19866, 11, 570, 264, 2010, 295, 17959, 291, 360, 307, 31226, 3755, 295, 264, 4846, 13, 51814, 51814], "temperature": 0.0, "avg_logprob": -0.05593109607696533, "compression_ratio": 1.75, "no_speech_prob": 3.7622237869072706e-05}, {"id": 1025, "seek": 580256, "start": 5817.56, "end": 5820.56, "text": " So it's a special case of denousi-autoencoder.", "tokens": [50364, 400, 264, 17959, 6532, 14689, 294, 31226, 512, 295, 264, 2283, 13, 50714, 50714, 400, 550, 264, 31565, 14689, 294, 32884, 264, 2283, 300, 366, 5361, 13, 50864, 50864, 509, 393, 1009, 5055, 264, 2283, 300, 366, 406, 5361, 11, 370, 291, 500, 380, 643, 281, 360, 309, 13, 51064, 51064, 1033, 30, 51114, 51114, 407, 309, 311, 257, 2121, 1389, 295, 1441, 563, 72, 12, 41988, 22660, 19866, 13, 51264, 51264, 467, 311, 767, 1219, 257, 45249, 8399, 22660, 19866, 11, 570, 264, 2010, 295, 17959, 291, 360, 307, 31226, 3755, 295, 264, 4846, 13, 51814, 51814], "temperature": 0.0, "avg_logprob": -0.05593109607696533, "compression_ratio": 1.75, "no_speech_prob": 3.7622237869072706e-05}, {"id": 1026, "seek": 580256, "start": 5820.56, "end": 5831.56, "text": " It's actually called a masked autoencoder, because the type of corruption you do is masking pieces of the input.", "tokens": [50364, 400, 264, 17959, 6532, 14689, 294, 31226, 512, 295, 264, 2283, 13, 50714, 50714, 400, 550, 264, 31565, 14689, 294, 32884, 264, 2283, 300, 366, 5361, 13, 50864, 50864, 509, 393, 1009, 5055, 264, 2283, 300, 366, 406, 5361, 11, 370, 291, 500, 380, 643, 281, 360, 309, 13, 51064, 51064, 1033, 30, 51114, 51114, 407, 309, 311, 257, 2121, 1389, 295, 1441, 563, 72, 12, 41988, 22660, 19866, 13, 51264, 51264, 467, 311, 767, 1219, 257, 45249, 8399, 22660, 19866, 11, 570, 264, 2010, 295, 17959, 291, 360, 307, 31226, 3755, 295, 264, 4846, 13, 51814, 51814], "temperature": 0.0, "avg_logprob": -0.05593109607696533, "compression_ratio": 1.75, "no_speech_prob": 3.7622237869072706e-05}, {"id": 1027, "seek": 583156, "start": 5831.56, "end": 5833.56, "text": " Okay?", "tokens": [50364, 1033, 30, 50464, 50464, 1057, 558, 13, 5925, 295, 565, 11, 321, 603, 751, 466, 544, 295, 729, 7512, 958, 565, 13, 50714], "temperature": 0.0, "avg_logprob": -0.13932550430297852, "compression_ratio": 1.025, "no_speech_prob": 0.0002565680188126862}, {"id": 1028, "seek": 583356, "start": 5833.56, "end": 5862.56, "text": " All right. Out of time, we'll talk about more of those techniques next time.", "tokens": [50364, 1057, 558, 13, 5925, 295, 565, 11, 321, 603, 751, 466, 544, 295, 729, 7512, 958, 565, 13, 51814], "temperature": 0.0, "avg_logprob": -0.09075916948772612, "compression_ratio": 1.0133333333333334, "no_speech_prob": 0.0015177569584921002}], "language": "en", "video_id": "tVwV14YkbYs", "entity": "Yann LeCun"}}