{"video_id": "jdjGdT_jR50", "title": "5.1 Neural Network Training | TensorFlow implementation --[Machine Learning | Andrew Ng]", "description": "Second Course:\nAdvanced Learning Algorithms.\n\n\nIf you liked the content please subscribe and put a little blue thumb.\nTake heart!", "author": "Machine Learning", "keywords": [], "channel_url": "https://www.youtube.com/channel/UClG5HEAJJFOavT_UolqYROQ", "length": 217, "views": 151, "publish_date": "11/04/2022", "timestamp": 1661817600, "entity": "ML Specialization, Andrew Ng (2022)", "transcript": {"text": " Welcome back to the second week of this course on advanced learning algorithms. Last week you learned how to carry out inference in a neural network. This week we're going to go over training of a neural network. I think being able to take your own data and train your own neural network on it is really fun. This week we'll look at how you could do that. Let's dive in. Let's continue with our running example of handwritten digit recognition, recognizing this image as 0 or a 1. And here we're using the neural network architecture that you saw last week, where you have an input x that is the image, and then the first hidden layer with 25 units, second hidden layer with 15 units, and then one output unit. If you are given a training set of examples comprising images x as well as the ground truth label y, how would you train the parameters of this neural network? Let me go ahead and show you the code that you can use in TensorFlow to train this network. And then in the next few videos after this, we'll dive into details to explain what the code is actually doing. So this is the code you would write. This first part may look familiar from the previous week, where you are asking TensorFlow to sequentially string together these three layers of a neural network, the first hidden layer with 25 units and sig 1 activation, the second hidden layer, and then finally the output layer. So nothing new here relative to what you saw last week. Second step is you have to ask TensorFlow to compile the model. And the key step in asking TensorFlow to compile the model is to specify what is the loss function you want to use. In this case, we'll use something that goes by the arcane name of sparse categorical cross entropy. We'll say more in the next video what this really is. And then having specified the loss function, the third step is to call the fit function, which tells TensorFlow to fit the model that you specified in step one. Using the loss of the cost function that you specified in step two to the data set x, y. And back in the first course, when we talked about gradient descent, we had to decide how many steps to run gradient descent or how long to run gradient descent. So epochs is a technical term for how many steps of learning algorithm like gradient descent you may want to run. And that's it. Step one is to specify the model, which tells TensorFlow how to compute for the inference. Step two compiles the model using a specific loss function. And step three is to train the model. So that's how you can train a neural network in TensorFlow. As usual, I hope that you'll be able to not just call these lines of code to train the model, but that you also understand what's actually going on behind these lines of code. So you don't just call it without really understanding what's going on. And I think this is important because when you're running a learning algorithm, if it doesn't work initially, having that conceptual mental framework of what's really going on will help you debug whenever things don't work the way you expect. So with that, let's go on to the next video, where we'll dive more deeply into what these steps in the TensorFlow implementation are actually doing. I'll see you in the next video.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 7.640000000000001, "text": " Welcome back to the second week of this course on advanced learning algorithms.", "tokens": [50364, 4027, 646, 281, 264, 1150, 1243, 295, 341, 1164, 322, 7339, 2539, 14642, 13, 50746, 50746, 5264, 1243, 291, 3264, 577, 281, 3985, 484, 38253, 294, 257, 18161, 3209, 13, 50952, 50952, 639, 1243, 321, 434, 516, 281, 352, 670, 3097, 295, 257, 18161, 3209, 13, 51152, 51152, 286, 519, 885, 1075, 281, 747, 428, 1065, 1412, 293, 3847, 428, 1065, 18161, 3209, 322, 309, 307, 534, 51404, 51404, 1019, 13, 51454, 51454, 639, 1243, 321, 603, 574, 412, 577, 291, 727, 360, 300, 13, 51576, 51576, 961, 311, 9192, 294, 13, 51626, 51626], "temperature": 0.0, "avg_logprob": -0.13069332639376322, "compression_ratio": 1.712962962962963, "no_speech_prob": 0.031117094680666924}, {"id": 1, "seek": 0, "start": 7.640000000000001, "end": 11.76, "text": " Last week you learned how to carry out inference in a neural network.", "tokens": [50364, 4027, 646, 281, 264, 1150, 1243, 295, 341, 1164, 322, 7339, 2539, 14642, 13, 50746, 50746, 5264, 1243, 291, 3264, 577, 281, 3985, 484, 38253, 294, 257, 18161, 3209, 13, 50952, 50952, 639, 1243, 321, 434, 516, 281, 352, 670, 3097, 295, 257, 18161, 3209, 13, 51152, 51152, 286, 519, 885, 1075, 281, 747, 428, 1065, 1412, 293, 3847, 428, 1065, 18161, 3209, 322, 309, 307, 534, 51404, 51404, 1019, 13, 51454, 51454, 639, 1243, 321, 603, 574, 412, 577, 291, 727, 360, 300, 13, 51576, 51576, 961, 311, 9192, 294, 13, 51626, 51626], "temperature": 0.0, "avg_logprob": -0.13069332639376322, "compression_ratio": 1.712962962962963, "no_speech_prob": 0.031117094680666924}, {"id": 2, "seek": 0, "start": 11.76, "end": 15.76, "text": " This week we're going to go over training of a neural network.", "tokens": [50364, 4027, 646, 281, 264, 1150, 1243, 295, 341, 1164, 322, 7339, 2539, 14642, 13, 50746, 50746, 5264, 1243, 291, 3264, 577, 281, 3985, 484, 38253, 294, 257, 18161, 3209, 13, 50952, 50952, 639, 1243, 321, 434, 516, 281, 352, 670, 3097, 295, 257, 18161, 3209, 13, 51152, 51152, 286, 519, 885, 1075, 281, 747, 428, 1065, 1412, 293, 3847, 428, 1065, 18161, 3209, 322, 309, 307, 534, 51404, 51404, 1019, 13, 51454, 51454, 639, 1243, 321, 603, 574, 412, 577, 291, 727, 360, 300, 13, 51576, 51576, 961, 311, 9192, 294, 13, 51626, 51626], "temperature": 0.0, "avg_logprob": -0.13069332639376322, "compression_ratio": 1.712962962962963, "no_speech_prob": 0.031117094680666924}, {"id": 3, "seek": 0, "start": 15.76, "end": 20.8, "text": " I think being able to take your own data and train your own neural network on it is really", "tokens": [50364, 4027, 646, 281, 264, 1150, 1243, 295, 341, 1164, 322, 7339, 2539, 14642, 13, 50746, 50746, 5264, 1243, 291, 3264, 577, 281, 3985, 484, 38253, 294, 257, 18161, 3209, 13, 50952, 50952, 639, 1243, 321, 434, 516, 281, 352, 670, 3097, 295, 257, 18161, 3209, 13, 51152, 51152, 286, 519, 885, 1075, 281, 747, 428, 1065, 1412, 293, 3847, 428, 1065, 18161, 3209, 322, 309, 307, 534, 51404, 51404, 1019, 13, 51454, 51454, 639, 1243, 321, 603, 574, 412, 577, 291, 727, 360, 300, 13, 51576, 51576, 961, 311, 9192, 294, 13, 51626, 51626], "temperature": 0.0, "avg_logprob": -0.13069332639376322, "compression_ratio": 1.712962962962963, "no_speech_prob": 0.031117094680666924}, {"id": 4, "seek": 0, "start": 20.8, "end": 21.8, "text": " fun.", "tokens": [50364, 4027, 646, 281, 264, 1150, 1243, 295, 341, 1164, 322, 7339, 2539, 14642, 13, 50746, 50746, 5264, 1243, 291, 3264, 577, 281, 3985, 484, 38253, 294, 257, 18161, 3209, 13, 50952, 50952, 639, 1243, 321, 434, 516, 281, 352, 670, 3097, 295, 257, 18161, 3209, 13, 51152, 51152, 286, 519, 885, 1075, 281, 747, 428, 1065, 1412, 293, 3847, 428, 1065, 18161, 3209, 322, 309, 307, 534, 51404, 51404, 1019, 13, 51454, 51454, 639, 1243, 321, 603, 574, 412, 577, 291, 727, 360, 300, 13, 51576, 51576, 961, 311, 9192, 294, 13, 51626, 51626], "temperature": 0.0, "avg_logprob": -0.13069332639376322, "compression_ratio": 1.712962962962963, "no_speech_prob": 0.031117094680666924}, {"id": 5, "seek": 0, "start": 21.8, "end": 24.240000000000002, "text": " This week we'll look at how you could do that.", "tokens": [50364, 4027, 646, 281, 264, 1150, 1243, 295, 341, 1164, 322, 7339, 2539, 14642, 13, 50746, 50746, 5264, 1243, 291, 3264, 577, 281, 3985, 484, 38253, 294, 257, 18161, 3209, 13, 50952, 50952, 639, 1243, 321, 434, 516, 281, 352, 670, 3097, 295, 257, 18161, 3209, 13, 51152, 51152, 286, 519, 885, 1075, 281, 747, 428, 1065, 1412, 293, 3847, 428, 1065, 18161, 3209, 322, 309, 307, 534, 51404, 51404, 1019, 13, 51454, 51454, 639, 1243, 321, 603, 574, 412, 577, 291, 727, 360, 300, 13, 51576, 51576, 961, 311, 9192, 294, 13, 51626, 51626], "temperature": 0.0, "avg_logprob": -0.13069332639376322, "compression_ratio": 1.712962962962963, "no_speech_prob": 0.031117094680666924}, {"id": 6, "seek": 0, "start": 24.240000000000002, "end": 25.240000000000002, "text": " Let's dive in.", "tokens": [50364, 4027, 646, 281, 264, 1150, 1243, 295, 341, 1164, 322, 7339, 2539, 14642, 13, 50746, 50746, 5264, 1243, 291, 3264, 577, 281, 3985, 484, 38253, 294, 257, 18161, 3209, 13, 50952, 50952, 639, 1243, 321, 434, 516, 281, 352, 670, 3097, 295, 257, 18161, 3209, 13, 51152, 51152, 286, 519, 885, 1075, 281, 747, 428, 1065, 1412, 293, 3847, 428, 1065, 18161, 3209, 322, 309, 307, 534, 51404, 51404, 1019, 13, 51454, 51454, 639, 1243, 321, 603, 574, 412, 577, 291, 727, 360, 300, 13, 51576, 51576, 961, 311, 9192, 294, 13, 51626, 51626], "temperature": 0.0, "avg_logprob": -0.13069332639376322, "compression_ratio": 1.712962962962963, "no_speech_prob": 0.031117094680666924}, {"id": 7, "seek": 2524, "start": 25.24, "end": 31.64, "text": " Let's continue with our running example of handwritten digit recognition, recognizing", "tokens": [50364, 961, 311, 2354, 365, 527, 2614, 1365, 295, 1011, 26859, 14293, 11150, 11, 18538, 50684, 50684, 341, 3256, 382, 1958, 420, 257, 502, 13, 50840, 50840, 400, 510, 321, 434, 1228, 264, 18161, 3209, 9482, 300, 291, 1866, 1036, 1243, 11, 689, 291, 362, 364, 51104, 51104, 4846, 2031, 300, 307, 264, 3256, 11, 293, 550, 264, 700, 7633, 4583, 365, 3552, 6815, 11, 1150, 7633, 51428, 51428, 4583, 365, 2119, 6815, 11, 293, 550, 472, 5598, 4985, 13, 51649, 51649], "temperature": 0.0, "avg_logprob": -0.1538623442132789, "compression_ratio": 1.6066350710900474, "no_speech_prob": 1.2803896424884442e-05}, {"id": 8, "seek": 2524, "start": 31.64, "end": 34.76, "text": " this image as 0 or a 1.", "tokens": [50364, 961, 311, 2354, 365, 527, 2614, 1365, 295, 1011, 26859, 14293, 11150, 11, 18538, 50684, 50684, 341, 3256, 382, 1958, 420, 257, 502, 13, 50840, 50840, 400, 510, 321, 434, 1228, 264, 18161, 3209, 9482, 300, 291, 1866, 1036, 1243, 11, 689, 291, 362, 364, 51104, 51104, 4846, 2031, 300, 307, 264, 3256, 11, 293, 550, 264, 700, 7633, 4583, 365, 3552, 6815, 11, 1150, 7633, 51428, 51428, 4583, 365, 2119, 6815, 11, 293, 550, 472, 5598, 4985, 13, 51649, 51649], "temperature": 0.0, "avg_logprob": -0.1538623442132789, "compression_ratio": 1.6066350710900474, "no_speech_prob": 1.2803896424884442e-05}, {"id": 9, "seek": 2524, "start": 34.76, "end": 40.04, "text": " And here we're using the neural network architecture that you saw last week, where you have an", "tokens": [50364, 961, 311, 2354, 365, 527, 2614, 1365, 295, 1011, 26859, 14293, 11150, 11, 18538, 50684, 50684, 341, 3256, 382, 1958, 420, 257, 502, 13, 50840, 50840, 400, 510, 321, 434, 1228, 264, 18161, 3209, 9482, 300, 291, 1866, 1036, 1243, 11, 689, 291, 362, 364, 51104, 51104, 4846, 2031, 300, 307, 264, 3256, 11, 293, 550, 264, 700, 7633, 4583, 365, 3552, 6815, 11, 1150, 7633, 51428, 51428, 4583, 365, 2119, 6815, 11, 293, 550, 472, 5598, 4985, 13, 51649, 51649], "temperature": 0.0, "avg_logprob": -0.1538623442132789, "compression_ratio": 1.6066350710900474, "no_speech_prob": 1.2803896424884442e-05}, {"id": 10, "seek": 2524, "start": 40.04, "end": 46.519999999999996, "text": " input x that is the image, and then the first hidden layer with 25 units, second hidden", "tokens": [50364, 961, 311, 2354, 365, 527, 2614, 1365, 295, 1011, 26859, 14293, 11150, 11, 18538, 50684, 50684, 341, 3256, 382, 1958, 420, 257, 502, 13, 50840, 50840, 400, 510, 321, 434, 1228, 264, 18161, 3209, 9482, 300, 291, 1866, 1036, 1243, 11, 689, 291, 362, 364, 51104, 51104, 4846, 2031, 300, 307, 264, 3256, 11, 293, 550, 264, 700, 7633, 4583, 365, 3552, 6815, 11, 1150, 7633, 51428, 51428, 4583, 365, 2119, 6815, 11, 293, 550, 472, 5598, 4985, 13, 51649, 51649], "temperature": 0.0, "avg_logprob": -0.1538623442132789, "compression_ratio": 1.6066350710900474, "no_speech_prob": 1.2803896424884442e-05}, {"id": 11, "seek": 2524, "start": 46.519999999999996, "end": 50.94, "text": " layer with 15 units, and then one output unit.", "tokens": [50364, 961, 311, 2354, 365, 527, 2614, 1365, 295, 1011, 26859, 14293, 11150, 11, 18538, 50684, 50684, 341, 3256, 382, 1958, 420, 257, 502, 13, 50840, 50840, 400, 510, 321, 434, 1228, 264, 18161, 3209, 9482, 300, 291, 1866, 1036, 1243, 11, 689, 291, 362, 364, 51104, 51104, 4846, 2031, 300, 307, 264, 3256, 11, 293, 550, 264, 700, 7633, 4583, 365, 3552, 6815, 11, 1150, 7633, 51428, 51428, 4583, 365, 2119, 6815, 11, 293, 550, 472, 5598, 4985, 13, 51649, 51649], "temperature": 0.0, "avg_logprob": -0.1538623442132789, "compression_ratio": 1.6066350710900474, "no_speech_prob": 1.2803896424884442e-05}, {"id": 12, "seek": 5094, "start": 50.94, "end": 56.72, "text": " If you are given a training set of examples comprising images x as well as the ground", "tokens": [50364, 759, 291, 366, 2212, 257, 3097, 992, 295, 5110, 16802, 3436, 5267, 2031, 382, 731, 382, 264, 2727, 50653, 50653, 3494, 7645, 288, 11, 577, 576, 291, 3847, 264, 9834, 295, 341, 18161, 3209, 30, 50923, 50923, 961, 385, 352, 2286, 293, 855, 291, 264, 3089, 300, 291, 393, 764, 294, 37624, 281, 3847, 341, 3209, 13, 51193, 51193, 400, 550, 294, 264, 958, 1326, 2145, 934, 341, 11, 321, 603, 9192, 666, 4365, 281, 2903, 437, 264, 51383, 51383, 3089, 307, 767, 884, 13, 51501, 51501, 407, 341, 307, 264, 3089, 291, 576, 2464, 13, 51595, 51595], "temperature": 0.0, "avg_logprob": -0.11304539680480957, "compression_ratio": 1.6194331983805668, "no_speech_prob": 1.4284648386819754e-05}, {"id": 13, "seek": 5094, "start": 56.72, "end": 62.12, "text": " truth label y, how would you train the parameters of this neural network?", "tokens": [50364, 759, 291, 366, 2212, 257, 3097, 992, 295, 5110, 16802, 3436, 5267, 2031, 382, 731, 382, 264, 2727, 50653, 50653, 3494, 7645, 288, 11, 577, 576, 291, 3847, 264, 9834, 295, 341, 18161, 3209, 30, 50923, 50923, 961, 385, 352, 2286, 293, 855, 291, 264, 3089, 300, 291, 393, 764, 294, 37624, 281, 3847, 341, 3209, 13, 51193, 51193, 400, 550, 294, 264, 958, 1326, 2145, 934, 341, 11, 321, 603, 9192, 666, 4365, 281, 2903, 437, 264, 51383, 51383, 3089, 307, 767, 884, 13, 51501, 51501, 407, 341, 307, 264, 3089, 291, 576, 2464, 13, 51595, 51595], "temperature": 0.0, "avg_logprob": -0.11304539680480957, "compression_ratio": 1.6194331983805668, "no_speech_prob": 1.4284648386819754e-05}, {"id": 14, "seek": 5094, "start": 62.12, "end": 67.52, "text": " Let me go ahead and show you the code that you can use in TensorFlow to train this network.", "tokens": [50364, 759, 291, 366, 2212, 257, 3097, 992, 295, 5110, 16802, 3436, 5267, 2031, 382, 731, 382, 264, 2727, 50653, 50653, 3494, 7645, 288, 11, 577, 576, 291, 3847, 264, 9834, 295, 341, 18161, 3209, 30, 50923, 50923, 961, 385, 352, 2286, 293, 855, 291, 264, 3089, 300, 291, 393, 764, 294, 37624, 281, 3847, 341, 3209, 13, 51193, 51193, 400, 550, 294, 264, 958, 1326, 2145, 934, 341, 11, 321, 603, 9192, 666, 4365, 281, 2903, 437, 264, 51383, 51383, 3089, 307, 767, 884, 13, 51501, 51501, 407, 341, 307, 264, 3089, 291, 576, 2464, 13, 51595, 51595], "temperature": 0.0, "avg_logprob": -0.11304539680480957, "compression_ratio": 1.6194331983805668, "no_speech_prob": 1.4284648386819754e-05}, {"id": 15, "seek": 5094, "start": 67.52, "end": 71.32, "text": " And then in the next few videos after this, we'll dive into details to explain what the", "tokens": [50364, 759, 291, 366, 2212, 257, 3097, 992, 295, 5110, 16802, 3436, 5267, 2031, 382, 731, 382, 264, 2727, 50653, 50653, 3494, 7645, 288, 11, 577, 576, 291, 3847, 264, 9834, 295, 341, 18161, 3209, 30, 50923, 50923, 961, 385, 352, 2286, 293, 855, 291, 264, 3089, 300, 291, 393, 764, 294, 37624, 281, 3847, 341, 3209, 13, 51193, 51193, 400, 550, 294, 264, 958, 1326, 2145, 934, 341, 11, 321, 603, 9192, 666, 4365, 281, 2903, 437, 264, 51383, 51383, 3089, 307, 767, 884, 13, 51501, 51501, 407, 341, 307, 264, 3089, 291, 576, 2464, 13, 51595, 51595], "temperature": 0.0, "avg_logprob": -0.11304539680480957, "compression_ratio": 1.6194331983805668, "no_speech_prob": 1.4284648386819754e-05}, {"id": 16, "seek": 5094, "start": 71.32, "end": 73.68, "text": " code is actually doing.", "tokens": [50364, 759, 291, 366, 2212, 257, 3097, 992, 295, 5110, 16802, 3436, 5267, 2031, 382, 731, 382, 264, 2727, 50653, 50653, 3494, 7645, 288, 11, 577, 576, 291, 3847, 264, 9834, 295, 341, 18161, 3209, 30, 50923, 50923, 961, 385, 352, 2286, 293, 855, 291, 264, 3089, 300, 291, 393, 764, 294, 37624, 281, 3847, 341, 3209, 13, 51193, 51193, 400, 550, 294, 264, 958, 1326, 2145, 934, 341, 11, 321, 603, 9192, 666, 4365, 281, 2903, 437, 264, 51383, 51383, 3089, 307, 767, 884, 13, 51501, 51501, 407, 341, 307, 264, 3089, 291, 576, 2464, 13, 51595, 51595], "temperature": 0.0, "avg_logprob": -0.11304539680480957, "compression_ratio": 1.6194331983805668, "no_speech_prob": 1.4284648386819754e-05}, {"id": 17, "seek": 5094, "start": 73.68, "end": 75.56, "text": " So this is the code you would write.", "tokens": [50364, 759, 291, 366, 2212, 257, 3097, 992, 295, 5110, 16802, 3436, 5267, 2031, 382, 731, 382, 264, 2727, 50653, 50653, 3494, 7645, 288, 11, 577, 576, 291, 3847, 264, 9834, 295, 341, 18161, 3209, 30, 50923, 50923, 961, 385, 352, 2286, 293, 855, 291, 264, 3089, 300, 291, 393, 764, 294, 37624, 281, 3847, 341, 3209, 13, 51193, 51193, 400, 550, 294, 264, 958, 1326, 2145, 934, 341, 11, 321, 603, 9192, 666, 4365, 281, 2903, 437, 264, 51383, 51383, 3089, 307, 767, 884, 13, 51501, 51501, 407, 341, 307, 264, 3089, 291, 576, 2464, 13, 51595, 51595], "temperature": 0.0, "avg_logprob": -0.11304539680480957, "compression_ratio": 1.6194331983805668, "no_speech_prob": 1.4284648386819754e-05}, {"id": 18, "seek": 7556, "start": 75.56, "end": 80.92, "text": " This first part may look familiar from the previous week, where you are asking TensorFlow", "tokens": [50364, 639, 700, 644, 815, 574, 4963, 490, 264, 3894, 1243, 11, 689, 291, 366, 3365, 37624, 50632, 50632, 281, 5123, 3137, 6798, 1214, 613, 1045, 7914, 295, 257, 18161, 3209, 11, 264, 700, 7633, 50920, 50920, 4583, 365, 3552, 6815, 293, 4556, 502, 24433, 11, 264, 1150, 7633, 4583, 11, 293, 550, 2721, 51216, 51216, 264, 5598, 4583, 13, 51294, 51294, 407, 1825, 777, 510, 4972, 281, 437, 291, 1866, 1036, 1243, 13, 51504, 51504, 5736, 1823, 307, 291, 362, 281, 1029, 37624, 281, 31413, 264, 2316, 13, 51726, 51726], "temperature": 0.0, "avg_logprob": -0.12479366426882536, "compression_ratio": 1.6666666666666667, "no_speech_prob": 1.6027607898649876e-06}, {"id": 19, "seek": 7556, "start": 80.92, "end": 86.68, "text": " to sequentially string together these three layers of a neural network, the first hidden", "tokens": [50364, 639, 700, 644, 815, 574, 4963, 490, 264, 3894, 1243, 11, 689, 291, 366, 3365, 37624, 50632, 50632, 281, 5123, 3137, 6798, 1214, 613, 1045, 7914, 295, 257, 18161, 3209, 11, 264, 700, 7633, 50920, 50920, 4583, 365, 3552, 6815, 293, 4556, 502, 24433, 11, 264, 1150, 7633, 4583, 11, 293, 550, 2721, 51216, 51216, 264, 5598, 4583, 13, 51294, 51294, 407, 1825, 777, 510, 4972, 281, 437, 291, 1866, 1036, 1243, 13, 51504, 51504, 5736, 1823, 307, 291, 362, 281, 1029, 37624, 281, 31413, 264, 2316, 13, 51726, 51726], "temperature": 0.0, "avg_logprob": -0.12479366426882536, "compression_ratio": 1.6666666666666667, "no_speech_prob": 1.6027607898649876e-06}, {"id": 20, "seek": 7556, "start": 86.68, "end": 92.6, "text": " layer with 25 units and sig 1 activation, the second hidden layer, and then finally", "tokens": [50364, 639, 700, 644, 815, 574, 4963, 490, 264, 3894, 1243, 11, 689, 291, 366, 3365, 37624, 50632, 50632, 281, 5123, 3137, 6798, 1214, 613, 1045, 7914, 295, 257, 18161, 3209, 11, 264, 700, 7633, 50920, 50920, 4583, 365, 3552, 6815, 293, 4556, 502, 24433, 11, 264, 1150, 7633, 4583, 11, 293, 550, 2721, 51216, 51216, 264, 5598, 4583, 13, 51294, 51294, 407, 1825, 777, 510, 4972, 281, 437, 291, 1866, 1036, 1243, 13, 51504, 51504, 5736, 1823, 307, 291, 362, 281, 1029, 37624, 281, 31413, 264, 2316, 13, 51726, 51726], "temperature": 0.0, "avg_logprob": -0.12479366426882536, "compression_ratio": 1.6666666666666667, "no_speech_prob": 1.6027607898649876e-06}, {"id": 21, "seek": 7556, "start": 92.6, "end": 94.16, "text": " the output layer.", "tokens": [50364, 639, 700, 644, 815, 574, 4963, 490, 264, 3894, 1243, 11, 689, 291, 366, 3365, 37624, 50632, 50632, 281, 5123, 3137, 6798, 1214, 613, 1045, 7914, 295, 257, 18161, 3209, 11, 264, 700, 7633, 50920, 50920, 4583, 365, 3552, 6815, 293, 4556, 502, 24433, 11, 264, 1150, 7633, 4583, 11, 293, 550, 2721, 51216, 51216, 264, 5598, 4583, 13, 51294, 51294, 407, 1825, 777, 510, 4972, 281, 437, 291, 1866, 1036, 1243, 13, 51504, 51504, 5736, 1823, 307, 291, 362, 281, 1029, 37624, 281, 31413, 264, 2316, 13, 51726, 51726], "temperature": 0.0, "avg_logprob": -0.12479366426882536, "compression_ratio": 1.6666666666666667, "no_speech_prob": 1.6027607898649876e-06}, {"id": 22, "seek": 7556, "start": 94.16, "end": 98.36, "text": " So nothing new here relative to what you saw last week.", "tokens": [50364, 639, 700, 644, 815, 574, 4963, 490, 264, 3894, 1243, 11, 689, 291, 366, 3365, 37624, 50632, 50632, 281, 5123, 3137, 6798, 1214, 613, 1045, 7914, 295, 257, 18161, 3209, 11, 264, 700, 7633, 50920, 50920, 4583, 365, 3552, 6815, 293, 4556, 502, 24433, 11, 264, 1150, 7633, 4583, 11, 293, 550, 2721, 51216, 51216, 264, 5598, 4583, 13, 51294, 51294, 407, 1825, 777, 510, 4972, 281, 437, 291, 1866, 1036, 1243, 13, 51504, 51504, 5736, 1823, 307, 291, 362, 281, 1029, 37624, 281, 31413, 264, 2316, 13, 51726, 51726], "temperature": 0.0, "avg_logprob": -0.12479366426882536, "compression_ratio": 1.6666666666666667, "no_speech_prob": 1.6027607898649876e-06}, {"id": 23, "seek": 7556, "start": 98.36, "end": 102.80000000000001, "text": " Second step is you have to ask TensorFlow to compile the model.", "tokens": [50364, 639, 700, 644, 815, 574, 4963, 490, 264, 3894, 1243, 11, 689, 291, 366, 3365, 37624, 50632, 50632, 281, 5123, 3137, 6798, 1214, 613, 1045, 7914, 295, 257, 18161, 3209, 11, 264, 700, 7633, 50920, 50920, 4583, 365, 3552, 6815, 293, 4556, 502, 24433, 11, 264, 1150, 7633, 4583, 11, 293, 550, 2721, 51216, 51216, 264, 5598, 4583, 13, 51294, 51294, 407, 1825, 777, 510, 4972, 281, 437, 291, 1866, 1036, 1243, 13, 51504, 51504, 5736, 1823, 307, 291, 362, 281, 1029, 37624, 281, 31413, 264, 2316, 13, 51726, 51726], "temperature": 0.0, "avg_logprob": -0.12479366426882536, "compression_ratio": 1.6666666666666667, "no_speech_prob": 1.6027607898649876e-06}, {"id": 24, "seek": 10280, "start": 102.8, "end": 108.84, "text": " And the key step in asking TensorFlow to compile the model is to specify what is the loss function", "tokens": [50364, 400, 264, 2141, 1823, 294, 3365, 37624, 281, 31413, 264, 2316, 307, 281, 16500, 437, 307, 264, 4470, 2445, 50666, 50666, 291, 528, 281, 764, 13, 50734, 50734, 682, 341, 1389, 11, 321, 603, 764, 746, 300, 1709, 538, 264, 10346, 1929, 1315, 295, 637, 11668, 19250, 804, 3278, 51018, 51018, 30867, 13, 51068, 51068, 492, 603, 584, 544, 294, 264, 958, 960, 437, 341, 534, 307, 13, 51262, 51262, 400, 550, 1419, 22206, 264, 4470, 2445, 11, 264, 2636, 1823, 307, 281, 818, 264, 3318, 2445, 11, 51580, 51580, 597, 5112, 37624, 281, 3318, 264, 2316, 300, 291, 22206, 294, 1823, 472, 13, 51810, 51810], "temperature": 0.0, "avg_logprob": -0.11672493263527199, "compression_ratio": 1.7768595041322315, "no_speech_prob": 1.56884179887129e-05}, {"id": 25, "seek": 10280, "start": 108.84, "end": 110.2, "text": " you want to use.", "tokens": [50364, 400, 264, 2141, 1823, 294, 3365, 37624, 281, 31413, 264, 2316, 307, 281, 16500, 437, 307, 264, 4470, 2445, 50666, 50666, 291, 528, 281, 764, 13, 50734, 50734, 682, 341, 1389, 11, 321, 603, 764, 746, 300, 1709, 538, 264, 10346, 1929, 1315, 295, 637, 11668, 19250, 804, 3278, 51018, 51018, 30867, 13, 51068, 51068, 492, 603, 584, 544, 294, 264, 958, 960, 437, 341, 534, 307, 13, 51262, 51262, 400, 550, 1419, 22206, 264, 4470, 2445, 11, 264, 2636, 1823, 307, 281, 818, 264, 3318, 2445, 11, 51580, 51580, 597, 5112, 37624, 281, 3318, 264, 2316, 300, 291, 22206, 294, 1823, 472, 13, 51810, 51810], "temperature": 0.0, "avg_logprob": -0.11672493263527199, "compression_ratio": 1.7768595041322315, "no_speech_prob": 1.56884179887129e-05}, {"id": 26, "seek": 10280, "start": 110.2, "end": 115.88, "text": " In this case, we'll use something that goes by the arcane name of sparse categorical cross", "tokens": [50364, 400, 264, 2141, 1823, 294, 3365, 37624, 281, 31413, 264, 2316, 307, 281, 16500, 437, 307, 264, 4470, 2445, 50666, 50666, 291, 528, 281, 764, 13, 50734, 50734, 682, 341, 1389, 11, 321, 603, 764, 746, 300, 1709, 538, 264, 10346, 1929, 1315, 295, 637, 11668, 19250, 804, 3278, 51018, 51018, 30867, 13, 51068, 51068, 492, 603, 584, 544, 294, 264, 958, 960, 437, 341, 534, 307, 13, 51262, 51262, 400, 550, 1419, 22206, 264, 4470, 2445, 11, 264, 2636, 1823, 307, 281, 818, 264, 3318, 2445, 11, 51580, 51580, 597, 5112, 37624, 281, 3318, 264, 2316, 300, 291, 22206, 294, 1823, 472, 13, 51810, 51810], "temperature": 0.0, "avg_logprob": -0.11672493263527199, "compression_ratio": 1.7768595041322315, "no_speech_prob": 1.56884179887129e-05}, {"id": 27, "seek": 10280, "start": 115.88, "end": 116.88, "text": " entropy.", "tokens": [50364, 400, 264, 2141, 1823, 294, 3365, 37624, 281, 31413, 264, 2316, 307, 281, 16500, 437, 307, 264, 4470, 2445, 50666, 50666, 291, 528, 281, 764, 13, 50734, 50734, 682, 341, 1389, 11, 321, 603, 764, 746, 300, 1709, 538, 264, 10346, 1929, 1315, 295, 637, 11668, 19250, 804, 3278, 51018, 51018, 30867, 13, 51068, 51068, 492, 603, 584, 544, 294, 264, 958, 960, 437, 341, 534, 307, 13, 51262, 51262, 400, 550, 1419, 22206, 264, 4470, 2445, 11, 264, 2636, 1823, 307, 281, 818, 264, 3318, 2445, 11, 51580, 51580, 597, 5112, 37624, 281, 3318, 264, 2316, 300, 291, 22206, 294, 1823, 472, 13, 51810, 51810], "temperature": 0.0, "avg_logprob": -0.11672493263527199, "compression_ratio": 1.7768595041322315, "no_speech_prob": 1.56884179887129e-05}, {"id": 28, "seek": 10280, "start": 116.88, "end": 120.75999999999999, "text": " We'll say more in the next video what this really is.", "tokens": [50364, 400, 264, 2141, 1823, 294, 3365, 37624, 281, 31413, 264, 2316, 307, 281, 16500, 437, 307, 264, 4470, 2445, 50666, 50666, 291, 528, 281, 764, 13, 50734, 50734, 682, 341, 1389, 11, 321, 603, 764, 746, 300, 1709, 538, 264, 10346, 1929, 1315, 295, 637, 11668, 19250, 804, 3278, 51018, 51018, 30867, 13, 51068, 51068, 492, 603, 584, 544, 294, 264, 958, 960, 437, 341, 534, 307, 13, 51262, 51262, 400, 550, 1419, 22206, 264, 4470, 2445, 11, 264, 2636, 1823, 307, 281, 818, 264, 3318, 2445, 11, 51580, 51580, 597, 5112, 37624, 281, 3318, 264, 2316, 300, 291, 22206, 294, 1823, 472, 13, 51810, 51810], "temperature": 0.0, "avg_logprob": -0.11672493263527199, "compression_ratio": 1.7768595041322315, "no_speech_prob": 1.56884179887129e-05}, {"id": 29, "seek": 10280, "start": 120.75999999999999, "end": 127.12, "text": " And then having specified the loss function, the third step is to call the fit function,", "tokens": [50364, 400, 264, 2141, 1823, 294, 3365, 37624, 281, 31413, 264, 2316, 307, 281, 16500, 437, 307, 264, 4470, 2445, 50666, 50666, 291, 528, 281, 764, 13, 50734, 50734, 682, 341, 1389, 11, 321, 603, 764, 746, 300, 1709, 538, 264, 10346, 1929, 1315, 295, 637, 11668, 19250, 804, 3278, 51018, 51018, 30867, 13, 51068, 51068, 492, 603, 584, 544, 294, 264, 958, 960, 437, 341, 534, 307, 13, 51262, 51262, 400, 550, 1419, 22206, 264, 4470, 2445, 11, 264, 2636, 1823, 307, 281, 818, 264, 3318, 2445, 11, 51580, 51580, 597, 5112, 37624, 281, 3318, 264, 2316, 300, 291, 22206, 294, 1823, 472, 13, 51810, 51810], "temperature": 0.0, "avg_logprob": -0.11672493263527199, "compression_ratio": 1.7768595041322315, "no_speech_prob": 1.56884179887129e-05}, {"id": 30, "seek": 10280, "start": 127.12, "end": 131.72, "text": " which tells TensorFlow to fit the model that you specified in step one.", "tokens": [50364, 400, 264, 2141, 1823, 294, 3365, 37624, 281, 31413, 264, 2316, 307, 281, 16500, 437, 307, 264, 4470, 2445, 50666, 50666, 291, 528, 281, 764, 13, 50734, 50734, 682, 341, 1389, 11, 321, 603, 764, 746, 300, 1709, 538, 264, 10346, 1929, 1315, 295, 637, 11668, 19250, 804, 3278, 51018, 51018, 30867, 13, 51068, 51068, 492, 603, 584, 544, 294, 264, 958, 960, 437, 341, 534, 307, 13, 51262, 51262, 400, 550, 1419, 22206, 264, 4470, 2445, 11, 264, 2636, 1823, 307, 281, 818, 264, 3318, 2445, 11, 51580, 51580, 597, 5112, 37624, 281, 3318, 264, 2316, 300, 291, 22206, 294, 1823, 472, 13, 51810, 51810], "temperature": 0.0, "avg_logprob": -0.11672493263527199, "compression_ratio": 1.7768595041322315, "no_speech_prob": 1.56884179887129e-05}, {"id": 31, "seek": 13172, "start": 131.72, "end": 138.4, "text": " Using the loss of the cost function that you specified in step two to the data set x, y.", "tokens": [50364, 11142, 264, 4470, 295, 264, 2063, 2445, 300, 291, 22206, 294, 1823, 732, 281, 264, 1412, 992, 2031, 11, 288, 13, 50698, 50698, 400, 646, 294, 264, 700, 1164, 11, 562, 321, 2825, 466, 16235, 23475, 11, 321, 632, 281, 4536, 577, 50956, 50956, 867, 4439, 281, 1190, 16235, 23475, 420, 577, 938, 281, 1190, 16235, 23475, 13, 51138, 51138, 407, 30992, 28346, 307, 257, 6191, 1433, 337, 577, 867, 4439, 295, 2539, 9284, 411, 16235, 51374, 51374, 23475, 291, 815, 528, 281, 1190, 13, 51546, 51546, 400, 300, 311, 309, 13, 51600, 51600], "temperature": 0.0, "avg_logprob": -0.15785298744837442, "compression_ratio": 1.7627906976744185, "no_speech_prob": 7.071493200783152e-06}, {"id": 32, "seek": 13172, "start": 138.4, "end": 143.56, "text": " And back in the first course, when we talked about gradient descent, we had to decide how", "tokens": [50364, 11142, 264, 4470, 295, 264, 2063, 2445, 300, 291, 22206, 294, 1823, 732, 281, 264, 1412, 992, 2031, 11, 288, 13, 50698, 50698, 400, 646, 294, 264, 700, 1164, 11, 562, 321, 2825, 466, 16235, 23475, 11, 321, 632, 281, 4536, 577, 50956, 50956, 867, 4439, 281, 1190, 16235, 23475, 420, 577, 938, 281, 1190, 16235, 23475, 13, 51138, 51138, 407, 30992, 28346, 307, 257, 6191, 1433, 337, 577, 867, 4439, 295, 2539, 9284, 411, 16235, 51374, 51374, 23475, 291, 815, 528, 281, 1190, 13, 51546, 51546, 400, 300, 311, 309, 13, 51600, 51600], "temperature": 0.0, "avg_logprob": -0.15785298744837442, "compression_ratio": 1.7627906976744185, "no_speech_prob": 7.071493200783152e-06}, {"id": 33, "seek": 13172, "start": 143.56, "end": 147.2, "text": " many steps to run gradient descent or how long to run gradient descent.", "tokens": [50364, 11142, 264, 4470, 295, 264, 2063, 2445, 300, 291, 22206, 294, 1823, 732, 281, 264, 1412, 992, 2031, 11, 288, 13, 50698, 50698, 400, 646, 294, 264, 700, 1164, 11, 562, 321, 2825, 466, 16235, 23475, 11, 321, 632, 281, 4536, 577, 50956, 50956, 867, 4439, 281, 1190, 16235, 23475, 420, 577, 938, 281, 1190, 16235, 23475, 13, 51138, 51138, 407, 30992, 28346, 307, 257, 6191, 1433, 337, 577, 867, 4439, 295, 2539, 9284, 411, 16235, 51374, 51374, 23475, 291, 815, 528, 281, 1190, 13, 51546, 51546, 400, 300, 311, 309, 13, 51600, 51600], "temperature": 0.0, "avg_logprob": -0.15785298744837442, "compression_ratio": 1.7627906976744185, "no_speech_prob": 7.071493200783152e-06}, {"id": 34, "seek": 13172, "start": 147.2, "end": 151.92, "text": " So epochs is a technical term for how many steps of learning algorithm like gradient", "tokens": [50364, 11142, 264, 4470, 295, 264, 2063, 2445, 300, 291, 22206, 294, 1823, 732, 281, 264, 1412, 992, 2031, 11, 288, 13, 50698, 50698, 400, 646, 294, 264, 700, 1164, 11, 562, 321, 2825, 466, 16235, 23475, 11, 321, 632, 281, 4536, 577, 50956, 50956, 867, 4439, 281, 1190, 16235, 23475, 420, 577, 938, 281, 1190, 16235, 23475, 13, 51138, 51138, 407, 30992, 28346, 307, 257, 6191, 1433, 337, 577, 867, 4439, 295, 2539, 9284, 411, 16235, 51374, 51374, 23475, 291, 815, 528, 281, 1190, 13, 51546, 51546, 400, 300, 311, 309, 13, 51600, 51600], "temperature": 0.0, "avg_logprob": -0.15785298744837442, "compression_ratio": 1.7627906976744185, "no_speech_prob": 7.071493200783152e-06}, {"id": 35, "seek": 13172, "start": 151.92, "end": 155.36, "text": " descent you may want to run.", "tokens": [50364, 11142, 264, 4470, 295, 264, 2063, 2445, 300, 291, 22206, 294, 1823, 732, 281, 264, 1412, 992, 2031, 11, 288, 13, 50698, 50698, 400, 646, 294, 264, 700, 1164, 11, 562, 321, 2825, 466, 16235, 23475, 11, 321, 632, 281, 4536, 577, 50956, 50956, 867, 4439, 281, 1190, 16235, 23475, 420, 577, 938, 281, 1190, 16235, 23475, 13, 51138, 51138, 407, 30992, 28346, 307, 257, 6191, 1433, 337, 577, 867, 4439, 295, 2539, 9284, 411, 16235, 51374, 51374, 23475, 291, 815, 528, 281, 1190, 13, 51546, 51546, 400, 300, 311, 309, 13, 51600, 51600], "temperature": 0.0, "avg_logprob": -0.15785298744837442, "compression_ratio": 1.7627906976744185, "no_speech_prob": 7.071493200783152e-06}, {"id": 36, "seek": 13172, "start": 155.36, "end": 156.44, "text": " And that's it.", "tokens": [50364, 11142, 264, 4470, 295, 264, 2063, 2445, 300, 291, 22206, 294, 1823, 732, 281, 264, 1412, 992, 2031, 11, 288, 13, 50698, 50698, 400, 646, 294, 264, 700, 1164, 11, 562, 321, 2825, 466, 16235, 23475, 11, 321, 632, 281, 4536, 577, 50956, 50956, 867, 4439, 281, 1190, 16235, 23475, 420, 577, 938, 281, 1190, 16235, 23475, 13, 51138, 51138, 407, 30992, 28346, 307, 257, 6191, 1433, 337, 577, 867, 4439, 295, 2539, 9284, 411, 16235, 51374, 51374, 23475, 291, 815, 528, 281, 1190, 13, 51546, 51546, 400, 300, 311, 309, 13, 51600, 51600], "temperature": 0.0, "avg_logprob": -0.15785298744837442, "compression_ratio": 1.7627906976744185, "no_speech_prob": 7.071493200783152e-06}, {"id": 37, "seek": 15644, "start": 156.44, "end": 163.68, "text": " Step one is to specify the model, which tells TensorFlow how to compute for the inference.", "tokens": [50364, 5470, 472, 307, 281, 16500, 264, 2316, 11, 597, 5112, 37624, 577, 281, 14722, 337, 264, 38253, 13, 50726, 50726, 5470, 732, 715, 4680, 264, 2316, 1228, 257, 2685, 4470, 2445, 13, 50946, 50946, 400, 1823, 1045, 307, 281, 3847, 264, 2316, 13, 51090, 51090, 407, 300, 311, 577, 291, 393, 3847, 257, 18161, 3209, 294, 37624, 13, 51282, 51282, 1018, 7713, 11, 286, 1454, 300, 291, 603, 312, 1075, 281, 406, 445, 818, 613, 3876, 295, 3089, 281, 3847, 264, 51516, 51516, 2316, 11, 457, 300, 291, 611, 1223, 437, 311, 767, 516, 322, 2261, 613, 3876, 295, 3089, 13, 51799, 51799], "temperature": 0.0, "avg_logprob": -0.11870715731666201, "compression_ratio": 1.7666666666666666, "no_speech_prob": 4.289162916393252e-06}, {"id": 38, "seek": 15644, "start": 163.68, "end": 168.07999999999998, "text": " Step two compiles the model using a specific loss function.", "tokens": [50364, 5470, 472, 307, 281, 16500, 264, 2316, 11, 597, 5112, 37624, 577, 281, 14722, 337, 264, 38253, 13, 50726, 50726, 5470, 732, 715, 4680, 264, 2316, 1228, 257, 2685, 4470, 2445, 13, 50946, 50946, 400, 1823, 1045, 307, 281, 3847, 264, 2316, 13, 51090, 51090, 407, 300, 311, 577, 291, 393, 3847, 257, 18161, 3209, 294, 37624, 13, 51282, 51282, 1018, 7713, 11, 286, 1454, 300, 291, 603, 312, 1075, 281, 406, 445, 818, 613, 3876, 295, 3089, 281, 3847, 264, 51516, 51516, 2316, 11, 457, 300, 291, 611, 1223, 437, 311, 767, 516, 322, 2261, 613, 3876, 295, 3089, 13, 51799, 51799], "temperature": 0.0, "avg_logprob": -0.11870715731666201, "compression_ratio": 1.7666666666666666, "no_speech_prob": 4.289162916393252e-06}, {"id": 39, "seek": 15644, "start": 168.07999999999998, "end": 170.96, "text": " And step three is to train the model.", "tokens": [50364, 5470, 472, 307, 281, 16500, 264, 2316, 11, 597, 5112, 37624, 577, 281, 14722, 337, 264, 38253, 13, 50726, 50726, 5470, 732, 715, 4680, 264, 2316, 1228, 257, 2685, 4470, 2445, 13, 50946, 50946, 400, 1823, 1045, 307, 281, 3847, 264, 2316, 13, 51090, 51090, 407, 300, 311, 577, 291, 393, 3847, 257, 18161, 3209, 294, 37624, 13, 51282, 51282, 1018, 7713, 11, 286, 1454, 300, 291, 603, 312, 1075, 281, 406, 445, 818, 613, 3876, 295, 3089, 281, 3847, 264, 51516, 51516, 2316, 11, 457, 300, 291, 611, 1223, 437, 311, 767, 516, 322, 2261, 613, 3876, 295, 3089, 13, 51799, 51799], "temperature": 0.0, "avg_logprob": -0.11870715731666201, "compression_ratio": 1.7666666666666666, "no_speech_prob": 4.289162916393252e-06}, {"id": 40, "seek": 15644, "start": 170.96, "end": 174.8, "text": " So that's how you can train a neural network in TensorFlow.", "tokens": [50364, 5470, 472, 307, 281, 16500, 264, 2316, 11, 597, 5112, 37624, 577, 281, 14722, 337, 264, 38253, 13, 50726, 50726, 5470, 732, 715, 4680, 264, 2316, 1228, 257, 2685, 4470, 2445, 13, 50946, 50946, 400, 1823, 1045, 307, 281, 3847, 264, 2316, 13, 51090, 51090, 407, 300, 311, 577, 291, 393, 3847, 257, 18161, 3209, 294, 37624, 13, 51282, 51282, 1018, 7713, 11, 286, 1454, 300, 291, 603, 312, 1075, 281, 406, 445, 818, 613, 3876, 295, 3089, 281, 3847, 264, 51516, 51516, 2316, 11, 457, 300, 291, 611, 1223, 437, 311, 767, 516, 322, 2261, 613, 3876, 295, 3089, 13, 51799, 51799], "temperature": 0.0, "avg_logprob": -0.11870715731666201, "compression_ratio": 1.7666666666666666, "no_speech_prob": 4.289162916393252e-06}, {"id": 41, "seek": 15644, "start": 174.8, "end": 179.48, "text": " As usual, I hope that you'll be able to not just call these lines of code to train the", "tokens": [50364, 5470, 472, 307, 281, 16500, 264, 2316, 11, 597, 5112, 37624, 577, 281, 14722, 337, 264, 38253, 13, 50726, 50726, 5470, 732, 715, 4680, 264, 2316, 1228, 257, 2685, 4470, 2445, 13, 50946, 50946, 400, 1823, 1045, 307, 281, 3847, 264, 2316, 13, 51090, 51090, 407, 300, 311, 577, 291, 393, 3847, 257, 18161, 3209, 294, 37624, 13, 51282, 51282, 1018, 7713, 11, 286, 1454, 300, 291, 603, 312, 1075, 281, 406, 445, 818, 613, 3876, 295, 3089, 281, 3847, 264, 51516, 51516, 2316, 11, 457, 300, 291, 611, 1223, 437, 311, 767, 516, 322, 2261, 613, 3876, 295, 3089, 13, 51799, 51799], "temperature": 0.0, "avg_logprob": -0.11870715731666201, "compression_ratio": 1.7666666666666666, "no_speech_prob": 4.289162916393252e-06}, {"id": 42, "seek": 15644, "start": 179.48, "end": 185.14, "text": " model, but that you also understand what's actually going on behind these lines of code.", "tokens": [50364, 5470, 472, 307, 281, 16500, 264, 2316, 11, 597, 5112, 37624, 577, 281, 14722, 337, 264, 38253, 13, 50726, 50726, 5470, 732, 715, 4680, 264, 2316, 1228, 257, 2685, 4470, 2445, 13, 50946, 50946, 400, 1823, 1045, 307, 281, 3847, 264, 2316, 13, 51090, 51090, 407, 300, 311, 577, 291, 393, 3847, 257, 18161, 3209, 294, 37624, 13, 51282, 51282, 1018, 7713, 11, 286, 1454, 300, 291, 603, 312, 1075, 281, 406, 445, 818, 613, 3876, 295, 3089, 281, 3847, 264, 51516, 51516, 2316, 11, 457, 300, 291, 611, 1223, 437, 311, 767, 516, 322, 2261, 613, 3876, 295, 3089, 13, 51799, 51799], "temperature": 0.0, "avg_logprob": -0.11870715731666201, "compression_ratio": 1.7666666666666666, "no_speech_prob": 4.289162916393252e-06}, {"id": 43, "seek": 18514, "start": 185.14, "end": 189.67999999999998, "text": " So you don't just call it without really understanding what's going on.", "tokens": [50364, 407, 291, 500, 380, 445, 818, 309, 1553, 534, 3701, 437, 311, 516, 322, 13, 50591, 50591, 400, 286, 519, 341, 307, 1021, 570, 562, 291, 434, 2614, 257, 2539, 9284, 11, 498, 309, 50847, 50847, 1177, 380, 589, 9105, 11, 1419, 300, 24106, 4973, 8388, 295, 437, 311, 534, 516, 322, 51151, 51151, 486, 854, 291, 24083, 5699, 721, 500, 380, 589, 264, 636, 291, 2066, 13, 51410, 51410, 407, 365, 300, 11, 718, 311, 352, 322, 281, 264, 958, 960, 11, 689, 321, 603, 9192, 544, 8760, 666, 437, 613, 51659, 51659, 4439, 294, 264, 37624, 11420, 366, 767, 884, 13, 51853, 51853], "temperature": 0.0, "avg_logprob": -0.10438608900408879, "compression_ratio": 1.6594982078853047, "no_speech_prob": 1.3630483408633154e-05}, {"id": 44, "seek": 18514, "start": 189.67999999999998, "end": 194.79999999999998, "text": " And I think this is important because when you're running a learning algorithm, if it", "tokens": [50364, 407, 291, 500, 380, 445, 818, 309, 1553, 534, 3701, 437, 311, 516, 322, 13, 50591, 50591, 400, 286, 519, 341, 307, 1021, 570, 562, 291, 434, 2614, 257, 2539, 9284, 11, 498, 309, 50847, 50847, 1177, 380, 589, 9105, 11, 1419, 300, 24106, 4973, 8388, 295, 437, 311, 534, 516, 322, 51151, 51151, 486, 854, 291, 24083, 5699, 721, 500, 380, 589, 264, 636, 291, 2066, 13, 51410, 51410, 407, 365, 300, 11, 718, 311, 352, 322, 281, 264, 958, 960, 11, 689, 321, 603, 9192, 544, 8760, 666, 437, 613, 51659, 51659, 4439, 294, 264, 37624, 11420, 366, 767, 884, 13, 51853, 51853], "temperature": 0.0, "avg_logprob": -0.10438608900408879, "compression_ratio": 1.6594982078853047, "no_speech_prob": 1.3630483408633154e-05}, {"id": 45, "seek": 18514, "start": 194.79999999999998, "end": 200.88, "text": " doesn't work initially, having that conceptual mental framework of what's really going on", "tokens": [50364, 407, 291, 500, 380, 445, 818, 309, 1553, 534, 3701, 437, 311, 516, 322, 13, 50591, 50591, 400, 286, 519, 341, 307, 1021, 570, 562, 291, 434, 2614, 257, 2539, 9284, 11, 498, 309, 50847, 50847, 1177, 380, 589, 9105, 11, 1419, 300, 24106, 4973, 8388, 295, 437, 311, 534, 516, 322, 51151, 51151, 486, 854, 291, 24083, 5699, 721, 500, 380, 589, 264, 636, 291, 2066, 13, 51410, 51410, 407, 365, 300, 11, 718, 311, 352, 322, 281, 264, 958, 960, 11, 689, 321, 603, 9192, 544, 8760, 666, 437, 613, 51659, 51659, 4439, 294, 264, 37624, 11420, 366, 767, 884, 13, 51853, 51853], "temperature": 0.0, "avg_logprob": -0.10438608900408879, "compression_ratio": 1.6594982078853047, "no_speech_prob": 1.3630483408633154e-05}, {"id": 46, "seek": 18514, "start": 200.88, "end": 206.06, "text": " will help you debug whenever things don't work the way you expect.", "tokens": [50364, 407, 291, 500, 380, 445, 818, 309, 1553, 534, 3701, 437, 311, 516, 322, 13, 50591, 50591, 400, 286, 519, 341, 307, 1021, 570, 562, 291, 434, 2614, 257, 2539, 9284, 11, 498, 309, 50847, 50847, 1177, 380, 589, 9105, 11, 1419, 300, 24106, 4973, 8388, 295, 437, 311, 534, 516, 322, 51151, 51151, 486, 854, 291, 24083, 5699, 721, 500, 380, 589, 264, 636, 291, 2066, 13, 51410, 51410, 407, 365, 300, 11, 718, 311, 352, 322, 281, 264, 958, 960, 11, 689, 321, 603, 9192, 544, 8760, 666, 437, 613, 51659, 51659, 4439, 294, 264, 37624, 11420, 366, 767, 884, 13, 51853, 51853], "temperature": 0.0, "avg_logprob": -0.10438608900408879, "compression_ratio": 1.6594982078853047, "no_speech_prob": 1.3630483408633154e-05}, {"id": 47, "seek": 18514, "start": 206.06, "end": 211.04, "text": " So with that, let's go on to the next video, where we'll dive more deeply into what these", "tokens": [50364, 407, 291, 500, 380, 445, 818, 309, 1553, 534, 3701, 437, 311, 516, 322, 13, 50591, 50591, 400, 286, 519, 341, 307, 1021, 570, 562, 291, 434, 2614, 257, 2539, 9284, 11, 498, 309, 50847, 50847, 1177, 380, 589, 9105, 11, 1419, 300, 24106, 4973, 8388, 295, 437, 311, 534, 516, 322, 51151, 51151, 486, 854, 291, 24083, 5699, 721, 500, 380, 589, 264, 636, 291, 2066, 13, 51410, 51410, 407, 365, 300, 11, 718, 311, 352, 322, 281, 264, 958, 960, 11, 689, 321, 603, 9192, 544, 8760, 666, 437, 613, 51659, 51659, 4439, 294, 264, 37624, 11420, 366, 767, 884, 13, 51853, 51853], "temperature": 0.0, "avg_logprob": -0.10438608900408879, "compression_ratio": 1.6594982078853047, "no_speech_prob": 1.3630483408633154e-05}, {"id": 48, "seek": 18514, "start": 211.04, "end": 214.92, "text": " steps in the TensorFlow implementation are actually doing.", "tokens": [50364, 407, 291, 500, 380, 445, 818, 309, 1553, 534, 3701, 437, 311, 516, 322, 13, 50591, 50591, 400, 286, 519, 341, 307, 1021, 570, 562, 291, 434, 2614, 257, 2539, 9284, 11, 498, 309, 50847, 50847, 1177, 380, 589, 9105, 11, 1419, 300, 24106, 4973, 8388, 295, 437, 311, 534, 516, 322, 51151, 51151, 486, 854, 291, 24083, 5699, 721, 500, 380, 589, 264, 636, 291, 2066, 13, 51410, 51410, 407, 365, 300, 11, 718, 311, 352, 322, 281, 264, 958, 960, 11, 689, 321, 603, 9192, 544, 8760, 666, 437, 613, 51659, 51659, 4439, 294, 264, 37624, 11420, 366, 767, 884, 13, 51853, 51853], "temperature": 0.0, "avg_logprob": -0.10438608900408879, "compression_ratio": 1.6594982078853047, "no_speech_prob": 1.3630483408633154e-05}, {"id": 49, "seek": 21492, "start": 214.92, "end": 216.2, "text": " I'll see you in the next video.", "tokens": [50364, 286, 603, 536, 291, 294, 264, 958, 960, 13, 50428], "temperature": 0.0, "avg_logprob": -0.13113333781560263, "compression_ratio": 0.7948717948717948, "no_speech_prob": 0.00036687604733742774}], "language": "en", "video_id": "jdjGdT_jR50", "entity": "ML Specialization, Andrew Ng (2022)"}}